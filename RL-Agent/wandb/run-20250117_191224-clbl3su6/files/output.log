Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.14488
Policy Entropy: 2.09965
Value Function Loss: 0.18156

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00120
Policy Update Magnitude: 0.10973
Value Function Update Magnitude: 0.17410

Collected Steps per Second: 7,160.20020
Overall Steps per Second: 3,884.07359

Timestep Collection Time: 6.98472
Timestep Consumption Time: 5.89145
PPO Batch Consumption Time: 2.46956
Total Iteration Time: 12.87617

Cumulative Model Updates: 5,438
Cumulative Timesteps: 45,466,744

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377.91097
Policy Entropy: 2.12072
Value Function Loss: 0.18146

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05445
Policy Update Magnitude: 0.22891
Value Function Update Magnitude: 0.30819

Collected Steps per Second: 20,455.87256
Overall Steps per Second: 11,685.38217

Timestep Collection Time: 2.44517
Timestep Consumption Time: 1.83522
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.28039

Cumulative Model Updates: 5,442
Cumulative Timesteps: 45,516,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 45516762...
Checkpoint 45516762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,912.75329
Policy Entropy: 2.10540
Value Function Loss: 0.17375

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.33566
Value Function Update Magnitude: 0.41132

Collected Steps per Second: 21,240.83063
Overall Steps per Second: 10,351.85073

Timestep Collection Time: 2.35443
Timestep Consumption Time: 2.47659
PPO Batch Consumption Time: 0.29933
Total Iteration Time: 4.83102

Cumulative Model Updates: 5,448
Cumulative Timesteps: 45,566,772

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530.23932
Policy Entropy: 2.11617
Value Function Loss: 0.18164

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07458
Policy Update Magnitude: 0.33000
Value Function Update Magnitude: 0.41064

Collected Steps per Second: 21,448.15264
Overall Steps per Second: 10,644.08168

Timestep Collection Time: 2.33139
Timestep Consumption Time: 2.36643
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.69782

Cumulative Model Updates: 5,454
Cumulative Timesteps: 45,616,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 45616776...
Checkpoint 45616776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,767.20595
Policy Entropy: 2.10632
Value Function Loss: 0.19160

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.33157
Value Function Update Magnitude: 0.35589

Collected Steps per Second: 21,173.00048
Overall Steps per Second: 10,116.04508

Timestep Collection Time: 2.36216
Timestep Consumption Time: 2.58187
PPO Batch Consumption Time: 0.31526
Total Iteration Time: 4.94403

Cumulative Model Updates: 5,460
Cumulative Timesteps: 45,666,790

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,734.90175
Policy Entropy: 2.10406
Value Function Loss: 0.17800

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08601
Policy Update Magnitude: 0.33644
Value Function Update Magnitude: 0.33914

Collected Steps per Second: 20,530.96043
Overall Steps per Second: 10,244.20728

Timestep Collection Time: 2.43554
Timestep Consumption Time: 2.44566
PPO Batch Consumption Time: 0.29792
Total Iteration Time: 4.88120

Cumulative Model Updates: 5,466
Cumulative Timesteps: 45,716,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 45716794...
Checkpoint 45716794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.79815
Policy Entropy: 2.09055
Value Function Loss: 0.18158

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08252
Policy Update Magnitude: 0.32452
Value Function Update Magnitude: 0.35252

Collected Steps per Second: 19,036.62411
Overall Steps per Second: 9,855.96878

Timestep Collection Time: 2.62736
Timestep Consumption Time: 2.44733
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 5.07469

Cumulative Model Updates: 5,472
Cumulative Timesteps: 45,766,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,161.31444
Policy Entropy: 2.09122
Value Function Loss: 0.16796

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06463
Policy Update Magnitude: 0.32582
Value Function Update Magnitude: 0.32581

Collected Steps per Second: 19,793.10376
Overall Steps per Second: 9,949.70114

Timestep Collection Time: 2.52644
Timestep Consumption Time: 2.49944
PPO Batch Consumption Time: 0.30031
Total Iteration Time: 5.02588

Cumulative Model Updates: 5,478
Cumulative Timesteps: 45,816,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 45816816...
Checkpoint 45816816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,813.08342
Policy Entropy: 2.09210
Value Function Loss: 0.15963

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07279
Policy Update Magnitude: 0.32807
Value Function Update Magnitude: 0.51827

Collected Steps per Second: 20,136.75258
Overall Steps per Second: 10,076.86836

Timestep Collection Time: 2.48342
Timestep Consumption Time: 2.47923
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 4.96265

Cumulative Model Updates: 5,484
Cumulative Timesteps: 45,866,824

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,019.10951
Policy Entropy: 2.09792
Value Function Loss: 0.15682

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.34191
Value Function Update Magnitude: 0.56957

Collected Steps per Second: 20,115.70108
Overall Steps per Second: 10,418.50061

Timestep Collection Time: 2.48582
Timestep Consumption Time: 2.31372
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.79954

Cumulative Model Updates: 5,490
Cumulative Timesteps: 45,916,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 45916828...
Checkpoint 45916828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,665.11163
Policy Entropy: 2.08188
Value Function Loss: 0.17100

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.30831
Value Function Update Magnitude: 0.45233

Collected Steps per Second: 21,209.65683
Overall Steps per Second: 10,606.72494

Timestep Collection Time: 2.35845
Timestep Consumption Time: 2.35761
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.71606

Cumulative Model Updates: 5,496
Cumulative Timesteps: 45,966,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,700.04727
Policy Entropy: 2.06987
Value Function Loss: 0.17591

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.30866
Value Function Update Magnitude: 0.35974

Collected Steps per Second: 20,725.81451
Overall Steps per Second: 10,408.29461

Timestep Collection Time: 2.41361
Timestep Consumption Time: 2.39256
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.80617

Cumulative Model Updates: 5,502
Cumulative Timesteps: 46,016,874

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 46016874...
Checkpoint 46016874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,232.56347
Policy Entropy: 2.07299
Value Function Loss: 0.18158

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.31562
Value Function Update Magnitude: 0.36547

Collected Steps per Second: 20,433.79412
Overall Steps per Second: 9,869.56018

Timestep Collection Time: 2.44810
Timestep Consumption Time: 2.62041
PPO Batch Consumption Time: 0.30694
Total Iteration Time: 5.06851

Cumulative Model Updates: 5,508
Cumulative Timesteps: 46,066,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.29351
Policy Entropy: 2.05711
Value Function Loss: 0.18271

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.16101
Policy Update Magnitude: 0.28176
Value Function Update Magnitude: 0.37496

Collected Steps per Second: 20,366.81935
Overall Steps per Second: 10,398.48757

Timestep Collection Time: 2.45615
Timestep Consumption Time: 2.35455
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.81070

Cumulative Model Updates: 5,514
Cumulative Timesteps: 46,116,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 46116922...
Checkpoint 46116922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.76006
Policy Entropy: 2.04619
Value Function Loss: 0.18552

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.16158
Policy Update Magnitude: 0.24040
Value Function Update Magnitude: 0.37168

Collected Steps per Second: 20,438.30517
Overall Steps per Second: 10,175.67369

Timestep Collection Time: 2.44727
Timestep Consumption Time: 2.46818
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.91545

Cumulative Model Updates: 5,520
Cumulative Timesteps: 46,166,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,271.50048
Policy Entropy: 2.03874
Value Function Loss: 0.20098

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.24600
Value Function Update Magnitude: 0.34996

Collected Steps per Second: 20,001.01284
Overall Steps per Second: 9,587.80799

Timestep Collection Time: 2.50187
Timestep Consumption Time: 2.71726
PPO Batch Consumption Time: 0.32129
Total Iteration Time: 5.21913

Cumulative Model Updates: 5,526
Cumulative Timesteps: 46,216,980

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 46216980...
Checkpoint 46216980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,079.85032
Policy Entropy: 2.04199
Value Function Loss: 0.18891

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.19263
Policy Update Magnitude: 0.24069
Value Function Update Magnitude: 0.31849

Collected Steps per Second: 19,322.66639
Overall Steps per Second: 9,594.84785

Timestep Collection Time: 2.58774
Timestep Consumption Time: 2.62360
PPO Batch Consumption Time: 0.31124
Total Iteration Time: 5.21134

Cumulative Model Updates: 5,532
Cumulative Timesteps: 46,266,982

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626.83353
Policy Entropy: 2.04294
Value Function Loss: 0.19893

Mean KL Divergence: 0.03514
SB3 Clip Fraction: 0.24532
Policy Update Magnitude: 0.22112
Value Function Update Magnitude: 0.31933

Collected Steps per Second: 19,764.41747
Overall Steps per Second: 10,091.80334

Timestep Collection Time: 2.53132
Timestep Consumption Time: 2.42617
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.95749

Cumulative Model Updates: 5,538
Cumulative Timesteps: 46,317,012

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 46317012...
Checkpoint 46317012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,559.84728
Policy Entropy: 2.05300
Value Function Loss: 0.21210

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.22097
Value Function Update Magnitude: 0.32295

Collected Steps per Second: 20,799.09006
Overall Steps per Second: 10,120.12438

Timestep Collection Time: 2.40491
Timestep Consumption Time: 2.53771
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.94263

Cumulative Model Updates: 5,544
Cumulative Timesteps: 46,367,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.96322
Policy Entropy: 2.04608
Value Function Loss: 0.22391

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.26063
Value Function Update Magnitude: 0.37817

Collected Steps per Second: 22,192.21898
Overall Steps per Second: 10,606.06674

Timestep Collection Time: 2.25331
Timestep Consumption Time: 2.46154
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 4.71485

Cumulative Model Updates: 5,550
Cumulative Timesteps: 46,417,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 46417038...
Checkpoint 46417038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,942.49177
Policy Entropy: 2.04305
Value Function Loss: 0.25903

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.25668
Value Function Update Magnitude: 0.30485

Collected Steps per Second: 19,345.57315
Overall Steps per Second: 9,757.91269

Timestep Collection Time: 2.58529
Timestep Consumption Time: 2.54019
PPO Batch Consumption Time: 0.29962
Total Iteration Time: 5.12548

Cumulative Model Updates: 5,556
Cumulative Timesteps: 46,467,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,053.08942
Policy Entropy: 2.05176
Value Function Loss: 0.21860

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.26359
Value Function Update Magnitude: 0.30151

Collected Steps per Second: 19,933.82328
Overall Steps per Second: 9,701.86977

Timestep Collection Time: 2.50970
Timestep Consumption Time: 2.64683
PPO Batch Consumption Time: 0.30382
Total Iteration Time: 5.15653

Cumulative Model Updates: 5,562
Cumulative Timesteps: 46,517,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 46517080...
Checkpoint 46517080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,069.17481
Policy Entropy: 2.07464
Value Function Loss: 0.20883

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.15699
Policy Update Magnitude: 0.26311
Value Function Update Magnitude: 0.34142

Collected Steps per Second: 19,526.79751
Overall Steps per Second: 9,924.58242

Timestep Collection Time: 2.56089
Timestep Consumption Time: 2.47771
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 5.03860

Cumulative Model Updates: 5,568
Cumulative Timesteps: 46,567,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.93440
Policy Entropy: 2.08824
Value Function Loss: 0.20197

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.25310
Value Function Update Magnitude: 0.38418

Collected Steps per Second: 20,031.48686
Overall Steps per Second: 9,732.60589

Timestep Collection Time: 2.49717
Timestep Consumption Time: 2.64246
PPO Batch Consumption Time: 0.30727
Total Iteration Time: 5.13963

Cumulative Model Updates: 5,574
Cumulative Timesteps: 46,617,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 46617108...
Checkpoint 46617108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,058.20910
Policy Entropy: 2.09038
Value Function Loss: 0.19605

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.28162
Value Function Update Magnitude: 0.38127

Collected Steps per Second: 20,333.37430
Overall Steps per Second: 10,112.61626

Timestep Collection Time: 2.45911
Timestep Consumption Time: 2.48541
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.94452

Cumulative Model Updates: 5,580
Cumulative Timesteps: 46,667,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.89597
Policy Entropy: 2.06941
Value Function Loss: 0.18707

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.28688
Value Function Update Magnitude: 0.48215

Collected Steps per Second: 16,349.17453
Overall Steps per Second: 8,771.75611

Timestep Collection Time: 3.05875
Timestep Consumption Time: 2.64228
PPO Batch Consumption Time: 0.29843
Total Iteration Time: 5.70102

Cumulative Model Updates: 5,586
Cumulative Timesteps: 46,717,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 46717118...
Checkpoint 46717118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,832.14298
Policy Entropy: 2.06332
Value Function Loss: 0.18104

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07338
Policy Update Magnitude: 0.30084
Value Function Update Magnitude: 0.47054

Collected Steps per Second: 15,121.99886
Overall Steps per Second: 7,336.18452

Timestep Collection Time: 3.30737
Timestep Consumption Time: 3.51007
PPO Batch Consumption Time: 0.45802
Total Iteration Time: 6.81744

Cumulative Model Updates: 5,592
Cumulative Timesteps: 46,767,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,164.21758
Policy Entropy: 2.05338
Value Function Loss: 0.17544

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08171
Policy Update Magnitude: 0.30408
Value Function Update Magnitude: 0.41784

Collected Steps per Second: 14,877.52317
Overall Steps per Second: 6,561.76276

Timestep Collection Time: 3.36266
Timestep Consumption Time: 4.26151
PPO Batch Consumption Time: 0.56343
Total Iteration Time: 7.62417

Cumulative Model Updates: 5,598
Cumulative Timesteps: 46,817,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 46817160...
Checkpoint 46817160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,383.76234
Policy Entropy: 2.05404
Value Function Loss: 0.17278

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07719
Policy Update Magnitude: 0.29790
Value Function Update Magnitude: 0.43550

Collected Steps per Second: 14,082.05091
Overall Steps per Second: 6,891.50596

Timestep Collection Time: 3.55133
Timestep Consumption Time: 3.70543
PPO Batch Consumption Time: 0.50194
Total Iteration Time: 7.25676

Cumulative Model Updates: 5,604
Cumulative Timesteps: 46,867,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051.80807
Policy Entropy: 2.04568
Value Function Loss: 0.17676

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.31352
Value Function Update Magnitude: 0.36275

Collected Steps per Second: 14,578.29985
Overall Steps per Second: 7,105.80748

Timestep Collection Time: 3.43003
Timestep Consumption Time: 3.60703
PPO Batch Consumption Time: 0.48650
Total Iteration Time: 7.03706

Cumulative Model Updates: 5,610
Cumulative Timesteps: 46,917,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 46917174...
Checkpoint 46917174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,466.04290
Policy Entropy: 2.03082
Value Function Loss: 0.18302

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07225
Policy Update Magnitude: 0.32104
Value Function Update Magnitude: 0.35369

Collected Steps per Second: 15,028.79337
Overall Steps per Second: 7,376.79659

Timestep Collection Time: 3.32854
Timestep Consumption Time: 3.45272
PPO Batch Consumption Time: 0.44909
Total Iteration Time: 6.78126

Cumulative Model Updates: 5,616
Cumulative Timesteps: 46,967,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,966.26715
Policy Entropy: 2.03037
Value Function Loss: 0.17520

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06889
Policy Update Magnitude: 0.31914
Value Function Update Magnitude: 0.38462

Collected Steps per Second: 15,041.33105
Overall Steps per Second: 7,262.53043

Timestep Collection Time: 3.32737
Timestep Consumption Time: 3.56390
PPO Batch Consumption Time: 0.47478
Total Iteration Time: 6.89126

Cumulative Model Updates: 5,622
Cumulative Timesteps: 47,017,246

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 47017246...
Checkpoint 47017246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,433.23803
Policy Entropy: 2.01987
Value Function Loss: 0.16804

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06849
Policy Update Magnitude: 0.30700
Value Function Update Magnitude: 0.44187

Collected Steps per Second: 14,383.12284
Overall Steps per Second: 7,017.27196

Timestep Collection Time: 3.47783
Timestep Consumption Time: 3.65059
PPO Batch Consumption Time: 0.49556
Total Iteration Time: 7.12841

Cumulative Model Updates: 5,628
Cumulative Timesteps: 47,067,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,171.05350
Policy Entropy: 2.01292
Value Function Loss: 0.16589

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.28968
Value Function Update Magnitude: 0.39838

Collected Steps per Second: 14,954.06881
Overall Steps per Second: 7,333.16407

Timestep Collection Time: 3.34478
Timestep Consumption Time: 3.47602
PPO Batch Consumption Time: 0.45314
Total Iteration Time: 6.82079

Cumulative Model Updates: 5,634
Cumulative Timesteps: 47,117,286

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 47117286...
Checkpoint 47117286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,085.77591
Policy Entropy: 2.00865
Value Function Loss: 0.17154

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.28656
Value Function Update Magnitude: 0.38940

Collected Steps per Second: 14,784.16441
Overall Steps per Second: 7,401.81938

Timestep Collection Time: 3.38416
Timestep Consumption Time: 3.37526
PPO Batch Consumption Time: 0.44552
Total Iteration Time: 6.75942

Cumulative Model Updates: 5,640
Cumulative Timesteps: 47,167,318

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,076.83451
Policy Entropy: 2.00393
Value Function Loss: 0.17147

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.25395
Value Function Update Magnitude: 0.37700

Collected Steps per Second: 15,119.74098
Overall Steps per Second: 7,504.79910

Timestep Collection Time: 3.30786
Timestep Consumption Time: 3.35641
PPO Batch Consumption Time: 0.44726
Total Iteration Time: 6.66427

Cumulative Model Updates: 5,646
Cumulative Timesteps: 47,217,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 47217332...
Checkpoint 47217332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764.11267
Policy Entropy: 2.01255
Value Function Loss: 0.17237

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.21674
Value Function Update Magnitude: 0.39351

Collected Steps per Second: 14,323.03901
Overall Steps per Second: 6,918.03713

Timestep Collection Time: 3.49297
Timestep Consumption Time: 3.73885
PPO Batch Consumption Time: 0.51075
Total Iteration Time: 7.23182

Cumulative Model Updates: 5,652
Cumulative Timesteps: 47,267,362

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,075.32670
Policy Entropy: 2.02255
Value Function Loss: 0.17539

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.23892
Value Function Update Magnitude: 0.40325

Collected Steps per Second: 14,686.62168
Overall Steps per Second: 7,348.63876

Timestep Collection Time: 3.40514
Timestep Consumption Time: 3.40020
PPO Batch Consumption Time: 0.45032
Total Iteration Time: 6.80534

Cumulative Model Updates: 5,658
Cumulative Timesteps: 47,317,372

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 47317372...
Checkpoint 47317372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,013.01566
Policy Entropy: 2.02697
Value Function Loss: 0.17970

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08158
Policy Update Magnitude: 0.28238
Value Function Update Magnitude: 0.39066

Collected Steps per Second: 15,456.24483
Overall Steps per Second: 7,493.94523

Timestep Collection Time: 3.23520
Timestep Consumption Time: 3.43739
PPO Batch Consumption Time: 0.45949
Total Iteration Time: 6.67259

Cumulative Model Updates: 5,664
Cumulative Timesteps: 47,367,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.11840
Policy Entropy: 2.03958
Value Function Loss: 0.18025

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.27247
Value Function Update Magnitude: 0.39621

Collected Steps per Second: 15,912.81334
Overall Steps per Second: 7,352.01991

Timestep Collection Time: 3.14250
Timestep Consumption Time: 3.65917
PPO Batch Consumption Time: 0.48314
Total Iteration Time: 6.80167

Cumulative Model Updates: 5,670
Cumulative Timesteps: 47,417,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 47417382...
Checkpoint 47417382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,171.70078
Policy Entropy: 2.02648
Value Function Loss: 0.17872

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.21431
Value Function Update Magnitude: 0.39361

Collected Steps per Second: 15,068.71644
Overall Steps per Second: 7,432.58932

Timestep Collection Time: 3.31840
Timestep Consumption Time: 3.40927
PPO Batch Consumption Time: 0.44946
Total Iteration Time: 6.72767

Cumulative Model Updates: 5,676
Cumulative Timesteps: 47,467,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,827.51652
Policy Entropy: 2.02603
Value Function Loss: 0.17704

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.12267
Policy Update Magnitude: 0.21667
Value Function Update Magnitude: 0.39309

Collected Steps per Second: 15,448.39716
Overall Steps per Second: 7,593.09834

Timestep Collection Time: 3.23775
Timestep Consumption Time: 3.34955
PPO Batch Consumption Time: 0.44517
Total Iteration Time: 6.58730

Cumulative Model Updates: 5,682
Cumulative Timesteps: 47,517,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 47517404...
Checkpoint 47517404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,006.60516
Policy Entropy: 2.04462
Value Function Loss: 0.17161

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.14708
Policy Update Magnitude: 0.21992
Value Function Update Magnitude: 0.40716

Collected Steps per Second: 15,217.94030
Overall Steps per Second: 7,433.97873

Timestep Collection Time: 3.28586
Timestep Consumption Time: 3.44055
PPO Batch Consumption Time: 0.45349
Total Iteration Time: 6.72641

Cumulative Model Updates: 5,688
Cumulative Timesteps: 47,567,408

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,828.50204
Policy Entropy: 2.03793
Value Function Loss: 0.16589

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.14116
Policy Update Magnitude: 0.20535
Value Function Update Magnitude: 0.40964

Collected Steps per Second: 15,363.30401
Overall Steps per Second: 7,281.92675

Timestep Collection Time: 3.25698
Timestep Consumption Time: 3.61455
PPO Batch Consumption Time: 0.48716
Total Iteration Time: 6.87153

Cumulative Model Updates: 5,694
Cumulative Timesteps: 47,617,446

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 47617446...
Checkpoint 47617446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.79821
Policy Entropy: 2.04502
Value Function Loss: 0.17235

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.21569
Value Function Update Magnitude: 0.43542

Collected Steps per Second: 15,898.71678
Overall Steps per Second: 7,591.27944

Timestep Collection Time: 3.14491
Timestep Consumption Time: 3.44160
PPO Batch Consumption Time: 0.44829
Total Iteration Time: 6.58651

Cumulative Model Updates: 5,700
Cumulative Timesteps: 47,667,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,380.53863
Policy Entropy: 2.04380
Value Function Loss: 0.17345

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.24513
Value Function Update Magnitude: 0.42890

Collected Steps per Second: 15,389.56118
Overall Steps per Second: 7,297.84414

Timestep Collection Time: 3.25155
Timestep Consumption Time: 3.60526
PPO Batch Consumption Time: 0.48660
Total Iteration Time: 6.85682

Cumulative Model Updates: 5,706
Cumulative Timesteps: 47,717,486

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 47717486...
Checkpoint 47717486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,549.86742
Policy Entropy: 2.04822
Value Function Loss: 0.16773

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10913
Policy Update Magnitude: 0.26966
Value Function Update Magnitude: 0.56201

Collected Steps per Second: 15,177.35126
Overall Steps per Second: 7,098.21080

Timestep Collection Time: 3.29478
Timestep Consumption Time: 3.75010
PPO Batch Consumption Time: 0.51096
Total Iteration Time: 7.04487

Cumulative Model Updates: 5,712
Cumulative Timesteps: 47,767,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,569.43795
Policy Entropy: 2.05475
Value Function Loss: 0.16284

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.16151
Policy Update Magnitude: 0.23399
Value Function Update Magnitude: 0.63365

Collected Steps per Second: 13,601.90618
Overall Steps per Second: 6,524.80813

Timestep Collection Time: 3.67801
Timestep Consumption Time: 3.98934
PPO Batch Consumption Time: 0.53096
Total Iteration Time: 7.66735

Cumulative Model Updates: 5,718
Cumulative Timesteps: 47,817,520

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 47817520...
Checkpoint 47817520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,428.55465
Policy Entropy: 2.04016
Value Function Loss: 0.15497

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.15433
Policy Update Magnitude: 0.22723
Value Function Update Magnitude: 0.56722

Collected Steps per Second: 13,914.14634
Overall Steps per Second: 7,182.11729

Timestep Collection Time: 3.59476
Timestep Consumption Time: 3.36948
PPO Batch Consumption Time: 0.43627
Total Iteration Time: 6.96424

Cumulative Model Updates: 5,724
Cumulative Timesteps: 47,867,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,597.30279
Policy Entropy: 2.03166
Value Function Loss: 0.16085

Mean KL Divergence: 0.02689
SB3 Clip Fraction: 0.22752
Policy Update Magnitude: 0.22025
Value Function Update Magnitude: 0.47921

Collected Steps per Second: 15,192.57426
Overall Steps per Second: 7,087.30465

Timestep Collection Time: 3.29292
Timestep Consumption Time: 3.76589
PPO Batch Consumption Time: 0.51333
Total Iteration Time: 7.05882

Cumulative Model Updates: 5,730
Cumulative Timesteps: 47,917,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 47917566...
Checkpoint 47917566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,962.77367
Policy Entropy: 2.01917
Value Function Loss: 0.16169

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.18335
Policy Update Magnitude: 0.22656
Value Function Update Magnitude: 0.51174

Collected Steps per Second: 14,628.47269
Overall Steps per Second: 6,965.00941

Timestep Collection Time: 3.41854
Timestep Consumption Time: 3.76135
PPO Batch Consumption Time: 0.51177
Total Iteration Time: 7.17989

Cumulative Model Updates: 5,736
Cumulative Timesteps: 47,967,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,412.65838
Policy Entropy: 2.03408
Value Function Loss: 0.16367

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.15484
Policy Update Magnitude: 0.21508
Value Function Update Magnitude: 0.53628

Collected Steps per Second: 14,972.11583
Overall Steps per Second: 7,024.06367

Timestep Collection Time: 3.34141
Timestep Consumption Time: 3.78096
PPO Batch Consumption Time: 0.51578
Total Iteration Time: 7.12237

Cumulative Model Updates: 5,742
Cumulative Timesteps: 48,017,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 48017602...
Checkpoint 48017602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,424.93566
Policy Entropy: 2.04816
Value Function Loss: 0.16063

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.17267
Policy Update Magnitude: 0.20100
Value Function Update Magnitude: 0.43785

Collected Steps per Second: 15,474.68644
Overall Steps per Second: 7,576.35436

Timestep Collection Time: 3.23186
Timestep Consumption Time: 3.36921
PPO Batch Consumption Time: 0.44582
Total Iteration Time: 6.60106

Cumulative Model Updates: 5,748
Cumulative Timesteps: 48,067,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,269.75291
Policy Entropy: 2.05005
Value Function Loss: 0.15491

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.18735
Value Function Update Magnitude: 0.43605

Collected Steps per Second: 15,457.72942
Overall Steps per Second: 7,400.90386

Timestep Collection Time: 3.23476
Timestep Consumption Time: 3.52144
PPO Batch Consumption Time: 0.47264
Total Iteration Time: 6.75620

Cumulative Model Updates: 5,754
Cumulative Timesteps: 48,117,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 48117616...
Checkpoint 48117616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,317.35032
Policy Entropy: 2.03163
Value Function Loss: 0.15657

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.14733
Policy Update Magnitude: 0.20988
Value Function Update Magnitude: 0.42607

Collected Steps per Second: 15,552.65273
Overall Steps per Second: 7,675.94193

Timestep Collection Time: 3.21617
Timestep Consumption Time: 3.30029
PPO Batch Consumption Time: 0.44042
Total Iteration Time: 6.51646

Cumulative Model Updates: 5,760
Cumulative Timesteps: 48,167,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,538.14400
Policy Entropy: 2.02328
Value Function Loss: 0.15063

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.21163
Value Function Update Magnitude: 0.42981

Collected Steps per Second: 15,807.65519
Overall Steps per Second: 7,555.34684

Timestep Collection Time: 3.16328
Timestep Consumption Time: 3.45508
PPO Batch Consumption Time: 0.46189
Total Iteration Time: 6.61836

Cumulative Model Updates: 5,766
Cumulative Timesteps: 48,217,640

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 48217640...
Checkpoint 48217640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,844.19944
Policy Entropy: 2.00676
Value Function Loss: 0.15153

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.22104
Value Function Update Magnitude: 0.43062

Collected Steps per Second: 14,832.17131
Overall Steps per Second: 7,182.16854

Timestep Collection Time: 3.37105
Timestep Consumption Time: 3.59064
PPO Batch Consumption Time: 0.48758
Total Iteration Time: 6.96169

Cumulative Model Updates: 5,772
Cumulative Timesteps: 48,267,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,917.28532
Policy Entropy: 2.01237
Value Function Loss: 0.14744

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.22980
Value Function Update Magnitude: 0.40228

Collected Steps per Second: 15,206.00566
Overall Steps per Second: 7,084.12702

Timestep Collection Time: 3.29015
Timestep Consumption Time: 3.77212
PPO Batch Consumption Time: 0.51476
Total Iteration Time: 7.06227

Cumulative Model Updates: 5,778
Cumulative Timesteps: 48,317,670

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 48317670...
Checkpoint 48317670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,197.91773
Policy Entropy: 2.01772
Value Function Loss: 0.14715

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10618
Policy Update Magnitude: 0.24609
Value Function Update Magnitude: 0.49780

Collected Steps per Second: 15,023.93366
Overall Steps per Second: 7,367.73777

Timestep Collection Time: 3.33175
Timestep Consumption Time: 3.46219
PPO Batch Consumption Time: 0.46546
Total Iteration Time: 6.79394

Cumulative Model Updates: 5,784
Cumulative Timesteps: 48,367,726

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,509.47323
Policy Entropy: 2.01894
Value Function Loss: 0.14365

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10736
Policy Update Magnitude: 0.25657
Value Function Update Magnitude: 0.57726

Collected Steps per Second: 15,022.22863
Overall Steps per Second: 7,220.08361

Timestep Collection Time: 3.32933
Timestep Consumption Time: 3.59773
PPO Batch Consumption Time: 0.48477
Total Iteration Time: 6.92707

Cumulative Model Updates: 5,790
Cumulative Timesteps: 48,417,740

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 48417740...
Checkpoint 48417740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,843.97153
Policy Entropy: 2.03345
Value Function Loss: 0.15673

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.26043
Value Function Update Magnitude: 0.59704

Collected Steps per Second: 14,701.91173
Overall Steps per Second: 7,408.19853

Timestep Collection Time: 3.40405
Timestep Consumption Time: 3.35144
PPO Batch Consumption Time: 0.44778
Total Iteration Time: 6.75549

Cumulative Model Updates: 5,796
Cumulative Timesteps: 48,467,786

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.56270
Policy Entropy: 2.01558
Value Function Loss: 0.17454

Mean KL Divergence: 0.02781
SB3 Clip Fraction: 0.22225
Policy Update Magnitude: 0.21372
Value Function Update Magnitude: 0.48124

Collected Steps per Second: 15,453.58801
Overall Steps per Second: 7,466.61044

Timestep Collection Time: 3.23769
Timestep Consumption Time: 3.46334
PPO Batch Consumption Time: 0.44825
Total Iteration Time: 6.70103

Cumulative Model Updates: 5,802
Cumulative Timesteps: 48,517,820

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 48517820...
Checkpoint 48517820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.31124
Policy Entropy: 2.01736
Value Function Loss: 0.17196

Mean KL Divergence: 0.02276
SB3 Clip Fraction: 0.20423
Policy Update Magnitude: 0.17524
Value Function Update Magnitude: 0.48732

Collected Steps per Second: 15,424.49383
Overall Steps per Second: 7,091.78268

Timestep Collection Time: 3.24432
Timestep Consumption Time: 3.81202
PPO Batch Consumption Time: 0.50870
Total Iteration Time: 7.05634

Cumulative Model Updates: 5,808
Cumulative Timesteps: 48,567,862

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,944.63393
Policy Entropy: 2.01641
Value Function Loss: 0.16924

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.18607
Policy Update Magnitude: 0.17530
Value Function Update Magnitude: 0.55151

Collected Steps per Second: 14,480.18348
Overall Steps per Second: 7,086.30091

Timestep Collection Time: 3.45355
Timestep Consumption Time: 3.60345
PPO Batch Consumption Time: 0.48607
Total Iteration Time: 7.05700

Cumulative Model Updates: 5,814
Cumulative Timesteps: 48,617,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 48617870...
Checkpoint 48617870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793.11224
Policy Entropy: 2.02065
Value Function Loss: 0.17406

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.18577
Policy Update Magnitude: 0.18043
Value Function Update Magnitude: 0.55144

Collected Steps per Second: 14,808.94942
Overall Steps per Second: 7,008.35286

Timestep Collection Time: 3.37674
Timestep Consumption Time: 3.75846
PPO Batch Consumption Time: 0.51150
Total Iteration Time: 7.13520

Cumulative Model Updates: 5,820
Cumulative Timesteps: 48,667,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.83490
Policy Entropy: 2.02526
Value Function Loss: 0.18059

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.18710
Policy Update Magnitude: 0.17234
Value Function Update Magnitude: 0.55222

Collected Steps per Second: 15,231.21234
Overall Steps per Second: 7,092.17405

Timestep Collection Time: 3.28444
Timestep Consumption Time: 3.76925
PPO Batch Consumption Time: 0.50035
Total Iteration Time: 7.05369

Cumulative Model Updates: 5,826
Cumulative Timesteps: 48,717,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 48717902...
Checkpoint 48717902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,575.66516
Policy Entropy: 2.02925
Value Function Loss: 0.18948

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.17771
Policy Update Magnitude: 0.16670
Value Function Update Magnitude: 0.51497

Collected Steps per Second: 14,660.07468
Overall Steps per Second: 6,959.70200

Timestep Collection Time: 3.41212
Timestep Consumption Time: 3.77525
PPO Batch Consumption Time: 0.49980
Total Iteration Time: 7.18738

Cumulative Model Updates: 5,832
Cumulative Timesteps: 48,767,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,837.51443
Policy Entropy: 2.02245
Value Function Loss: 0.19670

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.18172
Policy Update Magnitude: 0.15766
Value Function Update Magnitude: 0.47729

Collected Steps per Second: 15,064.49527
Overall Steps per Second: 7,038.42541

Timestep Collection Time: 3.32052
Timestep Consumption Time: 3.78646
PPO Batch Consumption Time: 0.50425
Total Iteration Time: 7.10699

Cumulative Model Updates: 5,838
Cumulative Timesteps: 48,817,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 48817946...
Checkpoint 48817946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619.80640
Policy Entropy: 2.02050
Value Function Loss: 0.20122

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.16738
Policy Update Magnitude: 0.15654
Value Function Update Magnitude: 0.36791

Collected Steps per Second: 15,327.15540
Overall Steps per Second: 7,469.12009

Timestep Collection Time: 3.26453
Timestep Consumption Time: 3.43452
PPO Batch Consumption Time: 0.44678
Total Iteration Time: 6.69905

Cumulative Model Updates: 5,844
Cumulative Timesteps: 48,867,982

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.14088
Policy Entropy: 2.02723
Value Function Loss: 0.19749

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.15973
Policy Update Magnitude: 0.16119
Value Function Update Magnitude: 0.41277

Collected Steps per Second: 15,502.60518
Overall Steps per Second: 7,438.39994

Timestep Collection Time: 3.22694
Timestep Consumption Time: 3.49843
PPO Batch Consumption Time: 0.45149
Total Iteration Time: 6.72537

Cumulative Model Updates: 5,850
Cumulative Timesteps: 48,918,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 48918008...
Checkpoint 48918008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.85971
Policy Entropy: 2.03296
Value Function Loss: 0.19830

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.17437
Policy Update Magnitude: 0.19244
Value Function Update Magnitude: 0.37028

Collected Steps per Second: 15,601.64385
Overall Steps per Second: 7,544.03662

Timestep Collection Time: 3.20479
Timestep Consumption Time: 3.42296
PPO Batch Consumption Time: 0.44328
Total Iteration Time: 6.62775

Cumulative Model Updates: 5,856
Cumulative Timesteps: 48,968,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.91581
Policy Entropy: 2.04791
Value Function Loss: 0.20340

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.16151
Policy Update Magnitude: 0.19271
Value Function Update Magnitude: 0.33612

Collected Steps per Second: 15,899.62655
Overall Steps per Second: 7,576.04371

Timestep Collection Time: 3.14762
Timestep Consumption Time: 3.45820
PPO Batch Consumption Time: 0.44770
Total Iteration Time: 6.60582

Cumulative Model Updates: 5,862
Cumulative Timesteps: 49,018,054

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 49018054...
Checkpoint 49018054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.51669
Policy Entropy: 2.03116
Value Function Loss: 0.21078

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.17620
Policy Update Magnitude: 0.18766
Value Function Update Magnitude: 0.29728

Collected Steps per Second: 15,795.98449
Overall Steps per Second: 7,239.55476

Timestep Collection Time: 3.16688
Timestep Consumption Time: 3.74294
PPO Batch Consumption Time: 0.49660
Total Iteration Time: 6.90982

Cumulative Model Updates: 5,868
Cumulative Timesteps: 49,068,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.95399
Policy Entropy: 2.03954
Value Function Loss: 0.20816

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.17546
Policy Update Magnitude: 0.19973
Value Function Update Magnitude: 0.32321

Collected Steps per Second: 15,128.60997
Overall Steps per Second: 7,081.37876

Timestep Collection Time: 3.30553
Timestep Consumption Time: 3.75638
PPO Batch Consumption Time: 0.49487
Total Iteration Time: 7.06190

Cumulative Model Updates: 5,874
Cumulative Timesteps: 49,118,086

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 49118086...
Checkpoint 49118086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.46374
Policy Entropy: 2.03250
Value Function Loss: 0.21100

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.15303
Policy Update Magnitude: 0.18832
Value Function Update Magnitude: 0.31625

Collected Steps per Second: 15,122.48990
Overall Steps per Second: 7,332.10276

Timestep Collection Time: 3.30700
Timestep Consumption Time: 3.51369
PPO Batch Consumption Time: 0.45597
Total Iteration Time: 6.82069

Cumulative Model Updates: 5,880
Cumulative Timesteps: 49,168,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,887.59079
Policy Entropy: 2.04250
Value Function Loss: 0.20387

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.16398
Policy Update Magnitude: 0.18681
Value Function Update Magnitude: 0.31725

Collected Steps per Second: 15,996.02638
Overall Steps per Second: 7,610.97793

Timestep Collection Time: 3.12703
Timestep Consumption Time: 3.44506
PPO Batch Consumption Time: 0.44677
Total Iteration Time: 6.57209

Cumulative Model Updates: 5,886
Cumulative Timesteps: 49,218,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 49218116...
Checkpoint 49218116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.51097
Policy Entropy: 2.04567
Value Function Loss: 0.20250

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.15852
Policy Update Magnitude: 0.19711
Value Function Update Magnitude: 0.28727

Collected Steps per Second: 15,640.80374
Overall Steps per Second: 7,483.45562

Timestep Collection Time: 3.19792
Timestep Consumption Time: 3.48589
PPO Batch Consumption Time: 0.45414
Total Iteration Time: 6.68381

Cumulative Model Updates: 5,892
Cumulative Timesteps: 49,268,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.69702
Policy Entropy: 2.05275
Value Function Loss: 0.19794

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.21165
Value Function Update Magnitude: 0.32316

Collected Steps per Second: 15,600.09265
Overall Steps per Second: 7,151.07030

Timestep Collection Time: 3.20601
Timestep Consumption Time: 3.78791
PPO Batch Consumption Time: 0.49624
Total Iteration Time: 6.99392

Cumulative Model Updates: 5,898
Cumulative Timesteps: 49,318,148

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 49318148...
Checkpoint 49318148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.62543
Policy Entropy: 2.03065
Value Function Loss: 0.20199

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.15643
Policy Update Magnitude: 0.21563
Value Function Update Magnitude: 0.31080

Collected Steps per Second: 15,643.98952
Overall Steps per Second: 7,279.61587

Timestep Collection Time: 3.19650
Timestep Consumption Time: 3.67282
PPO Batch Consumption Time: 0.48846
Total Iteration Time: 6.86932

Cumulative Model Updates: 5,904
Cumulative Timesteps: 49,368,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,902.74800
Policy Entropy: 2.05030
Value Function Loss: 0.20675

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.15461
Policy Update Magnitude: 0.22289
Value Function Update Magnitude: 0.31527

Collected Steps per Second: 15,469.06138
Overall Steps per Second: 7,419.63352

Timestep Collection Time: 3.23316
Timestep Consumption Time: 3.50760
PPO Batch Consumption Time: 0.45827
Total Iteration Time: 6.74076

Cumulative Model Updates: 5,910
Cumulative Timesteps: 49,418,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 49418168...
Checkpoint 49418168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,169.07418
Policy Entropy: 2.05326
Value Function Loss: 0.20761

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.16845
Policy Update Magnitude: 0.22874
Value Function Update Magnitude: 0.31473

Collected Steps per Second: 15,579.98994
Overall Steps per Second: 7,317.41712

Timestep Collection Time: 3.20963
Timestep Consumption Time: 3.62420
PPO Batch Consumption Time: 0.47756
Total Iteration Time: 6.83383

Cumulative Model Updates: 5,916
Cumulative Timesteps: 49,468,174

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.45280
Policy Entropy: 2.05522
Value Function Loss: 0.20850

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.23047
Value Function Update Magnitude: 0.30341

Collected Steps per Second: 15,528.35535
Overall Steps per Second: 7,251.84657

Timestep Collection Time: 3.22030
Timestep Consumption Time: 3.67532
PPO Batch Consumption Time: 0.48345
Total Iteration Time: 6.89562

Cumulative Model Updates: 5,922
Cumulative Timesteps: 49,518,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 49518180...
Checkpoint 49518180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.75573
Policy Entropy: 2.04466
Value Function Loss: 0.20744

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.16584
Policy Update Magnitude: 0.22660
Value Function Update Magnitude: 0.32216

Collected Steps per Second: 15,464.52248
Overall Steps per Second: 7,427.10809

Timestep Collection Time: 3.23618
Timestep Consumption Time: 3.50211
PPO Batch Consumption Time: 0.45516
Total Iteration Time: 6.73829

Cumulative Model Updates: 5,928
Cumulative Timesteps: 49,568,226

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.01678
Policy Entropy: 2.04253
Value Function Loss: 0.20534

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.23954
Value Function Update Magnitude: 0.33363

Collected Steps per Second: 15,875.01413
Overall Steps per Second: 7,408.60556

Timestep Collection Time: 3.15036
Timestep Consumption Time: 3.60017
PPO Batch Consumption Time: 0.47184
Total Iteration Time: 6.75053

Cumulative Model Updates: 5,934
Cumulative Timesteps: 49,618,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 49618238...
Checkpoint 49618238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,106.47547
Policy Entropy: 2.03107
Value Function Loss: 0.19781

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.22590
Value Function Update Magnitude: 0.37040

Collected Steps per Second: 15,582.42030
Overall Steps per Second: 7,390.35093

Timestep Collection Time: 3.20939
Timestep Consumption Time: 3.55755
PPO Batch Consumption Time: 0.47244
Total Iteration Time: 6.76693

Cumulative Model Updates: 5,940
Cumulative Timesteps: 49,668,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.15126
Policy Entropy: 2.03082
Value Function Loss: 0.18901

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.12033
Policy Update Magnitude: 0.24151
Value Function Update Magnitude: 0.37313

Collected Steps per Second: 15,622.17160
Overall Steps per Second: 7,399.88632

Timestep Collection Time: 3.20135
Timestep Consumption Time: 3.55713
PPO Batch Consumption Time: 0.46911
Total Iteration Time: 6.75848

Cumulative Model Updates: 5,946
Cumulative Timesteps: 49,718,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 49718260...
Checkpoint 49718260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,001.84236
Policy Entropy: 2.01733
Value Function Loss: 0.18653

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.24330
Value Function Update Magnitude: 0.39538

Collected Steps per Second: 15,660.77907
Overall Steps per Second: 7,582.52207

Timestep Collection Time: 3.19460
Timestep Consumption Time: 3.40346
PPO Batch Consumption Time: 0.43903
Total Iteration Time: 6.59807

Cumulative Model Updates: 5,952
Cumulative Timesteps: 49,768,290

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.60826
Policy Entropy: 2.02224
Value Function Loss: 0.19751

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.17505
Policy Update Magnitude: 0.22370
Value Function Update Magnitude: 0.36316

Collected Steps per Second: 16,920.74629
Overall Steps per Second: 7,607.81663

Timestep Collection Time: 2.95543
Timestep Consumption Time: 3.61781
PPO Batch Consumption Time: 0.47736
Total Iteration Time: 6.57324

Cumulative Model Updates: 5,958
Cumulative Timesteps: 49,818,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 49818298...
Checkpoint 49818298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,992.77148
Policy Entropy: 2.00351
Value Function Loss: 0.20729

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.22836
Value Function Update Magnitude: 0.37693

Collected Steps per Second: 15,873.13979
Overall Steps per Second: 7,432.59438

Timestep Collection Time: 3.15124
Timestep Consumption Time: 3.57858
PPO Batch Consumption Time: 0.47562
Total Iteration Time: 6.72982

Cumulative Model Updates: 5,964
Cumulative Timesteps: 49,868,318

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,885.91659
Policy Entropy: 2.00719
Value Function Loss: 0.20029

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10152
Policy Update Magnitude: 0.28978
Value Function Update Magnitude: 0.41047

Collected Steps per Second: 15,940.03522
Overall Steps per Second: 7,431.02457

Timestep Collection Time: 3.13688
Timestep Consumption Time: 3.59194
PPO Batch Consumption Time: 0.47697
Total Iteration Time: 6.72882

Cumulative Model Updates: 5,970
Cumulative Timesteps: 49,918,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 49918320...
Checkpoint 49918320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.53033
Policy Entropy: 1.99853
Value Function Loss: 0.19897

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.12049
Policy Update Magnitude: 0.31291
Value Function Update Magnitude: 0.37518

Collected Steps per Second: 15,837.65260
Overall Steps per Second: 7,410.85267

Timestep Collection Time: 3.15981
Timestep Consumption Time: 3.59299
PPO Batch Consumption Time: 0.47822
Total Iteration Time: 6.75280

Cumulative Model Updates: 5,976
Cumulative Timesteps: 49,968,364

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792.55418
Policy Entropy: 2.00007
Value Function Loss: 0.19907

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.14511
Policy Update Magnitude: 0.28039
Value Function Update Magnitude: 0.34983

Collected Steps per Second: 16,103.51778
Overall Steps per Second: 7,435.18545

Timestep Collection Time: 3.10677
Timestep Consumption Time: 3.62204
PPO Batch Consumption Time: 0.48074
Total Iteration Time: 6.72882

Cumulative Model Updates: 5,982
Cumulative Timesteps: 50,018,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 50018394...
Checkpoint 50018394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.23104
Policy Entropy: 1.97999
Value Function Loss: 0.20754

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.22000
Value Function Update Magnitude: 0.37324

Collected Steps per Second: 16,076.04757
Overall Steps per Second: 7,481.91811

Timestep Collection Time: 3.11134
Timestep Consumption Time: 3.57385
PPO Batch Consumption Time: 0.47407
Total Iteration Time: 6.68518

Cumulative Model Updates: 5,988
Cumulative Timesteps: 50,068,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,104.10359
Policy Entropy: 1.99805
Value Function Loss: 0.19275

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.14884
Policy Update Magnitude: 0.19740
Value Function Update Magnitude: 0.36076

Collected Steps per Second: 16,083.62094
Overall Steps per Second: 7,471.09564

Timestep Collection Time: 3.11149
Timestep Consumption Time: 3.58686
PPO Batch Consumption Time: 0.47730
Total Iteration Time: 6.69835

Cumulative Model Updates: 5,994
Cumulative Timesteps: 50,118,456

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 50118456...
Checkpoint 50118456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.87988
Policy Entropy: 1.97832
Value Function Loss: 0.18571

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.20266
Value Function Update Magnitude: 0.46681

Collected Steps per Second: 15,938.08054
Overall Steps per Second: 7,349.13474

Timestep Collection Time: 3.13739
Timestep Consumption Time: 3.66667
PPO Batch Consumption Time: 0.49091
Total Iteration Time: 6.80407

Cumulative Model Updates: 6,000
Cumulative Timesteps: 50,168,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.92190
Policy Entropy: 1.98943
Value Function Loss: 0.18639

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.22719
Value Function Update Magnitude: 0.42615

Collected Steps per Second: 15,950.61729
Overall Steps per Second: 7,476.05459

Timestep Collection Time: 3.13681
Timestep Consumption Time: 3.55576
PPO Batch Consumption Time: 0.47113
Total Iteration Time: 6.69257

Cumulative Model Updates: 6,006
Cumulative Timesteps: 50,218,494

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 50218494...
Checkpoint 50218494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.56392
Policy Entropy: 1.96979
Value Function Loss: 0.18881

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.20524
Policy Update Magnitude: 0.22414
Value Function Update Magnitude: 0.45005

Collected Steps per Second: 15,901.98503
Overall Steps per Second: 7,414.12574

Timestep Collection Time: 3.14615
Timestep Consumption Time: 3.60178
PPO Batch Consumption Time: 0.48124
Total Iteration Time: 6.74793

Cumulative Model Updates: 6,012
Cumulative Timesteps: 50,268,524

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,684.43097
Policy Entropy: 1.97009
Value Function Loss: 0.20013

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.15794
Policy Update Magnitude: 0.22224
Value Function Update Magnitude: 0.38990

Collected Steps per Second: 15,849.30240
Overall Steps per Second: 7,397.13922

Timestep Collection Time: 3.15560
Timestep Consumption Time: 3.60567
PPO Batch Consumption Time: 0.47815
Total Iteration Time: 6.76126

Cumulative Model Updates: 6,018
Cumulative Timesteps: 50,318,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 50318538...
Checkpoint 50318538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.51591
Policy Entropy: 1.97330
Value Function Loss: 0.19021

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.25091
Value Function Update Magnitude: 0.42565

Collected Steps per Second: 16,210.13532
Overall Steps per Second: 7,489.33181

Timestep Collection Time: 3.08498
Timestep Consumption Time: 3.59225
PPO Batch Consumption Time: 0.47224
Total Iteration Time: 6.67723

Cumulative Model Updates: 6,024
Cumulative Timesteps: 50,368,546

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,711.06433
Policy Entropy: 1.97112
Value Function Loss: 0.19341

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.29455
Value Function Update Magnitude: 0.45489

Collected Steps per Second: 15,983.25008
Overall Steps per Second: 7,455.45453

Timestep Collection Time: 3.12990
Timestep Consumption Time: 3.58009
PPO Batch Consumption Time: 0.47275
Total Iteration Time: 6.70999

Cumulative Model Updates: 6,030
Cumulative Timesteps: 50,418,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 50418572...
Checkpoint 50418572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.92367
Policy Entropy: 1.96614
Value Function Loss: 0.18874

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.30208
Value Function Update Magnitude: 0.38659

Collected Steps per Second: 15,977.89539
Overall Steps per Second: 7,466.76002

Timestep Collection Time: 3.13108
Timestep Consumption Time: 3.56902
PPO Batch Consumption Time: 0.47414
Total Iteration Time: 6.70009

Cumulative Model Updates: 6,036
Cumulative Timesteps: 50,468,600

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.56633
Policy Entropy: 1.95353
Value Function Loss: 0.19355

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.29566
Value Function Update Magnitude: 0.45902

Collected Steps per Second: 15,838.07764
Overall Steps per Second: 7,384.40922

Timestep Collection Time: 3.15859
Timestep Consumption Time: 3.61595
PPO Batch Consumption Time: 0.47994
Total Iteration Time: 6.77454

Cumulative Model Updates: 6,042
Cumulative Timesteps: 50,518,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 50518626...
Checkpoint 50518626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.11771
Policy Entropy: 1.94662
Value Function Loss: 0.19436

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.25925
Value Function Update Magnitude: 0.40356

Collected Steps per Second: 16,063.38958
Overall Steps per Second: 7,493.35677

Timestep Collection Time: 3.11304
Timestep Consumption Time: 3.56034
PPO Batch Consumption Time: 0.47335
Total Iteration Time: 6.67338

Cumulative Model Updates: 6,048
Cumulative Timesteps: 50,568,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,821.32285
Policy Entropy: 1.95184
Value Function Loss: 0.19260

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.14247
Policy Update Magnitude: 0.26422
Value Function Update Magnitude: 0.37477

Collected Steps per Second: 15,703.79108
Overall Steps per Second: 7,301.87831

Timestep Collection Time: 3.18560
Timestep Consumption Time: 3.66551
PPO Batch Consumption Time: 0.48253
Total Iteration Time: 6.85111

Cumulative Model Updates: 6,054
Cumulative Timesteps: 50,618,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 50618658...
Checkpoint 50618658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,379.78914
Policy Entropy: 1.94697
Value Function Loss: 0.18920

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.28548
Value Function Update Magnitude: 0.41998

Collected Steps per Second: 15,803.43439
Overall Steps per Second: 7,304.94580

Timestep Collection Time: 3.16539
Timestep Consumption Time: 3.68258
PPO Batch Consumption Time: 0.49312
Total Iteration Time: 6.84796

Cumulative Model Updates: 6,060
Cumulative Timesteps: 50,668,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,722.36153
Policy Entropy: 1.93577
Value Function Loss: 0.18634

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.30821
Value Function Update Magnitude: 0.46070

Collected Steps per Second: 16,107.53490
Overall Steps per Second: 7,470.12503

Timestep Collection Time: 3.10488
Timestep Consumption Time: 3.59005
PPO Batch Consumption Time: 0.47606
Total Iteration Time: 6.69493

Cumulative Model Updates: 6,066
Cumulative Timesteps: 50,718,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 50718694...
Checkpoint 50718694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,166.05161
Policy Entropy: 1.92652
Value Function Loss: 0.18254

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07571
Policy Update Magnitude: 0.31151
Value Function Update Magnitude: 0.46037

Collected Steps per Second: 14,840.92247
Overall Steps per Second: 8,405.67309

Timestep Collection Time: 3.37055
Timestep Consumption Time: 2.58044
PPO Batch Consumption Time: 0.30345
Total Iteration Time: 5.95098

Cumulative Model Updates: 6,072
Cumulative Timesteps: 50,768,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,954.21732
Policy Entropy: 1.92952
Value Function Loss: 0.19032

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.31696
Value Function Update Magnitude: 0.42053

Collected Steps per Second: 17,595.15403
Overall Steps per Second: 8,966.46096

Timestep Collection Time: 2.84317
Timestep Consumption Time: 2.73607
PPO Batch Consumption Time: 0.31253
Total Iteration Time: 5.57924

Cumulative Model Updates: 6,078
Cumulative Timesteps: 50,818,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 50818742...
Checkpoint 50818742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,405.57988
Policy Entropy: 1.93175
Value Function Loss: 0.18971

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10832
Policy Update Magnitude: 0.33558
Value Function Update Magnitude: 0.42347

Collected Steps per Second: 19,531.21569
Overall Steps per Second: 9,793.24444

Timestep Collection Time: 2.56185
Timestep Consumption Time: 2.54739
PPO Batch Consumption Time: 0.30054
Total Iteration Time: 5.10924

Cumulative Model Updates: 6,084
Cumulative Timesteps: 50,868,778

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,813.39013
Policy Entropy: 1.92418
Value Function Loss: 0.19078

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.15105
Policy Update Magnitude: 0.28190
Value Function Update Magnitude: 0.42243

Collected Steps per Second: 21,581.02354
Overall Steps per Second: 10,367.87144

Timestep Collection Time: 2.31778
Timestep Consumption Time: 2.50674
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.82452

Cumulative Model Updates: 6,090
Cumulative Timesteps: 50,918,798

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 50918798...
Checkpoint 50918798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,452.41120
Policy Entropy: 1.91646
Value Function Loss: 0.19358

Mean KL Divergence: 0.02460
SB3 Clip Fraction: 0.21317
Policy Update Magnitude: 0.24172
Value Function Update Magnitude: 0.43094

Collected Steps per Second: 21,093.52685
Overall Steps per Second: 10,295.94249

Timestep Collection Time: 2.37191
Timestep Consumption Time: 2.48748
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.85939

Cumulative Model Updates: 6,096
Cumulative Timesteps: 50,968,830

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,459.23862
Policy Entropy: 1.91028
Value Function Loss: 0.20179

Mean KL Divergence: 0.03681
SB3 Clip Fraction: 0.24702
Policy Update Magnitude: 0.20468
Value Function Update Magnitude: 0.40139

Collected Steps per Second: 21,537.79513
Overall Steps per Second: 10,407.56235

Timestep Collection Time: 2.32336
Timestep Consumption Time: 2.48468
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.80804

Cumulative Model Updates: 6,102
Cumulative Timesteps: 51,018,870

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 51018870...
Checkpoint 51018870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.50067
Policy Entropy: 1.90277
Value Function Loss: 0.20261

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.16019
Policy Update Magnitude: 0.21541
Value Function Update Magnitude: 0.42569

Collected Steps per Second: 20,539.77514
Overall Steps per Second: 10,038.59835

Timestep Collection Time: 2.43547
Timestep Consumption Time: 2.54770
PPO Batch Consumption Time: 0.30033
Total Iteration Time: 4.98317

Cumulative Model Updates: 6,108
Cumulative Timesteps: 51,068,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,269.81285
Policy Entropy: 1.90387
Value Function Loss: 0.19519

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.22589
Value Function Update Magnitude: 0.35102

Collected Steps per Second: 21,292.18071
Overall Steps per Second: 10,291.05025

Timestep Collection Time: 2.34828
Timestep Consumption Time: 2.51031
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.85859

Cumulative Model Updates: 6,114
Cumulative Timesteps: 51,118,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 51118894...
Checkpoint 51118894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,531.03262
Policy Entropy: 1.93439
Value Function Loss: 0.18563

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.22625
Value Function Update Magnitude: 0.33573

Collected Steps per Second: 20,865.19496
Overall Steps per Second: 10,249.93035

Timestep Collection Time: 2.39787
Timestep Consumption Time: 2.48334
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.88120

Cumulative Model Updates: 6,120
Cumulative Timesteps: 51,168,926

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,606.26392
Policy Entropy: 1.93252
Value Function Loss: 0.17214

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.22819
Value Function Update Magnitude: 0.43899

Collected Steps per Second: 21,065.08460
Overall Steps per Second: 10,169.48443

Timestep Collection Time: 2.37474
Timestep Consumption Time: 2.54429
PPO Batch Consumption Time: 0.30014
Total Iteration Time: 4.91903

Cumulative Model Updates: 6,126
Cumulative Timesteps: 51,218,950

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 51218950...
Checkpoint 51218950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,539.08384
Policy Entropy: 1.93011
Value Function Loss: 0.16749

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.23135
Value Function Update Magnitude: 0.46354

Collected Steps per Second: 21,184.22270
Overall Steps per Second: 10,215.26681

Timestep Collection Time: 2.36129
Timestep Consumption Time: 2.53550
PPO Batch Consumption Time: 0.29825
Total Iteration Time: 4.89679

Cumulative Model Updates: 6,132
Cumulative Timesteps: 51,268,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,559.98931
Policy Entropy: 1.93419
Value Function Loss: 0.15818

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06520
Policy Update Magnitude: 0.27500
Value Function Update Magnitude: 0.45141

Collected Steps per Second: 21,694.91455
Overall Steps per Second: 10,289.37372

Timestep Collection Time: 2.30598
Timestep Consumption Time: 2.55613
PPO Batch Consumption Time: 0.30241
Total Iteration Time: 4.86210

Cumulative Model Updates: 6,138
Cumulative Timesteps: 51,319,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 51319000...
Checkpoint 51319000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,818.32365
Policy Entropy: 1.93695
Value Function Loss: 0.15953

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08190
Policy Update Magnitude: 0.28566
Value Function Update Magnitude: 0.39783

Collected Steps per Second: 21,210.77622
Overall Steps per Second: 10,169.33780

Timestep Collection Time: 2.35758
Timestep Consumption Time: 2.55976
PPO Batch Consumption Time: 0.30298
Total Iteration Time: 4.91733

Cumulative Model Updates: 6,144
Cumulative Timesteps: 51,369,006

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,009.47192
Policy Entropy: 1.93317
Value Function Loss: 0.15295

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.04817
Policy Update Magnitude: 0.28608
Value Function Update Magnitude: 0.47679

Collected Steps per Second: 21,479.73308
Overall Steps per Second: 10,375.70635

Timestep Collection Time: 2.32805
Timestep Consumption Time: 2.49147
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.81953

Cumulative Model Updates: 6,150
Cumulative Timesteps: 51,419,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 51419012...
Checkpoint 51419012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,942.28133
Policy Entropy: 1.93868
Value Function Loss: 0.15704

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07838
Policy Update Magnitude: 0.28880
Value Function Update Magnitude: 0.54251

Collected Steps per Second: 20,864.92237
Overall Steps per Second: 10,200.41652

Timestep Collection Time: 2.39838
Timestep Consumption Time: 2.50750
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.90588

Cumulative Model Updates: 6,156
Cumulative Timesteps: 51,469,054

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,753.54949
Policy Entropy: 1.93914
Value Function Loss: 0.15571

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.25994
Value Function Update Magnitude: 0.58128

Collected Steps per Second: 21,286.40090
Overall Steps per Second: 10,186.82553

Timestep Collection Time: 2.35005
Timestep Consumption Time: 2.56061
PPO Batch Consumption Time: 0.30475
Total Iteration Time: 4.91066

Cumulative Model Updates: 6,162
Cumulative Timesteps: 51,519,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 51519078...
Checkpoint 51519078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,299.67649
Policy Entropy: 1.94248
Value Function Loss: 0.15570

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.24062
Value Function Update Magnitude: 0.58105

Collected Steps per Second: 20,881.00205
Overall Steps per Second: 10,106.48537

Timestep Collection Time: 2.39452
Timestep Consumption Time: 2.55280
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.94732

Cumulative Model Updates: 6,168
Cumulative Timesteps: 51,569,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,000.11982
Policy Entropy: 1.93113
Value Function Loss: 0.15518

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.23141
Value Function Update Magnitude: 0.52840

Collected Steps per Second: 21,265.54442
Overall Steps per Second: 10,123.09892

Timestep Collection Time: 2.35150
Timestep Consumption Time: 2.58829
PPO Batch Consumption Time: 0.30323
Total Iteration Time: 4.93979

Cumulative Model Updates: 6,174
Cumulative Timesteps: 51,619,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 51619084...
Checkpoint 51619084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,741.76688
Policy Entropy: 1.94086
Value Function Loss: 0.16004

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.11590
Policy Update Magnitude: 0.24182
Value Function Update Magnitude: 0.39161

Collected Steps per Second: 20,660.08049
Overall Steps per Second: 10,040.50070

Timestep Collection Time: 2.42206
Timestep Consumption Time: 2.56175
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 4.98382

Cumulative Model Updates: 6,180
Cumulative Timesteps: 51,669,124

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,026.72134
Policy Entropy: 1.93357
Value Function Loss: 0.15331

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.26372
Value Function Update Magnitude: 0.37130

Collected Steps per Second: 21,567.68708
Overall Steps per Second: 10,236.14839

Timestep Collection Time: 2.31949
Timestep Consumption Time: 2.56770
PPO Batch Consumption Time: 0.30624
Total Iteration Time: 4.88719

Cumulative Model Updates: 6,186
Cumulative Timesteps: 51,719,150

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 51719150...
Checkpoint 51719150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,995.42034
Policy Entropy: 1.93928
Value Function Loss: 0.15274

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.25322
Value Function Update Magnitude: 0.45794

Collected Steps per Second: 20,954.32625
Overall Steps per Second: 10,065.49757

Timestep Collection Time: 2.38719
Timestep Consumption Time: 2.58246
PPO Batch Consumption Time: 0.30500
Total Iteration Time: 4.96965

Cumulative Model Updates: 6,192
Cumulative Timesteps: 51,769,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,348.20979
Policy Entropy: 1.93796
Value Function Loss: 0.14984

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.23272
Value Function Update Magnitude: 0.48105

Collected Steps per Second: 21,423.61048
Overall Steps per Second: 10,172.24838

Timestep Collection Time: 2.33481
Timestep Consumption Time: 2.58249
PPO Batch Consumption Time: 0.30447
Total Iteration Time: 4.91730

Cumulative Model Updates: 6,198
Cumulative Timesteps: 51,819,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 51819192...
Checkpoint 51819192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,449.58599
Policy Entropy: 1.93609
Value Function Loss: 0.15280

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.25800
Value Function Update Magnitude: 0.40319

Collected Steps per Second: 20,626.69242
Overall Steps per Second: 10,046.89004

Timestep Collection Time: 2.42433
Timestep Consumption Time: 2.55293
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.97726

Cumulative Model Updates: 6,204
Cumulative Timesteps: 51,869,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939.98428
Policy Entropy: 1.92363
Value Function Loss: 0.16019

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.25158
Value Function Update Magnitude: 0.39065

Collected Steps per Second: 21,874.13615
Overall Steps per Second: 10,488.74504

Timestep Collection Time: 2.28736
Timestep Consumption Time: 2.48290
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.77026

Cumulative Model Updates: 6,210
Cumulative Timesteps: 51,919,232

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 51919232...
Checkpoint 51919232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,430.68161
Policy Entropy: 1.92001
Value Function Loss: 0.16681

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.22739
Value Function Update Magnitude: 0.52540

Collected Steps per Second: 21,007.84317
Overall Steps per Second: 10,212.81120

Timestep Collection Time: 2.38140
Timestep Consumption Time: 2.51716
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.89855

Cumulative Model Updates: 6,216
Cumulative Timesteps: 51,969,260

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,787.81450
Policy Entropy: 1.91099
Value Function Loss: 0.16278

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.24221
Value Function Update Magnitude: 0.52443

Collected Steps per Second: 21,595.29953
Overall Steps per Second: 10,369.91154

Timestep Collection Time: 2.31560
Timestep Consumption Time: 2.50662
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 4.82222

Cumulative Model Updates: 6,222
Cumulative Timesteps: 52,019,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 52019266...
Checkpoint 52019266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,339.27719
Policy Entropy: 1.91478
Value Function Loss: 0.15966

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.25305
Value Function Update Magnitude: 0.53761

Collected Steps per Second: 20,993.54035
Overall Steps per Second: 10,116.75387

Timestep Collection Time: 2.38254
Timestep Consumption Time: 2.56153
PPO Batch Consumption Time: 0.30573
Total Iteration Time: 4.94408

Cumulative Model Updates: 6,228
Cumulative Timesteps: 52,069,284

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,500.41813
Policy Entropy: 1.91568
Value Function Loss: 0.15344

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.23724
Value Function Update Magnitude: 0.50993

Collected Steps per Second: 20,911.21812
Overall Steps per Second: 10,248.38106

Timestep Collection Time: 2.39221
Timestep Consumption Time: 2.48895
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.88116

Cumulative Model Updates: 6,234
Cumulative Timesteps: 52,119,308

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 52119308...
Checkpoint 52119308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,441.42413
Policy Entropy: 1.90406
Value Function Loss: 0.15900

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.23436
Value Function Update Magnitude: 0.46510

Collected Steps per Second: 20,922.48157
Overall Steps per Second: 10,180.83096

Timestep Collection Time: 2.39063
Timestep Consumption Time: 2.52232
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.91296

Cumulative Model Updates: 6,240
Cumulative Timesteps: 52,169,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,907.13075
Policy Entropy: 1.89967
Value Function Loss: 0.16065

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.23767
Value Function Update Magnitude: 0.41291

Collected Steps per Second: 21,424.97412
Overall Steps per Second: 10,242.63045

Timestep Collection Time: 2.33429
Timestep Consumption Time: 2.54844
PPO Batch Consumption Time: 0.30333
Total Iteration Time: 4.88273

Cumulative Model Updates: 6,246
Cumulative Timesteps: 52,219,338

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 52219338...
Checkpoint 52219338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.27589
Policy Entropy: 1.89825
Value Function Loss: 0.17093

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.26140
Value Function Update Magnitude: 0.42495

Collected Steps per Second: 20,976.38335
Overall Steps per Second: 10,109.12296

Timestep Collection Time: 2.38506
Timestep Consumption Time: 2.56393
PPO Batch Consumption Time: 0.30422
Total Iteration Time: 4.94900

Cumulative Model Updates: 6,252
Cumulative Timesteps: 52,269,368

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,343.78406
Policy Entropy: 1.89821
Value Function Loss: 0.17479

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.30082
Value Function Update Magnitude: 0.40768

Collected Steps per Second: 21,247.45076
Overall Steps per Second: 10,145.51852

Timestep Collection Time: 2.35492
Timestep Consumption Time: 2.57691
PPO Batch Consumption Time: 0.30382
Total Iteration Time: 4.93183

Cumulative Model Updates: 6,258
Cumulative Timesteps: 52,319,404

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 52319404...
Checkpoint 52319404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,064.49429
Policy Entropy: 1.88377
Value Function Loss: 0.17060

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.27792
Value Function Update Magnitude: 0.39845

Collected Steps per Second: 20,897.82341
Overall Steps per Second: 10,092.47806

Timestep Collection Time: 2.39336
Timestep Consumption Time: 2.56241
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.95577

Cumulative Model Updates: 6,264
Cumulative Timesteps: 52,369,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,108.92458
Policy Entropy: 1.89831
Value Function Loss: 0.16303

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.28118
Value Function Update Magnitude: 0.37499

Collected Steps per Second: 21,205.96904
Overall Steps per Second: 10,242.17185

Timestep Collection Time: 2.35783
Timestep Consumption Time: 2.52395
PPO Batch Consumption Time: 0.30016
Total Iteration Time: 4.88178

Cumulative Model Updates: 6,270
Cumulative Timesteps: 52,419,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 52419420...
Checkpoint 52419420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719.20347
Policy Entropy: 1.87200
Value Function Loss: 0.16518

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.26315
Value Function Update Magnitude: 0.36493

Collected Steps per Second: 21,111.49386
Overall Steps per Second: 10,174.10199

Timestep Collection Time: 2.36942
Timestep Consumption Time: 2.54718
PPO Batch Consumption Time: 0.30325
Total Iteration Time: 4.91660

Cumulative Model Updates: 6,276
Cumulative Timesteps: 52,469,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,559.69069
Policy Entropy: 1.88827
Value Function Loss: 0.16308

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.26390
Value Function Update Magnitude: 0.37967

Collected Steps per Second: 21,449.88204
Overall Steps per Second: 10,354.46771

Timestep Collection Time: 2.33251
Timestep Consumption Time: 2.49942
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.83192

Cumulative Model Updates: 6,282
Cumulative Timesteps: 52,519,474

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 52519474...
Checkpoint 52519474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,517.26026
Policy Entropy: 1.87919
Value Function Loss: 0.16388

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.26994
Value Function Update Magnitude: 0.41087

Collected Steps per Second: 20,683.76760
Overall Steps per Second: 10,101.06109

Timestep Collection Time: 2.41842
Timestep Consumption Time: 2.53373
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 4.95215

Cumulative Model Updates: 6,288
Cumulative Timesteps: 52,569,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,230.32967
Policy Entropy: 1.88395
Value Function Loss: 0.15624

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.25838
Value Function Update Magnitude: 0.43381

Collected Steps per Second: 21,066.23743
Overall Steps per Second: 10,158.10954

Timestep Collection Time: 2.37499
Timestep Consumption Time: 2.55034
PPO Batch Consumption Time: 0.30327
Total Iteration Time: 4.92533

Cumulative Model Updates: 6,294
Cumulative Timesteps: 52,619,528

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 52619528...
Checkpoint 52619528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,025.38303
Policy Entropy: 1.89432
Value Function Loss: 0.14825

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.27215
Value Function Update Magnitude: 0.41957

Collected Steps per Second: 20,974.74081
Overall Steps per Second: 10,145.74003

Timestep Collection Time: 2.38439
Timestep Consumption Time: 2.54497
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.92936

Cumulative Model Updates: 6,300
Cumulative Timesteps: 52,669,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,904.43871
Policy Entropy: 1.88168
Value Function Loss: 0.14801

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.28098
Value Function Update Magnitude: 0.42042

Collected Steps per Second: 21,035.04147
Overall Steps per Second: 10,127.65413

Timestep Collection Time: 2.37765
Timestep Consumption Time: 2.56071
PPO Batch Consumption Time: 0.30207
Total Iteration Time: 4.93836

Cumulative Model Updates: 6,306
Cumulative Timesteps: 52,719,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 52719554...
Checkpoint 52719554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,973.15384
Policy Entropy: 1.88758
Value Function Loss: 0.14597

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07879
Policy Update Magnitude: 0.29008
Value Function Update Magnitude: 0.39385

Collected Steps per Second: 20,945.42168
Overall Steps per Second: 10,101.85590

Timestep Collection Time: 2.38802
Timestep Consumption Time: 2.56335
PPO Batch Consumption Time: 0.30175
Total Iteration Time: 4.95137

Cumulative Model Updates: 6,312
Cumulative Timesteps: 52,769,572

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,531.39014
Policy Entropy: 1.87641
Value Function Loss: 0.15176

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07214
Policy Update Magnitude: 0.29779
Value Function Update Magnitude: 0.35661

Collected Steps per Second: 21,282.19524
Overall Steps per Second: 10,151.98872

Timestep Collection Time: 2.34976
Timestep Consumption Time: 2.57617
PPO Batch Consumption Time: 0.30292
Total Iteration Time: 4.92593

Cumulative Model Updates: 6,318
Cumulative Timesteps: 52,819,580

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 52819580...
Checkpoint 52819580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483.66202
Policy Entropy: 1.88149
Value Function Loss: 0.14782

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06513
Policy Update Magnitude: 0.31354
Value Function Update Magnitude: 0.41921

Collected Steps per Second: 21,352.09413
Overall Steps per Second: 10,089.23988

Timestep Collection Time: 2.34281
Timestep Consumption Time: 2.61534
PPO Batch Consumption Time: 0.30695
Total Iteration Time: 4.95815

Cumulative Model Updates: 6,324
Cumulative Timesteps: 52,869,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,306.75076
Policy Entropy: 1.88542
Value Function Loss: 0.15468

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06664
Policy Update Magnitude: 0.33792
Value Function Update Magnitude: 0.42876

Collected Steps per Second: 21,163.70142
Overall Steps per Second: 10,202.72910

Timestep Collection Time: 2.36301
Timestep Consumption Time: 2.53862
PPO Batch Consumption Time: 0.30139
Total Iteration Time: 4.90163

Cumulative Model Updates: 6,330
Cumulative Timesteps: 52,919,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 52919614...
Checkpoint 52919614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,232.73335
Policy Entropy: 1.86631
Value Function Loss: 0.15668

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06791
Policy Update Magnitude: 0.33306
Value Function Update Magnitude: 0.39679

Collected Steps per Second: 21,188.58848
Overall Steps per Second: 9,959.21453

Timestep Collection Time: 2.36052
Timestep Consumption Time: 2.66157
PPO Batch Consumption Time: 0.32078
Total Iteration Time: 5.02208

Cumulative Model Updates: 6,336
Cumulative Timesteps: 52,969,630

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.62359
Policy Entropy: 1.86497
Value Function Loss: 0.15630

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.32213
Value Function Update Magnitude: 0.38682

Collected Steps per Second: 20,982.89091
Overall Steps per Second: 10,203.15767

Timestep Collection Time: 2.38490
Timestep Consumption Time: 2.51966
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.90456

Cumulative Model Updates: 6,342
Cumulative Timesteps: 53,019,672

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 53019672...
Checkpoint 53019672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,997.98491
Policy Entropy: 1.85725
Value Function Loss: 0.15748

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.28961
Value Function Update Magnitude: 0.41546

Collected Steps per Second: 21,263.89123
Overall Steps per Second: 10,158.00541

Timestep Collection Time: 2.35366
Timestep Consumption Time: 2.57329
PPO Batch Consumption Time: 0.29978
Total Iteration Time: 4.92695

Cumulative Model Updates: 6,348
Cumulative Timesteps: 53,069,720

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,843.37945
Policy Entropy: 1.86088
Value Function Loss: 0.14931

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.12808
Policy Update Magnitude: 0.25396
Value Function Update Magnitude: 0.43434

Collected Steps per Second: 21,438.06830
Overall Steps per Second: 10,403.75890

Timestep Collection Time: 2.33333
Timestep Consumption Time: 2.47474
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.80807

Cumulative Model Updates: 6,354
Cumulative Timesteps: 53,119,742

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 53119742...
Checkpoint 53119742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,130.65173
Policy Entropy: 1.85487
Value Function Loss: 0.14022

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.24066
Value Function Update Magnitude: 0.41476

Collected Steps per Second: 21,415.97239
Overall Steps per Second: 10,233.79597

Timestep Collection Time: 2.33499
Timestep Consumption Time: 2.55137
PPO Batch Consumption Time: 0.30032
Total Iteration Time: 4.88636

Cumulative Model Updates: 6,360
Cumulative Timesteps: 53,169,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,046.73836
Policy Entropy: 1.85096
Value Function Loss: 0.14858

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.15462
Policy Update Magnitude: 0.22481
Value Function Update Magnitude: 0.42990

Collected Steps per Second: 20,787.28992
Overall Steps per Second: 10,118.15897

Timestep Collection Time: 2.40570
Timestep Consumption Time: 2.53670
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.94240

Cumulative Model Updates: 6,366
Cumulative Timesteps: 53,219,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 53219756...
Checkpoint 53219756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,845.04684
Policy Entropy: 1.84654
Value Function Loss: 0.15693

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.16373
Policy Update Magnitude: 0.22798
Value Function Update Magnitude: 0.33511

Collected Steps per Second: 21,118.30450
Overall Steps per Second: 10,146.88281

Timestep Collection Time: 2.36941
Timestep Consumption Time: 2.56195
PPO Batch Consumption Time: 0.30280
Total Iteration Time: 4.93137

Cumulative Model Updates: 6,372
Cumulative Timesteps: 53,269,794

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,388.17576
Policy Entropy: 1.84875
Value Function Loss: 0.16828

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.15172
Policy Update Magnitude: 0.25234
Value Function Update Magnitude: 0.30132

Collected Steps per Second: 20,945.30385
Overall Steps per Second: 10,108.89459

Timestep Collection Time: 2.38755
Timestep Consumption Time: 2.55938
PPO Batch Consumption Time: 0.30364
Total Iteration Time: 4.94693

Cumulative Model Updates: 6,378
Cumulative Timesteps: 53,319,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 53319802...
Checkpoint 53319802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,267.10708
Policy Entropy: 1.86839
Value Function Loss: 0.16037

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.24397
Value Function Update Magnitude: 0.29972

Collected Steps per Second: 21,053.70041
Overall Steps per Second: 10,109.44221

Timestep Collection Time: 2.37545
Timestep Consumption Time: 2.57161
PPO Batch Consumption Time: 0.30321
Total Iteration Time: 4.94706

Cumulative Model Updates: 6,384
Cumulative Timesteps: 53,369,814

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,674.40942
Policy Entropy: 1.86397
Value Function Loss: 0.16701

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.15038
Policy Update Magnitude: 0.23145
Value Function Update Magnitude: 0.26880

Collected Steps per Second: 21,430.41832
Overall Steps per Second: 10,296.37217

Timestep Collection Time: 2.33481
Timestep Consumption Time: 2.52476
PPO Batch Consumption Time: 0.29902
Total Iteration Time: 4.85958

Cumulative Model Updates: 6,390
Cumulative Timesteps: 53,419,850

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 53419850...
Checkpoint 53419850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,732.05930
Policy Entropy: 1.86292
Value Function Loss: 0.17198

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.12338
Policy Update Magnitude: 0.24783
Value Function Update Magnitude: 0.25508

Collected Steps per Second: 21,277.56873
Overall Steps per Second: 10,290.70787

Timestep Collection Time: 2.35074
Timestep Consumption Time: 2.50976
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.86050

Cumulative Model Updates: 6,396
Cumulative Timesteps: 53,469,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,692.55975
Policy Entropy: 1.86254
Value Function Loss: 0.16793

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.23973
Value Function Update Magnitude: 0.26776

Collected Steps per Second: 21,261.46935
Overall Steps per Second: 10,194.47169

Timestep Collection Time: 2.35195
Timestep Consumption Time: 2.55325
PPO Batch Consumption Time: 0.30307
Total Iteration Time: 4.90521

Cumulative Model Updates: 6,402
Cumulative Timesteps: 53,519,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 53519874...
Checkpoint 53519874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,268.38289
Policy Entropy: 1.86494
Value Function Loss: 0.16826

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.26311
Value Function Update Magnitude: 0.26972

Collected Steps per Second: 21,193.99354
Overall Steps per Second: 10,138.57142

Timestep Collection Time: 2.36048
Timestep Consumption Time: 2.57394
PPO Batch Consumption Time: 0.30140
Total Iteration Time: 4.93442

Cumulative Model Updates: 6,408
Cumulative Timesteps: 53,569,902

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,985.60603
Policy Entropy: 1.87775
Value Function Loss: 0.15948

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.12049
Policy Update Magnitude: 0.25984
Value Function Update Magnitude: 0.32878

Collected Steps per Second: 21,063.62642
Overall Steps per Second: 10,088.35252

Timestep Collection Time: 2.37566
Timestep Consumption Time: 2.58452
PPO Batch Consumption Time: 0.29868
Total Iteration Time: 4.96018

Cumulative Model Updates: 6,414
Cumulative Timesteps: 53,619,942

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 53619942...
Checkpoint 53619942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,080.90349
Policy Entropy: 1.87819
Value Function Loss: 0.15363

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14873
Policy Update Magnitude: 0.25617
Value Function Update Magnitude: 0.42593

Collected Steps per Second: 20,995.99698
Overall Steps per Second: 10,162.71394

Timestep Collection Time: 2.38255
Timestep Consumption Time: 2.53976
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 4.92231

Cumulative Model Updates: 6,420
Cumulative Timesteps: 53,669,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,613.94103
Policy Entropy: 1.87851
Value Function Loss: 0.15085

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.26542
Value Function Update Magnitude: 0.38601

Collected Steps per Second: 20,866.72705
Overall Steps per Second: 10,093.70471

Timestep Collection Time: 2.39616
Timestep Consumption Time: 2.55742
PPO Batch Consumption Time: 0.30111
Total Iteration Time: 4.95358

Cumulative Model Updates: 6,426
Cumulative Timesteps: 53,719,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 53719966...
Checkpoint 53719966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.11204
Policy Entropy: 1.89355
Value Function Loss: 0.14435

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.29120
Value Function Update Magnitude: 0.44866

Collected Steps per Second: 21,141.93327
Overall Steps per Second: 10,131.27486

Timestep Collection Time: 2.36544
Timestep Consumption Time: 2.57076
PPO Batch Consumption Time: 0.30363
Total Iteration Time: 4.93620

Cumulative Model Updates: 6,432
Cumulative Timesteps: 53,769,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.56819
Policy Entropy: 1.88791
Value Function Loss: 0.14339

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.28155
Value Function Update Magnitude: 0.57488

Collected Steps per Second: 20,931.91648
Overall Steps per Second: 10,126.60750

Timestep Collection Time: 2.38908
Timestep Consumption Time: 2.54920
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.93828

Cumulative Model Updates: 6,438
Cumulative Timesteps: 53,819,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 53819984...
Checkpoint 53819984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.24582
Policy Entropy: 1.88578
Value Function Loss: 0.15947

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.28978
Value Function Update Magnitude: 0.49379

Collected Steps per Second: 21,226.52134
Overall Steps per Second: 10,125.50917

Timestep Collection Time: 2.35743
Timestep Consumption Time: 2.58455
PPO Batch Consumption Time: 0.30015
Total Iteration Time: 4.94197

Cumulative Model Updates: 6,444
Cumulative Timesteps: 53,870,024

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,892.40625
Policy Entropy: 1.89813
Value Function Loss: 0.16624

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11562
Policy Update Magnitude: 0.27773
Value Function Update Magnitude: 0.34408

Collected Steps per Second: 21,257.83590
Overall Steps per Second: 10,117.56056

Timestep Collection Time: 2.35292
Timestep Consumption Time: 2.59076
PPO Batch Consumption Time: 0.30000
Total Iteration Time: 4.94368

Cumulative Model Updates: 6,450
Cumulative Timesteps: 53,920,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 53920042...
Checkpoint 53920042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,831.81238
Policy Entropy: 1.89625
Value Function Loss: 0.18432

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12834
Policy Update Magnitude: 0.25819
Value Function Update Magnitude: 0.30607

Collected Steps per Second: 21,048.16318
Overall Steps per Second: 10,163.09244

Timestep Collection Time: 2.37645
Timestep Consumption Time: 2.54528
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.92173

Cumulative Model Updates: 6,456
Cumulative Timesteps: 53,970,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,203.84477
Policy Entropy: 1.89696
Value Function Loss: 0.17624

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.26542
Value Function Update Magnitude: 0.28067

Collected Steps per Second: 21,429.21833
Overall Steps per Second: 10,211.50368

Timestep Collection Time: 2.33420
Timestep Consumption Time: 2.56420
PPO Batch Consumption Time: 0.29992
Total Iteration Time: 4.89840

Cumulative Model Updates: 6,462
Cumulative Timesteps: 54,020,082

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 54020082...
Checkpoint 54020082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819.31294
Policy Entropy: 1.89498
Value Function Loss: 0.18076

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.15155
Policy Update Magnitude: 0.25385
Value Function Update Magnitude: 0.27502

Collected Steps per Second: 21,350.85191
Overall Steps per Second: 10,149.97443

Timestep Collection Time: 2.34333
Timestep Consumption Time: 2.58595
PPO Batch Consumption Time: 0.30686
Total Iteration Time: 4.92927

Cumulative Model Updates: 6,468
Cumulative Timesteps: 54,070,114

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,400.41219
Policy Entropy: 1.90460
Value Function Loss: 0.17730

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.13841
Policy Update Magnitude: 0.23213
Value Function Update Magnitude: 0.26678

Collected Steps per Second: 21,291.42426
Overall Steps per Second: 10,272.96854

Timestep Collection Time: 2.34855
Timestep Consumption Time: 2.51898
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.86753

Cumulative Model Updates: 6,474
Cumulative Timesteps: 54,120,118

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 54120118...
Checkpoint 54120118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.85504
Policy Entropy: 1.91757
Value Function Loss: 0.16936

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.22460
Value Function Update Magnitude: 0.25055

Collected Steps per Second: 21,224.62098
Overall Steps per Second: 10,200.60129

Timestep Collection Time: 2.35585
Timestep Consumption Time: 2.54602
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.90187

Cumulative Model Updates: 6,480
Cumulative Timesteps: 54,170,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,699.01837
Policy Entropy: 1.91466
Value Function Loss: 0.16904

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.23777
Value Function Update Magnitude: 0.26062

Collected Steps per Second: 21,229.03833
Overall Steps per Second: 10,154.49316

Timestep Collection Time: 2.35630
Timestep Consumption Time: 2.56979
PPO Batch Consumption Time: 0.30369
Total Iteration Time: 4.92610

Cumulative Model Updates: 6,486
Cumulative Timesteps: 54,220,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 54220142...
Checkpoint 54220142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,864.58489
Policy Entropy: 1.91741
Value Function Loss: 0.17439

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.23643
Value Function Update Magnitude: 0.26382

Collected Steps per Second: 21,422.63497
Overall Steps per Second: 10,190.08037

Timestep Collection Time: 2.33473
Timestep Consumption Time: 2.57358
PPO Batch Consumption Time: 0.30642
Total Iteration Time: 4.90830

Cumulative Model Updates: 6,492
Cumulative Timesteps: 54,270,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.45991
Policy Entropy: 1.91466
Value Function Loss: 0.19024

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.25022
Value Function Update Magnitude: 0.27516

Collected Steps per Second: 21,016.34846
Overall Steps per Second: 10,128.18011

Timestep Collection Time: 2.38110
Timestep Consumption Time: 2.55977
PPO Batch Consumption Time: 0.30408
Total Iteration Time: 4.94087

Cumulative Model Updates: 6,498
Cumulative Timesteps: 54,320,200

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 54320200...
Checkpoint 54320200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,951.35664
Policy Entropy: 1.91811
Value Function Loss: 0.17527

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.14453
Policy Update Magnitude: 0.26187
Value Function Update Magnitude: 0.28128

Collected Steps per Second: 21,021.89810
Overall Steps per Second: 10,088.04917

Timestep Collection Time: 2.37923
Timestep Consumption Time: 2.57871
PPO Batch Consumption Time: 0.30423
Total Iteration Time: 4.95795

Cumulative Model Updates: 6,504
Cumulative Timesteps: 54,370,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,282.00046
Policy Entropy: 1.91382
Value Function Loss: 0.15622

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.15004
Policy Update Magnitude: 0.24435
Value Function Update Magnitude: 0.34859

Collected Steps per Second: 21,308.22459
Overall Steps per Second: 10,233.15693

Timestep Collection Time: 2.34670
Timestep Consumption Time: 2.53977
PPO Batch Consumption Time: 0.30114
Total Iteration Time: 4.88647

Cumulative Model Updates: 6,510
Cumulative Timesteps: 54,420,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 54420220...
Checkpoint 54420220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,294.70160
Policy Entropy: 1.91493
Value Function Loss: 0.15669

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10843
Policy Update Magnitude: 0.26501
Value Function Update Magnitude: 0.38951

Collected Steps per Second: 21,183.71302
Overall Steps per Second: 10,193.29416

Timestep Collection Time: 2.36125
Timestep Consumption Time: 2.54590
PPO Batch Consumption Time: 0.30327
Total Iteration Time: 4.90715

Cumulative Model Updates: 6,516
Cumulative Timesteps: 54,470,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,604.52774
Policy Entropy: 1.91014
Value Function Loss: 0.16093

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09410
Policy Update Magnitude: 0.30149
Value Function Update Magnitude: 0.40481

Collected Steps per Second: 21,180.55863
Overall Steps per Second: 10,241.94045

Timestep Collection Time: 2.36103
Timestep Consumption Time: 2.52164
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.88267

Cumulative Model Updates: 6,522
Cumulative Timesteps: 54,520,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 54520248...
Checkpoint 54520248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,846.46259
Policy Entropy: 1.91313
Value Function Loss: 0.15518

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.27777
Value Function Update Magnitude: 0.42631

Collected Steps per Second: 21,164.12060
Overall Steps per Second: 10,237.99038

Timestep Collection Time: 2.36258
Timestep Consumption Time: 2.52138
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.88397

Cumulative Model Updates: 6,528
Cumulative Timesteps: 54,570,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,024.06028
Policy Entropy: 1.91186
Value Function Loss: 0.15818

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.13558
Policy Update Magnitude: 0.26524
Value Function Update Magnitude: 0.39976

Collected Steps per Second: 21,462.20267
Overall Steps per Second: 10,331.45406

Timestep Collection Time: 2.33042
Timestep Consumption Time: 2.51072
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.84114

Cumulative Model Updates: 6,534
Cumulative Timesteps: 54,620,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 54620266...
Checkpoint 54620266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,075.74484
Policy Entropy: 1.92264
Value Function Loss: 0.15073

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.27261
Value Function Update Magnitude: 0.39912

Collected Steps per Second: 21,274.30446
Overall Steps per Second: 10,273.66601

Timestep Collection Time: 2.35025
Timestep Consumption Time: 2.51656
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.86681

Cumulative Model Updates: 6,540
Cumulative Timesteps: 54,670,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,410.35363
Policy Entropy: 1.91697
Value Function Loss: 0.14815

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.27306
Value Function Update Magnitude: 0.39537

Collected Steps per Second: 20,648.03921
Overall Steps per Second: 10,038.67079

Timestep Collection Time: 2.42289
Timestep Consumption Time: 2.56063
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.98353

Cumulative Model Updates: 6,546
Cumulative Timesteps: 54,720,294

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 54720294...
Checkpoint 54720294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,464.89296
Policy Entropy: 1.92203
Value Function Loss: 0.14270

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10596
Policy Update Magnitude: 0.29019
Value Function Update Magnitude: 0.39714

Collected Steps per Second: 21,003.79231
Overall Steps per Second: 10,210.66696

Timestep Collection Time: 2.38147
Timestep Consumption Time: 2.51732
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.89880

Cumulative Model Updates: 6,552
Cumulative Timesteps: 54,770,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,702.31226
Policy Entropy: 1.92056
Value Function Loss: 0.14319

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.30383
Value Function Update Magnitude: 0.37662

Collected Steps per Second: 21,563.69785
Overall Steps per Second: 10,266.92654

Timestep Collection Time: 2.31992
Timestep Consumption Time: 2.55262
PPO Batch Consumption Time: 0.30335
Total Iteration Time: 4.87254

Cumulative Model Updates: 6,558
Cumulative Timesteps: 54,820,340

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 54820340...
Checkpoint 54820340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,842.17358
Policy Entropy: 1.90969
Value Function Loss: 0.15175

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.29289
Value Function Update Magnitude: 0.39281

Collected Steps per Second: 21,125.04769
Overall Steps per Second: 10,179.38097

Timestep Collection Time: 2.36856
Timestep Consumption Time: 2.54686
PPO Batch Consumption Time: 0.30303
Total Iteration Time: 4.91543

Cumulative Model Updates: 6,564
Cumulative Timesteps: 54,870,376

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,459.81071
Policy Entropy: 1.89113
Value Function Loss: 0.16413

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.11144
Policy Update Magnitude: 0.28070
Value Function Update Magnitude: 0.39841

Collected Steps per Second: 21,086.20745
Overall Steps per Second: 10,204.56515

Timestep Collection Time: 2.37150
Timestep Consumption Time: 2.52885
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.90036

Cumulative Model Updates: 6,570
Cumulative Timesteps: 54,920,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 54920382...
Checkpoint 54920382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,827.35338
Policy Entropy: 1.89173
Value Function Loss: 0.16162

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.11526
Policy Update Magnitude: 0.26948
Value Function Update Magnitude: 0.37864

Collected Steps per Second: 21,418.51181
Overall Steps per Second: 10,311.81978

Timestep Collection Time: 2.33536
Timestep Consumption Time: 2.51538
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.85074

Cumulative Model Updates: 6,576
Cumulative Timesteps: 54,970,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,537.12707
Policy Entropy: 1.89711
Value Function Loss: 0.15613

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.16342
Policy Update Magnitude: 0.26282
Value Function Update Magnitude: 0.32941

Collected Steps per Second: 21,169.27600
Overall Steps per Second: 10,040.21566

Timestep Collection Time: 2.36295
Timestep Consumption Time: 2.61921
PPO Batch Consumption Time: 0.30898
Total Iteration Time: 4.98216

Cumulative Model Updates: 6,582
Cumulative Timesteps: 55,020,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 55020424...
Checkpoint 55020424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,205.52012
Policy Entropy: 1.89788
Value Function Loss: 0.15326

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.22003
Value Function Update Magnitude: 0.31287

Collected Steps per Second: 21,403.21483
Overall Steps per Second: 10,256.88300

Timestep Collection Time: 2.33619
Timestep Consumption Time: 2.53878
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 4.87497

Cumulative Model Updates: 6,588
Cumulative Timesteps: 55,070,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,738.34861
Policy Entropy: 1.89995
Value Function Loss: 0.15336

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.22055
Value Function Update Magnitude: 0.29851

Collected Steps per Second: 20,832.20295
Overall Steps per Second: 9,995.54189

Timestep Collection Time: 2.40147
Timestep Consumption Time: 2.60356
PPO Batch Consumption Time: 0.30828
Total Iteration Time: 5.00503

Cumulative Model Updates: 6,594
Cumulative Timesteps: 55,120,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 55120454...
Checkpoint 55120454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,513.19170
Policy Entropy: 1.89650
Value Function Loss: 0.15648

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.22981
Value Function Update Magnitude: 0.28959

Collected Steps per Second: 21,312.39360
Overall Steps per Second: 10,260.72412

Timestep Collection Time: 2.34746
Timestep Consumption Time: 2.52841
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.87587

Cumulative Model Updates: 6,600
Cumulative Timesteps: 55,170,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,851.65972
Policy Entropy: 1.90154
Value Function Loss: 0.15678

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.24146
Value Function Update Magnitude: 0.30001

Collected Steps per Second: 21,206.31835
Overall Steps per Second: 10,085.67603

Timestep Collection Time: 2.35892
Timestep Consumption Time: 2.60099
PPO Batch Consumption Time: 0.30660
Total Iteration Time: 4.95991

Cumulative Model Updates: 6,606
Cumulative Timesteps: 55,220,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 55220508...
Checkpoint 55220508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.58879
Policy Entropy: 1.91340
Value Function Loss: 0.15283

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.24326
Value Function Update Magnitude: 0.34872

Collected Steps per Second: 21,151.07079
Overall Steps per Second: 10,184.21558

Timestep Collection Time: 2.36442
Timestep Consumption Time: 2.54612
PPO Batch Consumption Time: 0.30320
Total Iteration Time: 4.91054

Cumulative Model Updates: 6,612
Cumulative Timesteps: 55,270,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,771.82980
Policy Entropy: 1.90744
Value Function Loss: 0.14936

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.27812
Value Function Update Magnitude: 0.37131

Collected Steps per Second: 21,233.56716
Overall Steps per Second: 10,098.73957

Timestep Collection Time: 2.35514
Timestep Consumption Time: 2.59677
PPO Batch Consumption Time: 0.30345
Total Iteration Time: 4.95191

Cumulative Model Updates: 6,618
Cumulative Timesteps: 55,320,526

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 55320526...
Checkpoint 55320526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,379.20252
Policy Entropy: 1.90405
Value Function Loss: 0.14943

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07667
Policy Update Magnitude: 0.31038
Value Function Update Magnitude: 0.40630

Collected Steps per Second: 21,534.85607
Overall Steps per Second: 10,212.94616

Timestep Collection Time: 2.32228
Timestep Consumption Time: 2.57444
PPO Batch Consumption Time: 0.30170
Total Iteration Time: 4.89673

Cumulative Model Updates: 6,624
Cumulative Timesteps: 55,370,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,375.61195
Policy Entropy: 1.90750
Value Function Loss: 0.14759

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.31502
Value Function Update Magnitude: 0.50991

Collected Steps per Second: 21,148.39371
Overall Steps per Second: 10,163.28620

Timestep Collection Time: 2.36566
Timestep Consumption Time: 2.55696
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.92262

Cumulative Model Updates: 6,630
Cumulative Timesteps: 55,420,566

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 55420566...
Checkpoint 55420566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,575.61184
Policy Entropy: 1.90683
Value Function Loss: 0.14420

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09164
Policy Update Magnitude: 0.30287
Value Function Update Magnitude: 0.59016

Collected Steps per Second: 21,459.85469
Overall Steps per Second: 10,279.05496

Timestep Collection Time: 2.32993
Timestep Consumption Time: 2.53433
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.86426

Cumulative Model Updates: 6,636
Cumulative Timesteps: 55,470,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,540.71003
Policy Entropy: 1.90766
Value Function Loss: 0.14496

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11755
Policy Update Magnitude: 0.27981
Value Function Update Magnitude: 0.60036

Collected Steps per Second: 21,345.82959
Overall Steps per Second: 10,119.35456

Timestep Collection Time: 2.34285
Timestep Consumption Time: 2.59917
PPO Batch Consumption Time: 0.30946
Total Iteration Time: 4.94201

Cumulative Model Updates: 6,642
Cumulative Timesteps: 55,520,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 55520576...
Checkpoint 55520576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,073.18636
Policy Entropy: 1.90863
Value Function Loss: 0.14340

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.25949
Value Function Update Magnitude: 0.48241

Collected Steps per Second: 21,194.83555
Overall Steps per Second: 10,251.97848

Timestep Collection Time: 2.36020
Timestep Consumption Time: 2.51925
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.87945

Cumulative Model Updates: 6,648
Cumulative Timesteps: 55,570,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,322.21045
Policy Entropy: 1.92027
Value Function Loss: 0.14021

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.15893
Policy Update Magnitude: 0.25828
Value Function Update Magnitude: 0.46715

Collected Steps per Second: 21,023.52746
Overall Steps per Second: 10,233.36709

Timestep Collection Time: 2.37933
Timestep Consumption Time: 2.50879
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.88813

Cumulative Model Updates: 6,654
Cumulative Timesteps: 55,620,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 55620622...
Checkpoint 55620622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,119.61436
Policy Entropy: 1.91077
Value Function Loss: 0.13975

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.14962
Policy Update Magnitude: 0.25090
Value Function Update Magnitude: 0.53751

Collected Steps per Second: 22,090.78100
Overall Steps per Second: 10,500.03482

Timestep Collection Time: 2.26438
Timestep Consumption Time: 2.49960
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.76398

Cumulative Model Updates: 6,660
Cumulative Timesteps: 55,670,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.59755
Policy Entropy: 1.91272
Value Function Loss: 0.13770

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.26588
Value Function Update Magnitude: 0.53064

Collected Steps per Second: 20,491.67060
Overall Steps per Second: 9,976.59220

Timestep Collection Time: 2.44021
Timestep Consumption Time: 2.57192
PPO Batch Consumption Time: 0.30547
Total Iteration Time: 5.01213

Cumulative Model Updates: 6,666
Cumulative Timesteps: 55,720,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 55720648...
Checkpoint 55720648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,530.45467
Policy Entropy: 1.89930
Value Function Loss: 0.14933

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.25800
Value Function Update Magnitude: 0.53748

Collected Steps per Second: 20,857.85822
Overall Steps per Second: 9,869.80885

Timestep Collection Time: 2.39833
Timestep Consumption Time: 2.67006
PPO Batch Consumption Time: 0.32470
Total Iteration Time: 5.06839

Cumulative Model Updates: 6,672
Cumulative Timesteps: 55,770,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.64549
Policy Entropy: 1.89548
Value Function Loss: 0.14854

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.11780
Policy Update Magnitude: 0.27972
Value Function Update Magnitude: 0.46291

Collected Steps per Second: 20,948.41240
Overall Steps per Second: 9,778.25439

Timestep Collection Time: 2.38758
Timestep Consumption Time: 2.72744
PPO Batch Consumption Time: 0.32629
Total Iteration Time: 5.11502

Cumulative Model Updates: 6,678
Cumulative Timesteps: 55,820,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 55820688...
Checkpoint 55820688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,365.67071
Policy Entropy: 1.87921
Value Function Loss: 0.15883

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.25212
Value Function Update Magnitude: 0.44259

Collected Steps per Second: 19,062.68862
Overall Steps per Second: 9,638.40633

Timestep Collection Time: 2.62313
Timestep Consumption Time: 2.56486
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 5.18799

Cumulative Model Updates: 6,684
Cumulative Timesteps: 55,870,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,776.41333
Policy Entropy: 1.88322
Value Function Loss: 0.15120

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.13198
Policy Update Magnitude: 0.26746
Value Function Update Magnitude: 0.42819

Collected Steps per Second: 22,092.70870
Overall Steps per Second: 10,366.64905

Timestep Collection Time: 2.26346
Timestep Consumption Time: 2.56028
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.82374

Cumulative Model Updates: 6,690
Cumulative Timesteps: 55,920,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 55920698...
Checkpoint 55920698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,272.30104
Policy Entropy: 1.88994
Value Function Loss: 0.15002

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.14326
Policy Update Magnitude: 0.26799
Value Function Update Magnitude: 0.42428

Collected Steps per Second: 18,788.16134
Overall Steps per Second: 9,098.26573

Timestep Collection Time: 2.66253
Timestep Consumption Time: 2.83566
PPO Batch Consumption Time: 0.34315
Total Iteration Time: 5.49819

Cumulative Model Updates: 6,696
Cumulative Timesteps: 55,970,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,929.65141
Policy Entropy: 1.90173
Value Function Loss: 0.14660

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.14063
Policy Update Magnitude: 0.26779
Value Function Update Magnitude: 0.34735

Collected Steps per Second: 17,469.91314
Overall Steps per Second: 8,592.49258

Timestep Collection Time: 2.86309
Timestep Consumption Time: 2.95803
PPO Batch Consumption Time: 0.35482
Total Iteration Time: 5.82113

Cumulative Model Updates: 6,702
Cumulative Timesteps: 56,020,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 56020740...
Checkpoint 56020740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,981.12108
Policy Entropy: 1.90414
Value Function Loss: 0.14421

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.25532
Value Function Update Magnitude: 0.30496

Collected Steps per Second: 17,486.05504
Overall Steps per Second: 8,553.91842

Timestep Collection Time: 2.86091
Timestep Consumption Time: 2.98741
PPO Batch Consumption Time: 0.35425
Total Iteration Time: 5.84831

Cumulative Model Updates: 6,708
Cumulative Timesteps: 56,070,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,563.74753
Policy Entropy: 1.88441
Value Function Loss: 0.14622

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.27433
Value Function Update Magnitude: 0.35861

Collected Steps per Second: 17,638.47019
Overall Steps per Second: 8,569.63004

Timestep Collection Time: 2.83528
Timestep Consumption Time: 3.00044
PPO Batch Consumption Time: 0.36038
Total Iteration Time: 5.83572

Cumulative Model Updates: 6,714
Cumulative Timesteps: 56,120,776

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 56120776...
Checkpoint 56120776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,421.11272
Policy Entropy: 1.88354
Value Function Loss: 0.15097

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.13366
Policy Update Magnitude: 0.26805
Value Function Update Magnitude: 0.47441

Collected Steps per Second: 17,630.60302
Overall Steps per Second: 8,692.53527

Timestep Collection Time: 2.83723
Timestep Consumption Time: 2.91737
PPO Batch Consumption Time: 0.34986
Total Iteration Time: 5.75459

Cumulative Model Updates: 6,720
Cumulative Timesteps: 56,170,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.34089
Policy Entropy: 1.88101
Value Function Loss: 0.15302

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.26331
Value Function Update Magnitude: 0.42969

Collected Steps per Second: 17,658.59624
Overall Steps per Second: 8,674.59846

Timestep Collection Time: 2.83273
Timestep Consumption Time: 2.93376
PPO Batch Consumption Time: 0.35554
Total Iteration Time: 5.76649

Cumulative Model Updates: 6,726
Cumulative Timesteps: 56,220,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 56220820...
Checkpoint 56220820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,533.61294
Policy Entropy: 1.90048
Value Function Loss: 0.14774

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.27580
Value Function Update Magnitude: 0.38924

Collected Steps per Second: 17,656.98197
Overall Steps per Second: 8,653.13041

Timestep Collection Time: 2.83253
Timestep Consumption Time: 2.94734
PPO Batch Consumption Time: 0.35260
Total Iteration Time: 5.77987

Cumulative Model Updates: 6,732
Cumulative Timesteps: 56,270,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,414.50938
Policy Entropy: 1.91209
Value Function Loss: 0.13881

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.25992
Value Function Update Magnitude: 0.39125

Collected Steps per Second: 17,779.65832
Overall Steps per Second: 8,621.69772

Timestep Collection Time: 2.81243
Timestep Consumption Time: 2.98736
PPO Batch Consumption Time: 0.35439
Total Iteration Time: 5.79979

Cumulative Model Updates: 6,738
Cumulative Timesteps: 56,320,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 56320838...
Checkpoint 56320838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,850.67934
Policy Entropy: 1.89739
Value Function Loss: 0.12840

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.25580
Value Function Update Magnitude: 0.50260

Collected Steps per Second: 17,409.74833
Overall Steps per Second: 8,543.67295

Timestep Collection Time: 2.87253
Timestep Consumption Time: 2.98093
PPO Batch Consumption Time: 0.35376
Total Iteration Time: 5.85345

Cumulative Model Updates: 6,744
Cumulative Timesteps: 56,370,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,944.23790
Policy Entropy: 1.89647
Value Function Loss: 0.13118

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.25724
Value Function Update Magnitude: 0.46159

Collected Steps per Second: 17,522.39683
Overall Steps per Second: 8,585.73501

Timestep Collection Time: 2.85520
Timestep Consumption Time: 2.97190
PPO Batch Consumption Time: 0.35614
Total Iteration Time: 5.82711

Cumulative Model Updates: 6,750
Cumulative Timesteps: 56,420,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 56420878...
Checkpoint 56420878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,291.95362
Policy Entropy: 1.89301
Value Function Loss: 0.13406

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.28242
Value Function Update Magnitude: 0.47587

Collected Steps per Second: 17,573.76015
Overall Steps per Second: 8,687.94370

Timestep Collection Time: 2.84652
Timestep Consumption Time: 2.91135
PPO Batch Consumption Time: 0.35214
Total Iteration Time: 5.75786

Cumulative Model Updates: 6,756
Cumulative Timesteps: 56,470,902

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.73008
Policy Entropy: 1.88283
Value Function Loss: 0.13771

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.31824
Value Function Update Magnitude: 0.60099

Collected Steps per Second: 17,773.01304
Overall Steps per Second: 8,747.52478

Timestep Collection Time: 2.81438
Timestep Consumption Time: 2.90381
PPO Batch Consumption Time: 0.35204
Total Iteration Time: 5.71819

Cumulative Model Updates: 6,762
Cumulative Timesteps: 56,520,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 56520922...
Checkpoint 56520922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,182.73118
Policy Entropy: 1.89085
Value Function Loss: 0.14304

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.27552
Value Function Update Magnitude: 0.49152

Collected Steps per Second: 17,729.97468
Overall Steps per Second: 8,687.74124

Timestep Collection Time: 2.82042
Timestep Consumption Time: 2.93551
PPO Batch Consumption Time: 0.35972
Total Iteration Time: 5.75593

Cumulative Model Updates: 6,768
Cumulative Timesteps: 56,570,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,262.50887
Policy Entropy: 1.88677
Value Function Loss: 0.14324

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09594
Policy Update Magnitude: 0.28853
Value Function Update Magnitude: 0.44035

Collected Steps per Second: 17,811.76999
Overall Steps per Second: 8,646.41417

Timestep Collection Time: 2.80781
Timestep Consumption Time: 2.97633
PPO Batch Consumption Time: 0.36148
Total Iteration Time: 5.78413

Cumulative Model Updates: 6,774
Cumulative Timesteps: 56,620,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 56620940...
Checkpoint 56620940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,083.27404
Policy Entropy: 1.88188
Value Function Loss: 0.14647

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.31785
Value Function Update Magnitude: 0.44788

Collected Steps per Second: 17,838.32175
Overall Steps per Second: 8,686.83733

Timestep Collection Time: 2.80318
Timestep Consumption Time: 2.95312
PPO Batch Consumption Time: 0.35434
Total Iteration Time: 5.75630

Cumulative Model Updates: 6,780
Cumulative Timesteps: 56,670,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,823.09399
Policy Entropy: 1.88358
Value Function Loss: 0.13515

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08009
Policy Update Magnitude: 0.32494
Value Function Update Magnitude: 0.43543

Collected Steps per Second: 18,055.14675
Overall Steps per Second: 8,818.06834

Timestep Collection Time: 2.76996
Timestep Consumption Time: 2.90158
PPO Batch Consumption Time: 0.35478
Total Iteration Time: 5.67154

Cumulative Model Updates: 6,786
Cumulative Timesteps: 56,720,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 56720956...
Checkpoint 56720956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,692.31738
Policy Entropy: 1.87334
Value Function Loss: 0.13737

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.31710
Value Function Update Magnitude: 0.49258

Collected Steps per Second: 17,631.84808
Overall Steps per Second: 8,609.25279

Timestep Collection Time: 2.83793
Timestep Consumption Time: 2.97419
PPO Batch Consumption Time: 0.35768
Total Iteration Time: 5.81212

Cumulative Model Updates: 6,792
Cumulative Timesteps: 56,770,994

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,384.15118
Policy Entropy: 1.87533
Value Function Loss: 0.12603

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.27362
Value Function Update Magnitude: 0.44510

Collected Steps per Second: 17,376.37564
Overall Steps per Second: 8,546.84227

Timestep Collection Time: 2.87966
Timestep Consumption Time: 2.97490
PPO Batch Consumption Time: 0.35506
Total Iteration Time: 5.85456

Cumulative Model Updates: 6,798
Cumulative Timesteps: 56,821,032

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 56821032...
Checkpoint 56821032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,139.32013
Policy Entropy: 1.86580
Value Function Loss: 0.12988

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.23494
Value Function Update Magnitude: 0.41507

Collected Steps per Second: 17,661.44249
Overall Steps per Second: 8,595.39065

Timestep Collection Time: 2.83148
Timestep Consumption Time: 2.98652
PPO Batch Consumption Time: 0.35272
Total Iteration Time: 5.81800

Cumulative Model Updates: 6,804
Cumulative Timesteps: 56,871,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,402.69819
Policy Entropy: 1.86769
Value Function Loss: 0.12400

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.23198
Value Function Update Magnitude: 0.43631

Collected Steps per Second: 17,711.52973
Overall Steps per Second: 8,556.85957

Timestep Collection Time: 2.82437
Timestep Consumption Time: 3.02170
PPO Batch Consumption Time: 0.35770
Total Iteration Time: 5.84607

Cumulative Model Updates: 6,810
Cumulative Timesteps: 56,921,064

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 56921064...
Checkpoint 56921064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,520.53853
Policy Entropy: 1.85479
Value Function Loss: 0.12935

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.25603
Value Function Update Magnitude: 0.48733

Collected Steps per Second: 17,905.35614
Overall Steps per Second: 8,613.57888

Timestep Collection Time: 2.79347
Timestep Consumption Time: 3.01341
PPO Batch Consumption Time: 0.36671
Total Iteration Time: 5.80688

Cumulative Model Updates: 6,816
Cumulative Timesteps: 56,971,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997.27334
Policy Entropy: 1.84128
Value Function Loss: 0.12556

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.28680
Value Function Update Magnitude: 0.56127

Collected Steps per Second: 17,882.10794
Overall Steps per Second: 8,648.68930

Timestep Collection Time: 2.79855
Timestep Consumption Time: 2.98776
PPO Batch Consumption Time: 0.35750
Total Iteration Time: 5.78631

Cumulative Model Updates: 6,822
Cumulative Timesteps: 57,021,126

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 57021126...
Checkpoint 57021126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,589.39584
Policy Entropy: 1.83745
Value Function Loss: 0.12505

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06367
Policy Update Magnitude: 0.30389
Value Function Update Magnitude: 0.60329

Collected Steps per Second: 17,382.07649
Overall Steps per Second: 8,506.77928

Timestep Collection Time: 2.87768
Timestep Consumption Time: 3.00234
PPO Batch Consumption Time: 0.36422
Total Iteration Time: 5.88002

Cumulative Model Updates: 6,828
Cumulative Timesteps: 57,071,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,344.87526
Policy Entropy: 1.82441
Value Function Loss: 0.12354

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.05802
Policy Update Magnitude: 0.31395
Value Function Update Magnitude: 0.57189

Collected Steps per Second: 17,819.06665
Overall Steps per Second: 8,589.77424

Timestep Collection Time: 2.80711
Timestep Consumption Time: 3.01610
PPO Batch Consumption Time: 0.35799
Total Iteration Time: 5.82320

Cumulative Model Updates: 6,834
Cumulative Timesteps: 57,121,166

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 57121166...
Checkpoint 57121166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,555.41746
Policy Entropy: 1.82374
Value Function Loss: 0.13076

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07661
Policy Update Magnitude: 0.31759
Value Function Update Magnitude: 0.52861

Collected Steps per Second: 17,348.89489
Overall Steps per Second: 8,514.92454

Timestep Collection Time: 2.88295
Timestep Consumption Time: 2.99097
PPO Batch Consumption Time: 0.35531
Total Iteration Time: 5.87392

Cumulative Model Updates: 6,840
Cumulative Timesteps: 57,171,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685.52715
Policy Entropy: 1.82057
Value Function Loss: 0.13707

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06979
Policy Update Magnitude: 0.30669
Value Function Update Magnitude: 0.51461

Collected Steps per Second: 17,939.16229
Overall Steps per Second: 8,713.13361

Timestep Collection Time: 2.78954
Timestep Consumption Time: 2.95374
PPO Batch Consumption Time: 0.35363
Total Iteration Time: 5.74328

Cumulative Model Updates: 6,846
Cumulative Timesteps: 57,221,224

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 57221224...
Checkpoint 57221224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,780.46068
Policy Entropy: 1.81656
Value Function Loss: 0.13994

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.30317
Value Function Update Magnitude: 0.47237

Collected Steps per Second: 17,245.84925
Overall Steps per Second: 8,494.79935

Timestep Collection Time: 2.89983
Timestep Consumption Time: 2.98730
PPO Batch Consumption Time: 0.35422
Total Iteration Time: 5.88713

Cumulative Model Updates: 6,852
Cumulative Timesteps: 57,271,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,965.96773
Policy Entropy: 1.80538
Value Function Loss: 0.13685

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.16516
Policy Update Magnitude: 0.25539
Value Function Update Magnitude: 0.46390

Collected Steps per Second: 18,051.43255
Overall Steps per Second: 8,722.47417

Timestep Collection Time: 2.77130
Timestep Consumption Time: 2.96400
PPO Batch Consumption Time: 0.35712
Total Iteration Time: 5.73530

Cumulative Model Updates: 6,858
Cumulative Timesteps: 57,321,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 57321260...
Checkpoint 57321260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,541.44752
Policy Entropy: 1.81448
Value Function Loss: 0.12750

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.25415
Value Function Update Magnitude: 0.49352

Collected Steps per Second: 17,871.99393
Overall Steps per Second: 8,696.79855

Timestep Collection Time: 2.79790
Timestep Consumption Time: 2.95180
PPO Batch Consumption Time: 0.35041
Total Iteration Time: 5.74970

Cumulative Model Updates: 6,864
Cumulative Timesteps: 57,371,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,017.67100
Policy Entropy: 1.82460
Value Function Loss: 0.12203

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10733
Policy Update Magnitude: 0.26697
Value Function Update Magnitude: 0.49516

Collected Steps per Second: 17,973.33197
Overall Steps per Second: 8,734.87318

Timestep Collection Time: 2.78246
Timestep Consumption Time: 2.94287
PPO Batch Consumption Time: 0.35512
Total Iteration Time: 5.72533

Cumulative Model Updates: 6,870
Cumulative Timesteps: 57,421,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 57421274...
Checkpoint 57421274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,678.41352
Policy Entropy: 1.81578
Value Function Loss: 0.12413

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.26039
Value Function Update Magnitude: 0.41828

Collected Steps per Second: 17,630.84739
Overall Steps per Second: 8,629.87579

Timestep Collection Time: 2.83605
Timestep Consumption Time: 2.95801
PPO Batch Consumption Time: 0.35248
Total Iteration Time: 5.79406

Cumulative Model Updates: 6,876
Cumulative Timesteps: 57,471,276

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,234.07585
Policy Entropy: 1.80101
Value Function Loss: 0.13566

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.23290
Value Function Update Magnitude: 0.40710

Collected Steps per Second: 17,719.56164
Overall Steps per Second: 8,610.47604

Timestep Collection Time: 2.82298
Timestep Consumption Time: 2.98645
PPO Batch Consumption Time: 0.35629
Total Iteration Time: 5.80943

Cumulative Model Updates: 6,882
Cumulative Timesteps: 57,521,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 57521298...
Checkpoint 57521298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,217.22443
Policy Entropy: 1.80851
Value Function Loss: 0.13758

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.21598
Value Function Update Magnitude: 0.55529

Collected Steps per Second: 17,590.07900
Overall Steps per Second: 8,668.11677

Timestep Collection Time: 2.84353
Timestep Consumption Time: 2.92681
PPO Batch Consumption Time: 0.35615
Total Iteration Time: 5.77034

Cumulative Model Updates: 6,888
Cumulative Timesteps: 57,571,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,447.24260
Policy Entropy: 1.80690
Value Function Loss: 0.14290

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.16428
Policy Update Magnitude: 0.21398
Value Function Update Magnitude: 0.56404

Collected Steps per Second: 17,954.68772
Overall Steps per Second: 8,708.03392

Timestep Collection Time: 2.78690
Timestep Consumption Time: 2.95928
PPO Batch Consumption Time: 0.35631
Total Iteration Time: 5.74619

Cumulative Model Updates: 6,894
Cumulative Timesteps: 57,621,354

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 57621354...
Checkpoint 57621354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,541.04227
Policy Entropy: 1.80384
Value Function Loss: 0.14072

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.15786
Policy Update Magnitude: 0.23263
Value Function Update Magnitude: 0.49646

Collected Steps per Second: 17,847.97186
Overall Steps per Second: 8,738.22348

Timestep Collection Time: 2.80290
Timestep Consumption Time: 2.92207
PPO Batch Consumption Time: 0.35851
Total Iteration Time: 5.72496

Cumulative Model Updates: 6,900
Cumulative Timesteps: 57,671,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,477.55574
Policy Entropy: 1.79580
Value Function Loss: 0.13815

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14533
Policy Update Magnitude: 0.24365
Value Function Update Magnitude: 0.51511

Collected Steps per Second: 17,961.01461
Overall Steps per Second: 8,801.55369

Timestep Collection Time: 2.78381
Timestep Consumption Time: 2.89701
PPO Batch Consumption Time: 0.35682
Total Iteration Time: 5.68082

Cumulative Model Updates: 6,906
Cumulative Timesteps: 57,721,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 57721380...
Checkpoint 57721380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,295.69898
Policy Entropy: 1.80074
Value Function Loss: 0.13270

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.23050
Value Function Update Magnitude: 0.50323

Collected Steps per Second: 17,806.94237
Overall Steps per Second: 8,674.49376

Timestep Collection Time: 2.80913
Timestep Consumption Time: 2.95743
PPO Batch Consumption Time: 0.35584
Total Iteration Time: 5.76656

Cumulative Model Updates: 6,912
Cumulative Timesteps: 57,771,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,706.19320
Policy Entropy: 1.77741
Value Function Loss: 0.13665

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.13251
Policy Update Magnitude: 0.23412
Value Function Update Magnitude: 0.51619

Collected Steps per Second: 17,860.21457
Overall Steps per Second: 8,680.74016

Timestep Collection Time: 2.79974
Timestep Consumption Time: 2.96060
PPO Batch Consumption Time: 0.35417
Total Iteration Time: 5.76034

Cumulative Model Updates: 6,918
Cumulative Timesteps: 57,821,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 57821406...
Checkpoint 57821406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,165.66975
Policy Entropy: 1.78340
Value Function Loss: 0.13492

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.18159
Policy Update Magnitude: 0.24032
Value Function Update Magnitude: 0.52118

Collected Steps per Second: 17,922.95516
Overall Steps per Second: 8,765.86636

Timestep Collection Time: 2.79095
Timestep Consumption Time: 2.91551
PPO Batch Consumption Time: 0.35399
Total Iteration Time: 5.70645

Cumulative Model Updates: 6,924
Cumulative Timesteps: 57,871,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,247.27840
Policy Entropy: 1.77959
Value Function Loss: 0.14075

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.16275
Policy Update Magnitude: 0.23234
Value Function Update Magnitude: 0.45333

Collected Steps per Second: 18,139.89790
Overall Steps per Second: 8,720.95207

Timestep Collection Time: 2.75779
Timestep Consumption Time: 2.97851
PPO Batch Consumption Time: 0.35526
Total Iteration Time: 5.73630

Cumulative Model Updates: 6,930
Cumulative Timesteps: 57,921,454

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 57921454...
Checkpoint 57921454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.70013
Policy Entropy: 1.78261
Value Function Loss: 0.13992

Mean KL Divergence: 0.02189
SB3 Clip Fraction: 0.18587
Policy Update Magnitude: 0.21602
Value Function Update Magnitude: 0.52354

Collected Steps per Second: 17,396.84068
Overall Steps per Second: 8,568.79357

Timestep Collection Time: 2.87523
Timestep Consumption Time: 2.96223
PPO Batch Consumption Time: 0.36068
Total Iteration Time: 5.83746

Cumulative Model Updates: 6,936
Cumulative Timesteps: 57,971,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676.86954
Policy Entropy: 1.78276
Value Function Loss: 0.14932

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.16858
Policy Update Magnitude: 0.21057
Value Function Update Magnitude: 0.50001

Collected Steps per Second: 17,946.27057
Overall Steps per Second: 8,761.19439

Timestep Collection Time: 2.78843
Timestep Consumption Time: 2.92334
PPO Batch Consumption Time: 0.35509
Total Iteration Time: 5.71178

Cumulative Model Updates: 6,942
Cumulative Timesteps: 58,021,516

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 58021516...
Checkpoint 58021516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.01174
Policy Entropy: 1.79094
Value Function Loss: 0.14689

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.22875
Value Function Update Magnitude: 0.43450

Collected Steps per Second: 17,601.98843
Overall Steps per Second: 8,617.76702

Timestep Collection Time: 2.84172
Timestep Consumption Time: 2.96256
PPO Batch Consumption Time: 0.35471
Total Iteration Time: 5.80429

Cumulative Model Updates: 6,948
Cumulative Timesteps: 58,071,536

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,288.83355
Policy Entropy: 1.80410
Value Function Loss: 0.14755

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.25148
Value Function Update Magnitude: 0.39740

Collected Steps per Second: 17,909.41981
Overall Steps per Second: 8,661.15907

Timestep Collection Time: 2.79183
Timestep Consumption Time: 2.98107
PPO Batch Consumption Time: 0.35274
Total Iteration Time: 5.77290

Cumulative Model Updates: 6,954
Cumulative Timesteps: 58,121,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 58121536...
Checkpoint 58121536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,844.56880
Policy Entropy: 1.81597
Value Function Loss: 0.14335

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.23849
Value Function Update Magnitude: 0.40625

Collected Steps per Second: 17,431.09841
Overall Steps per Second: 8,627.21544

Timestep Collection Time: 2.86855
Timestep Consumption Time: 2.92729
PPO Batch Consumption Time: 0.35798
Total Iteration Time: 5.79584

Cumulative Model Updates: 6,960
Cumulative Timesteps: 58,171,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,024.79398
Policy Entropy: 1.81234
Value Function Loss: 0.14119

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.24303
Value Function Update Magnitude: 0.39503

Collected Steps per Second: 17,197.38221
Overall Steps per Second: 8,479.07499

Timestep Collection Time: 2.90905
Timestep Consumption Time: 2.99112
PPO Batch Consumption Time: 0.35488
Total Iteration Time: 5.90017

Cumulative Model Updates: 6,966
Cumulative Timesteps: 58,221,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 58221566...
Checkpoint 58221566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665.90874
Policy Entropy: 1.80617
Value Function Loss: 0.13975

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12498
Policy Update Magnitude: 0.25286
Value Function Update Magnitude: 0.43956

Collected Steps per Second: 17,583.90927
Overall Steps per Second: 8,687.04259

Timestep Collection Time: 2.84419
Timestep Consumption Time: 2.91289
PPO Batch Consumption Time: 0.35742
Total Iteration Time: 5.75708

Cumulative Model Updates: 6,972
Cumulative Timesteps: 58,271,578

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,434.02984
Policy Entropy: 1.79563
Value Function Loss: 0.14360

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.25346
Value Function Update Magnitude: 0.46573

Collected Steps per Second: 18,024.86309
Overall Steps per Second: 8,706.47428

Timestep Collection Time: 2.77572
Timestep Consumption Time: 2.97081
PPO Batch Consumption Time: 0.35468
Total Iteration Time: 5.74653

Cumulative Model Updates: 6,978
Cumulative Timesteps: 58,321,610

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 58321610...
Checkpoint 58321610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,570.53389
Policy Entropy: 1.79639
Value Function Loss: 0.14816

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.16696
Policy Update Magnitude: 0.24352
Value Function Update Magnitude: 0.42309

Collected Steps per Second: 17,528.60605
Overall Steps per Second: 8,560.86164

Timestep Collection Time: 2.85305
Timestep Consumption Time: 2.98865
PPO Batch Consumption Time: 0.35371
Total Iteration Time: 5.84170

Cumulative Model Updates: 6,984
Cumulative Timesteps: 58,371,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,771.90964
Policy Entropy: 1.80214
Value Function Loss: 0.14390

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.14159
Policy Update Magnitude: 0.23490
Value Function Update Magnitude: 0.47417

Collected Steps per Second: 17,656.72381
Overall Steps per Second: 9,380.19826

Timestep Collection Time: 2.83224
Timestep Consumption Time: 2.49900
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 5.33123

Cumulative Model Updates: 6,990
Cumulative Timesteps: 58,421,628

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 58421628...
Checkpoint 58421628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,926.05548
Policy Entropy: 1.80792
Value Function Loss: 0.14135

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.25034
Value Function Update Magnitude: 0.62254

Collected Steps per Second: 21,792.95335
Overall Steps per Second: 10,529.82256

Timestep Collection Time: 2.29533
Timestep Consumption Time: 2.45518
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.75051

Cumulative Model Updates: 6,996
Cumulative Timesteps: 58,471,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,744.28096
Policy Entropy: 1.79455
Value Function Loss: 0.13748

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08062
Policy Update Magnitude: 0.29391
Value Function Update Magnitude: 0.67788

Collected Steps per Second: 22,472.74943
Overall Steps per Second: 10,530.33283

Timestep Collection Time: 2.22492
Timestep Consumption Time: 2.52327
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.74819

Cumulative Model Updates: 7,002
Cumulative Timesteps: 58,521,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 58521650...
Checkpoint 58521650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,788.95557
Policy Entropy: 1.78999
Value Function Loss: 0.14311

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07433
Policy Update Magnitude: 0.31780
Value Function Update Magnitude: 0.60651

Collected Steps per Second: 21,785.72454
Overall Steps per Second: 10,530.98215

Timestep Collection Time: 2.29545
Timestep Consumption Time: 2.45321
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.74865

Cumulative Model Updates: 7,008
Cumulative Timesteps: 58,571,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.65990
Policy Entropy: 1.77442
Value Function Loss: 0.15006

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06813
Policy Update Magnitude: 0.32638
Value Function Update Magnitude: 0.48019

Collected Steps per Second: 22,356.23753
Overall Steps per Second: 10,567.98863

Timestep Collection Time: 2.23830
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.73505

Cumulative Model Updates: 7,014
Cumulative Timesteps: 58,621,698

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 58621698...
Checkpoint 58621698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,925.61309
Policy Entropy: 1.79355
Value Function Loss: 0.14559

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.32109
Value Function Update Magnitude: 0.43544

Collected Steps per Second: 22,249.59367
Overall Steps per Second: 10,639.34854

Timestep Collection Time: 2.24849
Timestep Consumption Time: 2.45368
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.70217

Cumulative Model Updates: 7,020
Cumulative Timesteps: 58,671,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,396.58759
Policy Entropy: 1.80005
Value Function Loss: 0.13639

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09168
Policy Update Magnitude: 0.31396
Value Function Update Magnitude: 0.59399

Collected Steps per Second: 22,159.20357
Overall Steps per Second: 10,447.16550

Timestep Collection Time: 2.25739
Timestep Consumption Time: 2.53070
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.78809

Cumulative Model Updates: 7,026
Cumulative Timesteps: 58,721,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 58721748...
Checkpoint 58721748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,503.02880
Policy Entropy: 1.80155
Value Function Loss: 0.13217

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.14668
Policy Update Magnitude: 0.26675
Value Function Update Magnitude: 0.56768

Collected Steps per Second: 20,803.70842
Overall Steps per Second: 10,153.34081

Timestep Collection Time: 2.40486
Timestep Consumption Time: 2.52258
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.92744

Cumulative Model Updates: 7,032
Cumulative Timesteps: 58,771,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,710.22460
Policy Entropy: 1.79668
Value Function Loss: 0.13578

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.23629
Value Function Update Magnitude: 0.52962

Collected Steps per Second: 22,770.25344
Overall Steps per Second: 10,572.84693

Timestep Collection Time: 2.19787
Timestep Consumption Time: 2.53558
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.73345

Cumulative Model Updates: 7,038
Cumulative Timesteps: 58,821,824

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 58821824...
Checkpoint 58821824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,648.26864
Policy Entropy: 1.78196
Value Function Loss: 0.14447

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.26670
Value Function Update Magnitude: 0.54262

Collected Steps per Second: 22,230.52586
Overall Steps per Second: 10,612.37574

Timestep Collection Time: 2.25042
Timestep Consumption Time: 2.46370
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.71412

Cumulative Model Updates: 7,044
Cumulative Timesteps: 58,871,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,379.22746
Policy Entropy: 1.79116
Value Function Loss: 0.14682

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.16114
Policy Update Magnitude: 0.25456
Value Function Update Magnitude: 0.50981

Collected Steps per Second: 22,375.58110
Overall Steps per Second: 10,556.71214

Timestep Collection Time: 2.23637
Timestep Consumption Time: 2.50375
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.74011

Cumulative Model Updates: 7,050
Cumulative Timesteps: 58,921,892

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 58921892...
Checkpoint 58921892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,091.13094
Policy Entropy: 1.79783
Value Function Loss: 0.14615

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.17526
Policy Update Magnitude: 0.24482
Value Function Update Magnitude: 0.56158

Collected Steps per Second: 22,376.26262
Overall Steps per Second: 10,549.24818

Timestep Collection Time: 2.23487
Timestep Consumption Time: 2.50556
PPO Batch Consumption Time: 0.29722
Total Iteration Time: 4.74043

Cumulative Model Updates: 7,056
Cumulative Timesteps: 58,971,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,273.74535
Policy Entropy: 1.81096
Value Function Loss: 0.14608

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.16114
Policy Update Magnitude: 0.22724
Value Function Update Magnitude: 0.56475

Collected Steps per Second: 22,634.28475
Overall Steps per Second: 10,496.06428

Timestep Collection Time: 2.21045
Timestep Consumption Time: 2.55629
PPO Batch Consumption Time: 0.30180
Total Iteration Time: 4.76674

Cumulative Model Updates: 7,062
Cumulative Timesteps: 59,021,932

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 59021932...
Checkpoint 59021932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,620.24680
Policy Entropy: 1.81677
Value Function Loss: 0.14633

Mean KL Divergence: 0.03123
SB3 Clip Fraction: 0.22763
Policy Update Magnitude: 0.20714
Value Function Update Magnitude: 0.60245

Collected Steps per Second: 22,259.52568
Overall Steps per Second: 10,551.61706

Timestep Collection Time: 2.24668
Timestep Consumption Time: 2.49288
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.73956

Cumulative Model Updates: 7,068
Cumulative Timesteps: 59,071,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,892.50077
Policy Entropy: 1.81816
Value Function Loss: 0.14088

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.17963
Policy Update Magnitude: 0.21266
Value Function Update Magnitude: 0.56826

Collected Steps per Second: 22,143.99193
Overall Steps per Second: 10,451.24483

Timestep Collection Time: 2.25795
Timestep Consumption Time: 2.52617
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.78412

Cumulative Model Updates: 7,074
Cumulative Timesteps: 59,121,942

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 59121942...
Checkpoint 59121942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,896.47571
Policy Entropy: 1.80984
Value Function Loss: 0.13793

Mean KL Divergence: 0.02664
SB3 Clip Fraction: 0.21130
Policy Update Magnitude: 0.21922
Value Function Update Magnitude: 0.56782

Collected Steps per Second: 22,092.84781
Overall Steps per Second: 10,574.58604

Timestep Collection Time: 2.26462
Timestep Consumption Time: 2.46672
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.73134

Cumulative Model Updates: 7,080
Cumulative Timesteps: 59,171,974

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.50625
Policy Entropy: 1.81746
Value Function Loss: 0.13845

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.19547
Policy Update Magnitude: 0.20216
Value Function Update Magnitude: 0.56972

Collected Steps per Second: 21,045.28860
Overall Steps per Second: 10,188.41542

Timestep Collection Time: 2.37706
Timestep Consumption Time: 2.53302
PPO Batch Consumption Time: 0.29717
Total Iteration Time: 4.91009

Cumulative Model Updates: 7,086
Cumulative Timesteps: 59,222,000

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 59222000...
Checkpoint 59222000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,422.11005
Policy Entropy: 1.82143
Value Function Loss: 0.13363

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.17741
Policy Update Magnitude: 0.20758
Value Function Update Magnitude: 0.55913

Collected Steps per Second: 22,483.47951
Overall Steps per Second: 10,570.89937

Timestep Collection Time: 2.22439
Timestep Consumption Time: 2.50671
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.73110

Cumulative Model Updates: 7,092
Cumulative Timesteps: 59,272,012

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,065.29955
Policy Entropy: 1.82410
Value Function Loss: 0.13012

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.18471
Policy Update Magnitude: 0.21521
Value Function Update Magnitude: 0.60144

Collected Steps per Second: 22,558.71926
Overall Steps per Second: 10,523.91741

Timestep Collection Time: 2.21662
Timestep Consumption Time: 2.53485
PPO Batch Consumption Time: 0.29694
Total Iteration Time: 4.75146

Cumulative Model Updates: 7,098
Cumulative Timesteps: 59,322,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 59322016...
Checkpoint 59322016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.35738
Policy Entropy: 1.82929
Value Function Loss: 0.13178

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.15341
Policy Update Magnitude: 0.22677
Value Function Update Magnitude: 0.57433

Collected Steps per Second: 22,499.86513
Overall Steps per Second: 10,476.51795

Timestep Collection Time: 2.22259
Timestep Consumption Time: 2.55075
PPO Batch Consumption Time: 0.29907
Total Iteration Time: 4.77334

Cumulative Model Updates: 7,104
Cumulative Timesteps: 59,372,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,701.09019
Policy Entropy: 1.83879
Value Function Loss: 0.12867

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.24505
Value Function Update Magnitude: 0.58808

Collected Steps per Second: 22,851.11643
Overall Steps per Second: 10,571.93625

Timestep Collection Time: 2.18808
Timestep Consumption Time: 2.54143
PPO Batch Consumption Time: 0.29796
Total Iteration Time: 4.72950

Cumulative Model Updates: 7,110
Cumulative Timesteps: 59,422,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 59422024...
Checkpoint 59422024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,667.76441
Policy Entropy: 1.84248
Value Function Loss: 0.12950

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.28783
Value Function Update Magnitude: 0.56207

Collected Steps per Second: 21,477.10570
Overall Steps per Second: 9,579.77203

Timestep Collection Time: 2.32834
Timestep Consumption Time: 2.89162
PPO Batch Consumption Time: 0.33316
Total Iteration Time: 5.21996

Cumulative Model Updates: 7,116
Cumulative Timesteps: 59,472,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,283.48060
Policy Entropy: 1.85012
Value Function Loss: 0.12753

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.28661
Value Function Update Magnitude: 0.57066

Collected Steps per Second: 18,704.29620
Overall Steps per Second: 9,455.37233

Timestep Collection Time: 2.67340
Timestep Consumption Time: 2.61503
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 5.28842

Cumulative Model Updates: 7,122
Cumulative Timesteps: 59,522,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 59522034...
Checkpoint 59522034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499.05116
Policy Entropy: 1.82991
Value Function Loss: 0.13411

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.29030
Value Function Update Magnitude: 0.50581

Collected Steps per Second: 20,159.41310
Overall Steps per Second: 9,899.13703

Timestep Collection Time: 2.48093
Timestep Consumption Time: 2.57143
PPO Batch Consumption Time: 0.30641
Total Iteration Time: 5.05236

Cumulative Model Updates: 7,128
Cumulative Timesteps: 59,572,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,620.69342
Policy Entropy: 1.84837
Value Function Loss: 0.13011

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.29477
Value Function Update Magnitude: 0.46863

Collected Steps per Second: 17,031.70217
Overall Steps per Second: 8,960.63689

Timestep Collection Time: 2.93664
Timestep Consumption Time: 2.64510
PPO Batch Consumption Time: 0.30764
Total Iteration Time: 5.58175

Cumulative Model Updates: 7,134
Cumulative Timesteps: 59,622,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 59622064...
Checkpoint 59622064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,658.30109
Policy Entropy: 1.84715
Value Function Loss: 0.13078

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11353
Policy Update Magnitude: 0.28730
Value Function Update Magnitude: 0.42269

Collected Steps per Second: 19,452.76372
Overall Steps per Second: 9,157.32922

Timestep Collection Time: 2.57064
Timestep Consumption Time: 2.89013
PPO Batch Consumption Time: 0.36236
Total Iteration Time: 5.46076

Cumulative Model Updates: 7,140
Cumulative Timesteps: 59,672,070

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,228.94047
Policy Entropy: 1.83824
Value Function Loss: 0.12333

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.13840
Policy Update Magnitude: 0.26843
Value Function Update Magnitude: 0.45494

Collected Steps per Second: 17,561.26567
Overall Steps per Second: 9,444.94638

Timestep Collection Time: 2.84888
Timestep Consumption Time: 2.44813
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 5.29701

Cumulative Model Updates: 7,146
Cumulative Timesteps: 59,722,100

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 59722100...
Checkpoint 59722100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,187.51518
Policy Entropy: 1.83050
Value Function Loss: 0.12896

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.23842
Value Function Update Magnitude: 0.52465

Collected Steps per Second: 21,142.94597
Overall Steps per Second: 10,300.82826

Timestep Collection Time: 2.36533
Timestep Consumption Time: 2.48962
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.85495

Cumulative Model Updates: 7,152
Cumulative Timesteps: 59,772,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,653.29115
Policy Entropy: 1.83881
Value Function Loss: 0.13601

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11816
Policy Update Magnitude: 0.23894
Value Function Update Magnitude: 0.42428

Collected Steps per Second: 21,871.91560
Overall Steps per Second: 10,442.83437

Timestep Collection Time: 2.28732
Timestep Consumption Time: 2.50334
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.79065

Cumulative Model Updates: 7,158
Cumulative Timesteps: 59,822,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 59822138...
Checkpoint 59822138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,076.96388
Policy Entropy: 1.83334
Value Function Loss: 0.14411

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.11943
Policy Update Magnitude: 0.25183
Value Function Update Magnitude: 0.37642

Collected Steps per Second: 21,310.72734
Overall Steps per Second: 9,919.96922

Timestep Collection Time: 2.34680
Timestep Consumption Time: 2.69475
PPO Batch Consumption Time: 0.32410
Total Iteration Time: 5.04155

Cumulative Model Updates: 7,164
Cumulative Timesteps: 59,872,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,478.18846
Policy Entropy: 1.83823
Value Function Loss: 0.13953

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.26980
Value Function Update Magnitude: 0.47619

Collected Steps per Second: 20,201.05001
Overall Steps per Second: 9,489.60609

Timestep Collection Time: 2.47581
Timestep Consumption Time: 2.79459
PPO Batch Consumption Time: 0.33447
Total Iteration Time: 5.27040

Cumulative Model Updates: 7,170
Cumulative Timesteps: 59,922,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 59922164...
Checkpoint 59922164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,719.53541
Policy Entropy: 1.83165
Value Function Loss: 0.13498

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12838
Policy Update Magnitude: 0.26063
Value Function Update Magnitude: 0.57394

Collected Steps per Second: 19,392.50442
Overall Steps per Second: 9,634.68063

Timestep Collection Time: 2.57904
Timestep Consumption Time: 2.61200
PPO Batch Consumption Time: 0.29718
Total Iteration Time: 5.19104

Cumulative Model Updates: 7,176
Cumulative Timesteps: 59,972,178

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,183.69993
Policy Entropy: 1.82838
Value Function Loss: 0.13920

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.25261
Value Function Update Magnitude: 0.55701

Collected Steps per Second: 20,222.69550
Overall Steps per Second: 10,047.83046

Timestep Collection Time: 2.47306
Timestep Consumption Time: 2.50433
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.97739

Cumulative Model Updates: 7,182
Cumulative Timesteps: 60,022,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 60022190...
Checkpoint 60022190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,122.05180
Policy Entropy: 1.81600
Value Function Loss: 0.15070

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07959
Policy Update Magnitude: 0.27718
Value Function Update Magnitude: 0.48043

Collected Steps per Second: 20,355.85094
Overall Steps per Second: 9,854.49926

Timestep Collection Time: 2.45718
Timestep Consumption Time: 2.61847
PPO Batch Consumption Time: 0.30686
Total Iteration Time: 5.07565

Cumulative Model Updates: 7,188
Cumulative Timesteps: 60,072,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,273.85153
Policy Entropy: 1.81791
Value Function Loss: 0.15440

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.29853
Value Function Update Magnitude: 0.40643

Collected Steps per Second: 21,502.61661
Overall Steps per Second: 10,019.84089

Timestep Collection Time: 2.32530
Timestep Consumption Time: 2.66480
PPO Batch Consumption Time: 0.32191
Total Iteration Time: 4.99010

Cumulative Model Updates: 7,194
Cumulative Timesteps: 60,122,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 60122208...
Checkpoint 60122208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,024.67278
Policy Entropy: 1.82360
Value Function Loss: 0.14390

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.27435
Value Function Update Magnitude: 0.41888

Collected Steps per Second: 20,769.20523
Overall Steps per Second: 10,134.64138

Timestep Collection Time: 2.40924
Timestep Consumption Time: 2.52808
PPO Batch Consumption Time: 0.29830
Total Iteration Time: 4.93732

Cumulative Model Updates: 7,200
Cumulative Timesteps: 60,172,246

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,704.14466
Policy Entropy: 1.81662
Value Function Loss: 0.13764

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.27955
Value Function Update Magnitude: 0.42621

Collected Steps per Second: 21,270.69327
Overall Steps per Second: 9,997.00310

Timestep Collection Time: 2.35206
Timestep Consumption Time: 2.65244
PPO Batch Consumption Time: 0.31685
Total Iteration Time: 5.00450

Cumulative Model Updates: 7,206
Cumulative Timesteps: 60,222,276

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 60222276...
Checkpoint 60222276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,319.25624
Policy Entropy: 1.82534
Value Function Loss: 0.12866

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11447
Policy Update Magnitude: 0.28746
Value Function Update Magnitude: 0.42645

Collected Steps per Second: 20,567.12456
Overall Steps per Second: 10,148.56807

Timestep Collection Time: 2.43223
Timestep Consumption Time: 2.49694
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.92917

Cumulative Model Updates: 7,212
Cumulative Timesteps: 60,272,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,224.83733
Policy Entropy: 1.81444
Value Function Loss: 0.13281

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.29193
Value Function Update Magnitude: 0.42505

Collected Steps per Second: 21,929.62552
Overall Steps per Second: 10,446.61897

Timestep Collection Time: 2.28066
Timestep Consumption Time: 2.50692
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.78758

Cumulative Model Updates: 7,218
Cumulative Timesteps: 60,322,314

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 60322314...
Checkpoint 60322314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,994.12315
Policy Entropy: 1.80920
Value Function Loss: 0.13107

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.27734
Value Function Update Magnitude: 0.41198

Collected Steps per Second: 18,846.01104
Overall Steps per Second: 9,461.62767

Timestep Collection Time: 2.65478
Timestep Consumption Time: 2.63311
PPO Batch Consumption Time: 0.30309
Total Iteration Time: 5.28789

Cumulative Model Updates: 7,224
Cumulative Timesteps: 60,372,346

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,897.89470
Policy Entropy: 1.80280
Value Function Loss: 0.13443

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.29635
Value Function Update Magnitude: 0.45694

Collected Steps per Second: 21,431.39430
Overall Steps per Second: 9,975.16760

Timestep Collection Time: 2.33349
Timestep Consumption Time: 2.67996
PPO Batch Consumption Time: 0.31967
Total Iteration Time: 5.01345

Cumulative Model Updates: 7,230
Cumulative Timesteps: 60,422,356

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 60422356...
Checkpoint 60422356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,178.52539
Policy Entropy: 1.80592
Value Function Loss: 0.14254

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.29579
Value Function Update Magnitude: 0.45418

Collected Steps per Second: 21,139.29835
Overall Steps per Second: 10,043.33546

Timestep Collection Time: 2.36536
Timestep Consumption Time: 2.61327
PPO Batch Consumption Time: 0.31212
Total Iteration Time: 4.97862

Cumulative Model Updates: 7,236
Cumulative Timesteps: 60,472,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.48625
Policy Entropy: 1.80646
Value Function Loss: 0.14587

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11859
Policy Update Magnitude: 0.30444
Value Function Update Magnitude: 0.46337

Collected Steps per Second: 19,340.07316
Overall Steps per Second: 9,882.31867

Timestep Collection Time: 2.58675
Timestep Consumption Time: 2.47562
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 5.06237

Cumulative Model Updates: 7,242
Cumulative Timesteps: 60,522,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 60522386...
Checkpoint 60522386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,323.63149
Policy Entropy: 1.80188
Value Function Loss: 0.14525

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.31138
Value Function Update Magnitude: 0.44337

Collected Steps per Second: 21,397.01985
Overall Steps per Second: 10,070.49285

Timestep Collection Time: 2.33715
Timestep Consumption Time: 2.62865
PPO Batch Consumption Time: 0.31006
Total Iteration Time: 4.96579

Cumulative Model Updates: 7,248
Cumulative Timesteps: 60,572,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,195.66586
Policy Entropy: 1.78720
Value Function Loss: 0.14754

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.32313
Value Function Update Magnitude: 0.40301

Collected Steps per Second: 21,908.58930
Overall Steps per Second: 10,536.84911

Timestep Collection Time: 2.28321
Timestep Consumption Time: 2.46413
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.74734

Cumulative Model Updates: 7,254
Cumulative Timesteps: 60,622,416

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 60622416...
Checkpoint 60622416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,438.94293
Policy Entropy: 1.78931
Value Function Loss: 0.14711

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08026
Policy Update Magnitude: 0.33409
Value Function Update Magnitude: 0.42739

Collected Steps per Second: 21,251.70034
Overall Steps per Second: 10,253.29740

Timestep Collection Time: 2.35351
Timestep Consumption Time: 2.52453
PPO Batch Consumption Time: 0.29898
Total Iteration Time: 4.87804

Cumulative Model Updates: 7,260
Cumulative Timesteps: 60,672,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,686.31255
Policy Entropy: 1.79082
Value Function Loss: 0.15495

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.34149
Value Function Update Magnitude: 0.36389

Collected Steps per Second: 19,632.40778
Overall Steps per Second: 9,591.52626

Timestep Collection Time: 2.54742
Timestep Consumption Time: 2.66677
PPO Batch Consumption Time: 0.30019
Total Iteration Time: 5.21419

Cumulative Model Updates: 7,266
Cumulative Timesteps: 60,722,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 60722444...
Checkpoint 60722444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,782.53150
Policy Entropy: 1.78156
Value Function Loss: 0.15928

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.34835
Value Function Update Magnitude: 0.37904

Collected Steps per Second: 20,099.34664
Overall Steps per Second: 9,868.82752

Timestep Collection Time: 2.49023
Timestep Consumption Time: 2.58150
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 5.07173

Cumulative Model Updates: 7,272
Cumulative Timesteps: 60,772,496

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,731.90517
Policy Entropy: 1.77468
Value Function Loss: 0.15182

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.32386
Value Function Update Magnitude: 0.40769

Collected Steps per Second: 21,684.58970
Overall Steps per Second: 10,409.48778

Timestep Collection Time: 2.30689
Timestep Consumption Time: 2.49872
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.80562

Cumulative Model Updates: 7,278
Cumulative Timesteps: 60,822,520

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 60822520...
Checkpoint 60822520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,817.80483
Policy Entropy: 1.76856
Value Function Loss: 0.14388

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.07030
Policy Update Magnitude: 0.32726
Value Function Update Magnitude: 0.40596

Collected Steps per Second: 20,749.23173
Overall Steps per Second: 10,200.96297

Timestep Collection Time: 2.41127
Timestep Consumption Time: 2.49337
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.90464

Cumulative Model Updates: 7,284
Cumulative Timesteps: 60,872,552

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,925.13516
Policy Entropy: 1.77077
Value Function Loss: 0.13361

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07377
Policy Update Magnitude: 0.33976
Value Function Update Magnitude: 0.40369

Collected Steps per Second: 18,999.89698
Overall Steps per Second: 9,798.80508

Timestep Collection Time: 2.63338
Timestep Consumption Time: 2.47275
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 5.10613

Cumulative Model Updates: 7,290
Cumulative Timesteps: 60,922,586

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 60922586...
Checkpoint 60922586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.69157
Policy Entropy: 1.76986
Value Function Loss: 0.13107

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06664
Policy Update Magnitude: 0.34674
Value Function Update Magnitude: 0.48008

Collected Steps per Second: 20,751.71318
Overall Steps per Second: 10,109.09762

Timestep Collection Time: 2.41040
Timestep Consumption Time: 2.53761
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.94802

Cumulative Model Updates: 7,296
Cumulative Timesteps: 60,972,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.88026
Policy Entropy: 1.76930
Value Function Loss: 0.13511

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06777
Policy Update Magnitude: 0.35972
Value Function Update Magnitude: 0.40832

Collected Steps per Second: 21,363.35668
Overall Steps per Second: 10,133.08698

Timestep Collection Time: 2.34111
Timestep Consumption Time: 2.59460
PPO Batch Consumption Time: 0.30270
Total Iteration Time: 4.93571

Cumulative Model Updates: 7,302
Cumulative Timesteps: 61,022,620

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 61022620...
Checkpoint 61022620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,333.64250
Policy Entropy: 1.77279
Value Function Loss: 0.14102

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07454
Policy Update Magnitude: 0.35445
Value Function Update Magnitude: 0.34979

Collected Steps per Second: 20,689.76046
Overall Steps per Second: 10,147.22794

Timestep Collection Time: 2.41714
Timestep Consumption Time: 2.51130
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.92844

Cumulative Model Updates: 7,308
Cumulative Timesteps: 61,072,630

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864.61632
Policy Entropy: 1.77167
Value Function Loss: 0.15410

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07391
Policy Update Magnitude: 0.36371
Value Function Update Magnitude: 0.33875

Collected Steps per Second: 20,407.62291
Overall Steps per Second: 9,701.24803

Timestep Collection Time: 2.45114
Timestep Consumption Time: 2.70510
PPO Batch Consumption Time: 0.32720
Total Iteration Time: 5.15624

Cumulative Model Updates: 7,314
Cumulative Timesteps: 61,122,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 61122652...
Checkpoint 61122652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,475.77509
Policy Entropy: 1.77927
Value Function Loss: 0.14777

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07466
Policy Update Magnitude: 0.36948
Value Function Update Magnitude: 0.35774

Collected Steps per Second: 20,302.55787
Overall Steps per Second: 10,305.00347

Timestep Collection Time: 2.46402
Timestep Consumption Time: 2.39051
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.85454

Cumulative Model Updates: 7,320
Cumulative Timesteps: 61,172,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.27652
Policy Entropy: 1.77357
Value Function Loss: 0.14973

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.35140
Value Function Update Magnitude: 0.39537

Collected Steps per Second: 21,818.10412
Overall Steps per Second: 10,143.34839

Timestep Collection Time: 2.29314
Timestep Consumption Time: 2.63935
PPO Batch Consumption Time: 0.31922
Total Iteration Time: 4.93249

Cumulative Model Updates: 7,326
Cumulative Timesteps: 61,222,710

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 61222710...
Checkpoint 61222710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,776.61937
Policy Entropy: 1.75794
Value Function Loss: 0.14267

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07716
Policy Update Magnitude: 0.35896
Value Function Update Magnitude: 0.41916

Collected Steps per Second: 18,190.63519
Overall Steps per Second: 9,535.24389

Timestep Collection Time: 2.74944
Timestep Consumption Time: 2.49574
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 5.24517

Cumulative Model Updates: 7,332
Cumulative Timesteps: 61,272,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,730.92334
Policy Entropy: 1.75792
Value Function Loss: 0.13706

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05917
Policy Update Magnitude: 0.34851
Value Function Update Magnitude: 0.46298

Collected Steps per Second: 19,114.81072
Overall Steps per Second: 9,716.89751

Timestep Collection Time: 2.61713
Timestep Consumption Time: 2.53122
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 5.14835

Cumulative Model Updates: 7,338
Cumulative Timesteps: 61,322,750

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 61322750...
Checkpoint 61322750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,083.95968
Policy Entropy: 1.76371
Value Function Loss: 0.14097

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10131
Policy Update Magnitude: 0.33629
Value Function Update Magnitude: 0.44980

Collected Steps per Second: 21,200.00829
Overall Steps per Second: 10,148.25958

Timestep Collection Time: 2.35934
Timestep Consumption Time: 2.56939
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.92873

Cumulative Model Updates: 7,344
Cumulative Timesteps: 61,372,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,905.97415
Policy Entropy: 1.78081
Value Function Loss: 0.14865

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.17655
Policy Update Magnitude: 0.26675
Value Function Update Magnitude: 0.44176

Collected Steps per Second: 20,280.54045
Overall Steps per Second: 9,806.41755

Timestep Collection Time: 2.46640
Timestep Consumption Time: 2.63434
PPO Batch Consumption Time: 0.30424
Total Iteration Time: 5.10074

Cumulative Model Updates: 7,350
Cumulative Timesteps: 61,422,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 61422788...
Checkpoint 61422788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,907.81728
Policy Entropy: 1.79705
Value Function Loss: 0.14813

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.15381
Policy Update Magnitude: 0.24111
Value Function Update Magnitude: 0.45139

Collected Steps per Second: 19,037.57558
Overall Steps per Second: 9,926.47995

Timestep Collection Time: 2.62744
Timestep Consumption Time: 2.41161
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 5.03905

Cumulative Model Updates: 7,356
Cumulative Timesteps: 61,472,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.85595
Policy Entropy: 1.80503
Value Function Loss: 0.15120

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.12052
Policy Update Magnitude: 0.24990
Value Function Update Magnitude: 0.41282

Collected Steps per Second: 21,246.52026
Overall Steps per Second: 10,322.16069

Timestep Collection Time: 2.35549
Timestep Consumption Time: 2.49291
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.84840

Cumulative Model Updates: 7,362
Cumulative Timesteps: 61,522,854

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 61522854...
Checkpoint 61522854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,882.95198
Policy Entropy: 1.79470
Value Function Loss: 0.14533

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.26677
Value Function Update Magnitude: 0.38967

Collected Steps per Second: 20,843.91055
Overall Steps per Second: 10,120.87040

Timestep Collection Time: 2.40080
Timestep Consumption Time: 2.54364
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.94444

Cumulative Model Updates: 7,368
Cumulative Timesteps: 61,572,896

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,501.23880
Policy Entropy: 1.79467
Value Function Loss: 0.14635

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.16606
Policy Update Magnitude: 0.24275
Value Function Update Magnitude: 0.42865

Collected Steps per Second: 21,238.26597
Overall Steps per Second: 10,141.88934

Timestep Collection Time: 2.35537
Timestep Consumption Time: 2.57704
PPO Batch Consumption Time: 0.30443
Total Iteration Time: 4.93241

Cumulative Model Updates: 7,374
Cumulative Timesteps: 61,622,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 61622920...
Checkpoint 61622920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,722.34198
Policy Entropy: 1.80137
Value Function Loss: 0.13801

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.21344
Value Function Update Magnitude: 0.53255

Collected Steps per Second: 21,351.08716
Overall Steps per Second: 10,528.20259

Timestep Collection Time: 2.34189
Timestep Consumption Time: 2.40744
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.74934

Cumulative Model Updates: 7,380
Cumulative Timesteps: 61,672,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,602.92619
Policy Entropy: 1.78244
Value Function Loss: 0.13991

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.14768
Policy Update Magnitude: 0.21191
Value Function Update Magnitude: 0.69253

Collected Steps per Second: 21,262.08691
Overall Steps per Second: 10,114.80512

Timestep Collection Time: 2.35264
Timestep Consumption Time: 2.59279
PPO Batch Consumption Time: 0.30976
Total Iteration Time: 4.94542

Cumulative Model Updates: 7,386
Cumulative Timesteps: 61,722,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 61722944...
Checkpoint 61722944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,121.07268
Policy Entropy: 1.77299
Value Function Loss: 0.13843

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.15840
Policy Update Magnitude: 0.22149
Value Function Update Magnitude: 0.67507

Collected Steps per Second: 20,982.89944
Overall Steps per Second: 10,199.77774

Timestep Collection Time: 2.38289
Timestep Consumption Time: 2.51917
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.90207

Cumulative Model Updates: 7,392
Cumulative Timesteps: 61,772,944

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,097.80538
Policy Entropy: 1.75889
Value Function Loss: 0.14364

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.15184
Policy Update Magnitude: 0.23374
Value Function Update Magnitude: 0.59313

Collected Steps per Second: 21,311.83858
Overall Steps per Second: 10,445.90836

Timestep Collection Time: 2.34724
Timestep Consumption Time: 2.44162
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.78886

Cumulative Model Updates: 7,398
Cumulative Timesteps: 61,822,968

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 61822968...
Checkpoint 61822968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,753.75069
Policy Entropy: 1.76129
Value Function Loss: 0.14002

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.16783
Policy Update Magnitude: 0.23034
Value Function Update Magnitude: 0.56310

Collected Steps per Second: 20,731.61850
Overall Steps per Second: 10,115.99086

Timestep Collection Time: 2.41390
Timestep Consumption Time: 2.53312
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.94702

Cumulative Model Updates: 7,404
Cumulative Timesteps: 61,873,012

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.29523
Policy Entropy: 1.76148
Value Function Loss: 0.13667

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11785
Policy Update Magnitude: 0.25800
Value Function Update Magnitude: 0.62645

Collected Steps per Second: 21,347.98744
Overall Steps per Second: 10,184.98949

Timestep Collection Time: 2.34252
Timestep Consumption Time: 2.56745
PPO Batch Consumption Time: 0.30487
Total Iteration Time: 4.90997

Cumulative Model Updates: 7,410
Cumulative Timesteps: 61,923,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 61923020...
Checkpoint 61923020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,901.84364
Policy Entropy: 1.76151
Value Function Loss: 0.13467

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.27869
Value Function Update Magnitude: 0.62341

Collected Steps per Second: 20,631.71027
Overall Steps per Second: 10,308.63648

Timestep Collection Time: 2.42355
Timestep Consumption Time: 2.42695
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.85050

Cumulative Model Updates: 7,416
Cumulative Timesteps: 61,973,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.60901
Policy Entropy: 1.77093
Value Function Loss: 0.13820

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.27277
Value Function Update Magnitude: 0.51356

Collected Steps per Second: 20,809.12038
Overall Steps per Second: 9,844.92424

Timestep Collection Time: 2.40462
Timestep Consumption Time: 2.67800
PPO Batch Consumption Time: 0.31366
Total Iteration Time: 5.08262

Cumulative Model Updates: 7,422
Cumulative Timesteps: 62,023,060

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 62023060...
Checkpoint 62023060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.72579
Policy Entropy: 1.75485
Value Function Loss: 0.14528

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.26332
Value Function Update Magnitude: 0.48780

Collected Steps per Second: 18,647.82428
Overall Steps per Second: 9,313.73358

Timestep Collection Time: 2.68160
Timestep Consumption Time: 2.68746
PPO Batch Consumption Time: 0.32668
Total Iteration Time: 5.36906

Cumulative Model Updates: 7,428
Cumulative Timesteps: 62,073,066

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,654.22234
Policy Entropy: 1.75200
Value Function Loss: 0.14249

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.26886
Value Function Update Magnitude: 0.54644

Collected Steps per Second: 19,004.10093
Overall Steps per Second: 9,747.77966

Timestep Collection Time: 2.63238
Timestep Consumption Time: 2.49966
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 5.13204

Cumulative Model Updates: 7,434
Cumulative Timesteps: 62,123,092

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 62123092...
Checkpoint 62123092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.25484
Policy Entropy: 1.75150
Value Function Loss: 0.14775

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.30056
Value Function Update Magnitude: 0.55418

Collected Steps per Second: 21,019.04627
Overall Steps per Second: 10,232.76596

Timestep Collection Time: 2.37899
Timestep Consumption Time: 2.50767
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.88666

Cumulative Model Updates: 7,440
Cumulative Timesteps: 62,173,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879.40921
Policy Entropy: 1.75792
Value Function Loss: 0.14585

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10029
Policy Update Magnitude: 0.31484
Value Function Update Magnitude: 0.47043

Collected Steps per Second: 19,623.02010
Overall Steps per Second: 9,701.42804

Timestep Collection Time: 2.54966
Timestep Consumption Time: 2.60752
PPO Batch Consumption Time: 0.30140
Total Iteration Time: 5.15718

Cumulative Model Updates: 7,446
Cumulative Timesteps: 62,223,128

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 62223128...
Checkpoint 62223128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,848.88648
Policy Entropy: 1.75860
Value Function Loss: 0.14157

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.29970
Value Function Update Magnitude: 0.45051

Collected Steps per Second: 19,083.95345
Overall Steps per Second: 9,592.97275

Timestep Collection Time: 2.62116
Timestep Consumption Time: 2.59329
PPO Batch Consumption Time: 0.30239
Total Iteration Time: 5.21444

Cumulative Model Updates: 7,452
Cumulative Timesteps: 62,273,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,175.29894
Policy Entropy: 1.76118
Value Function Loss: 0.14148

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.15223
Policy Update Magnitude: 0.25759
Value Function Update Magnitude: 0.41792

Collected Steps per Second: 19,133.03077
Overall Steps per Second: 9,820.42390

Timestep Collection Time: 2.61380
Timestep Consumption Time: 2.47864
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 5.09245

Cumulative Model Updates: 7,458
Cumulative Timesteps: 62,323,160

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 62323160...
Checkpoint 62323160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,189.14692
Policy Entropy: 1.75027
Value Function Loss: 0.13790

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.14348
Policy Update Magnitude: 0.23974
Value Function Update Magnitude: 0.52987

Collected Steps per Second: 21,318.44110
Overall Steps per Second: 10,329.26237

Timestep Collection Time: 2.34689
Timestep Consumption Time: 2.49683
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.84371

Cumulative Model Updates: 7,464
Cumulative Timesteps: 62,373,192

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,778.45530
Policy Entropy: 1.76148
Value Function Loss: 0.13787

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.16971
Policy Update Magnitude: 0.23251
Value Function Update Magnitude: 0.52562

Collected Steps per Second: 21,538.35079
Overall Steps per Second: 10,297.35167

Timestep Collection Time: 2.32255
Timestep Consumption Time: 2.53539
PPO Batch Consumption Time: 0.31039
Total Iteration Time: 4.85795

Cumulative Model Updates: 7,470
Cumulative Timesteps: 62,423,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 62423216...
Checkpoint 62423216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,249.34674
Policy Entropy: 1.74502
Value Function Loss: 0.13066

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.15364
Policy Update Magnitude: 0.23828
Value Function Update Magnitude: 0.48045

Collected Steps per Second: 20,485.26840
Overall Steps per Second: 10,293.68648

Timestep Collection Time: 2.44088
Timestep Consumption Time: 2.41666
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.85754

Cumulative Model Updates: 7,476
Cumulative Timesteps: 62,473,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,728.74200
Policy Entropy: 1.75536
Value Function Loss: 0.13959

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.21535
Value Function Update Magnitude: 0.40866

Collected Steps per Second: 21,312.45806
Overall Steps per Second: 10,098.22181

Timestep Collection Time: 2.34745
Timestep Consumption Time: 2.60688
PPO Batch Consumption Time: 0.30417
Total Iteration Time: 4.95434

Cumulative Model Updates: 7,482
Cumulative Timesteps: 62,523,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 62523248...
Checkpoint 62523248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,209.90839
Policy Entropy: 1.75216
Value Function Loss: 0.13751

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.22768
Value Function Update Magnitude: 0.39589

Collected Steps per Second: 20,715.40954
Overall Steps per Second: 10,032.90541

Timestep Collection Time: 2.41376
Timestep Consumption Time: 2.57004
PPO Batch Consumption Time: 0.30256
Total Iteration Time: 4.98380

Cumulative Model Updates: 7,488
Cumulative Timesteps: 62,573,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,038.18884
Policy Entropy: 1.74789
Value Function Loss: 0.14503

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.26078
Value Function Update Magnitude: 0.39062

Collected Steps per Second: 21,778.79369
Overall Steps per Second: 10,479.14117

Timestep Collection Time: 2.29618
Timestep Consumption Time: 2.47597
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 4.77215

Cumulative Model Updates: 7,494
Cumulative Timesteps: 62,623,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 62623258...
Checkpoint 62623258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,255.78518
Policy Entropy: 1.74886
Value Function Loss: 0.13990

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.28239
Value Function Update Magnitude: 0.38855

Collected Steps per Second: 21,004.96973
Overall Steps per Second: 10,264.43829

Timestep Collection Time: 2.38067
Timestep Consumption Time: 2.49110
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.87177

Cumulative Model Updates: 7,500
Cumulative Timesteps: 62,673,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,951.61764
Policy Entropy: 1.74535
Value Function Loss: 0.14094

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.29110
Value Function Update Magnitude: 0.42826

Collected Steps per Second: 21,657.03562
Overall Steps per Second: 10,552.23311

Timestep Collection Time: 2.30918
Timestep Consumption Time: 2.43010
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.73928

Cumulative Model Updates: 7,506
Cumulative Timesteps: 62,723,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 62723274...
Checkpoint 62723274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571.66651
Policy Entropy: 1.74827
Value Function Loss: 0.13719

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12573
Policy Update Magnitude: 0.25664
Value Function Update Magnitude: 0.45439

Collected Steps per Second: 20,794.96699
Overall Steps per Second: 10,287.17542

Timestep Collection Time: 2.40635
Timestep Consumption Time: 2.45796
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.86431

Cumulative Model Updates: 7,512
Cumulative Timesteps: 62,773,314

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,305.01726
Policy Entropy: 1.75272
Value Function Loss: 0.13480

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.24858
Value Function Update Magnitude: 0.46132

Collected Steps per Second: 21,081.44402
Overall Steps per Second: 9,973.97585

Timestep Collection Time: 2.37251
Timestep Consumption Time: 2.64214
PPO Batch Consumption Time: 0.30179
Total Iteration Time: 5.01465

Cumulative Model Updates: 7,518
Cumulative Timesteps: 62,823,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 62823330...
Checkpoint 62823330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,923.12962
Policy Entropy: 1.74303
Value Function Loss: 0.13431

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.27204
Value Function Update Magnitude: 0.45580

Collected Steps per Second: 21,400.99773
Overall Steps per Second: 10,232.59304

Timestep Collection Time: 2.33709
Timestep Consumption Time: 2.55082
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.88791

Cumulative Model Updates: 7,524
Cumulative Timesteps: 62,873,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,786.02955
Policy Entropy: 1.74541
Value Function Loss: 0.12792

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.15768
Policy Update Magnitude: 0.25582
Value Function Update Magnitude: 0.54174

Collected Steps per Second: 21,351.42251
Overall Steps per Second: 10,456.92409

Timestep Collection Time: 2.34223
Timestep Consumption Time: 2.44024
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.78248

Cumulative Model Updates: 7,530
Cumulative Timesteps: 62,923,356

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 62923356...
Checkpoint 62923356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,949.49747
Policy Entropy: 1.75017
Value Function Loss: 0.12575

Mean KL Divergence: 0.02538
SB3 Clip Fraction: 0.20082
Policy Update Magnitude: 0.22552
Value Function Update Magnitude: 0.58315

Collected Steps per Second: 21,007.45917
Overall Steps per Second: 10,204.26796

Timestep Collection Time: 2.38077
Timestep Consumption Time: 2.52051
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.90128

Cumulative Model Updates: 7,536
Cumulative Timesteps: 62,973,370

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,586.55721
Policy Entropy: 1.75451
Value Function Loss: 0.12938

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.16634
Policy Update Magnitude: 0.20082
Value Function Update Magnitude: 0.48451

Collected Steps per Second: 21,105.61792
Overall Steps per Second: 10,193.48444

Timestep Collection Time: 2.36999
Timestep Consumption Time: 2.53707
PPO Batch Consumption Time: 0.29959
Total Iteration Time: 4.90706

Cumulative Model Updates: 7,542
Cumulative Timesteps: 63,023,390

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 63023390...
Checkpoint 63023390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,427.16368
Policy Entropy: 1.75341
Value Function Loss: 0.13149

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.17218
Policy Update Magnitude: 0.21594
Value Function Update Magnitude: 0.47285

Collected Steps per Second: 19,271.86232
Overall Steps per Second: 9,703.68269

Timestep Collection Time: 2.59570
Timestep Consumption Time: 2.55945
PPO Batch Consumption Time: 0.29987
Total Iteration Time: 5.15516

Cumulative Model Updates: 7,548
Cumulative Timesteps: 63,073,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,344.73181
Policy Entropy: 1.73989
Value Function Loss: 0.13655

Mean KL Divergence: 0.02449
SB3 Clip Fraction: 0.17648
Policy Update Magnitude: 0.23030
Value Function Update Magnitude: 0.45668

Collected Steps per Second: 18,676.66468
Overall Steps per Second: 9,594.59683

Timestep Collection Time: 2.67885
Timestep Consumption Time: 2.53575
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 5.21460

Cumulative Model Updates: 7,554
Cumulative Timesteps: 63,123,446

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 63123446...
Checkpoint 63123446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.58711
Policy Entropy: 1.75107
Value Function Loss: 0.13719

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.15282
Policy Update Magnitude: 0.23784
Value Function Update Magnitude: 0.45105

Collected Steps per Second: 21,030.13422
Overall Steps per Second: 10,264.85300

Timestep Collection Time: 2.37764
Timestep Consumption Time: 2.49355
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.87119

Cumulative Model Updates: 7,560
Cumulative Timesteps: 63,173,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,769.69478
Policy Entropy: 1.76270
Value Function Loss: 0.13154

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.17830
Policy Update Magnitude: 0.23683
Value Function Update Magnitude: 0.46567

Collected Steps per Second: 21,292.87528
Overall Steps per Second: 10,231.33938

Timestep Collection Time: 2.34820
Timestep Consumption Time: 2.53874
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.88695

Cumulative Model Updates: 7,566
Cumulative Timesteps: 63,223,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 63223448...
Checkpoint 63223448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,154.05033
Policy Entropy: 1.75195
Value Function Loss: 0.13299

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.17665
Policy Update Magnitude: 0.20765
Value Function Update Magnitude: 0.46658

Collected Steps per Second: 20,485.78984
Overall Steps per Second: 9,970.93144

Timestep Collection Time: 2.44159
Timestep Consumption Time: 2.57479
PPO Batch Consumption Time: 0.30730
Total Iteration Time: 5.01638

Cumulative Model Updates: 7,572
Cumulative Timesteps: 63,273,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,745.85670
Policy Entropy: 1.75091
Value Function Loss: 0.14315

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.17094
Policy Update Magnitude: 0.20808
Value Function Update Magnitude: 0.37239

Collected Steps per Second: 19,197.55892
Overall Steps per Second: 9,638.51189

Timestep Collection Time: 2.60658
Timestep Consumption Time: 2.58509
PPO Batch Consumption Time: 0.29814
Total Iteration Time: 5.19167

Cumulative Model Updates: 7,578
Cumulative Timesteps: 63,323,506

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 63323506...
Checkpoint 63323506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,157.60163
Policy Entropy: 1.74667
Value Function Loss: 0.14186

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.15119
Policy Update Magnitude: 0.20278
Value Function Update Magnitude: 0.33266

Collected Steps per Second: 20,750.64681
Overall Steps per Second: 10,055.30781

Timestep Collection Time: 2.41091
Timestep Consumption Time: 2.56437
PPO Batch Consumption Time: 0.29748
Total Iteration Time: 4.97528

Cumulative Model Updates: 7,584
Cumulative Timesteps: 63,373,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,753.65344
Policy Entropy: 1.75388
Value Function Loss: 0.12974

Mean KL Divergence: 0.02406
SB3 Clip Fraction: 0.18587
Policy Update Magnitude: 0.21455
Value Function Update Magnitude: 0.48713

Collected Steps per Second: 21,351.15518
Overall Steps per Second: 10,419.46089

Timestep Collection Time: 2.34301
Timestep Consumption Time: 2.45820
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.80121

Cumulative Model Updates: 7,590
Cumulative Timesteps: 63,423,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 63423560...
Checkpoint 63423560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,567.48941
Policy Entropy: 1.75100
Value Function Loss: 0.13119

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.20951
Value Function Update Magnitude: 0.51624

Collected Steps per Second: 21,074.84757
Overall Steps per Second: 10,165.06615

Timestep Collection Time: 2.37278
Timestep Consumption Time: 2.54662
PPO Batch Consumption Time: 0.30214
Total Iteration Time: 4.91940

Cumulative Model Updates: 7,596
Cumulative Timesteps: 63,473,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,053.86184
Policy Entropy: 1.76498
Value Function Loss: 0.12973

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.22544
Value Function Update Magnitude: 0.54391

Collected Steps per Second: 21,380.63024
Overall Steps per Second: 10,330.53797

Timestep Collection Time: 2.33922
Timestep Consumption Time: 2.50215
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.84137

Cumulative Model Updates: 7,602
Cumulative Timesteps: 63,523,580

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 63523580...
Checkpoint 63523580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.44537
Policy Entropy: 1.75706
Value Function Loss: 0.13576

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.25062
Value Function Update Magnitude: 0.62409

Collected Steps per Second: 21,054.15014
Overall Steps per Second: 10,176.23281

Timestep Collection Time: 2.37483
Timestep Consumption Time: 2.53858
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.91341

Cumulative Model Updates: 7,608
Cumulative Timesteps: 63,573,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,854.99887
Policy Entropy: 1.76696
Value Function Loss: 0.13287

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11715
Policy Update Magnitude: 0.26436
Value Function Update Magnitude: 0.65212

Collected Steps per Second: 21,679.27723
Overall Steps per Second: 10,533.01468

Timestep Collection Time: 2.30746
Timestep Consumption Time: 2.44180
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.74926

Cumulative Model Updates: 7,614
Cumulative Timesteps: 63,623,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 63623604...
Checkpoint 63623604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,867.66836
Policy Entropy: 1.76174
Value Function Loss: 0.13328

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.15206
Policy Update Magnitude: 0.23349
Value Function Update Magnitude: 0.62823

Collected Steps per Second: 17,697.74118
Overall Steps per Second: 9,155.47355

Timestep Collection Time: 2.82646
Timestep Consumption Time: 2.63715
PPO Batch Consumption Time: 0.30154
Total Iteration Time: 5.46362

Cumulative Model Updates: 7,620
Cumulative Timesteps: 63,673,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,282.09668
Policy Entropy: 1.77201
Value Function Loss: 0.13273

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.23099
Value Function Update Magnitude: 0.59630

Collected Steps per Second: 21,202.58732
Overall Steps per Second: 10,215.00603

Timestep Collection Time: 2.35933
Timestep Consumption Time: 2.53777
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.89711

Cumulative Model Updates: 7,626
Cumulative Timesteps: 63,723,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 63723650...
Checkpoint 63723650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,657.54340
Policy Entropy: 1.76108
Value Function Loss: 0.14140

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.22348
Value Function Update Magnitude: 0.51535

Collected Steps per Second: 21,372.05482
Overall Steps per Second: 10,512.50577

Timestep Collection Time: 2.34109
Timestep Consumption Time: 2.41838
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.75947

Cumulative Model Updates: 7,632
Cumulative Timesteps: 63,773,684

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,197.56057
Policy Entropy: 1.76653
Value Function Loss: 0.14073

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07727
Policy Update Magnitude: 0.27166
Value Function Update Magnitude: 0.41851

Collected Steps per Second: 21,373.85700
Overall Steps per Second: 10,357.44126

Timestep Collection Time: 2.34024
Timestep Consumption Time: 2.48914
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.82938

Cumulative Model Updates: 7,638
Cumulative Timesteps: 63,823,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 63823704...
Checkpoint 63823704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,164.67464
Policy Entropy: 1.76887
Value Function Loss: 0.13213

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07355
Policy Update Magnitude: 0.31101
Value Function Update Magnitude: 0.39867

Collected Steps per Second: 20,954.54258
Overall Steps per Second: 10,042.48523

Timestep Collection Time: 2.38726
Timestep Consumption Time: 2.59397
PPO Batch Consumption Time: 0.30219
Total Iteration Time: 4.98124

Cumulative Model Updates: 7,644
Cumulative Timesteps: 63,873,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,124.33159
Policy Entropy: 1.77380
Value Function Loss: 0.13093

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.30820
Value Function Update Magnitude: 0.43516

Collected Steps per Second: 21,559.21914
Overall Steps per Second: 10,176.72414

Timestep Collection Time: 2.31994
Timestep Consumption Time: 2.59481
PPO Batch Consumption Time: 0.30386
Total Iteration Time: 4.91474

Cumulative Model Updates: 7,650
Cumulative Timesteps: 63,923,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 63923744...
Checkpoint 63923744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,221.50566
Policy Entropy: 1.79262
Value Function Loss: 0.12772

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.29767
Value Function Update Magnitude: 0.44097

Collected Steps per Second: 20,988.10998
Overall Steps per Second: 10,141.21628

Timestep Collection Time: 2.38373
Timestep Consumption Time: 2.54960
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.93333

Cumulative Model Updates: 7,656
Cumulative Timesteps: 63,973,774

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.19379
Policy Entropy: 1.78759
Value Function Loss: 0.13512

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.28711
Value Function Update Magnitude: 0.46901

Collected Steps per Second: 21,152.61667
Overall Steps per Second: 10,401.80092

Timestep Collection Time: 2.36387
Timestep Consumption Time: 2.44318
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.80705

Cumulative Model Updates: 7,662
Cumulative Timesteps: 64,023,776

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 64023776...
Checkpoint 64023776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,272.17334
Policy Entropy: 1.80816
Value Function Loss: 0.12998

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07325
Policy Update Magnitude: 0.30538
Value Function Update Magnitude: 0.44939

Collected Steps per Second: 20,962.29669
Overall Steps per Second: 10,366.78161

Timestep Collection Time: 2.38705
Timestep Consumption Time: 2.43972
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.82676

Cumulative Model Updates: 7,668
Cumulative Timesteps: 64,073,814

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,460.71118
Policy Entropy: 1.79826
Value Function Loss: 0.13065

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06441
Policy Update Magnitude: 0.31307
Value Function Update Magnitude: 0.46062

Collected Steps per Second: 21,466.77528
Overall Steps per Second: 10,446.28699

Timestep Collection Time: 2.32993
Timestep Consumption Time: 2.45800
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.78792

Cumulative Model Updates: 7,674
Cumulative Timesteps: 64,123,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 64123830...
Checkpoint 64123830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,863.72260
Policy Entropy: 1.79779
Value Function Loss: 0.13110

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.30289
Value Function Update Magnitude: 0.43399

Collected Steps per Second: 20,710.23490
Overall Steps per Second: 10,105.49064

Timestep Collection Time: 2.41436
Timestep Consumption Time: 2.53364
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.94800

Cumulative Model Updates: 7,680
Cumulative Timesteps: 64,173,832

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,395.84986
Policy Entropy: 1.79587
Value Function Loss: 0.13071

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.26248
Value Function Update Magnitude: 0.43410

Collected Steps per Second: 21,588.97218
Overall Steps per Second: 10,538.93933

Timestep Collection Time: 2.31683
Timestep Consumption Time: 2.42919
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.74602

Cumulative Model Updates: 7,686
Cumulative Timesteps: 64,223,850

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 64223850...
Checkpoint 64223850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,223.15733
Policy Entropy: 1.79705
Value Function Loss: 0.12968

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.22825
Value Function Update Magnitude: 0.44517

Collected Steps per Second: 21,457.68988
Overall Steps per Second: 10,346.96854

Timestep Collection Time: 2.33073
Timestep Consumption Time: 2.50277
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.83349

Cumulative Model Updates: 7,692
Cumulative Timesteps: 64,273,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,775.59839
Policy Entropy: 1.80102
Value Function Loss: 0.13209

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.21150
Value Function Update Magnitude: 0.47366

Collected Steps per Second: 21,464.37297
Overall Steps per Second: 10,287.66298

Timestep Collection Time: 2.33047
Timestep Consumption Time: 2.53186
PPO Batch Consumption Time: 0.30700
Total Iteration Time: 4.86233

Cumulative Model Updates: 7,698
Cumulative Timesteps: 64,323,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 64323884...
Checkpoint 64323884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,166.54464
Policy Entropy: 1.79921
Value Function Loss: 0.13694

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12665
Policy Update Magnitude: 0.21370
Value Function Update Magnitude: 0.52034

Collected Steps per Second: 21,068.71503
Overall Steps per Second: 10,200.30351

Timestep Collection Time: 2.37433
Timestep Consumption Time: 2.52984
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.90417

Cumulative Model Updates: 7,704
Cumulative Timesteps: 64,373,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.80877
Policy Entropy: 1.80515
Value Function Loss: 0.13805

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.21562
Value Function Update Magnitude: 0.49567

Collected Steps per Second: 21,616.21263
Overall Steps per Second: 9,955.97046

Timestep Collection Time: 2.31326
Timestep Consumption Time: 2.70925
PPO Batch Consumption Time: 0.30234
Total Iteration Time: 5.02251

Cumulative Model Updates: 7,710
Cumulative Timesteps: 64,423,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 64423912...
Checkpoint 64423912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,283.87902
Policy Entropy: 1.80127
Value Function Loss: 0.13712

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.21299
Value Function Update Magnitude: 0.45898

Collected Steps per Second: 18,804.28044
Overall Steps per Second: 9,240.94676

Timestep Collection Time: 2.66120
Timestep Consumption Time: 2.75404
PPO Batch Consumption Time: 0.32565
Total Iteration Time: 5.41525

Cumulative Model Updates: 7,716
Cumulative Timesteps: 64,473,954

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,156.56486
Policy Entropy: 1.80601
Value Function Loss: 0.13133

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.22846
Value Function Update Magnitude: 0.47038

Collected Steps per Second: 17,165.48007
Overall Steps per Second: 9,117.52480

Timestep Collection Time: 2.91282
Timestep Consumption Time: 2.57112
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 5.48394

Cumulative Model Updates: 7,722
Cumulative Timesteps: 64,523,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 64523954...
Checkpoint 64523954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,082.72549
Policy Entropy: 1.79803
Value Function Loss: 0.12623

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.22860
Value Function Update Magnitude: 0.46393

Collected Steps per Second: 20,966.24364
Overall Steps per Second: 10,314.76552

Timestep Collection Time: 2.38584
Timestep Consumption Time: 2.46372
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.84955

Cumulative Model Updates: 7,728
Cumulative Timesteps: 64,573,976

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.40855
Policy Entropy: 1.80265
Value Function Loss: 0.12832

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.21710
Value Function Update Magnitude: 0.46551

Collected Steps per Second: 21,070.28537
Overall Steps per Second: 10,046.82968

Timestep Collection Time: 2.37301
Timestep Consumption Time: 2.60368
PPO Batch Consumption Time: 0.30232
Total Iteration Time: 4.97669

Cumulative Model Updates: 7,734
Cumulative Timesteps: 64,623,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 64623976...
Checkpoint 64623976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,776.32799
Policy Entropy: 1.79748
Value Function Loss: 0.12731

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11467
Policy Update Magnitude: 0.21505
Value Function Update Magnitude: 0.46301

Collected Steps per Second: 21,579.12691
Overall Steps per Second: 10,380.18582

Timestep Collection Time: 2.31909
Timestep Consumption Time: 2.50202
PPO Batch Consumption Time: 0.30127
Total Iteration Time: 4.82111

Cumulative Model Updates: 7,740
Cumulative Timesteps: 64,674,020

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,906.83012
Policy Entropy: 1.80256
Value Function Loss: 0.13284

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07355
Policy Update Magnitude: 0.24868
Value Function Update Magnitude: 0.54009

Collected Steps per Second: 21,511.21928
Overall Steps per Second: 10,232.59879

Timestep Collection Time: 2.32502
Timestep Consumption Time: 2.56269
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.88771

Cumulative Model Updates: 7,746
Cumulative Timesteps: 64,724,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 64724034...
Checkpoint 64724034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,328.63075
Policy Entropy: 1.79636
Value Function Loss: 0.13115

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.27175
Value Function Update Magnitude: 0.68368

Collected Steps per Second: 21,010.10474
Overall Steps per Second: 10,229.15972

Timestep Collection Time: 2.38066
Timestep Consumption Time: 2.50908
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.88975

Cumulative Model Updates: 7,752
Cumulative Timesteps: 64,774,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,214.23931
Policy Entropy: 1.78517
Value Function Loss: 0.12854

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.13892
Policy Update Magnitude: 0.24232
Value Function Update Magnitude: 0.73780

Collected Steps per Second: 21,340.12085
Overall Steps per Second: 10,301.18909

Timestep Collection Time: 2.34375
Timestep Consumption Time: 2.51161
PPO Batch Consumption Time: 0.29938
Total Iteration Time: 4.85536

Cumulative Model Updates: 7,758
Cumulative Timesteps: 64,824,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 64824068...
Checkpoint 64824068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,619.86836
Policy Entropy: 1.78224
Value Function Loss: 0.12668

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.24004
Value Function Update Magnitude: 0.69730

Collected Steps per Second: 21,048.25973
Overall Steps per Second: 9,884.46755

Timestep Collection Time: 2.37597
Timestep Consumption Time: 2.68348
PPO Batch Consumption Time: 0.32332
Total Iteration Time: 5.05945

Cumulative Model Updates: 7,764
Cumulative Timesteps: 64,874,078

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,116.55081
Policy Entropy: 1.77819
Value Function Loss: 0.13161

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.24373
Value Function Update Magnitude: 0.69219

Collected Steps per Second: 18,558.06106
Overall Steps per Second: 9,485.13349

Timestep Collection Time: 2.69597
Timestep Consumption Time: 2.57881
PPO Batch Consumption Time: 0.30404
Total Iteration Time: 5.27478

Cumulative Model Updates: 7,770
Cumulative Timesteps: 64,924,110

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 64924110...
Checkpoint 64924110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,895.11454
Policy Entropy: 1.78283
Value Function Loss: 0.13688

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12226
Policy Update Magnitude: 0.25981
Value Function Update Magnitude: 0.67631

Collected Steps per Second: 20,934.79807
Overall Steps per Second: 10,365.30769

Timestep Collection Time: 2.38971
Timestep Consumption Time: 2.43678
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.82648

Cumulative Model Updates: 7,776
Cumulative Timesteps: 64,974,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051.81200
Policy Entropy: 1.77735
Value Function Loss: 0.13620

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.25279
Value Function Update Magnitude: 0.66064

Collected Steps per Second: 21,529.77636
Overall Steps per Second: 10,224.40312

Timestep Collection Time: 2.32311
Timestep Consumption Time: 2.56872
PPO Batch Consumption Time: 0.30298
Total Iteration Time: 4.89183

Cumulative Model Updates: 7,782
Cumulative Timesteps: 65,024,154

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 65024154...
Checkpoint 65024154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,951.92004
Policy Entropy: 1.77646
Value Function Loss: 0.13254

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.28533
Value Function Update Magnitude: 0.62035

Collected Steps per Second: 20,775.09301
Overall Steps per Second: 10,174.30803

Timestep Collection Time: 2.40827
Timestep Consumption Time: 2.50922
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.91748

Cumulative Model Updates: 7,788
Cumulative Timesteps: 65,074,186

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,925.00800
Policy Entropy: 1.75274
Value Function Loss: 0.13167

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.30614
Value Function Update Magnitude: 0.52416

Collected Steps per Second: 21,099.79374
Overall Steps per Second: 10,118.04910

Timestep Collection Time: 2.37054
Timestep Consumption Time: 2.57290
PPO Batch Consumption Time: 0.30602
Total Iteration Time: 4.94344

Cumulative Model Updates: 7,794
Cumulative Timesteps: 65,124,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 65124204...
Checkpoint 65124204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,902.71828
Policy Entropy: 1.75781
Value Function Loss: 0.13670

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.28768
Value Function Update Magnitude: 0.46365

Collected Steps per Second: 21,033.73444
Overall Steps per Second: 10,311.06382

Timestep Collection Time: 2.37875
Timestep Consumption Time: 2.47371
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 4.85246

Cumulative Model Updates: 7,800
Cumulative Timesteps: 65,174,238

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.83608
Policy Entropy: 1.75659
Value Function Loss: 0.14027

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10139
Policy Update Magnitude: 0.32899
Value Function Update Magnitude: 0.42708

Collected Steps per Second: 21,028.42045
Overall Steps per Second: 10,421.67478

Timestep Collection Time: 2.37811
Timestep Consumption Time: 2.42035
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.79846

Cumulative Model Updates: 7,806
Cumulative Timesteps: 65,224,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 65224246...
Checkpoint 65224246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,707.36673
Policy Entropy: 1.75847
Value Function Loss: 0.13593

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.33901
Value Function Update Magnitude: 0.43664

Collected Steps per Second: 20,667.23996
Overall Steps per Second: 10,108.88071

Timestep Collection Time: 2.42074
Timestep Consumption Time: 2.52837
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.94911

Cumulative Model Updates: 7,812
Cumulative Timesteps: 65,274,276

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,755.73617
Policy Entropy: 1.75714
Value Function Loss: 0.13237

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.31774
Value Function Update Magnitude: 0.44630

Collected Steps per Second: 21,422.89642
Overall Steps per Second: 10,343.55766

Timestep Collection Time: 2.33404
Timestep Consumption Time: 2.50008
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.83412

Cumulative Model Updates: 7,818
Cumulative Timesteps: 65,324,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 65324278...
Checkpoint 65324278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,407.23946
Policy Entropy: 1.75243
Value Function Loss: 0.13239

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.30252
Value Function Update Magnitude: 0.41902

Collected Steps per Second: 21,270.38866
Overall Steps per Second: 10,498.27194

Timestep Collection Time: 2.35078
Timestep Consumption Time: 2.41210
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.76288

Cumulative Model Updates: 7,824
Cumulative Timesteps: 65,374,280

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,752.11378
Policy Entropy: 1.75453
Value Function Loss: 0.13606

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10826
Policy Update Magnitude: 0.29155
Value Function Update Magnitude: 0.42027

Collected Steps per Second: 21,316.51415
Overall Steps per Second: 10,512.93063

Timestep Collection Time: 2.34729
Timestep Consumption Time: 2.41218
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.75947

Cumulative Model Updates: 7,830
Cumulative Timesteps: 65,424,316

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 65424316...
Checkpoint 65424316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,740.53909
Policy Entropy: 1.75704
Value Function Loss: 0.13411

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.30819
Value Function Update Magnitude: 0.50132

Collected Steps per Second: 20,922.50321
Overall Steps per Second: 10,106.53807

Timestep Collection Time: 2.39092
Timestep Consumption Time: 2.55875
PPO Batch Consumption Time: 0.30237
Total Iteration Time: 4.94967

Cumulative Model Updates: 7,836
Cumulative Timesteps: 65,474,340

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,686.73344
Policy Entropy: 1.75628
Value Function Loss: 0.13311

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07474
Policy Update Magnitude: 0.31998
Value Function Update Magnitude: 0.53961

Collected Steps per Second: 21,418.71525
Overall Steps per Second: 10,500.23559

Timestep Collection Time: 2.33581
Timestep Consumption Time: 2.42885
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.76465

Cumulative Model Updates: 7,842
Cumulative Timesteps: 65,524,370

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 65524370...
Checkpoint 65524370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,635.08987
Policy Entropy: 1.75087
Value Function Loss: 0.13381

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08863
Policy Update Magnitude: 0.31183
Value Function Update Magnitude: 0.52842

Collected Steps per Second: 21,135.54830
Overall Steps per Second: 10,447.92885

Timestep Collection Time: 2.36758
Timestep Consumption Time: 2.42189
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.78947

Cumulative Model Updates: 7,848
Cumulative Timesteps: 65,574,410

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,903.47669
Policy Entropy: 1.75250
Value Function Loss: 0.13194

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08422
Policy Update Magnitude: 0.32429
Value Function Update Magnitude: 0.49996

Collected Steps per Second: 21,259.49777
Overall Steps per Second: 10,322.27610

Timestep Collection Time: 2.35340
Timestep Consumption Time: 2.49360
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.84699

Cumulative Model Updates: 7,854
Cumulative Timesteps: 65,624,442

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 65624442...
Checkpoint 65624442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,110.34939
Policy Entropy: 1.74999
Value Function Loss: 0.13423

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.30728
Value Function Update Magnitude: 0.47709

Collected Steps per Second: 20,873.48622
Overall Steps per Second: 10,135.58441

Timestep Collection Time: 2.39672
Timestep Consumption Time: 2.53915
PPO Batch Consumption Time: 0.30090
Total Iteration Time: 4.93588

Cumulative Model Updates: 7,860
Cumulative Timesteps: 65,674,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,960.17374
Policy Entropy: 1.75135
Value Function Loss: 0.13152

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.28883
Value Function Update Magnitude: 0.53574

Collected Steps per Second: 21,800.75985
Overall Steps per Second: 10,605.18019

Timestep Collection Time: 2.29478
Timestep Consumption Time: 2.42253
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.71732

Cumulative Model Updates: 7,866
Cumulative Timesteps: 65,724,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 65724498...
Checkpoint 65724498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,134.26523
Policy Entropy: 1.75575
Value Function Loss: 0.13151

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.29424
Value Function Update Magnitude: 0.47877

Collected Steps per Second: 20,733.73323
Overall Steps per Second: 10,081.75924

Timestep Collection Time: 2.41240
Timestep Consumption Time: 2.54884
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 4.96124

Cumulative Model Updates: 7,872
Cumulative Timesteps: 65,774,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.59003
Policy Entropy: 1.75425
Value Function Loss: 0.12933

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.32353
Value Function Update Magnitude: 0.44886

Collected Steps per Second: 21,297.13864
Overall Steps per Second: 10,240.38765

Timestep Collection Time: 2.34848
Timestep Consumption Time: 2.53571
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.88419

Cumulative Model Updates: 7,878
Cumulative Timesteps: 65,824,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 65824532...
Checkpoint 65824532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,036.58116
Policy Entropy: 1.74051
Value Function Loss: 0.13135

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07889
Policy Update Magnitude: 0.32687
Value Function Update Magnitude: 0.42443

Collected Steps per Second: 21,424.76164
Overall Steps per Second: 10,237.68849

Timestep Collection Time: 2.33496
Timestep Consumption Time: 2.55149
PPO Batch Consumption Time: 0.30095
Total Iteration Time: 4.88645

Cumulative Model Updates: 7,884
Cumulative Timesteps: 65,874,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,924.41055
Policy Entropy: 1.73425
Value Function Loss: 0.12942

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.32439
Value Function Update Magnitude: 0.47962

Collected Steps per Second: 21,675.70688
Overall Steps per Second: 10,506.23849

Timestep Collection Time: 2.30747
Timestep Consumption Time: 2.45313
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.76060

Cumulative Model Updates: 7,890
Cumulative Timesteps: 65,924,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 65924574...
Checkpoint 65924574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,942.34015
Policy Entropy: 1.73979
Value Function Loss: 0.13119

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.15224
Policy Update Magnitude: 0.27577
Value Function Update Magnitude: 0.44433

Collected Steps per Second: 19,734.58008
Overall Steps per Second: 9,740.05294

Timestep Collection Time: 2.53383
Timestep Consumption Time: 2.60003
PPO Batch Consumption Time: 0.30085
Total Iteration Time: 5.13385

Cumulative Model Updates: 7,896
Cumulative Timesteps: 65,974,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,943.01489
Policy Entropy: 1.73393
Value Function Loss: 0.13113

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.25161
Value Function Update Magnitude: 0.44540

Collected Steps per Second: 21,345.54509
Overall Steps per Second: 10,395.82136

Timestep Collection Time: 2.34353
Timestep Consumption Time: 2.46840
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.81193

Cumulative Model Updates: 7,902
Cumulative Timesteps: 66,024,602

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 66024602...
Checkpoint 66024602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,778.50307
Policy Entropy: 1.73669
Value Function Loss: 0.13018

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12144
Policy Update Magnitude: 0.23582
Value Function Update Magnitude: 0.51425

Collected Steps per Second: 21,027.62720
Overall Steps per Second: 10,237.04933

Timestep Collection Time: 2.37811
Timestep Consumption Time: 2.50670
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.88481

Cumulative Model Updates: 7,908
Cumulative Timesteps: 66,074,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,371.06988
Policy Entropy: 1.74915
Value Function Loss: 0.12407

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.24759
Value Function Update Magnitude: 0.55041

Collected Steps per Second: 21,593.21945
Overall Steps per Second: 10,394.19660

Timestep Collection Time: 2.31684
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.81307

Cumulative Model Updates: 7,914
Cumulative Timesteps: 66,124,636

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 66124636...
Checkpoint 66124636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,492.11400
Policy Entropy: 1.75122
Value Function Loss: 0.12898

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12468
Policy Update Magnitude: 0.25835
Value Function Update Magnitude: 0.47329

Collected Steps per Second: 21,065.75125
Overall Steps per Second: 10,242.92522

Timestep Collection Time: 2.37362
Timestep Consumption Time: 2.50800
PPO Batch Consumption Time: 0.30165
Total Iteration Time: 4.88161

Cumulative Model Updates: 7,920
Cumulative Timesteps: 66,174,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377.56922
Policy Entropy: 1.76419
Value Function Loss: 0.12877

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.25516
Value Function Update Magnitude: 0.41114

Collected Steps per Second: 21,435.40657
Overall Steps per Second: 10,103.42084

Timestep Collection Time: 2.33259
Timestep Consumption Time: 2.61623
PPO Batch Consumption Time: 0.31179
Total Iteration Time: 4.94882

Cumulative Model Updates: 7,926
Cumulative Timesteps: 66,224,638

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 66224638...
Checkpoint 66224638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,445.23302
Policy Entropy: 1.74836
Value Function Loss: 0.12783

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.25818
Value Function Update Magnitude: 0.44758

Collected Steps per Second: 18,558.54682
Overall Steps per Second: 9,449.05643

Timestep Collection Time: 2.69569
Timestep Consumption Time: 2.59881
PPO Batch Consumption Time: 0.31788
Total Iteration Time: 5.29450

Cumulative Model Updates: 7,932
Cumulative Timesteps: 66,274,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,986.44121
Policy Entropy: 1.75581
Value Function Loss: 0.12498

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10266
Policy Update Magnitude: 0.27885
Value Function Update Magnitude: 0.46973

Collected Steps per Second: 20,393.50633
Overall Steps per Second: 10,063.94658

Timestep Collection Time: 2.45186
Timestep Consumption Time: 2.51657
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.96843

Cumulative Model Updates: 7,938
Cumulative Timesteps: 66,324,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 66324668...
Checkpoint 66324668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,169.59132
Policy Entropy: 1.74204
Value Function Loss: 0.13417

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.28752
Value Function Update Magnitude: 0.37751

Collected Steps per Second: 20,945.34098
Overall Steps per Second: 10,007.80328

Timestep Collection Time: 2.38803
Timestep Consumption Time: 2.60987
PPO Batch Consumption Time: 0.30421
Total Iteration Time: 4.99790

Cumulative Model Updates: 7,944
Cumulative Timesteps: 66,374,686

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,455.33672
Policy Entropy: 1.74618
Value Function Loss: 0.12878

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.26400
Value Function Update Magnitude: 0.33586

Collected Steps per Second: 21,489.93596
Overall Steps per Second: 10,236.43496

Timestep Collection Time: 2.32779
Timestep Consumption Time: 2.55907
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.88686

Cumulative Model Updates: 7,950
Cumulative Timesteps: 66,424,710

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 66424710...
Checkpoint 66424710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,249.33385
Policy Entropy: 1.74552
Value Function Loss: 0.12891

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.24924
Value Function Update Magnitude: 0.40997

Collected Steps per Second: 20,988.76136
Overall Steps per Second: 10,158.17221

Timestep Collection Time: 2.38385
Timestep Consumption Time: 2.54165
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.92549

Cumulative Model Updates: 7,956
Cumulative Timesteps: 66,474,744

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,044.97691
Policy Entropy: 1.73143
Value Function Loss: 0.12511

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.14054
Policy Update Magnitude: 0.25862
Value Function Update Magnitude: 0.45070

Collected Steps per Second: 21,607.11913
Overall Steps per Second: 10,307.64865

Timestep Collection Time: 2.31461
Timestep Consumption Time: 2.53732
PPO Batch Consumption Time: 0.29970
Total Iteration Time: 4.85193

Cumulative Model Updates: 7,962
Cumulative Timesteps: 66,524,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 66524756...
Checkpoint 66524756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,540.42087
Policy Entropy: 1.72599
Value Function Loss: 0.13362

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.15364
Policy Update Magnitude: 0.26632
Value Function Update Magnitude: 0.42760

Collected Steps per Second: 21,206.22929
Overall Steps per Second: 10,454.85170

Timestep Collection Time: 2.35808
Timestep Consumption Time: 2.42496
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.78304

Cumulative Model Updates: 7,968
Cumulative Timesteps: 66,574,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,594.29442
Policy Entropy: 1.72288
Value Function Loss: 0.13349

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13629
Policy Update Magnitude: 0.29518
Value Function Update Magnitude: 0.47092

Collected Steps per Second: 21,060.42726
Overall Steps per Second: 10,124.04926

Timestep Collection Time: 2.37460
Timestep Consumption Time: 2.56513
PPO Batch Consumption Time: 0.30259
Total Iteration Time: 4.93972

Cumulative Model Updates: 7,974
Cumulative Timesteps: 66,624,772

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 66624772...
Checkpoint 66624772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,514.55087
Policy Entropy: 1.72039
Value Function Loss: 0.14004

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.12114
Policy Update Magnitude: 0.31431
Value Function Update Magnitude: 0.43245

Collected Steps per Second: 21,022.11769
Overall Steps per Second: 10,004.60791

Timestep Collection Time: 2.37959
Timestep Consumption Time: 2.62051
PPO Batch Consumption Time: 0.31113
Total Iteration Time: 5.00010

Cumulative Model Updates: 7,980
Cumulative Timesteps: 66,674,796

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.83634
Policy Entropy: 1.72242
Value Function Loss: 0.14220

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.31010
Value Function Update Magnitude: 0.43594

Collected Steps per Second: 21,690.29991
Overall Steps per Second: 10,569.63505

Timestep Collection Time: 2.30647
Timestep Consumption Time: 2.42671
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.73318

Cumulative Model Updates: 7,986
Cumulative Timesteps: 66,724,824

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 66724824...
Checkpoint 66724824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,252.84588
Policy Entropy: 1.72530
Value Function Loss: 0.14551

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10983
Policy Update Magnitude: 0.30329
Value Function Update Magnitude: 0.43118

Collected Steps per Second: 20,638.07592
Overall Steps per Second: 10,261.96535

Timestep Collection Time: 2.42309
Timestep Consumption Time: 2.45005
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.87314

Cumulative Model Updates: 7,992
Cumulative Timesteps: 66,774,832

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,077.39334
Policy Entropy: 1.73429
Value Function Loss: 0.14785

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.32019
Value Function Update Magnitude: 0.40881

Collected Steps per Second: 19,494.98726
Overall Steps per Second: 9,683.66395

Timestep Collection Time: 2.56661
Timestep Consumption Time: 2.60044
PPO Batch Consumption Time: 0.30263
Total Iteration Time: 5.16705

Cumulative Model Updates: 7,998
Cumulative Timesteps: 66,824,868

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 66824868...
Checkpoint 66824868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.17335
Policy Entropy: 1.72535
Value Function Loss: 0.14566

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.32263
Value Function Update Magnitude: 0.42319

Collected Steps per Second: 21,184.14366
Overall Steps per Second: 10,140.53788

Timestep Collection Time: 2.36120
Timestep Consumption Time: 2.57148
PPO Batch Consumption Time: 0.30599
Total Iteration Time: 4.93268

Cumulative Model Updates: 8,004
Cumulative Timesteps: 66,874,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,048.60546
Policy Entropy: 1.70190
Value Function Loss: 0.14386

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07206
Policy Update Magnitude: 0.32533
Value Function Update Magnitude: 0.45725

Collected Steps per Second: 19,810.06884
Overall Steps per Second: 9,914.63702

Timestep Collection Time: 2.52548
Timestep Consumption Time: 2.52059
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 5.04607

Cumulative Model Updates: 8,010
Cumulative Timesteps: 66,924,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 66924918...
Checkpoint 66924918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,422.85569
Policy Entropy: 1.69640
Value Function Loss: 0.14090

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.32114
Value Function Update Magnitude: 0.43669

Collected Steps per Second: 20,909.05160
Overall Steps per Second: 10,214.38045

Timestep Collection Time: 2.39160
Timestep Consumption Time: 2.50405
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.89565

Cumulative Model Updates: 8,016
Cumulative Timesteps: 66,974,924

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,570.07596
Policy Entropy: 1.69965
Value Function Loss: 0.14380

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.30804
Value Function Update Magnitude: 0.42713

Collected Steps per Second: 21,593.75823
Overall Steps per Second: 10,395.16684

Timestep Collection Time: 2.31585
Timestep Consumption Time: 2.49484
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.81070

Cumulative Model Updates: 8,022
Cumulative Timesteps: 67,024,932

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 67024932...
Checkpoint 67024932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,934.07557
Policy Entropy: 1.69129
Value Function Loss: 0.14109

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.30348
Value Function Update Magnitude: 0.44126

Collected Steps per Second: 20,747.68816
Overall Steps per Second: 10,239.36113

Timestep Collection Time: 2.41126
Timestep Consumption Time: 2.47460
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.88585

Cumulative Model Updates: 8,028
Cumulative Timesteps: 67,074,960

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,590.24781
Policy Entropy: 1.69040
Value Function Loss: 0.14010

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08780
Policy Update Magnitude: 0.29836
Value Function Update Magnitude: 0.47329

Collected Steps per Second: 19,051.64598
Overall Steps per Second: 9,610.01162

Timestep Collection Time: 2.62612
Timestep Consumption Time: 2.58011
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 5.20624

Cumulative Model Updates: 8,034
Cumulative Timesteps: 67,124,992

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 67124992...
Checkpoint 67124992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,295.20012
Policy Entropy: 1.70710
Value Function Loss: 0.13410

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07981
Policy Update Magnitude: 0.31448
Value Function Update Magnitude: 0.45657

Collected Steps per Second: 16,880.28275
Overall Steps per Second: 8,951.71882

Timestep Collection Time: 2.96263
Timestep Consumption Time: 2.62401
PPO Batch Consumption Time: 0.30581
Total Iteration Time: 5.58664

Cumulative Model Updates: 8,040
Cumulative Timesteps: 67,175,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,924.66808
Policy Entropy: 1.71951
Value Function Loss: 0.13476

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08225
Policy Update Magnitude: 0.32108
Value Function Update Magnitude: 0.47933

Collected Steps per Second: 21,043.90240
Overall Steps per Second: 10,031.83874

Timestep Collection Time: 2.37751
Timestep Consumption Time: 2.60982
PPO Batch Consumption Time: 0.31063
Total Iteration Time: 4.98732

Cumulative Model Updates: 8,046
Cumulative Timesteps: 67,225,034

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 67225034...
Checkpoint 67225034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,207.36524
Policy Entropy: 1.71489
Value Function Loss: 0.13221

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.14437
Policy Update Magnitude: 0.28517
Value Function Update Magnitude: 0.50284

Collected Steps per Second: 18,012.96436
Overall Steps per Second: 9,027.83910

Timestep Collection Time: 2.77633
Timestep Consumption Time: 2.76320
PPO Batch Consumption Time: 0.32626
Total Iteration Time: 5.53953

Cumulative Model Updates: 8,052
Cumulative Timesteps: 67,275,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.44660
Policy Entropy: 1.70229
Value Function Loss: 0.14308

Mean KL Divergence: 0.03261
SB3 Clip Fraction: 0.22583
Policy Update Magnitude: 0.22699
Value Function Update Magnitude: 0.54009

Collected Steps per Second: 17,841.35890
Overall Steps per Second: 9,364.00246

Timestep Collection Time: 2.80427
Timestep Consumption Time: 2.53874
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 5.34301

Cumulative Model Updates: 8,058
Cumulative Timesteps: 67,325,076

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 67325076...
Checkpoint 67325076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.13786
Policy Entropy: 1.72086
Value Function Loss: 0.14006

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.17737
Policy Update Magnitude: 0.24339
Value Function Update Magnitude: 0.52345

Collected Steps per Second: 20,289.73146
Overall Steps per Second: 9,973.53031

Timestep Collection Time: 2.46440
Timestep Consumption Time: 2.54907
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 5.01347

Cumulative Model Updates: 8,064
Cumulative Timesteps: 67,375,078

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,827.92665
Policy Entropy: 1.70906
Value Function Loss: 0.14254

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.14615
Policy Update Magnitude: 0.23896
Value Function Update Magnitude: 0.51220

Collected Steps per Second: 21,682.32036
Overall Steps per Second: 10,171.00226

Timestep Collection Time: 2.30658
Timestep Consumption Time: 2.61054
PPO Batch Consumption Time: 0.30277
Total Iteration Time: 4.91712

Cumulative Model Updates: 8,070
Cumulative Timesteps: 67,425,090

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 67425090...
Checkpoint 67425090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.53321
Policy Entropy: 1.71361
Value Function Loss: 0.14368

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.22827
Value Function Update Magnitude: 0.47407

Collected Steps per Second: 18,975.86493
Overall Steps per Second: 9,676.07124

Timestep Collection Time: 2.63514
Timestep Consumption Time: 2.53266
PPO Batch Consumption Time: 0.30289
Total Iteration Time: 5.16780

Cumulative Model Updates: 8,076
Cumulative Timesteps: 67,475,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,570.51022
Policy Entropy: 1.68301
Value Function Loss: 0.14781

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.14272
Policy Update Magnitude: 0.24659
Value Function Update Magnitude: 0.46277

Collected Steps per Second: 22,553.11464
Overall Steps per Second: 10,394.52746

Timestep Collection Time: 2.21823
Timestep Consumption Time: 2.59469
PPO Batch Consumption Time: 0.31143
Total Iteration Time: 4.81292

Cumulative Model Updates: 8,082
Cumulative Timesteps: 67,525,122

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 67525122...
Checkpoint 67525122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,906.12973
Policy Entropy: 1.67257
Value Function Loss: 0.14963

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.14346
Policy Update Magnitude: 0.23955
Value Function Update Magnitude: 0.54885

Collected Steps per Second: 21,528.70319
Overall Steps per Second: 10,311.30315

Timestep Collection Time: 2.32350
Timestep Consumption Time: 2.52768
PPO Batch Consumption Time: 0.30104
Total Iteration Time: 4.85118

Cumulative Model Updates: 8,088
Cumulative Timesteps: 67,575,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,900.54628
Policy Entropy: 1.66569
Value Function Loss: 0.13936

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.24436
Value Function Update Magnitude: 0.62701

Collected Steps per Second: 22,671.34340
Overall Steps per Second: 10,606.86024

Timestep Collection Time: 2.20587
Timestep Consumption Time: 2.50900
PPO Batch Consumption Time: 0.29691
Total Iteration Time: 4.71487

Cumulative Model Updates: 8,094
Cumulative Timesteps: 67,625,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 67625154...
Checkpoint 67625154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,414.32369
Policy Entropy: 1.66811
Value Function Loss: 0.13277

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11931
Policy Update Magnitude: 0.23291
Value Function Update Magnitude: 0.66797

Collected Steps per Second: 20,081.93110
Overall Steps per Second: 10,081.90845

Timestep Collection Time: 2.49100
Timestep Consumption Time: 2.47076
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.96176

Cumulative Model Updates: 8,100
Cumulative Timesteps: 67,675,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,989.43415
Policy Entropy: 1.68161
Value Function Loss: 0.12826

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.13133
Policy Update Magnitude: 0.21186
Value Function Update Magnitude: 0.67453

Collected Steps per Second: 22,374.66344
Overall Steps per Second: 10,552.88619

Timestep Collection Time: 2.23592
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.74069

Cumulative Model Updates: 8,106
Cumulative Timesteps: 67,725,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 67725206...
Checkpoint 67725206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,916.46164
Policy Entropy: 1.68419
Value Function Loss: 0.12550

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.21245
Value Function Update Magnitude: 0.67608

Collected Steps per Second: 22,486.29861
Overall Steps per Second: 10,582.59171

Timestep Collection Time: 2.22384
Timestep Consumption Time: 2.50146
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.72531

Cumulative Model Updates: 8,112
Cumulative Timesteps: 67,775,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,155.60662
Policy Entropy: 1.69265
Value Function Loss: 0.12557

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.21171
Value Function Update Magnitude: 0.65734

Collected Steps per Second: 22,787.03731
Overall Steps per Second: 10,805.97106

Timestep Collection Time: 2.19441
Timestep Consumption Time: 2.43304
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.62744

Cumulative Model Updates: 8,118
Cumulative Timesteps: 67,825,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 67825216...
Checkpoint 67825216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,584.49022
Policy Entropy: 1.68908
Value Function Loss: 0.12670

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.21182
Value Function Update Magnitude: 0.65033

Collected Steps per Second: 22,025.72437
Overall Steps per Second: 10,648.23063

Timestep Collection Time: 2.27007
Timestep Consumption Time: 2.42554
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.69562

Cumulative Model Updates: 8,124
Cumulative Timesteps: 67,875,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.72112
Policy Entropy: 1.68219
Value Function Loss: 0.13099

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.21800
Value Function Update Magnitude: 0.66890

Collected Steps per Second: 22,380.83343
Overall Steps per Second: 10,501.38728

Timestep Collection Time: 2.23459
Timestep Consumption Time: 2.52783
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.76242

Cumulative Model Updates: 8,130
Cumulative Timesteps: 67,925,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 67925228...
Checkpoint 67925228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,708.10084
Policy Entropy: 1.67827
Value Function Loss: 0.13446

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.23505
Value Function Update Magnitude: 0.65294

Collected Steps per Second: 22,508.30974
Overall Steps per Second: 10,579.78047

Timestep Collection Time: 2.22345
Timestep Consumption Time: 2.50690
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.73034

Cumulative Model Updates: 8,136
Cumulative Timesteps: 67,975,274

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.02945
Policy Entropy: 1.67746
Value Function Loss: 0.13829

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.25123
Value Function Update Magnitude: 0.58573

Collected Steps per Second: 22,447.08099
Overall Steps per Second: 10,594.20941

Timestep Collection Time: 2.22817
Timestep Consumption Time: 2.49290
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.72107

Cumulative Model Updates: 8,142
Cumulative Timesteps: 68,025,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 68025290...
Checkpoint 68025290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,664.27513
Policy Entropy: 1.68075
Value Function Loss: 0.13597

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.24860
Value Function Update Magnitude: 0.49183

Collected Steps per Second: 22,494.07940
Overall Steps per Second: 10,509.27914

Timestep Collection Time: 2.22334
Timestep Consumption Time: 2.53550
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.75884

Cumulative Model Updates: 8,148
Cumulative Timesteps: 68,075,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,814.37019
Policy Entropy: 1.67453
Value Function Loss: 0.13416

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.28201
Value Function Update Magnitude: 0.54974

Collected Steps per Second: 22,455.81680
Overall Steps per Second: 10,585.89085

Timestep Collection Time: 2.22704
Timestep Consumption Time: 2.49717
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.72421

Cumulative Model Updates: 8,154
Cumulative Timesteps: 68,125,312

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 68125312...
Checkpoint 68125312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,126.98015
Policy Entropy: 1.69069
Value Function Loss: 0.13359

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.31115
Value Function Update Magnitude: 0.56724

Collected Steps per Second: 21,884.37230
Overall Steps per Second: 10,425.49149

Timestep Collection Time: 2.28556
Timestep Consumption Time: 2.51211
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.79766

Cumulative Model Updates: 8,160
Cumulative Timesteps: 68,175,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,210.68223
Policy Entropy: 1.69104
Value Function Loss: 0.12887

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07846
Policy Update Magnitude: 0.31594
Value Function Update Magnitude: 0.56528

Collected Steps per Second: 22,234.08554
Overall Steps per Second: 10,551.93386

Timestep Collection Time: 2.24970
Timestep Consumption Time: 2.49066
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.74036

Cumulative Model Updates: 8,166
Cumulative Timesteps: 68,225,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 68225350...
Checkpoint 68225350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,121.50964
Policy Entropy: 1.68064
Value Function Loss: 0.13216

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06818
Policy Update Magnitude: 0.31143
Value Function Update Magnitude: 0.49646

Collected Steps per Second: 21,788.91970
Overall Steps per Second: 10,253.70321

Timestep Collection Time: 2.29594
Timestep Consumption Time: 2.58289
PPO Batch Consumption Time: 0.30802
Total Iteration Time: 4.87882

Cumulative Model Updates: 8,172
Cumulative Timesteps: 68,275,376

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,289.05705
Policy Entropy: 1.66889
Value Function Loss: 0.12462

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06819
Policy Update Magnitude: 0.32498
Value Function Update Magnitude: 0.45923

Collected Steps per Second: 20,593.16652
Overall Steps per Second: 9,951.87737

Timestep Collection Time: 2.42906
Timestep Consumption Time: 2.59733
PPO Batch Consumption Time: 0.29773
Total Iteration Time: 5.02639

Cumulative Model Updates: 8,178
Cumulative Timesteps: 68,325,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 68325398...
Checkpoint 68325398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,972.08199
Policy Entropy: 1.66480
Value Function Loss: 0.13010

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.34082
Value Function Update Magnitude: 0.44314

Collected Steps per Second: 20,218.29140
Overall Steps per Second: 9,926.55792

Timestep Collection Time: 2.47311
Timestep Consumption Time: 2.56409
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 5.03719

Cumulative Model Updates: 8,184
Cumulative Timesteps: 68,375,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,773.11337
Policy Entropy: 1.65983
Value Function Loss: 0.13097

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08044
Policy Update Magnitude: 0.33878
Value Function Update Magnitude: 0.46955

Collected Steps per Second: 21,316.92292
Overall Steps per Second: 10,299.70923

Timestep Collection Time: 2.34687
Timestep Consumption Time: 2.51036
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.85722

Cumulative Model Updates: 8,190
Cumulative Timesteps: 68,425,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 68425428...
Checkpoint 68425428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,090.48909
Policy Entropy: 1.65155
Value Function Loss: 0.13803

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07705
Policy Update Magnitude: 0.33476
Value Function Update Magnitude: 0.48097

Collected Steps per Second: 22,123.44758
Overall Steps per Second: 10,652.82446

Timestep Collection Time: 2.26086
Timestep Consumption Time: 2.43442
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.69528

Cumulative Model Updates: 8,196
Cumulative Timesteps: 68,475,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,812.65689
Policy Entropy: 1.64447
Value Function Loss: 0.13590

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08111
Policy Update Magnitude: 0.33132
Value Function Update Magnitude: 0.48908

Collected Steps per Second: 22,261.89802
Overall Steps per Second: 10,508.47327

Timestep Collection Time: 2.24716
Timestep Consumption Time: 2.51338
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.76054

Cumulative Model Updates: 8,202
Cumulative Timesteps: 68,525,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 68525472...
Checkpoint 68525472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,649.66080
Policy Entropy: 1.64627
Value Function Loss: 0.13276

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.30733
Value Function Update Magnitude: 0.49639

Collected Steps per Second: 21,869.76191
Overall Steps per Second: 10,617.27621

Timestep Collection Time: 2.28745
Timestep Consumption Time: 2.42430
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.71175

Cumulative Model Updates: 8,208
Cumulative Timesteps: 68,575,498

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,077.85468
Policy Entropy: 1.65040
Value Function Loss: 0.12696

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07317
Policy Update Magnitude: 0.31281
Value Function Update Magnitude: 0.46357

Collected Steps per Second: 22,709.35871
Overall Steps per Second: 10,633.38252

Timestep Collection Time: 2.20244
Timestep Consumption Time: 2.50124
PPO Batch Consumption Time: 0.29619
Total Iteration Time: 4.70368

Cumulative Model Updates: 8,214
Cumulative Timesteps: 68,625,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 68625514...
Checkpoint 68625514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,610.99797
Policy Entropy: 1.65146
Value Function Loss: 0.12992

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.31622
Value Function Update Magnitude: 0.46167

Collected Steps per Second: 22,367.28978
Overall Steps per Second: 10,567.96585

Timestep Collection Time: 2.23666
Timestep Consumption Time: 2.49727
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.73393

Cumulative Model Updates: 8,220
Cumulative Timesteps: 68,675,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.34466
Policy Entropy: 1.65098
Value Function Loss: 0.12499

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11716
Policy Update Magnitude: 0.29580
Value Function Update Magnitude: 0.44972

Collected Steps per Second: 22,249.24294
Overall Steps per Second: 10,547.37204

Timestep Collection Time: 2.24799
Timestep Consumption Time: 2.49405
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.74203

Cumulative Model Updates: 8,226
Cumulative Timesteps: 68,725,558

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 68725558...
Checkpoint 68725558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,793.91974
Policy Entropy: 1.65133
Value Function Loss: 0.11829

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.30728
Value Function Update Magnitude: 0.53944

Collected Steps per Second: 21,932.23114
Overall Steps per Second: 10,567.95420

Timestep Collection Time: 2.27993
Timestep Consumption Time: 2.45173
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.73166

Cumulative Model Updates: 8,232
Cumulative Timesteps: 68,775,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,368.49129
Policy Entropy: 1.65686
Value Function Loss: 0.11521

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.29878
Value Function Update Magnitude: 0.61308

Collected Steps per Second: 22,619.29296
Overall Steps per Second: 10,568.80816

Timestep Collection Time: 2.21121
Timestep Consumption Time: 2.52121
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.73242

Cumulative Model Updates: 8,238
Cumulative Timesteps: 68,825,578

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 68825578...
Checkpoint 68825578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,739.57288
Policy Entropy: 1.64333
Value Function Loss: 0.11644

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.28555
Value Function Update Magnitude: 0.64817

Collected Steps per Second: 22,272.29714
Overall Steps per Second: 10,466.13848

Timestep Collection Time: 2.24548
Timestep Consumption Time: 2.53298
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.77846

Cumulative Model Updates: 8,244
Cumulative Timesteps: 68,875,590

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,890.78992
Policy Entropy: 1.63610
Value Function Loss: 0.12397

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.28140
Value Function Update Magnitude: 0.63397

Collected Steps per Second: 22,593.24524
Overall Steps per Second: 10,459.75098

Timestep Collection Time: 2.21376
Timestep Consumption Time: 2.56800
PPO Batch Consumption Time: 0.30672
Total Iteration Time: 4.78176

Cumulative Model Updates: 8,250
Cumulative Timesteps: 68,925,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 68925606...
Checkpoint 68925606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,212.80728
Policy Entropy: 1.62974
Value Function Loss: 0.12439

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.27344
Value Function Update Magnitude: 0.51748

Collected Steps per Second: 22,391.09942
Overall Steps per Second: 10,530.57541

Timestep Collection Time: 2.23410
Timestep Consumption Time: 2.51626
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.75036

Cumulative Model Updates: 8,256
Cumulative Timesteps: 68,975,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,836.69558
Policy Entropy: 1.64473
Value Function Loss: 0.12301

Mean KL Divergence: 0.03067
SB3 Clip Fraction: 0.23663
Policy Update Magnitude: 0.23368
Value Function Update Magnitude: 0.43597

Collected Steps per Second: 22,565.72990
Overall Steps per Second: 10,583.56845

Timestep Collection Time: 2.21637
Timestep Consumption Time: 2.50926
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.72563

Cumulative Model Updates: 8,262
Cumulative Timesteps: 69,025,644

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 69025644...
Checkpoint 69025644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,127.08505
Policy Entropy: 1.63040
Value Function Loss: 0.11894

Mean KL Divergence: 0.02488
SB3 Clip Fraction: 0.20458
Policy Update Magnitude: 0.17445
Value Function Update Magnitude: 0.42915

Collected Steps per Second: 22,296.60965
Overall Steps per Second: 10,645.33558

Timestep Collection Time: 2.24285
Timestep Consumption Time: 2.45479
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.69764

Cumulative Model Updates: 8,268
Cumulative Timesteps: 69,075,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,247.32297
Policy Entropy: 1.63854
Value Function Loss: 0.11385

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.15365
Policy Update Magnitude: 0.16748
Value Function Update Magnitude: 0.40370

Collected Steps per Second: 22,336.47512
Overall Steps per Second: 10,481.65435

Timestep Collection Time: 2.23992
Timestep Consumption Time: 2.53337
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 4.77329

Cumulative Model Updates: 8,274
Cumulative Timesteps: 69,125,684

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 69125684...
Checkpoint 69125684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,707.45353
Policy Entropy: 1.63106
Value Function Loss: 0.10827

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.18536
Value Function Update Magnitude: 0.49407

Collected Steps per Second: 22,006.91374
Overall Steps per Second: 10,570.23334

Timestep Collection Time: 2.27419
Timestep Consumption Time: 2.46061
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.73481

Cumulative Model Updates: 8,280
Cumulative Timesteps: 69,175,732

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,553.54512
Policy Entropy: 1.63361
Value Function Loss: 0.11365

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11530
Policy Update Magnitude: 0.21518
Value Function Update Magnitude: 0.57044

Collected Steps per Second: 22,367.89765
Overall Steps per Second: 10,508.12055

Timestep Collection Time: 2.23713
Timestep Consumption Time: 2.52490
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.76203

Cumulative Model Updates: 8,286
Cumulative Timesteps: 69,225,772

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 69225772...
Checkpoint 69225772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,097.35793
Policy Entropy: 1.62656
Value Function Loss: 0.11765

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10476
Policy Update Magnitude: 0.25704
Value Function Update Magnitude: 0.58854

Collected Steps per Second: 22,123.46994
Overall Steps per Second: 10,701.85643

Timestep Collection Time: 2.26004
Timestep Consumption Time: 2.41204
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.67209

Cumulative Model Updates: 8,292
Cumulative Timesteps: 69,275,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.17466
Policy Entropy: 1.62955
Value Function Loss: 0.12136

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.27206
Value Function Update Magnitude: 0.60936

Collected Steps per Second: 22,618.29229
Overall Steps per Second: 10,761.86921

Timestep Collection Time: 2.21157
Timestep Consumption Time: 2.43650
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.64808

Cumulative Model Updates: 8,298
Cumulative Timesteps: 69,325,794

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 69325794...
Checkpoint 69325794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.53527
Policy Entropy: 1.63414
Value Function Loss: 0.12364

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.14785
Policy Update Magnitude: 0.26736
Value Function Update Magnitude: 0.58718

Collected Steps per Second: 22,097.37444
Overall Steps per Second: 10,654.08316

Timestep Collection Time: 2.26316
Timestep Consumption Time: 2.43081
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.69398

Cumulative Model Updates: 8,304
Cumulative Timesteps: 69,375,804

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,399.02398
Policy Entropy: 1.63331
Value Function Loss: 0.12476

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.15238
Policy Update Magnitude: 0.21795
Value Function Update Magnitude: 0.49226

Collected Steps per Second: 22,385.28292
Overall Steps per Second: 10,528.01519

Timestep Collection Time: 2.23468
Timestep Consumption Time: 2.51683
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 4.75151

Cumulative Model Updates: 8,310
Cumulative Timesteps: 69,425,828

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 69425828...
Checkpoint 69425828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,247.74480
Policy Entropy: 1.62489
Value Function Loss: 0.12681

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.13967
Policy Update Magnitude: 0.21639
Value Function Update Magnitude: 0.46543

Collected Steps per Second: 22,225.39933
Overall Steps per Second: 10,640.78709

Timestep Collection Time: 2.25013
Timestep Consumption Time: 2.44971
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.69984

Cumulative Model Updates: 8,316
Cumulative Timesteps: 69,475,838

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,274.69118
Policy Entropy: 1.62580
Value Function Loss: 0.12894

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.26889
Value Function Update Magnitude: 0.45426

Collected Steps per Second: 22,418.43594
Overall Steps per Second: 10,493.81468

Timestep Collection Time: 2.23147
Timestep Consumption Time: 2.53572
PPO Batch Consumption Time: 0.29745
Total Iteration Time: 4.76719

Cumulative Model Updates: 8,322
Cumulative Timesteps: 69,525,864

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 69525864...
Checkpoint 69525864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,507.77545
Policy Entropy: 1.62860
Value Function Loss: 0.12964

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.30380
Value Function Update Magnitude: 0.48004

Collected Steps per Second: 22,371.51773
Overall Steps per Second: 10,491.99754

Timestep Collection Time: 2.23597
Timestep Consumption Time: 2.53167
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.76763

Cumulative Model Updates: 8,328
Cumulative Timesteps: 69,575,886

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,192.91316
Policy Entropy: 1.62214
Value Function Loss: 0.13054

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.30530
Value Function Update Magnitude: 0.52918

Collected Steps per Second: 22,420.15946
Overall Steps per Second: 10,392.31682

Timestep Collection Time: 2.23031
Timestep Consumption Time: 2.58132
PPO Batch Consumption Time: 0.30996
Total Iteration Time: 4.81163

Cumulative Model Updates: 8,334
Cumulative Timesteps: 69,625,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 69625890...
Checkpoint 69625890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,937.84384
Policy Entropy: 1.62124
Value Function Loss: 0.12817

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.30375
Value Function Update Magnitude: 0.57748

Collected Steps per Second: 22,205.35684
Overall Steps per Second: 10,488.97584

Timestep Collection Time: 2.25261
Timestep Consumption Time: 2.51621
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.76882

Cumulative Model Updates: 8,340
Cumulative Timesteps: 69,675,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,134.32667
Policy Entropy: 1.62742
Value Function Loss: 0.13693

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11938
Policy Update Magnitude: 0.27823
Value Function Update Magnitude: 0.46923

Collected Steps per Second: 22,527.30980
Overall Steps per Second: 10,724.05197

Timestep Collection Time: 2.22201
Timestep Consumption Time: 2.44562
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.66764

Cumulative Model Updates: 8,346
Cumulative Timesteps: 69,725,966

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 69725966...
Checkpoint 69725966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,564.82020
Policy Entropy: 1.60589
Value Function Loss: 0.14097

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14554
Policy Update Magnitude: 0.25996
Value Function Update Magnitude: 0.46638

Collected Steps per Second: 22,354.45205
Overall Steps per Second: 10,729.31822

Timestep Collection Time: 2.23759
Timestep Consumption Time: 2.42441
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.66199

Cumulative Model Updates: 8,352
Cumulative Timesteps: 69,775,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,776.52661
Policy Entropy: 1.59374
Value Function Loss: 0.14017

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.14983
Policy Update Magnitude: 0.24055
Value Function Update Magnitude: 0.62375

Collected Steps per Second: 22,642.70562
Overall Steps per Second: 10,798.82302

Timestep Collection Time: 2.20954
Timestep Consumption Time: 2.42337
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.63291

Cumulative Model Updates: 8,358
Cumulative Timesteps: 69,826,016

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 69826016...
Checkpoint 69826016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,878.64538
Policy Entropy: 1.59686
Value Function Loss: 0.13866

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.16971
Policy Update Magnitude: 0.22894
Value Function Update Magnitude: 0.54184

Collected Steps per Second: 22,297.42361
Overall Steps per Second: 10,746.78143

Timestep Collection Time: 2.24340
Timestep Consumption Time: 2.41120
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.65460

Cumulative Model Updates: 8,364
Cumulative Timesteps: 69,876,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,799.67039
Policy Entropy: 1.60203
Value Function Loss: 0.13770

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.23593
Value Function Update Magnitude: 0.58147

Collected Steps per Second: 22,654.57046
Overall Steps per Second: 10,792.83595

Timestep Collection Time: 2.20838
Timestep Consumption Time: 2.42710
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.63548

Cumulative Model Updates: 8,370
Cumulative Timesteps: 69,926,068

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 69926068...
Checkpoint 69926068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.01288
Policy Entropy: 1.59531
Value Function Loss: 0.14073

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.28792
Value Function Update Magnitude: 0.49758

Collected Steps per Second: 21,823.44824
Overall Steps per Second: 10,453.69788

Timestep Collection Time: 2.29267
Timestep Consumption Time: 2.49358
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.78625

Cumulative Model Updates: 8,376
Cumulative Timesteps: 69,976,102

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983.79137
Policy Entropy: 1.59752
Value Function Loss: 0.14310

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.28758
Value Function Update Magnitude: 0.45536

Collected Steps per Second: 22,585.63037
Overall Steps per Second: 10,794.65613

Timestep Collection Time: 2.21539
Timestep Consumption Time: 2.41987
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.63526

Cumulative Model Updates: 8,382
Cumulative Timesteps: 70,026,138

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 70026138...
Checkpoint 70026138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,907.37853
Policy Entropy: 1.59447
Value Function Loss: 0.15076

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.16190
Policy Update Magnitude: 0.25382
Value Function Update Magnitude: 0.42059

Collected Steps per Second: 21,979.97434
Overall Steps per Second: 10,639.70418

Timestep Collection Time: 2.27507
Timestep Consumption Time: 2.42487
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.69994

Cumulative Model Updates: 8,388
Cumulative Timesteps: 70,076,144

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,384.54270
Policy Entropy: 1.58703
Value Function Loss: 0.14894

Mean KL Divergence: 0.02620
SB3 Clip Fraction: 0.20301
Policy Update Magnitude: 0.24330
Value Function Update Magnitude: 0.41901

Collected Steps per Second: 22,547.80555
Overall Steps per Second: 10,614.02430

Timestep Collection Time: 2.21813
Timestep Consumption Time: 2.49394
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.71207

Cumulative Model Updates: 8,394
Cumulative Timesteps: 70,126,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 70126158...
Checkpoint 70126158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,077.67858
Policy Entropy: 1.58108
Value Function Loss: 0.14930

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.19443
Policy Update Magnitude: 0.24963
Value Function Update Magnitude: 0.42994

Collected Steps per Second: 21,962.87678
Overall Steps per Second: 10,441.67692

Timestep Collection Time: 2.27730
Timestep Consumption Time: 2.51274
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.79004

Cumulative Model Updates: 8,400
Cumulative Timesteps: 70,176,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,849.89015
Policy Entropy: 1.58513
Value Function Loss: 0.14626

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.16088
Policy Update Magnitude: 0.24848
Value Function Update Magnitude: 0.41781

Collected Steps per Second: 22,610.78348
Overall Steps per Second: 10,658.50551

Timestep Collection Time: 2.21257
Timestep Consumption Time: 2.48114
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.69372

Cumulative Model Updates: 8,406
Cumulative Timesteps: 70,226,202

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 70226202...
Checkpoint 70226202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,544.98450
Policy Entropy: 1.58513
Value Function Loss: 0.14547

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.15387
Policy Update Magnitude: 0.23003
Value Function Update Magnitude: 0.47035

Collected Steps per Second: 21,864.44942
Overall Steps per Second: 10,333.85897

Timestep Collection Time: 2.28764
Timestep Consumption Time: 2.55256
PPO Batch Consumption Time: 0.30241
Total Iteration Time: 4.84021

Cumulative Model Updates: 8,412
Cumulative Timesteps: 70,276,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.24347
Policy Entropy: 1.57486
Value Function Loss: 0.14726

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.25522
Value Function Update Magnitude: 0.50430

Collected Steps per Second: 21,856.58509
Overall Steps per Second: 10,603.87976

Timestep Collection Time: 2.28965
Timestep Consumption Time: 2.42975
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.71940

Cumulative Model Updates: 8,418
Cumulative Timesteps: 70,326,264

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 70326264...
Checkpoint 70326264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,933.30190
Policy Entropy: 1.56615
Value Function Loss: 0.14942

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11514
Policy Update Magnitude: 0.27585
Value Function Update Magnitude: 0.47213

Collected Steps per Second: 22,074.29048
Overall Steps per Second: 10,663.64214

Timestep Collection Time: 2.26608
Timestep Consumption Time: 2.42482
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.69089

Cumulative Model Updates: 8,424
Cumulative Timesteps: 70,376,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,916.59881
Policy Entropy: 1.56478
Value Function Loss: 0.14068

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.26236
Value Function Update Magnitude: 0.52260

Collected Steps per Second: 22,487.68498
Overall Steps per Second: 10,831.87299

Timestep Collection Time: 2.22442
Timestep Consumption Time: 2.39362
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.61804

Cumulative Model Updates: 8,430
Cumulative Timesteps: 70,426,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 70426308...
Checkpoint 70426308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850.97312
Policy Entropy: 1.56492
Value Function Loss: 0.13662

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.14390
Policy Update Magnitude: 0.23642
Value Function Update Magnitude: 0.60264

Collected Steps per Second: 21,407.19615
Overall Steps per Second: 10,605.77743

Timestep Collection Time: 2.33641
Timestep Consumption Time: 2.37951
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.71592

Cumulative Model Updates: 8,436
Cumulative Timesteps: 70,476,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.39305
Policy Entropy: 1.57825
Value Function Loss: 0.13074

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.22131
Value Function Update Magnitude: 0.59617

Collected Steps per Second: 21,990.61793
Overall Steps per Second: 10,545.85135

Timestep Collection Time: 2.27406
Timestep Consumption Time: 2.46790
PPO Batch Consumption Time: 0.29729
Total Iteration Time: 4.74196

Cumulative Model Updates: 8,442
Cumulative Timesteps: 70,526,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 70526332...
Checkpoint 70526332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,407.72930
Policy Entropy: 1.59050
Value Function Loss: 0.13181

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10592
Policy Update Magnitude: 0.22327
Value Function Update Magnitude: 0.62792

Collected Steps per Second: 21,529.28596
Overall Steps per Second: 10,640.59029

Timestep Collection Time: 2.32363
Timestep Consumption Time: 2.37781
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.70143

Cumulative Model Updates: 8,448
Cumulative Timesteps: 70,576,358

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,820.36886
Policy Entropy: 1.58175
Value Function Loss: 0.12873

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07783
Policy Update Magnitude: 0.26858
Value Function Update Magnitude: 0.66781

Collected Steps per Second: 21,832.71643
Overall Steps per Second: 10,547.34967

Timestep Collection Time: 2.29106
Timestep Consumption Time: 2.45137
PPO Batch Consumption Time: 0.29524
Total Iteration Time: 4.74242

Cumulative Model Updates: 8,454
Cumulative Timesteps: 70,626,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 70626378...
Checkpoint 70626378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,489.88673
Policy Entropy: 1.58338
Value Function Loss: 0.12586

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08069
Policy Update Magnitude: 0.29818
Value Function Update Magnitude: 0.67416

Collected Steps per Second: 21,774.54960
Overall Steps per Second: 10,526.30316

Timestep Collection Time: 2.29690
Timestep Consumption Time: 2.45443
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.75134

Cumulative Model Updates: 8,460
Cumulative Timesteps: 70,676,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764.66275
Policy Entropy: 1.56252
Value Function Loss: 0.13113

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08407
Policy Update Magnitude: 0.29605
Value Function Update Magnitude: 0.63622

Collected Steps per Second: 22,031.10532
Overall Steps per Second: 10,625.56399

Timestep Collection Time: 2.27070
Timestep Consumption Time: 2.43738
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.70808

Cumulative Model Updates: 8,466
Cumulative Timesteps: 70,726,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 70726418...
Checkpoint 70726418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465.71969
Policy Entropy: 1.55806
Value Function Loss: 0.13578

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07793
Policy Update Magnitude: 0.29797
Value Function Update Magnitude: 0.56435

Collected Steps per Second: 21,749.58782
Overall Steps per Second: 10,530.24535

Timestep Collection Time: 2.30064
Timestep Consumption Time: 2.45119
PPO Batch Consumption Time: 0.29751
Total Iteration Time: 4.75184

Cumulative Model Updates: 8,472
Cumulative Timesteps: 70,776,456

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,386.83200
Policy Entropy: 1.54312
Value Function Loss: 0.14128

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.29620
Value Function Update Magnitude: 0.46293

Collected Steps per Second: 21,361.64606
Overall Steps per Second: 10,407.62338

Timestep Collection Time: 2.34139
Timestep Consumption Time: 2.46432
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.80571

Cumulative Model Updates: 8,478
Cumulative Timesteps: 70,826,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 70826472...
Checkpoint 70826472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,375.36652
Policy Entropy: 1.54973
Value Function Loss: 0.13653

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.16113
Policy Update Magnitude: 0.23839
Value Function Update Magnitude: 0.48091

Collected Steps per Second: 21,506.66330
Overall Steps per Second: 10,595.14375

Timestep Collection Time: 2.32607
Timestep Consumption Time: 2.39553
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.72160

Cumulative Model Updates: 8,484
Cumulative Timesteps: 70,876,498

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,579.63411
Policy Entropy: 1.54749
Value Function Loss: 0.13673

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13854
Policy Update Magnitude: 0.21266
Value Function Update Magnitude: 0.50050

Collected Steps per Second: 21,561.13574
Overall Steps per Second: 10,502.63807

Timestep Collection Time: 2.31945
Timestep Consumption Time: 2.44221
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.76166

Cumulative Model Updates: 8,490
Cumulative Timesteps: 70,926,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 70926508...
Checkpoint 70926508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,187.50522
Policy Entropy: 1.53988
Value Function Loss: 0.14247

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.21988
Value Function Update Magnitude: 0.49435

Collected Steps per Second: 21,820.50218
Overall Steps per Second: 10,536.51819

Timestep Collection Time: 2.29243
Timestep Consumption Time: 2.45506
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.74749

Cumulative Model Updates: 8,496
Cumulative Timesteps: 70,976,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,504.90550
Policy Entropy: 1.53470
Value Function Loss: 0.14874

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.20325
Value Function Update Magnitude: 0.46822

Collected Steps per Second: 22,498.46842
Overall Steps per Second: 10,562.29965

Timestep Collection Time: 2.22237
Timestep Consumption Time: 2.51144
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.73382

Cumulative Model Updates: 8,502
Cumulative Timesteps: 71,026,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 71026530...
Checkpoint 71026530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,060.60610
Policy Entropy: 1.53058
Value Function Loss: 0.14360

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.20976
Value Function Update Magnitude: 0.48058

Collected Steps per Second: 22,316.14135
Overall Steps per Second: 10,663.27407

Timestep Collection Time: 2.24134
Timestep Consumption Time: 2.44934
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.69068

Cumulative Model Updates: 8,508
Cumulative Timesteps: 71,076,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,386.54501
Policy Entropy: 1.52281
Value Function Loss: 0.13862

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.21055
Value Function Update Magnitude: 0.44189

Collected Steps per Second: 22,580.54613
Overall Steps per Second: 10,581.18563

Timestep Collection Time: 2.21500
Timestep Consumption Time: 2.51188
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.72688

Cumulative Model Updates: 8,514
Cumulative Timesteps: 71,126,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 71126564...
Checkpoint 71126564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,854.41998
Policy Entropy: 1.51178
Value Function Loss: 0.14275

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.21059
Value Function Update Magnitude: 0.42228

Collected Steps per Second: 22,209.06498
Overall Steps per Second: 10,453.79707

Timestep Collection Time: 2.25241
Timestep Consumption Time: 2.53283
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.78525

Cumulative Model Updates: 8,520
Cumulative Timesteps: 71,176,588

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,885.87657
Policy Entropy: 1.53491
Value Function Loss: 0.13972

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.21207
Value Function Update Magnitude: 0.42855

Collected Steps per Second: 22,716.94127
Overall Steps per Second: 10,603.79211

Timestep Collection Time: 2.20135
Timestep Consumption Time: 2.51470
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.71605

Cumulative Model Updates: 8,526
Cumulative Timesteps: 71,226,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 71226596...
Checkpoint 71226596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,049.94775
Policy Entropy: 1.54019
Value Function Loss: 0.14272

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.10236
Policy Update Magnitude: 0.24588
Value Function Update Magnitude: 0.43012

Collected Steps per Second: 21,408.68753
Overall Steps per Second: 10,522.50458

Timestep Collection Time: 2.33559
Timestep Consumption Time: 2.41632
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.75191

Cumulative Model Updates: 8,532
Cumulative Timesteps: 71,276,598

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,802.14644
Policy Entropy: 1.53947
Value Function Loss: 0.13900

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08610
Policy Update Magnitude: 0.29316
Value Function Update Magnitude: 0.42996

Collected Steps per Second: 22,029.38799
Overall Steps per Second: 10,613.49872

Timestep Collection Time: 2.27024
Timestep Consumption Time: 2.44187
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.71211

Cumulative Model Updates: 8,538
Cumulative Timesteps: 71,326,610

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 71326610...
Checkpoint 71326610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,748.33351
Policy Entropy: 1.51921
Value Function Loss: 0.13977

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.26555
Value Function Update Magnitude: 0.42094

Collected Steps per Second: 21,470.24376
Overall Steps per Second: 10,441.08969

Timestep Collection Time: 2.32936
Timestep Consumption Time: 2.46056
PPO Batch Consumption Time: 0.29621
Total Iteration Time: 4.78992

Cumulative Model Updates: 8,544
Cumulative Timesteps: 71,376,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.19117
Policy Entropy: 1.51794
Value Function Loss: 0.13819

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.13469
Policy Update Magnitude: 0.23076
Value Function Update Magnitude: 0.42000

Collected Steps per Second: 21,615.27583
Overall Steps per Second: 10,482.28902

Timestep Collection Time: 2.31420
Timestep Consumption Time: 2.45785
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 4.77205

Cumulative Model Updates: 8,550
Cumulative Timesteps: 71,426,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 71426644...
Checkpoint 71426644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,713.03155
Policy Entropy: 1.52095
Value Function Loss: 0.13577

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.15142
Policy Update Magnitude: 0.21062
Value Function Update Magnitude: 0.42893

Collected Steps per Second: 21,338.83890
Overall Steps per Second: 10,590.74672

Timestep Collection Time: 2.34352
Timestep Consumption Time: 2.37834
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.72186

Cumulative Model Updates: 8,556
Cumulative Timesteps: 71,476,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,378.85091
Policy Entropy: 1.51457
Value Function Loss: 0.13723

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.15782
Policy Update Magnitude: 0.20723
Value Function Update Magnitude: 0.42913

Collected Steps per Second: 22,511.71283
Overall Steps per Second: 10,514.06712

Timestep Collection Time: 2.22169
Timestep Consumption Time: 2.53518
PPO Batch Consumption Time: 0.29745
Total Iteration Time: 4.75687

Cumulative Model Updates: 8,562
Cumulative Timesteps: 71,526,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 71526666...
Checkpoint 71526666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793.15996
Policy Entropy: 1.51169
Value Function Loss: 0.13530

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.21952
Value Function Update Magnitude: 0.47896

Collected Steps per Second: 20,961.04857
Overall Steps per Second: 10,295.35081

Timestep Collection Time: 2.38633
Timestep Consumption Time: 2.47217
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.85850

Cumulative Model Updates: 8,568
Cumulative Timesteps: 71,576,686

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,183.63220
Policy Entropy: 1.50665
Value Function Loss: 0.13450

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.13596
Policy Update Magnitude: 0.22645
Value Function Update Magnitude: 0.45976

Collected Steps per Second: 21,539.39716
Overall Steps per Second: 10,529.37867

Timestep Collection Time: 2.32179
Timestep Consumption Time: 2.42778
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.74957

Cumulative Model Updates: 8,574
Cumulative Timesteps: 71,626,696

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 71626696...
Checkpoint 71626696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,309.62773
Policy Entropy: 1.53010
Value Function Loss: 0.13409

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.24996
Value Function Update Magnitude: 0.44526

Collected Steps per Second: 22,404.25562
Overall Steps per Second: 10,530.74713

Timestep Collection Time: 2.23306
Timestep Consumption Time: 2.51779
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.75085

Cumulative Model Updates: 8,580
Cumulative Timesteps: 71,676,726

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,253.03204
Policy Entropy: 1.51836
Value Function Loss: 0.13779

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11046
Policy Update Magnitude: 0.26885
Value Function Update Magnitude: 0.41788

Collected Steps per Second: 22,863.48489
Overall Steps per Second: 10,785.83401

Timestep Collection Time: 2.18803
Timestep Consumption Time: 2.45009
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.63812

Cumulative Model Updates: 8,586
Cumulative Timesteps: 71,726,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 71726752...
Checkpoint 71726752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,460.47928
Policy Entropy: 1.51831
Value Function Loss: 0.12896

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.24806
Value Function Update Magnitude: 0.55451

Collected Steps per Second: 22,103.65335
Overall Steps per Second: 10,600.45635

Timestep Collection Time: 2.26415
Timestep Consumption Time: 2.45697
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.72112

Cumulative Model Updates: 8,592
Cumulative Timesteps: 71,776,798

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,745.19971
Policy Entropy: 1.51054
Value Function Loss: 0.12614

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.22467
Value Function Update Magnitude: 0.56003

Collected Steps per Second: 22,553.82537
Overall Steps per Second: 10,554.81019

Timestep Collection Time: 2.21701
Timestep Consumption Time: 2.52036
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.73737

Cumulative Model Updates: 8,598
Cumulative Timesteps: 71,826,800

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 71826800...
Checkpoint 71826800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,732.00630
Policy Entropy: 1.52230
Value Function Loss: 0.12115

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.21735
Value Function Update Magnitude: 0.46860

Collected Steps per Second: 22,264.54342
Overall Steps per Second: 10,666.09879

Timestep Collection Time: 2.24689
Timestep Consumption Time: 2.44330
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.69019

Cumulative Model Updates: 8,604
Cumulative Timesteps: 71,876,826

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983.29024
Policy Entropy: 1.51338
Value Function Loss: 0.13129

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.22190
Value Function Update Magnitude: 0.43948

Collected Steps per Second: 21,902.95807
Overall Steps per Second: 10,562.67688

Timestep Collection Time: 2.28371
Timestep Consumption Time: 2.45183
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.73554

Cumulative Model Updates: 8,610
Cumulative Timesteps: 71,926,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 71926846...
Checkpoint 71926846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,987.92674
Policy Entropy: 1.50211
Value Function Loss: 0.13217

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.22635
Value Function Update Magnitude: 0.45467

Collected Steps per Second: 21,438.95998
Overall Steps per Second: 10,482.37824

Timestep Collection Time: 2.33286
Timestep Consumption Time: 2.43839
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.77125

Cumulative Model Updates: 8,616
Cumulative Timesteps: 71,976,860

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,169.17648
Policy Entropy: 1.49479
Value Function Loss: 0.13645

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10368
Policy Update Magnitude: 0.24902
Value Function Update Magnitude: 0.47839

Collected Steps per Second: 22,589.18099
Overall Steps per Second: 10,564.36625

Timestep Collection Time: 2.21416
Timestep Consumption Time: 2.52025
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.73441

Cumulative Model Updates: 8,622
Cumulative Timesteps: 72,026,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 72026876...
Checkpoint 72026876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.00650
Policy Entropy: 1.48399
Value Function Loss: 0.13073

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.27139
Value Function Update Magnitude: 0.52582

Collected Steps per Second: 22,297.70621
Overall Steps per Second: 10,568.50519

Timestep Collection Time: 2.24274
Timestep Consumption Time: 2.48905
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.73180

Cumulative Model Updates: 8,628
Cumulative Timesteps: 72,076,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,645.94147
Policy Entropy: 1.49294
Value Function Loss: 0.12753

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08422
Policy Update Magnitude: 0.28732
Value Function Update Magnitude: 0.61254

Collected Steps per Second: 22,551.46503
Overall Steps per Second: 10,558.11084

Timestep Collection Time: 2.21751
Timestep Consumption Time: 2.51895
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.73645

Cumulative Model Updates: 8,634
Cumulative Timesteps: 72,126,892

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 72126892...
Checkpoint 72126892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,136.21560
Policy Entropy: 1.49319
Value Function Loss: 0.12775

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11312
Policy Update Magnitude: 0.28649
Value Function Update Magnitude: 0.61381

Collected Steps per Second: 21,410.08991
Overall Steps per Second: 10,486.12808

Timestep Collection Time: 2.33600
Timestep Consumption Time: 2.43354
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.76954

Cumulative Model Updates: 8,640
Cumulative Timesteps: 72,176,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,398.23394
Policy Entropy: 1.48494
Value Function Loss: 0.12921

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11744
Policy Update Magnitude: 0.24288
Value Function Update Magnitude: 0.52509

Collected Steps per Second: 21,638.29746
Overall Steps per Second: 10,423.19032

Timestep Collection Time: 2.31155
Timestep Consumption Time: 2.48717
PPO Batch Consumption Time: 0.29605
Total Iteration Time: 4.79872

Cumulative Model Updates: 8,646
Cumulative Timesteps: 72,226,924

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 72226924...
Checkpoint 72226924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,658.74041
Policy Entropy: 1.48529
Value Function Loss: 0.13001

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.24144
Value Function Update Magnitude: 0.46329

Collected Steps per Second: 21,842.28954
Overall Steps per Second: 10,435.08597

Timestep Collection Time: 2.29024
Timestep Consumption Time: 2.50359
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.79383

Cumulative Model Updates: 8,652
Cumulative Timesteps: 72,276,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,535.87396
Policy Entropy: 1.47628
Value Function Loss: 0.12519

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.16489
Policy Update Magnitude: 0.21332
Value Function Update Magnitude: 0.47458

Collected Steps per Second: 22,097.92410
Overall Steps per Second: 10,780.74050

Timestep Collection Time: 2.26302
Timestep Consumption Time: 2.37562
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.63864

Cumulative Model Updates: 8,658
Cumulative Timesteps: 72,326,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 72326956...
Checkpoint 72326956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,020.70692
Policy Entropy: 1.47960
Value Function Loss: 0.12486

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.20875
Value Function Update Magnitude: 0.49251

Collected Steps per Second: 21,215.59723
Overall Steps per Second: 10,546.89990

Timestep Collection Time: 2.35789
Timestep Consumption Time: 2.38512
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.74301

Cumulative Model Updates: 8,664
Cumulative Timesteps: 72,376,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,271.79584
Policy Entropy: 1.46280
Value Function Loss: 0.12908

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.20699
Value Function Update Magnitude: 0.47979

Collected Steps per Second: 21,815.24473
Overall Steps per Second: 10,551.47970

Timestep Collection Time: 2.29243
Timestep Consumption Time: 2.44719
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.73962

Cumulative Model Updates: 8,670
Cumulative Timesteps: 72,426,990

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 72426990...
Checkpoint 72426990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,778.38906
Policy Entropy: 1.46319
Value Function Loss: 0.12991

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08694
Policy Update Magnitude: 0.22262
Value Function Update Magnitude: 0.44763

Collected Steps per Second: 21,727.57456
Overall Steps per Second: 10,612.00004

Timestep Collection Time: 2.30224
Timestep Consumption Time: 2.41148
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.71372

Cumulative Model Updates: 8,676
Cumulative Timesteps: 72,477,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,014.42818
Policy Entropy: 1.45698
Value Function Loss: 0.12768

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08454
Policy Update Magnitude: 0.25417
Value Function Update Magnitude: 0.38548

Collected Steps per Second: 21,890.84278
Overall Steps per Second: 10,565.93689

Timestep Collection Time: 2.28424
Timestep Consumption Time: 2.44832
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.73257

Cumulative Model Updates: 8,682
Cumulative Timesteps: 72,527,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 72527016...
Checkpoint 72527016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,609.75655
Policy Entropy: 1.46424
Value Function Loss: 0.12351

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07996
Policy Update Magnitude: 0.27151
Value Function Update Magnitude: 0.42676

Collected Steps per Second: 21,526.43722
Overall Steps per Second: 10,498.11024

Timestep Collection Time: 2.32496
Timestep Consumption Time: 2.44238
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.76733

Cumulative Model Updates: 8,688
Cumulative Timesteps: 72,577,064

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,847.72162
Policy Entropy: 1.46612
Value Function Loss: 0.12316

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07167
Policy Update Magnitude: 0.27952
Value Function Update Magnitude: 0.61215

Collected Steps per Second: 21,934.92563
Overall Steps per Second: 10,612.90626

Timestep Collection Time: 2.28066
Timestep Consumption Time: 2.43304
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.71369

Cumulative Model Updates: 8,694
Cumulative Timesteps: 72,627,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 72627090...
Checkpoint 72627090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,974.44970
Policy Entropy: 1.45561
Value Function Loss: 0.11878

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07336
Policy Update Magnitude: 0.28625
Value Function Update Magnitude: 0.67335

Collected Steps per Second: 22,413.98231
Overall Steps per Second: 10,506.30118

Timestep Collection Time: 2.23075
Timestep Consumption Time: 2.52830
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.75905

Cumulative Model Updates: 8,700
Cumulative Timesteps: 72,677,090

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,017.90613
Policy Entropy: 1.45239
Value Function Loss: 0.12282

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08197
Policy Update Magnitude: 0.27023
Value Function Update Magnitude: 0.64783

Collected Steps per Second: 22,794.48046
Overall Steps per Second: 10,649.07457

Timestep Collection Time: 2.19465
Timestep Consumption Time: 2.50303
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.69769

Cumulative Model Updates: 8,706
Cumulative Timesteps: 72,727,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 72727116...
Checkpoint 72727116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,647.13528
Policy Entropy: 1.44405
Value Function Loss: 0.12588

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07894
Policy Update Magnitude: 0.27416
Value Function Update Magnitude: 0.61269

Collected Steps per Second: 22,380.63471
Overall Steps per Second: 10,523.83253

Timestep Collection Time: 2.23640
Timestep Consumption Time: 2.51966
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.75606

Cumulative Model Updates: 8,712
Cumulative Timesteps: 72,777,168

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,201.78536
Policy Entropy: 1.44380
Value Function Loss: 0.12985

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.27583
Value Function Update Magnitude: 0.60351

Collected Steps per Second: 22,882.85780
Overall Steps per Second: 10,776.25772

Timestep Collection Time: 2.18688
Timestep Consumption Time: 2.45685
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.64373

Cumulative Model Updates: 8,718
Cumulative Timesteps: 72,827,210

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 72827210...
Checkpoint 72827210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,327.46739
Policy Entropy: 1.44211
Value Function Loss: 0.12791

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09195
Policy Update Magnitude: 0.27969
Value Function Update Magnitude: 0.63563

Collected Steps per Second: 22,179.82009
Overall Steps per Second: 10,465.58197

Timestep Collection Time: 2.25502
Timestep Consumption Time: 2.52407
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 4.77909

Cumulative Model Updates: 8,724
Cumulative Timesteps: 72,877,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,667.27422
Policy Entropy: 1.43528
Value Function Loss: 0.12050

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.17096
Policy Update Magnitude: 0.24458
Value Function Update Magnitude: 0.66744

Collected Steps per Second: 22,875.67455
Overall Steps per Second: 10,694.88459

Timestep Collection Time: 2.18634
Timestep Consumption Time: 2.49010
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.67644

Cumulative Model Updates: 8,730
Cumulative Timesteps: 72,927,240

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 72927240...
Checkpoint 72927240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.14607
Policy Entropy: 1.42998
Value Function Loss: 0.12595

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.17948
Policy Update Magnitude: 0.20474
Value Function Update Magnitude: 0.61120

Collected Steps per Second: 22,530.48297
Overall Steps per Second: 10,605.65722

Timestep Collection Time: 2.21930
Timestep Consumption Time: 2.49535
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.71465

Cumulative Model Updates: 8,736
Cumulative Timesteps: 72,977,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,038.57851
Policy Entropy: 1.40580
Value Function Loss: 0.12921

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.11615
Policy Update Magnitude: 0.22880
Value Function Update Magnitude: 0.48148

Collected Steps per Second: 22,580.08901
Overall Steps per Second: 10,541.08566

Timestep Collection Time: 2.21452
Timestep Consumption Time: 2.52921
PPO Batch Consumption Time: 0.29693
Total Iteration Time: 4.74372

Cumulative Model Updates: 8,742
Cumulative Timesteps: 73,027,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 73027246...
Checkpoint 73027246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,805.47310
Policy Entropy: 1.40452
Value Function Loss: 0.13120

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.12191
Policy Update Magnitude: 0.23391
Value Function Update Magnitude: 0.40310

Collected Steps per Second: 22,455.16674
Overall Steps per Second: 10,580.24877

Timestep Collection Time: 2.22835
Timestep Consumption Time: 2.50103
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.72938

Cumulative Model Updates: 8,748
Cumulative Timesteps: 73,077,284

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.56189
Policy Entropy: 1.39634
Value Function Loss: 0.12563

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09962
Policy Update Magnitude: 0.23039
Value Function Update Magnitude: 0.43319

Collected Steps per Second: 22,748.47534
Overall Steps per Second: 10,627.83872

Timestep Collection Time: 2.19795
Timestep Consumption Time: 2.50668
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.70463

Cumulative Model Updates: 8,754
Cumulative Timesteps: 73,127,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 73127284...
Checkpoint 73127284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,767.50559
Policy Entropy: 1.40591
Value Function Loss: 0.12783

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10716
Policy Update Magnitude: 0.26611
Value Function Update Magnitude: 0.40567

Collected Steps per Second: 22,444.92956
Overall Steps per Second: 10,542.31154

Timestep Collection Time: 2.22865
Timestep Consumption Time: 2.51622
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.74488

Cumulative Model Updates: 8,760
Cumulative Timesteps: 73,177,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,544.66732
Policy Entropy: 1.39775
Value Function Loss: 0.12565

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.15895
Policy Update Magnitude: 0.23263
Value Function Update Magnitude: 0.39791

Collected Steps per Second: 21,892.98214
Overall Steps per Second: 10,739.60839

Timestep Collection Time: 2.28438
Timestep Consumption Time: 2.37240
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.65678

Cumulative Model Updates: 8,766
Cumulative Timesteps: 73,227,318

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 73227318...
Checkpoint 73227318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,563.45630
Policy Entropy: 1.41670
Value Function Loss: 0.11964

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11584
Policy Update Magnitude: 0.22469
Value Function Update Magnitude: 0.48499

Collected Steps per Second: 21,585.43668
Overall Steps per Second: 10,643.12296

Timestep Collection Time: 2.31675
Timestep Consumption Time: 2.38187
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.69862

Cumulative Model Updates: 8,772
Cumulative Timesteps: 73,277,326

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,614.49177
Policy Entropy: 1.42719
Value Function Loss: 0.11402

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.23165
Value Function Update Magnitude: 0.50836

Collected Steps per Second: 21,802.91162
Overall Steps per Second: 10,514.73429

Timestep Collection Time: 2.29419
Timestep Consumption Time: 2.46295
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.75713

Cumulative Model Updates: 8,778
Cumulative Timesteps: 73,327,346

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 73327346...
Checkpoint 73327346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,268.20062
Policy Entropy: 1.42738
Value Function Loss: 0.11921

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.21348
Value Function Update Magnitude: 0.47756

Collected Steps per Second: 21,379.65455
Overall Steps per Second: 10,581.54492

Timestep Collection Time: 2.33942
Timestep Consumption Time: 2.38730
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.72672

Cumulative Model Updates: 8,784
Cumulative Timesteps: 73,377,362

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,376.32232
Policy Entropy: 1.42448
Value Function Loss: 0.11999

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.15082
Policy Update Magnitude: 0.22856
Value Function Update Magnitude: 0.47110

Collected Steps per Second: 21,528.87634
Overall Steps per Second: 10,527.77322

Timestep Collection Time: 2.32432
Timestep Consumption Time: 2.42882
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.75314

Cumulative Model Updates: 8,790
Cumulative Timesteps: 73,427,402

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 73427402...
Checkpoint 73427402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.95486
Policy Entropy: 1.41493
Value Function Loss: 0.12914

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.22242
Value Function Update Magnitude: 0.46272

Collected Steps per Second: 21,222.77069
Overall Steps per Second: 10,574.82222

Timestep Collection Time: 2.35803
Timestep Consumption Time: 2.37434
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.73237

Cumulative Model Updates: 8,796
Cumulative Timesteps: 73,477,446

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,233.71682
Policy Entropy: 1.41880
Value Function Loss: 0.12653

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.15595
Policy Update Magnitude: 0.22096
Value Function Update Magnitude: 0.54456

Collected Steps per Second: 21,732.76811
Overall Steps per Second: 10,398.26325

Timestep Collection Time: 2.30159
Timestep Consumption Time: 2.50883
PPO Batch Consumption Time: 0.30254
Total Iteration Time: 4.81042

Cumulative Model Updates: 8,802
Cumulative Timesteps: 73,527,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 73527466...
Checkpoint 73527466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.47661
Policy Entropy: 1.42974
Value Function Loss: 0.12554

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.24697
Value Function Update Magnitude: 0.59016

Collected Steps per Second: 21,384.63662
Overall Steps per Second: 10,348.97184

Timestep Collection Time: 2.33859
Timestep Consumption Time: 2.49377
PPO Batch Consumption Time: 0.30346
Total Iteration Time: 4.83236

Cumulative Model Updates: 8,808
Cumulative Timesteps: 73,577,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,246.88738
Policy Entropy: 1.44399
Value Function Loss: 0.12328

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14098
Policy Update Magnitude: 0.23639
Value Function Update Magnitude: 0.53739

Collected Steps per Second: 21,946.52168
Overall Steps per Second: 10,615.07207

Timestep Collection Time: 2.27899
Timestep Consumption Time: 2.43280
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.71179

Cumulative Model Updates: 8,814
Cumulative Timesteps: 73,627,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 73627492...
Checkpoint 73627492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,603.97111
Policy Entropy: 1.42200
Value Function Loss: 0.13176

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.15556
Policy Update Magnitude: 0.21311
Value Function Update Magnitude: 0.50440

Collected Steps per Second: 21,901.80642
Overall Steps per Second: 10,606.52167

Timestep Collection Time: 2.28337
Timestep Consumption Time: 2.43165
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.71502

Cumulative Model Updates: 8,820
Cumulative Timesteps: 73,677,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,089.04020
Policy Entropy: 1.41007
Value Function Loss: 0.14182

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.16520
Policy Update Magnitude: 0.19956
Value Function Update Magnitude: 0.48738

Collected Steps per Second: 22,711.76431
Overall Steps per Second: 10,734.64177

Timestep Collection Time: 2.20159
Timestep Consumption Time: 2.45641
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.65800

Cumulative Model Updates: 8,826
Cumulative Timesteps: 73,727,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 73727504...
Checkpoint 73727504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,505.28358
Policy Entropy: 1.41653
Value Function Loss: 0.14527

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.15546
Policy Update Magnitude: 0.22235
Value Function Update Magnitude: 0.45786

Collected Steps per Second: 21,509.47677
Overall Steps per Second: 10,606.02244

Timestep Collection Time: 2.32549
Timestep Consumption Time: 2.39070
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.71619

Cumulative Model Updates: 8,832
Cumulative Timesteps: 73,777,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,280.09958
Policy Entropy: 1.43055
Value Function Loss: 0.14094

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.22697
Value Function Update Magnitude: 0.46797

Collected Steps per Second: 22,084.76898
Overall Steps per Second: 10,494.57247

Timestep Collection Time: 2.26437
Timestep Consumption Time: 2.50076
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.76513

Cumulative Model Updates: 8,838
Cumulative Timesteps: 73,827,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 73827532...
Checkpoint 73827532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426.48570
Policy Entropy: 1.43158
Value Function Loss: 0.13493

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.24673
Value Function Update Magnitude: 0.48312

Collected Steps per Second: 22,304.34470
Overall Steps per Second: 10,667.59025

Timestep Collection Time: 2.24261
Timestep Consumption Time: 2.44636
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.68897

Cumulative Model Updates: 8,844
Cumulative Timesteps: 73,877,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.26996
Policy Entropy: 1.43028
Value Function Loss: 0.13697

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.13967
Policy Update Magnitude: 0.23248
Value Function Update Magnitude: 0.51304

Collected Steps per Second: 22,640.73348
Overall Steps per Second: 10,621.26052

Timestep Collection Time: 2.20982
Timestep Consumption Time: 2.50073
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.71055

Cumulative Model Updates: 8,850
Cumulative Timesteps: 73,927,584

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 73927584...
Checkpoint 73927584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.54552
Policy Entropy: 1.43163
Value Function Loss: 0.14268

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.22026
Value Function Update Magnitude: 0.47268

Collected Steps per Second: 22,285.41320
Overall Steps per Second: 10,462.03784

Timestep Collection Time: 2.24371
Timestep Consumption Time: 2.53566
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.77937

Cumulative Model Updates: 8,856
Cumulative Timesteps: 73,977,586

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,079.56397
Policy Entropy: 1.44755
Value Function Loss: 0.13905

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.22758
Value Function Update Magnitude: 0.45469

Collected Steps per Second: 22,696.63884
Overall Steps per Second: 10,601.73474

Timestep Collection Time: 2.20315
Timestep Consumption Time: 2.51344
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.71659

Cumulative Model Updates: 8,862
Cumulative Timesteps: 74,027,590

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 74027590...
Checkpoint 74027590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,950.47635
Policy Entropy: 1.45192
Value Function Loss: 0.13310

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.24854
Value Function Update Magnitude: 0.44855

Collected Steps per Second: 22,336.22517
Overall Steps per Second: 10,486.30947

Timestep Collection Time: 2.23914
Timestep Consumption Time: 2.53031
PPO Batch Consumption Time: 0.29788
Total Iteration Time: 4.76946

Cumulative Model Updates: 8,868
Cumulative Timesteps: 74,077,604

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.28124
Policy Entropy: 1.46096
Value Function Loss: 0.12704

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.25986
Value Function Update Magnitude: 0.44713

Collected Steps per Second: 22,574.92068
Overall Steps per Second: 10,546.92521

Timestep Collection Time: 2.21494
Timestep Consumption Time: 2.52597
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.74091

Cumulative Model Updates: 8,874
Cumulative Timesteps: 74,127,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 74127606...
Checkpoint 74127606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,466.12657
Policy Entropy: 1.45778
Value Function Loss: 0.13132

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.27251
Value Function Update Magnitude: 0.42901

Collected Steps per Second: 22,501.20153
Overall Steps per Second: 10,524.01649

Timestep Collection Time: 2.22299
Timestep Consumption Time: 2.52995
PPO Batch Consumption Time: 0.29654
Total Iteration Time: 4.75294

Cumulative Model Updates: 8,880
Cumulative Timesteps: 74,177,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,980.76242
Policy Entropy: 1.46396
Value Function Loss: 0.13667

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.26343
Value Function Update Magnitude: 0.44826

Collected Steps per Second: 22,124.30765
Overall Steps per Second: 10,311.06396

Timestep Collection Time: 2.26131
Timestep Consumption Time: 2.59076
PPO Batch Consumption Time: 0.30688
Total Iteration Time: 4.85207

Cumulative Model Updates: 8,886
Cumulative Timesteps: 74,227,656

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 74227656...
Checkpoint 74227656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.00255
Policy Entropy: 1.46426
Value Function Loss: 0.13792

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.26414
Value Function Update Magnitude: 0.45064

Collected Steps per Second: 22,090.17653
Overall Steps per Second: 10,472.21583

Timestep Collection Time: 2.26454
Timestep Consumption Time: 2.51229
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.77683

Cumulative Model Updates: 8,892
Cumulative Timesteps: 74,277,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,848.36873
Policy Entropy: 1.46484
Value Function Loss: 0.13578

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.22588
Value Function Update Magnitude: 0.47722

Collected Steps per Second: 22,740.37108
Overall Steps per Second: 10,757.54092

Timestep Collection Time: 2.19996
Timestep Consumption Time: 2.45054
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.65051

Cumulative Model Updates: 8,898
Cumulative Timesteps: 74,327,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 74327708...
Checkpoint 74327708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,539.07406
Policy Entropy: 1.45590
Value Function Loss: 0.13361

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.21064
Value Function Update Magnitude: 0.45343

Collected Steps per Second: 22,001.87689
Overall Steps per Second: 10,586.86988

Timestep Collection Time: 2.27281
Timestep Consumption Time: 2.45059
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.72340

Cumulative Model Updates: 8,904
Cumulative Timesteps: 74,377,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,340.62850
Policy Entropy: 1.46390
Value Function Loss: 0.13791

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.20402
Value Function Update Magnitude: 0.48303

Collected Steps per Second: 22,346.17900
Overall Steps per Second: 10,557.53941

Timestep Collection Time: 2.23797
Timestep Consumption Time: 2.49893
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.73690

Cumulative Model Updates: 8,910
Cumulative Timesteps: 74,427,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 74427724...
Checkpoint 74427724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,920.08583
Policy Entropy: 1.45154
Value Function Loss: 0.14225

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12470
Policy Update Magnitude: 0.22308
Value Function Update Magnitude: 0.46616

Collected Steps per Second: 22,382.87334
Overall Steps per Second: 10,703.42455

Timestep Collection Time: 2.23448
Timestep Consumption Time: 2.43823
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.67271

Cumulative Model Updates: 8,916
Cumulative Timesteps: 74,477,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.77865
Policy Entropy: 1.44353
Value Function Loss: 0.14563

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10684
Policy Update Magnitude: 0.24690
Value Function Update Magnitude: 0.57468

Collected Steps per Second: 22,935.71040
Overall Steps per Second: 10,782.44147

Timestep Collection Time: 2.18062
Timestep Consumption Time: 2.45785
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.63847

Cumulative Model Updates: 8,922
Cumulative Timesteps: 74,527,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 74527752...
Checkpoint 74527752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,211.08692
Policy Entropy: 1.43543
Value Function Loss: 0.14573

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.28759
Value Function Update Magnitude: 0.58053

Collected Steps per Second: 22,186.01520
Overall Steps per Second: 10,620.73356

Timestep Collection Time: 2.25493
Timestep Consumption Time: 2.45548
PPO Batch Consumption Time: 0.28193
Total Iteration Time: 4.71041

Cumulative Model Updates: 8,928
Cumulative Timesteps: 74,577,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.14100
Policy Entropy: 1.41891
Value Function Loss: 0.14306

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07902
Policy Update Magnitude: 0.30200
Value Function Update Magnitude: 0.59302

Collected Steps per Second: 22,248.97431
Overall Steps per Second: 10,575.16889

Timestep Collection Time: 2.24738
Timestep Consumption Time: 2.48086
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.72825

Cumulative Model Updates: 8,934
Cumulative Timesteps: 74,627,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 74627782...
Checkpoint 74627782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,660.82259
Policy Entropy: 1.42396
Value Function Loss: 0.13581

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06860
Policy Update Magnitude: 0.30335
Value Function Update Magnitude: 0.59666

Collected Steps per Second: 22,455.62165
Overall Steps per Second: 10,621.31982

Timestep Collection Time: 2.22795
Timestep Consumption Time: 2.48239
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.71034

Cumulative Model Updates: 8,940
Cumulative Timesteps: 74,677,812

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,945.03412
Policy Entropy: 1.43143
Value Function Loss: 0.13105

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.30139
Value Function Update Magnitude: 0.51200

Collected Steps per Second: 22,407.61386
Overall Steps per Second: 10,510.52610

Timestep Collection Time: 2.23138
Timestep Consumption Time: 2.52575
PPO Batch Consumption Time: 0.29602
Total Iteration Time: 4.75714

Cumulative Model Updates: 8,946
Cumulative Timesteps: 74,727,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 74727812...
Checkpoint 74727812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,310.21882
Policy Entropy: 1.45311
Value Function Loss: 0.13131

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05945
Policy Update Magnitude: 0.29815
Value Function Update Magnitude: 0.52965

Collected Steps per Second: 22,219.65595
Overall Steps per Second: 10,583.63055

Timestep Collection Time: 2.25143
Timestep Consumption Time: 2.47530
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.72673

Cumulative Model Updates: 8,952
Cumulative Timesteps: 74,777,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,770.89071
Policy Entropy: 1.45297
Value Function Loss: 0.13504

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08211
Policy Update Magnitude: 0.28495
Value Function Update Magnitude: 0.53239

Collected Steps per Second: 22,525.05984
Overall Steps per Second: 10,543.01679

Timestep Collection Time: 2.22090
Timestep Consumption Time: 2.52404
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.74494

Cumulative Model Updates: 8,958
Cumulative Timesteps: 74,827,864

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 74827864...
Checkpoint 74827864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,287.79884
Policy Entropy: 1.45479
Value Function Loss: 0.14072

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.29371
Value Function Update Magnitude: 0.50398

Collected Steps per Second: 22,057.36759
Overall Steps per Second: 10,517.62374

Timestep Collection Time: 2.26709
Timestep Consumption Time: 2.48741
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.75450

Cumulative Model Updates: 8,964
Cumulative Timesteps: 74,877,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,243.68837
Policy Entropy: 1.45441
Value Function Loss: 0.13841

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.29251
Value Function Update Magnitude: 0.49963

Collected Steps per Second: 22,303.07392
Overall Steps per Second: 10,455.30201

Timestep Collection Time: 2.24301
Timestep Consumption Time: 2.54174
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.78475

Cumulative Model Updates: 8,970
Cumulative Timesteps: 74,927,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 74927896...
Checkpoint 74927896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,457.65583
Policy Entropy: 1.46191
Value Function Loss: 0.13920

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08564
Policy Update Magnitude: 0.28881
Value Function Update Magnitude: 0.54037

Collected Steps per Second: 22,196.30785
Overall Steps per Second: 10,626.16281

Timestep Collection Time: 2.25452
Timestep Consumption Time: 2.45480
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.70932

Cumulative Model Updates: 8,976
Cumulative Timesteps: 74,977,938

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.08706
Policy Entropy: 1.45024
Value Function Loss: 0.13339

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.28417
Value Function Update Magnitude: 0.58170

Collected Steps per Second: 22,606.91191
Overall Steps per Second: 10,537.50527

Timestep Collection Time: 2.21216
Timestep Consumption Time: 2.53375
PPO Batch Consumption Time: 0.29643
Total Iteration Time: 4.74591

Cumulative Model Updates: 8,982
Cumulative Timesteps: 75,027,948

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 75027948...
Checkpoint 75027948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,531.08286
Policy Entropy: 1.44654
Value Function Loss: 0.13132

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08233
Policy Update Magnitude: 0.28899
Value Function Update Magnitude: 0.63988

Collected Steps per Second: 22,188.15404
Overall Steps per Second: 10,619.68924

Timestep Collection Time: 2.25345
Timestep Consumption Time: 2.45478
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.70824

Cumulative Model Updates: 8,988
Cumulative Timesteps: 75,077,948

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,963.35897
Policy Entropy: 1.45386
Value Function Loss: 0.12517

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10028
Policy Update Magnitude: 0.27664
Value Function Update Magnitude: 0.71147

Collected Steps per Second: 22,719.90882
Overall Steps per Second: 10,602.41622

Timestep Collection Time: 2.20177
Timestep Consumption Time: 2.51640
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.71817

Cumulative Model Updates: 8,994
Cumulative Timesteps: 75,127,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 75127972...
Checkpoint 75127972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,861.45019
Policy Entropy: 1.46176
Value Function Loss: 0.12438

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.28654
Value Function Update Magnitude: 0.64420

Collected Steps per Second: 22,514.09831
Overall Steps per Second: 10,534.21212

Timestep Collection Time: 2.22199
Timestep Consumption Time: 2.52692
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.74891

Cumulative Model Updates: 9,000
Cumulative Timesteps: 75,177,998

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,578.61627
Policy Entropy: 1.45995
Value Function Loss: 0.12315

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.27654
Value Function Update Magnitude: 0.55031

Collected Steps per Second: 22,043.56687
Overall Steps per Second: 10,400.88867

Timestep Collection Time: 2.26960
Timestep Consumption Time: 2.54057
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.81017

Cumulative Model Updates: 9,006
Cumulative Timesteps: 75,228,028

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 75228028...
Checkpoint 75228028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,577.32575
Policy Entropy: 1.44757
Value Function Loss: 0.12822

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.23229
Value Function Update Magnitude: 0.52333

Collected Steps per Second: 22,129.14108
Overall Steps per Second: 10,566.40963

Timestep Collection Time: 2.25992
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.73292

Cumulative Model Updates: 9,012
Cumulative Timesteps: 75,278,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,882.21082
Policy Entropy: 1.43189
Value Function Loss: 0.13422

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.14715
Policy Update Magnitude: 0.22566
Value Function Update Magnitude: 0.52226

Collected Steps per Second: 22,567.95648
Overall Steps per Second: 10,533.87946

Timestep Collection Time: 2.21686
Timestep Consumption Time: 2.53258
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.74944

Cumulative Model Updates: 9,018
Cumulative Timesteps: 75,328,068

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 75328068...
Checkpoint 75328068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,652.62145
Policy Entropy: 1.43745
Value Function Loss: 0.13323

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.26360
Value Function Update Magnitude: 0.51167

Collected Steps per Second: 22,198.07160
Overall Steps per Second: 10,629.33258

Timestep Collection Time: 2.25290
Timestep Consumption Time: 2.45201
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.70491

Cumulative Model Updates: 9,024
Cumulative Timesteps: 75,378,078

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,316.88560
Policy Entropy: 1.41902
Value Function Loss: 0.13005

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11806
Policy Update Magnitude: 0.27173
Value Function Update Magnitude: 0.52734

Collected Steps per Second: 22,979.45738
Overall Steps per Second: 10,684.68548

Timestep Collection Time: 2.17655
Timestep Consumption Time: 2.50454
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.68109

Cumulative Model Updates: 9,030
Cumulative Timesteps: 75,428,094

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 75428094...
Checkpoint 75428094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.85910
Policy Entropy: 1.43787
Value Function Loss: 0.13016

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.26768
Value Function Update Magnitude: 0.55686

Collected Steps per Second: 22,363.96965
Overall Steps per Second: 10,513.11758

Timestep Collection Time: 2.23744
Timestep Consumption Time: 2.52214
PPO Batch Consumption Time: 0.29696
Total Iteration Time: 4.75958

Cumulative Model Updates: 9,036
Cumulative Timesteps: 75,478,132

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,460.97822
Policy Entropy: 1.44158
Value Function Loss: 0.12921

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.26450
Value Function Update Magnitude: 0.58672

Collected Steps per Second: 22,198.83234
Overall Steps per Second: 10,377.41626

Timestep Collection Time: 2.25273
Timestep Consumption Time: 2.56619
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 4.81893

Cumulative Model Updates: 9,042
Cumulative Timesteps: 75,528,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 75528140...
Checkpoint 75528140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945.32445
Policy Entropy: 1.43780
Value Function Loss: 0.13105

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.24554
Value Function Update Magnitude: 0.63255

Collected Steps per Second: 21,793.26844
Overall Steps per Second: 10,567.68180

Timestep Collection Time: 2.29566
Timestep Consumption Time: 2.43858
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.73425

Cumulative Model Updates: 9,048
Cumulative Timesteps: 75,578,170

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,574.63354
Policy Entropy: 1.44097
Value Function Loss: 0.13379

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.26305
Value Function Update Magnitude: 0.57723

Collected Steps per Second: 22,587.79070
Overall Steps per Second: 10,538.02133

Timestep Collection Time: 2.21474
Timestep Consumption Time: 2.53245
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.74719

Cumulative Model Updates: 9,054
Cumulative Timesteps: 75,628,196

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 75628196...
Checkpoint 75628196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,208.87053
Policy Entropy: 1.42023
Value Function Loss: 0.13505

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.27135
Value Function Update Magnitude: 0.55132

Collected Steps per Second: 22,135.35005
Overall Steps per Second: 10,625.52640

Timestep Collection Time: 2.25946
Timestep Consumption Time: 2.44750
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.70697

Cumulative Model Updates: 9,060
Cumulative Timesteps: 75,678,210

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,539.04668
Policy Entropy: 1.42299
Value Function Loss: 0.12701

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.27004
Value Function Update Magnitude: 0.57024

Collected Steps per Second: 22,735.33899
Overall Steps per Second: 10,618.38750

Timestep Collection Time: 2.19940
Timestep Consumption Time: 2.50979
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.70919

Cumulative Model Updates: 9,066
Cumulative Timesteps: 75,728,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 75728214...
Checkpoint 75728214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,804.67702
Policy Entropy: 1.42346
Value Function Loss: 0.11727

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06203
Policy Update Magnitude: 0.27734
Value Function Update Magnitude: 0.64919

Collected Steps per Second: 22,352.30221
Overall Steps per Second: 10,479.17365

Timestep Collection Time: 2.23708
Timestep Consumption Time: 2.53467
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.77175

Cumulative Model Updates: 9,072
Cumulative Timesteps: 75,778,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,323.34632
Policy Entropy: 1.42111
Value Function Loss: 0.11059

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06174
Policy Update Magnitude: 0.27565
Value Function Update Magnitude: 0.63433

Collected Steps per Second: 22,643.13961
Overall Steps per Second: 10,540.41841

Timestep Collection Time: 2.20835
Timestep Consumption Time: 2.53567
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.74402

Cumulative Model Updates: 9,078
Cumulative Timesteps: 75,828,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 75828222...
Checkpoint 75828222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,938.81545
Policy Entropy: 1.42857
Value Function Loss: 0.11519

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06861
Policy Update Magnitude: 0.27417
Value Function Update Magnitude: 0.64832

Collected Steps per Second: 22,265.10561
Overall Steps per Second: 10,562.62083

Timestep Collection Time: 2.24594
Timestep Consumption Time: 2.48831
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.73424

Cumulative Model Updates: 9,084
Cumulative Timesteps: 75,878,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,618.00622
Policy Entropy: 1.41210
Value Function Loss: 0.11856

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.26561
Value Function Update Magnitude: 0.67569

Collected Steps per Second: 22,762.24778
Overall Steps per Second: 10,624.64763

Timestep Collection Time: 2.19741
Timestep Consumption Time: 2.51032
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.70773

Cumulative Model Updates: 9,090
Cumulative Timesteps: 75,928,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 75928246...
Checkpoint 75928246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,661.30371
Policy Entropy: 1.41284
Value Function Loss: 0.12067

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.17293
Policy Update Magnitude: 0.24267
Value Function Update Magnitude: 0.65578

Collected Steps per Second: 22,647.71234
Overall Steps per Second: 10,605.99630

Timestep Collection Time: 2.20773
Timestep Consumption Time: 2.50659
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.71431

Cumulative Model Updates: 9,096
Cumulative Timesteps: 75,978,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,008.42110
Policy Entropy: 1.41883
Value Function Loss: 0.11657

Mean KL Divergence: 0.02552
SB3 Clip Fraction: 0.19165
Policy Update Magnitude: 0.21170
Value Function Update Magnitude: 0.63351

Collected Steps per Second: 22,617.64916
Overall Steps per Second: 10,721.08241

Timestep Collection Time: 2.21102
Timestep Consumption Time: 2.45344
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.66445

Cumulative Model Updates: 9,102
Cumulative Timesteps: 76,028,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 76028254...
Checkpoint 76028254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,912.60094
Policy Entropy: 1.43423
Value Function Loss: 0.11259

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.17689
Policy Update Magnitude: 0.20937
Value Function Update Magnitude: 0.62818

Collected Steps per Second: 22,096.41846
Overall Steps per Second: 10,638.06282

Timestep Collection Time: 2.26390
Timestep Consumption Time: 2.43846
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.70236

Cumulative Model Updates: 9,108
Cumulative Timesteps: 76,078,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,792.33336
Policy Entropy: 1.42169
Value Function Loss: 0.11650

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.22279
Value Function Update Magnitude: 0.63364

Collected Steps per Second: 22,393.27700
Overall Steps per Second: 10,525.94949

Timestep Collection Time: 2.23281
Timestep Consumption Time: 2.51735
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.75017

Cumulative Model Updates: 9,114
Cumulative Timesteps: 76,128,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 76128278...
Checkpoint 76128278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,623.22657
Policy Entropy: 1.42659
Value Function Loss: 0.12259

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.14887
Policy Update Magnitude: 0.24781
Value Function Update Magnitude: 0.58518

Collected Steps per Second: 22,367.19511
Overall Steps per Second: 10,565.27360

Timestep Collection Time: 2.23685
Timestep Consumption Time: 2.49867
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.73551

Cumulative Model Updates: 9,120
Cumulative Timesteps: 76,178,310

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,506.73811
Policy Entropy: 1.40295
Value Function Loss: 0.12647

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.21543
Value Function Update Magnitude: 0.53721

Collected Steps per Second: 21,849.72498
Overall Steps per Second: 10,579.83489

Timestep Collection Time: 2.28937
Timestep Consumption Time: 2.43869
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.72805

Cumulative Model Updates: 9,126
Cumulative Timesteps: 76,228,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 76228332...
Checkpoint 76228332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,848.14223
Policy Entropy: 1.41005
Value Function Loss: 0.12770

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.14074
Policy Update Magnitude: 0.20965
Value Function Update Magnitude: 0.50343

Collected Steps per Second: 22,198.42214
Overall Steps per Second: 10,612.79267

Timestep Collection Time: 2.25349
Timestep Consumption Time: 2.46006
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.71356

Cumulative Model Updates: 9,132
Cumulative Timesteps: 76,278,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,986.11212
Policy Entropy: 1.40005
Value Function Loss: 0.13022

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10368
Policy Update Magnitude: 0.24517
Value Function Update Magnitude: 0.53269

Collected Steps per Second: 22,831.91496
Overall Steps per Second: 10,617.42691

Timestep Collection Time: 2.19141
Timestep Consumption Time: 2.52103
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.71244

Cumulative Model Updates: 9,138
Cumulative Timesteps: 76,328,390

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 76328390...
Checkpoint 76328390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,129.37906
Policy Entropy: 1.41107
Value Function Loss: 0.13192

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09353
Policy Update Magnitude: 0.26944
Value Function Update Magnitude: 0.47425

Collected Steps per Second: 22,160.01266
Overall Steps per Second: 10,487.41059

Timestep Collection Time: 2.25632
Timestep Consumption Time: 2.51130
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.76762

Cumulative Model Updates: 9,144
Cumulative Timesteps: 76,378,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,647.00162
Policy Entropy: 1.40864
Value Function Loss: 0.12510

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.25036
Value Function Update Magnitude: 0.50220

Collected Steps per Second: 22,370.84625
Overall Steps per Second: 10,498.55498

Timestep Collection Time: 2.23541
Timestep Consumption Time: 2.52791
PPO Batch Consumption Time: 0.29757
Total Iteration Time: 4.76332

Cumulative Model Updates: 9,150
Cumulative Timesteps: 76,428,398

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 76428398...
Checkpoint 76428398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733.50498
Policy Entropy: 1.42526
Value Function Loss: 0.12324

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07180
Policy Update Magnitude: 0.25213
Value Function Update Magnitude: 0.55397

Collected Steps per Second: 22,571.90858
Overall Steps per Second: 10,599.48264

Timestep Collection Time: 2.21567
Timestep Consumption Time: 2.50267
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.71834

Cumulative Model Updates: 9,156
Cumulative Timesteps: 76,478,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,892.47338
Policy Entropy: 1.41191
Value Function Loss: 0.12230

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.25267
Value Function Update Magnitude: 0.63819

Collected Steps per Second: 22,737.67043
Overall Steps per Second: 10,608.81598

Timestep Collection Time: 2.19979
Timestep Consumption Time: 2.51497
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.71476

Cumulative Model Updates: 9,162
Cumulative Timesteps: 76,528,428

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 76528428...
Checkpoint 76528428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,048.86331
Policy Entropy: 1.40016
Value Function Loss: 0.12512

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.20413
Value Function Update Magnitude: 0.61611

Collected Steps per Second: 22,674.35282
Overall Steps per Second: 10,574.35712

Timestep Collection Time: 2.20672
Timestep Consumption Time: 2.52510
PPO Batch Consumption Time: 0.29659
Total Iteration Time: 4.73182

Cumulative Model Updates: 9,168
Cumulative Timesteps: 76,578,464

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.47640
Policy Entropy: 1.37397
Value Function Loss: 0.13075

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.19021
Value Function Update Magnitude: 0.55495

Collected Steps per Second: 22,736.62370
Overall Steps per Second: 10,743.47317

Timestep Collection Time: 2.20006
Timestep Consumption Time: 2.45597
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.65604

Cumulative Model Updates: 9,174
Cumulative Timesteps: 76,628,486

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 76628486...
Checkpoint 76628486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,891.62262
Policy Entropy: 1.37962
Value Function Loss: 0.12695

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.18824
Value Function Update Magnitude: 0.56317

Collected Steps per Second: 22,083.16829
Overall Steps per Second: 10,427.58690

Timestep Collection Time: 2.26652
Timestep Consumption Time: 2.53344
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.79996

Cumulative Model Updates: 9,180
Cumulative Timesteps: 76,678,538

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.23612
Policy Entropy: 1.39375
Value Function Loss: 0.12743

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.19710
Value Function Update Magnitude: 0.55897

Collected Steps per Second: 22,736.03437
Overall Steps per Second: 10,734.41289

Timestep Collection Time: 2.19915
Timestep Consumption Time: 2.45876
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.65792

Cumulative Model Updates: 9,186
Cumulative Timesteps: 76,728,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 76728538...
Checkpoint 76728538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,055.74827
Policy Entropy: 1.41705
Value Function Loss: 0.12344

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.21235
Value Function Update Magnitude: 0.51327

Collected Steps per Second: 22,173.64788
Overall Steps per Second: 10,616.85255

Timestep Collection Time: 2.25574
Timestep Consumption Time: 2.45545
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.71119

Cumulative Model Updates: 9,192
Cumulative Timesteps: 76,778,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,114.03780
Policy Entropy: 1.40300
Value Function Loss: 0.13022

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.22022
Value Function Update Magnitude: 0.49021

Collected Steps per Second: 22,506.75675
Overall Steps per Second: 10,353.27117

Timestep Collection Time: 2.22200
Timestep Consumption Time: 2.60836
PPO Batch Consumption Time: 0.31032
Total Iteration Time: 4.83036

Cumulative Model Updates: 9,198
Cumulative Timesteps: 76,828,566

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 76828566...
Checkpoint 76828566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.53093
Policy Entropy: 1.40332
Value Function Loss: 0.12791

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.22962
Value Function Update Magnitude: 0.50301

Collected Steps per Second: 21,827.15902
Overall Steps per Second: 10,384.51343

Timestep Collection Time: 2.29219
Timestep Consumption Time: 2.52575
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.81794

Cumulative Model Updates: 9,204
Cumulative Timesteps: 76,878,598

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,579.38662
Policy Entropy: 1.39348
Value Function Loss: 0.12767

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.26243
Value Function Update Magnitude: 0.58848

Collected Steps per Second: 22,827.04046
Overall Steps per Second: 10,642.03884

Timestep Collection Time: 2.19214
Timestep Consumption Time: 2.50997
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.70211

Cumulative Model Updates: 9,210
Cumulative Timesteps: 76,928,638

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 76928638...
Checkpoint 76928638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,134.78780
Policy Entropy: 1.38800
Value Function Loss: 0.12093

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07974
Policy Update Magnitude: 0.27873
Value Function Update Magnitude: 0.62793

Collected Steps per Second: 22,589.55273
Overall Steps per Second: 10,597.86893

Timestep Collection Time: 2.21421
Timestep Consumption Time: 2.50542
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.71963

Cumulative Model Updates: 9,216
Cumulative Timesteps: 76,978,656

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852.95997
Policy Entropy: 1.38722
Value Function Loss: 0.11757

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08007
Policy Update Magnitude: 0.27958
Value Function Update Magnitude: 0.67031

Collected Steps per Second: 22,910.41275
Overall Steps per Second: 10,808.02505

Timestep Collection Time: 2.18390
Timestep Consumption Time: 2.44544
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.62934

Cumulative Model Updates: 9,222
Cumulative Timesteps: 77,028,690

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 77028690...
Checkpoint 77028690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,674.59555
Policy Entropy: 1.38686
Value Function Loss: 0.11064

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.27453
Value Function Update Magnitude: 0.67554

Collected Steps per Second: 22,082.22960
Overall Steps per Second: 10,628.53030

Timestep Collection Time: 2.26553
Timestep Consumption Time: 2.44142
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.70695

Cumulative Model Updates: 9,228
Cumulative Timesteps: 77,078,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,703.28584
Policy Entropy: 1.40565
Value Function Loss: 0.11424

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.26306
Value Function Update Magnitude: 0.67569

Collected Steps per Second: 22,183.65147
Overall Steps per Second: 10,472.54803

Timestep Collection Time: 2.25490
Timestep Consumption Time: 2.52158
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.77649

Cumulative Model Updates: 9,234
Cumulative Timesteps: 77,128,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 77128740...
Checkpoint 77128740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,220.91102
Policy Entropy: 1.40982
Value Function Loss: 0.11278

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06898
Policy Update Magnitude: 0.25197
Value Function Update Magnitude: 0.66697

Collected Steps per Second: 22,444.81062
Overall Steps per Second: 10,576.90836

Timestep Collection Time: 2.22974
Timestep Consumption Time: 2.50189
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.73163

Cumulative Model Updates: 9,240
Cumulative Timesteps: 77,178,786

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,076.95763
Policy Entropy: 1.41136
Value Function Loss: 0.11724

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07757
Policy Update Magnitude: 0.27591
Value Function Update Magnitude: 0.69997

Collected Steps per Second: 22,661.94024
Overall Steps per Second: 10,577.31706

Timestep Collection Time: 2.20714
Timestep Consumption Time: 2.52166
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.72880

Cumulative Model Updates: 9,246
Cumulative Timesteps: 77,228,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 77228804...
Checkpoint 77228804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,479.33109
Policy Entropy: 1.40554
Value Function Loss: 0.11481

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07220
Policy Update Magnitude: 0.27587
Value Function Update Magnitude: 0.69406

Collected Steps per Second: 22,579.08313
Overall Steps per Second: 10,528.59351

Timestep Collection Time: 2.21444
Timestep Consumption Time: 2.53453
PPO Batch Consumption Time: 0.29731
Total Iteration Time: 4.74897

Cumulative Model Updates: 9,252
Cumulative Timesteps: 77,278,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.05733
Policy Entropy: 1.39171
Value Function Loss: 0.11670

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11589
Policy Update Magnitude: 0.26518
Value Function Update Magnitude: 0.69128

Collected Steps per Second: 22,717.04117
Overall Steps per Second: 10,584.98031

Timestep Collection Time: 2.20108
Timestep Consumption Time: 2.52278
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.72386

Cumulative Model Updates: 9,258
Cumulative Timesteps: 77,328,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 77328806...
Checkpoint 77328806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,372.19806
Policy Entropy: 1.41179
Value Function Loss: 0.11686

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.22227
Value Function Update Magnitude: 0.61912

Collected Steps per Second: 21,746.62276
Overall Steps per Second: 10,503.23225

Timestep Collection Time: 2.30004
Timestep Consumption Time: 2.46212
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.76215

Cumulative Model Updates: 9,264
Cumulative Timesteps: 77,378,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,237.06289
Policy Entropy: 1.40649
Value Function Loss: 0.12339

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11670
Policy Update Magnitude: 0.20704
Value Function Update Magnitude: 0.50962

Collected Steps per Second: 21,874.07122
Overall Steps per Second: 10,533.92309

Timestep Collection Time: 2.28627
Timestep Consumption Time: 2.46125
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.74752

Cumulative Model Updates: 9,270
Cumulative Timesteps: 77,428,834

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 77428834...
Checkpoint 77428834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,352.62182
Policy Entropy: 1.40307
Value Function Loss: 0.12682

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.21406
Value Function Update Magnitude: 0.52608

Collected Steps per Second: 22,381.28614
Overall Steps per Second: 10,417.68670

Timestep Collection Time: 2.23455
Timestep Consumption Time: 2.56614
PPO Batch Consumption Time: 0.30180
Total Iteration Time: 4.80068

Cumulative Model Updates: 9,276
Cumulative Timesteps: 77,478,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,200.19288
Policy Entropy: 1.39891
Value Function Loss: 0.13257

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.16024
Policy Update Magnitude: 0.19555
Value Function Update Magnitude: 0.49099

Collected Steps per Second: 22,657.68594
Overall Steps per Second: 10,589.57343

Timestep Collection Time: 2.20702
Timestep Consumption Time: 2.51517
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.72219

Cumulative Model Updates: 9,282
Cumulative Timesteps: 77,528,852

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 77528852...
Checkpoint 77528852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,188.63112
Policy Entropy: 1.41094
Value Function Loss: 0.13037

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.14109
Policy Update Magnitude: 0.21158
Value Function Update Magnitude: 0.44261

Collected Steps per Second: 22,270.84208
Overall Steps per Second: 10,639.28332

Timestep Collection Time: 2.24545
Timestep Consumption Time: 2.45487
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.70032

Cumulative Model Updates: 9,288
Cumulative Timesteps: 77,578,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,700.16732
Policy Entropy: 1.42257
Value Function Loss: 0.12786

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.14229
Policy Update Magnitude: 0.22613
Value Function Update Magnitude: 0.45000

Collected Steps per Second: 22,557.67756
Overall Steps per Second: 10,536.64795

Timestep Collection Time: 2.21663
Timestep Consumption Time: 2.52890
PPO Batch Consumption Time: 0.29715
Total Iteration Time: 4.74553

Cumulative Model Updates: 9,294
Cumulative Timesteps: 77,628,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 77628862...
Checkpoint 77628862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969.97232
Policy Entropy: 1.42284
Value Function Loss: 0.12018

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.15168
Policy Update Magnitude: 0.20453
Value Function Update Magnitude: 0.56658

Collected Steps per Second: 21,715.82084
Overall Steps per Second: 10,514.84778

Timestep Collection Time: 2.30265
Timestep Consumption Time: 2.45291
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.75556

Cumulative Model Updates: 9,300
Cumulative Timesteps: 77,678,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,341.64651
Policy Entropy: 1.42583
Value Function Loss: 0.11668

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.21453
Value Function Update Magnitude: 0.59651

Collected Steps per Second: 21,610.21417
Overall Steps per Second: 10,494.86151

Timestep Collection Time: 2.31428
Timestep Consumption Time: 2.45110
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.76538

Cumulative Model Updates: 9,306
Cumulative Timesteps: 77,728,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 77728878...
Checkpoint 77728878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.19339
Policy Entropy: 1.42668
Value Function Loss: 0.12624

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.16599
Policy Update Magnitude: 0.20541
Value Function Update Magnitude: 0.58159

Collected Steps per Second: 21,425.38218
Overall Steps per Second: 10,591.05818

Timestep Collection Time: 2.33396
Timestep Consumption Time: 2.38757
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.72153

Cumulative Model Updates: 9,312
Cumulative Timesteps: 77,778,884

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,880.45680
Policy Entropy: 1.41799
Value Function Loss: 0.12753

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.15570
Policy Update Magnitude: 0.20368
Value Function Update Magnitude: 0.62715

Collected Steps per Second: 21,646.20094
Overall Steps per Second: 10,536.15240

Timestep Collection Time: 2.31080
Timestep Consumption Time: 2.43667
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.74746

Cumulative Model Updates: 9,318
Cumulative Timesteps: 77,828,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 77828904...
Checkpoint 77828904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.45861
Policy Entropy: 1.41020
Value Function Loss: 0.12982

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.16940
Policy Update Magnitude: 0.20170
Value Function Update Magnitude: 0.56152

Collected Steps per Second: 21,300.55282
Overall Steps per Second: 10,549.00653

Timestep Collection Time: 2.34764
Timestep Consumption Time: 2.39271
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.74035

Cumulative Model Updates: 9,324
Cumulative Timesteps: 77,878,910

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,632.23853
Policy Entropy: 1.40257
Value Function Loss: 0.12390

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.15614
Policy Update Magnitude: 0.22440
Value Function Update Magnitude: 0.58812

Collected Steps per Second: 22,149.62353
Overall Steps per Second: 10,643.95344

Timestep Collection Time: 2.25756
Timestep Consumption Time: 2.44032
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.69788

Cumulative Model Updates: 9,330
Cumulative Timesteps: 77,928,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 77928914...
Checkpoint 77928914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018.05016
Policy Entropy: 1.40575
Value Function Loss: 0.12351

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14663
Policy Update Magnitude: 0.21205
Value Function Update Magnitude: 0.61099

Collected Steps per Second: 21,550.72212
Overall Steps per Second: 10,515.40651

Timestep Collection Time: 2.32076
Timestep Consumption Time: 2.43550
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.75626

Cumulative Model Updates: 9,336
Cumulative Timesteps: 77,978,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,645.26569
Policy Entropy: 1.41136
Value Function Loss: 0.12327

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.22800
Value Function Update Magnitude: 0.66722

Collected Steps per Second: 21,895.87847
Overall Steps per Second: 10,603.10135

Timestep Collection Time: 2.28490
Timestep Consumption Time: 2.43353
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.71843

Cumulative Model Updates: 9,342
Cumulative Timesteps: 78,028,958

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 78028958...
Checkpoint 78028958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,142.64796
Policy Entropy: 1.39723
Value Function Loss: 0.12669

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07685
Policy Update Magnitude: 0.25914
Value Function Update Magnitude: 0.67366

Collected Steps per Second: 21,632.36844
Overall Steps per Second: 10,492.63357

Timestep Collection Time: 2.31329
Timestep Consumption Time: 2.45596
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.76925

Cumulative Model Updates: 9,348
Cumulative Timesteps: 78,079,000

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.91059
Policy Entropy: 1.40194
Value Function Loss: 0.13200

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07363
Policy Update Magnitude: 0.26897
Value Function Update Magnitude: 0.57512

Collected Steps per Second: 22,633.07723
Overall Steps per Second: 10,531.00334

Timestep Collection Time: 2.21039
Timestep Consumption Time: 2.54015
PPO Batch Consumption Time: 0.29940
Total Iteration Time: 4.75054

Cumulative Model Updates: 9,354
Cumulative Timesteps: 78,129,028

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 78129028...
Checkpoint 78129028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,414.59505
Policy Entropy: 1.38829
Value Function Loss: 0.12701

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.25844
Value Function Update Magnitude: 0.59042

Collected Steps per Second: 21,984.81254
Overall Steps per Second: 10,414.50574

Timestep Collection Time: 2.27530
Timestep Consumption Time: 2.52781
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.80311

Cumulative Model Updates: 9,360
Cumulative Timesteps: 78,179,050

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,166.08029
Policy Entropy: 1.38521
Value Function Loss: 0.12030

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.21814
Value Function Update Magnitude: 0.59637

Collected Steps per Second: 22,990.54704
Overall Steps per Second: 10,688.63100

Timestep Collection Time: 2.17576
Timestep Consumption Time: 2.50416
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.67993

Cumulative Model Updates: 9,366
Cumulative Timesteps: 78,229,072

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 78229072...
Checkpoint 78229072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,849.26221
Policy Entropy: 1.36752
Value Function Loss: 0.12436

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.20402
Value Function Update Magnitude: 0.50399

Collected Steps per Second: 22,220.54051
Overall Steps per Second: 10,650.61262

Timestep Collection Time: 2.25035
Timestep Consumption Time: 2.44459
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.69494

Cumulative Model Updates: 9,372
Cumulative Timesteps: 78,279,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,134.51069
Policy Entropy: 1.37107
Value Function Loss: 0.12783

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.14619
Policy Update Magnitude: 0.21300
Value Function Update Magnitude: 0.48389

Collected Steps per Second: 22,555.06821
Overall Steps per Second: 10,553.73591

Timestep Collection Time: 2.21795
Timestep Consumption Time: 2.52217
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.74012

Cumulative Model Updates: 9,378
Cumulative Timesteps: 78,329,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 78329102...
Checkpoint 78329102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,763.13341
Policy Entropy: 1.38485
Value Function Loss: 0.13276

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.22110
Value Function Update Magnitude: 0.52115

Collected Steps per Second: 22,417.61665
Overall Steps per Second: 10,511.29602

Timestep Collection Time: 2.23182
Timestep Consumption Time: 2.52802
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.75983

Cumulative Model Updates: 9,384
Cumulative Timesteps: 78,379,134

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,401.97874
Policy Entropy: 1.41802
Value Function Loss: 0.12560

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.25006
Value Function Update Magnitude: 0.53266

Collected Steps per Second: 22,961.43683
Overall Steps per Second: 10,674.64649

Timestep Collection Time: 2.17835
Timestep Consumption Time: 2.50733
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.68568

Cumulative Model Updates: 9,390
Cumulative Timesteps: 78,429,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 78429152...
Checkpoint 78429152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,729.57248
Policy Entropy: 1.42334
Value Function Loss: 0.12438

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.25784
Value Function Update Magnitude: 0.51754

Collected Steps per Second: 22,490.96903
Overall Steps per Second: 10,550.56352

Timestep Collection Time: 2.22374
Timestep Consumption Time: 2.51667
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.74041

Cumulative Model Updates: 9,396
Cumulative Timesteps: 78,479,166

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,388.13709
Policy Entropy: 1.42709
Value Function Loss: 0.12388

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08910
Policy Update Magnitude: 0.26762
Value Function Update Magnitude: 0.52494

Collected Steps per Second: 22,583.83321
Overall Steps per Second: 10,729.38637

Timestep Collection Time: 2.21512
Timestep Consumption Time: 2.44740
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.66252

Cumulative Model Updates: 9,402
Cumulative Timesteps: 78,529,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 78529192...
Checkpoint 78529192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,493.08528
Policy Entropy: 1.41536
Value Function Loss: 0.12326

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.26406
Value Function Update Magnitude: 0.49498

Collected Steps per Second: 22,071.93296
Overall Steps per Second: 10,597.08199

Timestep Collection Time: 2.26532
Timestep Consumption Time: 2.45296
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.71828

Cumulative Model Updates: 9,408
Cumulative Timesteps: 78,579,192

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,124.57011
Policy Entropy: 1.41638
Value Function Loss: 0.12088

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.24225
Value Function Update Magnitude: 0.52353

Collected Steps per Second: 22,483.32525
Overall Steps per Second: 10,578.50742

Timestep Collection Time: 2.22512
Timestep Consumption Time: 2.50410
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.72921

Cumulative Model Updates: 9,414
Cumulative Timesteps: 78,629,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 78629220...
Checkpoint 78629220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,902.17016
Policy Entropy: 1.41313
Value Function Loss: 0.11627

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.24131
Value Function Update Magnitude: 0.52971

Collected Steps per Second: 21,561.14835
Overall Steps per Second: 10,664.00383

Timestep Collection Time: 2.32001
Timestep Consumption Time: 2.37073
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.69073

Cumulative Model Updates: 9,420
Cumulative Timesteps: 78,679,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,639.67816
Policy Entropy: 1.41089
Value Function Loss: 0.11325

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.22289
Value Function Update Magnitude: 0.58570

Collected Steps per Second: 21,838.15374
Overall Steps per Second: 10,562.26830

Timestep Collection Time: 2.29085
Timestep Consumption Time: 2.44563
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.73648

Cumulative Model Updates: 9,426
Cumulative Timesteps: 78,729,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 78729270...
Checkpoint 78729270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,411.24191
Policy Entropy: 1.38818
Value Function Loss: 0.12170

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.16707
Policy Update Magnitude: 0.20512
Value Function Update Magnitude: 0.52210

Collected Steps per Second: 21,755.41772
Overall Steps per Second: 10,496.93765

Timestep Collection Time: 2.29947
Timestep Consumption Time: 2.46630
PPO Batch Consumption Time: 0.29731
Total Iteration Time: 4.76577

Cumulative Model Updates: 9,432
Cumulative Timesteps: 78,779,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,737.04716
Policy Entropy: 1.38877
Value Function Loss: 0.12848

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.14935
Policy Update Magnitude: 0.20191
Value Function Update Magnitude: 0.57374

Collected Steps per Second: 22,254.39543
Overall Steps per Second: 10,354.43977

Timestep Collection Time: 2.24845
Timestep Consumption Time: 2.58406
PPO Batch Consumption Time: 0.30684
Total Iteration Time: 4.83252

Cumulative Model Updates: 9,438
Cumulative Timesteps: 78,829,334

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 78829334...
Checkpoint 78829334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,911.21690
Policy Entropy: 1.38156
Value Function Loss: 0.13158

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.14486
Policy Update Magnitude: 0.22198
Value Function Update Magnitude: 0.56820

Collected Steps per Second: 22,208.81516
Overall Steps per Second: 10,684.21905

Timestep Collection Time: 2.25271
Timestep Consumption Time: 2.42990
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.68261

Cumulative Model Updates: 9,444
Cumulative Timesteps: 78,879,364

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,226.74727
Policy Entropy: 1.38158
Value Function Loss: 0.13322

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11395
Policy Update Magnitude: 0.23927
Value Function Update Magnitude: 0.45579

Collected Steps per Second: 22,707.54794
Overall Steps per Second: 10,576.09944

Timestep Collection Time: 2.20235
Timestep Consumption Time: 2.52623
PPO Batch Consumption Time: 0.29721
Total Iteration Time: 4.72859

Cumulative Model Updates: 9,450
Cumulative Timesteps: 78,929,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 78929374...
Checkpoint 78929374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,293.00329
Policy Entropy: 1.38019
Value Function Loss: 0.12985

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11457
Policy Update Magnitude: 0.26326
Value Function Update Magnitude: 0.42377

Collected Steps per Second: 21,507.67272
Overall Steps per Second: 10,653.32951

Timestep Collection Time: 2.32531
Timestep Consumption Time: 2.36919
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.69449

Cumulative Model Updates: 9,456
Cumulative Timesteps: 78,979,386

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,382.39588
Policy Entropy: 1.36899
Value Function Loss: 0.13308

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.26080
Value Function Update Magnitude: 0.49872

Collected Steps per Second: 22,709.04514
Overall Steps per Second: 10,765.58438

Timestep Collection Time: 2.20221
Timestep Consumption Time: 2.44315
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.64536

Cumulative Model Updates: 9,462
Cumulative Timesteps: 79,029,396

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 79029396...
Checkpoint 79029396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,019.72739
Policy Entropy: 1.36541
Value Function Loss: 0.13165

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.16926
Policy Update Magnitude: 0.24403
Value Function Update Magnitude: 0.52671

Collected Steps per Second: 22,410.64538
Overall Steps per Second: 10,680.29977

Timestep Collection Time: 2.23117
Timestep Consumption Time: 2.45053
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.68170

Cumulative Model Updates: 9,468
Cumulative Timesteps: 79,079,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,800.11110
Policy Entropy: 1.36226
Value Function Loss: 0.12572

Mean KL Divergence: 0.02904
SB3 Clip Fraction: 0.21467
Policy Update Magnitude: 0.20585
Value Function Update Magnitude: 0.62311

Collected Steps per Second: 21,784.90165
Overall Steps per Second: 10,470.51815

Timestep Collection Time: 2.29544
Timestep Consumption Time: 2.48044
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.77589

Cumulative Model Updates: 9,474
Cumulative Timesteps: 79,129,404

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 79129404...
Checkpoint 79129404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,032.45198
Policy Entropy: 1.36315
Value Function Loss: 0.12640

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.19095
Policy Update Magnitude: 0.17552
Value Function Update Magnitude: 0.63818

Collected Steps per Second: 22,282.93192
Overall Steps per Second: 10,654.02740

Timestep Collection Time: 2.24405
Timestep Consumption Time: 2.44939
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.69344

Cumulative Model Updates: 9,480
Cumulative Timesteps: 79,179,408

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,151.72540
Policy Entropy: 1.36655
Value Function Loss: 0.13368

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.14338
Policy Update Magnitude: 0.19439
Value Function Update Magnitude: 0.47710

Collected Steps per Second: 22,664.03427
Overall Steps per Second: 10,612.89748

Timestep Collection Time: 2.20640
Timestep Consumption Time: 2.50541
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.71181

Cumulative Model Updates: 9,486
Cumulative Timesteps: 79,229,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 79229414...
Checkpoint 79229414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,080.23281
Policy Entropy: 1.36880
Value Function Loss: 0.13720

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.16227
Policy Update Magnitude: 0.19385
Value Function Update Magnitude: 0.41790

Collected Steps per Second: 22,573.73030
Overall Steps per Second: 10,567.56971

Timestep Collection Time: 2.21505
Timestep Consumption Time: 2.51659
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.73165

Cumulative Model Updates: 9,492
Cumulative Timesteps: 79,279,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,031.64647
Policy Entropy: 1.37456
Value Function Loss: 0.13223

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.13709
Policy Update Magnitude: 0.21182
Value Function Update Magnitude: 0.42732

Collected Steps per Second: 22,745.32167
Overall Steps per Second: 10,745.88750

Timestep Collection Time: 2.19869
Timestep Consumption Time: 2.45518
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.65387

Cumulative Model Updates: 9,498
Cumulative Timesteps: 79,329,426

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 79329426...
Checkpoint 79329426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.61381
Policy Entropy: 1.35384
Value Function Loss: 0.12955

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.19739
Value Function Update Magnitude: 0.43465

Collected Steps per Second: 22,149.35723
Overall Steps per Second: 10,615.54748

Timestep Collection Time: 2.25858
Timestep Consumption Time: 2.45395
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.71252

Cumulative Model Updates: 9,504
Cumulative Timesteps: 79,379,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,330.94984
Policy Entropy: 1.35559
Value Function Loss: 0.12779

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.19160
Value Function Update Magnitude: 0.44509

Collected Steps per Second: 22,788.73968
Overall Steps per Second: 10,594.97833

Timestep Collection Time: 2.19582
Timestep Consumption Time: 2.52717
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 4.72299

Cumulative Model Updates: 9,510
Cumulative Timesteps: 79,429,492

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 79429492...
Checkpoint 79429492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,789.02662
Policy Entropy: 1.36129
Value Function Loss: 0.13543

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.21806
Value Function Update Magnitude: 0.38775

Collected Steps per Second: 21,944.40307
Overall Steps per Second: 10,607.16826

Timestep Collection Time: 2.27985
Timestep Consumption Time: 2.43677
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.71662

Cumulative Model Updates: 9,516
Cumulative Timesteps: 79,479,522

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,262.79949
Policy Entropy: 1.36101
Value Function Loss: 0.13626

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.23294
Value Function Update Magnitude: 0.36168

Collected Steps per Second: 22,386.62335
Overall Steps per Second: 10,558.66537

Timestep Collection Time: 2.23410
Timestep Consumption Time: 2.50267
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.73677

Cumulative Model Updates: 9,522
Cumulative Timesteps: 79,529,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 79529536...
Checkpoint 79529536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,777.83857
Policy Entropy: 1.36745
Value Function Loss: 0.13147

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.14619
Policy Update Magnitude: 0.23679
Value Function Update Magnitude: 0.34837

Collected Steps per Second: 22,451.71064
Overall Steps per Second: 10,510.43287

Timestep Collection Time: 2.22700
Timestep Consumption Time: 2.53018
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.75718

Cumulative Model Updates: 9,528
Cumulative Timesteps: 79,579,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,313.72556
Policy Entropy: 1.35495
Value Function Loss: 0.12727

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.16042
Policy Update Magnitude: 0.22971
Value Function Update Magnitude: 0.44712

Collected Steps per Second: 23,017.69996
Overall Steps per Second: 10,861.23243

Timestep Collection Time: 2.17363
Timestep Consumption Time: 2.43284
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.60648

Cumulative Model Updates: 9,534
Cumulative Timesteps: 79,629,568

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 79629568...
Checkpoint 79629568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,208.05161
Policy Entropy: 1.37812
Value Function Loss: 0.11700

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.22173
Value Function Update Magnitude: 0.49432

Collected Steps per Second: 21,292.93976
Overall Steps per Second: 10,458.32488

Timestep Collection Time: 2.34857
Timestep Consumption Time: 2.43307
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.78165

Cumulative Model Updates: 9,540
Cumulative Timesteps: 79,679,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,477.01300
Policy Entropy: 1.34875
Value Function Loss: 0.12511

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.14496
Policy Update Magnitude: 0.23586
Value Function Update Magnitude: 0.42861

Collected Steps per Second: 22,027.29029
Overall Steps per Second: 10,689.83941

Timestep Collection Time: 2.27046
Timestep Consumption Time: 2.40801
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.67846

Cumulative Model Updates: 9,546
Cumulative Timesteps: 79,729,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 79729588...
Checkpoint 79729588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.89844
Policy Entropy: 1.36226
Value Function Loss: 0.12677

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10787
Policy Update Magnitude: 0.25522
Value Function Update Magnitude: 0.45813

Collected Steps per Second: 22,270.25220
Overall Steps per Second: 10,657.42977

Timestep Collection Time: 2.24587
Timestep Consumption Time: 2.44720
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.69306

Cumulative Model Updates: 9,552
Cumulative Timesteps: 79,779,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,462.14131
Policy Entropy: 1.35946
Value Function Loss: 0.12195

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.28582
Value Function Update Magnitude: 0.54193

Collected Steps per Second: 22,661.43397
Overall Steps per Second: 10,551.60324

Timestep Collection Time: 2.20860
Timestep Consumption Time: 2.53476
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.74336

Cumulative Model Updates: 9,558
Cumulative Timesteps: 79,829,654

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 79829654...
Checkpoint 79829654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,159.19658
Policy Entropy: 1.36653
Value Function Loss: 0.12500

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06924
Policy Update Magnitude: 0.29737
Value Function Update Magnitude: 0.53598

Collected Steps per Second: 21,572.87781
Overall Steps per Second: 10,521.75259

Timestep Collection Time: 2.31791
Timestep Consumption Time: 2.43453
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.75244

Cumulative Model Updates: 9,564
Cumulative Timesteps: 79,879,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,193.27344
Policy Entropy: 1.34977
Value Function Loss: 0.12537

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07166
Policy Update Magnitude: 0.31651
Value Function Update Magnitude: 0.50634

Collected Steps per Second: 22,642.73798
Overall Steps per Second: 10,612.09366

Timestep Collection Time: 2.20848
Timestep Consumption Time: 2.50369
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.71217

Cumulative Model Updates: 9,570
Cumulative Timesteps: 79,929,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 79929664...
Checkpoint 79929664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,755.36590
Policy Entropy: 1.35618
Value Function Loss: 0.13189

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05820
Policy Update Magnitude: 0.32505
Value Function Update Magnitude: 0.48929

Collected Steps per Second: 21,616.79277
Overall Steps per Second: 10,506.52867

Timestep Collection Time: 2.31357
Timestep Consumption Time: 2.44652
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.76009

Cumulative Model Updates: 9,576
Cumulative Timesteps: 79,979,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.14947
Policy Entropy: 1.34929
Value Function Loss: 0.12771

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06389
Policy Update Magnitude: 0.31482
Value Function Update Magnitude: 0.58982

Collected Steps per Second: 22,703.34414
Overall Steps per Second: 10,637.07661

Timestep Collection Time: 2.20267
Timestep Consumption Time: 2.49862
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.70129

Cumulative Model Updates: 9,582
Cumulative Timesteps: 80,029,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 80029684...
Checkpoint 80029684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,455.08551
Policy Entropy: 1.35579
Value Function Loss: 0.12531

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06764
Policy Update Magnitude: 0.31579
Value Function Update Magnitude: 0.63857

Collected Steps per Second: 22,254.10337
Overall Steps per Second: 10,482.33411

Timestep Collection Time: 2.24696
Timestep Consumption Time: 2.52336
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.77031

Cumulative Model Updates: 9,588
Cumulative Timesteps: 80,079,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.88740
Policy Entropy: 1.35733
Value Function Loss: 0.12063

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06175
Policy Update Magnitude: 0.31954
Value Function Update Magnitude: 0.65578

Collected Steps per Second: 22,797.72820
Overall Steps per Second: 10,569.16590

Timestep Collection Time: 2.19355
Timestep Consumption Time: 2.53795
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.73150

Cumulative Model Updates: 9,594
Cumulative Timesteps: 80,129,696

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 80129696...
Checkpoint 80129696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,624.03420
Policy Entropy: 1.36320
Value Function Loss: 0.11926

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05545
Policy Update Magnitude: 0.32599
Value Function Update Magnitude: 0.68792

Collected Steps per Second: 21,841.07115
Overall Steps per Second: 10,475.02439

Timestep Collection Time: 2.29055
Timestep Consumption Time: 2.48538
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.77593

Cumulative Model Updates: 9,600
Cumulative Timesteps: 80,179,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,709.35923
Policy Entropy: 1.37052
Value Function Loss: 0.11212

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07394
Policy Update Magnitude: 0.33503
Value Function Update Magnitude: 0.73154

Collected Steps per Second: 22,100.41128
Overall Steps per Second: 10,630.82415

Timestep Collection Time: 2.26322
Timestep Consumption Time: 2.44178
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.70500

Cumulative Model Updates: 9,606
Cumulative Timesteps: 80,229,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 80229742...
Checkpoint 80229742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,007.04689
Policy Entropy: 1.37839
Value Function Loss: 0.11537

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.30930
Value Function Update Magnitude: 0.73434

Collected Steps per Second: 21,191.10729
Overall Steps per Second: 10,483.05515

Timestep Collection Time: 2.36080
Timestep Consumption Time: 2.41147
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.77227

Cumulative Model Updates: 9,612
Cumulative Timesteps: 80,279,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,202.96738
Policy Entropy: 1.38411
Value Function Loss: 0.11633

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.30525
Value Function Update Magnitude: 0.66689

Collected Steps per Second: 22,032.94040
Overall Steps per Second: 10,602.89127

Timestep Collection Time: 2.26942
Timestep Consumption Time: 2.44646
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.71588

Cumulative Model Updates: 9,618
Cumulative Timesteps: 80,329,772

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 80329772...
Checkpoint 80329772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,218.22136
Policy Entropy: 1.37566
Value Function Loss: 0.11934

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07517
Policy Update Magnitude: 0.30583
Value Function Update Magnitude: 0.69372

Collected Steps per Second: 21,852.27971
Overall Steps per Second: 10,536.14456

Timestep Collection Time: 2.28928
Timestep Consumption Time: 2.45876
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.74804

Cumulative Model Updates: 9,624
Cumulative Timesteps: 80,379,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,824.40744
Policy Entropy: 1.37473
Value Function Loss: 0.11503

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06285
Policy Update Magnitude: 0.31316
Value Function Update Magnitude: 0.73472

Collected Steps per Second: 22,109.05711
Overall Steps per Second: 10,783.12116

Timestep Collection Time: 2.26224
Timestep Consumption Time: 2.37612
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.63836

Cumulative Model Updates: 9,630
Cumulative Timesteps: 80,429,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 80429814...
Checkpoint 80429814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,749.51831
Policy Entropy: 1.36374
Value Function Loss: 0.11649

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07378
Policy Update Magnitude: 0.31369
Value Function Update Magnitude: 0.75364

Collected Steps per Second: 22,353.15227
Overall Steps per Second: 10,668.07753

Timestep Collection Time: 2.23709
Timestep Consumption Time: 2.45035
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.68744

Cumulative Model Updates: 9,636
Cumulative Timesteps: 80,479,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,370.35952
Policy Entropy: 1.37227
Value Function Loss: 0.11386

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06654
Policy Update Magnitude: 0.31655
Value Function Update Magnitude: 0.75539

Collected Steps per Second: 22,554.15095
Overall Steps per Second: 10,528.41340

Timestep Collection Time: 2.21768
Timestep Consumption Time: 2.53308
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 4.75076

Cumulative Model Updates: 9,642
Cumulative Timesteps: 80,529,838

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 80529838...
Checkpoint 80529838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,830.52208
Policy Entropy: 1.35823
Value Function Loss: 0.11181

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07637
Policy Update Magnitude: 0.31128
Value Function Update Magnitude: 0.74364

Collected Steps per Second: 22,227.81933
Overall Steps per Second: 10,650.24639

Timestep Collection Time: 2.24997
Timestep Consumption Time: 2.44588
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.69585

Cumulative Model Updates: 9,648
Cumulative Timesteps: 80,579,850

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,864.19109
Policy Entropy: 1.37157
Value Function Loss: 0.11187

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06667
Policy Update Magnitude: 0.30687
Value Function Update Magnitude: 0.72603

Collected Steps per Second: 21,992.57884
Overall Steps per Second: 10,647.56581

Timestep Collection Time: 2.27377
Timestep Consumption Time: 2.42271
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.69647

Cumulative Model Updates: 9,654
Cumulative Timesteps: 80,629,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 80629856...
Checkpoint 80629856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.84995
Policy Entropy: 1.36602
Value Function Loss: 0.11905

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.26901
Value Function Update Magnitude: 0.65708

Collected Steps per Second: 21,880.93373
Overall Steps per Second: 10,620.87970

Timestep Collection Time: 2.28656
Timestep Consumption Time: 2.42416
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.71072

Cumulative Model Updates: 9,660
Cumulative Timesteps: 80,679,888

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,957.68434
Policy Entropy: 1.37314
Value Function Loss: 0.12789

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.22617
Value Function Update Magnitude: 0.55576

Collected Steps per Second: 22,163.89571
Overall Steps per Second: 10,705.52286

Timestep Collection Time: 2.25592
Timestep Consumption Time: 2.41457
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.67049

Cumulative Model Updates: 9,666
Cumulative Timesteps: 80,729,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 80729888...
Checkpoint 80729888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.21411
Policy Entropy: 1.36490
Value Function Loss: 0.12781

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11253
Policy Update Magnitude: 0.22475
Value Function Update Magnitude: 0.50446

Collected Steps per Second: 22,425.04777
Overall Steps per Second: 10,487.05870

Timestep Collection Time: 2.23063
Timestep Consumption Time: 2.53925
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.76988

Cumulative Model Updates: 9,672
Cumulative Timesteps: 80,779,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,834.25983
Policy Entropy: 1.36999
Value Function Loss: 0.12867

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.21477
Value Function Update Magnitude: 0.51529

Collected Steps per Second: 22,357.37216
Overall Steps per Second: 10,599.80943

Timestep Collection Time: 2.23658
Timestep Consumption Time: 2.48087
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.71744

Cumulative Model Updates: 9,678
Cumulative Timesteps: 80,829,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 80829914...
Checkpoint 80829914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,759.95685
Policy Entropy: 1.35808
Value Function Loss: 0.12466

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12573
Policy Update Magnitude: 0.22011
Value Function Update Magnitude: 0.50250

Collected Steps per Second: 22,171.98173
Overall Steps per Second: 10,635.83344

Timestep Collection Time: 2.25564
Timestep Consumption Time: 2.44658
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.70222

Cumulative Model Updates: 9,684
Cumulative Timesteps: 80,879,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,007.10322
Policy Entropy: 1.36529
Value Function Loss: 0.12278

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 0.21933
Value Function Update Magnitude: 0.50183

Collected Steps per Second: 21,904.06643
Overall Steps per Second: 10,534.48414

Timestep Collection Time: 2.28305
Timestep Consumption Time: 2.46403
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.74708

Cumulative Model Updates: 9,690
Cumulative Timesteps: 80,929,934

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 80929934...
Checkpoint 80929934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,208.77243
Policy Entropy: 1.35902
Value Function Loss: 0.11812

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06846
Policy Update Magnitude: 0.26267
Value Function Update Magnitude: 0.53994

Collected Steps per Second: 21,872.55469
Overall Steps per Second: 10,550.67502

Timestep Collection Time: 2.28780
Timestep Consumption Time: 2.45503
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.74282

Cumulative Model Updates: 9,696
Cumulative Timesteps: 80,979,974

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,384.28131
Policy Entropy: 1.36606
Value Function Loss: 0.11453

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.07077
Policy Update Magnitude: 0.30032
Value Function Update Magnitude: 0.63019

Collected Steps per Second: 21,911.42118
Overall Steps per Second: 10,559.32539

Timestep Collection Time: 2.28219
Timestep Consumption Time: 2.45353
PPO Batch Consumption Time: 0.29642
Total Iteration Time: 4.73572

Cumulative Model Updates: 9,702
Cumulative Timesteps: 81,029,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 81029980...
Checkpoint 81029980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,655.93085
Policy Entropy: 1.36103
Value Function Loss: 0.11029

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.29824
Value Function Update Magnitude: 0.64295

Collected Steps per Second: 21,497.34230
Overall Steps per Second: 10,550.64477

Timestep Collection Time: 2.32773
Timestep Consumption Time: 2.41511
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.74284

Cumulative Model Updates: 9,708
Cumulative Timesteps: 81,080,020

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,813.20806
Policy Entropy: 1.35861
Value Function Loss: 0.10673

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.26433
Value Function Update Magnitude: 0.64487

Collected Steps per Second: 21,968.19936
Overall Steps per Second: 10,639.55958

Timestep Collection Time: 2.27620
Timestep Consumption Time: 2.42362
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.69982

Cumulative Model Updates: 9,714
Cumulative Timesteps: 81,130,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 81130024...
Checkpoint 81130024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,065.02773
Policy Entropy: 1.35080
Value Function Loss: 0.10877

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.26212
Value Function Update Magnitude: 0.66647

Collected Steps per Second: 21,838.02409
Overall Steps per Second: 10,545.47356

Timestep Collection Time: 2.29032
Timestep Consumption Time: 2.45257
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.74289

Cumulative Model Updates: 9,720
Cumulative Timesteps: 81,180,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,916.47359
Policy Entropy: 1.35015
Value Function Loss: 0.10973

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08584
Policy Update Magnitude: 0.28704
Value Function Update Magnitude: 0.64291

Collected Steps per Second: 21,983.88112
Overall Steps per Second: 10,752.02438

Timestep Collection Time: 2.27539
Timestep Consumption Time: 2.37694
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.65233

Cumulative Model Updates: 9,726
Cumulative Timesteps: 81,230,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 81230062...
Checkpoint 81230062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,883.02328
Policy Entropy: 1.35327
Value Function Loss: 0.11142

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.28027
Value Function Update Magnitude: 0.61760

Collected Steps per Second: 21,349.69808
Overall Steps per Second: 10,600.14699

Timestep Collection Time: 2.34364
Timestep Consumption Time: 2.37667
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.72031

Cumulative Model Updates: 9,732
Cumulative Timesteps: 81,280,098

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,123.76722
Policy Entropy: 1.35565
Value Function Loss: 0.11107

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08683
Policy Update Magnitude: 0.27215
Value Function Update Magnitude: 0.64283

Collected Steps per Second: 21,647.54631
Overall Steps per Second: 10,535.80693

Timestep Collection Time: 2.31139
Timestep Consumption Time: 2.43774
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.74914

Cumulative Model Updates: 9,738
Cumulative Timesteps: 81,330,134

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 81330134...
Checkpoint 81330134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,257.89581
Policy Entropy: 1.35898
Value Function Loss: 0.11133

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.26423
Value Function Update Magnitude: 0.65185

Collected Steps per Second: 21,733.58319
Overall Steps per Second: 10,675.28371

Timestep Collection Time: 2.30197
Timestep Consumption Time: 2.38456
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.68653

Cumulative Model Updates: 9,744
Cumulative Timesteps: 81,380,164

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,466.31586
Policy Entropy: 1.36111
Value Function Loss: 0.11614

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.16918
Policy Update Magnitude: 0.21460
Value Function Update Magnitude: 0.63934

Collected Steps per Second: 22,451.57723
Overall Steps per Second: 10,738.14324

Timestep Collection Time: 2.22808
Timestep Consumption Time: 2.43045
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.65853

Cumulative Model Updates: 9,750
Cumulative Timesteps: 81,430,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 81430188...
Checkpoint 81430188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,187.65639
Policy Entropy: 1.37128
Value Function Loss: 0.11761

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.20821
Value Function Update Magnitude: 0.61701

Collected Steps per Second: 21,674.51982
Overall Steps per Second: 10,394.69799

Timestep Collection Time: 2.30750
Timestep Consumption Time: 2.50399
PPO Batch Consumption Time: 0.30405
Total Iteration Time: 4.81149

Cumulative Model Updates: 9,756
Cumulative Timesteps: 81,480,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,905.65717
Policy Entropy: 1.36864
Value Function Loss: 0.11755

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.14301
Policy Update Magnitude: 0.21230
Value Function Update Magnitude: 0.57606

Collected Steps per Second: 21,875.05713
Overall Steps per Second: 10,581.64905

Timestep Collection Time: 2.28662
Timestep Consumption Time: 2.44043
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.72705

Cumulative Model Updates: 9,762
Cumulative Timesteps: 81,530,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 81530222...
Checkpoint 81530222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.20323
Policy Entropy: 1.36472
Value Function Loss: 0.11712

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.23977
Value Function Update Magnitude: 0.54774

Collected Steps per Second: 21,774.88855
Overall Steps per Second: 10,514.77308

Timestep Collection Time: 2.29659
Timestep Consumption Time: 2.45938
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 4.75598

Cumulative Model Updates: 9,768
Cumulative Timesteps: 81,580,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.76989
Policy Entropy: 1.36413
Value Function Loss: 0.11100

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.25540
Value Function Update Magnitude: 0.62179

Collected Steps per Second: 21,988.44205
Overall Steps per Second: 10,612.62158

Timestep Collection Time: 2.27520
Timestep Consumption Time: 2.43881
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.71401

Cumulative Model Updates: 9,774
Cumulative Timesteps: 81,630,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 81630258...
Checkpoint 81630258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,764.73877
Policy Entropy: 1.36511
Value Function Loss: 0.11036

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.24484
Value Function Update Magnitude: 0.64997

Collected Steps per Second: 21,637.04219
Overall Steps per Second: 10,492.23624

Timestep Collection Time: 2.31113
Timestep Consumption Time: 2.45487
PPO Batch Consumption Time: 0.29698
Total Iteration Time: 4.76600

Cumulative Model Updates: 9,780
Cumulative Timesteps: 81,680,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,721.21000
Policy Entropy: 1.37577
Value Function Loss: 0.10831

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.25077
Value Function Update Magnitude: 0.65065

Collected Steps per Second: 22,090.00422
Overall Steps per Second: 10,780.11092

Timestep Collection Time: 2.26347
Timestep Consumption Time: 2.37470
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.63817

Cumulative Model Updates: 9,786
Cumulative Timesteps: 81,730,264

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 81730264...
Checkpoint 81730264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,613.61070
Policy Entropy: 1.37200
Value Function Loss: 0.11116

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.25729
Value Function Update Magnitude: 0.63823

Collected Steps per Second: 21,365.52491
Overall Steps per Second: 10,444.10153

Timestep Collection Time: 2.34069
Timestep Consumption Time: 2.44766
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.78835

Cumulative Model Updates: 9,792
Cumulative Timesteps: 81,780,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,676.79334
Policy Entropy: 1.37173
Value Function Loss: 0.11417

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.26712
Value Function Update Magnitude: 0.58084

Collected Steps per Second: 22,188.00612
Overall Steps per Second: 10,818.08443

Timestep Collection Time: 2.25365
Timestep Consumption Time: 2.36861
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.62226

Cumulative Model Updates: 9,798
Cumulative Timesteps: 81,830,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 81830278...
Checkpoint 81830278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,061.73380
Policy Entropy: 1.36794
Value Function Loss: 0.11544

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.27154
Value Function Update Magnitude: 0.56376

Collected Steps per Second: 22,056.50111
Overall Steps per Second: 10,611.33805

Timestep Collection Time: 2.26817
Timestep Consumption Time: 2.44641
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.71458

Cumulative Model Updates: 9,804
Cumulative Timesteps: 81,880,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,520.10009
Policy Entropy: 1.36982
Value Function Loss: 0.11651

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.28402
Value Function Update Magnitude: 0.53053

Collected Steps per Second: 22,651.32023
Overall Steps per Second: 10,582.54630

Timestep Collection Time: 2.20835
Timestep Consumption Time: 2.51849
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.72684

Cumulative Model Updates: 9,810
Cumulative Timesteps: 81,930,328

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 81930328...
Checkpoint 81930328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,099.15427
Policy Entropy: 1.37577
Value Function Loss: 0.11662

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.27510
Value Function Update Magnitude: 0.50114

Collected Steps per Second: 22,468.87353
Overall Steps per Second: 10,482.85300

Timestep Collection Time: 2.22530
Timestep Consumption Time: 2.54439
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.76969

Cumulative Model Updates: 9,816
Cumulative Timesteps: 81,980,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,812.53120
Policy Entropy: 1.35424
Value Function Loss: 0.12144

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.14618
Policy Update Magnitude: 0.26083
Value Function Update Magnitude: 0.46885

Collected Steps per Second: 22,571.33044
Overall Steps per Second: 10,552.39546

Timestep Collection Time: 2.21626
Timestep Consumption Time: 2.52427
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.74053

Cumulative Model Updates: 9,822
Cumulative Timesteps: 82,030,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 82030352...
Checkpoint 82030352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776.05148
Policy Entropy: 1.36388
Value Function Loss: 0.11520

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.26948
Value Function Update Magnitude: 0.57015

Collected Steps per Second: 21,658.25573
Overall Steps per Second: 10,566.60934

Timestep Collection Time: 2.30923
Timestep Consumption Time: 2.42398
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.73321

Cumulative Model Updates: 9,828
Cumulative Timesteps: 82,080,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,544.31675
Policy Entropy: 1.36524
Value Function Loss: 0.11313

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.16417
Policy Update Magnitude: 0.23978
Value Function Update Magnitude: 0.63327

Collected Steps per Second: 21,550.51827
Overall Steps per Second: 10,299.83467

Timestep Collection Time: 2.32161
Timestep Consumption Time: 2.53594
PPO Batch Consumption Time: 0.30988
Total Iteration Time: 4.85755

Cumulative Model Updates: 9,834
Cumulative Timesteps: 82,130,398

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 82130398...
Checkpoint 82130398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.98535
Policy Entropy: 1.38114
Value Function Loss: 0.11402

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.21948
Value Function Update Magnitude: 0.58835

Collected Steps per Second: 21,533.96507
Overall Steps per Second: 10,500.17202

Timestep Collection Time: 2.32312
Timestep Consumption Time: 2.44118
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.76430

Cumulative Model Updates: 9,840
Cumulative Timesteps: 82,180,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,816.63675
Policy Entropy: 1.37655
Value Function Loss: 0.11898

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.22191
Value Function Update Magnitude: 0.54504

Collected Steps per Second: 22,553.68074
Overall Steps per Second: 10,717.85851

Timestep Collection Time: 2.21826
Timestep Consumption Time: 2.44965
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.66791

Cumulative Model Updates: 9,846
Cumulative Timesteps: 82,230,454

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 82230454...
Checkpoint 82230454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,081.74577
Policy Entropy: 1.37341
Value Function Loss: 0.12515

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.22761
Value Function Update Magnitude: 0.53581

Collected Steps per Second: 22,438.90286
Overall Steps per Second: 10,723.41191

Timestep Collection Time: 2.22845
Timestep Consumption Time: 2.43462
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.66307

Cumulative Model Updates: 9,852
Cumulative Timesteps: 82,280,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,056.72704
Policy Entropy: 1.39261
Value Function Loss: 0.12489

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.26264
Value Function Update Magnitude: 0.54246

Collected Steps per Second: 21,984.51907
Overall Steps per Second: 10,752.73833

Timestep Collection Time: 2.27524
Timestep Consumption Time: 2.37660
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.65184

Cumulative Model Updates: 9,858
Cumulative Timesteps: 82,330,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 82330478...
Checkpoint 82330478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,802.46307
Policy Entropy: 1.39293
Value Function Loss: 0.12422

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.26728
Value Function Update Magnitude: 0.50581

Collected Steps per Second: 21,622.11416
Overall Steps per Second: 10,668.32052

Timestep Collection Time: 2.31346
Timestep Consumption Time: 2.37537
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.68884

Cumulative Model Updates: 9,864
Cumulative Timesteps: 82,380,500

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,483.84334
Policy Entropy: 1.38916
Value Function Loss: 0.12576

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.26113
Value Function Update Magnitude: 0.47192

Collected Steps per Second: 22,742.72150
Overall Steps per Second: 10,560.44086

Timestep Collection Time: 2.20053
Timestep Consumption Time: 2.53848
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.73901

Cumulative Model Updates: 9,870
Cumulative Timesteps: 82,430,546

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 82430546...
Checkpoint 82430546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,048.03681
Policy Entropy: 1.36894
Value Function Loss: 0.12734

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10923
Policy Update Magnitude: 0.26599
Value Function Update Magnitude: 0.47324

Collected Steps per Second: 22,185.89444
Overall Steps per Second: 10,621.75634

Timestep Collection Time: 2.25404
Timestep Consumption Time: 2.45403
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.70807

Cumulative Model Updates: 9,876
Cumulative Timesteps: 82,480,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,371.84597
Policy Entropy: 1.37316
Value Function Loss: 0.11979

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.27073
Value Function Update Magnitude: 0.54618

Collected Steps per Second: 22,649.17882
Overall Steps per Second: 10,587.34742

Timestep Collection Time: 2.20873
Timestep Consumption Time: 2.51634
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.72507

Cumulative Model Updates: 9,882
Cumulative Timesteps: 82,530,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 82530580...
Checkpoint 82530580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,272.07630
Policy Entropy: 1.37826
Value Function Loss: 0.11180

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.27867
Value Function Update Magnitude: 0.59690

Collected Steps per Second: 21,804.66829
Overall Steps per Second: 10,540.75635

Timestep Collection Time: 2.29373
Timestep Consumption Time: 2.45109
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.74482

Cumulative Model Updates: 9,888
Cumulative Timesteps: 82,580,594

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,767.48358
Policy Entropy: 1.37246
Value Function Loss: 0.11106

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.28084
Value Function Update Magnitude: 0.58518

Collected Steps per Second: 21,804.20656
Overall Steps per Second: 10,558.96645

Timestep Collection Time: 2.29424
Timestep Consumption Time: 2.44335
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.73758

Cumulative Model Updates: 9,894
Cumulative Timesteps: 82,630,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 82630618...
Checkpoint 82630618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,696.41787
Policy Entropy: 1.38587
Value Function Loss: 0.10918

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.28194
Value Function Update Magnitude: 0.52842

Collected Steps per Second: 21,715.72173
Overall Steps per Second: 10,503.46307

Timestep Collection Time: 2.30368
Timestep Consumption Time: 2.45913
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 4.76281

Cumulative Model Updates: 9,900
Cumulative Timesteps: 82,680,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,069.09728
Policy Entropy: 1.38040
Value Function Loss: 0.11385

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09032
Policy Update Magnitude: 0.28466
Value Function Update Magnitude: 0.47090

Collected Steps per Second: 22,561.20823
Overall Steps per Second: 10,584.63932

Timestep Collection Time: 2.21681
Timestep Consumption Time: 2.50834
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.72515

Cumulative Model Updates: 9,906
Cumulative Timesteps: 82,730,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 82730658...
Checkpoint 82730658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,765.39738
Policy Entropy: 1.38050
Value Function Loss: 0.12063

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.26469
Value Function Update Magnitude: 0.45860

Collected Steps per Second: 21,294.95834
Overall Steps per Second: 10,469.76123

Timestep Collection Time: 2.34797
Timestep Consumption Time: 2.42768
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.77566

Cumulative Model Updates: 9,912
Cumulative Timesteps: 82,780,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,316.71192
Policy Entropy: 1.37717
Value Function Loss: 0.12427

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08658
Policy Update Magnitude: 0.28710
Value Function Update Magnitude: 0.46421

Collected Steps per Second: 21,259.18056
Overall Steps per Second: 10,496.66981

Timestep Collection Time: 2.35390
Timestep Consumption Time: 2.41352
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.76742

Cumulative Model Updates: 9,918
Cumulative Timesteps: 82,830,700

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 82830700...
Checkpoint 82830700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,812.32903
Policy Entropy: 1.36674
Value Function Loss: 0.12683

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08900
Policy Update Magnitude: 0.29066
Value Function Update Magnitude: 0.46085

Collected Steps per Second: 22,065.16437
Overall Steps per Second: 10,601.70113

Timestep Collection Time: 2.26647
Timestep Consumption Time: 2.45070
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.71717

Cumulative Model Updates: 9,924
Cumulative Timesteps: 82,880,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,157.10831
Policy Entropy: 1.37442
Value Function Loss: 0.12411

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.29093
Value Function Update Magnitude: 0.45554

Collected Steps per Second: 22,096.41956
Overall Steps per Second: 10,476.26417

Timestep Collection Time: 2.26399
Timestep Consumption Time: 2.51119
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.77518

Cumulative Model Updates: 9,930
Cumulative Timesteps: 82,930,736

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 82930736...
Checkpoint 82930736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,686.84410
Policy Entropy: 1.36739
Value Function Loss: 0.12316

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.14763
Policy Update Magnitude: 0.26847
Value Function Update Magnitude: 0.44325

Collected Steps per Second: 21,803.94716
Overall Steps per Second: 10,687.94435

Timestep Collection Time: 2.29463
Timestep Consumption Time: 2.38653
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.68116

Cumulative Model Updates: 9,936
Cumulative Timesteps: 82,980,768

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,277.93097
Policy Entropy: 1.37969
Value Function Loss: 0.12178

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10640
Policy Update Magnitude: 0.24796
Value Function Update Magnitude: 0.51430

Collected Steps per Second: 22,835.92991
Overall Steps per Second: 10,641.59652

Timestep Collection Time: 2.19015
Timestep Consumption Time: 2.50971
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.69986

Cumulative Model Updates: 9,942
Cumulative Timesteps: 83,030,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 83030782...
Checkpoint 83030782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,391.52217
Policy Entropy: 1.36525
Value Function Loss: 0.11651

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10704
Policy Update Magnitude: 0.28189
Value Function Update Magnitude: 0.49132

Collected Steps per Second: 21,816.27182
Overall Steps per Second: 10,562.76467

Timestep Collection Time: 2.29187
Timestep Consumption Time: 2.44174
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.73361

Cumulative Model Updates: 9,948
Cumulative Timesteps: 83,080,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,130.49818
Policy Entropy: 1.36313
Value Function Loss: 0.11829

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.15261
Policy Update Magnitude: 0.26840
Value Function Update Magnitude: 0.45900

Collected Steps per Second: 22,591.65600
Overall Steps per Second: 10,721.23631

Timestep Collection Time: 2.21445
Timestep Consumption Time: 2.45181
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.66625

Cumulative Model Updates: 9,954
Cumulative Timesteps: 83,130,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 83130810...
Checkpoint 83130810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.64866
Policy Entropy: 1.36879
Value Function Loss: 0.11803

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.18052
Policy Update Magnitude: 0.22436
Value Function Update Magnitude: 0.43795

Collected Steps per Second: 22,167.38936
Overall Steps per Second: 10,626.17097

Timestep Collection Time: 2.25692
Timestep Consumption Time: 2.45127
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.70819

Cumulative Model Updates: 9,960
Cumulative Timesteps: 83,180,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,344.51486
Policy Entropy: 1.38000
Value Function Loss: 0.11815

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.15785
Policy Update Magnitude: 0.20633
Value Function Update Magnitude: 0.53421

Collected Steps per Second: 22,647.68176
Overall Steps per Second: 10,564.23525

Timestep Collection Time: 2.20791
Timestep Consumption Time: 2.52542
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.73333

Cumulative Model Updates: 9,966
Cumulative Timesteps: 83,230,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 83230844...
Checkpoint 83230844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,876.50792
Policy Entropy: 1.38912
Value Function Loss: 0.11026

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.21733
Value Function Update Magnitude: 0.59382

Collected Steps per Second: 21,702.21685
Overall Steps per Second: 10,623.80271

Timestep Collection Time: 2.30391
Timestep Consumption Time: 2.40250
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.70641

Cumulative Model Updates: 9,972
Cumulative Timesteps: 83,280,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,613.20296
Policy Entropy: 1.39013
Value Function Loss: 0.11151

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.22026
Value Function Update Magnitude: 0.58537

Collected Steps per Second: 21,952.46018
Overall Steps per Second: 10,600.18723

Timestep Collection Time: 2.27847
Timestep Consumption Time: 2.44013
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.71860

Cumulative Model Updates: 9,978
Cumulative Timesteps: 83,330,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 83330862...
Checkpoint 83330862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,595.15889
Policy Entropy: 1.38904
Value Function Loss: 0.11108

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08327
Policy Update Magnitude: 0.25206
Value Function Update Magnitude: 0.56172

Collected Steps per Second: 21,656.03496
Overall Steps per Second: 10,493.01805

Timestep Collection Time: 2.30929
Timestep Consumption Time: 2.45674
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.76603

Cumulative Model Updates: 9,984
Cumulative Timesteps: 83,380,872

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,301.98036
Policy Entropy: 1.39643
Value Function Loss: 0.10748

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.27040
Value Function Update Magnitude: 0.59940

Collected Steps per Second: 21,689.66113
Overall Steps per Second: 10,544.09486

Timestep Collection Time: 2.30534
Timestep Consumption Time: 2.43684
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.74218

Cumulative Model Updates: 9,990
Cumulative Timesteps: 83,430,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 83430874...
Checkpoint 83430874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,037.40347
Policy Entropy: 1.39232
Value Function Loss: 0.10334

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.27384
Value Function Update Magnitude: 0.60512

Collected Steps per Second: 21,384.21522
Overall Steps per Second: 10,538.35720

Timestep Collection Time: 2.33939
Timestep Consumption Time: 2.40765
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.74704

Cumulative Model Updates: 9,996
Cumulative Timesteps: 83,480,900

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,397.68251
Policy Entropy: 1.38822
Value Function Loss: 0.10009

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.25383
Value Function Update Magnitude: 0.60532

Collected Steps per Second: 22,239.56216
Overall Steps per Second: 10,786.52283

Timestep Collection Time: 2.24825
Timestep Consumption Time: 2.38717
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.63541

Cumulative Model Updates: 10,002
Cumulative Timesteps: 83,530,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 83530900...
Checkpoint 83530900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,413.75341
Policy Entropy: 1.37687
Value Function Loss: 0.09619

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.22756
Value Function Update Magnitude: 0.62262

Collected Steps per Second: 21,630.62025
Overall Steps per Second: 10,665.71060

Timestep Collection Time: 2.31219
Timestep Consumption Time: 2.37705
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.68923

Cumulative Model Updates: 10,008
Cumulative Timesteps: 83,580,914

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,658.57973
Policy Entropy: 1.37635
Value Function Loss: 0.10112

Mean KL Divergence: 0.02509
SB3 Clip Fraction: 0.19737
Policy Update Magnitude: 0.21862
Value Function Update Magnitude: 0.63007

Collected Steps per Second: 22,690.88286
Overall Steps per Second: 10,582.11177

Timestep Collection Time: 2.20441
Timestep Consumption Time: 2.52244
PPO Batch Consumption Time: 0.29696
Total Iteration Time: 4.72684

Cumulative Model Updates: 10,014
Cumulative Timesteps: 83,630,934

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 83630934...
Checkpoint 83630934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,785.90049
Policy Entropy: 1.37738
Value Function Loss: 0.10401

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.15881
Policy Update Magnitude: 0.22909
Value Function Update Magnitude: 0.62314

Collected Steps per Second: 21,604.23586
Overall Steps per Second: 10,586.44746

Timestep Collection Time: 2.31566
Timestep Consumption Time: 2.41001
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.72566

Cumulative Model Updates: 10,020
Cumulative Timesteps: 83,680,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,072.80070
Policy Entropy: 1.37430
Value Function Loss: 0.10895

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.25509
Value Function Update Magnitude: 0.63166

Collected Steps per Second: 21,920.36471
Overall Steps per Second: 10,589.43396

Timestep Collection Time: 2.28181
Timestep Consumption Time: 2.44158
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.72339

Cumulative Model Updates: 10,026
Cumulative Timesteps: 83,730,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 83730980...
Checkpoint 83730980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,929.43247
Policy Entropy: 1.37572
Value Function Loss: 0.11491

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11063
Policy Update Magnitude: 0.25604
Value Function Update Magnitude: 0.62486

Collected Steps per Second: 21,692.61746
Overall Steps per Second: 10,529.57679

Timestep Collection Time: 2.30576
Timestep Consumption Time: 2.44448
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.75024

Cumulative Model Updates: 10,032
Cumulative Timesteps: 83,780,998

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,576.85488
Policy Entropy: 1.35704
Value Function Loss: 0.11833

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11764
Policy Update Magnitude: 0.24315
Value Function Update Magnitude: 0.55302

Collected Steps per Second: 21,923.58766
Overall Steps per Second: 10,637.88327

Timestep Collection Time: 2.28092
Timestep Consumption Time: 2.41982
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.70075

Cumulative Model Updates: 10,038
Cumulative Timesteps: 83,831,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 83831004...
Checkpoint 83831004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,372.55193
Policy Entropy: 1.35819
Value Function Loss: 0.11898

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.25118
Value Function Update Magnitude: 0.47292

Collected Steps per Second: 21,806.83633
Overall Steps per Second: 10,577.20183

Timestep Collection Time: 2.29313
Timestep Consumption Time: 2.43458
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.72772

Cumulative Model Updates: 10,044
Cumulative Timesteps: 83,881,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,805.73960
Policy Entropy: 1.35179
Value Function Loss: 0.11056

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10970
Policy Update Magnitude: 0.24963
Value Function Update Magnitude: 0.59502

Collected Steps per Second: 22,030.14169
Overall Steps per Second: 10,726.48518

Timestep Collection Time: 2.27034
Timestep Consumption Time: 2.39251
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.66285

Cumulative Model Updates: 10,050
Cumulative Timesteps: 83,931,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 83931026...
Checkpoint 83931026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,734.46028
Policy Entropy: 1.36245
Value Function Loss: 0.11405

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10656
Policy Update Magnitude: 0.25248
Value Function Update Magnitude: 0.67977

Collected Steps per Second: 21,368.40515
Overall Steps per Second: 10,602.24077

Timestep Collection Time: 2.34037
Timestep Consumption Time: 2.37656
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.71693

Cumulative Model Updates: 10,056
Cumulative Timesteps: 83,981,036

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,533.23116
Policy Entropy: 1.35847
Value Function Loss: 0.11510

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.25908
Value Function Update Magnitude: 0.69109

Collected Steps per Second: 22,636.46848
Overall Steps per Second: 10,570.17590

Timestep Collection Time: 2.20997
Timestep Consumption Time: 2.52278
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 4.73275

Cumulative Model Updates: 10,062
Cumulative Timesteps: 84,031,062

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 84031062...
Checkpoint 84031062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720.27112
Policy Entropy: 1.35064
Value Function Loss: 0.11920

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07977
Policy Update Magnitude: 0.27566
Value Function Update Magnitude: 0.69452

Collected Steps per Second: 21,848.94144
Overall Steps per Second: 10,557.36427

Timestep Collection Time: 2.28871
Timestep Consumption Time: 2.44788
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.73660

Cumulative Model Updates: 10,068
Cumulative Timesteps: 84,081,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,796.81498
Policy Entropy: 1.35032
Value Function Loss: 0.11924

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.27627
Value Function Update Magnitude: 0.55347

Collected Steps per Second: 21,785.54387
Overall Steps per Second: 10,531.31605

Timestep Collection Time: 2.29694
Timestep Consumption Time: 2.45461
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.75154

Cumulative Model Updates: 10,074
Cumulative Timesteps: 84,131,108

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 84131108...
Checkpoint 84131108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,327.33439
Policy Entropy: 1.36470
Value Function Loss: 0.11766

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07038
Policy Update Magnitude: 0.28179
Value Function Update Magnitude: 0.47854

Collected Steps per Second: 21,902.46234
Overall Steps per Second: 10,636.07744

Timestep Collection Time: 2.28449
Timestep Consumption Time: 2.41987
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.70437

Cumulative Model Updates: 10,080
Cumulative Timesteps: 84,181,144

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,431.51528
Policy Entropy: 1.35020
Value Function Loss: 0.11468

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.27061
Value Function Update Magnitude: 0.47323

Collected Steps per Second: 22,039.15885
Overall Steps per Second: 10,654.59560

Timestep Collection Time: 2.26960
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.69469

Cumulative Model Updates: 10,086
Cumulative Timesteps: 84,231,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 84231164...
Checkpoint 84231164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,887.12934
Policy Entropy: 1.35352
Value Function Loss: 0.11302

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07565
Policy Update Magnitude: 0.26962
Value Function Update Magnitude: 0.47413

Collected Steps per Second: 21,974.82682
Overall Steps per Second: 10,627.80887

Timestep Collection Time: 2.27542
Timestep Consumption Time: 2.42940
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.70483

Cumulative Model Updates: 10,092
Cumulative Timesteps: 84,281,166

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,537.71347
Policy Entropy: 1.35283
Value Function Loss: 0.11605

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.27632
Value Function Update Magnitude: 0.47743

Collected Steps per Second: 21,963.01757
Overall Steps per Second: 10,723.18210

Timestep Collection Time: 2.27801
Timestep Consumption Time: 2.38777
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.66578

Cumulative Model Updates: 10,098
Cumulative Timesteps: 84,331,198

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 84331198...
Checkpoint 84331198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.63969
Policy Entropy: 1.35556
Value Function Loss: 0.11332

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.15995
Policy Update Magnitude: 0.23226
Value Function Update Magnitude: 0.53346

Collected Steps per Second: 21,544.98103
Overall Steps per Second: 10,650.14833

Timestep Collection Time: 2.32165
Timestep Consumption Time: 2.37499
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.69665

Cumulative Model Updates: 10,104
Cumulative Timesteps: 84,381,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,874.49332
Policy Entropy: 1.36470
Value Function Loss: 0.11846

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.15994
Policy Update Magnitude: 0.21909
Value Function Update Magnitude: 0.49620

Collected Steps per Second: 21,999.84502
Overall Steps per Second: 10,634.16520

Timestep Collection Time: 2.27383
Timestep Consumption Time: 2.43025
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.70408

Cumulative Model Updates: 10,110
Cumulative Timesteps: 84,431,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 84431242...
Checkpoint 84431242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,835.36992
Policy Entropy: 1.37025
Value Function Loss: 0.12270

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.24722
Value Function Update Magnitude: 0.40204

Collected Steps per Second: 21,620.77897
Overall Steps per Second: 10,505.95252

Timestep Collection Time: 2.31444
Timestep Consumption Time: 2.44857
PPO Batch Consumption Time: 0.29643
Total Iteration Time: 4.76301

Cumulative Model Updates: 10,116
Cumulative Timesteps: 84,481,282

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,826.33199
Policy Entropy: 1.38285
Value Function Loss: 0.11109

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.27315
Value Function Update Magnitude: 0.42876

Collected Steps per Second: 22,073.42303
Overall Steps per Second: 10,747.89806

Timestep Collection Time: 2.26680
Timestep Consumption Time: 2.38862
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.65542

Cumulative Model Updates: 10,122
Cumulative Timesteps: 84,531,318

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 84531318...
Checkpoint 84531318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,892.73257
Policy Entropy: 1.37177
Value Function Loss: 0.11566

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07589
Policy Update Magnitude: 0.28906
Value Function Update Magnitude: 0.46226

Collected Steps per Second: 21,708.39565
Overall Steps per Second: 10,681.45757

Timestep Collection Time: 2.30556
Timestep Consumption Time: 2.38013
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.68569

Cumulative Model Updates: 10,128
Cumulative Timesteps: 84,581,368

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,134.45926
Policy Entropy: 1.37098
Value Function Loss: 0.11493

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08230
Policy Update Magnitude: 0.29554
Value Function Update Magnitude: 0.48069

Collected Steps per Second: 22,459.23958
Overall Steps per Second: 10,497.82339

Timestep Collection Time: 2.22688
Timestep Consumption Time: 2.53735
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.76423

Cumulative Model Updates: 10,134
Cumulative Timesteps: 84,631,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 84631382...
Checkpoint 84631382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,149.00474
Policy Entropy: 1.36489
Value Function Loss: 0.11254

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10958
Policy Update Magnitude: 0.28001
Value Function Update Magnitude: 0.50047

Collected Steps per Second: 21,449.96703
Overall Steps per Second: 10,607.18382

Timestep Collection Time: 2.33352
Timestep Consumption Time: 2.38535
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.71888

Cumulative Model Updates: 10,140
Cumulative Timesteps: 84,681,436

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,752.53651
Policy Entropy: 1.37038
Value Function Loss: 0.11003

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.14514
Policy Update Magnitude: 0.24318
Value Function Update Magnitude: 0.53394

Collected Steps per Second: 21,437.33348
Overall Steps per Second: 10,317.84402

Timestep Collection Time: 2.33303
Timestep Consumption Time: 2.51430
PPO Batch Consumption Time: 0.30247
Total Iteration Time: 4.84733

Cumulative Model Updates: 10,146
Cumulative Timesteps: 84,731,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 84731450...
Checkpoint 84731450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,939.53052
Policy Entropy: 1.39755
Value Function Loss: 0.10838

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.25572
Value Function Update Magnitude: 0.49576

Collected Steps per Second: 21,916.19036
Overall Steps per Second: 10,515.11800

Timestep Collection Time: 2.28206
Timestep Consumption Time: 2.47433
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.75639

Cumulative Model Updates: 10,152
Cumulative Timesteps: 84,781,464

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,697.89436
Policy Entropy: 1.37944
Value Function Loss: 0.10690

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10310
Policy Update Magnitude: 0.26935
Value Function Update Magnitude: 0.49204

Collected Steps per Second: 22,179.24363
Overall Steps per Second: 10,752.37838

Timestep Collection Time: 2.25652
Timestep Consumption Time: 2.39807
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.65460

Cumulative Model Updates: 10,158
Cumulative Timesteps: 84,831,512

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 84831512...
Checkpoint 84831512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,972.81598
Policy Entropy: 1.39384
Value Function Loss: 0.10896

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07832
Policy Update Magnitude: 0.28186
Value Function Update Magnitude: 0.51869

Collected Steps per Second: 21,667.96830
Overall Steps per Second: 10,670.81262

Timestep Collection Time: 2.30838
Timestep Consumption Time: 2.37898
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.68737

Cumulative Model Updates: 10,164
Cumulative Timesteps: 84,881,530

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,523.69094
Policy Entropy: 1.37985
Value Function Loss: 0.11193

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.07046
Policy Update Magnitude: 0.29733
Value Function Update Magnitude: 0.65306

Collected Steps per Second: 22,504.42384
Overall Steps per Second: 10,524.04841

Timestep Collection Time: 2.22205
Timestep Consumption Time: 2.52954
PPO Batch Consumption Time: 0.29765
Total Iteration Time: 4.75159

Cumulative Model Updates: 10,170
Cumulative Timesteps: 84,931,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 84931536...
Checkpoint 84931536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.41944
Policy Entropy: 1.39287
Value Function Loss: 0.11358

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.29061
Value Function Update Magnitude: 0.67946

Collected Steps per Second: 22,413.27191
Overall Steps per Second: 10,588.59241

Timestep Collection Time: 2.23162
Timestep Consumption Time: 2.49214
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.72376

Cumulative Model Updates: 10,176
Cumulative Timesteps: 84,981,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,644.22706
Policy Entropy: 1.39117
Value Function Loss: 0.11361

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10992
Policy Update Magnitude: 0.28753
Value Function Update Magnitude: 0.64317

Collected Steps per Second: 22,346.42463
Overall Steps per Second: 10,454.42615

Timestep Collection Time: 2.23785
Timestep Consumption Time: 2.54558
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 4.78343

Cumulative Model Updates: 10,182
Cumulative Timesteps: 85,031,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 85031562...
Checkpoint 85031562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,249.56281
Policy Entropy: 1.41195
Value Function Loss: 0.11084

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.23962
Value Function Update Magnitude: 0.53801

Collected Steps per Second: 21,562.74701
Overall Steps per Second: 10,636.43452

Timestep Collection Time: 2.32002
Timestep Consumption Time: 2.38325
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.70327

Cumulative Model Updates: 10,188
Cumulative Timesteps: 85,081,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,885.05708
Policy Entropy: 1.39846
Value Function Loss: 0.11273

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.14926
Policy Update Magnitude: 0.22566
Value Function Update Magnitude: 0.48404

Collected Steps per Second: 22,019.64133
Overall Steps per Second: 10,607.46303

Timestep Collection Time: 2.27161
Timestep Consumption Time: 2.44394
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.71555

Cumulative Model Updates: 10,194
Cumulative Timesteps: 85,131,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 85131608...
Checkpoint 85131608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,502.72089
Policy Entropy: 1.38225
Value Function Loss: 0.11728

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10233
Policy Update Magnitude: 0.24421
Value Function Update Magnitude: 0.48468

Collected Steps per Second: 21,732.04919
Overall Steps per Second: 10,486.92519

Timestep Collection Time: 2.30093
Timestep Consumption Time: 2.46729
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.76822

Cumulative Model Updates: 10,200
Cumulative Timesteps: 85,181,612

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,056.92437
Policy Entropy: 1.37320
Value Function Loss: 0.12093

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08902
Policy Update Magnitude: 0.28780
Value Function Update Magnitude: 0.50044

Collected Steps per Second: 22,855.05384
Overall Steps per Second: 10,665.53592

Timestep Collection Time: 2.18831
Timestep Consumption Time: 2.50100
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.68931

Cumulative Model Updates: 10,206
Cumulative Timesteps: 85,231,626

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 85231626...
Checkpoint 85231626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,472.79228
Policy Entropy: 1.36283
Value Function Loss: 0.12518

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09874
Policy Update Magnitude: 0.28784
Value Function Update Magnitude: 0.49419

Collected Steps per Second: 22,537.95238
Overall Steps per Second: 10,595.33126

Timestep Collection Time: 2.21972
Timestep Consumption Time: 2.50198
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.72170

Cumulative Model Updates: 10,212
Cumulative Timesteps: 85,281,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.51538
Policy Entropy: 1.37430
Value Function Loss: 0.12107

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.24703
Value Function Update Magnitude: 0.52981

Collected Steps per Second: 22,958.23366
Overall Steps per Second: 10,773.33430

Timestep Collection Time: 2.17909
Timestep Consumption Time: 2.46460
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.64369

Cumulative Model Updates: 10,218
Cumulative Timesteps: 85,331,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 85331682...
Checkpoint 85331682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,737.25256
Policy Entropy: 1.37765
Value Function Loss: 0.12042

Mean KL Divergence: 0.03087
SB3 Clip Fraction: 0.20991
Policy Update Magnitude: 0.19407
Value Function Update Magnitude: 0.62424

Collected Steps per Second: 22,002.44030
Overall Steps per Second: 10,533.04899

Timestep Collection Time: 2.27284
Timestep Consumption Time: 2.47488
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.74772

Cumulative Model Updates: 10,224
Cumulative Timesteps: 85,381,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,201.62229
Policy Entropy: 1.36917
Value Function Loss: 0.11494

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.15564
Policy Update Magnitude: 0.20834
Value Function Update Magnitude: 0.64070

Collected Steps per Second: 22,485.14283
Overall Steps per Second: 10,367.74053

Timestep Collection Time: 2.22431
Timestep Consumption Time: 2.59969
PPO Batch Consumption Time: 0.30883
Total Iteration Time: 4.82400

Cumulative Model Updates: 10,230
Cumulative Timesteps: 85,431,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 85431704...
Checkpoint 85431704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,174.12628
Policy Entropy: 1.37046
Value Function Loss: 0.11424

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11538
Policy Update Magnitude: 0.22330
Value Function Update Magnitude: 0.57828

Collected Steps per Second: 22,439.98347
Overall Steps per Second: 10,541.22288

Timestep Collection Time: 2.22906
Timestep Consumption Time: 2.51612
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.74518

Cumulative Model Updates: 10,236
Cumulative Timesteps: 85,481,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,484.36410
Policy Entropy: 1.36831
Value Function Loss: 0.11702

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.23751
Value Function Update Magnitude: 0.48492

Collected Steps per Second: 22,935.33609
Overall Steps per Second: 10,754.50224

Timestep Collection Time: 2.18126
Timestep Consumption Time: 2.47056
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.65182

Cumulative Model Updates: 10,242
Cumulative Timesteps: 85,531,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 85531752...
Checkpoint 85531752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,177.61439
Policy Entropy: 1.36071
Value Function Loss: 0.12095

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.16563
Policy Update Magnitude: 0.22501
Value Function Update Magnitude: 0.44246

Collected Steps per Second: 22,455.49435
Overall Steps per Second: 10,642.48883

Timestep Collection Time: 2.22778
Timestep Consumption Time: 2.47281
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.70059

Cumulative Model Updates: 10,248
Cumulative Timesteps: 85,581,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,203.03385
Policy Entropy: 1.37123
Value Function Loss: 0.11691

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.22902
Value Function Update Magnitude: 0.43820

Collected Steps per Second: 21,775.45390
Overall Steps per Second: 10,568.22070

Timestep Collection Time: 2.29717
Timestep Consumption Time: 2.43607
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.73325

Cumulative Model Updates: 10,254
Cumulative Timesteps: 85,631,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 85631800...
Checkpoint 85631800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,644.53203
Policy Entropy: 1.36264
Value Function Loss: 0.12094

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08921
Policy Update Magnitude: 0.24832
Value Function Update Magnitude: 0.37147

Collected Steps per Second: 21,605.34646
Overall Steps per Second: 10,523.60546

Timestep Collection Time: 2.31452
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.75179

Cumulative Model Updates: 10,260
Cumulative Timesteps: 85,681,806

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,374.49969
Policy Entropy: 1.36474
Value Function Loss: 0.11565

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07694
Policy Update Magnitude: 0.26648
Value Function Update Magnitude: 0.42272

Collected Steps per Second: 21,840.62014
Overall Steps per Second: 10,588.52543

Timestep Collection Time: 2.29059
Timestep Consumption Time: 2.43414
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.72474

Cumulative Model Updates: 10,266
Cumulative Timesteps: 85,731,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 85731834...
Checkpoint 85731834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,292.26339
Policy Entropy: 1.36070
Value Function Loss: 0.11623

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07765
Policy Update Magnitude: 0.28854
Value Function Update Magnitude: 0.46653

Collected Steps per Second: 21,622.05543
Overall Steps per Second: 10,491.38470

Timestep Collection Time: 2.31264
Timestep Consumption Time: 2.45356
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.76620

Cumulative Model Updates: 10,272
Cumulative Timesteps: 85,781,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,334.22855
Policy Entropy: 1.36118
Value Function Loss: 0.11288

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.27611
Value Function Update Magnitude: 0.53214

Collected Steps per Second: 22,138.74763
Overall Steps per Second: 10,660.67664

Timestep Collection Time: 2.25993
Timestep Consumption Time: 2.43321
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.69314

Cumulative Model Updates: 10,278
Cumulative Timesteps: 85,831,870

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 85831870...
Checkpoint 85831870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,794.87724
Policy Entropy: 1.36010
Value Function Loss: 0.10851

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10048
Policy Update Magnitude: 0.27350
Value Function Update Magnitude: 0.62147

Collected Steps per Second: 21,801.18641
Overall Steps per Second: 10,577.87533

Timestep Collection Time: 2.29474
Timestep Consumption Time: 2.43476
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.72949

Cumulative Model Updates: 10,284
Cumulative Timesteps: 85,881,898

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.48354
Policy Entropy: 1.35536
Value Function Loss: 0.11724

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10760
Policy Update Magnitude: 0.27692
Value Function Update Magnitude: 0.59114

Collected Steps per Second: 22,336.56548
Overall Steps per Second: 10,495.98468

Timestep Collection Time: 2.23983
Timestep Consumption Time: 2.52676
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.76658

Cumulative Model Updates: 10,290
Cumulative Timesteps: 85,931,928

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 85931928...
Checkpoint 85931928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,840.03367
Policy Entropy: 1.35650
Value Function Loss: 0.11715

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.15487
Policy Update Magnitude: 0.25346
Value Function Update Magnitude: 0.56651

Collected Steps per Second: 21,770.61107
Overall Steps per Second: 10,422.60419

Timestep Collection Time: 2.29713
Timestep Consumption Time: 2.50109
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.79822

Cumulative Model Updates: 10,296
Cumulative Timesteps: 85,981,938

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,473.60034
Policy Entropy: 1.35532
Value Function Loss: 0.12638

Mean KL Divergence: 0.03537
SB3 Clip Fraction: 0.22254
Policy Update Magnitude: 0.20022
Value Function Update Magnitude: 0.54036

Collected Steps per Second: 22,484.23450
Overall Steps per Second: 10,523.43835

Timestep Collection Time: 2.22378
Timestep Consumption Time: 2.52752
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.75130

Cumulative Model Updates: 10,302
Cumulative Timesteps: 86,031,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 86031938...
Checkpoint 86031938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881.08276
Policy Entropy: 1.37485
Value Function Loss: 0.12920

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.16899
Policy Update Magnitude: 0.21610
Value Function Update Magnitude: 0.56343

Collected Steps per Second: 22,010.76955
Overall Steps per Second: 10,503.83909

Timestep Collection Time: 2.27280
Timestep Consumption Time: 2.48984
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.76264

Cumulative Model Updates: 10,308
Cumulative Timesteps: 86,081,964

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,635.10583
Policy Entropy: 1.38175
Value Function Loss: 0.13530

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.22956
Value Function Update Magnitude: 0.52756

Collected Steps per Second: 22,571.52474
Overall Steps per Second: 10,556.82537

Timestep Collection Time: 2.21598
Timestep Consumption Time: 2.52200
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.73798

Cumulative Model Updates: 10,314
Cumulative Timesteps: 86,131,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 86131982...
Checkpoint 86131982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,800.58275
Policy Entropy: 1.38936
Value Function Loss: 0.13163

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14631
Policy Update Magnitude: 0.22136
Value Function Update Magnitude: 0.50763

Collected Steps per Second: 21,662.22413
Overall Steps per Second: 10,401.14055

Timestep Collection Time: 2.30964
Timestep Consumption Time: 2.50060
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.81024

Cumulative Model Updates: 10,320
Cumulative Timesteps: 86,182,014

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,254.24100
Policy Entropy: 1.39261
Value Function Loss: 0.12602

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14920
Policy Update Magnitude: 0.20604
Value Function Update Magnitude: 0.48128

Collected Steps per Second: 22,863.03023
Overall Steps per Second: 10,722.36088

Timestep Collection Time: 2.18851
Timestep Consumption Time: 2.47800
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.66651

Cumulative Model Updates: 10,326
Cumulative Timesteps: 86,232,050

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 86232050...
Checkpoint 86232050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,541.18279
Policy Entropy: 1.40916
Value Function Loss: 0.12237

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13643
Policy Update Magnitude: 0.19208
Value Function Update Magnitude: 0.48044

Collected Steps per Second: 22,062.35063
Overall Steps per Second: 10,602.44890

Timestep Collection Time: 2.26649
Timestep Consumption Time: 2.44978
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.71627

Cumulative Model Updates: 10,332
Cumulative Timesteps: 86,282,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,382.12463
Policy Entropy: 1.39901
Value Function Loss: 0.11615

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.20533
Value Function Update Magnitude: 0.54545

Collected Steps per Second: 22,605.31445
Overall Steps per Second: 10,559.51632

Timestep Collection Time: 2.21311
Timestep Consumption Time: 2.52461
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.73772

Cumulative Model Updates: 10,338
Cumulative Timesteps: 86,332,082

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 86332082...
Checkpoint 86332082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,022.58478
Policy Entropy: 1.40562
Value Function Loss: 0.11931

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.19786
Policy Update Magnitude: 0.19608
Value Function Update Magnitude: 0.51767

Collected Steps per Second: 21,674.69227
Overall Steps per Second: 10,511.87084

Timestep Collection Time: 2.30693
Timestep Consumption Time: 2.44979
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.75672

Cumulative Model Updates: 10,344
Cumulative Timesteps: 86,382,084

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570.73210
Policy Entropy: 1.40140
Value Function Loss: 0.11940

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.17691
Policy Update Magnitude: 0.21569
Value Function Update Magnitude: 0.49247

Collected Steps per Second: 22,637.97970
Overall Steps per Second: 10,593.67904

Timestep Collection Time: 2.20894
Timestep Consumption Time: 2.51142
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.72036

Cumulative Model Updates: 10,350
Cumulative Timesteps: 86,432,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 86432090...
Checkpoint 86432090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,109.16150
Policy Entropy: 1.40689
Value Function Loss: 0.12253

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.16170
Policy Update Magnitude: 0.21402
Value Function Update Magnitude: 0.42748

Collected Steps per Second: 22,381.97642
Overall Steps per Second: 10,532.75113

Timestep Collection Time: 2.23466
Timestep Consumption Time: 2.51396
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.74862

Cumulative Model Updates: 10,356
Cumulative Timesteps: 86,482,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488.85655
Policy Entropy: 1.41105
Value Function Loss: 0.13097

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14339
Policy Update Magnitude: 0.21901
Value Function Update Magnitude: 0.40657

Collected Steps per Second: 22,854.93738
Overall Steps per Second: 10,663.05968

Timestep Collection Time: 2.18780
Timestep Consumption Time: 2.50147
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.68927

Cumulative Model Updates: 10,362
Cumulative Timesteps: 86,532,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 86532108...
Checkpoint 86532108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,099.28375
Policy Entropy: 1.41154
Value Function Loss: 0.12963

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.21755
Value Function Update Magnitude: 0.41721

Collected Steps per Second: 22,245.62988
Overall Steps per Second: 10,467.47406

Timestep Collection Time: 2.24817
Timestep Consumption Time: 2.52968
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.77785

Cumulative Model Updates: 10,368
Cumulative Timesteps: 86,582,120

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,297.97693
Policy Entropy: 1.41257
Value Function Loss: 0.12386

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.26292
Value Function Update Magnitude: 0.43567

Collected Steps per Second: 22,546.19239
Overall Steps per Second: 10,582.14171

Timestep Collection Time: 2.21953
Timestep Consumption Time: 2.50938
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.72891

Cumulative Model Updates: 10,374
Cumulative Timesteps: 86,632,162

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 86632162...
Checkpoint 86632162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,221.18526
Policy Entropy: 1.40939
Value Function Loss: 0.11251

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11190
Policy Update Magnitude: 0.27710
Value Function Update Magnitude: 0.50950

Collected Steps per Second: 22,230.71889
Overall Steps per Second: 10,465.40502

Timestep Collection Time: 2.24977
Timestep Consumption Time: 2.52921
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.77898

Cumulative Model Updates: 10,380
Cumulative Timesteps: 86,682,176

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,129.59547
Policy Entropy: 1.41359
Value Function Loss: 0.10687

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.24802
Value Function Update Magnitude: 0.59675

Collected Steps per Second: 22,018.31470
Overall Steps per Second: 10,634.85170

Timestep Collection Time: 2.27156
Timestep Consumption Time: 2.43146
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.70303

Cumulative Model Updates: 10,386
Cumulative Timesteps: 86,732,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 86732192...
Checkpoint 86732192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,169.57756
Policy Entropy: 1.41578
Value Function Loss: 0.11132

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.23253
Value Function Update Magnitude: 0.58604

Collected Steps per Second: 21,466.18756
Overall Steps per Second: 10,393.46740

Timestep Collection Time: 2.33027
Timestep Consumption Time: 2.48256
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.81283

Cumulative Model Updates: 10,392
Cumulative Timesteps: 86,782,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,400.06491
Policy Entropy: 1.42180
Value Function Loss: 0.11131

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10784
Policy Update Magnitude: 0.26570
Value Function Update Magnitude: 0.60296

Collected Steps per Second: 22,351.85749
Overall Steps per Second: 10,570.22087

Timestep Collection Time: 2.23758
Timestep Consumption Time: 2.49402
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.73159

Cumulative Model Updates: 10,398
Cumulative Timesteps: 86,832,228

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 86832228...
Checkpoint 86832228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.88431
Policy Entropy: 1.42342
Value Function Loss: 0.11369

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12797
Policy Update Magnitude: 0.26973
Value Function Update Magnitude: 0.64607

Collected Steps per Second: 22,497.97838
Overall Steps per Second: 10,621.52128

Timestep Collection Time: 2.22260
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.70780

Cumulative Model Updates: 10,404
Cumulative Timesteps: 86,882,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899.15698
Policy Entropy: 1.42391
Value Function Loss: 0.11275

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.15190
Policy Update Magnitude: 0.22960
Value Function Update Magnitude: 0.64275

Collected Steps per Second: 22,730.84222
Overall Steps per Second: 10,609.16113

Timestep Collection Time: 2.19983
Timestep Consumption Time: 2.51345
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.71328

Cumulative Model Updates: 10,410
Cumulative Timesteps: 86,932,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 86932236...
Checkpoint 86932236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,819.39019
Policy Entropy: 1.41371
Value Function Loss: 0.11658

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.15490
Policy Update Magnitude: 0.22399
Value Function Update Magnitude: 0.56798

Collected Steps per Second: 21,749.25303
Overall Steps per Second: 10,541.29664

Timestep Collection Time: 2.29985
Timestep Consumption Time: 2.44530
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.74515

Cumulative Model Updates: 10,416
Cumulative Timesteps: 86,982,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,246.84099
Policy Entropy: 1.41784
Value Function Loss: 0.11647

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.13986
Policy Update Magnitude: 0.21216
Value Function Update Magnitude: 0.49730

Collected Steps per Second: 21,809.45379
Overall Steps per Second: 10,593.09312

Timestep Collection Time: 2.29313
Timestep Consumption Time: 2.42806
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.72119

Cumulative Model Updates: 10,422
Cumulative Timesteps: 87,032,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 87032268...
Checkpoint 87032268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,861.09865
Policy Entropy: 1.40778
Value Function Loss: 0.11433

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.15608
Policy Update Magnitude: 0.20831
Value Function Update Magnitude: 0.48914

Collected Steps per Second: 21,913.06107
Overall Steps per Second: 10,633.24844

Timestep Collection Time: 2.28174
Timestep Consumption Time: 2.42049
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.70223

Cumulative Model Updates: 10,428
Cumulative Timesteps: 87,082,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,407.08478
Policy Entropy: 1.41831
Value Function Loss: 0.11248

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.14920
Policy Update Magnitude: 0.23094
Value Function Update Magnitude: 0.45032

Collected Steps per Second: 22,186.89709
Overall Steps per Second: 10,719.59382

Timestep Collection Time: 2.25511
Timestep Consumption Time: 2.41241
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.66753

Cumulative Model Updates: 10,434
Cumulative Timesteps: 87,132,302

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 87132302...
Checkpoint 87132302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.38246
Policy Entropy: 1.39797
Value Function Loss: 0.11354

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.14676
Policy Update Magnitude: 0.23475
Value Function Update Magnitude: 0.52558

Collected Steps per Second: 21,683.80790
Overall Steps per Second: 10,672.71683

Timestep Collection Time: 2.30651
Timestep Consumption Time: 2.37964
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.68615

Cumulative Model Updates: 10,440
Cumulative Timesteps: 87,182,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,257.92003
Policy Entropy: 1.40222
Value Function Loss: 0.11151

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.25915
Value Function Update Magnitude: 0.57909

Collected Steps per Second: 22,180.51020
Overall Steps per Second: 10,803.84593

Timestep Collection Time: 2.25477
Timestep Consumption Time: 2.37432
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.62909

Cumulative Model Updates: 10,446
Cumulative Timesteps: 87,232,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 87232328...
Checkpoint 87232328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,694.81177
Policy Entropy: 1.41291
Value Function Loss: 0.10184

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.27834
Value Function Update Magnitude: 0.59957

Collected Steps per Second: 21,564.70189
Overall Steps per Second: 10,620.00401

Timestep Collection Time: 2.31879
Timestep Consumption Time: 2.38968
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.70847

Cumulative Model Updates: 10,452
Cumulative Timesteps: 87,282,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,015.64380
Policy Entropy: 1.41254
Value Function Loss: 0.10829

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.26055
Value Function Update Magnitude: 0.60598

Collected Steps per Second: 21,930.35431
Overall Steps per Second: 10,554.92972

Timestep Collection Time: 2.28095
Timestep Consumption Time: 2.45826
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.73921

Cumulative Model Updates: 10,458
Cumulative Timesteps: 87,332,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 87332354...
Checkpoint 87332354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,536.44125
Policy Entropy: 1.41261
Value Function Loss: 0.10899

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.24457
Value Function Update Magnitude: 0.63808

Collected Steps per Second: 21,299.91681
Overall Steps per Second: 10,564.32010

Timestep Collection Time: 2.34771
Timestep Consumption Time: 2.38577
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.73348

Cumulative Model Updates: 10,464
Cumulative Timesteps: 87,382,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,015.91002
Policy Entropy: 1.38789
Value Function Loss: 0.11191

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.22716
Value Function Update Magnitude: 0.64020

Collected Steps per Second: 21,979.80022
Overall Steps per Second: 10,398.87997

Timestep Collection Time: 2.27536
Timestep Consumption Time: 2.53400
PPO Batch Consumption Time: 0.31062
Total Iteration Time: 4.80936

Cumulative Model Updates: 10,470
Cumulative Timesteps: 87,432,372

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 87432372...
Checkpoint 87432372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,389.35234
Policy Entropy: 1.39959
Value Function Loss: 0.10955

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.22841
Value Function Update Magnitude: 0.65843

Collected Steps per Second: 21,551.20594
Overall Steps per Second: 10,578.10505

Timestep Collection Time: 2.32071
Timestep Consumption Time: 2.40736
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.72807

Cumulative Model Updates: 10,476
Cumulative Timesteps: 87,482,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 956.56276
Policy Entropy: 1.38396
Value Function Loss: 0.11256

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.23511
Value Function Update Magnitude: 0.67631

Collected Steps per Second: 22,842.49043
Overall Steps per Second: 10,620.77791

Timestep Collection Time: 2.18987
Timestep Consumption Time: 2.51996
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.70982

Cumulative Model Updates: 10,482
Cumulative Timesteps: 87,532,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 87532408...
Checkpoint 87532408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864.18334
Policy Entropy: 1.39103
Value Function Loss: 0.11015

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11945
Policy Update Magnitude: 0.23623
Value Function Update Magnitude: 0.64968

Collected Steps per Second: 20,997.81432
Overall Steps per Second: 10,323.95133

Timestep Collection Time: 2.38196
Timestep Consumption Time: 2.46269
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.84466

Cumulative Model Updates: 10,488
Cumulative Timesteps: 87,582,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,120.67991
Policy Entropy: 1.39454
Value Function Loss: 0.10820

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.24624
Value Function Update Magnitude: 0.63050

Collected Steps per Second: 22,326.84881
Overall Steps per Second: 10,833.17540

Timestep Collection Time: 2.23946
Timestep Consumption Time: 2.37600
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.61545

Cumulative Model Updates: 10,494
Cumulative Timesteps: 87,632,424

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 87632424...
Checkpoint 87632424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,159.00664
Policy Entropy: 1.39955
Value Function Loss: 0.10524

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.25589
Value Function Update Magnitude: 0.60601

Collected Steps per Second: 21,562.55821
Overall Steps per Second: 10,649.41866

Timestep Collection Time: 2.31967
Timestep Consumption Time: 2.37711
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.69678

Cumulative Model Updates: 10,500
Cumulative Timesteps: 87,682,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,055.81269
Policy Entropy: 1.39237
Value Function Loss: 0.10842

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07744
Policy Update Magnitude: 0.29651
Value Function Update Magnitude: 0.63691

Collected Steps per Second: 22,743.82634
Overall Steps per Second: 10,748.97545

Timestep Collection Time: 2.19919
Timestep Consumption Time: 2.45409
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.65328

Cumulative Model Updates: 10,506
Cumulative Timesteps: 87,732,460

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 87732460...
Checkpoint 87732460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.87014
Policy Entropy: 1.39120
Value Function Loss: 0.11055

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.32566
Value Function Update Magnitude: 0.58667

Collected Steps per Second: 21,486.93377
Overall Steps per Second: 10,641.55559

Timestep Collection Time: 2.32923
Timestep Consumption Time: 2.37384
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.70307

Cumulative Model Updates: 10,512
Cumulative Timesteps: 87,782,508

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,422.67892
Policy Entropy: 1.40096
Value Function Loss: 0.10964

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.31449
Value Function Update Magnitude: 0.47038

Collected Steps per Second: 21,750.53036
Overall Steps per Second: 10,569.73835

Timestep Collection Time: 2.30036
Timestep Consumption Time: 2.43335
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.73370

Cumulative Model Updates: 10,518
Cumulative Timesteps: 87,832,542

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 87832542...
Checkpoint 87832542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,719.61654
Policy Entropy: 1.41029
Value Function Loss: 0.11668

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10962
Policy Update Magnitude: 0.28831
Value Function Update Magnitude: 0.43704

Collected Steps per Second: 21,354.15054
Overall Steps per Second: 10,571.14499

Timestep Collection Time: 2.34165
Timestep Consumption Time: 2.38858
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.73023

Cumulative Model Updates: 10,524
Cumulative Timesteps: 87,882,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,262.36393
Policy Entropy: 1.40311
Value Function Loss: 0.11036

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.11875
Policy Update Magnitude: 0.29348
Value Function Update Magnitude: 0.49701

Collected Steps per Second: 22,143.15744
Overall Steps per Second: 10,647.26583

Timestep Collection Time: 2.25849
Timestep Consumption Time: 2.43849
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.69698

Cumulative Model Updates: 10,530
Cumulative Timesteps: 87,932,556

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 87932556...
Checkpoint 87932556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,882.40165
Policy Entropy: 1.39923
Value Function Loss: 0.11612

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11810
Policy Update Magnitude: 0.30313
Value Function Update Magnitude: 0.53272

Collected Steps per Second: 21,495.75087
Overall Steps per Second: 10,473.26133

Timestep Collection Time: 2.32827
Timestep Consumption Time: 2.45037
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.77865

Cumulative Model Updates: 10,536
Cumulative Timesteps: 87,982,604

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,319.49840
Policy Entropy: 1.39525
Value Function Loss: 0.11412

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.31938
Value Function Update Magnitude: 0.53538

Collected Steps per Second: 22,060.26441
Overall Steps per Second: 10,611.65250

Timestep Collection Time: 2.26679
Timestep Consumption Time: 2.44558
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.71237

Cumulative Model Updates: 10,542
Cumulative Timesteps: 88,032,610

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 88032610...
Checkpoint 88032610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,436.34173
Policy Entropy: 1.39525
Value Function Loss: 0.11884

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.32519
Value Function Update Magnitude: 0.47763

Collected Steps per Second: 21,582.67328
Overall Steps per Second: 10,467.29560

Timestep Collection Time: 2.31741
Timestep Consumption Time: 2.46090
PPO Batch Consumption Time: 0.29821
Total Iteration Time: 4.77831

Cumulative Model Updates: 10,548
Cumulative Timesteps: 88,082,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.93767
Policy Entropy: 1.39635
Value Function Loss: 0.11493

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.32485
Value Function Update Magnitude: 0.51802

Collected Steps per Second: 21,569.49403
Overall Steps per Second: 10,320.29588

Timestep Collection Time: 2.31855
Timestep Consumption Time: 2.52724
PPO Batch Consumption Time: 0.30863
Total Iteration Time: 4.84579

Cumulative Model Updates: 10,554
Cumulative Timesteps: 88,132,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 88132636...
Checkpoint 88132636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,593.42995
Policy Entropy: 1.40371
Value Function Loss: 0.10796

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.30616
Value Function Update Magnitude: 0.57211

Collected Steps per Second: 21,522.36626
Overall Steps per Second: 10,483.00946

Timestep Collection Time: 2.32447
Timestep Consumption Time: 2.44783
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.77229

Cumulative Model Updates: 10,560
Cumulative Timesteps: 88,182,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,668.37274
Policy Entropy: 1.40563
Value Function Loss: 0.10952

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.29992
Value Function Update Magnitude: 0.52365

Collected Steps per Second: 22,034.40338
Overall Steps per Second: 10,782.25065

Timestep Collection Time: 2.27154
Timestep Consumption Time: 2.37053
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.64207

Cumulative Model Updates: 10,566
Cumulative Timesteps: 88,232,716

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 88232716...
Checkpoint 88232716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,895.55681
Policy Entropy: 1.40858
Value Function Loss: 0.11241

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.12615
Policy Update Magnitude: 0.30454
Value Function Update Magnitude: 0.45377

Collected Steps per Second: 21,525.41007
Overall Steps per Second: 10,625.35026

Timestep Collection Time: 2.32339
Timestep Consumption Time: 2.38346
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.70686

Cumulative Model Updates: 10,572
Cumulative Timesteps: 88,282,728

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,987.26887
Policy Entropy: 1.40100
Value Function Loss: 0.11361

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.17601
Policy Update Magnitude: 0.25710
Value Function Update Magnitude: 0.45231

Collected Steps per Second: 21,928.94274
Overall Steps per Second: 10,566.60236

Timestep Collection Time: 2.28046
Timestep Consumption Time: 2.45219
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.73265

Cumulative Model Updates: 10,578
Cumulative Timesteps: 88,332,736

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 88332736...
Checkpoint 88332736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,223.37652
Policy Entropy: 1.38343
Value Function Loss: 0.11584

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.16305
Policy Update Magnitude: 0.22582
Value Function Update Magnitude: 0.48730

Collected Steps per Second: 21,595.78598
Overall Steps per Second: 10,577.70805

Timestep Collection Time: 2.31693
Timestep Consumption Time: 2.41339
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.73033

Cumulative Model Updates: 10,584
Cumulative Timesteps: 88,382,772

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,175.94925
Policy Entropy: 1.37708
Value Function Loss: 0.11984

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.21902
Value Function Update Magnitude: 0.55453

Collected Steps per Second: 22,076.44756
Overall Steps per Second: 10,655.38750

Timestep Collection Time: 2.26558
Timestep Consumption Time: 2.42838
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.69396

Cumulative Model Updates: 10,590
Cumulative Timesteps: 88,432,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 88432788...
Checkpoint 88432788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,851.64245
Policy Entropy: 1.36533
Value Function Loss: 0.12666

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.24310
Value Function Update Magnitude: 0.54404

Collected Steps per Second: 22,385.19986
Overall Steps per Second: 10,527.66372

Timestep Collection Time: 2.23371
Timestep Consumption Time: 2.51587
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.74958

Cumulative Model Updates: 10,596
Cumulative Timesteps: 88,482,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,538.85046
Policy Entropy: 1.37620
Value Function Loss: 0.12360

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11344
Policy Update Magnitude: 0.27345
Value Function Update Magnitude: 0.48703

Collected Steps per Second: 22,999.11197
Overall Steps per Second: 10,825.23879

Timestep Collection Time: 2.17504
Timestep Consumption Time: 2.44601
PPO Batch Consumption Time: 0.28190
Total Iteration Time: 4.62105

Cumulative Model Updates: 10,602
Cumulative Timesteps: 88,532,814

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 88532814...
Checkpoint 88532814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,488.15596
Policy Entropy: 1.37557
Value Function Loss: 0.11954

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.26777
Value Function Update Magnitude: 0.46279

Collected Steps per Second: 22,311.63234
Overall Steps per Second: 10,660.87581

Timestep Collection Time: 2.24143
Timestep Consumption Time: 2.44955
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.69098

Cumulative Model Updates: 10,608
Cumulative Timesteps: 88,582,824

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,394.14386
Policy Entropy: 1.38367
Value Function Loss: 0.11399

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.24741
Value Function Update Magnitude: 0.45987

Collected Steps per Second: 21,768.44378
Overall Steps per Second: 10,556.00654

Timestep Collection Time: 2.29699
Timestep Consumption Time: 2.43983
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.73683

Cumulative Model Updates: 10,614
Cumulative Timesteps: 88,632,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 88632826...
Checkpoint 88632826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,576.52646
Policy Entropy: 1.39077
Value Function Loss: 0.12086

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.24856
Value Function Update Magnitude: 0.47458

Collected Steps per Second: 21,540.40614
Overall Steps per Second: 10,501.30742

Timestep Collection Time: 2.32122
Timestep Consumption Time: 2.44009
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.76131

Cumulative Model Updates: 10,620
Cumulative Timesteps: 88,682,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,336.01067
Policy Entropy: 1.38568
Value Function Loss: 0.12118

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08761
Policy Update Magnitude: 0.28029
Value Function Update Magnitude: 0.48940

Collected Steps per Second: 22,972.66928
Overall Steps per Second: 10,675.31722

Timestep Collection Time: 2.17728
Timestep Consumption Time: 2.50810
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.68539

Cumulative Model Updates: 10,626
Cumulative Timesteps: 88,732,844

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 88732844...
Checkpoint 88732844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,233.20129
Policy Entropy: 1.38685
Value Function Loss: 0.12184

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.29882
Value Function Update Magnitude: 0.46400

Collected Steps per Second: 21,542.49242
Overall Steps per Second: 10,381.58101

Timestep Collection Time: 2.32192
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.30472
Total Iteration Time: 4.81815

Cumulative Model Updates: 10,632
Cumulative Timesteps: 88,782,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,435.87471
Policy Entropy: 1.38795
Value Function Loss: 0.12054

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.29331
Value Function Update Magnitude: 0.45989

Collected Steps per Second: 22,231.06877
Overall Steps per Second: 10,523.03269

Timestep Collection Time: 2.24946
Timestep Consumption Time: 2.50278
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.75224

Cumulative Model Updates: 10,638
Cumulative Timesteps: 88,832,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 88832872...
Checkpoint 88832872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,898.90698
Policy Entropy: 1.39495
Value Function Loss: 0.11903

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.24299
Value Function Update Magnitude: 0.49446

Collected Steps per Second: 22,156.52272
Overall Steps per Second: 10,626.29996

Timestep Collection Time: 2.25694
Timestep Consumption Time: 2.44893
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.70587

Cumulative Model Updates: 10,644
Cumulative Timesteps: 88,882,878

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,956.13870
Policy Entropy: 1.38553
Value Function Loss: 0.11522

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.14041
Policy Update Magnitude: 0.22405
Value Function Update Magnitude: 0.54552

Collected Steps per Second: 21,828.10559
Overall Steps per Second: 10,533.96666

Timestep Collection Time: 2.29099
Timestep Consumption Time: 2.45632
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.74731

Cumulative Model Updates: 10,650
Cumulative Timesteps: 88,932,886

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 88932886...
Checkpoint 88932886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,530.90481
Policy Entropy: 1.40164
Value Function Loss: 0.11387

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.22130
Value Function Update Magnitude: 0.52328

Collected Steps per Second: 21,516.63002
Overall Steps per Second: 10,491.62752

Timestep Collection Time: 2.32564
Timestep Consumption Time: 2.44387
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.76952

Cumulative Model Updates: 10,656
Cumulative Timesteps: 88,982,926

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,521.14030
Policy Entropy: 1.40760
Value Function Loss: 0.11074

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11908
Policy Update Magnitude: 0.23451
Value Function Update Magnitude: 0.49764

Collected Steps per Second: 21,845.28421
Overall Steps per Second: 10,519.45148

Timestep Collection Time: 2.29020
Timestep Consumption Time: 2.46575
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.75595

Cumulative Model Updates: 10,662
Cumulative Timesteps: 89,032,956

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 89032956...
Checkpoint 89032956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,916.12740
Policy Entropy: 1.42128
Value Function Loss: 0.11405

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.11160
Policy Update Magnitude: 0.24473
Value Function Update Magnitude: 0.50138

Collected Steps per Second: 21,559.98663
Overall Steps per Second: 10,640.61209

Timestep Collection Time: 2.31911
Timestep Consumption Time: 2.37987
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.69898

Cumulative Model Updates: 10,668
Cumulative Timesteps: 89,082,956

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,400.47873
Policy Entropy: 1.40653
Value Function Loss: 0.11520

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.24985
Value Function Update Magnitude: 0.48153

Collected Steps per Second: 21,587.15854
Overall Steps per Second: 10,444.20597

Timestep Collection Time: 2.31693
Timestep Consumption Time: 2.47194
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.78888

Cumulative Model Updates: 10,674
Cumulative Timesteps: 89,132,972

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 89132972...
Checkpoint 89132972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,232.54074
Policy Entropy: 1.38243
Value Function Loss: 0.12288

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.22850
Value Function Update Magnitude: 0.49997

Collected Steps per Second: 21,643.51252
Overall Steps per Second: 10,689.21817

Timestep Collection Time: 2.31062
Timestep Consumption Time: 2.36792
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.67855

Cumulative Model Updates: 10,680
Cumulative Timesteps: 89,182,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,527.71492
Policy Entropy: 1.37552
Value Function Loss: 0.12109

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10938
Policy Update Magnitude: 0.24500
Value Function Update Magnitude: 0.53071

Collected Steps per Second: 21,968.54191
Overall Steps per Second: 10,617.67447

Timestep Collection Time: 2.27707
Timestep Consumption Time: 2.43432
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.71139

Cumulative Model Updates: 10,686
Cumulative Timesteps: 89,233,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 89233006...
Checkpoint 89233006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,801.29104
Policy Entropy: 1.38285
Value Function Loss: 0.11662

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.14482
Policy Update Magnitude: 0.22747
Value Function Update Magnitude: 0.59233

Collected Steps per Second: 21,927.79921
Overall Steps per Second: 10,609.01928

Timestep Collection Time: 2.28030
Timestep Consumption Time: 2.43286
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.71316

Cumulative Model Updates: 10,692
Cumulative Timesteps: 89,283,008

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,359.91907
Policy Entropy: 1.38729
Value Function Loss: 0.10838

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10038
Policy Update Magnitude: 0.24493
Value Function Update Magnitude: 0.64930

Collected Steps per Second: 22,447.90620
Overall Steps per Second: 10,740.33836

Timestep Collection Time: 2.22791
Timestep Consumption Time: 2.42855
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.65646

Cumulative Model Updates: 10,698
Cumulative Timesteps: 89,333,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 89333020...
Checkpoint 89333020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,295.74427
Policy Entropy: 1.39129
Value Function Loss: 0.10241

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.25292
Value Function Update Magnitude: 0.64621

Collected Steps per Second: 21,711.78200
Overall Steps per Second: 10,692.83450

Timestep Collection Time: 2.30400
Timestep Consumption Time: 2.37427
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.67827

Cumulative Model Updates: 10,704
Cumulative Timesteps: 89,383,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,720.43706
Policy Entropy: 1.38091
Value Function Loss: 0.10058

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.15900
Policy Update Magnitude: 0.22392
Value Function Update Magnitude: 0.64708

Collected Steps per Second: 21,661.57910
Overall Steps per Second: 10,597.90736

Timestep Collection Time: 2.30916
Timestep Consumption Time: 2.41064
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.71980

Cumulative Model Updates: 10,710
Cumulative Timesteps: 89,433,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 89433064...
Checkpoint 89433064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,322.23334
Policy Entropy: 1.37696
Value Function Loss: 0.10372

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.14830
Policy Update Magnitude: 0.23214
Value Function Update Magnitude: 0.63735

Collected Steps per Second: 21,136.42525
Overall Steps per Second: 10,466.05072

Timestep Collection Time: 2.36719
Timestep Consumption Time: 2.41341
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.78060

Cumulative Model Updates: 10,716
Cumulative Timesteps: 89,483,098

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,074.96452
Policy Entropy: 1.37477
Value Function Loss: 0.10478

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14956
Policy Update Magnitude: 0.23613
Value Function Update Magnitude: 0.63470

Collected Steps per Second: 21,894.80939
Overall Steps per Second: 10,570.23673

Timestep Collection Time: 2.28429
Timestep Consumption Time: 2.44730
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.73159

Cumulative Model Updates: 10,722
Cumulative Timesteps: 89,533,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 89533112...
Checkpoint 89533112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,325.90877
Policy Entropy: 1.37343
Value Function Loss: 0.10463

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.15983
Policy Update Magnitude: 0.22034
Value Function Update Magnitude: 0.64062

Collected Steps per Second: 21,960.41162
Overall Steps per Second: 10,558.31760

Timestep Collection Time: 2.27701
Timestep Consumption Time: 2.45898
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.73598

Cumulative Model Updates: 10,728
Cumulative Timesteps: 89,583,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,201.93277
Policy Entropy: 1.36020
Value Function Loss: 0.10562

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.24688
Value Function Update Magnitude: 0.64528

Collected Steps per Second: 21,963.40629
Overall Steps per Second: 10,451.25715

Timestep Collection Time: 2.27770
Timestep Consumption Time: 2.50890
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.78660

Cumulative Model Updates: 10,734
Cumulative Timesteps: 89,633,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 89633142...
Checkpoint 89633142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,823.60469
Policy Entropy: 1.34819
Value Function Loss: 0.11452

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07793
Policy Update Magnitude: 0.30322
Value Function Update Magnitude: 0.64931

Collected Steps per Second: 22,392.76498
Overall Steps per Second: 10,754.01258

Timestep Collection Time: 2.23376
Timestep Consumption Time: 2.41753
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.65129

Cumulative Model Updates: 10,740
Cumulative Timesteps: 89,683,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,724.55281
Policy Entropy: 1.34761
Value Function Loss: 0.11828

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.29891
Value Function Update Magnitude: 0.66187

Collected Steps per Second: 22,244.11068
Overall Steps per Second: 10,762.57428

Timestep Collection Time: 2.24878
Timestep Consumption Time: 2.39900
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.64777

Cumulative Model Updates: 10,746
Cumulative Timesteps: 89,733,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 89733184...
Checkpoint 89733184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,788.47151
Policy Entropy: 1.33279
Value Function Loss: 0.11690

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07295
Policy Update Magnitude: 0.30485
Value Function Update Magnitude: 0.64520

Collected Steps per Second: 21,476.88052
Overall Steps per Second: 10,599.97193

Timestep Collection Time: 2.32911
Timestep Consumption Time: 2.38996
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.71907

Cumulative Model Updates: 10,752
Cumulative Timesteps: 89,783,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,012.35465
Policy Entropy: 1.34527
Value Function Loss: 0.11439

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06839
Policy Update Magnitude: 0.31633
Value Function Update Magnitude: 0.55184

Collected Steps per Second: 21,888.48429
Overall Steps per Second: 10,470.03384

Timestep Collection Time: 2.28623
Timestep Consumption Time: 2.49332
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.77955

Cumulative Model Updates: 10,758
Cumulative Timesteps: 89,833,248

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 89833248...
Checkpoint 89833248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,425.73759
Policy Entropy: 1.35315
Value Function Loss: 0.11385

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06853
Policy Update Magnitude: 0.31489
Value Function Update Magnitude: 0.48685

Collected Steps per Second: 22,045.09871
Overall Steps per Second: 10,630.49581

Timestep Collection Time: 2.26908
Timestep Consumption Time: 2.43644
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.70552

Cumulative Model Updates: 10,764
Cumulative Timesteps: 89,883,270

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.15243
Policy Entropy: 1.34818
Value Function Loss: 0.11978

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07160
Policy Update Magnitude: 0.31223
Value Function Update Magnitude: 0.47715

Collected Steps per Second: 22,576.97023
Overall Steps per Second: 10,615.73649

Timestep Collection Time: 2.21553
Timestep Consumption Time: 2.49634
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.71187

Cumulative Model Updates: 10,770
Cumulative Timesteps: 89,933,290

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 89933290...
Checkpoint 89933290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,447.53996
Policy Entropy: 1.34684
Value Function Loss: 0.11739

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07563
Policy Update Magnitude: 0.30154
Value Function Update Magnitude: 0.48320

Collected Steps per Second: 22,398.40498
Overall Steps per Second: 10,562.69513

Timestep Collection Time: 2.23355
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.73629

Cumulative Model Updates: 10,776
Cumulative Timesteps: 89,983,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,557.35667
Policy Entropy: 1.34583
Value Function Loss: 0.11832

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.29977
Value Function Update Magnitude: 0.45342

Collected Steps per Second: 22,632.08619
Overall Steps per Second: 10,781.57517

Timestep Collection Time: 2.20987
Timestep Consumption Time: 2.42897
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.63884

Cumulative Model Updates: 10,782
Cumulative Timesteps: 90,033,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 90033332...
Checkpoint 90033332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,941.48747
Policy Entropy: 1.33878
Value Function Loss: 0.11650

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08330
Policy Update Magnitude: 0.29318
Value Function Update Magnitude: 0.46906

Collected Steps per Second: 22,088.41114
Overall Steps per Second: 10,565.60167

Timestep Collection Time: 2.26454
Timestep Consumption Time: 2.46970
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.73423

Cumulative Model Updates: 10,788
Cumulative Timesteps: 90,083,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,512.91688
Policy Entropy: 1.33241
Value Function Loss: 0.11503

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11732
Policy Update Magnitude: 0.28817
Value Function Update Magnitude: 0.54871

Collected Steps per Second: 22,050.92178
Overall Steps per Second: 10,615.10271

Timestep Collection Time: 2.26820
Timestep Consumption Time: 2.44357
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.71178

Cumulative Model Updates: 10,794
Cumulative Timesteps: 90,133,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 90133368...
Checkpoint 90133368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,692.46517
Policy Entropy: 1.34053
Value Function Loss: 0.11139

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.24472
Value Function Update Magnitude: 0.57194

Collected Steps per Second: 21,791.88959
Overall Steps per Second: 10,562.45841

Timestep Collection Time: 2.29562
Timestep Consumption Time: 2.44058
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.73621

Cumulative Model Updates: 10,800
Cumulative Timesteps: 90,183,394

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,736.48242
Policy Entropy: 1.35076
Value Function Loss: 0.10798

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12138
Policy Update Magnitude: 0.23353
Value Function Update Magnitude: 0.62543

Collected Steps per Second: 22,560.43932
Overall Steps per Second: 10,612.31761

Timestep Collection Time: 2.21645
Timestep Consumption Time: 2.49544
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.71188

Cumulative Model Updates: 10,806
Cumulative Timesteps: 90,233,398

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 90233398...
Checkpoint 90233398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,845.62590
Policy Entropy: 1.34602
Value Function Loss: 0.10825

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.25563
Value Function Update Magnitude: 0.64636

Collected Steps per Second: 22,053.01474
Overall Steps per Second: 10,551.14442

Timestep Collection Time: 2.26735
Timestep Consumption Time: 2.47166
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.73901

Cumulative Model Updates: 10,812
Cumulative Timesteps: 90,283,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,144.27278
Policy Entropy: 1.34295
Value Function Loss: 0.11178

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.24295
Value Function Update Magnitude: 0.65311

Collected Steps per Second: 22,030.99945
Overall Steps per Second: 10,431.90128

Timestep Collection Time: 2.26980
Timestep Consumption Time: 2.52376
PPO Batch Consumption Time: 0.29773
Total Iteration Time: 4.79357

Cumulative Model Updates: 10,818
Cumulative Timesteps: 90,333,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 90333406...
Checkpoint 90333406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,432.61940
Policy Entropy: 1.34012
Value Function Loss: 0.11440

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.15225
Policy Update Magnitude: 0.25802
Value Function Update Magnitude: 0.63424

Collected Steps per Second: 22,253.37093
Overall Steps per Second: 10,698.11328

Timestep Collection Time: 2.24757
Timestep Consumption Time: 2.42765
PPO Batch Consumption Time: 0.28169
Total Iteration Time: 4.67522

Cumulative Model Updates: 10,824
Cumulative Timesteps: 90,383,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,616.45296
Policy Entropy: 1.36161
Value Function Loss: 0.10766

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.15603
Policy Update Magnitude: 0.24625
Value Function Update Magnitude: 0.56473

Collected Steps per Second: 22,272.49350
Overall Steps per Second: 10,556.23244

Timestep Collection Time: 2.24555
Timestep Consumption Time: 2.49231
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.73786

Cumulative Model Updates: 10,830
Cumulative Timesteps: 90,433,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 90433436...
Checkpoint 90433436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,119.54644
Policy Entropy: 1.36395
Value Function Loss: 0.11135

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.24359
Value Function Update Magnitude: 0.48643

Collected Steps per Second: 22,245.04449
Overall Steps per Second: 10,511.51479

Timestep Collection Time: 2.24868
Timestep Consumption Time: 2.51010
PPO Batch Consumption Time: 0.29656
Total Iteration Time: 4.75878

Cumulative Model Updates: 10,836
Cumulative Timesteps: 90,483,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,884.14677
Policy Entropy: 1.36836
Value Function Loss: 0.11038

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13159
Policy Update Magnitude: 0.24008
Value Function Update Magnitude: 0.50654

Collected Steps per Second: 22,645.45551
Overall Steps per Second: 10,797.95483

Timestep Collection Time: 2.20883
Timestep Consumption Time: 2.42353
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.63236

Cumulative Model Updates: 10,842
Cumulative Timesteps: 90,533,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 90533478...
Checkpoint 90533478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,134.12394
Policy Entropy: 1.36892
Value Function Loss: 0.11249

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.23268
Value Function Update Magnitude: 0.50230

Collected Steps per Second: 22,327.13489
Overall Steps per Second: 10,754.05957

Timestep Collection Time: 2.24023
Timestep Consumption Time: 2.41085
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.65108

Cumulative Model Updates: 10,848
Cumulative Timesteps: 90,583,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,812.11387
Policy Entropy: 1.38583
Value Function Loss: 0.10972

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.21782
Value Function Update Magnitude: 0.56055

Collected Steps per Second: 22,469.34114
Overall Steps per Second: 10,611.29389

Timestep Collection Time: 2.22534
Timestep Consumption Time: 2.48681
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.71215

Cumulative Model Updates: 10,854
Cumulative Timesteps: 90,633,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 90633498...
Checkpoint 90633498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,076.34482
Policy Entropy: 1.38695
Value Function Loss: 0.10800

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.22622
Value Function Update Magnitude: 0.58577

Collected Steps per Second: 22,374.06951
Overall Steps per Second: 10,619.97877

Timestep Collection Time: 2.23643
Timestep Consumption Time: 2.47526
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.71169

Cumulative Model Updates: 10,860
Cumulative Timesteps: 90,683,536

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,030.83870
Policy Entropy: 1.38566
Value Function Loss: 0.11193

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.23632
Value Function Update Magnitude: 0.63952

Collected Steps per Second: 21,908.80784
Overall Steps per Second: 10,303.59702

Timestep Collection Time: 2.28410
Timestep Consumption Time: 2.57265
PPO Batch Consumption Time: 0.30669
Total Iteration Time: 4.85675

Cumulative Model Updates: 10,866
Cumulative Timesteps: 90,733,578

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 90733578...
Checkpoint 90733578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,813.44970
Policy Entropy: 1.37431
Value Function Loss: 0.11394

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.14274
Policy Update Magnitude: 0.24711
Value Function Update Magnitude: 0.66785

Collected Steps per Second: 22,357.91487
Overall Steps per Second: 10,683.85920

Timestep Collection Time: 2.23867
Timestep Consumption Time: 2.44615
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.68482

Cumulative Model Updates: 10,872
Cumulative Timesteps: 90,783,630

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,345.19235
Policy Entropy: 1.38404
Value Function Loss: 0.11402

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.25618
Value Function Update Magnitude: 0.64264

Collected Steps per Second: 22,456.65918
Overall Steps per Second: 10,610.74347

Timestep Collection Time: 2.22687
Timestep Consumption Time: 2.48609
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.71296

Cumulative Model Updates: 10,878
Cumulative Timesteps: 90,833,638

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 90833638...
Checkpoint 90833638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,198.83005
Policy Entropy: 1.39462
Value Function Loss: 0.11152

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.29405
Value Function Update Magnitude: 0.67114

Collected Steps per Second: 22,370.51038
Overall Steps per Second: 10,492.52561

Timestep Collection Time: 2.23643
Timestep Consumption Time: 2.53173
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.76816

Cumulative Model Updates: 10,884
Cumulative Timesteps: 90,883,668

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,089.94767
Policy Entropy: 1.39655
Value Function Loss: 0.11011

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07352
Policy Update Magnitude: 0.31512
Value Function Update Magnitude: 0.68593

Collected Steps per Second: 22,615.69653
Overall Steps per Second: 10,602.23286

Timestep Collection Time: 2.21147
Timestep Consumption Time: 2.50584
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.71731

Cumulative Model Updates: 10,890
Cumulative Timesteps: 90,933,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 90933682...
Checkpoint 90933682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,027.54445
Policy Entropy: 1.37983
Value Function Loss: 0.11033

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08721
Policy Update Magnitude: 0.32036
Value Function Update Magnitude: 0.67814

Collected Steps per Second: 22,272.22882
Overall Steps per Second: 10,471.72328

Timestep Collection Time: 2.24495
Timestep Consumption Time: 2.52982
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 4.77476

Cumulative Model Updates: 10,896
Cumulative Timesteps: 90,983,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,170.57099
Policy Entropy: 1.36416
Value Function Loss: 0.10878

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.32582
Value Function Update Magnitude: 0.68343

Collected Steps per Second: 22,532.77526
Overall Steps per Second: 10,530.53278

Timestep Collection Time: 2.22068
Timestep Consumption Time: 2.53103
PPO Batch Consumption Time: 0.29584
Total Iteration Time: 4.75171

Cumulative Model Updates: 10,902
Cumulative Timesteps: 91,033,720

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 91033720...
Checkpoint 91033720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,028.20669
Policy Entropy: 1.36331
Value Function Loss: 0.11313

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.31023
Value Function Update Magnitude: 0.65576

Collected Steps per Second: 22,325.62575
Overall Steps per Second: 10,540.88948

Timestep Collection Time: 2.24003
Timestep Consumption Time: 2.50435
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.74438

Cumulative Model Updates: 10,908
Cumulative Timesteps: 91,083,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,813.23960
Policy Entropy: 1.36631
Value Function Loss: 0.11337

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11240
Policy Update Magnitude: 0.30108
Value Function Update Magnitude: 0.64093

Collected Steps per Second: 22,817.78051
Overall Steps per Second: 10,791.25908

Timestep Collection Time: 2.19145
Timestep Consumption Time: 2.44230
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.63375

Cumulative Model Updates: 10,914
Cumulative Timesteps: 91,133,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 91133734...
Checkpoint 91133734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,965.84591
Policy Entropy: 1.36804
Value Function Loss: 0.11534

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.31615
Value Function Update Magnitude: 0.62269

Collected Steps per Second: 22,303.13139
Overall Steps per Second: 10,723.30148

Timestep Collection Time: 2.24273
Timestep Consumption Time: 2.42187
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.66461

Cumulative Model Updates: 10,920
Cumulative Timesteps: 91,183,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,315.65543
Policy Entropy: 1.37407
Value Function Loss: 0.11406

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.31942
Value Function Update Magnitude: 0.55777

Collected Steps per Second: 22,579.92522
Overall Steps per Second: 10,664.66547

Timestep Collection Time: 2.21613
Timestep Consumption Time: 2.47600
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.69213

Cumulative Model Updates: 10,926
Cumulative Timesteps: 91,233,794

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 91233794...
Checkpoint 91233794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,768.31676
Policy Entropy: 1.37645
Value Function Loss: 0.12080

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10345
Policy Update Magnitude: 0.30773
Value Function Update Magnitude: 0.46667

Collected Steps per Second: 22,212.17255
Overall Steps per Second: 10,454.58185

Timestep Collection Time: 2.25237
Timestep Consumption Time: 2.53309
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.78546

Cumulative Model Updates: 10,932
Cumulative Timesteps: 91,283,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.43249
Policy Entropy: 1.37418
Value Function Loss: 0.12682

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09692
Policy Update Magnitude: 0.28767
Value Function Update Magnitude: 0.39646

Collected Steps per Second: 22,334.59784
Overall Steps per Second: 10,437.92841

Timestep Collection Time: 2.23922
Timestep Consumption Time: 2.55216
PPO Batch Consumption Time: 0.29750
Total Iteration Time: 4.79137

Cumulative Model Updates: 10,938
Cumulative Timesteps: 91,333,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 91333836...
Checkpoint 91333836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,530.22908
Policy Entropy: 1.37085
Value Function Loss: 0.12282

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.26481
Value Function Update Magnitude: 0.38542

Collected Steps per Second: 21,884.68090
Overall Steps per Second: 10,404.15364

Timestep Collection Time: 2.28607
Timestep Consumption Time: 2.52258
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.80866

Cumulative Model Updates: 10,944
Cumulative Timesteps: 91,383,866

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,497.32508
Policy Entropy: 1.34793
Value Function Loss: 0.11925

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.24168
Value Function Update Magnitude: 0.45043

Collected Steps per Second: 21,737.59582
Overall Steps per Second: 10,269.23010

Timestep Collection Time: 2.30053
Timestep Consumption Time: 2.56916
PPO Batch Consumption Time: 0.30219
Total Iteration Time: 4.86969

Cumulative Model Updates: 10,950
Cumulative Timesteps: 91,433,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 91433874...
Checkpoint 91433874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,868.23632
Policy Entropy: 1.35597
Value Function Loss: 0.10935

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.26244
Value Function Update Magnitude: 0.46212

Collected Steps per Second: 22,212.84181
Overall Steps per Second: 10,716.45986

Timestep Collection Time: 2.25221
Timestep Consumption Time: 2.41612
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.66833

Cumulative Model Updates: 10,956
Cumulative Timesteps: 91,483,902

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.77651
Policy Entropy: 1.36073
Value Function Loss: 0.10751

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.29730
Value Function Update Magnitude: 0.50221

Collected Steps per Second: 22,823.55480
Overall Steps per Second: 10,823.01616

Timestep Collection Time: 2.19160
Timestep Consumption Time: 2.43004
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.62163

Cumulative Model Updates: 10,962
Cumulative Timesteps: 91,533,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 91533922...
Checkpoint 91533922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,610.44268
Policy Entropy: 1.36662
Value Function Loss: 0.10601

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.29941
Value Function Update Magnitude: 0.54139

Collected Steps per Second: 22,421.49350
Overall Steps per Second: 10,648.02567

Timestep Collection Time: 2.23036
Timestep Consumption Time: 2.46610
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.69646

Cumulative Model Updates: 10,968
Cumulative Timesteps: 91,583,930

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,796.48664
Policy Entropy: 1.36988
Value Function Loss: 0.10932

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10801
Policy Update Magnitude: 0.28112
Value Function Update Magnitude: 0.58479

Collected Steps per Second: 22,536.16135
Overall Steps per Second: 10,500.90775

Timestep Collection Time: 2.21892
Timestep Consumption Time: 2.54314
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.76206

Cumulative Model Updates: 10,974
Cumulative Timesteps: 91,633,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 91633936...
Checkpoint 91633936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,843.48552
Policy Entropy: 1.36402
Value Function Loss: 0.11276

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.14849
Policy Update Magnitude: 0.26651
Value Function Update Magnitude: 0.61161

Collected Steps per Second: 22,220.61836
Overall Steps per Second: 10,636.61332

Timestep Collection Time: 2.25151
Timestep Consumption Time: 2.45205
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.70356

Cumulative Model Updates: 10,980
Cumulative Timesteps: 91,683,966

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.96539
Policy Entropy: 1.36943
Value Function Loss: 0.11397

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.15676
Policy Update Magnitude: 0.23932
Value Function Update Magnitude: 0.63419

Collected Steps per Second: 22,709.03877
Overall Steps per Second: 10,805.61571

Timestep Collection Time: 2.20256
Timestep Consumption Time: 2.42633
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.62889

Cumulative Model Updates: 10,986
Cumulative Timesteps: 91,733,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 91733984...
Checkpoint 91733984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,314.85368
Policy Entropy: 1.37509
Value Function Loss: 0.11319

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.15055
Policy Update Magnitude: 0.22796
Value Function Update Magnitude: 0.63359

Collected Steps per Second: 22,045.65559
Overall Steps per Second: 10,450.03408

Timestep Collection Time: 2.26866
Timestep Consumption Time: 2.51736
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.78601

Cumulative Model Updates: 10,992
Cumulative Timesteps: 91,783,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,005.18290
Policy Entropy: 1.37450
Value Function Loss: 0.11728

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.22186
Value Function Update Magnitude: 0.60124

Collected Steps per Second: 22,677.26280
Overall Steps per Second: 10,719.69725

Timestep Collection Time: 2.20688
Timestep Consumption Time: 2.46172
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.66860

Cumulative Model Updates: 10,998
Cumulative Timesteps: 91,834,044

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 91834044...
Checkpoint 91834044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733.75276
Policy Entropy: 1.37387
Value Function Loss: 0.12036

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.22798
Value Function Update Magnitude: 0.56716

Collected Steps per Second: 22,270.86322
Overall Steps per Second: 10,645.40463

Timestep Collection Time: 2.24625
Timestep Consumption Time: 2.45305
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.69930

Cumulative Model Updates: 11,004
Cumulative Timesteps: 91,884,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,714.95312
Policy Entropy: 1.37275
Value Function Loss: 0.12870

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.22971
Value Function Update Magnitude: 0.51240

Collected Steps per Second: 22,262.18234
Overall Steps per Second: 10,528.97170

Timestep Collection Time: 2.24713
Timestep Consumption Time: 2.50414
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.75127

Cumulative Model Updates: 11,010
Cumulative Timesteps: 91,934,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 91934096...
Checkpoint 91934096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.49046
Policy Entropy: 1.37094
Value Function Loss: 0.12505

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.23573
Value Function Update Magnitude: 0.58810

Collected Steps per Second: 22,123.21548
Overall Steps per Second: 10,564.43657

Timestep Collection Time: 2.26025
Timestep Consumption Time: 2.47299
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.73324

Cumulative Model Updates: 11,016
Cumulative Timesteps: 91,984,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,911.61823
Policy Entropy: 1.36501
Value Function Loss: 0.12353

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.24110
Value Function Update Magnitude: 0.50402

Collected Steps per Second: 22,323.18077
Overall Steps per Second: 10,558.91493

Timestep Collection Time: 2.24081
Timestep Consumption Time: 2.49661
PPO Batch Consumption Time: 0.29571
Total Iteration Time: 4.73742

Cumulative Model Updates: 11,022
Cumulative Timesteps: 92,034,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 92034122...
Checkpoint 92034122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,057.85512
Policy Entropy: 1.35966
Value Function Loss: 0.12366

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11528
Policy Update Magnitude: 0.26119
Value Function Update Magnitude: 0.44241

Collected Steps per Second: 21,903.03347
Overall Steps per Second: 10,395.10324

Timestep Collection Time: 2.28498
Timestep Consumption Time: 2.52959
PPO Batch Consumption Time: 0.30189
Total Iteration Time: 4.81457

Cumulative Model Updates: 11,028
Cumulative Timesteps: 92,084,170

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,305.67336
Policy Entropy: 1.35486
Value Function Loss: 0.11896

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12953
Policy Update Magnitude: 0.25120
Value Function Update Magnitude: 0.46487

Collected Steps per Second: 22,466.89207
Overall Steps per Second: 10,617.13081

Timestep Collection Time: 2.22567
Timestep Consumption Time: 2.48407
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.70975

Cumulative Model Updates: 11,034
Cumulative Timesteps: 92,134,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 92134174...
Checkpoint 92134174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,655.93388
Policy Entropy: 1.34138
Value Function Loss: 0.12215

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.24629
Value Function Update Magnitude: 0.49068

Collected Steps per Second: 22,005.60632
Overall Steps per Second: 10,642.85373

Timestep Collection Time: 2.27315
Timestep Consumption Time: 2.42691
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.70006

Cumulative Model Updates: 11,040
Cumulative Timesteps: 92,184,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,230.62960
Policy Entropy: 1.32948
Value Function Loss: 0.12510

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.14316
Policy Update Magnitude: 0.21349
Value Function Update Magnitude: 0.54072

Collected Steps per Second: 22,563.59130
Overall Steps per Second: 10,637.42357

Timestep Collection Time: 2.21711
Timestep Consumption Time: 2.48572
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.70283

Cumulative Model Updates: 11,046
Cumulative Timesteps: 92,234,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 92234222...
Checkpoint 92234222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,735.87738
Policy Entropy: 1.32053
Value Function Loss: 0.12866

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.22645
Value Function Update Magnitude: 0.48682

Collected Steps per Second: 22,288.74869
Overall Steps per Second: 10,579.51404

Timestep Collection Time: 2.24328
Timestep Consumption Time: 2.48283
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.72611

Cumulative Model Updates: 11,052
Cumulative Timesteps: 92,284,222

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,757.79315
Policy Entropy: 1.31666
Value Function Loss: 0.12930

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.25630
Value Function Update Magnitude: 0.48598

Collected Steps per Second: 22,433.52514
Overall Steps per Second: 10,730.89650

Timestep Collection Time: 2.22899
Timestep Consumption Time: 2.43083
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.65982

Cumulative Model Updates: 11,058
Cumulative Timesteps: 92,334,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 92334226...
Checkpoint 92334226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,866.39133
Policy Entropy: 1.30439
Value Function Loss: 0.12509

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.27852
Value Function Update Magnitude: 0.56216

Collected Steps per Second: 22,009.08085
Overall Steps per Second: 10,627.68441

Timestep Collection Time: 2.27261
Timestep Consumption Time: 2.43378
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.70639

Cumulative Model Updates: 11,064
Cumulative Timesteps: 92,384,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,495.42885
Policy Entropy: 1.31163
Value Function Loss: 0.12122

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.16389
Policy Update Magnitude: 0.24702
Value Function Update Magnitude: 0.62758

Collected Steps per Second: 22,629.98170
Overall Steps per Second: 10,338.44434

Timestep Collection Time: 2.21052
Timestep Consumption Time: 2.62812
PPO Batch Consumption Time: 0.29951
Total Iteration Time: 4.83864

Cumulative Model Updates: 11,070
Cumulative Timesteps: 92,434,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 92434268...
Checkpoint 92434268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,106.21950
Policy Entropy: 1.30580
Value Function Loss: 0.11645

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.14907
Policy Update Magnitude: 0.24278
Value Function Update Magnitude: 0.66626

Collected Steps per Second: 22,286.46609
Overall Steps per Second: 10,580.02363

Timestep Collection Time: 2.24360
Timestep Consumption Time: 2.48247
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.72608

Cumulative Model Updates: 11,076
Cumulative Timesteps: 92,484,270

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,396.99448
Policy Entropy: 1.31695
Value Function Loss: 0.10841

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.28519
Value Function Update Magnitude: 0.66722

Collected Steps per Second: 22,831.20452
Overall Steps per Second: 10,563.31884

Timestep Collection Time: 2.19007
Timestep Consumption Time: 2.54348
PPO Batch Consumption Time: 0.30165
Total Iteration Time: 4.73355

Cumulative Model Updates: 11,082
Cumulative Timesteps: 92,534,272

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 92534272...
Checkpoint 92534272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,577.42026
Policy Entropy: 1.30141
Value Function Loss: 0.10898

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.32087
Value Function Update Magnitude: 0.62704

Collected Steps per Second: 21,082.94299
Overall Steps per Second: 10,156.04330

Timestep Collection Time: 2.37187
Timestep Consumption Time: 2.55190
PPO Batch Consumption Time: 0.30340
Total Iteration Time: 4.92377

Cumulative Model Updates: 11,088
Cumulative Timesteps: 92,584,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,322.23609
Policy Entropy: 1.29008
Value Function Loss: 0.11418

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.33012
Value Function Update Magnitude: 0.56422

Collected Steps per Second: 22,815.50606
Overall Steps per Second: 10,645.11477

Timestep Collection Time: 2.19246
Timestep Consumption Time: 2.50660
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.69906

Cumulative Model Updates: 11,094
Cumulative Timesteps: 92,634,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 92634300...
Checkpoint 92634300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,087.35068
Policy Entropy: 1.27791
Value Function Loss: 0.11885

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.31811
Value Function Update Magnitude: 0.52005

Collected Steps per Second: 22,038.41071
Overall Steps per Second: 10,636.74041

Timestep Collection Time: 2.27013
Timestep Consumption Time: 2.43338
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.70351

Cumulative Model Updates: 11,100
Cumulative Timesteps: 92,684,330

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,307.82226
Policy Entropy: 1.28547
Value Function Loss: 0.11743

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12903
Policy Update Magnitude: 0.28194
Value Function Update Magnitude: 0.50827

Collected Steps per Second: 22,441.32701
Overall Steps per Second: 10,543.84755

Timestep Collection Time: 2.22830
Timestep Consumption Time: 2.51437
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.74267

Cumulative Model Updates: 11,106
Cumulative Timesteps: 92,734,336

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 92734336...
Checkpoint 92734336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,808.96051
Policy Entropy: 1.27594
Value Function Loss: 0.11418

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.26518
Value Function Update Magnitude: 0.53942

Collected Steps per Second: 22,358.99562
Overall Steps per Second: 10,343.74720

Timestep Collection Time: 2.23713
Timestep Consumption Time: 2.59864
PPO Batch Consumption Time: 0.30982
Total Iteration Time: 4.83577

Cumulative Model Updates: 11,112
Cumulative Timesteps: 92,784,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,362.68547
Policy Entropy: 1.27380
Value Function Loss: 0.11258

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.14818
Policy Update Magnitude: 0.25703
Value Function Update Magnitude: 0.51108

Collected Steps per Second: 21,697.15171
Overall Steps per Second: 10,578.65241

Timestep Collection Time: 2.30546
Timestep Consumption Time: 2.42312
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.72858

Cumulative Model Updates: 11,118
Cumulative Timesteps: 92,834,378

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 92834378...
Checkpoint 92834378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,503.49760
Policy Entropy: 1.27821
Value Function Loss: 0.11209

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.27295
Value Function Update Magnitude: 0.52488

Collected Steps per Second: 17,908.31599
Overall Steps per Second: 9,179.34479

Timestep Collection Time: 2.79468
Timestep Consumption Time: 2.65756
PPO Batch Consumption Time: 0.30700
Total Iteration Time: 5.45224

Cumulative Model Updates: 11,124
Cumulative Timesteps: 92,884,426

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,786.10584
Policy Entropy: 1.29072
Value Function Loss: 0.10811

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.31030
Value Function Update Magnitude: 0.51313

Collected Steps per Second: 20,804.33156
Overall Steps per Second: 10,078.65116

Timestep Collection Time: 2.40431
Timestep Consumption Time: 2.55866
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.96297

Cumulative Model Updates: 11,130
Cumulative Timesteps: 92,934,446

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 92934446...
Checkpoint 92934446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,085.36290
Policy Entropy: 1.28757
Value Function Loss: 0.10656

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07399
Policy Update Magnitude: 0.32399
Value Function Update Magnitude: 0.53727

Collected Steps per Second: 20,659.23428
Overall Steps per Second: 10,090.18771

Timestep Collection Time: 2.42100
Timestep Consumption Time: 2.53590
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.95689

Cumulative Model Updates: 11,136
Cumulative Timesteps: 92,984,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,889.90729
Policy Entropy: 1.29112
Value Function Loss: 0.10359

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.32618
Value Function Update Magnitude: 0.59177

Collected Steps per Second: 19,652.03156
Overall Steps per Second: 9,876.74510

Timestep Collection Time: 2.54467
Timestep Consumption Time: 2.51853
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 5.06321

Cumulative Model Updates: 11,142
Cumulative Timesteps: 93,034,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 93034470...
Checkpoint 93034470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,777.94064
Policy Entropy: 1.30119
Value Function Loss: 0.10738

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.32034
Value Function Update Magnitude: 0.58593

Collected Steps per Second: 20,873.49178
Overall Steps per Second: 10,051.06108

Timestep Collection Time: 2.39634
Timestep Consumption Time: 2.58025
PPO Batch Consumption Time: 0.30293
Total Iteration Time: 4.97659

Cumulative Model Updates: 11,148
Cumulative Timesteps: 93,084,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,917.23363
Policy Entropy: 1.29855
Value Function Loss: 0.11146

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.31066
Value Function Update Magnitude: 0.52735

Collected Steps per Second: 22,323.31847
Overall Steps per Second: 10,135.09570

Timestep Collection Time: 2.24053
Timestep Consumption Time: 2.69440
PPO Batch Consumption Time: 0.32798
Total Iteration Time: 4.93493

Cumulative Model Updates: 11,154
Cumulative Timesteps: 93,134,506

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 93134506...
Checkpoint 93134506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,128.27856
Policy Entropy: 1.30234
Value Function Loss: 0.11494

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07522
Policy Update Magnitude: 0.31815
Value Function Update Magnitude: 0.51417

Collected Steps per Second: 20,256.75756
Overall Steps per Second: 10,065.64177

Timestep Collection Time: 2.46950
Timestep Consumption Time: 2.50028
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.96978

Cumulative Model Updates: 11,160
Cumulative Timesteps: 93,184,530

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.47849
Policy Entropy: 1.30201
Value Function Loss: 0.11942

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08124
Policy Update Magnitude: 0.31637
Value Function Update Magnitude: 0.46693

Collected Steps per Second: 21,198.70530
Overall Steps per Second: 10,411.59192

Timestep Collection Time: 2.35986
Timestep Consumption Time: 2.44498
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.80484

Cumulative Model Updates: 11,166
Cumulative Timesteps: 93,234,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 93234556...
Checkpoint 93234556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,402.56446
Policy Entropy: 1.30336
Value Function Loss: 0.11854

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08557
Policy Update Magnitude: 0.31562
Value Function Update Magnitude: 0.44518

Collected Steps per Second: 20,762.82139
Overall Steps per Second: 10,180.47521

Timestep Collection Time: 2.40940
Timestep Consumption Time: 2.50451
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.91392

Cumulative Model Updates: 11,172
Cumulative Timesteps: 93,284,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,459.07139
Policy Entropy: 1.29917
Value Function Loss: 0.11733

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.31813
Value Function Update Magnitude: 0.43411

Collected Steps per Second: 21,538.95363
Overall Steps per Second: 10,390.09589

Timestep Collection Time: 2.32165
Timestep Consumption Time: 2.49120
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.81285

Cumulative Model Updates: 11,178
Cumulative Timesteps: 93,334,588

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 93334588...
Checkpoint 93334588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852.04043
Policy Entropy: 1.27666
Value Function Loss: 0.11587

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.32900
Value Function Update Magnitude: 0.45225

Collected Steps per Second: 21,268.35605
Overall Steps per Second: 10,270.30133

Timestep Collection Time: 2.35110
Timestep Consumption Time: 2.51770
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.86880

Cumulative Model Updates: 11,184
Cumulative Timesteps: 93,384,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,092.30671
Policy Entropy: 1.27434
Value Function Loss: 0.11144

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11193
Policy Update Magnitude: 0.30302
Value Function Update Magnitude: 0.47671

Collected Steps per Second: 20,441.37291
Overall Steps per Second: 10,168.71749

Timestep Collection Time: 2.44612
Timestep Consumption Time: 2.47112
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.91724

Cumulative Model Updates: 11,190
Cumulative Timesteps: 93,434,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 93434594...
Checkpoint 93434594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,858.27470
Policy Entropy: 1.27458
Value Function Loss: 0.11474

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.29017
Value Function Update Magnitude: 0.48889

Collected Steps per Second: 22,241.33211
Overall Steps per Second: 10,634.20791

Timestep Collection Time: 2.24852
Timestep Consumption Time: 2.45423
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.70275

Cumulative Model Updates: 11,196
Cumulative Timesteps: 93,484,604

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,786.96221
Policy Entropy: 1.26208
Value Function Loss: 0.11405

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11832
Policy Update Magnitude: 0.28614
Value Function Update Magnitude: 0.47708

Collected Steps per Second: 22,456.80580
Overall Steps per Second: 10,601.48790

Timestep Collection Time: 2.22765
Timestep Consumption Time: 2.49112
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.71877

Cumulative Model Updates: 11,202
Cumulative Timesteps: 93,534,630

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 93534630...
Checkpoint 93534630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.39386
Policy Entropy: 1.26360
Value Function Loss: 0.11810

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.30111
Value Function Update Magnitude: 0.48136

Collected Steps per Second: 22,502.51380
Overall Steps per Second: 10,633.36226

Timestep Collection Time: 2.22313
Timestep Consumption Time: 2.48150
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.70463

Cumulative Model Updates: 11,208
Cumulative Timesteps: 93,584,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,484.22940
Policy Entropy: 1.25855
Value Function Loss: 0.11697

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.15381
Policy Update Magnitude: 0.26209
Value Function Update Magnitude: 0.48876

Collected Steps per Second: 22,562.29013
Overall Steps per Second: 10,779.59950

Timestep Collection Time: 2.21671
Timestep Consumption Time: 2.42298
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.63969

Cumulative Model Updates: 11,214
Cumulative Timesteps: 93,634,670

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 93634670...
Checkpoint 93634670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,071.91905
Policy Entropy: 1.26502
Value Function Loss: 0.11609

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.17187
Policy Update Magnitude: 0.25412
Value Function Update Magnitude: 0.48031

Collected Steps per Second: 22,481.26400
Overall Steps per Second: 10,442.73170

Timestep Collection Time: 2.22487
Timestep Consumption Time: 2.56487
PPO Batch Consumption Time: 0.30576
Total Iteration Time: 4.78974

Cumulative Model Updates: 11,220
Cumulative Timesteps: 93,684,688

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,652.02952
Policy Entropy: 1.26335
Value Function Loss: 0.11261

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.15582
Policy Update Magnitude: 0.24522
Value Function Update Magnitude: 0.56764

Collected Steps per Second: 22,522.97881
Overall Steps per Second: 10,591.15667

Timestep Collection Time: 2.22120
Timestep Consumption Time: 2.50237
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.72356

Cumulative Model Updates: 11,226
Cumulative Timesteps: 93,734,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 93734716...
Checkpoint 93734716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,206.54305
Policy Entropy: 1.25682
Value Function Loss: 0.10922

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.14117
Policy Update Magnitude: 0.23450
Value Function Update Magnitude: 0.59801

Collected Steps per Second: 22,202.09609
Overall Steps per Second: 10,615.94002

Timestep Collection Time: 2.25213
Timestep Consumption Time: 2.45796
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.71009

Cumulative Model Updates: 11,232
Cumulative Timesteps: 93,784,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.46169
Policy Entropy: 1.24799
Value Function Loss: 0.11054

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.14511
Policy Update Magnitude: 0.21394
Value Function Update Magnitude: 0.62056

Collected Steps per Second: 22,421.43821
Overall Steps per Second: 10,544.02314

Timestep Collection Time: 2.23037
Timestep Consumption Time: 2.51242
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.74278

Cumulative Model Updates: 11,238
Cumulative Timesteps: 93,834,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 93834726...
Checkpoint 93834726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,916.08608
Policy Entropy: 1.26133
Value Function Loss: 0.11096

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.21649
Value Function Update Magnitude: 0.65185

Collected Steps per Second: 22,141.31928
Overall Steps per Second: 10,690.07530

Timestep Collection Time: 2.25931
Timestep Consumption Time: 2.42018
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.67948

Cumulative Model Updates: 11,244
Cumulative Timesteps: 93,884,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,274.26042
Policy Entropy: 1.26226
Value Function Loss: 0.11770

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.24835
Value Function Update Magnitude: 0.65809

Collected Steps per Second: 22,733.00363
Overall Steps per Second: 10,778.92811

Timestep Collection Time: 2.20138
Timestep Consumption Time: 2.44138
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.64276

Cumulative Model Updates: 11,250
Cumulative Timesteps: 93,934,794

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 93934794...
Checkpoint 93934794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,710.47116
Policy Entropy: 1.28714
Value Function Loss: 0.11599

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12166
Policy Update Magnitude: 0.24470
Value Function Update Magnitude: 0.65592

Collected Steps per Second: 22,361.74737
Overall Steps per Second: 10,734.94391

Timestep Collection Time: 2.23730
Timestep Consumption Time: 2.42318
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.66048

Cumulative Model Updates: 11,256
Cumulative Timesteps: 93,984,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.87865
Policy Entropy: 1.27545
Value Function Loss: 0.11575

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09302
Policy Update Magnitude: 0.24613
Value Function Update Magnitude: 0.65727

Collected Steps per Second: 22,686.20814
Overall Steps per Second: 10,780.55605

Timestep Collection Time: 2.20495
Timestep Consumption Time: 2.43507
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.64002

Cumulative Model Updates: 11,262
Cumulative Timesteps: 94,034,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 94034846...
Checkpoint 94034846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,189.03187
Policy Entropy: 1.28250
Value Function Loss: 0.11440

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.23184
Value Function Update Magnitude: 0.66678

Collected Steps per Second: 21,743.94336
Overall Steps per Second: 10,440.22961

Timestep Collection Time: 2.30087
Timestep Consumption Time: 2.49117
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.79204

Cumulative Model Updates: 11,268
Cumulative Timesteps: 94,084,876

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,797.64316
Policy Entropy: 1.27858
Value Function Loss: 0.11225

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.21449
Value Function Update Magnitude: 0.68172

Collected Steps per Second: 23,011.42131
Overall Steps per Second: 10,778.03019

Timestep Collection Time: 2.17309
Timestep Consumption Time: 2.46653
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.63962

Cumulative Model Updates: 11,274
Cumulative Timesteps: 94,134,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 94134882...
Checkpoint 94134882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,591.88652
Policy Entropy: 1.28515
Value Function Loss: 0.10848

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.23099
Value Function Update Magnitude: 0.65796

Collected Steps per Second: 22,230.46955
Overall Steps per Second: 10,603.06040

Timestep Collection Time: 2.25042
Timestep Consumption Time: 2.46784
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.71826

Cumulative Model Updates: 11,280
Cumulative Timesteps: 94,184,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,411.86568
Policy Entropy: 1.28716
Value Function Loss: 0.10561

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.23885
Value Function Update Magnitude: 0.63773

Collected Steps per Second: 22,509.78320
Overall Steps per Second: 10,495.88303

Timestep Collection Time: 2.22126
Timestep Consumption Time: 2.54252
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.76377

Cumulative Model Updates: 11,286
Cumulative Timesteps: 94,234,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 94234910...
Checkpoint 94234910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,730.43541
Policy Entropy: 1.28459
Value Function Loss: 0.10305

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12127
Policy Update Magnitude: 0.23843
Value Function Update Magnitude: 0.63251

Collected Steps per Second: 22,295.40218
Overall Steps per Second: 10,653.18878

Timestep Collection Time: 2.24360
Timestep Consumption Time: 2.45189
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.69550

Cumulative Model Updates: 11,292
Cumulative Timesteps: 94,284,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,290.51540
Policy Entropy: 1.27106
Value Function Loss: 0.10173

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.28234
Value Function Update Magnitude: 0.63478

Collected Steps per Second: 22,620.63866
Overall Steps per Second: 10,534.39178

Timestep Collection Time: 2.21134
Timestep Consumption Time: 2.53710
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.74845

Cumulative Model Updates: 11,298
Cumulative Timesteps: 94,334,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 94334954...
Checkpoint 94334954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,910.24062
Policy Entropy: 1.26140
Value Function Loss: 0.10867

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.30393
Value Function Update Magnitude: 0.65583

Collected Steps per Second: 22,300.71579
Overall Steps per Second: 10,380.25662

Timestep Collection Time: 2.24208
Timestep Consumption Time: 2.57476
PPO Batch Consumption Time: 0.30989
Total Iteration Time: 4.81684

Cumulative Model Updates: 11,304
Cumulative Timesteps: 94,384,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,444.23356
Policy Entropy: 1.26998
Value Function Loss: 0.10576

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.31536
Value Function Update Magnitude: 0.64956

Collected Steps per Second: 22,841.81257
Overall Steps per Second: 10,668.68038

Timestep Collection Time: 2.18906
Timestep Consumption Time: 2.49775
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.68680

Cumulative Model Updates: 11,310
Cumulative Timesteps: 94,434,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 94434956...
Checkpoint 94434956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,855.24829
Policy Entropy: 1.28344
Value Function Loss: 0.11047

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.29809
Value Function Update Magnitude: 0.60744

Collected Steps per Second: 22,169.30841
Overall Steps per Second: 10,590.90952

Timestep Collection Time: 2.25591
Timestep Consumption Time: 2.46625
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.72216

Cumulative Model Updates: 11,316
Cumulative Timesteps: 94,484,968

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,890.84515
Policy Entropy: 1.29354
Value Function Loss: 0.10715

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07704
Policy Update Magnitude: 0.31308
Value Function Update Magnitude: 0.56426

Collected Steps per Second: 22,626.84924
Overall Steps per Second: 10,646.31304

Timestep Collection Time: 2.21012
Timestep Consumption Time: 2.48710
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.69721

Cumulative Model Updates: 11,322
Cumulative Timesteps: 94,534,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 94534976...
Checkpoint 94534976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070.82961
Policy Entropy: 1.29274
Value Function Loss: 0.11123

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07992
Policy Update Magnitude: 0.30871
Value Function Update Magnitude: 0.48629

Collected Steps per Second: 18,839.48132
Overall Steps per Second: 9,509.60320

Timestep Collection Time: 2.65527
Timestep Consumption Time: 2.60509
PPO Batch Consumption Time: 0.30513
Total Iteration Time: 5.26037

Cumulative Model Updates: 11,328
Cumulative Timesteps: 94,585,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,456.44960
Policy Entropy: 1.27472
Value Function Loss: 0.10831

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.29852
Value Function Update Magnitude: 0.48965

Collected Steps per Second: 20,972.95642
Overall Steps per Second: 10,186.25278

Timestep Collection Time: 2.38402
Timestep Consumption Time: 2.52455
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.90858

Cumulative Model Updates: 11,334
Cumulative Timesteps: 94,635,000

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 94635000...
Checkpoint 94635000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,556.49636
Policy Entropy: 1.28383
Value Function Loss: 0.11338

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08136
Policy Update Magnitude: 0.30610
Value Function Update Magnitude: 0.47966

Collected Steps per Second: 22,308.23748
Overall Steps per Second: 10,669.09156

Timestep Collection Time: 2.24177
Timestep Consumption Time: 2.44560
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.68737

Cumulative Model Updates: 11,340
Cumulative Timesteps: 94,685,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,521.82125
Policy Entropy: 1.27295
Value Function Loss: 0.11462

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.29204
Value Function Update Magnitude: 0.48395

Collected Steps per Second: 22,810.79064
Overall Steps per Second: 10,818.45041

Timestep Collection Time: 2.19221
Timestep Consumption Time: 2.43008
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.62229

Cumulative Model Updates: 11,346
Cumulative Timesteps: 94,735,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 94735016...
Checkpoint 94735016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,260.85357
Policy Entropy: 1.28960
Value Function Loss: 0.11603

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11375
Policy Update Magnitude: 0.28487
Value Function Update Magnitude: 0.55910

Collected Steps per Second: 22,131.94328
Overall Steps per Second: 10,665.77281

Timestep Collection Time: 2.26008
Timestep Consumption Time: 2.42969
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.68977

Cumulative Model Updates: 11,352
Cumulative Timesteps: 94,785,036

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,554.65532
Policy Entropy: 1.28079
Value Function Loss: 0.11571

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.29643
Value Function Update Magnitude: 0.57806

Collected Steps per Second: 22,491.09166
Overall Steps per Second: 10,595.47632

Timestep Collection Time: 2.22381
Timestep Consumption Time: 2.49669
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.72051

Cumulative Model Updates: 11,358
Cumulative Timesteps: 94,835,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 94835052...
Checkpoint 94835052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,368.02879
Policy Entropy: 1.29080
Value Function Loss: 0.11369

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.30113
Value Function Update Magnitude: 0.50528

Collected Steps per Second: 21,891.19596
Overall Steps per Second: 10,561.08241

Timestep Collection Time: 2.28549
Timestep Consumption Time: 2.45191
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.73739

Cumulative Model Updates: 11,364
Cumulative Timesteps: 94,885,084

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,188.06854
Policy Entropy: 1.28913
Value Function Loss: 0.10848

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10944
Policy Update Magnitude: 0.32048
Value Function Update Magnitude: 0.50580

Collected Steps per Second: 22,390.08020
Overall Steps per Second: 10,503.60120

Timestep Collection Time: 2.23456
Timestep Consumption Time: 2.52876
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.76332

Cumulative Model Updates: 11,370
Cumulative Timesteps: 94,935,116

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 94935116...
Checkpoint 94935116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,813.53810
Policy Entropy: 1.28866
Value Function Loss: 0.10804

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.14158
Policy Update Magnitude: 0.28817
Value Function Update Magnitude: 0.51284

Collected Steps per Second: 22,099.08920
Overall Steps per Second: 10,572.41237

Timestep Collection Time: 2.26353
Timestep Consumption Time: 2.46784
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.73137

Cumulative Model Updates: 11,376
Cumulative Timesteps: 94,985,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,237.15282
Policy Entropy: 1.28449
Value Function Loss: 0.11320

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.26132
Value Function Update Magnitude: 0.47474

Collected Steps per Second: 22,077.27364
Overall Steps per Second: 10,305.89165

Timestep Collection Time: 2.26577
Timestep Consumption Time: 2.58796
PPO Batch Consumption Time: 0.30584
Total Iteration Time: 4.85373

Cumulative Model Updates: 11,382
Cumulative Timesteps: 95,035,160

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 95035160...
Checkpoint 95035160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.03160
Policy Entropy: 1.28069
Value Function Loss: 0.12137

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.18562
Policy Update Magnitude: 0.25973
Value Function Update Magnitude: 0.47070

Collected Steps per Second: 22,282.75009
Overall Steps per Second: 10,544.54406

Timestep Collection Time: 2.24550
Timestep Consumption Time: 2.49970
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.74520

Cumulative Model Updates: 11,388
Cumulative Timesteps: 95,085,196

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.94093
Policy Entropy: 1.29213
Value Function Loss: 0.12140

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.16110
Policy Update Magnitude: 0.27391
Value Function Update Magnitude: 0.57204

Collected Steps per Second: 22,589.97698
Overall Steps per Second: 10,681.58981

Timestep Collection Time: 2.21514
Timestep Consumption Time: 2.46955
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.68470

Cumulative Model Updates: 11,394
Cumulative Timesteps: 95,135,236

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 95135236...
Checkpoint 95135236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,225.42667
Policy Entropy: 1.27100
Value Function Loss: 0.11578

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.16212
Policy Update Magnitude: 0.29431
Value Function Update Magnitude: 0.62566

Collected Steps per Second: 22,184.73989
Overall Steps per Second: 10,651.78201

Timestep Collection Time: 2.25606
Timestep Consumption Time: 2.44269
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 4.69874

Cumulative Model Updates: 11,400
Cumulative Timesteps: 95,185,286

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,988.32839
Policy Entropy: 1.28519
Value Function Loss: 0.10803

Mean KL Divergence: 0.02238
SB3 Clip Fraction: 0.19165
Policy Update Magnitude: 0.27038
Value Function Update Magnitude: 0.63702

Collected Steps per Second: 22,314.35214
Overall Steps per Second: 10,508.63437

Timestep Collection Time: 2.24179
Timestep Consumption Time: 2.51849
PPO Batch Consumption Time: 0.29749
Total Iteration Time: 4.76028

Cumulative Model Updates: 11,406
Cumulative Timesteps: 95,235,310

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 95235310...
Checkpoint 95235310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,243.35384
Policy Entropy: 1.26640
Value Function Loss: 0.10858

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.15720
Policy Update Magnitude: 0.22631
Value Function Update Magnitude: 0.63204

Collected Steps per Second: 21,725.23351
Overall Steps per Second: 10,532.13094

Timestep Collection Time: 2.30267
Timestep Consumption Time: 2.44718
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.74985

Cumulative Model Updates: 11,412
Cumulative Timesteps: 95,285,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,766.20834
Policy Entropy: 1.27056
Value Function Loss: 0.10965

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.20339
Value Function Update Magnitude: 0.61406

Collected Steps per Second: 22,497.06545
Overall Steps per Second: 10,531.45473

Timestep Collection Time: 2.22393
Timestep Consumption Time: 2.52679
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.75072

Cumulative Model Updates: 11,418
Cumulative Timesteps: 95,335,368

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 95335368...
Checkpoint 95335368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,799.48589
Policy Entropy: 1.25255
Value Function Loss: 0.11084

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.12115
Policy Update Magnitude: 0.20746
Value Function Update Magnitude: 0.64472

Collected Steps per Second: 21,802.39593
Overall Steps per Second: 10,572.02825

Timestep Collection Time: 2.29351
Timestep Consumption Time: 2.43633
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.72984

Cumulative Model Updates: 11,424
Cumulative Timesteps: 95,385,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.46947
Policy Entropy: 1.26804
Value Function Loss: 0.10586

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.22532
Value Function Update Magnitude: 0.65594

Collected Steps per Second: 22,471.72940
Overall Steps per Second: 10,529.94794

Timestep Collection Time: 2.22591
Timestep Consumption Time: 2.52435
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.75026

Cumulative Model Updates: 11,430
Cumulative Timesteps: 95,435,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 95435392...
Checkpoint 95435392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,098.77528
Policy Entropy: 1.26482
Value Function Loss: 0.10081

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.25257
Value Function Update Magnitude: 0.66974

Collected Steps per Second: 22,176.68052
Overall Steps per Second: 10,618.11629

Timestep Collection Time: 2.25561
Timestep Consumption Time: 2.45539
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.71101

Cumulative Model Updates: 11,436
Cumulative Timesteps: 95,485,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,487.91402
Policy Entropy: 1.27047
Value Function Loss: 0.09731

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.23957
Value Function Update Magnitude: 0.66738

Collected Steps per Second: 22,823.42958
Overall Steps per Second: 10,624.30129

Timestep Collection Time: 2.19213
Timestep Consumption Time: 2.51707
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.70920

Cumulative Model Updates: 11,442
Cumulative Timesteps: 95,535,446

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 95535446...
Checkpoint 95535446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,038.58585
Policy Entropy: 1.26317
Value Function Loss: 0.09721

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.21741
Value Function Update Magnitude: 0.63957

Collected Steps per Second: 22,318.97388
Overall Steps per Second: 10,481.05876

Timestep Collection Time: 2.24060
Timestep Consumption Time: 2.53067
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.77127

Cumulative Model Updates: 11,448
Cumulative Timesteps: 95,585,454

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,077.07429
Policy Entropy: 1.26106
Value Function Loss: 0.10499

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.20832
Value Function Update Magnitude: 0.66265

Collected Steps per Second: 22,559.06636
Overall Steps per Second: 10,527.41437

Timestep Collection Time: 2.21738
Timestep Consumption Time: 2.53422
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.75159

Cumulative Model Updates: 11,454
Cumulative Timesteps: 95,635,476

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 95635476...
Checkpoint 95635476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,267.89792
Policy Entropy: 1.26793
Value Function Loss: 0.10883

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.21145
Value Function Update Magnitude: 0.68884

Collected Steps per Second: 22,139.40906
Overall Steps per Second: 10,629.35212

Timestep Collection Time: 2.25941
Timestep Consumption Time: 2.44662
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.70603

Cumulative Model Updates: 11,460
Cumulative Timesteps: 95,685,498

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,067.60073
Policy Entropy: 1.26774
Value Function Loss: 0.11301

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.24936
Value Function Update Magnitude: 0.68633

Collected Steps per Second: 22,337.06102
Overall Steps per Second: 10,576.35174

Timestep Collection Time: 2.23879
Timestep Consumption Time: 2.48949
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.72828

Cumulative Model Updates: 11,466
Cumulative Timesteps: 95,735,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 95735506...
Checkpoint 95735506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,549.16505
Policy Entropy: 1.27203
Value Function Loss: 0.11003

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.27529
Value Function Update Magnitude: 0.69633

Collected Steps per Second: 22,046.82272
Overall Steps per Second: 10,479.40260

Timestep Collection Time: 2.26854
Timestep Consumption Time: 2.50406
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.77260

Cumulative Model Updates: 11,472
Cumulative Timesteps: 95,785,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,944.21699
Policy Entropy: 1.26678
Value Function Loss: 0.10279

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08643
Policy Update Magnitude: 0.27765
Value Function Update Magnitude: 0.70896

Collected Steps per Second: 22,628.49970
Overall Steps per Second: 10,641.98960

Timestep Collection Time: 2.20996
Timestep Consumption Time: 2.48916
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.69912

Cumulative Model Updates: 11,478
Cumulative Timesteps: 95,835,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 95835528...
Checkpoint 95835528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,020.02264
Policy Entropy: 1.26846
Value Function Loss: 0.10094

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06671
Policy Update Magnitude: 0.29483
Value Function Update Magnitude: 0.69488

Collected Steps per Second: 22,385.69449
Overall Steps per Second: 10,455.27205

Timestep Collection Time: 2.23482
Timestep Consumption Time: 2.55013
PPO Batch Consumption Time: 0.30041
Total Iteration Time: 4.78495

Cumulative Model Updates: 11,484
Cumulative Timesteps: 95,885,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.10009
Policy Entropy: 1.27007
Value Function Loss: 0.10674

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07092
Policy Update Magnitude: 0.30337
Value Function Update Magnitude: 0.68823

Collected Steps per Second: 22,100.40948
Overall Steps per Second: 10,481.83207

Timestep Collection Time: 2.26285
Timestep Consumption Time: 2.50826
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.77111

Cumulative Model Updates: 11,490
Cumulative Timesteps: 95,935,566

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 95935566...
Checkpoint 95935566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,461.81720
Policy Entropy: 1.27713
Value Function Loss: 0.10710

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.30344
Value Function Update Magnitude: 0.69232

Collected Steps per Second: 22,127.24461
Overall Steps per Second: 10,554.79721

Timestep Collection Time: 2.26138
Timestep Consumption Time: 2.47941
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.74078

Cumulative Model Updates: 11,496
Cumulative Timesteps: 95,985,604

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.74844
Policy Entropy: 1.27671
Value Function Loss: 0.10790

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.26551
Value Function Update Magnitude: 0.66998

Collected Steps per Second: 22,573.94930
Overall Steps per Second: 10,539.82904

Timestep Collection Time: 2.21547
Timestep Consumption Time: 2.52957
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.74505

Cumulative Model Updates: 11,502
Cumulative Timesteps: 96,035,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 96035616...
Checkpoint 96035616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,533.32636
Policy Entropy: 1.27835
Value Function Loss: 0.11224

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.24374
Value Function Update Magnitude: 0.63717

Collected Steps per Second: 21,867.72453
Overall Steps per Second: 10,579.94991

Timestep Collection Time: 2.28748
Timestep Consumption Time: 2.44052
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.72800

Cumulative Model Updates: 11,508
Cumulative Timesteps: 96,085,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,783.48491
Policy Entropy: 1.25728
Value Function Loss: 0.11424

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.15085
Policy Update Magnitude: 0.23860
Value Function Update Magnitude: 0.65632

Collected Steps per Second: 22,570.13624
Overall Steps per Second: 10,581.48110

Timestep Collection Time: 2.21594
Timestep Consumption Time: 2.51062
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.72656

Cumulative Model Updates: 11,514
Cumulative Timesteps: 96,135,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 96135652...
Checkpoint 96135652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.18323
Policy Entropy: 1.25378
Value Function Loss: 0.11694

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.15038
Policy Update Magnitude: 0.22821
Value Function Update Magnitude: 0.65757

Collected Steps per Second: 22,158.55686
Overall Steps per Second: 10,531.12524

Timestep Collection Time: 2.25764
Timestep Consumption Time: 2.49266
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.75030

Cumulative Model Updates: 11,520
Cumulative Timesteps: 96,185,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,785.51430
Policy Entropy: 1.25341
Value Function Loss: 0.11259

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.18134
Policy Update Magnitude: 0.21679
Value Function Update Magnitude: 0.66939

Collected Steps per Second: 23,023.01805
Overall Steps per Second: 10,880.78150

Timestep Collection Time: 2.17374
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.59949

Cumulative Model Updates: 11,526
Cumulative Timesteps: 96,235,724

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 96235724...
Checkpoint 96235724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.04990
Policy Entropy: 1.24656
Value Function Loss: 0.11052

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.17324
Policy Update Magnitude: 0.22046
Value Function Update Magnitude: 0.64370

Collected Steps per Second: 22,133.03130
Overall Steps per Second: 10,670.75970

Timestep Collection Time: 2.26069
Timestep Consumption Time: 2.42838
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.68908

Cumulative Model Updates: 11,532
Cumulative Timesteps: 96,285,760

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,014.15539
Policy Entropy: 1.24664
Value Function Loss: 0.10968

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.14263
Policy Update Magnitude: 0.22587
Value Function Update Magnitude: 0.57812

Collected Steps per Second: 22,434.11240
Overall Steps per Second: 10,470.88581

Timestep Collection Time: 2.23044
Timestep Consumption Time: 2.54833
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.77877

Cumulative Model Updates: 11,538
Cumulative Timesteps: 96,335,798

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 96335798...
Checkpoint 96335798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,796.71580
Policy Entropy: 1.25419
Value Function Loss: 0.11345

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11006
Policy Update Magnitude: 0.24625
Value Function Update Magnitude: 0.52275

Collected Steps per Second: 22,232.58063
Overall Steps per Second: 10,629.65054

Timestep Collection Time: 2.24895
Timestep Consumption Time: 2.45487
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.70382

Cumulative Model Updates: 11,544
Cumulative Timesteps: 96,385,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,143.02051
Policy Entropy: 1.23559
Value Function Loss: 0.11752

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.27066
Value Function Update Magnitude: 0.47383

Collected Steps per Second: 22,655.89565
Overall Steps per Second: 10,669.72507

Timestep Collection Time: 2.20720
Timestep Consumption Time: 2.47952
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.68672

Cumulative Model Updates: 11,550
Cumulative Timesteps: 96,435,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 96435804...
Checkpoint 96435804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495.69336
Policy Entropy: 1.21857
Value Function Loss: 0.11443

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10552
Policy Update Magnitude: 0.27016
Value Function Update Magnitude: 0.46362

Collected Steps per Second: 22,328.12165
Overall Steps per Second: 10,589.95241

Timestep Collection Time: 2.24112
Timestep Consumption Time: 2.48411
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.72523

Cumulative Model Updates: 11,556
Cumulative Timesteps: 96,485,844

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,844.93323
Policy Entropy: 1.22847
Value Function Loss: 0.10926

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.23175
Value Function Update Magnitude: 0.48164

Collected Steps per Second: 22,915.93685
Overall Steps per Second: 10,593.08240

Timestep Collection Time: 2.18320
Timestep Consumption Time: 2.53970
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.72289

Cumulative Model Updates: 11,562
Cumulative Timesteps: 96,535,874

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 96535874...
Checkpoint 96535874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,906.45075
Policy Entropy: 1.23566
Value Function Loss: 0.10444

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.22457
Value Function Update Magnitude: 0.45308

Collected Steps per Second: 22,198.18540
Overall Steps per Second: 10,413.49936

Timestep Collection Time: 2.25469
Timestep Consumption Time: 2.55157
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.80626

Cumulative Model Updates: 11,568
Cumulative Timesteps: 96,585,924

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,169.79126
Policy Entropy: 1.26113
Value Function Loss: 0.10219

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07643
Policy Update Magnitude: 0.24331
Value Function Update Magnitude: 0.47144

Collected Steps per Second: 22,730.12249
Overall Steps per Second: 10,793.21358

Timestep Collection Time: 2.20034
Timestep Consumption Time: 2.43350
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.63384

Cumulative Model Updates: 11,574
Cumulative Timesteps: 96,635,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 96635938...
Checkpoint 96635938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,141.59287
Policy Entropy: 1.24729
Value Function Loss: 0.10230

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07421
Policy Update Magnitude: 0.27156
Value Function Update Magnitude: 0.47304

Collected Steps per Second: 22,021.49774
Overall Steps per Second: 10,647.56647

Timestep Collection Time: 2.27051
Timestep Consumption Time: 2.42540
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.69591

Cumulative Model Updates: 11,580
Cumulative Timesteps: 96,685,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,363.03908
Policy Entropy: 1.26439
Value Function Loss: 0.10685

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07524
Policy Update Magnitude: 0.27968
Value Function Update Magnitude: 0.44818

Collected Steps per Second: 21,894.30803
Overall Steps per Second: 10,506.88572

Timestep Collection Time: 2.28470
Timestep Consumption Time: 2.47617
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.76088

Cumulative Model Updates: 11,586
Cumulative Timesteps: 96,735,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 96735960...
Checkpoint 96735960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,845.48296
Policy Entropy: 1.25306
Value Function Loss: 0.10995

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06620
Policy Update Magnitude: 0.29787
Value Function Update Magnitude: 0.51859

Collected Steps per Second: 21,940.64260
Overall Steps per Second: 10,590.94464

Timestep Collection Time: 2.27933
Timestep Consumption Time: 2.44263
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.72196

Cumulative Model Updates: 11,592
Cumulative Timesteps: 96,785,970

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,319.11955
Policy Entropy: 1.26301
Value Function Loss: 0.10694

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07321
Policy Update Magnitude: 0.29984
Value Function Update Magnitude: 0.59601

Collected Steps per Second: 22,696.90664
Overall Steps per Second: 10,517.96798

Timestep Collection Time: 2.20409
Timestep Consumption Time: 2.55215
PPO Batch Consumption Time: 0.29736
Total Iteration Time: 4.75624

Cumulative Model Updates: 11,598
Cumulative Timesteps: 96,835,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 96835996...
Checkpoint 96835996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,512.12052
Policy Entropy: 1.24988
Value Function Loss: 0.10799

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.30760
Value Function Update Magnitude: 0.62883

Collected Steps per Second: 21,775.20884
Overall Steps per Second: 10,601.57495

Timestep Collection Time: 2.29729
Timestep Consumption Time: 2.42125
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.71854

Cumulative Model Updates: 11,604
Cumulative Timesteps: 96,886,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,706.06730
Policy Entropy: 1.25392
Value Function Loss: 0.10474

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07575
Policy Update Magnitude: 0.30570
Value Function Update Magnitude: 0.62368

Collected Steps per Second: 22,681.16707
Overall Steps per Second: 10,554.97466

Timestep Collection Time: 2.20447
Timestep Consumption Time: 2.53263
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.73710

Cumulative Model Updates: 11,610
Cumulative Timesteps: 96,936,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 96936020...
Checkpoint 96936020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,158.46709
Policy Entropy: 1.25763
Value Function Loss: 0.10623

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07190
Policy Update Magnitude: 0.30235
Value Function Update Magnitude: 0.63940

Collected Steps per Second: 22,038.86299
Overall Steps per Second: 10,580.29460

Timestep Collection Time: 2.27099
Timestep Consumption Time: 2.45950
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.73049

Cumulative Model Updates: 11,616
Cumulative Timesteps: 96,986,070

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,118.93257
Policy Entropy: 1.26177
Value Function Loss: 0.10514

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.29483
Value Function Update Magnitude: 0.64095

Collected Steps per Second: 22,631.84962
Overall Steps per Second: 10,666.35638

Timestep Collection Time: 2.20989
Timestep Consumption Time: 2.47905
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.68895

Cumulative Model Updates: 11,622
Cumulative Timesteps: 97,036,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 97036084...
Checkpoint 97036084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,462.47226
Policy Entropy: 1.24976
Value Function Loss: 0.10462

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07489
Policy Update Magnitude: 0.29089
Value Function Update Magnitude: 0.63106

Collected Steps per Second: 22,444.22050
Overall Steps per Second: 10,530.51447

Timestep Collection Time: 2.22775
Timestep Consumption Time: 2.52036
PPO Batch Consumption Time: 0.29667
Total Iteration Time: 4.74811

Cumulative Model Updates: 11,628
Cumulative Timesteps: 97,086,084

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,002.09054
Policy Entropy: 1.24214
Value Function Loss: 0.10854

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07842
Policy Update Magnitude: 0.28378
Value Function Update Magnitude: 0.61882

Collected Steps per Second: 22,497.39313
Overall Steps per Second: 10,566.75486

Timestep Collection Time: 2.22479
Timestep Consumption Time: 2.51195
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.73674

Cumulative Model Updates: 11,634
Cumulative Timesteps: 97,136,136

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 97136136...
Checkpoint 97136136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,937.79724
Policy Entropy: 1.24424
Value Function Loss: 0.10892

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07504
Policy Update Magnitude: 0.28829
Value Function Update Magnitude: 0.54399

Collected Steps per Second: 21,973.35085
Overall Steps per Second: 10,312.43749

Timestep Collection Time: 2.27585
Timestep Consumption Time: 2.57344
PPO Batch Consumption Time: 0.30140
Total Iteration Time: 4.84929

Cumulative Model Updates: 11,640
Cumulative Timesteps: 97,186,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,984.41365
Policy Entropy: 1.23425
Value Function Loss: 0.11692

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.26600
Value Function Update Magnitude: 0.46691

Collected Steps per Second: 22,735.64366
Overall Steps per Second: 10,483.43961

Timestep Collection Time: 2.19998
Timestep Consumption Time: 2.57116
PPO Batch Consumption Time: 0.30184
Total Iteration Time: 4.77114

Cumulative Model Updates: 11,646
Cumulative Timesteps: 97,236,162

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 97236162...
Checkpoint 97236162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.69959
Policy Entropy: 1.23078
Value Function Loss: 0.11915

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.16427
Policy Update Magnitude: 0.23198
Value Function Update Magnitude: 0.43341

Collected Steps per Second: 21,921.68696
Overall Steps per Second: 10,499.93158

Timestep Collection Time: 2.28121
Timestep Consumption Time: 2.48149
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.76270

Cumulative Model Updates: 11,652
Cumulative Timesteps: 97,286,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,654.27240
Policy Entropy: 1.20668
Value Function Loss: 0.12131

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.15215
Policy Update Magnitude: 0.21783
Value Function Update Magnitude: 0.48917

Collected Steps per Second: 22,773.43983
Overall Steps per Second: 10,692.30380

Timestep Collection Time: 2.19642
Timestep Consumption Time: 2.48171
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.67813

Cumulative Model Updates: 11,658
Cumulative Timesteps: 97,336,190

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 97336190...
Checkpoint 97336190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,767.11490
Policy Entropy: 1.22302
Value Function Loss: 0.11477

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.21039
Value Function Update Magnitude: 0.54907

Collected Steps per Second: 22,148.92687
Overall Steps per Second: 10,696.11974

Timestep Collection Time: 2.25799
Timestep Consumption Time: 2.41773
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.67571

Cumulative Model Updates: 11,664
Cumulative Timesteps: 97,386,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.02492
Policy Entropy: 1.23161
Value Function Loss: 0.10968

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.23697
Value Function Update Magnitude: 0.58514

Collected Steps per Second: 22,862.10965
Overall Steps per Second: 10,838.00518

Timestep Collection Time: 2.18825
Timestep Consumption Time: 2.42773
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.61598

Cumulative Model Updates: 11,670
Cumulative Timesteps: 97,436,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 97436230...
Checkpoint 97436230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,981.47444
Policy Entropy: 1.25883
Value Function Loss: 0.10610

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09641
Policy Update Magnitude: 0.27336
Value Function Update Magnitude: 0.62973

Collected Steps per Second: 22,147.03463
Overall Steps per Second: 10,701.58975

Timestep Collection Time: 2.25782
Timestep Consumption Time: 2.41476
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.67258

Cumulative Model Updates: 11,676
Cumulative Timesteps: 97,486,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,610.46267
Policy Entropy: 1.27184
Value Function Loss: 0.10284

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10899
Policy Update Magnitude: 0.28136
Value Function Update Magnitude: 0.66311

Collected Steps per Second: 22,728.07415
Overall Steps per Second: 10,570.37370

Timestep Collection Time: 2.20063
Timestep Consumption Time: 2.53109
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.73172

Cumulative Model Updates: 11,682
Cumulative Timesteps: 97,536,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 97536250...
Checkpoint 97536250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,927.55623
Policy Entropy: 1.25621
Value Function Loss: 0.11110

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.25204
Value Function Update Magnitude: 0.67039

Collected Steps per Second: 22,372.96229
Overall Steps per Second: 10,571.80705

Timestep Collection Time: 2.23484
Timestep Consumption Time: 2.49472
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.72956

Cumulative Model Updates: 11,688
Cumulative Timesteps: 97,586,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,786.69430
Policy Entropy: 1.26445
Value Function Loss: 0.11183

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.22793
Value Function Update Magnitude: 0.68870

Collected Steps per Second: 22,742.26552
Overall Steps per Second: 10,805.40695

Timestep Collection Time: 2.19969
Timestep Consumption Time: 2.43003
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.62972

Cumulative Model Updates: 11,694
Cumulative Timesteps: 97,636,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 97636276...
Checkpoint 97636276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,926.12526
Policy Entropy: 1.26051
Value Function Loss: 0.11282

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.23826
Value Function Update Magnitude: 0.67022

Collected Steps per Second: 21,848.75389
Overall Steps per Second: 10,575.43126

Timestep Collection Time: 2.28910
Timestep Consumption Time: 2.44016
PPO Batch Consumption Time: 0.28190
Total Iteration Time: 4.72926

Cumulative Model Updates: 11,700
Cumulative Timesteps: 97,686,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,700.59356
Policy Entropy: 1.28035
Value Function Loss: 0.10380

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11241
Policy Update Magnitude: 0.25719
Value Function Update Magnitude: 0.66209

Collected Steps per Second: 22,569.36915
Overall Steps per Second: 10,573.76525

Timestep Collection Time: 2.21592
Timestep Consumption Time: 2.51390
PPO Batch Consumption Time: 0.29781
Total Iteration Time: 4.72982

Cumulative Model Updates: 11,706
Cumulative Timesteps: 97,736,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 97736302...
Checkpoint 97736302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,354.99104
Policy Entropy: 1.27461
Value Function Loss: 0.10380

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.25931
Value Function Update Magnitude: 0.65697

Collected Steps per Second: 22,231.46435
Overall Steps per Second: 10,584.86251

Timestep Collection Time: 2.25104
Timestep Consumption Time: 2.47684
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.72788

Cumulative Model Updates: 11,712
Cumulative Timesteps: 97,786,346

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,117.65406
Policy Entropy: 1.27558
Value Function Loss: 0.10836

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.23770
Value Function Update Magnitude: 0.59235

Collected Steps per Second: 22,393.08657
Overall Steps per Second: 10,570.82229

Timestep Collection Time: 2.23426
Timestep Consumption Time: 2.49877
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.73303

Cumulative Model Updates: 11,718
Cumulative Timesteps: 97,836,378

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 97836378...
Checkpoint 97836378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,131.62339
Policy Entropy: 1.27017
Value Function Loss: 0.11453

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.25745
Value Function Update Magnitude: 0.49535

Collected Steps per Second: 22,006.65303
Overall Steps per Second: 10,415.55373

Timestep Collection Time: 2.27295
Timestep Consumption Time: 2.52948
PPO Batch Consumption Time: 0.30053
Total Iteration Time: 4.80243

Cumulative Model Updates: 11,724
Cumulative Timesteps: 97,886,398

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,891.87244
Policy Entropy: 1.26823
Value Function Loss: 0.11924

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11179
Policy Update Magnitude: 0.27417
Value Function Update Magnitude: 0.47289

Collected Steps per Second: 22,457.13506
Overall Steps per Second: 10,620.01499

Timestep Collection Time: 2.22878
Timestep Consumption Time: 2.48421
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.71299

Cumulative Model Updates: 11,730
Cumulative Timesteps: 97,936,450

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 97936450...
Checkpoint 97936450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,022.93431
Policy Entropy: 1.27645
Value Function Loss: 0.11846

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.27961
Value Function Update Magnitude: 0.43718

Collected Steps per Second: 21,971.49646
Overall Steps per Second: 10,650.35268

Timestep Collection Time: 2.27577
Timestep Consumption Time: 2.41910
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.69487

Cumulative Model Updates: 11,736
Cumulative Timesteps: 97,986,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,183.85673
Policy Entropy: 1.28248
Value Function Loss: 0.11498

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11114
Policy Update Magnitude: 0.28480
Value Function Update Magnitude: 0.45036

Collected Steps per Second: 22,507.60524
Overall Steps per Second: 10,792.68985

Timestep Collection Time: 2.22156
Timestep Consumption Time: 2.41139
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.63295

Cumulative Model Updates: 11,742
Cumulative Timesteps: 98,036,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 98036454...
Checkpoint 98036454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,711.30632
Policy Entropy: 1.28197
Value Function Loss: 0.11135

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11217
Policy Update Magnitude: 0.29588
Value Function Update Magnitude: 0.44246

Collected Steps per Second: 22,134.86772
Overall Steps per Second: 10,684.97504

Timestep Collection Time: 2.25978
Timestep Consumption Time: 2.42156
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.68134

Cumulative Model Updates: 11,748
Cumulative Timesteps: 98,086,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,634.00380
Policy Entropy: 1.28298
Value Function Loss: 0.11574

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.15067
Policy Update Magnitude: 0.25830
Value Function Update Magnitude: 0.44038

Collected Steps per Second: 22,560.44956
Overall Steps per Second: 10,582.35602

Timestep Collection Time: 2.21715
Timestep Consumption Time: 2.50958
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.72674

Cumulative Model Updates: 11,754
Cumulative Timesteps: 98,136,494

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 98136494...
Checkpoint 98136494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,220.27669
Policy Entropy: 1.28413
Value Function Loss: 0.11524

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.23274
Value Function Update Magnitude: 0.48054

Collected Steps per Second: 22,348.46506
Overall Steps per Second: 10,541.59855

Timestep Collection Time: 2.23747
Timestep Consumption Time: 2.50602
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.74349

Cumulative Model Updates: 11,760
Cumulative Timesteps: 98,186,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,995.51749
Policy Entropy: 1.28878
Value Function Loss: 0.11551

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.23253
Value Function Update Magnitude: 0.49941

Collected Steps per Second: 22,577.88986
Overall Steps per Second: 10,648.67950

Timestep Collection Time: 2.21473
Timestep Consumption Time: 2.48106
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.69579

Cumulative Model Updates: 11,766
Cumulative Timesteps: 98,236,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 98236502...
Checkpoint 98236502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,987.49514
Policy Entropy: 1.28053
Value Function Loss: 0.11543

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.24486
Value Function Update Magnitude: 0.45747

Collected Steps per Second: 22,307.42966
Overall Steps per Second: 10,575.08071

Timestep Collection Time: 2.24141
Timestep Consumption Time: 2.48669
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.72810

Cumulative Model Updates: 11,772
Cumulative Timesteps: 98,286,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,851.30605
Policy Entropy: 1.27793
Value Function Loss: 0.11603

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.25028
Value Function Update Magnitude: 0.48963

Collected Steps per Second: 22,757.16592
Overall Steps per Second: 10,756.35488

Timestep Collection Time: 2.19790
Timestep Consumption Time: 2.45219
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.65009

Cumulative Model Updates: 11,778
Cumulative Timesteps: 98,336,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 98336520...
Checkpoint 98336520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642.75481
Policy Entropy: 1.27914
Value Function Loss: 0.11748

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.28339
Value Function Update Magnitude: 0.50155

Collected Steps per Second: 22,385.75760
Overall Steps per Second: 10,638.97499

Timestep Collection Time: 2.23481
Timestep Consumption Time: 2.46752
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.70233

Cumulative Model Updates: 11,784
Cumulative Timesteps: 98,386,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983.47092
Policy Entropy: 1.27961
Value Function Loss: 0.11854

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.28680
Value Function Update Magnitude: 0.49845

Collected Steps per Second: 22,613.18534
Overall Steps per Second: 10,563.81229

Timestep Collection Time: 2.21296
Timestep Consumption Time: 2.52416
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.73712

Cumulative Model Updates: 11,790
Cumulative Timesteps: 98,436,590

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 98436590...
Checkpoint 98436590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,743.10162
Policy Entropy: 1.26919
Value Function Loss: 0.11662

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.27275
Value Function Update Magnitude: 0.55645

Collected Steps per Second: 22,270.54369
Overall Steps per Second: 10,565.65260

Timestep Collection Time: 2.24575
Timestep Consumption Time: 2.48789
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.73364

Cumulative Model Updates: 11,796
Cumulative Timesteps: 98,486,604

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,095.47059
Policy Entropy: 1.26889
Value Function Loss: 0.11349

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.26203
Value Function Update Magnitude: 0.53642

Collected Steps per Second: 21,893.01063
Overall Steps per Second: 10,473.35828

Timestep Collection Time: 2.28502
Timestep Consumption Time: 2.49148
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.77650

Cumulative Model Updates: 11,802
Cumulative Timesteps: 98,536,630

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 98536630...
Checkpoint 98536630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,276.74316
Policy Entropy: 1.27186
Value Function Loss: 0.10800

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.19225
Policy Update Magnitude: 0.23450
Value Function Update Magnitude: 0.53213

Collected Steps per Second: 21,889.33085
Overall Steps per Second: 10,547.78550

Timestep Collection Time: 2.28550
Timestep Consumption Time: 2.45749
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.74299

Cumulative Model Updates: 11,808
Cumulative Timesteps: 98,586,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.59770
Policy Entropy: 1.27197
Value Function Loss: 0.11057

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.17602
Policy Update Magnitude: 0.22707
Value Function Update Magnitude: 0.52037

Collected Steps per Second: 22,346.58541
Overall Steps per Second: 10,515.96755

Timestep Collection Time: 2.23775
Timestep Consumption Time: 2.51750
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.75524

Cumulative Model Updates: 11,814
Cumulative Timesteps: 98,636,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 98636664...
Checkpoint 98636664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,940.61492
Policy Entropy: 1.26931
Value Function Loss: 0.10707

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.16667
Policy Update Magnitude: 0.22321
Value Function Update Magnitude: 0.53650

Collected Steps per Second: 22,099.74124
Overall Steps per Second: 10,691.30817

Timestep Collection Time: 2.26464
Timestep Consumption Time: 2.41654
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.68119

Cumulative Model Updates: 11,820
Cumulative Timesteps: 98,686,712

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,670.93340
Policy Entropy: 1.27190
Value Function Loss: 0.10550

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.22907
Value Function Update Magnitude: 0.54623

Collected Steps per Second: 22,371.23754
Overall Steps per Second: 10,589.13920

Timestep Collection Time: 2.23510
Timestep Consumption Time: 2.48691
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.72201

Cumulative Model Updates: 11,826
Cumulative Timesteps: 98,736,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 98736714...
Checkpoint 98736714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,380.17117
Policy Entropy: 1.26737
Value Function Loss: 0.10526

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.14077
Policy Update Magnitude: 0.21556
Value Function Update Magnitude: 0.50770

Collected Steps per Second: 22,306.52084
Overall Steps per Second: 10,540.69380

Timestep Collection Time: 2.24221
Timestep Consumption Time: 2.50282
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.74504

Cumulative Model Updates: 11,832
Cumulative Timesteps: 98,786,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,879.84618
Policy Entropy: 1.27966
Value Function Loss: 0.10609

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13366
Policy Update Magnitude: 0.21790
Value Function Update Magnitude: 0.51949

Collected Steps per Second: 22,475.93248
Overall Steps per Second: 10,732.53579

Timestep Collection Time: 2.22576
Timestep Consumption Time: 2.43540
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.66115

Cumulative Model Updates: 11,838
Cumulative Timesteps: 98,836,756

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 98836756...
Checkpoint 98836756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,534.05130
Policy Entropy: 1.27489
Value Function Loss: 0.10951

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.22664
Value Function Update Magnitude: 0.52271

Collected Steps per Second: 21,705.87836
Overall Steps per Second: 10,434.46737

Timestep Collection Time: 2.30362
Timestep Consumption Time: 2.48839
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.79200

Cumulative Model Updates: 11,844
Cumulative Timesteps: 98,886,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,453.02035
Policy Entropy: 1.28574
Value Function Loss: 0.10610

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.26158
Value Function Update Magnitude: 0.51758

Collected Steps per Second: 22,622.91347
Overall Steps per Second: 10,780.21017

Timestep Collection Time: 2.21050
Timestep Consumption Time: 2.42837
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.63887

Cumulative Model Updates: 11,850
Cumulative Timesteps: 98,936,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 98936766...
Checkpoint 98936766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,588.63411
Policy Entropy: 1.27611
Value Function Loss: 0.10882

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.26569
Value Function Update Magnitude: 0.50095

Collected Steps per Second: 22,312.27267
Overall Steps per Second: 10,668.68158

Timestep Collection Time: 2.24119
Timestep Consumption Time: 2.44599
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.68718

Cumulative Model Updates: 11,856
Cumulative Timesteps: 98,986,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,819.57920
Policy Entropy: 1.28323
Value Function Loss: 0.11367

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11860
Policy Update Magnitude: 0.24348
Value Function Update Magnitude: 0.49836

Collected Steps per Second: 22,594.53755
Overall Steps per Second: 10,781.38159

Timestep Collection Time: 2.21372
Timestep Consumption Time: 2.42557
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.63929

Cumulative Model Updates: 11,862
Cumulative Timesteps: 99,036,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 99036790...
Checkpoint 99036790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,458.59972
Policy Entropy: 1.27627
Value Function Loss: 0.11379

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.25971
Value Function Update Magnitude: 0.48401

Collected Steps per Second: 22,272.05909
Overall Steps per Second: 10,637.25952

Timestep Collection Time: 2.24550
Timestep Consumption Time: 2.45608
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.70159

Cumulative Model Updates: 11,868
Cumulative Timesteps: 99,086,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,963.88117
Policy Entropy: 1.28246
Value Function Loss: 0.11340

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10881
Policy Update Magnitude: 0.27642
Value Function Update Magnitude: 0.50528

Collected Steps per Second: 22,680.59548
Overall Steps per Second: 10,618.24512

Timestep Collection Time: 2.20479
Timestep Consumption Time: 2.50465
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.70944

Cumulative Model Updates: 11,874
Cumulative Timesteps: 99,136,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 99136808...
Checkpoint 99136808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,836.37330
Policy Entropy: 1.28473
Value Function Loss: 0.11064

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.29180
Value Function Update Magnitude: 0.53213

Collected Steps per Second: 22,416.90187
Overall Steps per Second: 10,497.09303

Timestep Collection Time: 2.23207
Timestep Consumption Time: 2.53459
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.76665

Cumulative Model Updates: 11,880
Cumulative Timesteps: 99,186,844

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.39507
Policy Entropy: 1.28553
Value Function Loss: 0.11614

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.29278
Value Function Update Magnitude: 0.53314

Collected Steps per Second: 21,982.74901
Overall Steps per Second: 10,533.93662

Timestep Collection Time: 2.27497
Timestep Consumption Time: 2.47255
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.74751

Cumulative Model Updates: 11,886
Cumulative Timesteps: 99,236,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 99236854...
Checkpoint 99236854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,232.89441
Policy Entropy: 1.29207
Value Function Loss: 0.11578

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.15459
Policy Update Magnitude: 0.25295
Value Function Update Magnitude: 0.55949

Collected Steps per Second: 22,082.54106
Overall Steps per Second: 10,622.07679

Timestep Collection Time: 2.26505
Timestep Consumption Time: 2.44382
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.70887

Cumulative Model Updates: 11,892
Cumulative Timesteps: 99,286,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,650.52254
Policy Entropy: 1.30130
Value Function Loss: 0.11763

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.16731
Policy Update Magnitude: 0.25546
Value Function Update Magnitude: 0.55638

Collected Steps per Second: 22,584.86111
Overall Steps per Second: 10,533.94652

Timestep Collection Time: 2.21440
Timestep Consumption Time: 2.53329
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.74770

Cumulative Model Updates: 11,898
Cumulative Timesteps: 99,336,884

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 99336884...
Checkpoint 99336884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,627.93600
Policy Entropy: 1.31274
Value Function Loss: 0.11514

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14544
Policy Update Magnitude: 0.26269
Value Function Update Magnitude: 0.52650

Collected Steps per Second: 22,516.24941
Overall Steps per Second: 10,595.20223

Timestep Collection Time: 2.22062
Timestep Consumption Time: 2.49850
PPO Batch Consumption Time: 0.29733
Total Iteration Time: 4.71912

Cumulative Model Updates: 11,904
Cumulative Timesteps: 99,386,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,743.75841
Policy Entropy: 1.32093
Value Function Loss: 0.11609

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.26862
Value Function Update Magnitude: 0.52387

Collected Steps per Second: 22,847.12081
Overall Steps per Second: 10,843.94977

Timestep Collection Time: 2.18855
Timestep Consumption Time: 2.42250
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.61105

Cumulative Model Updates: 11,910
Cumulative Timesteps: 99,436,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 99436886...
Checkpoint 99436886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,224.68674
Policy Entropy: 1.32299
Value Function Loss: 0.11350

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.27405
Value Function Update Magnitude: 0.58537

Collected Steps per Second: 22,177.46905
Overall Steps per Second: 10,697.16167

Timestep Collection Time: 2.25553
Timestep Consumption Time: 2.42066
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.67619

Cumulative Model Updates: 11,916
Cumulative Timesteps: 99,486,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,796.09172
Policy Entropy: 1.31445
Value Function Loss: 0.11475

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10216
Policy Update Magnitude: 0.28069
Value Function Update Magnitude: 0.65844

Collected Steps per Second: 22,615.09588
Overall Steps per Second: 10,784.02180

Timestep Collection Time: 2.21144
Timestep Consumption Time: 2.42616
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.63760

Cumulative Model Updates: 11,922
Cumulative Timesteps: 99,536,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 99536920...
Checkpoint 99536920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,167.96533
Policy Entropy: 1.33139
Value Function Loss: 0.11450

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.27538
Value Function Update Magnitude: 0.55866

Collected Steps per Second: 21,866.76608
Overall Steps per Second: 10,616.90230

Timestep Collection Time: 2.28749
Timestep Consumption Time: 2.42387
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.71136

Cumulative Model Updates: 11,928
Cumulative Timesteps: 99,586,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,238.95903
Policy Entropy: 1.32396
Value Function Loss: 0.10585

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.16646
Policy Update Magnitude: 0.24211
Value Function Update Magnitude: 0.57344

Collected Steps per Second: 22,381.40734
Overall Steps per Second: 10,560.68779

Timestep Collection Time: 2.23409
Timestep Consumption Time: 2.50064
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.73473

Cumulative Model Updates: 11,934
Cumulative Timesteps: 99,636,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 99636942...
Checkpoint 99636942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,968.62778
Policy Entropy: 1.31420
Value Function Loss: 0.10717

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.16829
Policy Update Magnitude: 0.24593
Value Function Update Magnitude: 0.63954

Collected Steps per Second: 22,132.39405
Overall Steps per Second: 10,682.87178

Timestep Collection Time: 2.26022
Timestep Consumption Time: 2.42242
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.68264

Cumulative Model Updates: 11,940
Cumulative Timesteps: 99,686,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,788.11324
Policy Entropy: 1.30389
Value Function Loss: 0.11145

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.28165
Value Function Update Magnitude: 0.67272

Collected Steps per Second: 22,509.86224
Overall Steps per Second: 10,629.17145

Timestep Collection Time: 2.22267
Timestep Consumption Time: 2.48438
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.70705

Cumulative Model Updates: 11,946
Cumulative Timesteps: 99,736,998

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 99736998...
Checkpoint 99736998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,415.68134
Policy Entropy: 1.30107
Value Function Loss: 0.11408

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.30038
Value Function Update Magnitude: 0.64218

Collected Steps per Second: 22,603.49720
Overall Steps per Second: 10,802.63211

Timestep Collection Time: 2.21293
Timestep Consumption Time: 2.41742
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.63035

Cumulative Model Updates: 11,952
Cumulative Timesteps: 99,787,018

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,092.39048
Policy Entropy: 1.31892
Value Function Loss: 0.10754

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07800
Policy Update Magnitude: 0.30827
Value Function Update Magnitude: 0.65196

Collected Steps per Second: 22,493.38336
Overall Steps per Second: 10,413.08738

Timestep Collection Time: 2.22341
Timestep Consumption Time: 2.57939
PPO Batch Consumption Time: 0.30968
Total Iteration Time: 4.80280

Cumulative Model Updates: 11,958
Cumulative Timesteps: 99,837,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 99837030...
Checkpoint 99837030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,805.31834
Policy Entropy: 1.31050
Value Function Loss: 0.10443

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.31365
Value Function Update Magnitude: 0.64031

Collected Steps per Second: 22,053.27121
Overall Steps per Second: 10,462.58812

Timestep Collection Time: 2.26760
Timestep Consumption Time: 2.51210
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.77970

Cumulative Model Updates: 11,964
Cumulative Timesteps: 99,887,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,739.36971
Policy Entropy: 1.31815
Value Function Loss: 0.10482

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 0.30634
Value Function Update Magnitude: 0.64206

Collected Steps per Second: 22,508.64663
Overall Steps per Second: 10,775.12198

Timestep Collection Time: 2.22208
Timestep Consumption Time: 2.41972
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.64180

Cumulative Model Updates: 11,970
Cumulative Timesteps: 99,937,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 99937054...
Checkpoint 99937054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,203.17685
Policy Entropy: 1.31675
Value Function Loss: 0.10719

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.26972
Value Function Update Magnitude: 0.64579

Collected Steps per Second: 22,261.66484
Overall Steps per Second: 10,641.78669

Timestep Collection Time: 2.24754
Timestep Consumption Time: 2.45411
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.70165

Cumulative Model Updates: 11,976
Cumulative Timesteps: 99,987,088

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,671.20234
Policy Entropy: 1.30198
Value Function Loss: 0.10885

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.12291
Policy Update Magnitude: 0.24492
Value Function Update Magnitude: 0.66401

Collected Steps per Second: 22,716.77551
Overall Steps per Second: 10,804.05320

Timestep Collection Time: 2.20102
Timestep Consumption Time: 2.42688
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.62789

Cumulative Model Updates: 11,982
Cumulative Timesteps: 100,037,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 100037088...
Checkpoint 100037088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,814.70093
Policy Entropy: 1.30463
Value Function Loss: 0.10810

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10764
Policy Update Magnitude: 0.25182
Value Function Update Magnitude: 0.67538

Collected Steps per Second: 21,942.51342
Overall Steps per Second: 10,434.01889

Timestep Collection Time: 2.27959
Timestep Consumption Time: 2.51434
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.79393

Cumulative Model Updates: 11,988
Cumulative Timesteps: 100,087,108

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,209.97920
Policy Entropy: 1.29552
Value Function Loss: 0.10624

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.23206
Value Function Update Magnitude: 0.68294

Collected Steps per Second: 22,630.77717
Overall Steps per Second: 10,769.66152

Timestep Collection Time: 2.21009
Timestep Consumption Time: 2.43407
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.64416

Cumulative Model Updates: 11,994
Cumulative Timesteps: 100,137,124

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 100137124...
Checkpoint 100137124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.81079
Policy Entropy: 1.29601
Value Function Loss: 0.10395

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.25389
Value Function Update Magnitude: 0.68663

Collected Steps per Second: 22,365.95777
Overall Steps per Second: 10,640.06680

Timestep Collection Time: 2.23760
Timestep Consumption Time: 2.46594
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.70354

Cumulative Model Updates: 12,000
Cumulative Timesteps: 100,187,170

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,104.12080
Policy Entropy: 1.28224
Value Function Loss: 0.10695

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.30672
Value Function Update Magnitude: 0.67733

Collected Steps per Second: 22,652.78716
Overall Steps per Second: 10,800.83591

Timestep Collection Time: 2.20732
Timestep Consumption Time: 2.42213
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.62946

Cumulative Model Updates: 12,006
Cumulative Timesteps: 100,237,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 100237172...
Checkpoint 100237172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,724.42993
Policy Entropy: 1.27967
Value Function Loss: 0.10540

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08057
Policy Update Magnitude: 0.31399
Value Function Update Magnitude: 0.65632

Collected Steps per Second: 21,592.31034
Overall Steps per Second: 10,249.47664

Timestep Collection Time: 2.31749
Timestep Consumption Time: 2.56471
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.88220

Cumulative Model Updates: 12,012
Cumulative Timesteps: 100,287,212

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,297.92684
Policy Entropy: 1.29698
Value Function Loss: 0.11079

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.31661
Value Function Update Magnitude: 0.60127

Collected Steps per Second: 20,764.60288
Overall Steps per Second: 10,007.40608

Timestep Collection Time: 2.41035
Timestep Consumption Time: 2.59094
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 5.00130

Cumulative Model Updates: 12,018
Cumulative Timesteps: 100,337,262

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 100337262...
Checkpoint 100337262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,766.67044
Policy Entropy: 1.30578
Value Function Loss: 0.11009

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.28559
Value Function Update Magnitude: 0.60321

Collected Steps per Second: 22,187.11077
Overall Steps per Second: 10,666.37322

Timestep Collection Time: 2.25428
Timestep Consumption Time: 2.43485
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.68913

Cumulative Model Updates: 12,024
Cumulative Timesteps: 100,387,278

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,444.13982
Policy Entropy: 1.30802
Value Function Loss: 0.11564

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08902
Policy Update Magnitude: 0.27519
Value Function Update Magnitude: 0.53836

Collected Steps per Second: 22,639.48191
Overall Steps per Second: 10,631.07537

Timestep Collection Time: 2.20959
Timestep Consumption Time: 2.49586
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.70545

Cumulative Model Updates: 12,030
Cumulative Timesteps: 100,437,302

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 100437302...
Checkpoint 100437302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,562.83467
Policy Entropy: 1.30990
Value Function Loss: 0.11532

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.29714
Value Function Update Magnitude: 0.49725

Collected Steps per Second: 21,970.55075
Overall Steps per Second: 10,444.55875

Timestep Collection Time: 2.27687
Timestep Consumption Time: 2.51261
PPO Batch Consumption Time: 0.29715
Total Iteration Time: 4.78948

Cumulative Model Updates: 12,036
Cumulative Timesteps: 100,487,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,659.94727
Policy Entropy: 1.32252
Value Function Loss: 0.11382

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07191
Policy Update Magnitude: 0.31720
Value Function Update Magnitude: 0.49174

Collected Steps per Second: 22,434.65884
Overall Steps per Second: 10,443.79466

Timestep Collection Time: 2.22932
Timestep Consumption Time: 2.55955
PPO Batch Consumption Time: 0.30693
Total Iteration Time: 4.78887

Cumulative Model Updates: 12,042
Cumulative Timesteps: 100,537,340

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 100537340...
Checkpoint 100537340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,334.42512
Policy Entropy: 1.31079
Value Function Loss: 0.10966

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06114
Policy Update Magnitude: 0.32062
Value Function Update Magnitude: 0.49201

Collected Steps per Second: 22,184.63189
Overall Steps per Second: 10,680.99385

Timestep Collection Time: 2.25489
Timestep Consumption Time: 2.42857
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.68346

Cumulative Model Updates: 12,048
Cumulative Timesteps: 100,587,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,801.47139
Policy Entropy: 1.31979
Value Function Loss: 0.10331

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07635
Policy Update Magnitude: 0.32149
Value Function Update Magnitude: 0.51473

Collected Steps per Second: 22,563.86202
Overall Steps per Second: 10,519.52397

Timestep Collection Time: 2.21638
Timestep Consumption Time: 2.53764
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.75402

Cumulative Model Updates: 12,054
Cumulative Timesteps: 100,637,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 100637374...
Checkpoint 100637374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,003.86069
Policy Entropy: 1.31076
Value Function Loss: 0.10890

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08250
Policy Update Magnitude: 0.30474
Value Function Update Magnitude: 0.51267

Collected Steps per Second: 21,972.33110
Overall Steps per Second: 10,583.40294

Timestep Collection Time: 2.27586
Timestep Consumption Time: 2.44908
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.72495

Cumulative Model Updates: 12,060
Cumulative Timesteps: 100,687,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.75988
Policy Entropy: 1.30749
Value Function Loss: 0.11238

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.27848
Value Function Update Magnitude: 0.54011

Collected Steps per Second: 22,397.06062
Overall Steps per Second: 10,574.54626

Timestep Collection Time: 2.23253
Timestep Consumption Time: 2.49600
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.72852

Cumulative Model Updates: 12,066
Cumulative Timesteps: 100,737,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 100737382...
Checkpoint 100737382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,637.35376
Policy Entropy: 1.31303
Value Function Loss: 0.11467

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.25007
Value Function Update Magnitude: 0.50434

Collected Steps per Second: 22,183.73670
Overall Steps per Second: 10,572.09426

Timestep Collection Time: 2.25435
Timestep Consumption Time: 2.47602
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.73038

Cumulative Model Updates: 12,072
Cumulative Timesteps: 100,787,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,918.75724
Policy Entropy: 1.31436
Value Function Loss: 0.10796

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12712
Policy Update Magnitude: 0.24461
Value Function Update Magnitude: 0.54728

Collected Steps per Second: 22,711.36668
Overall Steps per Second: 10,802.60015

Timestep Collection Time: 2.20242
Timestep Consumption Time: 2.42795
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.63037

Cumulative Model Updates: 12,078
Cumulative Timesteps: 100,837,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 100837412...
Checkpoint 100837412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,607.09044
Policy Entropy: 1.31125
Value Function Loss: 0.10449

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.24228
Value Function Update Magnitude: 0.60824

Collected Steps per Second: 22,147.22973
Overall Steps per Second: 10,699.93267

Timestep Collection Time: 2.25762
Timestep Consumption Time: 2.41531
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.67293

Cumulative Model Updates: 12,084
Cumulative Timesteps: 100,887,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,676.07067
Policy Entropy: 1.32599
Value Function Loss: 0.09975

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.22640
Value Function Update Magnitude: 0.62622

Collected Steps per Second: 22,215.31257
Overall Steps per Second: 10,487.24293

Timestep Collection Time: 2.25160
Timestep Consumption Time: 2.51800
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 4.76960

Cumulative Model Updates: 12,090
Cumulative Timesteps: 100,937,432

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 100937432...
Checkpoint 100937432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.54050
Policy Entropy: 1.30941
Value Function Loss: 0.10268

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.12638
Policy Update Magnitude: 0.25014
Value Function Update Magnitude: 0.62477

Collected Steps per Second: 22,305.03064
Overall Steps per Second: 10,621.58166

Timestep Collection Time: 2.24263
Timestep Consumption Time: 2.46683
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.70947

Cumulative Model Updates: 12,096
Cumulative Timesteps: 100,987,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,402.45959
Policy Entropy: 1.31946
Value Function Loss: 0.10330

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.26303
Value Function Update Magnitude: 0.65219

Collected Steps per Second: 22,485.77637
Overall Steps per Second: 10,595.66595

Timestep Collection Time: 2.22478
Timestep Consumption Time: 2.49658
PPO Batch Consumption Time: 0.29602
Total Iteration Time: 4.72136

Cumulative Model Updates: 12,102
Cumulative Timesteps: 101,037,480

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 101037480...
Checkpoint 101037480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,978.37028
Policy Entropy: 1.32693
Value Function Loss: 0.10836

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.27772
Value Function Update Magnitude: 0.65874

Collected Steps per Second: 22,328.08659
Overall Steps per Second: 10,555.93426

Timestep Collection Time: 2.23951
Timestep Consumption Time: 2.49754
PPO Batch Consumption Time: 0.29694
Total Iteration Time: 4.73705

Cumulative Model Updates: 12,108
Cumulative Timesteps: 101,087,484

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,046.88020
Policy Entropy: 1.33101
Value Function Loss: 0.10760

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.27262
Value Function Update Magnitude: 0.65369

Collected Steps per Second: 22,691.20691
Overall Steps per Second: 10,793.63199

Timestep Collection Time: 2.20367
Timestep Consumption Time: 2.42906
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.63273

Cumulative Model Updates: 12,114
Cumulative Timesteps: 101,137,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 101137488...
Checkpoint 101137488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,000.69922
Policy Entropy: 1.33425
Value Function Loss: 0.10686

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.15044
Policy Update Magnitude: 0.26578
Value Function Update Magnitude: 0.59562

Collected Steps per Second: 21,772.29966
Overall Steps per Second: 10,348.29923

Timestep Collection Time: 2.29751
Timestep Consumption Time: 2.53633
PPO Batch Consumption Time: 0.30199
Total Iteration Time: 4.83384

Cumulative Model Updates: 12,120
Cumulative Timesteps: 101,187,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,723.63754
Policy Entropy: 1.33873
Value Function Loss: 0.10655

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.26321
Value Function Update Magnitude: 0.59820

Collected Steps per Second: 22,668.87482
Overall Steps per Second: 10,801.28200

Timestep Collection Time: 2.20673
Timestep Consumption Time: 2.42458
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.63130

Cumulative Model Updates: 12,126
Cumulative Timesteps: 101,237,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 101237534...
Checkpoint 101237534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,472.10433
Policy Entropy: 1.33178
Value Function Loss: 0.10716

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.27180
Value Function Update Magnitude: 0.60687

Collected Steps per Second: 21,903.48398
Overall Steps per Second: 10,646.76285

Timestep Collection Time: 2.28302
Timestep Consumption Time: 2.41381
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.69683

Cumulative Model Updates: 12,132
Cumulative Timesteps: 101,287,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,105.85134
Policy Entropy: 1.32998
Value Function Loss: 0.11629

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.24842
Value Function Update Magnitude: 0.53235

Collected Steps per Second: 22,901.32048
Overall Steps per Second: 10,844.01013

Timestep Collection Time: 2.18407
Timestep Consumption Time: 2.42843
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.61250

Cumulative Model Updates: 12,138
Cumulative Timesteps: 101,337,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 101337558...
Checkpoint 101337558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,562.95888
Policy Entropy: 1.33108
Value Function Loss: 0.12283

Mean KL Divergence: 0.03314
SB3 Clip Fraction: 0.22001
Policy Update Magnitude: 0.21753
Value Function Update Magnitude: 0.56084

Collected Steps per Second: 22,207.09065
Overall Steps per Second: 10,696.98816

Timestep Collection Time: 2.25180
Timestep Consumption Time: 2.42297
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.67477

Cumulative Model Updates: 12,144
Cumulative Timesteps: 101,387,564

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.50421
Policy Entropy: 1.35464
Value Function Loss: 0.12879

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.16492
Policy Update Magnitude: 0.22751
Value Function Update Magnitude: 0.62426

Collected Steps per Second: 22,543.58794
Overall Steps per Second: 10,612.11150

Timestep Collection Time: 2.21864
Timestep Consumption Time: 2.49447
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.71311

Cumulative Model Updates: 12,150
Cumulative Timesteps: 101,437,580

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 101437580...
Checkpoint 101437580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,625.50428
Policy Entropy: 1.35023
Value Function Loss: 0.12969

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14688
Policy Update Magnitude: 0.24780
Value Function Update Magnitude: 0.54677

Collected Steps per Second: 21,988.13836
Overall Steps per Second: 10,538.43034

Timestep Collection Time: 2.27441
Timestep Consumption Time: 2.47108
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.74549

Cumulative Model Updates: 12,156
Cumulative Timesteps: 101,487,590

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.03197
Policy Entropy: 1.34699
Value Function Loss: 0.13496

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.24549
Value Function Update Magnitude: 0.48215

Collected Steps per Second: 22,614.34997
Overall Steps per Second: 10,788.08073

Timestep Collection Time: 2.21187
Timestep Consumption Time: 2.42473
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.63660

Cumulative Model Updates: 12,162
Cumulative Timesteps: 101,537,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 101537610...
Checkpoint 101537610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,735.38736
Policy Entropy: 1.34494
Value Function Loss: 0.12866

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13251
Policy Update Magnitude: 0.25166
Value Function Update Magnitude: 0.47415

Collected Steps per Second: 22,042.27027
Overall Steps per Second: 10,644.79827

Timestep Collection Time: 2.26946
Timestep Consumption Time: 2.42993
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.69938

Cumulative Model Updates: 12,168
Cumulative Timesteps: 101,587,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.41633
Policy Entropy: 1.34263
Value Function Loss: 0.12797

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.22726
Value Function Update Magnitude: 0.44700

Collected Steps per Second: 22,622.62260
Overall Steps per Second: 10,621.96070

Timestep Collection Time: 2.21150
Timestep Consumption Time: 2.49855
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.71005

Cumulative Model Updates: 12,174
Cumulative Timesteps: 101,637,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 101637664...
Checkpoint 101637664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,131.01374
Policy Entropy: 1.34002
Value Function Loss: 0.12024

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.22604
Value Function Update Magnitude: 0.45511

Collected Steps per Second: 21,887.79736
Overall Steps per Second: 10,628.00883

Timestep Collection Time: 2.28538
Timestep Consumption Time: 2.42124
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.70662

Cumulative Model Updates: 12,180
Cumulative Timesteps: 101,687,686

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,907.47388
Policy Entropy: 1.32839
Value Function Loss: 0.12333

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11036
Policy Update Magnitude: 0.22930
Value Function Update Magnitude: 0.44275

Collected Steps per Second: 22,585.57528
Overall Steps per Second: 10,773.92238

Timestep Collection Time: 2.21522
Timestep Consumption Time: 2.42859
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.64381

Cumulative Model Updates: 12,186
Cumulative Timesteps: 101,737,718

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 101737718...
Checkpoint 101737718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,520.23549
Policy Entropy: 1.34040
Value Function Loss: 0.11749

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06930
Policy Update Magnitude: 0.28105
Value Function Update Magnitude: 0.45959

Collected Steps per Second: 22,083.94459
Overall Steps per Second: 10,651.54309

Timestep Collection Time: 2.26527
Timestep Consumption Time: 2.43133
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.69660

Cumulative Model Updates: 12,192
Cumulative Timesteps: 101,787,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,954.87220
Policy Entropy: 1.34560
Value Function Loss: 0.12170

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06050
Policy Update Magnitude: 0.32650
Value Function Update Magnitude: 0.50136

Collected Steps per Second: 21,905.72155
Overall Steps per Second: 10,555.76306

Timestep Collection Time: 2.28278
Timestep Consumption Time: 2.45453
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.73732

Cumulative Model Updates: 12,198
Cumulative Timesteps: 101,837,750

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 101837750...
Checkpoint 101837750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.37368
Policy Entropy: 1.35663
Value Function Loss: 0.11523

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06324
Policy Update Magnitude: 0.33605
Value Function Update Magnitude: 0.54037

Collected Steps per Second: 21,754.03464
Overall Steps per Second: 10,595.15334

Timestep Collection Time: 2.29888
Timestep Consumption Time: 2.42120
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.72008

Cumulative Model Updates: 12,204
Cumulative Timesteps: 101,887,760

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,116.61143
Policy Entropy: 1.35282
Value Function Loss: 0.11433

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07259
Policy Update Magnitude: 0.34301
Value Function Update Magnitude: 0.57084

Collected Steps per Second: 22,700.01360
Overall Steps per Second: 10,643.26764

Timestep Collection Time: 2.20493
Timestep Consumption Time: 2.49776
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.70269

Cumulative Model Updates: 12,210
Cumulative Timesteps: 101,937,812

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 101937812...
Checkpoint 101937812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,481.68264
Policy Entropy: 1.37088
Value Function Loss: 0.11313

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.32317
Value Function Update Magnitude: 0.60186

Collected Steps per Second: 22,106.91514
Overall Steps per Second: 10,483.91652

Timestep Collection Time: 2.26273
Timestep Consumption Time: 2.50858
PPO Batch Consumption Time: 0.29733
Total Iteration Time: 4.77131

Cumulative Model Updates: 12,216
Cumulative Timesteps: 101,987,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,497.14441
Policy Entropy: 1.35762
Value Function Loss: 0.11309

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.29459
Value Function Update Magnitude: 0.57259

Collected Steps per Second: 22,396.41958
Overall Steps per Second: 10,551.45522

Timestep Collection Time: 2.23277
Timestep Consumption Time: 2.50648
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.73925

Cumulative Model Updates: 12,222
Cumulative Timesteps: 102,037,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 102037840...
Checkpoint 102037840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,200.58706
Policy Entropy: 1.34409
Value Function Loss: 0.11627

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.27755
Value Function Update Magnitude: 0.54638

Collected Steps per Second: 22,163.47977
Overall Steps per Second: 10,552.83155

Timestep Collection Time: 2.25705
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.74034

Cumulative Model Updates: 12,228
Cumulative Timesteps: 102,087,864

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197.86566
Policy Entropy: 1.33394
Value Function Loss: 0.11885

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10885
Policy Update Magnitude: 0.29972
Value Function Update Magnitude: 0.57047

Collected Steps per Second: 22,706.46329
Overall Steps per Second: 10,796.73514

Timestep Collection Time: 2.20202
Timestep Consumption Time: 2.42901
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.63103

Cumulative Model Updates: 12,234
Cumulative Timesteps: 102,137,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 102137864...
Checkpoint 102137864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,808.73344
Policy Entropy: 1.33989
Value Function Loss: 0.12258

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.29222
Value Function Update Magnitude: 0.64549

Collected Steps per Second: 22,046.13030
Overall Steps per Second: 10,658.29308

Timestep Collection Time: 2.26933
Timestep Consumption Time: 2.42466
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.69400

Cumulative Model Updates: 12,240
Cumulative Timesteps: 102,187,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,328.09711
Policy Entropy: 1.35007
Value Function Loss: 0.11575

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11674
Policy Update Magnitude: 0.27734
Value Function Update Magnitude: 0.70490

Collected Steps per Second: 22,539.03531
Overall Steps per Second: 10,580.57141

Timestep Collection Time: 2.21873
Timestep Consumption Time: 2.50767
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.72640

Cumulative Model Updates: 12,246
Cumulative Timesteps: 102,237,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 102237902...
Checkpoint 102237902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.65228
Policy Entropy: 1.35529
Value Function Loss: 0.11491

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12464
Policy Update Magnitude: 0.28438
Value Function Update Magnitude: 0.70720

Collected Steps per Second: 22,135.63718
Overall Steps per Second: 10,598.08658

Timestep Collection Time: 2.25979
Timestep Consumption Time: 2.46011
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.71991

Cumulative Model Updates: 12,252
Cumulative Timesteps: 102,287,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,349.82335
Policy Entropy: 1.35385
Value Function Loss: 0.11160

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.11928
Policy Update Magnitude: 0.27043
Value Function Update Magnitude: 0.66118

Collected Steps per Second: 22,621.10130
Overall Steps per Second: 10,630.34214

Timestep Collection Time: 2.21148
Timestep Consumption Time: 2.49449
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.70596

Cumulative Model Updates: 12,258
Cumulative Timesteps: 102,337,950

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 102337950...
Checkpoint 102337950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,460.13537
Policy Entropy: 1.35279
Value Function Loss: 0.11607

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.26321
Value Function Update Magnitude: 0.68872

Collected Steps per Second: 22,228.90224
Overall Steps per Second: 10,515.97942

Timestep Collection Time: 2.25049
Timestep Consumption Time: 2.50665
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 4.75714

Cumulative Model Updates: 12,264
Cumulative Timesteps: 102,387,976

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,310.29957
Policy Entropy: 1.35711
Value Function Loss: 0.11704

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.25767
Value Function Update Magnitude: 0.69467

Collected Steps per Second: 22,627.83376
Overall Steps per Second: 10,770.60336

Timestep Collection Time: 2.21029
Timestep Consumption Time: 2.43328
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.64357

Cumulative Model Updates: 12,270
Cumulative Timesteps: 102,437,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 102437990...
Checkpoint 102437990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,990.45777
Policy Entropy: 1.36654
Value Function Loss: 0.11095

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10776
Policy Update Magnitude: 0.27048
Value Function Update Magnitude: 0.67025

Collected Steps per Second: 22,121.41142
Overall Steps per Second: 10,529.43537

Timestep Collection Time: 2.26107
Timestep Consumption Time: 2.48923
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.75030

Cumulative Model Updates: 12,276
Cumulative Timesteps: 102,488,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,815.30042
Policy Entropy: 1.35802
Value Function Loss: 0.10849

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.29223
Value Function Update Magnitude: 0.67552

Collected Steps per Second: 22,447.91738
Overall Steps per Second: 10,665.00649

Timestep Collection Time: 2.22773
Timestep Consumption Time: 2.46125
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.68898

Cumulative Model Updates: 12,282
Cumulative Timesteps: 102,538,016

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 102538016...
Checkpoint 102538016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,627.15286
Policy Entropy: 1.36836
Value Function Loss: 0.10486

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.30671
Value Function Update Magnitude: 0.65586

Collected Steps per Second: 22,102.75408
Overall Steps per Second: 10,605.69422

Timestep Collection Time: 2.26370
Timestep Consumption Time: 2.45395
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.71765

Cumulative Model Updates: 12,288
Cumulative Timesteps: 102,588,050

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,311.08219
Policy Entropy: 1.37556
Value Function Loss: 0.10812

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.32862
Value Function Update Magnitude: 0.57012

Collected Steps per Second: 22,528.91408
Overall Steps per Second: 10,646.23403

Timestep Collection Time: 2.21964
Timestep Consumption Time: 2.47742
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.69706

Cumulative Model Updates: 12,294
Cumulative Timesteps: 102,638,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 102638056...
Checkpoint 102638056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,653.52224
Policy Entropy: 1.38095
Value Function Loss: 0.10431

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.33608
Value Function Update Magnitude: 0.54415

Collected Steps per Second: 22,393.21309
Overall Steps per Second: 10,601.32149

Timestep Collection Time: 2.23371
Timestep Consumption Time: 2.48457
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.71828

Cumulative Model Updates: 12,300
Cumulative Timesteps: 102,688,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,066.45533
Policy Entropy: 1.37903
Value Function Loss: 0.10350

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.32361
Value Function Update Magnitude: 0.56664

Collected Steps per Second: 22,823.84616
Overall Steps per Second: 10,721.81996

Timestep Collection Time: 2.19244
Timestep Consumption Time: 2.47467
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.66712

Cumulative Model Updates: 12,306
Cumulative Timesteps: 102,738,116

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 102738116...
Checkpoint 102738116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,098.04977
Policy Entropy: 1.37673
Value Function Loss: 0.10799

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.29493
Value Function Update Magnitude: 0.59399

Collected Steps per Second: 21,920.72113
Overall Steps per Second: 10,633.28032

Timestep Collection Time: 2.28177
Timestep Consumption Time: 2.42214
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.70391

Cumulative Model Updates: 12,312
Cumulative Timesteps: 102,788,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,604.01641
Policy Entropy: 1.37080
Value Function Loss: 0.11332

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.26284
Value Function Update Magnitude: 0.63726

Collected Steps per Second: 22,881.11268
Overall Steps per Second: 10,742.53488

Timestep Collection Time: 2.18608
Timestep Consumption Time: 2.47017
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.65626

Cumulative Model Updates: 12,318
Cumulative Timesteps: 102,838,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 102838154...
Checkpoint 102838154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969.37309
Policy Entropy: 1.36942
Value Function Loss: 0.11016

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.24696
Value Function Update Magnitude: 0.65911

Collected Steps per Second: 22,060.98101
Overall Steps per Second: 10,506.21032

Timestep Collection Time: 2.26708
Timestep Consumption Time: 2.49334
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.76042

Cumulative Model Updates: 12,324
Cumulative Timesteps: 102,888,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,022.00781
Policy Entropy: 1.36003
Value Function Loss: 0.10458

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13636
Policy Update Magnitude: 0.24860
Value Function Update Magnitude: 0.65985

Collected Steps per Second: 22,596.07815
Overall Steps per Second: 10,733.59150

Timestep Collection Time: 2.21463
Timestep Consumption Time: 2.44755
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.66219

Cumulative Model Updates: 12,330
Cumulative Timesteps: 102,938,210

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 102938210...
Checkpoint 102938210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,029.32794
Policy Entropy: 1.36267
Value Function Loss: 0.10039

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.25491
Value Function Update Magnitude: 0.64549

Collected Steps per Second: 22,154.11454
Overall Steps per Second: 10,478.92671

Timestep Collection Time: 2.25809
Timestep Consumption Time: 2.51587
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.77396

Cumulative Model Updates: 12,336
Cumulative Timesteps: 102,988,236

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,003.29155
Policy Entropy: 1.37163
Value Function Loss: 0.10260

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.28127
Value Function Update Magnitude: 0.66965

Collected Steps per Second: 22,552.27437
Overall Steps per Second: 10,678.37618

Timestep Collection Time: 2.21805
Timestep Consumption Time: 2.46637
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.68442

Cumulative Model Updates: 12,342
Cumulative Timesteps: 103,038,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 103038258...
Checkpoint 103038258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.58010
Policy Entropy: 1.35545
Value Function Loss: 0.10832

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.28370
Value Function Update Magnitude: 0.68098

Collected Steps per Second: 22,194.02708
Overall Steps per Second: 10,680.36509

Timestep Collection Time: 2.25421
Timestep Consumption Time: 2.43009
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.68430

Cumulative Model Updates: 12,348
Cumulative Timesteps: 103,088,288

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,263.03018
Policy Entropy: 1.35107
Value Function Loss: 0.10687

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.27087
Value Function Update Magnitude: 0.70685

Collected Steps per Second: 22,579.01798
Overall Steps per Second: 10,469.08177

Timestep Collection Time: 2.21480
Timestep Consumption Time: 2.56193
PPO Batch Consumption Time: 0.30509
Total Iteration Time: 4.77673

Cumulative Model Updates: 12,354
Cumulative Timesteps: 103,138,296

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 103138296...
Checkpoint 103138296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,393.59155
Policy Entropy: 1.34505
Value Function Loss: 0.10782

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.28023
Value Function Update Magnitude: 0.65017

Collected Steps per Second: 22,117.70965
Overall Steps per Second: 10,515.96918

Timestep Collection Time: 2.26063
Timestep Consumption Time: 2.49404
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.75467

Cumulative Model Updates: 12,360
Cumulative Timesteps: 103,188,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.76380
Policy Entropy: 1.35079
Value Function Loss: 0.10332

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.15224
Policy Update Magnitude: 0.25607
Value Function Update Magnitude: 0.62691

Collected Steps per Second: 22,457.93859
Overall Steps per Second: 10,545.06104

Timestep Collection Time: 2.22861
Timestep Consumption Time: 2.51769
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.74630

Cumulative Model Updates: 12,366
Cumulative Timesteps: 103,238,346

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 103238346...
Checkpoint 103238346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,298.40028
Policy Entropy: 1.34280
Value Function Loss: 0.10781

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.17002
Policy Update Magnitude: 0.25281
Value Function Update Magnitude: 0.62844

Collected Steps per Second: 22,161.68950
Overall Steps per Second: 10,681.75362

Timestep Collection Time: 2.25678
Timestep Consumption Time: 2.42541
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.68219

Cumulative Model Updates: 12,372
Cumulative Timesteps: 103,288,360

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,410.53957
Policy Entropy: 1.35372
Value Function Loss: 0.11044

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.12170
Policy Update Magnitude: 0.28932
Value Function Update Magnitude: 0.57949

Collected Steps per Second: 22,575.61973
Overall Steps per Second: 10,776.75089

Timestep Collection Time: 2.21602
Timestep Consumption Time: 2.42620
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.64222

Cumulative Model Updates: 12,378
Cumulative Timesteps: 103,338,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 103338388...
Checkpoint 103338388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,175.62700
Policy Entropy: 1.35626
Value Function Loss: 0.11356

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.30446
Value Function Update Magnitude: 0.54258

Collected Steps per Second: 22,003.40593
Overall Steps per Second: 10,646.16021

Timestep Collection Time: 2.27374
Timestep Consumption Time: 2.42561
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.69935

Cumulative Model Updates: 12,384
Cumulative Timesteps: 103,388,418

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,372.05334
Policy Entropy: 1.35696
Value Function Loss: 0.11004

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07526
Policy Update Magnitude: 0.31843
Value Function Update Magnitude: 0.50721

Collected Steps per Second: 22,671.47838
Overall Steps per Second: 10,634.53769

Timestep Collection Time: 2.20656
Timestep Consumption Time: 2.49755
PPO Batch Consumption Time: 0.29577
Total Iteration Time: 4.70411

Cumulative Model Updates: 12,390
Cumulative Timesteps: 103,438,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 103438444...
Checkpoint 103438444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687.50127
Policy Entropy: 1.34752
Value Function Loss: 0.11044

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06633
Policy Update Magnitude: 0.31906
Value Function Update Magnitude: 0.48606

Collected Steps per Second: 21,894.86317
Overall Steps per Second: 10,572.16095

Timestep Collection Time: 2.28510
Timestep Consumption Time: 2.44733
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.73243

Cumulative Model Updates: 12,396
Cumulative Timesteps: 103,488,476

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,005.23838
Policy Entropy: 1.33287
Value Function Loss: 0.11764

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.33290
Value Function Update Magnitude: 0.45852

Collected Steps per Second: 22,439.17694
Overall Steps per Second: 10,633.40361

Timestep Collection Time: 2.22878
Timestep Consumption Time: 2.47451
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.70329

Cumulative Model Updates: 12,402
Cumulative Timesteps: 103,538,488

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 103538488...
Checkpoint 103538488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,749.89716
Policy Entropy: 1.33857
Value Function Loss: 0.11999

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.31832
Value Function Update Magnitude: 0.48266

Collected Steps per Second: 22,281.73147
Overall Steps per Second: 10,588.96513

Timestep Collection Time: 2.24417
Timestep Consumption Time: 2.47810
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.72227

Cumulative Model Updates: 12,408
Cumulative Timesteps: 103,588,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,008.08144
Policy Entropy: 1.32904
Value Function Loss: 0.11751

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07912
Policy Update Magnitude: 0.32048
Value Function Update Magnitude: 0.50550

Collected Steps per Second: 22,431.79492
Overall Steps per Second: 10,737.25855

Timestep Collection Time: 2.22987
Timestep Consumption Time: 2.42867
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.65854

Cumulative Model Updates: 12,414
Cumulative Timesteps: 103,638,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 103638512...
Checkpoint 103638512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,277.50543
Policy Entropy: 1.32964
Value Function Loss: 0.11587

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07239
Policy Update Magnitude: 0.32445
Value Function Update Magnitude: 0.52930

Collected Steps per Second: 22,178.96019
Overall Steps per Second: 10,724.56350

Timestep Collection Time: 2.25448
Timestep Consumption Time: 2.40790
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.66238

Cumulative Model Updates: 12,420
Cumulative Timesteps: 103,688,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.94990
Policy Entropy: 1.32083
Value Function Loss: 0.11521

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07321
Policy Update Magnitude: 0.34198
Value Function Update Magnitude: 0.56121

Collected Steps per Second: 22,598.13099
Overall Steps per Second: 10,747.13698

Timestep Collection Time: 2.21381
Timestep Consumption Time: 2.44120
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.65501

Cumulative Model Updates: 12,426
Cumulative Timesteps: 103,738,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 103738542...
Checkpoint 103738542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,656.33891
Policy Entropy: 1.32560
Value Function Loss: 0.11765

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07965
Policy Update Magnitude: 0.32598
Value Function Update Magnitude: 0.55636

Collected Steps per Second: 22,287.15065
Overall Steps per Second: 10,698.49093

Timestep Collection Time: 2.24380
Timestep Consumption Time: 2.43050
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.67430

Cumulative Model Updates: 12,432
Cumulative Timesteps: 103,788,550

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,472.46147
Policy Entropy: 1.33573
Value Function Loss: 0.11431

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.29829
Value Function Update Magnitude: 0.55074

Collected Steps per Second: 21,828.08534
Overall Steps per Second: 10,307.27558

Timestep Collection Time: 2.29090
Timestep Consumption Time: 2.56062
PPO Batch Consumption Time: 0.30584
Total Iteration Time: 4.85152

Cumulative Model Updates: 12,438
Cumulative Timesteps: 103,838,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 103838556...
Checkpoint 103838556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969.05895
Policy Entropy: 1.33682
Value Function Loss: 0.10996

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.27369
Value Function Update Magnitude: 0.53836

Collected Steps per Second: 22,048.65043
Overall Steps per Second: 10,556.56904

Timestep Collection Time: 2.26780
Timestep Consumption Time: 2.46877
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.73658

Cumulative Model Updates: 12,444
Cumulative Timesteps: 103,888,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,927.78464
Policy Entropy: 1.34398
Value Function Loss: 0.10559

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08949
Policy Update Magnitude: 0.29000
Value Function Update Magnitude: 0.63296

Collected Steps per Second: 22,567.30090
Overall Steps per Second: 10,762.54515

Timestep Collection Time: 2.21692
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.64853

Cumulative Model Updates: 12,450
Cumulative Timesteps: 103,938,588

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 103938588...
Checkpoint 103938588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,895.12438
Policy Entropy: 1.34727
Value Function Loss: 0.10242

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.29700
Value Function Update Magnitude: 0.66225

Collected Steps per Second: 22,284.03766
Overall Steps per Second: 10,589.89905

Timestep Collection Time: 2.24403
Timestep Consumption Time: 2.47802
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.72205

Cumulative Model Updates: 12,456
Cumulative Timesteps: 103,988,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,383.00025
Policy Entropy: 1.33255
Value Function Loss: 0.10545

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.24642
Value Function Update Magnitude: 0.68207

Collected Steps per Second: 22,451.75318
Overall Steps per Second: 10,584.73059

Timestep Collection Time: 2.22735
Timestep Consumption Time: 2.49719
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.72454

Cumulative Model Updates: 12,462
Cumulative Timesteps: 104,038,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 104038602...
Checkpoint 104038602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,430.20113
Policy Entropy: 1.33237
Value Function Loss: 0.11156

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.23398
Value Function Update Magnitude: 0.67613

Collected Steps per Second: 22,454.28758
Overall Steps per Second: 10,601.05623

Timestep Collection Time: 2.22710
Timestep Consumption Time: 2.49016
PPO Batch Consumption Time: 0.29619
Total Iteration Time: 4.71727

Cumulative Model Updates: 12,468
Cumulative Timesteps: 104,088,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,465.90283
Policy Entropy: 1.33646
Value Function Loss: 0.11740

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10921
Policy Update Magnitude: 0.26228
Value Function Update Magnitude: 0.62993

Collected Steps per Second: 22,792.82620
Overall Steps per Second: 10,795.46051

Timestep Collection Time: 2.19578
Timestep Consumption Time: 2.44024
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.63602

Cumulative Model Updates: 12,474
Cumulative Timesteps: 104,138,658

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 104138658...
Checkpoint 104138658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,089.69486
Policy Entropy: 1.35051
Value Function Loss: 0.11547

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.29932
Value Function Update Magnitude: 0.54411

Collected Steps per Second: 22,299.83875
Overall Steps per Second: 10,604.22812

Timestep Collection Time: 2.24271
Timestep Consumption Time: 2.47353
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.71623

Cumulative Model Updates: 12,480
Cumulative Timesteps: 104,188,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,852.34472
Policy Entropy: 1.34937
Value Function Loss: 0.11443

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.27044
Value Function Update Magnitude: 0.58788

Collected Steps per Second: 22,682.70600
Overall Steps per Second: 10,689.25976

Timestep Collection Time: 2.20476
Timestep Consumption Time: 2.47376
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.67853

Cumulative Model Updates: 12,486
Cumulative Timesteps: 104,238,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 104238680...
Checkpoint 104238680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,316.89862
Policy Entropy: 1.32710
Value Function Loss: 0.11612

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.29739
Value Function Update Magnitude: 0.65321

Collected Steps per Second: 22,496.36320
Overall Steps per Second: 10,671.17710

Timestep Collection Time: 2.22338
Timestep Consumption Time: 2.46382
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.68721

Cumulative Model Updates: 12,492
Cumulative Timesteps: 104,288,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.28122
Policy Entropy: 1.31179
Value Function Loss: 0.12314

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.31518
Value Function Update Magnitude: 0.53116

Collected Steps per Second: 22,742.16687
Overall Steps per Second: 10,699.03285

Timestep Collection Time: 2.19961
Timestep Consumption Time: 2.47595
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.67556

Cumulative Model Updates: 12,498
Cumulative Timesteps: 104,338,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 104338722...
Checkpoint 104338722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,541.67056
Policy Entropy: 1.30304
Value Function Loss: 0.12223

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.30535
Value Function Update Magnitude: 0.46032

Collected Steps per Second: 22,048.00012
Overall Steps per Second: 10,671.77186

Timestep Collection Time: 2.26796
Timestep Consumption Time: 2.41767
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.68563

Cumulative Model Updates: 12,504
Cumulative Timesteps: 104,388,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,889.02572
Policy Entropy: 1.32428
Value Function Loss: 0.11778

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.28305
Value Function Update Magnitude: 0.43478

Collected Steps per Second: 22,594.34417
Overall Steps per Second: 10,804.11991

Timestep Collection Time: 2.21401
Timestep Consumption Time: 2.41608
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.63009

Cumulative Model Updates: 12,510
Cumulative Timesteps: 104,438,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 104438750...
Checkpoint 104438750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,436.93575
Policy Entropy: 1.32947
Value Function Loss: 0.11389

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.12012
Policy Update Magnitude: 0.29337
Value Function Update Magnitude: 0.47891

Collected Steps per Second: 21,550.84398
Overall Steps per Second: 10,458.24336

Timestep Collection Time: 2.32130
Timestep Consumption Time: 2.46210
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.78340

Cumulative Model Updates: 12,516
Cumulative Timesteps: 104,488,776

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,379.65184
Policy Entropy: 1.33230
Value Function Loss: 0.11003

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.28930
Value Function Update Magnitude: 0.45675

Collected Steps per Second: 22,369.06952
Overall Steps per Second: 10,747.87301

Timestep Collection Time: 2.23603
Timestep Consumption Time: 2.41772
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.65376

Cumulative Model Updates: 12,522
Cumulative Timesteps: 104,538,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 104538794...
Checkpoint 104538794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,818.75778
Policy Entropy: 1.32754
Value Function Loss: 0.11477

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.29617
Value Function Update Magnitude: 0.48332

Collected Steps per Second: 22,394.98020
Overall Steps per Second: 10,596.68082

Timestep Collection Time: 2.23282
Timestep Consumption Time: 2.48601
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.71884

Cumulative Model Updates: 12,528
Cumulative Timesteps: 104,588,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.09567
Policy Entropy: 1.31420
Value Function Loss: 0.12124

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.15714
Policy Update Magnitude: 0.28377
Value Function Update Magnitude: 0.41616

Collected Steps per Second: 22,237.49862
Overall Steps per Second: 10,611.39539

Timestep Collection Time: 2.24980
Timestep Consumption Time: 2.46494
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.71474

Cumulative Model Updates: 12,534
Cumulative Timesteps: 104,638,828

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 104638828...
Checkpoint 104638828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,150.69773
Policy Entropy: 1.30952
Value Function Loss: 0.12311

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.15438
Policy Update Magnitude: 0.25111
Value Function Update Magnitude: 0.43519

Collected Steps per Second: 22,206.42743
Overall Steps per Second: 10,520.82943

Timestep Collection Time: 2.25250
Timestep Consumption Time: 2.50188
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.75438

Cumulative Model Updates: 12,540
Cumulative Timesteps: 104,688,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,124.50571
Policy Entropy: 1.29563
Value Function Loss: 0.12056

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.25774
Value Function Update Magnitude: 0.50532

Collected Steps per Second: 22,184.60786
Overall Steps per Second: 10,475.89655

Timestep Collection Time: 2.25517
Timestep Consumption Time: 2.52056
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.77572

Cumulative Model Updates: 12,546
Cumulative Timesteps: 104,738,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 104738878...
Checkpoint 104738878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,996.00760
Policy Entropy: 1.29941
Value Function Loss: 0.12138

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11542
Policy Update Magnitude: 0.25356
Value Function Update Magnitude: 0.50870

Collected Steps per Second: 22,237.14780
Overall Steps per Second: 10,587.13453

Timestep Collection Time: 2.24849
Timestep Consumption Time: 2.47422
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.72271

Cumulative Model Updates: 12,552
Cumulative Timesteps: 104,788,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.25172
Policy Entropy: 1.29270
Value Function Loss: 0.12299

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12496
Policy Update Magnitude: 0.27719
Value Function Update Magnitude: 0.53357

Collected Steps per Second: 22,372.67893
Overall Steps per Second: 10,577.40193

Timestep Collection Time: 2.23496
Timestep Consumption Time: 2.49229
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.72725

Cumulative Model Updates: 12,558
Cumulative Timesteps: 104,838,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 104838880...
Checkpoint 104838880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,186.97895
Policy Entropy: 1.29007
Value Function Loss: 0.12095

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.28618
Value Function Update Magnitude: 0.56020

Collected Steps per Second: 22,406.60782
Overall Steps per Second: 10,559.68527

Timestep Collection Time: 2.23256
Timestep Consumption Time: 2.50471
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.73726

Cumulative Model Updates: 12,564
Cumulative Timesteps: 104,888,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.02226
Policy Entropy: 1.28792
Value Function Loss: 0.11932

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.15387
Policy Update Magnitude: 0.26768
Value Function Update Magnitude: 0.51532

Collected Steps per Second: 22,507.90817
Overall Steps per Second: 10,635.86009

Timestep Collection Time: 2.22153
Timestep Consumption Time: 2.47973
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.70127

Cumulative Model Updates: 12,570
Cumulative Timesteps: 104,938,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 104938906...
Checkpoint 104938906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889.64466
Policy Entropy: 1.29568
Value Function Loss: 0.12511

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.24957
Value Function Update Magnitude: 0.49058

Collected Steps per Second: 22,300.55119
Overall Steps per Second: 10,600.25092

Timestep Collection Time: 2.24237
Timestep Consumption Time: 2.47507
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.71744

Cumulative Model Updates: 12,576
Cumulative Timesteps: 104,988,912

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.91399
Policy Entropy: 1.30465
Value Function Loss: 0.12557

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.28308
Value Function Update Magnitude: 0.44693

Collected Steps per Second: 22,499.51221
Overall Steps per Second: 10,783.67838

Timestep Collection Time: 2.22227
Timestep Consumption Time: 2.41437
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.63664

Cumulative Model Updates: 12,582
Cumulative Timesteps: 105,038,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 105038912...
Checkpoint 105038912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,119.40293
Policy Entropy: 1.31588
Value Function Loss: 0.11707

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.31910
Value Function Update Magnitude: 0.45528

Collected Steps per Second: 22,223.44970
Overall Steps per Second: 10,563.70182

Timestep Collection Time: 2.25033
Timestep Consumption Time: 2.48381
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.73414

Cumulative Model Updates: 12,588
Cumulative Timesteps: 105,088,922

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,163.08461
Policy Entropy: 1.32094
Value Function Loss: 0.11177

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08853
Policy Update Magnitude: 0.32664
Value Function Update Magnitude: 0.51212

Collected Steps per Second: 22,580.23501
Overall Steps per Second: 10,512.34646

Timestep Collection Time: 2.21477
Timestep Consumption Time: 2.54249
PPO Batch Consumption Time: 0.29858
Total Iteration Time: 4.75726

Cumulative Model Updates: 12,594
Cumulative Timesteps: 105,138,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 105138932...
Checkpoint 105138932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,838.94003
Policy Entropy: 1.34088
Value Function Loss: 0.11101

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.28156
Value Function Update Magnitude: 0.50091

Collected Steps per Second: 21,690.65716
Overall Steps per Second: 10,577.16420

Timestep Collection Time: 2.30625
Timestep Consumption Time: 2.42319
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.72943

Cumulative Model Updates: 12,600
Cumulative Timesteps: 105,188,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,177.16465
Policy Entropy: 1.32894
Value Function Loss: 0.11729

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.30154
Value Function Update Magnitude: 0.55234

Collected Steps per Second: 22,358.92417
Overall Steps per Second: 10,551.90270

Timestep Collection Time: 2.23669
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.73943

Cumulative Model Updates: 12,606
Cumulative Timesteps: 105,238,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 105238966...
Checkpoint 105238966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,097.49074
Policy Entropy: 1.33019
Value Function Loss: 0.11668

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.32696
Value Function Update Magnitude: 0.57581

Collected Steps per Second: 22,370.91938
Overall Steps per Second: 10,556.64767

Timestep Collection Time: 2.23576
Timestep Consumption Time: 2.50211
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.73787

Cumulative Model Updates: 12,612
Cumulative Timesteps: 105,288,982

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.05112
Policy Entropy: 1.32900
Value Function Loss: 0.11523

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07524
Policy Update Magnitude: 0.34446
Value Function Update Magnitude: 0.61374

Collected Steps per Second: 22,630.44595
Overall Steps per Second: 10,649.24318

Timestep Collection Time: 2.21030
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.69705

Cumulative Model Updates: 12,618
Cumulative Timesteps: 105,339,002

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 105339002...
Checkpoint 105339002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,757.70593
Policy Entropy: 1.31928
Value Function Loss: 0.11571

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.33382
Value Function Update Magnitude: 0.62618

Collected Steps per Second: 22,406.30108
Overall Steps per Second: 10,601.19268

Timestep Collection Time: 2.23205
Timestep Consumption Time: 2.48553
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.71758

Cumulative Model Updates: 12,624
Cumulative Timesteps: 105,389,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.11265
Policy Entropy: 1.31265
Value Function Loss: 0.11221

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07308
Policy Update Magnitude: 0.33195
Value Function Update Magnitude: 0.63135

Collected Steps per Second: 22,481.14911
Overall Steps per Second: 10,725.24998

Timestep Collection Time: 2.22409
Timestep Consumption Time: 2.43781
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.66190

Cumulative Model Updates: 12,630
Cumulative Timesteps: 105,439,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 105439014...
Checkpoint 105439014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,949.48936
Policy Entropy: 1.30323
Value Function Loss: 0.10965

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.30926
Value Function Update Magnitude: 0.64783

Collected Steps per Second: 22,063.38860
Overall Steps per Second: 10,641.16067

Timestep Collection Time: 2.26738
Timestep Consumption Time: 2.43380
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.70118

Cumulative Model Updates: 12,636
Cumulative Timesteps: 105,489,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,123.97914
Policy Entropy: 1.31686
Value Function Loss: 0.10494

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.26847
Value Function Update Magnitude: 0.67906

Collected Steps per Second: 22,492.42966
Overall Steps per Second: 10,595.37737

Timestep Collection Time: 2.22457
Timestep Consumption Time: 2.49787
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.72244

Cumulative Model Updates: 12,642
Cumulative Timesteps: 105,539,076

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 105539076...
Checkpoint 105539076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,474.70234
Policy Entropy: 1.30987
Value Function Loss: 0.10640

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.25734
Value Function Update Magnitude: 0.69665

Collected Steps per Second: 22,214.58635
Overall Steps per Second: 10,509.32187

Timestep Collection Time: 2.25194
Timestep Consumption Time: 2.50821
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.76015

Cumulative Model Updates: 12,648
Cumulative Timesteps: 105,589,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864.86741
Policy Entropy: 1.31047
Value Function Loss: 0.11027

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.25354
Value Function Update Magnitude: 0.71197

Collected Steps per Second: 22,323.67870
Overall Steps per Second: 10,541.44566

Timestep Collection Time: 2.23995
Timestep Consumption Time: 2.50361
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.74356

Cumulative Model Updates: 12,654
Cumulative Timesteps: 105,639,106

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 105639106...
Checkpoint 105639106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,609.19677
Policy Entropy: 1.31221
Value Function Loss: 0.11553

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.29495
Value Function Update Magnitude: 0.60305

Collected Steps per Second: 22,343.95732
Overall Steps per Second: 10,589.27004

Timestep Collection Time: 2.23891
Timestep Consumption Time: 2.48531
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.72422

Cumulative Model Updates: 12,660
Cumulative Timesteps: 105,689,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.45753
Policy Entropy: 1.32090
Value Function Loss: 0.11230

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.32097
Value Function Update Magnitude: 0.53328

Collected Steps per Second: 22,245.36748
Overall Steps per Second: 10,495.09563

Timestep Collection Time: 2.24793
Timestep Consumption Time: 2.51677
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 4.76470

Cumulative Model Updates: 12,666
Cumulative Timesteps: 105,739,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 105739138...
Checkpoint 105739138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,762.38027
Policy Entropy: 1.32827
Value Function Loss: 0.10781

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.12280
Policy Update Magnitude: 0.29577
Value Function Update Magnitude: 0.59773

Collected Steps per Second: 22,427.77505
Overall Steps per Second: 10,455.64590

Timestep Collection Time: 2.23125
Timestep Consumption Time: 2.55487
PPO Batch Consumption Time: 0.30343
Total Iteration Time: 4.78612

Cumulative Model Updates: 12,672
Cumulative Timesteps: 105,789,180

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,948.34189
Policy Entropy: 1.34710
Value Function Loss: 0.10731

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11502
Policy Update Magnitude: 0.28872
Value Function Update Magnitude: 0.60372

Collected Steps per Second: 21,763.71458
Overall Steps per Second: 10,576.83148

Timestep Collection Time: 2.29823
Timestep Consumption Time: 2.43079
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.72902

Cumulative Model Updates: 12,678
Cumulative Timesteps: 105,839,198

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 105839198...
Checkpoint 105839198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,106.74470
Policy Entropy: 1.33402
Value Function Loss: 0.11141

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.26007
Value Function Update Magnitude: 0.54544

Collected Steps per Second: 22,156.38266
Overall Steps per Second: 10,697.81850

Timestep Collection Time: 2.25687
Timestep Consumption Time: 2.41736
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.67422

Cumulative Model Updates: 12,684
Cumulative Timesteps: 105,889,202

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,545.54540
Policy Entropy: 1.34178
Value Function Loss: 0.10946

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.23905
Value Function Update Magnitude: 0.58128

Collected Steps per Second: 22,275.48814
Overall Steps per Second: 10,560.69530

Timestep Collection Time: 2.24534
Timestep Consumption Time: 2.49071
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.73605

Cumulative Model Updates: 12,690
Cumulative Timesteps: 105,939,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 105939218...
Checkpoint 105939218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,312.98063
Policy Entropy: 1.33266
Value Function Loss: 0.10538

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10536
Policy Update Magnitude: 0.28294
Value Function Update Magnitude: 0.61471

Collected Steps per Second: 22,349.37782
Overall Steps per Second: 10,553.99574

Timestep Collection Time: 2.23827
Timestep Consumption Time: 2.50154
PPO Batch Consumption Time: 0.29701
Total Iteration Time: 4.73982

Cumulative Model Updates: 12,696
Cumulative Timesteps: 105,989,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,935.95501
Policy Entropy: 1.32783
Value Function Loss: 0.10322

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.12239
Policy Update Magnitude: 0.28687
Value Function Update Magnitude: 0.63882

Collected Steps per Second: 22,565.69192
Overall Steps per Second: 10,773.34487

Timestep Collection Time: 2.21628
Timestep Consumption Time: 2.42591
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.64220

Cumulative Model Updates: 12,702
Cumulative Timesteps: 106,039,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 106039254...
Checkpoint 106039254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,105.40176
Policy Entropy: 1.31961
Value Function Loss: 0.10583

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11127
Policy Update Magnitude: 0.27269
Value Function Update Magnitude: 0.66778

Collected Steps per Second: 21,380.00640
Overall Steps per Second: 10,343.30868

Timestep Collection Time: 2.33938
Timestep Consumption Time: 2.49621
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.83559

Cumulative Model Updates: 12,708
Cumulative Timesteps: 106,089,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,069.62302
Policy Entropy: 1.33219
Value Function Loss: 0.10406

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.30624
Value Function Update Magnitude: 0.69286

Collected Steps per Second: 22,411.06976
Overall Steps per Second: 10,726.46941

Timestep Collection Time: 2.23166
Timestep Consumption Time: 2.43101
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.66267

Cumulative Model Updates: 12,714
Cumulative Timesteps: 106,139,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 106139284...
Checkpoint 106139284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.90796
Policy Entropy: 1.34262
Value Function Loss: 0.10217

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12738
Policy Update Magnitude: 0.30342
Value Function Update Magnitude: 0.69060

Collected Steps per Second: 22,141.75406
Overall Steps per Second: 10,644.25948

Timestep Collection Time: 2.25881
Timestep Consumption Time: 2.43987
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.69868

Cumulative Model Updates: 12,720
Cumulative Timesteps: 106,189,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,334.64531
Policy Entropy: 1.34498
Value Function Loss: 0.10694

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.15497
Policy Update Magnitude: 0.26911
Value Function Update Magnitude: 0.70013

Collected Steps per Second: 22,542.22035
Overall Steps per Second: 10,576.65771

Timestep Collection Time: 2.21877
Timestep Consumption Time: 2.51013
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.72890

Cumulative Model Updates: 12,726
Cumulative Timesteps: 106,239,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 106239314...
Checkpoint 106239314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,188.98308
Policy Entropy: 1.32565
Value Function Loss: 0.11079

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.15500
Policy Update Magnitude: 0.28616
Value Function Update Magnitude: 0.70018

Collected Steps per Second: 22,000.98869
Overall Steps per Second: 10,654.61155

Timestep Collection Time: 2.27372
Timestep Consumption Time: 2.42134
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.69506

Cumulative Model Updates: 12,732
Cumulative Timesteps: 106,289,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,056.84440
Policy Entropy: 1.31980
Value Function Loss: 0.11285

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.26519
Value Function Update Magnitude: 0.67689

Collected Steps per Second: 22,629.29499
Overall Steps per Second: 10,787.41393

Timestep Collection Time: 2.21050
Timestep Consumption Time: 2.42657
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.63707

Cumulative Model Updates: 12,738
Cumulative Timesteps: 106,339,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 106339360...
Checkpoint 106339360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,657.82303
Policy Entropy: 1.31933
Value Function Loss: 0.11522

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12700
Policy Update Magnitude: 0.24252
Value Function Update Magnitude: 0.69644

Collected Steps per Second: 22,070.39102
Overall Steps per Second: 10,642.40514

Timestep Collection Time: 2.26611
Timestep Consumption Time: 2.43339
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.69950

Cumulative Model Updates: 12,744
Cumulative Timesteps: 106,389,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,767.48364
Policy Entropy: 1.32888
Value Function Loss: 0.11674

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.14581
Policy Update Magnitude: 0.25300
Value Function Update Magnitude: 0.69916

Collected Steps per Second: 22,879.83999
Overall Steps per Second: 10,558.92204

Timestep Collection Time: 2.18620
Timestep Consumption Time: 2.55102
PPO Batch Consumption Time: 0.30435
Total Iteration Time: 4.73723

Cumulative Model Updates: 12,750
Cumulative Timesteps: 106,439,394

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 106439394...
Checkpoint 106439394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,389.06979
Policy Entropy: 1.31875
Value Function Loss: 0.11512

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.14949
Policy Update Magnitude: 0.25703
Value Function Update Magnitude: 0.67112

Collected Steps per Second: 22,146.73507
Overall Steps per Second: 10,521.44816

Timestep Collection Time: 2.25866
Timestep Consumption Time: 2.49563
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.75429

Cumulative Model Updates: 12,756
Cumulative Timesteps: 106,489,416

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798.13644
Policy Entropy: 1.29579
Value Function Loss: 0.11619

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.25179
Value Function Update Magnitude: 0.69077

Collected Steps per Second: 22,548.33119
Overall Steps per Second: 10,583.10487

Timestep Collection Time: 2.21764
Timestep Consumption Time: 2.50725
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 4.72489

Cumulative Model Updates: 12,762
Cumulative Timesteps: 106,539,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 106539420...
Checkpoint 106539420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,223.81717
Policy Entropy: 1.30202
Value Function Loss: 0.11326

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.15383
Policy Update Magnitude: 0.23645
Value Function Update Magnitude: 0.69570

Collected Steps per Second: 22,176.55398
Overall Steps per Second: 10,606.54226

Timestep Collection Time: 2.25545
Timestep Consumption Time: 2.46032
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.71577

Cumulative Model Updates: 12,768
Cumulative Timesteps: 106,589,438

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.44782
Policy Entropy: 1.30910
Value Function Loss: 0.11345

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.14950
Policy Update Magnitude: 0.24559
Value Function Update Magnitude: 0.64961

Collected Steps per Second: 22,382.87596
Overall Steps per Second: 10,565.80230

Timestep Collection Time: 2.23474
Timestep Consumption Time: 2.49940
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.73414

Cumulative Model Updates: 12,774
Cumulative Timesteps: 106,639,458

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 106639458...
Checkpoint 106639458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,897.86440
Policy Entropy: 1.31404
Value Function Loss: 0.10801

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.26776
Value Function Update Magnitude: 0.59791

Collected Steps per Second: 22,109.89289
Overall Steps per Second: 10,540.67554

Timestep Collection Time: 2.26234
Timestep Consumption Time: 2.48309
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.74543

Cumulative Model Updates: 12,780
Cumulative Timesteps: 106,689,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,106.35260
Policy Entropy: 1.30514
Value Function Loss: 0.10654

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.29867
Value Function Update Magnitude: 0.61956

Collected Steps per Second: 22,527.69493
Overall Steps per Second: 10,640.09269

Timestep Collection Time: 2.22029
Timestep Consumption Time: 2.48061
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.70090

Cumulative Model Updates: 12,786
Cumulative Timesteps: 106,739,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 106739496...
Checkpoint 106739496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,554.65877
Policy Entropy: 1.30293
Value Function Loss: 0.10552

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.29326
Value Function Update Magnitude: 0.63169

Collected Steps per Second: 22,208.86055
Overall Steps per Second: 10,519.84369

Timestep Collection Time: 2.25171
Timestep Consumption Time: 2.50197
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.75368

Cumulative Model Updates: 12,792
Cumulative Timesteps: 106,789,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,236.84954
Policy Entropy: 1.29302
Value Function Loss: 0.10671

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.27876
Value Function Update Magnitude: 0.62468

Collected Steps per Second: 22,688.60258
Overall Steps per Second: 10,791.63400

Timestep Collection Time: 2.20419
Timestep Consumption Time: 2.42995
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.63415

Cumulative Model Updates: 12,798
Cumulative Timesteps: 106,839,514

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 106839514...
Checkpoint 106839514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,503.05236
Policy Entropy: 1.29899
Value Function Loss: 0.10916

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12700
Policy Update Magnitude: 0.27383
Value Function Update Magnitude: 0.66457

Collected Steps per Second: 21,788.09611
Overall Steps per Second: 10,611.04557

Timestep Collection Time: 2.29584
Timestep Consumption Time: 2.41830
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.71414

Cumulative Model Updates: 12,804
Cumulative Timesteps: 106,889,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,221.09463
Policy Entropy: 1.30364
Value Function Loss: 0.11013

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.28107
Value Function Update Magnitude: 0.67564

Collected Steps per Second: 22,593.68799
Overall Steps per Second: 10,613.83546

Timestep Collection Time: 2.21407
Timestep Consumption Time: 2.49902
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.71309

Cumulative Model Updates: 12,810
Cumulative Timesteps: 106,939,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 106939560...
Checkpoint 106939560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051.56814
Policy Entropy: 1.29715
Value Function Loss: 0.11607

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12602
Policy Update Magnitude: 0.28535
Value Function Update Magnitude: 0.58801

Collected Steps per Second: 22,245.37930
Overall Steps per Second: 10,542.18511

Timestep Collection Time: 2.24928
Timestep Consumption Time: 2.49699
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.74626

Cumulative Model Updates: 12,816
Cumulative Timesteps: 106,989,596

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,912.73438
Policy Entropy: 1.30352
Value Function Loss: 0.11173

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.29309
Value Function Update Magnitude: 0.51153

Collected Steps per Second: 22,687.78621
Overall Steps per Second: 10,685.33123

Timestep Collection Time: 2.20392
Timestep Consumption Time: 2.47558
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.67950

Cumulative Model Updates: 12,822
Cumulative Timesteps: 107,039,598

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 107039598...
Checkpoint 107039598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,981.70653
Policy Entropy: 1.30612
Value Function Loss: 0.11533

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.31765
Value Function Update Magnitude: 0.50672

Collected Steps per Second: 22,240.24273
Overall Steps per Second: 10,576.44411

Timestep Collection Time: 2.24917
Timestep Consumption Time: 2.48040
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.72957

Cumulative Model Updates: 12,828
Cumulative Timesteps: 107,089,620

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,688.03650
Policy Entropy: 1.29699
Value Function Loss: 0.11256

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.33114
Value Function Update Magnitude: 0.47022

Collected Steps per Second: 20,807.10479
Overall Steps per Second: 10,167.31005

Timestep Collection Time: 2.40331
Timestep Consumption Time: 2.51500
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.91831

Cumulative Model Updates: 12,834
Cumulative Timesteps: 107,139,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 107139626...
Checkpoint 107139626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,458.27935
Policy Entropy: 1.30085
Value Function Loss: 0.11768

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.31764
Value Function Update Magnitude: 0.52760

Collected Steps per Second: 22,177.93790
Overall Steps per Second: 10,682.93670

Timestep Collection Time: 2.25467
Timestep Consumption Time: 2.42606
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.68074

Cumulative Model Updates: 12,840
Cumulative Timesteps: 107,189,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,239.19229
Policy Entropy: 1.29980
Value Function Loss: 0.11881

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.28163
Value Function Update Magnitude: 0.51771

Collected Steps per Second: 22,576.54454
Overall Steps per Second: 10,587.81459

Timestep Collection Time: 2.21611
Timestep Consumption Time: 2.50933
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.72543

Cumulative Model Updates: 12,846
Cumulative Timesteps: 107,239,662

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 107239662...
Checkpoint 107239662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,017.40035
Policy Entropy: 1.31454
Value Function Loss: 0.11492

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.27872
Value Function Update Magnitude: 0.47926

Collected Steps per Second: 22,303.43012
Overall Steps per Second: 10,604.84582

Timestep Collection Time: 2.24226
Timestep Consumption Time: 2.47351
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.71577

Cumulative Model Updates: 12,852
Cumulative Timesteps: 107,289,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,004.34863
Policy Entropy: 1.32408
Value Function Loss: 0.11305

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.26974
Value Function Update Magnitude: 0.50995

Collected Steps per Second: 22,718.41225
Overall Steps per Second: 10,790.21437

Timestep Collection Time: 2.20130
Timestep Consumption Time: 2.43346
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.63476

Cumulative Model Updates: 12,858
Cumulative Timesteps: 107,339,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 107339682...
Checkpoint 107339682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,188.77337
Policy Entropy: 1.32432
Value Function Loss: 0.10876

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12839
Policy Update Magnitude: 0.26828
Value Function Update Magnitude: 0.52641

Collected Steps per Second: 22,032.99461
Overall Steps per Second: 10,653.85756

Timestep Collection Time: 2.27014
Timestep Consumption Time: 2.42468
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.69483

Cumulative Model Updates: 12,864
Cumulative Timesteps: 107,389,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.33799
Policy Entropy: 1.31672
Value Function Loss: 0.11518

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.25943
Value Function Update Magnitude: 0.48096

Collected Steps per Second: 22,574.76118
Overall Steps per Second: 10,599.16270

Timestep Collection Time: 2.21575
Timestep Consumption Time: 2.50349
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 4.71924

Cumulative Model Updates: 12,870
Cumulative Timesteps: 107,439,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 107439720...
Checkpoint 107439720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.60890
Policy Entropy: 1.30745
Value Function Loss: 0.11900

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.14445
Policy Update Magnitude: 0.26543
Value Function Update Magnitude: 0.48980

Collected Steps per Second: 22,106.06101
Overall Steps per Second: 10,602.60768

Timestep Collection Time: 2.26291
Timestep Consumption Time: 2.45518
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.71808

Cumulative Model Updates: 12,876
Cumulative Timesteps: 107,489,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,007.10841
Policy Entropy: 1.32715
Value Function Loss: 0.11491

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.28720
Value Function Update Magnitude: 0.50297

Collected Steps per Second: 22,614.26450
Overall Steps per Second: 10,551.11228

Timestep Collection Time: 2.21152
Timestep Consumption Time: 2.52845
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.73997

Cumulative Model Updates: 12,882
Cumulative Timesteps: 107,539,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 107539756...
Checkpoint 107539756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,565.34278
Policy Entropy: 1.33246
Value Function Loss: 0.11195

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10209
Policy Update Magnitude: 0.30680
Value Function Update Magnitude: 0.51260

Collected Steps per Second: 22,380.78273
Overall Steps per Second: 10,527.98686

Timestep Collection Time: 2.23451
Timestep Consumption Time: 2.51569
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.75020

Cumulative Model Updates: 12,888
Cumulative Timesteps: 107,589,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,337.56898
Policy Entropy: 1.33368
Value Function Loss: 0.10884

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.31503
Value Function Update Magnitude: 0.53254

Collected Steps per Second: 22,116.62129
Overall Steps per Second: 10,487.06820

Timestep Collection Time: 2.26273
Timestep Consumption Time: 2.50924
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.77197

Cumulative Model Updates: 12,894
Cumulative Timesteps: 107,639,810

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 107639810...
Checkpoint 107639810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,788.11307
Policy Entropy: 1.32380
Value Function Loss: 0.11524

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.32017
Value Function Update Magnitude: 0.47794

Collected Steps per Second: 21,975.23972
Overall Steps per Second: 10,607.96173

Timestep Collection Time: 2.27738
Timestep Consumption Time: 2.44040
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.71778

Cumulative Model Updates: 12,900
Cumulative Timesteps: 107,689,856

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,898.70349
Policy Entropy: 1.31239
Value Function Loss: 0.12066

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06867
Policy Update Magnitude: 0.33136
Value Function Update Magnitude: 0.49014

Collected Steps per Second: 22,682.25255
Overall Steps per Second: 10,654.88539

Timestep Collection Time: 2.20507
Timestep Consumption Time: 2.48911
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.69418

Cumulative Model Updates: 12,906
Cumulative Timesteps: 107,739,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 107739872...
Checkpoint 107739872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,015.51049
Policy Entropy: 1.33093
Value Function Loss: 0.11485

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08072
Policy Update Magnitude: 0.34815
Value Function Update Magnitude: 0.59594

Collected Steps per Second: 21,598.90531
Overall Steps per Second: 10,395.34931

Timestep Collection Time: 2.31614
Timestep Consumption Time: 2.49621
PPO Batch Consumption Time: 0.29605
Total Iteration Time: 4.81234

Cumulative Model Updates: 12,912
Cumulative Timesteps: 107,789,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,544.23096
Policy Entropy: 1.33583
Value Function Loss: 0.11077

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.33026
Value Function Update Magnitude: 0.62984

Collected Steps per Second: 21,718.83684
Overall Steps per Second: 10,497.59291

Timestep Collection Time: 2.30325
Timestep Consumption Time: 2.46203
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.76528

Cumulative Model Updates: 12,918
Cumulative Timesteps: 107,839,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 107839922...
Checkpoint 107839922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,192.10132
Policy Entropy: 1.32289
Value Function Loss: 0.11578

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10894
Policy Update Magnitude: 0.29717
Value Function Update Magnitude: 0.56705

Collected Steps per Second: 21,960.72645
Overall Steps per Second: 10,621.77800

Timestep Collection Time: 2.27716
Timestep Consumption Time: 2.43091
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.70806

Cumulative Model Updates: 12,924
Cumulative Timesteps: 107,889,930

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,208.07328
Policy Entropy: 1.31047
Value Function Loss: 0.11461

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.30259
Value Function Update Magnitude: 0.51962

Collected Steps per Second: 22,453.15586
Overall Steps per Second: 10,546.90043

Timestep Collection Time: 2.22775
Timestep Consumption Time: 2.51488
PPO Batch Consumption Time: 0.29681
Total Iteration Time: 4.74263

Cumulative Model Updates: 12,930
Cumulative Timesteps: 107,939,950

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 107939950...
Checkpoint 107939950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,732.92124
Policy Entropy: 1.31202
Value Function Loss: 0.11141

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10828
Policy Update Magnitude: 0.30274
Value Function Update Magnitude: 0.57626

Collected Steps per Second: 22,320.12749
Overall Steps per Second: 10,607.84163

Timestep Collection Time: 2.24058
Timestep Consumption Time: 2.47386
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.71444

Cumulative Model Updates: 12,936
Cumulative Timesteps: 107,989,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,970.32809
Policy Entropy: 1.32651
Value Function Loss: 0.10432

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.12004
Policy Update Magnitude: 0.29175
Value Function Update Magnitude: 0.62085

Collected Steps per Second: 22,493.51721
Overall Steps per Second: 10,528.76675

Timestep Collection Time: 2.22420
Timestep Consumption Time: 2.52755
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.75174

Cumulative Model Updates: 12,942
Cumulative Timesteps: 108,039,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 108039990...
Checkpoint 108039990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,282.19475
Policy Entropy: 1.30887
Value Function Loss: 0.10258

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.12054
Policy Update Magnitude: 0.24619
Value Function Update Magnitude: 0.59426

Collected Steps per Second: 22,276.43836
Overall Steps per Second: 10,568.16124

Timestep Collection Time: 2.24488
Timestep Consumption Time: 2.48707
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.73195

Cumulative Model Updates: 12,948
Cumulative Timesteps: 108,089,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,227.64266
Policy Entropy: 1.28914
Value Function Loss: 0.10701

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12114
Policy Update Magnitude: 0.23114
Value Function Update Magnitude: 0.56806

Collected Steps per Second: 22,650.52138
Overall Steps per Second: 10,775.10581

Timestep Collection Time: 2.20772
Timestep Consumption Time: 2.43316
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.64088

Cumulative Model Updates: 12,954
Cumulative Timesteps: 108,140,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 108140004...
Checkpoint 108140004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,873.68035
Policy Entropy: 1.28064
Value Function Loss: 0.10990

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09798
Policy Update Magnitude: 0.24116
Value Function Update Magnitude: 0.61500

Collected Steps per Second: 22,117.90016
Overall Steps per Second: 10,673.48258

Timestep Collection Time: 2.26125
Timestep Consumption Time: 2.42457
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.68582

Cumulative Model Updates: 12,960
Cumulative Timesteps: 108,190,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,761.99188
Policy Entropy: 1.28801
Value Function Loss: 0.10975

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.28454
Value Function Update Magnitude: 0.65350

Collected Steps per Second: 22,825.12091
Overall Steps per Second: 10,694.17674

Timestep Collection Time: 2.19250
Timestep Consumption Time: 2.48706
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.67956

Cumulative Model Updates: 12,966
Cumulative Timesteps: 108,240,062

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 108240062...
Checkpoint 108240062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.02352
Policy Entropy: 1.28920
Value Function Loss: 0.10947

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11236
Policy Update Magnitude: 0.29877
Value Function Update Magnitude: 0.63821

Collected Steps per Second: 22,269.52502
Overall Steps per Second: 10,539.17285

Timestep Collection Time: 2.24558
Timestep Consumption Time: 2.49938
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.74496

Cumulative Model Updates: 12,972
Cumulative Timesteps: 108,290,070

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,937.92302
Policy Entropy: 1.28820
Value Function Loss: 0.10725

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10956
Policy Update Magnitude: 0.29939
Value Function Update Magnitude: 0.65365

Collected Steps per Second: 22,618.59548
Overall Steps per Second: 10,775.32265

Timestep Collection Time: 2.21172
Timestep Consumption Time: 2.43093
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.64265

Cumulative Model Updates: 12,978
Cumulative Timesteps: 108,340,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 108340096...
Checkpoint 108340096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,107.22206
Policy Entropy: 1.29621
Value Function Loss: 0.10997

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.32044
Value Function Update Magnitude: 0.65221

Collected Steps per Second: 22,129.87779
Overall Steps per Second: 10,669.85654

Timestep Collection Time: 2.26120
Timestep Consumption Time: 2.42865
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.68985

Cumulative Model Updates: 12,984
Cumulative Timesteps: 108,390,136

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,293.72980
Policy Entropy: 1.30001
Value Function Loss: 0.10387

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.32308
Value Function Update Magnitude: 0.58168

Collected Steps per Second: 22,472.14948
Overall Steps per Second: 10,566.62669

Timestep Collection Time: 2.22498
Timestep Consumption Time: 2.50690
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.73188

Cumulative Model Updates: 12,990
Cumulative Timesteps: 108,440,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 108440136...
Checkpoint 108440136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,327.72059
Policy Entropy: 1.30059
Value Function Loss: 0.10796

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10926
Policy Update Magnitude: 0.30669
Value Function Update Magnitude: 0.56532

Collected Steps per Second: 21,563.47668
Overall Steps per Second: 10,559.24579

Timestep Collection Time: 2.31901
Timestep Consumption Time: 2.41674
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.73575

Cumulative Model Updates: 12,996
Cumulative Timesteps: 108,490,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,089.68020
Policy Entropy: 1.30239
Value Function Loss: 0.10782

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.28755
Value Function Update Magnitude: 0.51834

Collected Steps per Second: 22,713.34445
Overall Steps per Second: 10,796.69636

Timestep Collection Time: 2.20170
Timestep Consumption Time: 2.43009
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.63179

Cumulative Model Updates: 13,002
Cumulative Timesteps: 108,540,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 108540150...
Checkpoint 108540150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.17833
Policy Entropy: 1.30679
Value Function Loss: 0.11402

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.15843
Policy Update Magnitude: 0.28358
Value Function Update Magnitude: 0.50195

Collected Steps per Second: 22,072.90299
Overall Steps per Second: 10,651.55497

Timestep Collection Time: 2.26576
Timestep Consumption Time: 2.42951
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.69528

Cumulative Model Updates: 13,008
Cumulative Timesteps: 108,590,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,815.35319
Policy Entropy: 1.32335
Value Function Loss: 0.10527

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.15137
Policy Update Magnitude: 0.25807
Value Function Update Magnitude: 0.50160

Collected Steps per Second: 22,584.13002
Overall Steps per Second: 10,608.93631

Timestep Collection Time: 2.21465
Timestep Consumption Time: 2.49986
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.71452

Cumulative Model Updates: 13,014
Cumulative Timesteps: 108,640,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 108640178...
Checkpoint 108640178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,179.16870
Policy Entropy: 1.32625
Value Function Loss: 0.10565

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13473
Policy Update Magnitude: 0.25862
Value Function Update Magnitude: 0.48540

Collected Steps per Second: 22,023.06600
Overall Steps per Second: 10,593.44921

Timestep Collection Time: 2.27089
Timestep Consumption Time: 2.45014
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.72103

Cumulative Model Updates: 13,020
Cumulative Timesteps: 108,690,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,300.18802
Policy Entropy: 1.32347
Value Function Loss: 0.10605

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.15895
Policy Update Magnitude: 0.24476
Value Function Update Magnitude: 0.52595

Collected Steps per Second: 22,582.11690
Overall Steps per Second: 10,784.86914

Timestep Collection Time: 2.21441
Timestep Consumption Time: 2.42227
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.63668

Cumulative Model Updates: 13,026
Cumulative Timesteps: 108,740,196

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 108740196...
Checkpoint 108740196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,023.27523
Policy Entropy: 1.32137
Value Function Loss: 0.11416

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.16847
Policy Update Magnitude: 0.25188
Value Function Update Magnitude: 0.48381

Collected Steps per Second: 21,918.88270
Overall Steps per Second: 10,487.86033

Timestep Collection Time: 2.28260
Timestep Consumption Time: 2.48787
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.77047

Cumulative Model Updates: 13,032
Cumulative Timesteps: 108,790,228

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,992.72432
Policy Entropy: 1.31760
Value Function Loss: 0.11205

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.26256
Value Function Update Magnitude: 0.45476

Collected Steps per Second: 22,847.99969
Overall Steps per Second: 10,719.06282

Timestep Collection Time: 2.18943
Timestep Consumption Time: 2.47740
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.66683

Cumulative Model Updates: 13,038
Cumulative Timesteps: 108,840,252

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 108840252...
Checkpoint 108840252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,104.53107
Policy Entropy: 1.32680
Value Function Loss: 0.11297

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.27620
Value Function Update Magnitude: 0.47921

Collected Steps per Second: 22,198.99476
Overall Steps per Second: 10,681.37083

Timestep Collection Time: 2.25298
Timestep Consumption Time: 2.42937
PPO Batch Consumption Time: 0.28192
Total Iteration Time: 4.68236

Cumulative Model Updates: 13,044
Cumulative Timesteps: 108,890,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,939.86383
Policy Entropy: 1.31157
Value Function Loss: 0.11159

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.26140
Value Function Update Magnitude: 0.53082

Collected Steps per Second: 22,549.94151
Overall Steps per Second: 10,762.29033

Timestep Collection Time: 2.21899
Timestep Consumption Time: 2.43040
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.64938

Cumulative Model Updates: 13,050
Cumulative Timesteps: 108,940,304

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 108940304...
Checkpoint 108940304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,036.14620
Policy Entropy: 1.30460
Value Function Loss: 0.11174

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.25773
Value Function Update Magnitude: 0.59299

Collected Steps per Second: 20,152.38874
Overall Steps per Second: 10,200.40255

Timestep Collection Time: 2.48189
Timestep Consumption Time: 2.42145
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.90334

Cumulative Model Updates: 13,056
Cumulative Timesteps: 108,990,320

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446.94666
Policy Entropy: 1.29225
Value Function Loss: 0.11779

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10642
Policy Update Magnitude: 0.27434
Value Function Update Magnitude: 0.51903

Collected Steps per Second: 22,880.36933
Overall Steps per Second: 10,699.07349

Timestep Collection Time: 2.18677
Timestep Consumption Time: 2.48971
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.67648

Cumulative Model Updates: 13,062
Cumulative Timesteps: 109,040,354

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 109040354...
Checkpoint 109040354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,374.91516
Policy Entropy: 1.28235
Value Function Loss: 0.11603

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.30681
Value Function Update Magnitude: 0.51152

Collected Steps per Second: 22,224.16987
Overall Steps per Second: 10,549.44473

Timestep Collection Time: 2.25115
Timestep Consumption Time: 2.49128
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.74243

Cumulative Model Updates: 13,068
Cumulative Timesteps: 109,090,384

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,047.68544
Policy Entropy: 1.27596
Value Function Loss: 0.11701

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.31057
Value Function Update Magnitude: 0.50640

Collected Steps per Second: 23,120.64119
Overall Steps per Second: 10,932.79507

Timestep Collection Time: 2.16309
Timestep Consumption Time: 2.41140
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.57449

Cumulative Model Updates: 13,074
Cumulative Timesteps: 109,140,396

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 109140396...
Checkpoint 109140396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,117.23616
Policy Entropy: 1.27689
Value Function Loss: 0.11197

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09914
Policy Update Magnitude: 0.29890
Value Function Update Magnitude: 0.51726

Collected Steps per Second: 22,393.86405
Overall Steps per Second: 10,564.61272

Timestep Collection Time: 2.23392
Timestep Consumption Time: 2.50133
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.73524

Cumulative Model Updates: 13,080
Cumulative Timesteps: 109,190,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,541.35741
Policy Entropy: 1.28201
Value Function Loss: 0.11031

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.27159
Value Function Update Magnitude: 0.57426

Collected Steps per Second: 22,532.76699
Overall Steps per Second: 10,637.76613

Timestep Collection Time: 2.21961
Timestep Consumption Time: 2.48194
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.70155

Cumulative Model Updates: 13,086
Cumulative Timesteps: 109,240,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 109240436...
Checkpoint 109240436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.40296
Policy Entropy: 1.27914
Value Function Loss: 0.11597

Mean KL Divergence: 0.03161
SB3 Clip Fraction: 0.21391
Policy Update Magnitude: 0.21644
Value Function Update Magnitude: 0.59045

Collected Steps per Second: 20,475.64715
Overall Steps per Second: 10,134.47603

Timestep Collection Time: 2.44261
Timestep Consumption Time: 2.49243
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.93504

Cumulative Model Updates: 13,092
Cumulative Timesteps: 109,290,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.64937
Policy Entropy: 1.27707
Value Function Loss: 0.12707

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.15626
Policy Update Magnitude: 0.25384
Value Function Update Magnitude: 0.52225

Collected Steps per Second: 22,762.58180
Overall Steps per Second: 10,855.15478

Timestep Collection Time: 2.19799
Timestep Consumption Time: 2.41106
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.60905

Cumulative Model Updates: 13,098
Cumulative Timesteps: 109,340,482

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 109340482...
Checkpoint 109340482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,152.44273
Policy Entropy: 1.27704
Value Function Loss: 0.13040

Mean KL Divergence: 0.02358
SB3 Clip Fraction: 0.19434
Policy Update Magnitude: 0.26140
Value Function Update Magnitude: 0.44077

Collected Steps per Second: 22,664.40376
Overall Steps per Second: 10,636.78285

Timestep Collection Time: 2.20831
Timestep Consumption Time: 2.49706
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.70537

Cumulative Model Updates: 13,104
Cumulative Timesteps: 109,390,532

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,437.07977
Policy Entropy: 1.27875
Value Function Loss: 0.13142

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.16643
Policy Update Magnitude: 0.26340
Value Function Update Magnitude: 0.43747

Collected Steps per Second: 22,673.10267
Overall Steps per Second: 10,817.74793

Timestep Collection Time: 2.20534
Timestep Consumption Time: 2.41687
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.62222

Cumulative Model Updates: 13,110
Cumulative Timesteps: 109,440,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 109440534...
Checkpoint 109440534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,117.39906
Policy Entropy: 1.29219
Value Function Loss: 0.11943

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.26432
Value Function Update Magnitude: 0.45700

Collected Steps per Second: 22,356.80296
Overall Steps per Second: 10,771.65019

Timestep Collection Time: 2.23780
Timestep Consumption Time: 2.40680
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.64460

Cumulative Model Updates: 13,116
Cumulative Timesteps: 109,490,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.35912
Policy Entropy: 1.29263
Value Function Loss: 0.11209

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.29844
Value Function Update Magnitude: 0.45255

Collected Steps per Second: 22,617.14251
Overall Steps per Second: 10,749.46511

Timestep Collection Time: 2.21098
Timestep Consumption Time: 2.44097
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.65195

Cumulative Model Updates: 13,122
Cumulative Timesteps: 109,540,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 109540570...
Checkpoint 109540570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,687.77249
Policy Entropy: 1.29158
Value Function Loss: 0.10500

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.30847
Value Function Update Magnitude: 0.43612

Collected Steps per Second: 22,371.16856
Overall Steps per Second: 10,748.16271

Timestep Collection Time: 2.23609
Timestep Consumption Time: 2.41810
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.65419

Cumulative Model Updates: 13,128
Cumulative Timesteps: 109,590,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,393.42371
Policy Entropy: 1.28623
Value Function Loss: 0.10651

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09010
Policy Update Magnitude: 0.30924
Value Function Update Magnitude: 0.48752

Collected Steps per Second: 22,646.97651
Overall Steps per Second: 10,809.15613

Timestep Collection Time: 2.20904
Timestep Consumption Time: 2.41926
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.62830

Cumulative Model Updates: 13,134
Cumulative Timesteps: 109,640,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 109640622...
Checkpoint 109640622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,363.53027
Policy Entropy: 1.28575
Value Function Loss: 0.10904

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.28591
Value Function Update Magnitude: 0.47586

Collected Steps per Second: 22,808.18129
Overall Steps per Second: 10,751.85914

Timestep Collection Time: 2.19316
Timestep Consumption Time: 2.45924
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.65240

Cumulative Model Updates: 13,140
Cumulative Timesteps: 109,690,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,938.05221
Policy Entropy: 1.27809
Value Function Loss: 0.10897

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.25828
Value Function Update Magnitude: 0.56909

Collected Steps per Second: 22,539.33304
Overall Steps per Second: 10,614.85020

Timestep Collection Time: 2.22030
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.71453

Cumulative Model Updates: 13,146
Cumulative Timesteps: 109,740,688

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 109740688...
Checkpoint 109740688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,170.28507
Policy Entropy: 1.26826
Value Function Loss: 0.10824

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.25741
Value Function Update Magnitude: 0.65567

Collected Steps per Second: 22,735.77532
Overall Steps per Second: 10,839.56017

Timestep Collection Time: 2.20120
Timestep Consumption Time: 2.41578
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.61698

Cumulative Model Updates: 13,152
Cumulative Timesteps: 109,790,734

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.23445
Policy Entropy: 1.26611
Value Function Loss: 0.10801

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11219
Policy Update Magnitude: 0.25111
Value Function Update Magnitude: 0.69169

Collected Steps per Second: 22,645.58308
Overall Steps per Second: 10,660.44190

Timestep Collection Time: 2.20802
Timestep Consumption Time: 2.48240
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.69042

Cumulative Model Updates: 13,158
Cumulative Timesteps: 109,840,736

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 109840736...
Checkpoint 109840736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.90149
Policy Entropy: 1.26750
Value Function Loss: 0.11021

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.24666
Value Function Update Magnitude: 0.70045

Collected Steps per Second: 22,489.39936
Overall Steps per Second: 10,611.18405

Timestep Collection Time: 2.22416
Timestep Consumption Time: 2.48974
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.71389

Cumulative Model Updates: 13,164
Cumulative Timesteps: 109,890,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,598.81659
Policy Entropy: 1.26220
Value Function Loss: 0.11136

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.24624
Value Function Update Magnitude: 0.69238

Collected Steps per Second: 21,325.82436
Overall Steps per Second: 10,326.03006

Timestep Collection Time: 2.34486
Timestep Consumption Time: 2.49786
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.84271

Cumulative Model Updates: 13,170
Cumulative Timesteps: 109,940,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 109940762...
Checkpoint 109940762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,839.20963
Policy Entropy: 1.25587
Value Function Loss: 0.11512

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.14343
Policy Update Magnitude: 0.26721
Value Function Update Magnitude: 0.62845

Collected Steps per Second: 22,407.46335
Overall Steps per Second: 10,677.46878

Timestep Collection Time: 2.23158
Timestep Consumption Time: 2.45155
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.68313

Cumulative Model Updates: 13,176
Cumulative Timesteps: 109,990,766

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,872.90779
Policy Entropy: 1.24966
Value Function Loss: 0.11350

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.26731
Value Function Update Magnitude: 0.53695

Collected Steps per Second: 22,894.83180
Overall Steps per Second: 10,837.81461

Timestep Collection Time: 2.18407
Timestep Consumption Time: 2.42977
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.61385

Cumulative Model Updates: 13,182
Cumulative Timesteps: 110,040,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 110040770...
Checkpoint 110040770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,330.64059
Policy Entropy: 1.24956
Value Function Loss: 0.11203

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12107
Policy Update Magnitude: 0.29102
Value Function Update Magnitude: 0.49179

Collected Steps per Second: 22,528.00352
Overall Steps per Second: 10,717.97170

Timestep Collection Time: 2.22061
Timestep Consumption Time: 2.44687
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.66749

Cumulative Model Updates: 13,188
Cumulative Timesteps: 110,090,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645.04860
Policy Entropy: 1.25889
Value Function Loss: 0.11696

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.30084
Value Function Update Magnitude: 0.50525

Collected Steps per Second: 22,781.94560
Overall Steps per Second: 10,825.70856

Timestep Collection Time: 2.19525
Timestep Consumption Time: 2.42450
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.61974

Cumulative Model Updates: 13,194
Cumulative Timesteps: 110,140,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 110140808...
Checkpoint 110140808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,532.24447
Policy Entropy: 1.26556
Value Function Loss: 0.11880

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.29783
Value Function Update Magnitude: 0.44913

Collected Steps per Second: 22,562.37419
Overall Steps per Second: 10,658.07578

Timestep Collection Time: 2.21723
Timestep Consumption Time: 2.47649
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.69372

Cumulative Model Updates: 13,200
Cumulative Timesteps: 110,190,834

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,959.45641
Policy Entropy: 1.28022
Value Function Loss: 0.11164

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 0.31335
Value Function Update Magnitude: 0.45299

Collected Steps per Second: 22,698.70328
Overall Steps per Second: 10,591.49266

Timestep Collection Time: 2.20356
Timestep Consumption Time: 2.51891
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.72247

Cumulative Model Updates: 13,206
Cumulative Timesteps: 110,240,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 110240852...
Checkpoint 110240852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,515.44514
Policy Entropy: 1.27631
Value Function Loss: 0.11131

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.30705
Value Function Update Magnitude: 0.50374

Collected Steps per Second: 22,579.11312
Overall Steps per Second: 10,625.09751

Timestep Collection Time: 2.21506
Timestep Consumption Time: 2.49210
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.70716

Cumulative Model Updates: 13,212
Cumulative Timesteps: 110,290,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,956.36098
Policy Entropy: 1.26811
Value Function Loss: 0.10819

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12261
Policy Update Magnitude: 0.30002
Value Function Update Magnitude: 0.50172

Collected Steps per Second: 22,835.66042
Overall Steps per Second: 10,887.73607

Timestep Collection Time: 2.18991
Timestep Consumption Time: 2.40315
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.59306

Cumulative Model Updates: 13,218
Cumulative Timesteps: 110,340,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 110340874...
Checkpoint 110340874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,715.63496
Policy Entropy: 1.26178
Value Function Loss: 0.11415

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.15381
Policy Update Magnitude: 0.26918
Value Function Update Magnitude: 0.51896

Collected Steps per Second: 22,462.51987
Overall Steps per Second: 10,774.12685

Timestep Collection Time: 2.22655
Timestep Consumption Time: 2.41549
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.64205

Cumulative Model Updates: 13,224
Cumulative Timesteps: 110,390,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,073.23060
Policy Entropy: 1.25964
Value Function Loss: 0.11203

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.15100
Policy Update Magnitude: 0.28797
Value Function Update Magnitude: 0.50221

Collected Steps per Second: 23,048.62153
Overall Steps per Second: 10,905.09403

Timestep Collection Time: 2.17072
Timestep Consumption Time: 2.41723
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.58795

Cumulative Model Updates: 13,230
Cumulative Timesteps: 110,440,920

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 110440920...
Checkpoint 110440920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,703.80404
Policy Entropy: 1.27061
Value Function Loss: 0.11115

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.31484
Value Function Update Magnitude: 0.48915

Collected Steps per Second: 22,599.75010
Overall Steps per Second: 10,645.48391

Timestep Collection Time: 2.21356
Timestep Consumption Time: 2.48571
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.69927

Cumulative Model Updates: 13,236
Cumulative Timesteps: 110,490,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,199.02020
Policy Entropy: 1.26482
Value Function Loss: 0.11131

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.31761
Value Function Update Magnitude: 0.50116

Collected Steps per Second: 22,626.20928
Overall Steps per Second: 10,584.18347

Timestep Collection Time: 2.21159
Timestep Consumption Time: 2.51621
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.72781

Cumulative Model Updates: 13,242
Cumulative Timesteps: 110,540,986

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 110540986...
Checkpoint 110540986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,485.69125
Policy Entropy: 1.26673
Value Function Loss: 0.11307

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.31973
Value Function Update Magnitude: 0.49448

Collected Steps per Second: 22,802.98023
Overall Steps per Second: 10,722.92712

Timestep Collection Time: 2.19331
Timestep Consumption Time: 2.47090
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.66421

Cumulative Model Updates: 13,248
Cumulative Timesteps: 110,591,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,638.54349
Policy Entropy: 1.25971
Value Function Loss: 0.11327

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.29116
Value Function Update Magnitude: 0.49683

Collected Steps per Second: 22,828.74222
Overall Steps per Second: 10,736.97576

Timestep Collection Time: 2.19110
Timestep Consumption Time: 2.46757
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.65867

Cumulative Model Updates: 13,254
Cumulative Timesteps: 110,641,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 110641020...
Checkpoint 110641020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,877.24411
Policy Entropy: 1.24793
Value Function Loss: 0.11213

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.15783
Policy Update Magnitude: 0.26365
Value Function Update Magnitude: 0.49831

Collected Steps per Second: 22,583.72378
Overall Steps per Second: 10,601.14792

Timestep Collection Time: 2.21434
Timestep Consumption Time: 2.50289
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.71723

Cumulative Model Updates: 13,260
Cumulative Timesteps: 110,691,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,159.74199
Policy Entropy: 1.25932
Value Function Loss: 0.11296

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.17232
Policy Update Magnitude: 0.25818
Value Function Update Magnitude: 0.52430

Collected Steps per Second: 22,702.51040
Overall Steps per Second: 10,826.12487

Timestep Collection Time: 2.20258
Timestep Consumption Time: 2.41625
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.61883

Cumulative Model Updates: 13,266
Cumulative Timesteps: 110,741,032

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 110741032...
Checkpoint 110741032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,486.36300
Policy Entropy: 1.25634
Value Function Loss: 0.10865

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.27044
Value Function Update Magnitude: 0.57485

Collected Steps per Second: 22,726.45477
Overall Steps per Second: 10,785.35765

Timestep Collection Time: 2.20061
Timestep Consumption Time: 2.43642
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.63703

Cumulative Model Updates: 13,272
Cumulative Timesteps: 110,791,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,208.27123
Policy Entropy: 1.24573
Value Function Loss: 0.11128

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.27643
Value Function Update Magnitude: 0.59828

Collected Steps per Second: 22,976.72172
Overall Steps per Second: 10,841.90301

Timestep Collection Time: 2.17672
Timestep Consumption Time: 2.43630
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.61303

Cumulative Model Updates: 13,278
Cumulative Timesteps: 110,841,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 110841058...
Checkpoint 110841058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,096.24088
Policy Entropy: 1.23464
Value Function Loss: 0.11414

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.27370
Value Function Update Magnitude: 0.67926

Collected Steps per Second: 22,621.77590
Overall Steps per Second: 10,657.45135

Timestep Collection Time: 2.21097
Timestep Consumption Time: 2.48209
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.69305

Cumulative Model Updates: 13,284
Cumulative Timesteps: 110,891,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.61391
Policy Entropy: 1.23367
Value Function Loss: 0.11703

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07815
Policy Update Magnitude: 0.29579
Value Function Update Magnitude: 0.71447

Collected Steps per Second: 22,829.76211
Overall Steps per Second: 10,850.57401

Timestep Collection Time: 2.19074
Timestep Consumption Time: 2.41860
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.60934

Cumulative Model Updates: 13,290
Cumulative Timesteps: 110,941,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 110941088...
Checkpoint 110941088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,605.63559
Policy Entropy: 1.24190
Value Function Loss: 0.11671

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07033
Policy Update Magnitude: 0.32823
Value Function Update Magnitude: 0.65604

Collected Steps per Second: 22,621.49167
Overall Steps per Second: 10,669.43663

Timestep Collection Time: 2.21038
Timestep Consumption Time: 2.47609
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.68647

Cumulative Model Updates: 13,296
Cumulative Timesteps: 110,991,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,921.86529
Policy Entropy: 1.24912
Value Function Loss: 0.11306

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.07027
Policy Update Magnitude: 0.34046
Value Function Update Magnitude: 0.60224

Collected Steps per Second: 22,825.11727
Overall Steps per Second: 10,821.92361

Timestep Collection Time: 2.19153
Timestep Consumption Time: 2.43075
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.62228

Cumulative Model Updates: 13,302
Cumulative Timesteps: 111,041,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 111041112...
Checkpoint 111041112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,290.99072
Policy Entropy: 1.24628
Value Function Loss: 0.11406

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07929
Policy Update Magnitude: 0.32428
Value Function Update Magnitude: 0.59254

Collected Steps per Second: 22,297.63965
Overall Steps per Second: 10,726.06535

Timestep Collection Time: 2.24266
Timestep Consumption Time: 2.41944
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.66210

Cumulative Model Updates: 13,308
Cumulative Timesteps: 111,091,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,046.22278
Policy Entropy: 1.25322
Value Function Loss: 0.11626

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.32244
Value Function Update Magnitude: 0.53991

Collected Steps per Second: 22,587.45774
Overall Steps per Second: 10,661.36880

Timestep Collection Time: 2.21388
Timestep Consumption Time: 2.47651
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.69039

Cumulative Model Updates: 13,314
Cumulative Timesteps: 111,141,124

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 111141124...
Checkpoint 111141124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,632.07376
Policy Entropy: 1.24805
Value Function Loss: 0.12077

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08658
Policy Update Magnitude: 0.31911
Value Function Update Magnitude: 0.50313

Collected Steps per Second: 22,769.97549
Overall Steps per Second: 10,830.51396

Timestep Collection Time: 2.19631
Timestep Consumption Time: 2.42120
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.61751

Cumulative Model Updates: 13,320
Cumulative Timesteps: 111,191,134

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.88998
Policy Entropy: 1.24666
Value Function Loss: 0.11933

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.31414
Value Function Update Magnitude: 0.48466

Collected Steps per Second: 22,748.80224
Overall Steps per Second: 10,726.43119

Timestep Collection Time: 2.19994
Timestep Consumption Time: 2.46573
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.66567

Cumulative Model Updates: 13,326
Cumulative Timesteps: 111,241,180

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 111241180...
Checkpoint 111241180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,101.33889
Policy Entropy: 1.23023
Value Function Loss: 0.12334

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.29786
Value Function Update Magnitude: 0.48724

Collected Steps per Second: 22,494.28829
Overall Steps per Second: 10,814.80800

Timestep Collection Time: 2.22368
Timestep Consumption Time: 2.40146
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.62514

Cumulative Model Updates: 13,332
Cumulative Timesteps: 111,291,200

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.18925
Policy Entropy: 1.23277
Value Function Loss: 0.11924

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11444
Policy Update Magnitude: 0.28944
Value Function Update Magnitude: 0.48061

Collected Steps per Second: 22,784.96711
Overall Steps per Second: 10,721.26251

Timestep Collection Time: 2.19645
Timestep Consumption Time: 2.47147
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.66792

Cumulative Model Updates: 13,338
Cumulative Timesteps: 111,341,246

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 111341246...
Checkpoint 111341246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.93598
Policy Entropy: 1.22598
Value Function Loss: 0.12252

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.25972
Value Function Update Magnitude: 0.50349

Collected Steps per Second: 22,553.82927
Overall Steps per Second: 10,811.92213

Timestep Collection Time: 2.21745
Timestep Consumption Time: 2.40818
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.62563

Cumulative Model Updates: 13,344
Cumulative Timesteps: 111,391,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.94190
Policy Entropy: 1.23103
Value Function Loss: 0.12230

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.25070
Value Function Update Magnitude: 0.47424

Collected Steps per Second: 22,965.14352
Overall Steps per Second: 10,768.19896

Timestep Collection Time: 2.17878
Timestep Consumption Time: 2.46787
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.64665

Cumulative Model Updates: 13,350
Cumulative Timesteps: 111,441,294

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 111441294...
Checkpoint 111441294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,735.35436
Policy Entropy: 1.23511
Value Function Loss: 0.12028

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.26871
Value Function Update Magnitude: 0.46942

Collected Steps per Second: 22,543.70463
Overall Steps per Second: 10,797.38034

Timestep Collection Time: 2.21800
Timestep Consumption Time: 2.41294
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.63094

Cumulative Model Updates: 13,356
Cumulative Timesteps: 111,491,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.84886
Policy Entropy: 1.22676
Value Function Loss: 0.11736

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.29965
Value Function Update Magnitude: 0.49250

Collected Steps per Second: 22,859.38226
Overall Steps per Second: 10,712.89355

Timestep Collection Time: 2.18834
Timestep Consumption Time: 2.48118
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.66951

Cumulative Model Updates: 13,362
Cumulative Timesteps: 111,541,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 111541320...
Checkpoint 111541320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,666.94064
Policy Entropy: 1.24038
Value Function Loss: 0.11192

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.29731
Value Function Update Magnitude: 0.49257

Collected Steps per Second: 22,546.49849
Overall Steps per Second: 10,658.63675

Timestep Collection Time: 2.21844
Timestep Consumption Time: 2.47428
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.69272

Cumulative Model Updates: 13,368
Cumulative Timesteps: 111,591,338

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.70898
Policy Entropy: 1.22881
Value Function Loss: 0.11437

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.11008
Policy Update Magnitude: 0.28077
Value Function Update Magnitude: 0.49294

Collected Steps per Second: 23,133.60027
Overall Steps per Second: 10,732.32526

Timestep Collection Time: 2.16144
Timestep Consumption Time: 2.49756
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.65901

Cumulative Model Updates: 13,374
Cumulative Timesteps: 111,641,340

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 111641340...
Checkpoint 111641340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.25393
Policy Entropy: 1.23244
Value Function Loss: 0.11449

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11943
Policy Update Magnitude: 0.26583
Value Function Update Magnitude: 0.48864

Collected Steps per Second: 22,710.67911
Overall Steps per Second: 10,660.17826

Timestep Collection Time: 2.20293
Timestep Consumption Time: 2.49024
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.69317

Cumulative Model Updates: 13,380
Cumulative Timesteps: 111,691,370

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,526.52548
Policy Entropy: 1.23790
Value Function Loss: 0.11348

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.15108
Policy Update Magnitude: 0.26667
Value Function Update Magnitude: 0.48869

Collected Steps per Second: 22,936.49729
Overall Steps per Second: 10,849.96616

Timestep Collection Time: 2.18019
Timestep Consumption Time: 2.42867
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.60886

Cumulative Model Updates: 13,386
Cumulative Timesteps: 111,741,376

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 111741376...
Checkpoint 111741376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,997.44590
Policy Entropy: 1.22584
Value Function Loss: 0.11439

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.14024
Policy Update Magnitude: 0.25423
Value Function Update Magnitude: 0.57133

Collected Steps per Second: 22,512.23407
Overall Steps per Second: 10,628.82000

Timestep Collection Time: 2.22173
Timestep Consumption Time: 2.48397
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.70570

Cumulative Model Updates: 13,392
Cumulative Timesteps: 111,791,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,398.95291
Policy Entropy: 1.23998
Value Function Loss: 0.10970

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.27478
Value Function Update Magnitude: 0.56811

Collected Steps per Second: 22,963.60422
Overall Steps per Second: 10,884.14804

Timestep Collection Time: 2.17814
Timestep Consumption Time: 2.41735
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.59549

Cumulative Model Updates: 13,398
Cumulative Timesteps: 111,841,410

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 111841410...
Checkpoint 111841410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,418.55438
Policy Entropy: 1.23832
Value Function Loss: 0.11132

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.26878
Value Function Update Magnitude: 0.50674

Collected Steps per Second: 22,246.14271
Overall Steps per Second: 10,739.87517

Timestep Collection Time: 2.24884
Timestep Consumption Time: 2.40932
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.65815

Cumulative Model Updates: 13,404
Cumulative Timesteps: 111,891,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,413.37455
Policy Entropy: 1.24282
Value Function Loss: 0.10823

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.26513
Value Function Update Magnitude: 0.47460

Collected Steps per Second: 22,921.00365
Overall Steps per Second: 10,822.70871

Timestep Collection Time: 2.18210
Timestep Consumption Time: 2.43929
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.62139

Cumulative Model Updates: 13,410
Cumulative Timesteps: 111,941,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 111941454...
Checkpoint 111941454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.55459
Policy Entropy: 1.23640
Value Function Loss: 0.11447

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11835
Policy Update Magnitude: 0.26506
Value Function Update Magnitude: 0.52830

Collected Steps per Second: 22,331.67394
Overall Steps per Second: 10,650.56544

Timestep Collection Time: 2.23969
Timestep Consumption Time: 2.45640
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.69609

Cumulative Model Updates: 13,416
Cumulative Timesteps: 111,991,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,797.50360
Policy Entropy: 1.23661
Value Function Loss: 0.11106

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.24492
Value Function Update Magnitude: 0.50808

Collected Steps per Second: 22,764.42785
Overall Steps per Second: 10,858.67955

Timestep Collection Time: 2.19773
Timestep Consumption Time: 2.40965
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.60737

Cumulative Model Updates: 13,422
Cumulative Timesteps: 112,041,500

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 112041500...
Checkpoint 112041500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,885.81697
Policy Entropy: 1.23267
Value Function Loss: 0.11036

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.24189
Value Function Update Magnitude: 0.52676

Collected Steps per Second: 22,567.41229
Overall Steps per Second: 10,734.30636

Timestep Collection Time: 2.21594
Timestep Consumption Time: 2.44277
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.65871

Cumulative Model Updates: 13,428
Cumulative Timesteps: 112,091,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,476.56445
Policy Entropy: 1.23534
Value Function Loss: 0.11441

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10634
Policy Update Magnitude: 0.25103
Value Function Update Magnitude: 0.48860

Collected Steps per Second: 23,064.19938
Overall Steps per Second: 10,908.77657

Timestep Collection Time: 2.16942
Timestep Consumption Time: 2.41734
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.58677

Cumulative Model Updates: 13,434
Cumulative Timesteps: 112,141,544

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 112141544...
Checkpoint 112141544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,440.83972
Policy Entropy: 1.22888
Value Function Loss: 0.11363

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.30805
Value Function Update Magnitude: 0.46186

Collected Steps per Second: 22,587.21705
Overall Steps per Second: 10,609.77812

Timestep Collection Time: 2.21373
Timestep Consumption Time: 2.49909
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.71282

Cumulative Model Updates: 13,440
Cumulative Timesteps: 112,191,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,895.42364
Policy Entropy: 1.23150
Value Function Loss: 0.11143

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.31853
Value Function Update Magnitude: 0.45798

Collected Steps per Second: 22,734.04781
Overall Steps per Second: 10,836.72806

Timestep Collection Time: 2.20058
Timestep Consumption Time: 2.41595
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.61652

Cumulative Model Updates: 13,446
Cumulative Timesteps: 112,241,574

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 112241574...
Checkpoint 112241574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,813.78257
Policy Entropy: 1.24528
Value Function Loss: 0.10654

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.31073
Value Function Update Magnitude: 0.49524

Collected Steps per Second: 22,100.55319
Overall Steps per Second: 10,687.94646

Timestep Collection Time: 2.26257
Timestep Consumption Time: 2.41597
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.67854

Cumulative Model Updates: 13,452
Cumulative Timesteps: 112,291,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,531.30871
Policy Entropy: 1.26337
Value Function Loss: 0.09761

Mean KL Divergence: 0.02765
SB3 Clip Fraction: 0.21012
Policy Update Magnitude: 0.27622
Value Function Update Magnitude: 0.56896

Collected Steps per Second: 22,917.98724
Overall Steps per Second: 10,845.50009

Timestep Collection Time: 2.18213
Timestep Consumption Time: 2.42900
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.61113

Cumulative Model Updates: 13,458
Cumulative Timesteps: 112,341,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 112341588...
Checkpoint 112341588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,753.29716
Policy Entropy: 1.27861
Value Function Loss: 0.09803

Mean KL Divergence: 0.02817
SB3 Clip Fraction: 0.20896
Policy Update Magnitude: 0.21751
Value Function Update Magnitude: 0.60498

Collected Steps per Second: 22,265.17934
Overall Steps per Second: 10,692.00054

Timestep Collection Time: 2.24674
Timestep Consumption Time: 2.43190
PPO Batch Consumption Time: 0.28192
Total Iteration Time: 4.67864

Cumulative Model Updates: 13,464
Cumulative Timesteps: 112,391,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,039.98421
Policy Entropy: 1.28164
Value Function Loss: 0.10193

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.14768
Policy Update Magnitude: 0.21762
Value Function Update Magnitude: 0.62469

Collected Steps per Second: 22,735.64431
Overall Steps per Second: 10,666.63777

Timestep Collection Time: 2.19954
Timestep Consumption Time: 2.48872
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.68826

Cumulative Model Updates: 13,470
Cumulative Timesteps: 112,441,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 112441620...
Checkpoint 112441620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,492.79437
Policy Entropy: 1.25436
Value Function Loss: 0.10741

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.15981
Policy Update Magnitude: 0.23040
Value Function Update Magnitude: 0.62208

Collected Steps per Second: 22,839.67373
Overall Steps per Second: 10,899.81607

Timestep Collection Time: 2.19057
Timestep Consumption Time: 2.39960
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.59017

Cumulative Model Updates: 13,476
Cumulative Timesteps: 112,491,652

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,662.85665
Policy Entropy: 1.25088
Value Function Loss: 0.10767

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.17462
Policy Update Magnitude: 0.24104
Value Function Update Magnitude: 0.61234

Collected Steps per Second: 22,928.14594
Overall Steps per Second: 10,864.26709

Timestep Collection Time: 2.18125
Timestep Consumption Time: 2.42210
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.60335

Cumulative Model Updates: 13,482
Cumulative Timesteps: 112,541,664

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 112541664...
Checkpoint 112541664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.58134
Policy Entropy: 1.24459
Value Function Loss: 0.11551

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.30081
Value Function Update Magnitude: 0.58429

Collected Steps per Second: 22,530.84072
Overall Steps per Second: 10,770.66848

Timestep Collection Time: 2.21998
Timestep Consumption Time: 2.42393
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.64391

Cumulative Model Updates: 13,488
Cumulative Timesteps: 112,591,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,199.56052
Policy Entropy: 1.25104
Value Function Loss: 0.11622

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.16200
Policy Update Magnitude: 0.31740
Value Function Update Magnitude: 0.57482

Collected Steps per Second: 22,620.28204
Overall Steps per Second: 10,801.67168

Timestep Collection Time: 2.21049
Timestep Consumption Time: 2.41860
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.62910

Cumulative Model Updates: 13,494
Cumulative Timesteps: 112,641,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 112641684...
Checkpoint 112641684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,050.26688
Policy Entropy: 1.24803
Value Function Loss: 0.11466

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.15606
Policy Update Magnitude: 0.28620
Value Function Update Magnitude: 0.57245

Collected Steps per Second: 22,130.49378
Overall Steps per Second: 10,714.81832

Timestep Collection Time: 2.25933
Timestep Consumption Time: 2.40711
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.66643

Cumulative Model Updates: 13,500
Cumulative Timesteps: 112,691,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,269.06182
Policy Entropy: 1.25339
Value Function Loss: 0.10770

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.27137
Value Function Update Magnitude: 0.59275

Collected Steps per Second: 22,106.31739
Overall Steps per Second: 10,465.55726

Timestep Collection Time: 2.26306
Timestep Consumption Time: 2.51719
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.78025

Cumulative Model Updates: 13,506
Cumulative Timesteps: 112,741,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 112741712...
Checkpoint 112741712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,210.55729
Policy Entropy: 1.22906
Value Function Loss: 0.10831

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.31154
Value Function Update Magnitude: 0.63357

Collected Steps per Second: 22,442.09867
Overall Steps per Second: 10,598.12936

Timestep Collection Time: 2.22929
Timestep Consumption Time: 2.49135
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.72064

Cumulative Model Updates: 13,512
Cumulative Timesteps: 112,791,742

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,349.94927
Policy Entropy: 1.23172
Value Function Loss: 0.10420

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.32523
Value Function Update Magnitude: 0.66073

Collected Steps per Second: 22,388.73270
Overall Steps per Second: 10,520.18728

Timestep Collection Time: 2.23327
Timestep Consumption Time: 2.51950
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.75277

Cumulative Model Updates: 13,518
Cumulative Timesteps: 112,841,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 112841742...
Checkpoint 112841742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,458.72762
Policy Entropy: 1.21683
Value Function Loss: 0.10987

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08699
Policy Update Magnitude: 0.31801
Value Function Update Magnitude: 0.66900

Collected Steps per Second: 22,531.71496
Overall Steps per Second: 10,618.46734

Timestep Collection Time: 2.21980
Timestep Consumption Time: 2.49048
PPO Batch Consumption Time: 0.29706
Total Iteration Time: 4.71028

Cumulative Model Updates: 13,524
Cumulative Timesteps: 112,891,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.57253
Policy Entropy: 1.22079
Value Function Loss: 0.10842

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07403
Policy Update Magnitude: 0.32321
Value Function Update Magnitude: 0.67423

Collected Steps per Second: 23,012.35805
Overall Steps per Second: 10,905.26991

Timestep Collection Time: 2.17440
Timestep Consumption Time: 2.41403
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.58842

Cumulative Model Updates: 13,530
Cumulative Timesteps: 112,941,796

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 112941796...
Checkpoint 112941796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.81949
Policy Entropy: 1.22607
Value Function Loss: 0.11463

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.33321
Value Function Update Magnitude: 0.62376

Collected Steps per Second: 22,499.33206
Overall Steps per Second: 10,586.91963

Timestep Collection Time: 2.22327
Timestep Consumption Time: 2.50162
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.72489

Cumulative Model Updates: 13,536
Cumulative Timesteps: 112,991,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.14953
Policy Entropy: 1.22617
Value Function Loss: 0.11365

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07570
Policy Update Magnitude: 0.32954
Value Function Update Magnitude: 0.66119

Collected Steps per Second: 22,960.98895
Overall Steps per Second: 10,875.59379

Timestep Collection Time: 2.17856
Timestep Consumption Time: 2.42091
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.59947

Cumulative Model Updates: 13,542
Cumulative Timesteps: 113,041,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 113041840...
Checkpoint 113041840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,529.30633
Policy Entropy: 1.23726
Value Function Loss: 0.10827

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.32541
Value Function Update Magnitude: 0.71664

Collected Steps per Second: 22,369.97152
Overall Steps per Second: 10,752.29216

Timestep Collection Time: 2.23693
Timestep Consumption Time: 2.41696
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.65389

Cumulative Model Updates: 13,548
Cumulative Timesteps: 113,091,880

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,702.67024
Policy Entropy: 1.22901
Value Function Loss: 0.10308

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.32128
Value Function Update Magnitude: 0.71717

Collected Steps per Second: 22,870.75250
Overall Steps per Second: 10,842.01515

Timestep Collection Time: 2.18786
Timestep Consumption Time: 2.42733
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.61519

Cumulative Model Updates: 13,554
Cumulative Timesteps: 113,141,918

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 113141918...
Checkpoint 113141918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,354.87611
Policy Entropy: 1.22418
Value Function Loss: 0.10672

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08612
Policy Update Magnitude: 0.32115
Value Function Update Magnitude: 0.71385

Collected Steps per Second: 22,915.28397
Overall Steps per Second: 10,693.63667

Timestep Collection Time: 2.18247
Timestep Consumption Time: 2.49433
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.67680

Cumulative Model Updates: 13,560
Cumulative Timesteps: 113,191,930

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,414.85191
Policy Entropy: 1.21605
Value Function Loss: 0.10877

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11136
Policy Update Magnitude: 0.31555
Value Function Update Magnitude: 0.65911

Collected Steps per Second: 22,690.59128
Overall Steps per Second: 10,805.57187

Timestep Collection Time: 2.20417
Timestep Consumption Time: 2.42436
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.62854

Cumulative Model Updates: 13,566
Cumulative Timesteps: 113,241,944

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 113241944...
Checkpoint 113241944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,312.16726
Policy Entropy: 1.23039
Value Function Loss: 0.10939

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.14573
Policy Update Magnitude: 0.28058
Value Function Update Magnitude: 0.61117

Collected Steps per Second: 22,448.13290
Overall Steps per Second: 10,756.60055

Timestep Collection Time: 2.22789
Timestep Consumption Time: 2.42153
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.64942

Cumulative Model Updates: 13,572
Cumulative Timesteps: 113,291,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,301.11230
Policy Entropy: 1.23635
Value Function Loss: 0.11017

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.16536
Policy Update Magnitude: 0.24760
Value Function Update Magnitude: 0.53996

Collected Steps per Second: 22,970.78753
Overall Steps per Second: 10,903.60179

Timestep Collection Time: 2.17842
Timestep Consumption Time: 2.41089
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.58931

Cumulative Model Updates: 13,578
Cumulative Timesteps: 113,341,996

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 113341996...
Checkpoint 113341996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,155.98149
Policy Entropy: 1.24601
Value Function Loss: 0.10889

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.14028
Policy Update Magnitude: 0.23918
Value Function Update Magnitude: 0.54643

Collected Steps per Second: 22,160.23633
Overall Steps per Second: 10,610.28908

Timestep Collection Time: 2.25747
Timestep Consumption Time: 2.45739
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.71486

Cumulative Model Updates: 13,584
Cumulative Timesteps: 113,392,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,665.08672
Policy Entropy: 1.24085
Value Function Loss: 0.10617

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11502
Policy Update Magnitude: 0.26178
Value Function Update Magnitude: 0.55118

Collected Steps per Second: 22,739.55092
Overall Steps per Second: 10,840.79498

Timestep Collection Time: 2.20013
Timestep Consumption Time: 2.41484
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.61498

Cumulative Model Updates: 13,590
Cumulative Timesteps: 113,442,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 113442052...
Checkpoint 113442052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,526.69707
Policy Entropy: 1.22670
Value Function Loss: 0.10448

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.27040
Value Function Update Magnitude: 0.60118

Collected Steps per Second: 22,285.77107
Overall Steps per Second: 10,665.26306

Timestep Collection Time: 2.24394
Timestep Consumption Time: 2.44492
PPO Batch Consumption Time: 0.28169
Total Iteration Time: 4.68887

Cumulative Model Updates: 13,596
Cumulative Timesteps: 113,492,060

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,657.42705
Policy Entropy: 1.23020
Value Function Loss: 0.10258

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.13546
Policy Update Magnitude: 0.25327
Value Function Update Magnitude: 0.56883

Collected Steps per Second: 22,670.83628
Overall Steps per Second: 10,655.31917

Timestep Collection Time: 2.20618
Timestep Consumption Time: 2.48781
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.69399

Cumulative Model Updates: 13,602
Cumulative Timesteps: 113,542,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 113542076...
Checkpoint 113542076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,116.80268
Policy Entropy: 1.22644
Value Function Loss: 0.10447

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.25253
Value Function Update Magnitude: 0.60256

Collected Steps per Second: 22,346.63619
Overall Steps per Second: 10,599.03305

Timestep Collection Time: 2.23899
Timestep Consumption Time: 2.48162
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.72062

Cumulative Model Updates: 13,608
Cumulative Timesteps: 113,592,110

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,205.28830
Policy Entropy: 1.22279
Value Function Loss: 0.10455

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12600
Policy Update Magnitude: 0.27017
Value Function Update Magnitude: 0.62871

Collected Steps per Second: 22,914.00290
Overall Steps per Second: 10,807.75512

Timestep Collection Time: 2.18268
Timestep Consumption Time: 2.44492
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.62760

Cumulative Model Updates: 13,614
Cumulative Timesteps: 113,642,124

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 113642124...
Checkpoint 113642124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,068.60746
Policy Entropy: 1.20549
Value Function Loss: 0.10449

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.29357
Value Function Update Magnitude: 0.64047

Collected Steps per Second: 22,525.92717
Overall Steps per Second: 10,634.12135

Timestep Collection Time: 2.22073
Timestep Consumption Time: 2.48337
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.70410

Cumulative Model Updates: 13,620
Cumulative Timesteps: 113,692,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,797.49672
Policy Entropy: 1.20426
Value Function Loss: 0.11093

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.15633
Policy Update Magnitude: 0.26968
Value Function Update Magnitude: 0.61301

Collected Steps per Second: 22,785.19749
Overall Steps per Second: 10,855.61779

Timestep Collection Time: 2.19528
Timestep Consumption Time: 2.41247
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.60775

Cumulative Model Updates: 13,626
Cumulative Timesteps: 113,742,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 113742168...
Checkpoint 113742168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733.14634
Policy Entropy: 1.20840
Value Function Loss: 0.10733

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.15557
Policy Update Magnitude: 0.27180
Value Function Update Magnitude: 0.56942

Collected Steps per Second: 22,601.78349
Overall Steps per Second: 10,650.03406

Timestep Collection Time: 2.21301
Timestep Consumption Time: 2.48350
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.69651

Cumulative Model Updates: 13,632
Cumulative Timesteps: 113,792,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,278.66368
Policy Entropy: 1.22651
Value Function Loss: 0.10986

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.29133
Value Function Update Magnitude: 0.53124

Collected Steps per Second: 22,721.74507
Overall Steps per Second: 10,627.34841

Timestep Collection Time: 2.20133
Timestep Consumption Time: 2.50521
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.70654

Cumulative Model Updates: 13,638
Cumulative Timesteps: 113,842,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 113842204...
Checkpoint 113842204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,241.77089
Policy Entropy: 1.21882
Value Function Loss: 0.10575

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08527
Policy Update Magnitude: 0.30855
Value Function Update Magnitude: 0.59345

Collected Steps per Second: 22,691.78240
Overall Steps per Second: 10,859.32349

Timestep Collection Time: 2.20406
Timestep Consumption Time: 2.40157
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.60563

Cumulative Model Updates: 13,644
Cumulative Timesteps: 113,892,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,538.74673
Policy Entropy: 1.21002
Value Function Loss: 0.10542

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06548
Policy Update Magnitude: 0.32902
Value Function Update Magnitude: 0.68329

Collected Steps per Second: 22,836.54197
Overall Steps per Second: 10,625.97113

Timestep Collection Time: 2.19009
Timestep Consumption Time: 2.51668
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.70677

Cumulative Model Updates: 13,650
Cumulative Timesteps: 113,942,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 113942232...
Checkpoint 113942232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,650.03694
Policy Entropy: 1.20260
Value Function Loss: 0.10740

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.31906
Value Function Update Magnitude: 0.69466

Collected Steps per Second: 22,794.35228
Overall Steps per Second: 10,626.26296

Timestep Collection Time: 2.19458
Timestep Consumption Time: 2.51300
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.70758

Cumulative Model Updates: 13,656
Cumulative Timesteps: 113,992,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,400.87306
Policy Entropy: 1.20218
Value Function Loss: 0.10739

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11984
Policy Update Magnitude: 0.30425
Value Function Update Magnitude: 0.62829

Collected Steps per Second: 22,837.10736
Overall Steps per Second: 10,796.15319

Timestep Collection Time: 2.19108
Timestep Consumption Time: 2.44372
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.63480

Cumulative Model Updates: 13,662
Cumulative Timesteps: 114,042,294

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 114042294...
Checkpoint 114042294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,239.64045
Policy Entropy: 1.19483
Value Function Loss: 0.10882

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.30742
Value Function Update Magnitude: 0.55204

Collected Steps per Second: 22,735.94025
Overall Steps per Second: 10,667.78614

Timestep Collection Time: 2.20048
Timestep Consumption Time: 2.48934
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.68982

Cumulative Model Updates: 13,668
Cumulative Timesteps: 114,092,324

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,749.02928
Policy Entropy: 1.19066
Value Function Loss: 0.10953

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.31621
Value Function Update Magnitude: 0.54060

Collected Steps per Second: 22,987.51830
Overall Steps per Second: 10,883.07196

Timestep Collection Time: 2.17675
Timestep Consumption Time: 2.42104
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.59778

Cumulative Model Updates: 13,674
Cumulative Timesteps: 114,142,362

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 114142362...
Checkpoint 114142362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,893.01727
Policy Entropy: 1.17854
Value Function Loss: 0.11174

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11536
Policy Update Magnitude: 0.31199
Value Function Update Magnitude: 0.52185

Collected Steps per Second: 22,509.95242
Overall Steps per Second: 10,728.80828

Timestep Collection Time: 2.22160
Timestep Consumption Time: 2.43950
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.66110

Cumulative Model Updates: 13,680
Cumulative Timesteps: 114,192,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,273.83130
Policy Entropy: 1.16829
Value Function Loss: 0.11201

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.28174
Value Function Update Magnitude: 0.59125

Collected Steps per Second: 22,960.70056
Overall Steps per Second: 10,893.61260

Timestep Collection Time: 2.17920
Timestep Consumption Time: 2.41395
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.59315

Cumulative Model Updates: 13,686
Cumulative Timesteps: 114,242,406

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 114242406...
Checkpoint 114242406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,429.23736
Policy Entropy: 1.17608
Value Function Loss: 0.11023

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.15395
Policy Update Magnitude: 0.28814
Value Function Update Magnitude: 0.65021

Collected Steps per Second: 22,285.66394
Overall Steps per Second: 10,610.93108

Timestep Collection Time: 2.24377
Timestep Consumption Time: 2.46872
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.71250

Cumulative Model Updates: 13,692
Cumulative Timesteps: 114,292,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,138.13840
Policy Entropy: 1.17909
Value Function Loss: 0.11219

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.26202
Value Function Update Magnitude: 0.65835

Collected Steps per Second: 22,968.16835
Overall Steps per Second: 10,862.20937

Timestep Collection Time: 2.17797
Timestep Consumption Time: 2.42735
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.60532

Cumulative Model Updates: 13,698
Cumulative Timesteps: 114,342,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 114342434...
Checkpoint 114342434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,608.16084
Policy Entropy: 1.18153
Value Function Loss: 0.11182

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.23619
Value Function Update Magnitude: 0.66790

Collected Steps per Second: 22,294.66937
Overall Steps per Second: 10,738.76705

Timestep Collection Time: 2.24314
Timestep Consumption Time: 2.41382
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.65696

Cumulative Model Updates: 13,704
Cumulative Timesteps: 114,392,444

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,985.10843
Policy Entropy: 1.18576
Value Function Loss: 0.10620

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.24767
Value Function Update Magnitude: 0.70976

Collected Steps per Second: 22,642.04076
Overall Steps per Second: 10,807.03553

Timestep Collection Time: 2.21022
Timestep Consumption Time: 2.42046
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.63069

Cumulative Model Updates: 13,710
Cumulative Timesteps: 114,442,488

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 114442488...
Checkpoint 114442488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,436.68255
Policy Entropy: 1.18387
Value Function Loss: 0.10706

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.27214
Value Function Update Magnitude: 0.66621

Collected Steps per Second: 22,538.77387
Overall Steps per Second: 10,693.81944

Timestep Collection Time: 2.21867
Timestep Consumption Time: 2.45749
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.67616

Cumulative Model Updates: 13,716
Cumulative Timesteps: 114,492,494

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,868.36196
Policy Entropy: 1.19505
Value Function Loss: 0.10995

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10669
Policy Update Magnitude: 0.31895
Value Function Update Magnitude: 0.62888

Collected Steps per Second: 23,057.75438
Overall Steps per Second: 10,876.10983

Timestep Collection Time: 2.16916
Timestep Consumption Time: 2.42954
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.59870

Cumulative Model Updates: 13,722
Cumulative Timesteps: 114,542,510

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 114542510...
Checkpoint 114542510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,066.30897
Policy Entropy: 1.18629
Value Function Loss: 0.11109

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07668
Policy Update Magnitude: 0.32558
Value Function Update Magnitude: 0.65082

Collected Steps per Second: 22,602.91742
Overall Steps per Second: 10,659.86544

Timestep Collection Time: 2.21334
Timestep Consumption Time: 2.47977
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.69312

Cumulative Model Updates: 13,728
Cumulative Timesteps: 114,592,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,767.55755
Policy Entropy: 1.18942
Value Function Loss: 0.11032

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06729
Policy Update Magnitude: 0.31520
Value Function Update Magnitude: 0.66075

Collected Steps per Second: 22,860.39009
Overall Steps per Second: 10,874.21600

Timestep Collection Time: 2.18911
Timestep Consumption Time: 2.41296
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.60208

Cumulative Model Updates: 13,734
Cumulative Timesteps: 114,642,582

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 114642582...
Checkpoint 114642582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,729.77119
Policy Entropy: 1.19103
Value Function Loss: 0.10894

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07673
Policy Update Magnitude: 0.32194
Value Function Update Magnitude: 0.67002

Collected Steps per Second: 22,151.17707
Overall Steps per Second: 10,714.41810

Timestep Collection Time: 2.25875
Timestep Consumption Time: 2.41103
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.66978

Cumulative Model Updates: 13,740
Cumulative Timesteps: 114,692,616

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,438.52092
Policy Entropy: 1.19739
Value Function Loss: 0.10620

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07459
Policy Update Magnitude: 0.32612
Value Function Update Magnitude: 0.69482

Collected Steps per Second: 23,106.24594
Overall Steps per Second: 10,927.10340

Timestep Collection Time: 2.16625
Timestep Consumption Time: 2.41447
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.58072

Cumulative Model Updates: 13,746
Cumulative Timesteps: 114,742,670

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 114742670...
Checkpoint 114742670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,775.22757
Policy Entropy: 1.20754
Value Function Loss: 0.10509

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.32356
Value Function Update Magnitude: 0.68370

Collected Steps per Second: 22,523.04867
Overall Steps per Second: 10,586.98907

Timestep Collection Time: 2.22164
Timestep Consumption Time: 2.50473
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.72637

Cumulative Model Updates: 13,752
Cumulative Timesteps: 114,792,708

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,184.26595
Policy Entropy: 1.19114
Value Function Loss: 0.11129

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.27839
Value Function Update Magnitude: 0.64753

Collected Steps per Second: 23,017.91576
Overall Steps per Second: 10,879.12558

Timestep Collection Time: 2.17378
Timestep Consumption Time: 2.42548
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.59927

Cumulative Model Updates: 13,758
Cumulative Timesteps: 114,842,744

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 114842744...
Checkpoint 114842744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,990.73129
Policy Entropy: 1.19828
Value Function Loss: 0.11438

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.28070
Value Function Update Magnitude: 0.62480

Collected Steps per Second: 22,278.28767
Overall Steps per Second: 10,758.17676

Timestep Collection Time: 2.24488
Timestep Consumption Time: 2.40387
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.64874

Cumulative Model Updates: 13,764
Cumulative Timesteps: 114,892,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,609.36297
Policy Entropy: 1.17806
Value Function Loss: 0.11662

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.26858
Value Function Update Magnitude: 0.62859

Collected Steps per Second: 23,034.87468
Overall Steps per Second: 10,897.79061

Timestep Collection Time: 2.17080
Timestep Consumption Time: 2.41766
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.58845

Cumulative Model Updates: 13,770
Cumulative Timesteps: 114,942,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 114942760...
Checkpoint 114942760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,321.99716
Policy Entropy: 1.18835
Value Function Loss: 0.10848

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.28472
Value Function Update Magnitude: 0.62544

Collected Steps per Second: 22,425.77229
Overall Steps per Second: 10,592.97808

Timestep Collection Time: 2.23074
Timestep Consumption Time: 2.49183
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.72256

Cumulative Model Updates: 13,776
Cumulative Timesteps: 114,992,786

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,985.09345
Policy Entropy: 1.17627
Value Function Loss: 0.11050

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.30460
Value Function Update Magnitude: 0.67092

Collected Steps per Second: 22,866.80559
Overall Steps per Second: 10,845.61834

Timestep Collection Time: 2.18666
Timestep Consumption Time: 2.42368
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.61034

Cumulative Model Updates: 13,782
Cumulative Timesteps: 115,042,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 115042788...
Checkpoint 115042788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,514.20540
Policy Entropy: 1.18786
Value Function Loss: 0.11014

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10492
Policy Update Magnitude: 0.31835
Value Function Update Magnitude: 0.67048

Collected Steps per Second: 22,244.27785
Overall Steps per Second: 10,719.51745

Timestep Collection Time: 2.24876
Timestep Consumption Time: 2.41768
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.66644

Cumulative Model Updates: 13,788
Cumulative Timesteps: 115,092,810

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,365.72815
Policy Entropy: 1.17813
Value Function Loss: 0.10799

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.28776
Value Function Update Magnitude: 0.67951

Collected Steps per Second: 22,957.61097
Overall Steps per Second: 10,878.18502

Timestep Collection Time: 2.17810
Timestep Consumption Time: 2.41862
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.59672

Cumulative Model Updates: 13,794
Cumulative Timesteps: 115,142,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 115142814...
Checkpoint 115142814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,734.38762
Policy Entropy: 1.18518
Value Function Loss: 0.10433

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11835
Policy Update Magnitude: 0.29485
Value Function Update Magnitude: 0.69149

Collected Steps per Second: 22,592.18748
Overall Steps per Second: 10,633.59269

Timestep Collection Time: 2.21404
Timestep Consumption Time: 2.48992
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.70396

Cumulative Model Updates: 13,800
Cumulative Timesteps: 115,192,834

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,986.32313
Policy Entropy: 1.18924
Value Function Loss: 0.10384

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.14999
Policy Update Magnitude: 0.27471
Value Function Update Magnitude: 0.68929

Collected Steps per Second: 23,032.28114
Overall Steps per Second: 10,889.16938

Timestep Collection Time: 2.17269
Timestep Consumption Time: 2.42289
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.59558

Cumulative Model Updates: 13,806
Cumulative Timesteps: 115,242,876

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 115242876...
Checkpoint 115242876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,203.00265
Policy Entropy: 1.19897
Value Function Loss: 0.10546

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13359
Policy Update Magnitude: 0.27088
Value Function Update Magnitude: 0.68729

Collected Steps per Second: 22,529.10896
Overall Steps per Second: 10,699.49940

Timestep Collection Time: 2.21962
Timestep Consumption Time: 2.45406
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.67368

Cumulative Model Updates: 13,812
Cumulative Timesteps: 115,292,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,479.91476
Policy Entropy: 1.19207
Value Function Loss: 0.10582

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.27221
Value Function Update Magnitude: 0.67455

Collected Steps per Second: 22,834.77678
Overall Steps per Second: 10,802.91486

Timestep Collection Time: 2.19026
Timestep Consumption Time: 2.43942
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.62968

Cumulative Model Updates: 13,818
Cumulative Timesteps: 115,342,896

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 115342896...
Checkpoint 115342896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,315.70927
Policy Entropy: 1.20435
Value Function Loss: 0.10808

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.13770
Policy Update Magnitude: 0.28062
Value Function Update Magnitude: 0.62931

Collected Steps per Second: 22,389.06506
Overall Steps per Second: 10,677.10392

Timestep Collection Time: 2.23430
Timestep Consumption Time: 2.45086
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.68517

Cumulative Model Updates: 13,824
Cumulative Timesteps: 115,392,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722.48228
Policy Entropy: 1.20216
Value Function Loss: 0.11279

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.28994
Value Function Update Magnitude: 0.58173

Collected Steps per Second: 22,959.54410
Overall Steps per Second: 10,884.19773

Timestep Collection Time: 2.17783
Timestep Consumption Time: 2.41617
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.59400

Cumulative Model Updates: 13,830
Cumulative Timesteps: 115,442,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 115442922...
Checkpoint 115442922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,858.68856
Policy Entropy: 1.20247
Value Function Loss: 0.11577

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.27221
Value Function Update Magnitude: 0.63042

Collected Steps per Second: 22,049.75915
Overall Steps per Second: 10,695.50300

Timestep Collection Time: 2.26841
Timestep Consumption Time: 2.40813
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.67654

Cumulative Model Updates: 13,836
Cumulative Timesteps: 115,492,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,884.87235
Policy Entropy: 1.20899
Value Function Loss: 0.11650

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08672
Policy Update Magnitude: 0.31402
Value Function Update Magnitude: 0.59091

Collected Steps per Second: 22,843.52977
Overall Steps per Second: 10,851.79801

Timestep Collection Time: 2.18915
Timestep Consumption Time: 2.41911
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.60827

Cumulative Model Updates: 13,842
Cumulative Timesteps: 115,542,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 115542948...
Checkpoint 115542948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,128.68649
Policy Entropy: 1.21705
Value Function Loss: 0.11207

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07581
Policy Update Magnitude: 0.35371
Value Function Update Magnitude: 0.51500

Collected Steps per Second: 22,586.21002
Overall Steps per Second: 10,751.30142

Timestep Collection Time: 2.21418
Timestep Consumption Time: 2.43735
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.65153

Cumulative Model Updates: 13,848
Cumulative Timesteps: 115,592,958

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,803.76215
Policy Entropy: 1.21799
Value Function Loss: 0.11369

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.07221
Policy Update Magnitude: 0.34981
Value Function Update Magnitude: 0.50151

Collected Steps per Second: 22,800.05015
Overall Steps per Second: 10,838.24538

Timestep Collection Time: 2.19421
Timestep Consumption Time: 2.42167
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.61588

Cumulative Model Updates: 13,854
Cumulative Timesteps: 115,642,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 115642986...
Checkpoint 115642986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,127.27645
Policy Entropy: 1.20399
Value Function Loss: 0.11174

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12923
Policy Update Magnitude: 0.31625
Value Function Update Magnitude: 0.51761

Collected Steps per Second: 22,377.36980
Overall Steps per Second: 10,663.78648

Timestep Collection Time: 2.23485
Timestep Consumption Time: 2.45486
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.68970

Cumulative Model Updates: 13,860
Cumulative Timesteps: 115,692,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,612.76892
Policy Entropy: 1.20446
Value Function Loss: 0.10909

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.27761
Value Function Update Magnitude: 0.54711

Collected Steps per Second: 23,089.85249
Overall Steps per Second: 10,916.59646

Timestep Collection Time: 2.16632
Timestep Consumption Time: 2.41569
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.58201

Cumulative Model Updates: 13,866
Cumulative Timesteps: 115,743,016

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 115743016...
Checkpoint 115743016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,550.99937
Policy Entropy: 1.20505
Value Function Loss: 0.10919

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.25772
Value Function Update Magnitude: 0.56377

Collected Steps per Second: 22,676.70527
Overall Steps per Second: 10,631.23466

Timestep Collection Time: 2.20596
Timestep Consumption Time: 2.49942
PPO Batch Consumption Time: 0.29577
Total Iteration Time: 4.70538

Cumulative Model Updates: 13,872
Cumulative Timesteps: 115,793,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,225.94610
Policy Entropy: 1.22779
Value Function Loss: 0.10635

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13117
Policy Update Magnitude: 0.27376
Value Function Update Magnitude: 0.54087

Collected Steps per Second: 22,553.06319
Overall Steps per Second: 10,663.66582

Timestep Collection Time: 2.21850
Timestep Consumption Time: 2.47351
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.69201

Cumulative Model Updates: 13,878
Cumulative Timesteps: 115,843,074

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 115843074...
Checkpoint 115843074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.89646
Policy Entropy: 1.22012
Value Function Loss: 0.11058

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.12089
Policy Update Magnitude: 0.29105
Value Function Update Magnitude: 0.56929

Collected Steps per Second: 22,412.85033
Overall Steps per Second: 10,631.98657

Timestep Collection Time: 2.23095
Timestep Consumption Time: 2.47203
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.70298

Cumulative Model Updates: 13,884
Cumulative Timesteps: 115,893,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,003.14083
Policy Entropy: 1.21227
Value Function Loss: 0.10820

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12990
Policy Update Magnitude: 0.29576
Value Function Update Magnitude: 0.56855

Collected Steps per Second: 22,823.27019
Overall Steps per Second: 10,699.58763

Timestep Collection Time: 2.19154
Timestep Consumption Time: 2.48322
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.67476

Cumulative Model Updates: 13,890
Cumulative Timesteps: 115,943,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 115943094...
Checkpoint 115943094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,258.64708
Policy Entropy: 1.18732
Value Function Loss: 0.11179

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11848
Policy Update Magnitude: 0.26931
Value Function Update Magnitude: 0.58952

Collected Steps per Second: 22,652.52131
Overall Steps per Second: 10,621.80470

Timestep Collection Time: 2.20832
Timestep Consumption Time: 2.50124
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.70956

Cumulative Model Updates: 13,896
Cumulative Timesteps: 115,993,118

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,339.44591
Policy Entropy: 1.19455
Value Function Loss: 0.11344

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14274
Policy Update Magnitude: 0.25481
Value Function Update Magnitude: 0.53278

Collected Steps per Second: 22,840.66685
Overall Steps per Second: 10,860.39707

Timestep Collection Time: 2.19013
Timestep Consumption Time: 2.41596
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.60609

Cumulative Model Updates: 13,902
Cumulative Timesteps: 116,043,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 116043142...
Checkpoint 116043142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,517.56173
Policy Entropy: 1.19081
Value Function Loss: 0.11470

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.27219
Value Function Update Magnitude: 0.50061

Collected Steps per Second: 22,442.93697
Overall Steps per Second: 10,710.86086

Timestep Collection Time: 2.22903
Timestep Consumption Time: 2.44156
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.67059

Cumulative Model Updates: 13,908
Cumulative Timesteps: 116,093,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,990.32402
Policy Entropy: 1.19839
Value Function Loss: 0.11665

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.27519
Value Function Update Magnitude: 0.46662

Collected Steps per Second: 22,921.75920
Overall Steps per Second: 10,873.16977

Timestep Collection Time: 2.18142
Timestep Consumption Time: 2.41724
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.59866

Cumulative Model Updates: 13,914
Cumulative Timesteps: 116,143,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 116143170...
Checkpoint 116143170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638.34273
Policy Entropy: 1.19821
Value Function Loss: 0.11305

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.28333
Value Function Update Magnitude: 0.49277

Collected Steps per Second: 22,542.49315
Overall Steps per Second: 10,667.12292

Timestep Collection Time: 2.21812
Timestep Consumption Time: 2.46936
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.68749

Cumulative Model Updates: 13,920
Cumulative Timesteps: 116,193,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,936.47448
Policy Entropy: 1.20898
Value Function Loss: 0.11364

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.26445
Value Function Update Magnitude: 0.48164

Collected Steps per Second: 22,794.27438
Overall Steps per Second: 10,812.91136

Timestep Collection Time: 2.19459
Timestep Consumption Time: 2.43173
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.62632

Cumulative Model Updates: 13,926
Cumulative Timesteps: 116,243,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 116243196...
Checkpoint 116243196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,119.69970
Policy Entropy: 1.20294
Value Function Loss: 0.11208

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.26522
Value Function Update Magnitude: 0.48867

Collected Steps per Second: 22,411.66407
Overall Steps per Second: 10,705.09594

Timestep Collection Time: 2.23178
Timestep Consumption Time: 2.44057
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.67235

Cumulative Model Updates: 13,932
Cumulative Timesteps: 116,293,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,873.44742
Policy Entropy: 1.21363
Value Function Loss: 0.10916

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.17071
Policy Update Magnitude: 0.24432
Value Function Update Magnitude: 0.57861

Collected Steps per Second: 20,716.84113
Overall Steps per Second: 10,195.61886

Timestep Collection Time: 2.41504
Timestep Consumption Time: 2.49217
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.90721

Cumulative Model Updates: 13,938
Cumulative Timesteps: 116,343,246

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 116343246...
Checkpoint 116343246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,631.10815
Policy Entropy: 1.21072
Value Function Loss: 0.10994

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.26848
Value Function Update Magnitude: 0.60548

Collected Steps per Second: 21,500.97257
Overall Steps per Second: 40.08818

Timestep Collection Time: 2.32548
Timestep Consumption Time: 1,244.92490
PPO Batch Consumption Time: 0.50552
Total Iteration Time: 1,247.25038

Cumulative Model Updates: 13,944
Cumulative Timesteps: 116,393,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,027.11641
Policy Entropy: 1.22610
Value Function Loss: 0.10843

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.28683
Value Function Update Magnitude: 0.60724

Collected Steps per Second: 10,911.42747
Overall Steps per Second: 7,230.92254

Timestep Collection Time: 4.58437
Timestep Consumption Time: 2.33342
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 6.91779

Cumulative Model Updates: 13,950
Cumulative Timesteps: 116,443,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 116443268...
Checkpoint 116443268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,529.57281
Policy Entropy: 1.22947
Value Function Loss: 0.10802

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.26401
Value Function Update Magnitude: 0.67349

Collected Steps per Second: 16,701.51239
Overall Steps per Second: 9,003.99428

Timestep Collection Time: 2.99554
Timestep Consumption Time: 2.56089
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 5.55642

Cumulative Model Updates: 13,956
Cumulative Timesteps: 116,493,298

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,538.92472
Policy Entropy: 1.22522
Value Function Loss: 0.10664

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.25655
Value Function Update Magnitude: 0.70440

Collected Steps per Second: 21,788.30037
Overall Steps per Second: 10,665.48275

Timestep Collection Time: 2.29554
Timestep Consumption Time: 2.39398
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.68952

Cumulative Model Updates: 13,962
Cumulative Timesteps: 116,543,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 116543314...
Checkpoint 116543314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,575.14424
Policy Entropy: 1.23439
Value Function Loss: 0.10588

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.18205
Policy Update Magnitude: 0.25809
Value Function Update Magnitude: 0.71255

Collected Steps per Second: 22,040.42048
Overall Steps per Second: 10,488.78040

Timestep Collection Time: 2.26929
Timestep Consumption Time: 2.49924
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.76852

Cumulative Model Updates: 13,968
Cumulative Timesteps: 116,593,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,369.92373
Policy Entropy: 1.24778
Value Function Loss: 0.10502

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.15641
Policy Update Magnitude: 0.29588
Value Function Update Magnitude: 0.68462

Collected Steps per Second: 22,878.90476
Overall Steps per Second: 10,652.05667

Timestep Collection Time: 2.18647
Timestep Consumption Time: 2.50971
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.69618

Cumulative Model Updates: 13,974
Cumulative Timesteps: 116,643,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 116643354...
Checkpoint 116643354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,613.97272
Policy Entropy: 1.23029
Value Function Loss: 0.10477

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.32704
Value Function Update Magnitude: 0.68094

Collected Steps per Second: 22,726.53252
Overall Steps per Second: 10,639.14439

Timestep Collection Time: 2.20148
Timestep Consumption Time: 2.50115
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.70263

Cumulative Model Updates: 13,980
Cumulative Timesteps: 116,693,386

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,779.05115
Policy Entropy: 1.22677
Value Function Loss: 0.10526

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.33853
Value Function Update Magnitude: 0.72359

Collected Steps per Second: 22,833.90131
Overall Steps per Second: 10,801.60133

Timestep Collection Time: 2.19095
Timestep Consumption Time: 2.44058
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.63154

Cumulative Model Updates: 13,986
Cumulative Timesteps: 116,743,414

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 116743414...
Checkpoint 116743414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,229.15310
Policy Entropy: 1.21570
Value Function Loss: 0.10328

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07182
Policy Update Magnitude: 0.34738
Value Function Update Magnitude: 0.70511

Collected Steps per Second: 22,944.64714
Overall Steps per Second: 10,847.36283

Timestep Collection Time: 2.18020
Timestep Consumption Time: 2.43142
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.61163

Cumulative Model Updates: 13,992
Cumulative Timesteps: 116,793,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,507.00220
Policy Entropy: 1.21650
Value Function Loss: 0.10569

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.33644
Value Function Update Magnitude: 0.68621

Collected Steps per Second: 23,038.00197
Overall Steps per Second: 10,827.90720

Timestep Collection Time: 2.17033
Timestep Consumption Time: 2.44737
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.61770

Cumulative Model Updates: 13,998
Cumulative Timesteps: 116,843,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 116843438...
Checkpoint 116843438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,112.10250
Policy Entropy: 1.21635
Value Function Loss: 0.09933

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.33301
Value Function Update Magnitude: 0.67844

Collected Steps per Second: 22,787.61955
Overall Steps per Second: 10,921.80368

Timestep Collection Time: 2.19496
Timestep Consumption Time: 2.38468
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.57965

Cumulative Model Updates: 14,004
Cumulative Timesteps: 116,893,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,300.05390
Policy Entropy: 1.21310
Value Function Loss: 0.10204

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07387
Policy Update Magnitude: 0.33724
Value Function Update Magnitude: 0.64953

Collected Steps per Second: 23,187.81326
Overall Steps per Second: 10,908.27441

Timestep Collection Time: 2.15631
Timestep Consumption Time: 2.42737
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.58368

Cumulative Model Updates: 14,010
Cumulative Timesteps: 116,943,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 116943456...
Checkpoint 116943456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,003.58001
Policy Entropy: 1.21022
Value Function Loss: 0.09923

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07593
Policy Update Magnitude: 0.33820
Value Function Update Magnitude: 0.66249

Collected Steps per Second: 22,642.90095
Overall Steps per Second: 10,662.57183

Timestep Collection Time: 2.20908
Timestep Consumption Time: 2.48209
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.69118

Cumulative Model Updates: 14,016
Cumulative Timesteps: 116,993,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,092.18111
Policy Entropy: 1.21023
Value Function Loss: 0.09862

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.32069
Value Function Update Magnitude: 0.65510

Collected Steps per Second: 22,759.94670
Overall Steps per Second: 10,814.44072

Timestep Collection Time: 2.19684
Timestep Consumption Time: 2.42661
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.62345

Cumulative Model Updates: 14,022
Cumulative Timesteps: 117,043,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 117043476...
Checkpoint 117043476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,782.07356
Policy Entropy: 1.21583
Value Function Loss: 0.09796

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.26396
Value Function Update Magnitude: 0.58145

Collected Steps per Second: 20,439.73841
Overall Steps per Second: 10,259.19472

Timestep Collection Time: 2.44690
Timestep Consumption Time: 2.42814
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.87504

Cumulative Model Updates: 14,028
Cumulative Timesteps: 117,093,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,439.93956
Policy Entropy: 1.21580
Value Function Loss: 0.10578

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.26342
Value Function Update Magnitude: 0.51181

Collected Steps per Second: 22,994.40594
Overall Steps per Second: 10,964.24735

Timestep Collection Time: 2.17488
Timestep Consumption Time: 2.38631
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.56119

Cumulative Model Updates: 14,034
Cumulative Timesteps: 117,143,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 117143500...
Checkpoint 117143500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,030.43950
Policy Entropy: 1.21611
Value Function Loss: 0.11019

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12351
Policy Update Magnitude: 0.28092
Value Function Update Magnitude: 0.50298

Collected Steps per Second: 22,965.82490
Overall Steps per Second: 10,827.41256

Timestep Collection Time: 2.17845
Timestep Consumption Time: 2.44222
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.62068

Cumulative Model Updates: 14,040
Cumulative Timesteps: 117,193,530

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,628.53087
Policy Entropy: 1.21768
Value Function Loss: 0.11100

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.28842
Value Function Update Magnitude: 0.52264

Collected Steps per Second: 23,259.45474
Overall Steps per Second: 10,761.04237

Timestep Collection Time: 2.15070
Timestep Consumption Time: 2.49792
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.64862

Cumulative Model Updates: 14,046
Cumulative Timesteps: 117,243,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 117243554...
Checkpoint 117243554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,031.24554
Policy Entropy: 1.21885
Value Function Loss: 0.10529

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.31077
Value Function Update Magnitude: 0.56308

Collected Steps per Second: 23,017.93459
Overall Steps per Second: 10,776.46984

Timestep Collection Time: 2.17317
Timestep Consumption Time: 2.46860
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.64178

Cumulative Model Updates: 14,052
Cumulative Timesteps: 117,293,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,253.79438
Policy Entropy: 1.21157
Value Function Loss: 0.10837

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.13159
Policy Update Magnitude: 0.29426
Value Function Update Magnitude: 0.57915

Collected Steps per Second: 22,946.34396
Overall Steps per Second: 10,733.65318

Timestep Collection Time: 2.18022
Timestep Consumption Time: 2.48064
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.66085

Cumulative Model Updates: 14,058
Cumulative Timesteps: 117,343,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 117343604...
Checkpoint 117343604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,801.20106
Policy Entropy: 1.21066
Value Function Loss: 0.11016

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.15740
Policy Update Magnitude: 0.29857
Value Function Update Magnitude: 0.61538

Collected Steps per Second: 22,817.30364
Overall Steps per Second: 10,731.97826

Timestep Collection Time: 2.19149
Timestep Consumption Time: 2.46785
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.65935

Cumulative Model Updates: 14,064
Cumulative Timesteps: 117,393,608

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,911.34132
Policy Entropy: 1.20889
Value Function Loss: 0.10735

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13654
Policy Update Magnitude: 0.29178
Value Function Update Magnitude: 0.65599

Collected Steps per Second: 23,266.38885
Overall Steps per Second: 10,817.57108

Timestep Collection Time: 2.14945
Timestep Consumption Time: 2.47358
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.62303

Cumulative Model Updates: 14,070
Cumulative Timesteps: 117,443,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 117443618...
Checkpoint 117443618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,173.93994
Policy Entropy: 1.21012
Value Function Loss: 0.10469

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.15438
Policy Update Magnitude: 0.29860
Value Function Update Magnitude: 0.60198

Collected Steps per Second: 22,892.25441
Overall Steps per Second: 10,714.97058

Timestep Collection Time: 2.18432
Timestep Consumption Time: 2.48242
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.66674

Cumulative Model Updates: 14,076
Cumulative Timesteps: 117,493,622

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,631.73082
Policy Entropy: 1.20806
Value Function Loss: 0.10565

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.16073
Policy Update Magnitude: 0.28971
Value Function Update Magnitude: 0.48497

Collected Steps per Second: 23,384.06813
Overall Steps per Second: 10,832.09003

Timestep Collection Time: 2.13992
Timestep Consumption Time: 2.47969
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.61961

Cumulative Model Updates: 14,082
Cumulative Timesteps: 117,543,662

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 117543662...
Checkpoint 117543662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,472.85917
Policy Entropy: 1.19968
Value Function Loss: 0.10873

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.32362
Value Function Update Magnitude: 0.45474

Collected Steps per Second: 22,901.87353
Overall Steps per Second: 10,681.74427

Timestep Collection Time: 2.18384
Timestep Consumption Time: 2.49836
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.68219

Cumulative Model Updates: 14,088
Cumulative Timesteps: 117,593,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,953.14874
Policy Entropy: 1.19733
Value Function Loss: 0.11315

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.33762
Value Function Update Magnitude: 0.48056

Collected Steps per Second: 23,452.79377
Overall Steps per Second: 10,877.43741

Timestep Collection Time: 2.13297
Timestep Consumption Time: 2.46591
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.59888

Cumulative Model Updates: 14,094
Cumulative Timesteps: 117,643,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 117643700...
Checkpoint 117643700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,127.20977
Policy Entropy: 1.20203
Value Function Loss: 0.11141

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.29951
Value Function Update Magnitude: 0.50393

Collected Steps per Second: 22,741.31531
Overall Steps per Second: 10,649.04875

Timestep Collection Time: 2.19899
Timestep Consumption Time: 2.49701
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.69601

Cumulative Model Updates: 14,100
Cumulative Timesteps: 117,693,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,753.54834
Policy Entropy: 1.21304
Value Function Loss: 0.11253

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.29378
Value Function Update Magnitude: 0.48167

Collected Steps per Second: 23,268.43649
Overall Steps per Second: 10,887.84412

Timestep Collection Time: 2.14935
Timestep Consumption Time: 2.44403
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.59338

Cumulative Model Updates: 14,106
Cumulative Timesteps: 117,743,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 117743720...
Checkpoint 117743720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,575.34725
Policy Entropy: 1.21749
Value Function Loss: 0.11297

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.33436
Value Function Update Magnitude: 0.50668

Collected Steps per Second: 22,887.70719
Overall Steps per Second: 10,794.60156

Timestep Collection Time: 2.18668
Timestep Consumption Time: 2.44972
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.63639

Cumulative Model Updates: 14,112
Cumulative Timesteps: 117,793,768

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,437.00103
Policy Entropy: 1.21311
Value Function Loss: 0.11614

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07697
Policy Update Magnitude: 0.34745
Value Function Update Magnitude: 0.52136

Collected Steps per Second: 23,268.21537
Overall Steps per Second: 10,882.37093

Timestep Collection Time: 2.14885
Timestep Consumption Time: 2.44573
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.59459

Cumulative Model Updates: 14,118
Cumulative Timesteps: 117,843,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 117843768...
Checkpoint 117843768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,839.12723
Policy Entropy: 1.20207
Value Function Loss: 0.11260

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.07120
Policy Update Magnitude: 0.35009
Value Function Update Magnitude: 0.60286

Collected Steps per Second: 23,061.25533
Overall Steps per Second: 10,951.29191

Timestep Collection Time: 2.16918
Timestep Consumption Time: 2.39868
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.56786

Cumulative Model Updates: 14,124
Cumulative Timesteps: 117,893,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,871.30781
Policy Entropy: 1.20991
Value Function Loss: 0.11061

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07877
Policy Update Magnitude: 0.35327
Value Function Update Magnitude: 0.56755

Collected Steps per Second: 23,079.15758
Overall Steps per Second: 10,976.01059

Timestep Collection Time: 2.16706
Timestep Consumption Time: 2.38960
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.55666

Cumulative Model Updates: 14,130
Cumulative Timesteps: 117,943,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 117943806...
Checkpoint 117943806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,483.26349
Policy Entropy: 1.20929
Value Function Loss: 0.10639

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.34388
Value Function Update Magnitude: 0.52322

Collected Steps per Second: 23,049.60967
Overall Steps per Second: 10,644.65769

Timestep Collection Time: 2.16932
Timestep Consumption Time: 2.52806
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.69738

Cumulative Model Updates: 14,136
Cumulative Timesteps: 117,993,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,721.62425
Policy Entropy: 1.20934
Value Function Loss: 0.10482

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06791
Policy Update Magnitude: 0.33688
Value Function Update Magnitude: 0.56101

Collected Steps per Second: 23,063.22413
Overall Steps per Second: 10,906.79426

Timestep Collection Time: 2.16934
Timestep Consumption Time: 2.41789
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.58723

Cumulative Model Updates: 14,142
Cumulative Timesteps: 118,043,840

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 118043840...
Checkpoint 118043840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,726.97575
Policy Entropy: 1.19748
Value Function Loss: 0.10918

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.33700
Value Function Update Magnitude: 0.56699

Collected Steps per Second: 23,050.59431
Overall Steps per Second: 10,959.50098

Timestep Collection Time: 2.16931
Timestep Consumption Time: 2.39330
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.56262

Cumulative Model Updates: 14,148
Cumulative Timesteps: 118,093,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,821.76733
Policy Entropy: 1.18030
Value Function Loss: 0.11104

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.30113
Value Function Update Magnitude: 0.48613

Collected Steps per Second: 23,281.16247
Overall Steps per Second: 11,010.89560

Timestep Collection Time: 2.14792
Timestep Consumption Time: 2.39358
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.54150

Cumulative Model Updates: 14,154
Cumulative Timesteps: 118,143,850

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 118143850...
Checkpoint 118143850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.43458
Policy Entropy: 1.17826
Value Function Loss: 0.11227

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12897
Policy Update Magnitude: 0.28253
Value Function Update Magnitude: 0.50048

Collected Steps per Second: 22,743.57923
Overall Steps per Second: 10,713.92372

Timestep Collection Time: 2.20018
Timestep Consumption Time: 2.47038
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.67056

Cumulative Model Updates: 14,160
Cumulative Timesteps: 118,193,890

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.85099
Policy Entropy: 1.18119
Value Function Loss: 0.11324

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.14131
Policy Update Magnitude: 0.27289
Value Function Update Magnitude: 0.47167

Collected Steps per Second: 23,313.12468
Overall Steps per Second: 10,827.65363

Timestep Collection Time: 2.14583
Timestep Consumption Time: 2.47438
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.62021

Cumulative Model Updates: 14,166
Cumulative Timesteps: 118,243,916

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 118243916...
Checkpoint 118243916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,609.31011
Policy Entropy: 1.18364
Value Function Loss: 0.11030

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.30107
Value Function Update Magnitude: 0.51011

Collected Steps per Second: 22,961.49991
Overall Steps per Second: 10,777.12851

Timestep Collection Time: 2.17773
Timestep Consumption Time: 2.46209
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.63983

Cumulative Model Updates: 14,172
Cumulative Timesteps: 118,293,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,609.85924
Policy Entropy: 1.19177
Value Function Loss: 0.11357

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.15279
Policy Update Magnitude: 0.28188
Value Function Update Magnitude: 0.52360

Collected Steps per Second: 23,030.41935
Overall Steps per Second: 10,778.25552

Timestep Collection Time: 2.17174
Timestep Consumption Time: 2.46872
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.64045

Cumulative Model Updates: 14,178
Cumulative Timesteps: 118,343,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 118343936...
Checkpoint 118343936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,084.89159
Policy Entropy: 1.19937
Value Function Loss: 0.10852

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.16998
Policy Update Magnitude: 0.26231
Value Function Update Magnitude: 0.50217

Collected Steps per Second: 22,943.45289
Overall Steps per Second: 10,779.31476

Timestep Collection Time: 2.17997
Timestep Consumption Time: 2.46003
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.64000

Cumulative Model Updates: 14,184
Cumulative Timesteps: 118,393,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,235.04521
Policy Entropy: 1.21453
Value Function Loss: 0.10895

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.28293
Value Function Update Magnitude: 0.50220

Collected Steps per Second: 23,447.92068
Overall Steps per Second: 10,778.64749

Timestep Collection Time: 2.13315
Timestep Consumption Time: 2.50732
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.64047

Cumulative Model Updates: 14,190
Cumulative Timesteps: 118,443,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 118443970...
Checkpoint 118443970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,686.60206
Policy Entropy: 1.20926
Value Function Loss: 0.10932

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.14578
Policy Update Magnitude: 0.28435
Value Function Update Magnitude: 0.52063

Collected Steps per Second: 22,754.89900
Overall Steps per Second: 10,740.50843

Timestep Collection Time: 2.19891
Timestep Consumption Time: 2.45971
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.65862

Cumulative Model Updates: 14,196
Cumulative Timesteps: 118,494,006

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,645.46476
Policy Entropy: 1.19821
Value Function Loss: 0.11362

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.27473
Value Function Update Magnitude: 0.59104

Collected Steps per Second: 23,375.30921
Overall Steps per Second: 10,856.42949

Timestep Collection Time: 2.13952
Timestep Consumption Time: 2.46715
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.60667

Cumulative Model Updates: 14,202
Cumulative Timesteps: 118,544,018

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 118544018...
Checkpoint 118544018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,634.70413
Policy Entropy: 1.18686
Value Function Loss: 0.11335

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.14345
Policy Update Magnitude: 0.25898
Value Function Update Magnitude: 0.57829

Collected Steps per Second: 22,877.36269
Overall Steps per Second: 10,938.56367

Timestep Collection Time: 2.18592
Timestep Consumption Time: 2.38580
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.57172

Cumulative Model Updates: 14,208
Cumulative Timesteps: 118,594,026

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,584.96889
Policy Entropy: 1.18744
Value Function Loss: 0.11579

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.23500
Value Function Update Magnitude: 0.53822

Collected Steps per Second: 22,638.38992
Overall Steps per Second: 10,698.85816

Timestep Collection Time: 2.20934
Timestep Consumption Time: 2.46555
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.67489

Cumulative Model Updates: 14,214
Cumulative Timesteps: 118,644,042

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 118644042...
Checkpoint 118644042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,176.06707
Policy Entropy: 1.18856
Value Function Loss: 0.11082

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.23579
Value Function Update Magnitude: 0.57105

Collected Steps per Second: 23,187.61932
Overall Steps per Second: 10,995.23401

Timestep Collection Time: 2.15675
Timestep Consumption Time: 2.39158
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.54833

Cumulative Model Updates: 14,220
Cumulative Timesteps: 118,694,052

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,090.96018
Policy Entropy: 1.17994
Value Function Loss: 0.11046

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11451
Policy Update Magnitude: 0.26112
Value Function Update Magnitude: 0.61437

Collected Steps per Second: 23,416.94275
Overall Steps per Second: 10,842.53998

Timestep Collection Time: 2.13580
Timestep Consumption Time: 2.47695
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.61276

Cumulative Model Updates: 14,226
Cumulative Timesteps: 118,744,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 118744066...
Checkpoint 118744066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,303.03157
Policy Entropy: 1.19367
Value Function Loss: 0.10672

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.29885
Value Function Update Magnitude: 0.65360

Collected Steps per Second: 22,052.18464
Overall Steps per Second: 10,642.73973

Timestep Collection Time: 2.26817
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.69973

Cumulative Model Updates: 14,232
Cumulative Timesteps: 118,794,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,581.34468
Policy Entropy: 1.18045
Value Function Loss: 0.11163

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07416
Policy Update Magnitude: 0.31906
Value Function Update Magnitude: 0.66217

Collected Steps per Second: 23,381.59181
Overall Steps per Second: 10,939.51523

Timestep Collection Time: 2.13938
Timestep Consumption Time: 2.43322
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.57260

Cumulative Model Updates: 14,238
Cumulative Timesteps: 118,844,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 118844106...
Checkpoint 118844106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,290.29370
Policy Entropy: 1.18112
Value Function Loss: 0.11315

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06956
Policy Update Magnitude: 0.33106
Value Function Update Magnitude: 0.61117

Collected Steps per Second: 22,868.76547
Overall Steps per Second: 10,760.18375

Timestep Collection Time: 2.18726
Timestep Consumption Time: 2.46136
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.64862

Cumulative Model Updates: 14,244
Cumulative Timesteps: 118,894,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,602.57764
Policy Entropy: 1.17279
Value Function Loss: 0.11313

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06806
Policy Update Magnitude: 0.34950
Value Function Update Magnitude: 0.64712

Collected Steps per Second: 23,156.48591
Overall Steps per Second: 10,763.54543

Timestep Collection Time: 2.16052
Timestep Consumption Time: 2.48758
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.64810

Cumulative Model Updates: 14,250
Cumulative Timesteps: 118,944,156

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 118944156...
Checkpoint 118944156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,287.13708
Policy Entropy: 1.17699
Value Function Loss: 0.11027

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.34098
Value Function Update Magnitude: 0.71416

Collected Steps per Second: 22,486.01829
Overall Steps per Second: 10,642.37004

Timestep Collection Time: 2.22423
Timestep Consumption Time: 2.47529
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.69952

Cumulative Model Updates: 14,256
Cumulative Timesteps: 118,994,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,858.10379
Policy Entropy: 1.18010
Value Function Loss: 0.10515

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.31951
Value Function Update Magnitude: 0.71784

Collected Steps per Second: 23,353.05372
Overall Steps per Second: 10,961.17785

Timestep Collection Time: 2.14122
Timestep Consumption Time: 2.42070
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.56192

Cumulative Model Updates: 14,262
Cumulative Timesteps: 119,044,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 119044174...
Checkpoint 119044174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,511.23428
Policy Entropy: 1.17951
Value Function Loss: 0.10898

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11326
Policy Update Magnitude: 0.29703
Value Function Update Magnitude: 0.65593

Collected Steps per Second: 22,813.18229
Overall Steps per Second: 10,658.68319

Timestep Collection Time: 2.19303
Timestep Consumption Time: 2.50080
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.69383

Cumulative Model Updates: 14,268
Cumulative Timesteps: 119,094,204

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,360.80038
Policy Entropy: 1.17766
Value Function Loss: 0.11371

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.15862
Policy Update Magnitude: 0.27855
Value Function Update Magnitude: 0.56710

Collected Steps per Second: 23,368.95543
Overall Steps per Second: 10,872.17011

Timestep Collection Time: 2.14070
Timestep Consumption Time: 2.46059
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.60129

Cumulative Model Updates: 14,274
Cumulative Timesteps: 119,144,230

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 119144230...
Checkpoint 119144230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,342.77564
Policy Entropy: 1.17105
Value Function Loss: 0.11754

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.27183
Value Function Update Magnitude: 0.54549

Collected Steps per Second: 23,078.92822
Overall Steps per Second: 10,818.94779

Timestep Collection Time: 2.16674
Timestep Consumption Time: 2.45534
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.62208

Cumulative Model Updates: 14,280
Cumulative Timesteps: 119,194,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,846.15533
Policy Entropy: 1.16971
Value Function Loss: 0.11360

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.15686
Policy Update Magnitude: 0.26195
Value Function Update Magnitude: 0.53131

Collected Steps per Second: 23,137.76654
Overall Steps per Second: 10,851.15842

Timestep Collection Time: 2.16261
Timestep Consumption Time: 2.44869
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.61130

Cumulative Model Updates: 14,286
Cumulative Timesteps: 119,244,274

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 119244274...
Checkpoint 119244274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,192.63220
Policy Entropy: 1.17008
Value Function Loss: 0.11054

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.26695
Value Function Update Magnitude: 0.54840

Collected Steps per Second: 23,048.86097
Overall Steps per Second: 10,214.63811

Timestep Collection Time: 2.16991
Timestep Consumption Time: 2.72639
PPO Batch Consumption Time: 0.33053
Total Iteration Time: 4.89631

Cumulative Model Updates: 14,292
Cumulative Timesteps: 119,294,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,220.82154
Policy Entropy: 1.17622
Value Function Loss: 0.10747

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09147
Policy Update Magnitude: 0.29821
Value Function Update Magnitude: 0.54336

Collected Steps per Second: 14,550.21349
Overall Steps per Second: 7,444.30888

Timestep Collection Time: 3.43789
Timestep Consumption Time: 3.28161
PPO Batch Consumption Time: 0.36758
Total Iteration Time: 6.71950

Cumulative Model Updates: 14,298
Cumulative Timesteps: 119,344,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 119344310...
Checkpoint 119344310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,462.50037
Policy Entropy: 1.17585
Value Function Loss: 0.11077

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.31470
Value Function Update Magnitude: 0.52773

Collected Steps per Second: 19,928.63863
Overall Steps per Second: 9,988.27814

Timestep Collection Time: 2.51066
Timestep Consumption Time: 2.49861
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 5.00927

Cumulative Model Updates: 14,304
Cumulative Timesteps: 119,394,344

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,410.92929
Policy Entropy: 1.16842
Value Function Loss: 0.11373

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09104
Policy Update Magnitude: 0.31093
Value Function Update Magnitude: 0.55225

Collected Steps per Second: 22,084.18868
Overall Steps per Second: 10,479.38536

Timestep Collection Time: 2.26443
Timestep Consumption Time: 2.50761
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.77204

Cumulative Model Updates: 14,310
Cumulative Timesteps: 119,444,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 119444352...
Checkpoint 119444352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,258.27356
Policy Entropy: 1.16712
Value Function Loss: 0.11403

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.30960
Value Function Update Magnitude: 0.61028

Collected Steps per Second: 21,004.85644
Overall Steps per Second: 10,274.22314

Timestep Collection Time: 2.38164
Timestep Consumption Time: 2.48744
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.86908

Cumulative Model Updates: 14,316
Cumulative Timesteps: 119,494,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,114.07324
Policy Entropy: 1.16663
Value Function Loss: 0.11057

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.28372
Value Function Update Magnitude: 0.65082

Collected Steps per Second: 16,832.08675
Overall Steps per Second: 9,251.03233

Timestep Collection Time: 2.97218
Timestep Consumption Time: 2.43565
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 5.40783

Cumulative Model Updates: 14,322
Cumulative Timesteps: 119,544,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 119544406...
Checkpoint 119544406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,438.17961
Policy Entropy: 1.17011
Value Function Loss: 0.11272

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.30561
Value Function Update Magnitude: 0.68825

Collected Steps per Second: 18,422.22541
Overall Steps per Second: 9,079.00881

Timestep Collection Time: 2.71509
Timestep Consumption Time: 2.79410
PPO Batch Consumption Time: 0.33958
Total Iteration Time: 5.50919

Cumulative Model Updates: 14,328
Cumulative Timesteps: 119,594,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,326.56690
Policy Entropy: 1.18969
Value Function Loss: 0.11106

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.14473
Policy Update Magnitude: 0.28955
Value Function Update Magnitude: 0.67968

Collected Steps per Second: 20,016.98357
Overall Steps per Second: 9,852.88453

Timestep Collection Time: 2.49818
Timestep Consumption Time: 2.57709
PPO Batch Consumption Time: 0.30097
Total Iteration Time: 5.07526

Cumulative Model Updates: 14,334
Cumulative Timesteps: 119,644,430

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 119644430...
Checkpoint 119644430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,091.28831
Policy Entropy: 1.18472
Value Function Loss: 0.11092

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.26172
Value Function Update Magnitude: 0.68439

Collected Steps per Second: 19,450.03301
Overall Steps per Second: 9,560.63584

Timestep Collection Time: 2.57172
Timestep Consumption Time: 2.66015
PPO Batch Consumption Time: 0.31424
Total Iteration Time: 5.23187

Cumulative Model Updates: 14,340
Cumulative Timesteps: 119,694,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,253.75258
Policy Entropy: 1.18989
Value Function Loss: 0.10737

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.26506
Value Function Update Magnitude: 0.68591

Collected Steps per Second: 20,524.86694
Overall Steps per Second: 10,266.01943

Timestep Collection Time: 2.43656
Timestep Consumption Time: 2.43485
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.87141

Cumulative Model Updates: 14,346
Cumulative Timesteps: 119,744,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 119744460...
Checkpoint 119744460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,697.03360
Policy Entropy: 1.19114
Value Function Loss: 0.10540

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.28795
Value Function Update Magnitude: 0.66035

Collected Steps per Second: 21,985.81816
Overall Steps per Second: 10,396.70462

Timestep Collection Time: 2.27556
Timestep Consumption Time: 2.53654
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.81210

Cumulative Model Updates: 14,352
Cumulative Timesteps: 119,794,490

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,415.83882
Policy Entropy: 1.19131
Value Function Loss: 0.11187

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11618
Policy Update Magnitude: 0.28049
Value Function Update Magnitude: 0.59488

Collected Steps per Second: 20,581.18458
Overall Steps per Second: 10,061.11991

Timestep Collection Time: 2.43067
Timestep Consumption Time: 2.54154
PPO Batch Consumption Time: 0.30352
Total Iteration Time: 4.97221

Cumulative Model Updates: 14,358
Cumulative Timesteps: 119,844,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 119844516...
Checkpoint 119844516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,548.68715
Policy Entropy: 1.19695
Value Function Loss: 0.11365

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.29267
Value Function Update Magnitude: 0.55761

Collected Steps per Second: 19,928.71822
Overall Steps per Second: 10,085.40033

Timestep Collection Time: 2.51035
Timestep Consumption Time: 2.45009
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.96044

Cumulative Model Updates: 14,364
Cumulative Timesteps: 119,894,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,555.51448
Policy Entropy: 1.19349
Value Function Loss: 0.11771

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.13902
Policy Update Magnitude: 0.27940
Value Function Update Magnitude: 0.58659

Collected Steps per Second: 19,665.24724
Overall Steps per Second: 9,574.49387

Timestep Collection Time: 2.54306
Timestep Consumption Time: 2.68019
PPO Batch Consumption Time: 0.31402
Total Iteration Time: 5.22325

Cumulative Model Updates: 14,370
Cumulative Timesteps: 119,944,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 119944554...
Checkpoint 119944554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,014.61459
Policy Entropy: 1.17986
Value Function Loss: 0.11544

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.30275
Value Function Update Magnitude: 0.57630

Collected Steps per Second: 19,796.65067
Overall Steps per Second: 9,734.13301

Timestep Collection Time: 2.52618
Timestep Consumption Time: 2.61141
PPO Batch Consumption Time: 0.30208
Total Iteration Time: 5.13759

Cumulative Model Updates: 14,376
Cumulative Timesteps: 119,994,564

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,583.39967
Policy Entropy: 1.17294
Value Function Loss: 0.10687

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.30663
Value Function Update Magnitude: 0.66918

Collected Steps per Second: 19,994.51526
Overall Steps per Second: 10,058.08860

Timestep Collection Time: 2.50149
Timestep Consumption Time: 2.47123
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.97271

Cumulative Model Updates: 14,382
Cumulative Timesteps: 120,044,580

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 120044580...
Checkpoint 120044580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,936.34042
Policy Entropy: 1.17954
Value Function Loss: 0.10091

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.15192
Policy Update Magnitude: 0.27130
Value Function Update Magnitude: 0.70329

Collected Steps per Second: 21,555.79821
Overall Steps per Second: 10,385.92793

Timestep Collection Time: 2.31965
Timestep Consumption Time: 2.49474
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.81440

Cumulative Model Updates: 14,388
Cumulative Timesteps: 120,094,582

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,391.64633
Policy Entropy: 1.19152
Value Function Loss: 0.10175

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.14426
Policy Update Magnitude: 0.25218
Value Function Update Magnitude: 0.67005

Collected Steps per Second: 17,679.68748
Overall Steps per Second: 8,560.29460

Timestep Collection Time: 2.83003
Timestep Consumption Time: 3.01486
PPO Batch Consumption Time: 0.31532
Total Iteration Time: 5.84489

Cumulative Model Updates: 14,394
Cumulative Timesteps: 120,144,616

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 120144616...
Checkpoint 120144616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,107.26685
Policy Entropy: 1.18724
Value Function Loss: 0.10812

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.25339
Value Function Update Magnitude: 0.62167

Collected Steps per Second: 15,213.53818
Overall Steps per Second: 6,756.24572

Timestep Collection Time: 3.28812
Timestep Consumption Time: 4.11599
PPO Batch Consumption Time: 0.55090
Total Iteration Time: 7.40411

Cumulative Model Updates: 14,400
Cumulative Timesteps: 120,194,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,650.59296
Policy Entropy: 1.19219
Value Function Loss: 0.10402

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.29643
Value Function Update Magnitude: 0.62401

Collected Steps per Second: 15,495.49907
Overall Steps per Second: 6,949.85626

Timestep Collection Time: 3.22778
Timestep Consumption Time: 3.96892
PPO Batch Consumption Time: 0.53603
Total Iteration Time: 7.19670

Cumulative Model Updates: 14,406
Cumulative Timesteps: 120,244,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 120244656...
Checkpoint 120244656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,262.73656
Policy Entropy: 1.18574
Value Function Loss: 0.10653

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.29433
Value Function Update Magnitude: 0.62764

Collected Steps per Second: 15,692.70746
Overall Steps per Second: 7,168.23778

Timestep Collection Time: 3.18849
Timestep Consumption Time: 3.79175
PPO Batch Consumption Time: 0.50588
Total Iteration Time: 6.98024

Cumulative Model Updates: 14,412
Cumulative Timesteps: 120,294,692

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,567.16342
Policy Entropy: 1.18321
Value Function Loss: 0.10274

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.30226
Value Function Update Magnitude: 0.68083

Collected Steps per Second: 15,159.83738
Overall Steps per Second: 7,046.73591

Timestep Collection Time: 3.30004
Timestep Consumption Time: 3.79942
PPO Batch Consumption Time: 0.50192
Total Iteration Time: 7.09946

Cumulative Model Updates: 14,418
Cumulative Timesteps: 120,344,720

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 120344720...
Checkpoint 120344720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,600.89414
Policy Entropy: 1.18773
Value Function Loss: 0.10034

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.33014
Value Function Update Magnitude: 0.68995

Collected Steps per Second: 14,926.22672
Overall Steps per Second: 7,015.89559

Timestep Collection Time: 3.35021
Timestep Consumption Time: 3.77732
PPO Batch Consumption Time: 0.50015
Total Iteration Time: 7.12753

Cumulative Model Updates: 14,424
Cumulative Timesteps: 120,394,726

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,989.06164
Policy Entropy: 1.20589
Value Function Loss: 0.10271

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.30770
Value Function Update Magnitude: 0.63562

Collected Steps per Second: 15,012.79961
Overall Steps per Second: 7,065.00133

Timestep Collection Time: 3.33049
Timestep Consumption Time: 3.74665
PPO Batch Consumption Time: 0.49984
Total Iteration Time: 7.07714

Cumulative Model Updates: 14,430
Cumulative Timesteps: 120,444,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 120444726...
Checkpoint 120444726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,033.23497
Policy Entropy: 1.20809
Value Function Loss: 0.10632

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13881
Policy Update Magnitude: 0.26356
Value Function Update Magnitude: 0.64298

Collected Steps per Second: 15,462.41419
Overall Steps per Second: 7,424.77605

Timestep Collection Time: 3.23507
Timestep Consumption Time: 3.50210
PPO Batch Consumption Time: 0.46050
Total Iteration Time: 6.73717

Cumulative Model Updates: 14,436
Cumulative Timesteps: 120,494,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,842.29310
Policy Entropy: 1.20920
Value Function Loss: 0.11058

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.29719
Value Function Update Magnitude: 0.66783

Collected Steps per Second: 16,125.19694
Overall Steps per Second: 7,447.66090

Timestep Collection Time: 3.10148
Timestep Consumption Time: 3.61365
PPO Batch Consumption Time: 0.48001
Total Iteration Time: 6.71513

Cumulative Model Updates: 14,442
Cumulative Timesteps: 120,544,760

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 120544760...
Checkpoint 120544760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,203.08140
Policy Entropy: 1.20946
Value Function Loss: 0.11238

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08294
Policy Update Magnitude: 0.34606
Value Function Update Magnitude: 0.60309

Collected Steps per Second: 15,766.34517
Overall Steps per Second: 7,519.18386

Timestep Collection Time: 3.17271
Timestep Consumption Time: 3.47988
PPO Batch Consumption Time: 0.45512
Total Iteration Time: 6.65258

Cumulative Model Updates: 14,448
Cumulative Timesteps: 120,594,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,066.87512
Policy Entropy: 1.21668
Value Function Loss: 0.10610

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.34393
Value Function Update Magnitude: 0.59031

Collected Steps per Second: 16,272.44265
Overall Steps per Second: 7,625.78887

Timestep Collection Time: 3.07538
Timestep Consumption Time: 3.48709
PPO Batch Consumption Time: 0.45009
Total Iteration Time: 6.56247

Cumulative Model Updates: 14,454
Cumulative Timesteps: 120,644,826

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 120644826...
Checkpoint 120644826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,981.36673
Policy Entropy: 1.22570
Value Function Loss: 0.10203

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.11057
Policy Update Magnitude: 0.31836
Value Function Update Magnitude: 0.60728

Collected Steps per Second: 15,628.33052
Overall Steps per Second: 7,571.45068

Timestep Collection Time: 3.19957
Timestep Consumption Time: 3.40471
PPO Batch Consumption Time: 0.44048
Total Iteration Time: 6.60428

Cumulative Model Updates: 14,460
Cumulative Timesteps: 120,694,830

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,086.83176
Policy Entropy: 1.22315
Value Function Loss: 0.10273

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.30833
Value Function Update Magnitude: 0.59786

Collected Steps per Second: 16,141.71028
Overall Steps per Second: 7,703.38353

Timestep Collection Time: 3.09769
Timestep Consumption Time: 3.39322
PPO Batch Consumption Time: 0.44190
Total Iteration Time: 6.49091

Cumulative Model Updates: 14,466
Cumulative Timesteps: 120,744,832

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 120744832...
Checkpoint 120744832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.42168
Policy Entropy: 1.22099
Value Function Loss: 0.11500

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.30507
Value Function Update Magnitude: 0.52161

Collected Steps per Second: 15,999.57155
Overall Steps per Second: 7,700.08358

Timestep Collection Time: 3.12571
Timestep Consumption Time: 3.36903
PPO Batch Consumption Time: 0.43788
Total Iteration Time: 6.49473

Cumulative Model Updates: 14,472
Cumulative Timesteps: 120,794,842

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.59125
Policy Entropy: 1.21236
Value Function Loss: 0.11974

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.31471
Value Function Update Magnitude: 0.49365

Collected Steps per Second: 16,009.42668
Overall Steps per Second: 7,667.38474

Timestep Collection Time: 3.12441
Timestep Consumption Time: 3.39933
PPO Batch Consumption Time: 0.44590
Total Iteration Time: 6.52374

Cumulative Model Updates: 14,478
Cumulative Timesteps: 120,844,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 120844862...
Checkpoint 120844862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,672.00895
Policy Entropy: 1.22170
Value Function Loss: 0.11881

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11752
Policy Update Magnitude: 0.34871
Value Function Update Magnitude: 0.45015

Collected Steps per Second: 15,769.36221
Overall Steps per Second: 7,583.43594

Timestep Collection Time: 3.17350
Timestep Consumption Time: 3.42562
PPO Batch Consumption Time: 0.44642
Total Iteration Time: 6.59912

Cumulative Model Updates: 14,484
Cumulative Timesteps: 120,894,906

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,459.09475
Policy Entropy: 1.21527
Value Function Loss: 0.11668

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.11137
Policy Update Magnitude: 0.35121
Value Function Update Magnitude: 0.44662

Collected Steps per Second: 16,141.31598
Overall Steps per Second: 7,470.15928

Timestep Collection Time: 3.09838
Timestep Consumption Time: 3.59652
PPO Batch Consumption Time: 0.47522
Total Iteration Time: 6.69490

Cumulative Model Updates: 14,490
Cumulative Timesteps: 120,944,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 120944918...
Checkpoint 120944918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,723.35245
Policy Entropy: 1.22118
Value Function Loss: 0.11619

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.32523
Value Function Update Magnitude: 0.47107

Collected Steps per Second: 15,557.98312
Overall Steps per Second: 7,255.14372

Timestep Collection Time: 3.21584
Timestep Consumption Time: 3.68023
PPO Batch Consumption Time: 0.49173
Total Iteration Time: 6.89607

Cumulative Model Updates: 14,496
Cumulative Timesteps: 120,994,950

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,029.28194
Policy Entropy: 1.21479
Value Function Loss: 0.11887

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.14947
Policy Update Magnitude: 0.26904
Value Function Update Magnitude: 0.52529

Collected Steps per Second: 15,710.62192
Overall Steps per Second: 7,549.48505

Timestep Collection Time: 3.18269
Timestep Consumption Time: 3.44055
PPO Batch Consumption Time: 0.44595
Total Iteration Time: 6.62323

Cumulative Model Updates: 14,502
Cumulative Timesteps: 121,044,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 121044952...
Checkpoint 121044952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,913.16658
Policy Entropy: 1.22327
Value Function Loss: 0.11749

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.25491
Value Function Update Magnitude: 0.55138

Collected Steps per Second: 15,661.50326
Overall Steps per Second: 7,652.08601

Timestep Collection Time: 3.19586
Timestep Consumption Time: 3.34510
PPO Batch Consumption Time: 0.43386
Total Iteration Time: 6.54096

Cumulative Model Updates: 14,508
Cumulative Timesteps: 121,095,004

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,749.86711
Policy Entropy: 1.23673
Value Function Loss: 0.11393

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.17461
Policy Update Magnitude: 0.24369
Value Function Update Magnitude: 0.53648

Collected Steps per Second: 15,859.19124
Overall Steps per Second: 7,564.29503

Timestep Collection Time: 3.15287
Timestep Consumption Time: 3.45739
PPO Batch Consumption Time: 0.45242
Total Iteration Time: 6.61027

Cumulative Model Updates: 14,514
Cumulative Timesteps: 121,145,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 121145006...
Checkpoint 121145006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819.23193
Policy Entropy: 1.24222
Value Function Loss: 0.11010

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.27528
Value Function Update Magnitude: 0.49366

Collected Steps per Second: 15,112.61408
Overall Steps per Second: 7,505.55039

Timestep Collection Time: 3.30995
Timestep Consumption Time: 3.35472
PPO Batch Consumption Time: 0.43414
Total Iteration Time: 6.66467

Cumulative Model Updates: 14,520
Cumulative Timesteps: 121,195,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,662.71209
Policy Entropy: 1.24697
Value Function Loss: 0.10438

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.31668
Value Function Update Magnitude: 0.46464

Collected Steps per Second: 15,784.22061
Overall Steps per Second: 7,556.64334

Timestep Collection Time: 3.16987
Timestep Consumption Time: 3.45132
PPO Batch Consumption Time: 0.44243
Total Iteration Time: 6.62119

Cumulative Model Updates: 14,526
Cumulative Timesteps: 121,245,062

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 121245062...
Checkpoint 121245062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,504.26996
Policy Entropy: 1.24262
Value Function Loss: 0.10583

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.31770
Value Function Update Magnitude: 0.48435

Collected Steps per Second: 15,960.33759
Overall Steps per Second: 7,701.42468

Timestep Collection Time: 3.13377
Timestep Consumption Time: 3.36061
PPO Batch Consumption Time: 0.43839
Total Iteration Time: 6.49438

Cumulative Model Updates: 14,532
Cumulative Timesteps: 121,295,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,016.57319
Policy Entropy: 1.24541
Value Function Loss: 0.10611

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08927
Policy Update Magnitude: 0.32016
Value Function Update Magnitude: 0.49138

Collected Steps per Second: 16,202.88864
Overall Steps per Second: 7,351.98942

Timestep Collection Time: 3.08797
Timestep Consumption Time: 3.71754
PPO Batch Consumption Time: 0.49186
Total Iteration Time: 6.80550

Cumulative Model Updates: 14,538
Cumulative Timesteps: 121,345,112

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 121345112...
Checkpoint 121345112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,530.33917
Policy Entropy: 1.22919
Value Function Loss: 0.10857

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11256
Policy Update Magnitude: 0.30175
Value Function Update Magnitude: 0.48553

Collected Steps per Second: 15,500.98684
Overall Steps per Second: 7,121.10270

Timestep Collection Time: 3.22728
Timestep Consumption Time: 3.79776
PPO Batch Consumption Time: 0.50272
Total Iteration Time: 7.02504

Cumulative Model Updates: 14,544
Cumulative Timesteps: 121,395,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,380.76459
Policy Entropy: 1.22835
Value Function Loss: 0.10653

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11934
Policy Update Magnitude: 0.28712
Value Function Update Magnitude: 0.49213

Collected Steps per Second: 15,257.46181
Overall Steps per Second: 7,338.43505

Timestep Collection Time: 3.27748
Timestep Consumption Time: 3.53678
PPO Batch Consumption Time: 0.46028
Total Iteration Time: 6.81426

Cumulative Model Updates: 14,550
Cumulative Timesteps: 121,445,144

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 121445144...
Checkpoint 121445144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,552.44527
Policy Entropy: 1.23404
Value Function Loss: 0.10594

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.28322
Value Function Update Magnitude: 0.49670

Collected Steps per Second: 15,157.38054
Overall Steps per Second: 7,060.24772

Timestep Collection Time: 3.30031
Timestep Consumption Time: 3.78500
PPO Batch Consumption Time: 0.50711
Total Iteration Time: 7.08530

Cumulative Model Updates: 14,556
Cumulative Timesteps: 121,495,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.50968
Policy Entropy: 1.22698
Value Function Loss: 0.10532

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.14868
Policy Update Magnitude: 0.28464
Value Function Update Magnitude: 0.49776

Collected Steps per Second: 14,753.23938
Overall Steps per Second: 8,354.49722

Timestep Collection Time: 3.38909
Timestep Consumption Time: 2.59571
PPO Batch Consumption Time: 0.31226
Total Iteration Time: 5.98480

Cumulative Model Updates: 14,562
Cumulative Timesteps: 121,545,168

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 121545168...
Checkpoint 121545168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,073.74453
Policy Entropy: 1.23306
Value Function Loss: 0.10651

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12318
Policy Update Magnitude: 0.31960
Value Function Update Magnitude: 0.48861

Collected Steps per Second: 18,055.09729
Overall Steps per Second: 9,156.17357

Timestep Collection Time: 2.76952
Timestep Consumption Time: 2.69171
PPO Batch Consumption Time: 0.31126
Total Iteration Time: 5.46123

Cumulative Model Updates: 14,568
Cumulative Timesteps: 121,595,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,765.49863
Policy Entropy: 1.23960
Value Function Loss: 0.11244

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11399
Policy Update Magnitude: 0.32369
Value Function Update Magnitude: 0.46292

Collected Steps per Second: 18,304.98048
Overall Steps per Second: 9,075.44791

Timestep Collection Time: 2.73215
Timestep Consumption Time: 2.77854
PPO Batch Consumption Time: 0.32885
Total Iteration Time: 5.51069

Cumulative Model Updates: 14,574
Cumulative Timesteps: 121,645,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 121645184...
Checkpoint 121645184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,905.36155
Policy Entropy: 1.25546
Value Function Loss: 0.11249

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.33888
Value Function Update Magnitude: 0.44874

Collected Steps per Second: 19,452.83374
Overall Steps per Second: 9,776.87216

Timestep Collection Time: 2.57186
Timestep Consumption Time: 2.54532
PPO Batch Consumption Time: 0.29956
Total Iteration Time: 5.11718

Cumulative Model Updates: 14,580
Cumulative Timesteps: 121,695,214

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,419.97638
Policy Entropy: 1.24943
Value Function Loss: 0.11103

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10236
Policy Update Magnitude: 0.34477
Value Function Update Magnitude: 0.45699

Collected Steps per Second: 20,757.59325
Overall Steps per Second: 9,719.15367

Timestep Collection Time: 2.41088
Timestep Consumption Time: 2.73813
PPO Batch Consumption Time: 0.33397
Total Iteration Time: 5.14901

Cumulative Model Updates: 14,586
Cumulative Timesteps: 121,745,258

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 121745258...
Checkpoint 121745258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030.17208
Policy Entropy: 1.25099
Value Function Loss: 0.11040

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10704
Policy Update Magnitude: 0.33434
Value Function Update Magnitude: 0.48499

Collected Steps per Second: 19,776.22139
Overall Steps per Second: 9,792.34995

Timestep Collection Time: 2.52910
Timestep Consumption Time: 2.57856
PPO Batch Consumption Time: 0.30064
Total Iteration Time: 5.10766

Cumulative Model Updates: 14,592
Cumulative Timesteps: 121,795,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,222.35229
Policy Entropy: 1.25449
Value Function Loss: 0.10591

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.30574
Value Function Update Magnitude: 0.52810

Collected Steps per Second: 20,559.04442
Overall Steps per Second: 10,082.77689

Timestep Collection Time: 2.43328
Timestep Consumption Time: 2.52825
PPO Batch Consumption Time: 0.29872
Total Iteration Time: 4.96153

Cumulative Model Updates: 14,598
Cumulative Timesteps: 121,845,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 121845300...
Checkpoint 121845300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,823.31982
Policy Entropy: 1.26529
Value Function Loss: 0.10580

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.15753
Policy Update Magnitude: 0.29283
Value Function Update Magnitude: 0.57713

Collected Steps per Second: 20,448.12001
Overall Steps per Second: 10,008.70598

Timestep Collection Time: 2.44560
Timestep Consumption Time: 2.55085
PPO Batch Consumption Time: 0.30211
Total Iteration Time: 4.99645

Cumulative Model Updates: 14,604
Cumulative Timesteps: 121,895,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.66347
Policy Entropy: 1.26542
Value Function Loss: 0.10437

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.12988
Policy Update Magnitude: 0.31077
Value Function Update Magnitude: 0.59737

Collected Steps per Second: 19,342.40391
Overall Steps per Second: 9,650.71622

Timestep Collection Time: 2.58520
Timestep Consumption Time: 2.59618
PPO Batch Consumption Time: 0.30322
Total Iteration Time: 5.18138

Cumulative Model Updates: 14,610
Cumulative Timesteps: 121,945,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 121945312...
Checkpoint 121945312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,811.03616
Policy Entropy: 1.27236
Value Function Loss: 0.10401

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.32519
Value Function Update Magnitude: 0.60397

Collected Steps per Second: 21,080.80331
Overall Steps per Second: 10,310.89564

Timestep Collection Time: 2.37296
Timestep Consumption Time: 2.47860
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.85157

Cumulative Model Updates: 14,616
Cumulative Timesteps: 121,995,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,089.19262
Policy Entropy: 1.26333
Value Function Loss: 0.10322

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12434
Policy Update Magnitude: 0.30628
Value Function Update Magnitude: 0.60279

Collected Steps per Second: 19,886.82304
Overall Steps per Second: 10,020.50952

Timestep Collection Time: 2.51564
Timestep Consumption Time: 2.47692
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.99256

Cumulative Model Updates: 14,622
Cumulative Timesteps: 122,045,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 122045364...
Checkpoint 122045364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,219.20742
Policy Entropy: 1.27035
Value Function Loss: 0.10129

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.30418
Value Function Update Magnitude: 0.61348

Collected Steps per Second: 17,538.69897
Overall Steps per Second: 9,168.39809

Timestep Collection Time: 2.85118
Timestep Consumption Time: 2.60299
PPO Batch Consumption Time: 0.30675
Total Iteration Time: 5.45417

Cumulative Model Updates: 14,628
Cumulative Timesteps: 122,095,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,287.96654
Policy Entropy: 1.26445
Value Function Loss: 0.09899

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.29758
Value Function Update Magnitude: 0.60110

Collected Steps per Second: 19,271.83946
Overall Steps per Second: 9,418.86850

Timestep Collection Time: 2.59560
Timestep Consumption Time: 2.71523
PPO Batch Consumption Time: 0.31619
Total Iteration Time: 5.31083

Cumulative Model Updates: 14,634
Cumulative Timesteps: 122,145,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 122145392...
Checkpoint 122145392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,187.54742
Policy Entropy: 1.26098
Value Function Loss: 0.10025

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11345
Policy Update Magnitude: 0.28834
Value Function Update Magnitude: 0.56476

Collected Steps per Second: 21,040.35917
Overall Steps per Second: 10,273.59160

Timestep Collection Time: 2.37658
Timestep Consumption Time: 2.49066
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.86724

Cumulative Model Updates: 14,640
Cumulative Timesteps: 122,195,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,609.76162
Policy Entropy: 1.25202
Value Function Loss: 0.10708

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.29045
Value Function Update Magnitude: 0.51044

Collected Steps per Second: 21,613.82071
Overall Steps per Second: 10,082.05654

Timestep Collection Time: 2.31352
Timestep Consumption Time: 2.64618
PPO Batch Consumption Time: 0.31379
Total Iteration Time: 4.95970

Cumulative Model Updates: 14,646
Cumulative Timesteps: 122,245,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 122245400...
Checkpoint 122245400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,051.35208
Policy Entropy: 1.24220
Value Function Loss: 0.11246

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.32248
Value Function Update Magnitude: 0.50532

Collected Steps per Second: 20,801.14947
Overall Steps per Second: 9,963.17168

Timestep Collection Time: 2.40487
Timestep Consumption Time: 2.61602
PPO Batch Consumption Time: 0.30326
Total Iteration Time: 5.02089

Cumulative Model Updates: 14,652
Cumulative Timesteps: 122,295,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,737.64593
Policy Entropy: 1.24253
Value Function Loss: 0.11121

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08603
Policy Update Magnitude: 0.35280
Value Function Update Magnitude: 0.53074

Collected Steps per Second: 21,530.32680
Overall Steps per Second: 10,288.57247

Timestep Collection Time: 2.32314
Timestep Consumption Time: 2.53837
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.86151

Cumulative Model Updates: 14,658
Cumulative Timesteps: 122,345,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 122345442...
Checkpoint 122345442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,300.11385
Policy Entropy: 1.22767
Value Function Loss: 0.10842

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.32966
Value Function Update Magnitude: 0.50960

Collected Steps per Second: 20,344.74201
Overall Steps per Second: 9,807.92365

Timestep Collection Time: 2.45842
Timestep Consumption Time: 2.64113
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 5.09955

Cumulative Model Updates: 14,664
Cumulative Timesteps: 122,395,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,133.64830
Policy Entropy: 1.22928
Value Function Loss: 0.11003

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.11108
Policy Update Magnitude: 0.30452
Value Function Update Magnitude: 0.46389

Collected Steps per Second: 22,280.52401
Overall Steps per Second: 10,623.44469

Timestep Collection Time: 2.24510
Timestep Consumption Time: 2.46354
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.70864

Cumulative Model Updates: 14,670
Cumulative Timesteps: 122,445,480

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 122445480...
Checkpoint 122445480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,605.05348
Policy Entropy: 1.22551
Value Function Loss: 0.10814

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.14584
Policy Update Magnitude: 0.27782
Value Function Update Magnitude: 0.51608

Collected Steps per Second: 22,176.18335
Overall Steps per Second: 10,626.31255

Timestep Collection Time: 2.25476
Timestep Consumption Time: 2.45073
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.70549

Cumulative Model Updates: 14,676
Cumulative Timesteps: 122,495,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,092.64203
Policy Entropy: 1.23464
Value Function Loss: 0.10799

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.14360
Policy Update Magnitude: 0.30740
Value Function Update Magnitude: 0.51499

Collected Steps per Second: 20,761.40737
Overall Steps per Second: 10,150.39140

Timestep Collection Time: 2.40957
Timestep Consumption Time: 2.51891
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.92848

Cumulative Model Updates: 14,682
Cumulative Timesteps: 122,545,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 122545508...
Checkpoint 122545508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,269.57980
Policy Entropy: 1.23018
Value Function Loss: 0.10138

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.30022
Value Function Update Magnitude: 0.56560

Collected Steps per Second: 21,986.29999
Overall Steps per Second: 10,468.14995

Timestep Collection Time: 2.27533
Timestep Consumption Time: 2.50355
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.77888

Cumulative Model Updates: 14,688
Cumulative Timesteps: 122,595,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,176.35387
Policy Entropy: 1.22613
Value Function Loss: 0.09931

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.31877
Value Function Update Magnitude: 0.61926

Collected Steps per Second: 19,152.33417
Overall Steps per Second: 9,633.26029

Timestep Collection Time: 2.61086
Timestep Consumption Time: 2.57991
PPO Batch Consumption Time: 0.29912
Total Iteration Time: 5.19077

Cumulative Model Updates: 14,694
Cumulative Timesteps: 122,645,538

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 122645538...
Checkpoint 122645538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,111.45561
Policy Entropy: 1.23209
Value Function Loss: 0.09762

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08187
Policy Update Magnitude: 0.36054
Value Function Update Magnitude: 0.65054

Collected Steps per Second: 19,230.19782
Overall Steps per Second: 9,867.45445

Timestep Collection Time: 2.60153
Timestep Consumption Time: 2.46847
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 5.07000

Cumulative Model Updates: 14,700
Cumulative Timesteps: 122,695,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,886.11849
Policy Entropy: 1.21703
Value Function Loss: 0.10099

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07535
Policy Update Magnitude: 0.35948
Value Function Update Magnitude: 0.66407

Collected Steps per Second: 22,224.12575
Overall Steps per Second: 10,369.24672

Timestep Collection Time: 2.25080
Timestep Consumption Time: 2.57328
PPO Batch Consumption Time: 0.30249
Total Iteration Time: 4.82407

Cumulative Model Updates: 14,706
Cumulative Timesteps: 122,745,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 122745588...
Checkpoint 122745588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,813.80019
Policy Entropy: 1.21547
Value Function Loss: 0.09846

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07382
Policy Update Magnitude: 0.36041
Value Function Update Magnitude: 0.68387

Collected Steps per Second: 22,032.76990
Overall Steps per Second: 10,465.18415

Timestep Collection Time: 2.27035
Timestep Consumption Time: 2.50950
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.77985

Cumulative Model Updates: 14,712
Cumulative Timesteps: 122,795,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,293.26867
Policy Entropy: 1.22232
Value Function Loss: 0.09613

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.36468
Value Function Update Magnitude: 0.66615

Collected Steps per Second: 22,134.92615
Overall Steps per Second: 10,301.11689

Timestep Collection Time: 2.26005
Timestep Consumption Time: 2.59632
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.85637

Cumulative Model Updates: 14,718
Cumulative Timesteps: 122,845,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 122845636...
Checkpoint 122845636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,856.40014
Policy Entropy: 1.21968
Value Function Loss: 0.09609

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.35014
Value Function Update Magnitude: 0.64745

Collected Steps per Second: 18,387.24255
Overall Steps per Second: 9,489.42236

Timestep Collection Time: 2.71960
Timestep Consumption Time: 2.55005
PPO Batch Consumption Time: 0.29810
Total Iteration Time: 5.26966

Cumulative Model Updates: 14,724
Cumulative Timesteps: 122,895,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,103.04606
Policy Entropy: 1.21659
Value Function Loss: 0.10703

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.31943
Value Function Update Magnitude: 0.66997

Collected Steps per Second: 21,739.11720
Overall Steps per Second: 10,258.22868

Timestep Collection Time: 2.30009
Timestep Consumption Time: 2.57424
PPO Batch Consumption Time: 0.30692
Total Iteration Time: 4.87433

Cumulative Model Updates: 14,730
Cumulative Timesteps: 122,945,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 122945644...
Checkpoint 122945644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,787.83744
Policy Entropy: 1.20787
Value Function Loss: 0.10685

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.15633
Policy Update Magnitude: 0.29613
Value Function Update Magnitude: 0.61394

Collected Steps per Second: 20,283.39831
Overall Steps per Second: 9,716.51269

Timestep Collection Time: 2.46635
Timestep Consumption Time: 2.68220
PPO Batch Consumption Time: 0.31324
Total Iteration Time: 5.14855

Cumulative Model Updates: 14,736
Cumulative Timesteps: 122,995,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,525.80287
Policy Entropy: 1.20483
Value Function Loss: 0.10252

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.27863
Value Function Update Magnitude: 0.58621

Collected Steps per Second: 20,411.61880
Overall Steps per Second: 10,176.36841

Timestep Collection Time: 2.45037
Timestep Consumption Time: 2.46455
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.91492

Cumulative Model Updates: 14,742
Cumulative Timesteps: 123,045,686

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 123045686...
Checkpoint 123045686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,805.25111
Policy Entropy: 1.20448
Value Function Loss: 0.09685

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.29760
Value Function Update Magnitude: 0.65164

Collected Steps per Second: 21,123.71258
Overall Steps per Second: 10,341.38073

Timestep Collection Time: 2.36777
Timestep Consumption Time: 2.46873
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.83649

Cumulative Model Updates: 14,748
Cumulative Timesteps: 123,095,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,173.02126
Policy Entropy: 1.19049
Value Function Loss: 0.09801

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12916
Policy Update Magnitude: 0.28974
Value Function Update Magnitude: 0.68690

Collected Steps per Second: 19,815.49947
Overall Steps per Second: 10,023.87547

Timestep Collection Time: 2.52328
Timestep Consumption Time: 2.46481
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.98809

Cumulative Model Updates: 14,754
Cumulative Timesteps: 123,145,702

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 123145702...
Checkpoint 123145702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,041.36095
Policy Entropy: 1.18001
Value Function Loss: 0.09959

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.27762
Value Function Update Magnitude: 0.68597

Collected Steps per Second: 22,292.49707
Overall Steps per Second: 10,665.66576

Timestep Collection Time: 2.24345
Timestep Consumption Time: 2.44562
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.68906

Cumulative Model Updates: 14,760
Cumulative Timesteps: 123,195,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,979.26558
Policy Entropy: 1.16719
Value Function Loss: 0.10205

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.15821
Policy Update Magnitude: 0.27174
Value Function Update Magnitude: 0.66397

Collected Steps per Second: 22,843.77458
Overall Steps per Second: 10,835.27480

Timestep Collection Time: 2.18992
Timestep Consumption Time: 2.42704
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.61696

Cumulative Model Updates: 14,766
Cumulative Timesteps: 123,245,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 123245740...
Checkpoint 123245740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,534.39237
Policy Entropy: 1.16805
Value Function Loss: 0.10637

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.27736
Value Function Update Magnitude: 0.65739

Collected Steps per Second: 22,208.02389
Overall Steps per Second: 10,728.92810

Timestep Collection Time: 2.25144
Timestep Consumption Time: 2.40886
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.66030

Cumulative Model Updates: 14,772
Cumulative Timesteps: 123,295,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.60972
Policy Entropy: 1.17012
Value Function Loss: 0.11067

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.28536
Value Function Update Magnitude: 0.61145

Collected Steps per Second: 20,572.31545
Overall Steps per Second: 10,205.67077

Timestep Collection Time: 2.43113
Timestep Consumption Time: 2.46948
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.90061

Cumulative Model Updates: 14,778
Cumulative Timesteps: 123,345,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 123345754...
Checkpoint 123345754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,995.24784
Policy Entropy: 1.17233
Value Function Loss: 0.11403

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.14350
Policy Update Magnitude: 0.28361
Value Function Update Magnitude: 0.51832

Collected Steps per Second: 22,478.04694
Overall Steps per Second: 10,199.56836

Timestep Collection Time: 2.22528
Timestep Consumption Time: 2.67885
PPO Batch Consumption Time: 0.31964
Total Iteration Time: 4.90413

Cumulative Model Updates: 14,784
Cumulative Timesteps: 123,395,774

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,772.09194
Policy Entropy: 1.18445
Value Function Loss: 0.11282

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.29845
Value Function Update Magnitude: 0.59277

Collected Steps per Second: 19,506.41493
Overall Steps per Second: 9,313.14642

Timestep Collection Time: 2.56418
Timestep Consumption Time: 2.80651
PPO Batch Consumption Time: 0.32149
Total Iteration Time: 5.37069

Cumulative Model Updates: 14,790
Cumulative Timesteps: 123,445,792

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 123445792...
Checkpoint 123445792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,364.30984
Policy Entropy: 1.19093
Value Function Loss: 0.10868

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.28216
Value Function Update Magnitude: 0.62112

Collected Steps per Second: 19,543.18804
Overall Steps per Second: 9,639.81273

Timestep Collection Time: 2.55977
Timestep Consumption Time: 2.62975
PPO Batch Consumption Time: 0.31062
Total Iteration Time: 5.18952

Cumulative Model Updates: 14,796
Cumulative Timesteps: 123,495,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,637.06719
Policy Entropy: 1.18407
Value Function Loss: 0.10502

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.28194
Value Function Update Magnitude: 0.57735

Collected Steps per Second: 21,472.08061
Overall Steps per Second: 10,160.79644

Timestep Collection Time: 2.32888
Timestep Consumption Time: 2.59258
PPO Batch Consumption Time: 0.30133
Total Iteration Time: 4.92146

Cumulative Model Updates: 14,802
Cumulative Timesteps: 123,545,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 123545824...
Checkpoint 123545824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,990.69054
Policy Entropy: 1.17564
Value Function Loss: 0.10798

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.28510
Value Function Update Magnitude: 0.55478

Collected Steps per Second: 20,811.19891
Overall Steps per Second: 10,149.33088

Timestep Collection Time: 2.40265
Timestep Consumption Time: 2.52398
PPO Batch Consumption Time: 0.29788
Total Iteration Time: 4.92663

Cumulative Model Updates: 14,808
Cumulative Timesteps: 123,595,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,951.63693
Policy Entropy: 1.17442
Value Function Loss: 0.11113

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.27284
Value Function Update Magnitude: 0.55639

Collected Steps per Second: 21,376.93356
Overall Steps per Second: 10,089.32248

Timestep Collection Time: 2.33944
Timestep Consumption Time: 2.61729
PPO Batch Consumption Time: 0.31349
Total Iteration Time: 4.95673

Cumulative Model Updates: 14,814
Cumulative Timesteps: 123,645,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 123645836...
Checkpoint 123645836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,894.96204
Policy Entropy: 1.17607
Value Function Loss: 0.11288

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.12008
Policy Update Magnitude: 0.29897
Value Function Update Magnitude: 0.57053

Collected Steps per Second: 20,913.44704
Overall Steps per Second: 10,161.46639

Timestep Collection Time: 2.39272
Timestep Consumption Time: 2.53177
PPO Batch Consumption Time: 0.30035
Total Iteration Time: 4.92449

Cumulative Model Updates: 14,820
Cumulative Timesteps: 123,695,876

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698.51844
Policy Entropy: 1.17693
Value Function Loss: 0.10833

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.28183
Value Function Update Magnitude: 0.57702

Collected Steps per Second: 21,410.39546
Overall Steps per Second: 10,288.26207

Timestep Collection Time: 2.33550
Timestep Consumption Time: 2.52480
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.86030

Cumulative Model Updates: 14,826
Cumulative Timesteps: 123,745,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 123745880...
Checkpoint 123745880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864.43213
Policy Entropy: 1.17113
Value Function Loss: 0.10788

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14202
Policy Update Magnitude: 0.27946
Value Function Update Magnitude: 0.66578

Collected Steps per Second: 21,326.25067
Overall Steps per Second: 10,145.18175

Timestep Collection Time: 2.34594
Timestep Consumption Time: 2.58547
PPO Batch Consumption Time: 0.30826
Total Iteration Time: 4.93141

Cumulative Model Updates: 14,832
Cumulative Timesteps: 123,795,910

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,513.08125
Policy Entropy: 1.16424
Value Function Loss: 0.10598

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12814
Policy Update Magnitude: 0.31535
Value Function Update Magnitude: 0.69102

Collected Steps per Second: 21,454.07769
Overall Steps per Second: 10,430.17683

Timestep Collection Time: 2.33186
Timestep Consumption Time: 2.46460
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.79647

Cumulative Model Updates: 14,838
Cumulative Timesteps: 123,845,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 123845938...
Checkpoint 123845938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,817.20717
Policy Entropy: 1.16549
Value Function Loss: 0.10474

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.30412
Value Function Update Magnitude: 0.70092

Collected Steps per Second: 21,264.67577
Overall Steps per Second: 10,292.17726

Timestep Collection Time: 2.35310
Timestep Consumption Time: 2.50865
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.86175

Cumulative Model Updates: 14,844
Cumulative Timesteps: 123,895,976

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,585.48935
Policy Entropy: 1.17464
Value Function Loss: 0.10604

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12903
Policy Update Magnitude: 0.28864
Value Function Update Magnitude: 0.71800

Collected Steps per Second: 21,497.93192
Overall Steps per Second: 10,368.39364

Timestep Collection Time: 2.32692
Timestep Consumption Time: 2.49774
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.82466

Cumulative Model Updates: 14,850
Cumulative Timesteps: 123,946,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 123946000...
Checkpoint 123946000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,306.70054
Policy Entropy: 1.18332
Value Function Loss: 0.10756

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.27156
Value Function Update Magnitude: 0.61263

Collected Steps per Second: 20,785.35999
Overall Steps per Second: 9,874.06403

Timestep Collection Time: 2.40650
Timestep Consumption Time: 2.65930
PPO Batch Consumption Time: 0.30874
Total Iteration Time: 5.06580

Cumulative Model Updates: 14,856
Cumulative Timesteps: 123,996,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,413.00721
Policy Entropy: 1.18896
Value Function Loss: 0.10637

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.30358
Value Function Update Magnitude: 0.55132

Collected Steps per Second: 21,327.99091
Overall Steps per Second: 10,353.44614

Timestep Collection Time: 2.34640
Timestep Consumption Time: 2.48716
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.83356

Cumulative Model Updates: 14,862
Cumulative Timesteps: 124,046,064

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 124046064...
Checkpoint 124046064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,087.69787
Policy Entropy: 1.18868
Value Function Loss: 0.10223

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07867
Policy Update Magnitude: 0.32680
Value Function Update Magnitude: 0.52448

Collected Steps per Second: 22,258.22010
Overall Steps per Second: 10,484.70011

Timestep Collection Time: 2.24717
Timestep Consumption Time: 2.52340
PPO Batch Consumption Time: 0.29919
Total Iteration Time: 4.77057

Cumulative Model Updates: 14,868
Cumulative Timesteps: 124,096,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,828.36789
Policy Entropy: 1.18113
Value Function Loss: 0.10411

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07824
Policy Update Magnitude: 0.34413
Value Function Update Magnitude: 0.53294

Collected Steps per Second: 21,184.16376
Overall Steps per Second: 10,145.21274

Timestep Collection Time: 2.36158
Timestep Consumption Time: 2.56962
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.93119

Cumulative Model Updates: 14,874
Cumulative Timesteps: 124,146,110

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 124146110...
Checkpoint 124146110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,833.43479
Policy Entropy: 1.16948
Value Function Loss: 0.10958

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.34862
Value Function Update Magnitude: 0.53049

Collected Steps per Second: 20,266.55320
Overall Steps per Second: 9,989.25870

Timestep Collection Time: 2.46761
Timestep Consumption Time: 2.53876
PPO Batch Consumption Time: 0.30252
Total Iteration Time: 5.00638

Cumulative Model Updates: 14,880
Cumulative Timesteps: 124,196,120

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,585.98017
Policy Entropy: 1.16737
Value Function Loss: 0.10917

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.35091
Value Function Update Magnitude: 0.55727

Collected Steps per Second: 20,752.41534
Overall Steps per Second: 10,213.54521

Timestep Collection Time: 2.40936
Timestep Consumption Time: 2.48610
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.89546

Cumulative Model Updates: 14,886
Cumulative Timesteps: 124,246,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 124246120...
Checkpoint 124246120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,252.01864
Policy Entropy: 1.17648
Value Function Loss: 0.10627

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.34380
Value Function Update Magnitude: 0.51492

Collected Steps per Second: 22,086.08486
Overall Steps per Second: 10,541.69721

Timestep Collection Time: 2.26441
Timestep Consumption Time: 2.47980
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.74421

Cumulative Model Updates: 14,892
Cumulative Timesteps: 124,296,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,613.30432
Policy Entropy: 1.17535
Value Function Loss: 0.10608

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.29288
Value Function Update Magnitude: 0.53470

Collected Steps per Second: 22,071.46380
Overall Steps per Second: 10,417.79481

Timestep Collection Time: 2.26627
Timestep Consumption Time: 2.53513
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.80140

Cumulative Model Updates: 14,898
Cumulative Timesteps: 124,346,152

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 124346152...
Checkpoint 124346152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,504.76481
Policy Entropy: 1.17857
Value Function Loss: 0.10631

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.25964
Value Function Update Magnitude: 0.53538

Collected Steps per Second: 22,358.57830
Overall Steps per Second: 10,670.55851

Timestep Collection Time: 2.23673
Timestep Consumption Time: 2.45000
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.68673

Cumulative Model Updates: 14,904
Cumulative Timesteps: 124,396,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821.50836
Policy Entropy: 1.17725
Value Function Loss: 0.11017

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.25664
Value Function Update Magnitude: 0.50506

Collected Steps per Second: 22,135.31471
Overall Steps per Second: 10,514.15766

Timestep Collection Time: 2.25929
Timestep Consumption Time: 2.49716
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.75644

Cumulative Model Updates: 14,910
Cumulative Timesteps: 124,446,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 124446172...
Checkpoint 124446172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.11069
Policy Entropy: 1.17330
Value Function Loss: 0.11111

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.27353
Value Function Update Magnitude: 0.54741

Collected Steps per Second: 22,121.91505
Overall Steps per Second: 10,579.48398

Timestep Collection Time: 2.26074
Timestep Consumption Time: 2.46652
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.72726

Cumulative Model Updates: 14,916
Cumulative Timesteps: 124,496,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,572.53575
Policy Entropy: 1.18478
Value Function Loss: 0.11072

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.28727
Value Function Update Magnitude: 0.57419

Collected Steps per Second: 22,482.22224
Overall Steps per Second: 10,117.38397

Timestep Collection Time: 2.22603
Timestep Consumption Time: 2.72051
PPO Batch Consumption Time: 0.33062
Total Iteration Time: 4.94654

Cumulative Model Updates: 14,922
Cumulative Timesteps: 124,546,230

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 124546230...
Checkpoint 124546230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,358.73356
Policy Entropy: 1.18631
Value Function Loss: 0.11113

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12093
Policy Update Magnitude: 0.28497
Value Function Update Magnitude: 0.50904

Collected Steps per Second: 18,241.85399
Overall Steps per Second: 9,333.37644

Timestep Collection Time: 2.74248
Timestep Consumption Time: 2.61763
PPO Batch Consumption Time: 0.31169
Total Iteration Time: 5.36012

Cumulative Model Updates: 14,928
Cumulative Timesteps: 124,596,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,631.90781
Policy Entropy: 1.19400
Value Function Loss: 0.10695

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.27558
Value Function Update Magnitude: 0.50743

Collected Steps per Second: 17,793.27584
Overall Steps per Second: 8,855.03021

Timestep Collection Time: 2.81039
Timestep Consumption Time: 2.83680
PPO Batch Consumption Time: 0.33502
Total Iteration Time: 5.64719

Cumulative Model Updates: 14,934
Cumulative Timesteps: 124,646,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 124646264...
Checkpoint 124646264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,454.98378
Policy Entropy: 1.18586
Value Function Loss: 0.10819

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.27048
Value Function Update Magnitude: 0.58035

Collected Steps per Second: 19,865.14734
Overall Steps per Second: 9,785.51126

Timestep Collection Time: 2.51798
Timestep Consumption Time: 2.59366
PPO Batch Consumption Time: 0.31111
Total Iteration Time: 5.11164

Cumulative Model Updates: 14,940
Cumulative Timesteps: 124,696,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614.91197
Policy Entropy: 1.18942
Value Function Loss: 0.10597

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.14055
Policy Update Magnitude: 0.26222
Value Function Update Magnitude: 0.63821

Collected Steps per Second: 21,304.77619
Overall Steps per Second: 10,083.85398

Timestep Collection Time: 2.34877
Timestep Consumption Time: 2.61362
PPO Batch Consumption Time: 0.31361
Total Iteration Time: 4.96239

Cumulative Model Updates: 14,946
Cumulative Timesteps: 124,746,324

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 124746324...
Checkpoint 124746324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,756.92604
Policy Entropy: 1.16799
Value Function Loss: 0.11114

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.25778
Value Function Update Magnitude: 0.58150

Collected Steps per Second: 18,797.11254
Overall Steps per Second: 9,503.37568

Timestep Collection Time: 2.66169
Timestep Consumption Time: 2.60297
PPO Batch Consumption Time: 0.31206
Total Iteration Time: 5.26466

Cumulative Model Updates: 14,952
Cumulative Timesteps: 124,796,356

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,247.05235
Policy Entropy: 1.16966
Value Function Loss: 0.11016

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10883
Policy Update Magnitude: 0.26030
Value Function Update Magnitude: 0.54373

Collected Steps per Second: 21,477.86335
Overall Steps per Second: 10,238.17742

Timestep Collection Time: 2.32891
Timestep Consumption Time: 2.55673
PPO Batch Consumption Time: 0.30270
Total Iteration Time: 4.88564

Cumulative Model Updates: 14,958
Cumulative Timesteps: 124,846,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 124846376...
Checkpoint 124846376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,915.13861
Policy Entropy: 1.17991
Value Function Loss: 0.10961

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.14926
Policy Update Magnitude: 0.26088
Value Function Update Magnitude: 0.56229

Collected Steps per Second: 20,825.66653
Overall Steps per Second: 9,991.52540

Timestep Collection Time: 2.40213
Timestep Consumption Time: 2.60471
PPO Batch Consumption Time: 0.31245
Total Iteration Time: 5.00684

Cumulative Model Updates: 14,964
Cumulative Timesteps: 124,896,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,876.12510
Policy Entropy: 1.19659
Value Function Loss: 0.10433

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.14505
Policy Update Magnitude: 0.25921
Value Function Update Magnitude: 0.57914

Collected Steps per Second: 21,315.11261
Overall Steps per Second: 10,115.10729

Timestep Collection Time: 2.34575
Timestep Consumption Time: 2.59735
PPO Batch Consumption Time: 0.30984
Total Iteration Time: 4.94310

Cumulative Model Updates: 14,970
Cumulative Timesteps: 124,946,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 124946402...
Checkpoint 124946402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,822.12504
Policy Entropy: 1.19980
Value Function Loss: 0.10660

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.14887
Policy Update Magnitude: 0.27221
Value Function Update Magnitude: 0.56609

Collected Steps per Second: 20,800.65166
Overall Steps per Second: 10,061.08710

Timestep Collection Time: 2.40444
Timestep Consumption Time: 2.56659
PPO Batch Consumption Time: 0.30456
Total Iteration Time: 4.97103

Cumulative Model Updates: 14,976
Cumulative Timesteps: 124,996,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,374.32958
Policy Entropy: 1.21119
Value Function Loss: 0.10879

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.28944
Value Function Update Magnitude: 0.55723

Collected Steps per Second: 21,544.27013
Overall Steps per Second: 10,162.13760

Timestep Collection Time: 2.32229
Timestep Consumption Time: 2.60109
PPO Batch Consumption Time: 0.31087
Total Iteration Time: 4.92337

Cumulative Model Updates: 14,982
Cumulative Timesteps: 125,046,448

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 125046448...
Checkpoint 125046448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,120.91808
Policy Entropy: 1.21134
Value Function Loss: 0.11713

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.14492
Policy Update Magnitude: 0.28143
Value Function Update Magnitude: 0.49258

Collected Steps per Second: 20,685.35024
Overall Steps per Second: 10,096.46511

Timestep Collection Time: 2.41872
Timestep Consumption Time: 2.53668
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 4.95540

Cumulative Model Updates: 14,988
Cumulative Timesteps: 125,096,480

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,457.01417
Policy Entropy: 1.21843
Value Function Loss: 0.11810

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.28237
Value Function Update Magnitude: 0.49567

Collected Steps per Second: 19,124.87452
Overall Steps per Second: 9,107.07586

Timestep Collection Time: 2.61586
Timestep Consumption Time: 2.87745
PPO Batch Consumption Time: 0.34402
Total Iteration Time: 5.49331

Cumulative Model Updates: 14,994
Cumulative Timesteps: 125,146,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 125146508...
Checkpoint 125146508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.64754
Policy Entropy: 1.21474
Value Function Loss: 0.11232

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.28018
Value Function Update Magnitude: 0.56289

Collected Steps per Second: 20,672.63711
Overall Steps per Second: 10,033.10338

Timestep Collection Time: 2.41885
Timestep Consumption Time: 2.56505
PPO Batch Consumption Time: 0.30383
Total Iteration Time: 4.98390

Cumulative Model Updates: 15,000
Cumulative Timesteps: 125,196,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,225.75346
Policy Entropy: 1.20952
Value Function Loss: 0.10778

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.27244
Value Function Update Magnitude: 0.59747

Collected Steps per Second: 21,542.35380
Overall Steps per Second: 10,181.55132

Timestep Collection Time: 2.32184
Timestep Consumption Time: 2.59077
PPO Batch Consumption Time: 0.30930
Total Iteration Time: 4.91261

Cumulative Model Updates: 15,006
Cumulative Timesteps: 125,246,530

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 125246530...
Checkpoint 125246530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,815.06316
Policy Entropy: 1.20366
Value Function Loss: 0.10477

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.24963
Value Function Update Magnitude: 0.57196

Collected Steps per Second: 20,404.63146
Overall Steps per Second: 9,892.55252

Timestep Collection Time: 2.45062
Timestep Consumption Time: 2.60409
PPO Batch Consumption Time: 0.31027
Total Iteration Time: 5.05471

Cumulative Model Updates: 15,012
Cumulative Timesteps: 125,296,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,776.78221
Policy Entropy: 1.21462
Value Function Loss: 0.10553

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.26710
Value Function Update Magnitude: 0.54837

Collected Steps per Second: 21,227.41955
Overall Steps per Second: 10,141.63059

Timestep Collection Time: 2.35601
Timestep Consumption Time: 2.57535
PPO Batch Consumption Time: 0.30100
Total Iteration Time: 4.93136

Cumulative Model Updates: 15,018
Cumulative Timesteps: 125,346,546

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 125346546...
Checkpoint 125346546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,360.44070
Policy Entropy: 1.21207
Value Function Loss: 0.10688

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.25247
Value Function Update Magnitude: 0.62024

Collected Steps per Second: 20,920.39709
Overall Steps per Second: 10,004.45596

Timestep Collection Time: 2.39078
Timestep Consumption Time: 2.60860
PPO Batch Consumption Time: 0.31284
Total Iteration Time: 4.99937

Cumulative Model Updates: 15,024
Cumulative Timesteps: 125,396,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,216.00727
Policy Entropy: 1.20723
Value Function Loss: 0.11334

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.25997
Value Function Update Magnitude: 0.59691

Collected Steps per Second: 21,473.42295
Overall Steps per Second: 10,222.62789

Timestep Collection Time: 2.33088
Timestep Consumption Time: 2.56532
PPO Batch Consumption Time: 0.30208
Total Iteration Time: 4.89620

Cumulative Model Updates: 15,030
Cumulative Timesteps: 125,446,614

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 125446614...
Checkpoint 125446614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,484.68043
Policy Entropy: 1.20997
Value Function Loss: 0.11395

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.25504
Value Function Update Magnitude: 0.53360

Collected Steps per Second: 21,057.98268
Overall Steps per Second: 10,091.11344

Timestep Collection Time: 2.37630
Timestep Consumption Time: 2.58252
PPO Batch Consumption Time: 0.30770
Total Iteration Time: 4.95882

Cumulative Model Updates: 15,036
Cumulative Timesteps: 125,496,654

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,967.81650
Policy Entropy: 1.19965
Value Function Loss: 0.11047

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.24733
Value Function Update Magnitude: 0.56736

Collected Steps per Second: 21,427.07802
Overall Steps per Second: 10,227.98661

Timestep Collection Time: 2.33359
Timestep Consumption Time: 2.55515
PPO Batch Consumption Time: 0.30101
Total Iteration Time: 4.88874

Cumulative Model Updates: 15,042
Cumulative Timesteps: 125,546,656

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 125546656...
Checkpoint 125546656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,526.28455
Policy Entropy: 1.20239
Value Function Loss: 0.10265

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.27334
Value Function Update Magnitude: 0.67949

Collected Steps per Second: 21,042.65223
Overall Steps per Second: 10,166.10024

Timestep Collection Time: 2.37670
Timestep Consumption Time: 2.54279
PPO Batch Consumption Time: 0.30025
Total Iteration Time: 4.91949

Cumulative Model Updates: 15,048
Cumulative Timesteps: 125,596,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.58684
Policy Entropy: 1.20558
Value Function Loss: 0.10333

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.27913
Value Function Update Magnitude: 0.68904

Collected Steps per Second: 21,375.56853
Overall Steps per Second: 10,093.58080

Timestep Collection Time: 2.33931
Timestep Consumption Time: 2.61473
PPO Batch Consumption Time: 0.31191
Total Iteration Time: 4.95404

Cumulative Model Updates: 15,054
Cumulative Timesteps: 125,646,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 125646672...
Checkpoint 125646672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,828.33610
Policy Entropy: 1.20801
Value Function Loss: 0.10398

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.27594
Value Function Update Magnitude: 0.72343

Collected Steps per Second: 20,768.35003
Overall Steps per Second: 9,956.48855

Timestep Collection Time: 2.40751
Timestep Consumption Time: 2.61434
PPO Batch Consumption Time: 0.30973
Total Iteration Time: 5.02185

Cumulative Model Updates: 15,060
Cumulative Timesteps: 125,696,672

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,705.12269
Policy Entropy: 1.20629
Value Function Loss: 0.10457

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.26131
Value Function Update Magnitude: 0.74553

Collected Steps per Second: 21,559.61440
Overall Steps per Second: 10,169.33756

Timestep Collection Time: 2.32008
Timestep Consumption Time: 2.59863
PPO Batch Consumption Time: 0.30281
Total Iteration Time: 4.91871

Cumulative Model Updates: 15,066
Cumulative Timesteps: 125,746,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 125746692...
Checkpoint 125746692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,353.74479
Policy Entropy: 1.19862
Value Function Loss: 0.10448

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12502
Policy Update Magnitude: 0.25922
Value Function Update Magnitude: 0.72629

Collected Steps per Second: 20,966.26581
Overall Steps per Second: 9,933.08763

Timestep Collection Time: 2.38669
Timestep Consumption Time: 2.65102
PPO Batch Consumption Time: 0.31419
Total Iteration Time: 5.03771

Cumulative Model Updates: 15,072
Cumulative Timesteps: 125,796,732

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,413.97962
Policy Entropy: 1.19732
Value Function Loss: 0.10596

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.27124
Value Function Update Magnitude: 0.74472

Collected Steps per Second: 21,517.39592
Overall Steps per Second: 10,032.27540

Timestep Collection Time: 2.32417
Timestep Consumption Time: 2.66075
PPO Batch Consumption Time: 0.31401
Total Iteration Time: 4.98491

Cumulative Model Updates: 15,078
Cumulative Timesteps: 125,846,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 125846742...
Checkpoint 125846742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,738.38352
Policy Entropy: 1.19836
Value Function Loss: 0.10871

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.30650
Value Function Update Magnitude: 0.71180

Collected Steps per Second: 21,071.97855
Overall Steps per Second: 10,091.20564

Timestep Collection Time: 2.37339
Timestep Consumption Time: 2.58261
PPO Batch Consumption Time: 0.30241
Total Iteration Time: 4.95600

Cumulative Model Updates: 15,084
Cumulative Timesteps: 125,896,754

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,210.17072
Policy Entropy: 1.20807
Value Function Loss: 0.10746

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.32040
Value Function Update Magnitude: 0.67027

Collected Steps per Second: 20,812.92774
Overall Steps per Second: 10,000.45213

Timestep Collection Time: 2.40283
Timestep Consumption Time: 2.59794
PPO Batch Consumption Time: 0.30449
Total Iteration Time: 5.00077

Cumulative Model Updates: 15,090
Cumulative Timesteps: 125,946,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 125946764...
Checkpoint 125946764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,984.03735
Policy Entropy: 1.20349
Value Function Loss: 0.10142

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.15985
Policy Update Magnitude: 0.27569
Value Function Update Magnitude: 0.64418

Collected Steps per Second: 20,733.62454
Overall Steps per Second: 9,968.29182

Timestep Collection Time: 2.41202
Timestep Consumption Time: 2.60488
PPO Batch Consumption Time: 0.30634
Total Iteration Time: 5.01691

Cumulative Model Updates: 15,096
Cumulative Timesteps: 125,996,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,630.91198
Policy Entropy: 1.21303
Value Function Loss: 0.09825

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12375
Policy Update Magnitude: 0.26963
Value Function Update Magnitude: 0.63840

Collected Steps per Second: 21,464.38432
Overall Steps per Second: 10,051.22836

Timestep Collection Time: 2.33074
Timestep Consumption Time: 2.64656
PPO Batch Consumption Time: 0.31185
Total Iteration Time: 4.97730

Cumulative Model Updates: 15,102
Cumulative Timesteps: 126,046,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 126046802...
Checkpoint 126046802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,155.68244
Policy Entropy: 1.21063
Value Function Loss: 0.09512

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.27324
Value Function Update Magnitude: 0.57549

Collected Steps per Second: 21,098.66543
Overall Steps per Second: 10,161.94123

Timestep Collection Time: 2.37029
Timestep Consumption Time: 2.55101
PPO Batch Consumption Time: 0.30078
Total Iteration Time: 4.92130

Cumulative Model Updates: 15,108
Cumulative Timesteps: 126,096,812

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,971.81391
Policy Entropy: 1.20840
Value Function Loss: 0.09899

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.16424
Policy Update Magnitude: 0.26244
Value Function Update Magnitude: 0.56064

Collected Steps per Second: 21,478.00175
Overall Steps per Second: 10,100.97644

Timestep Collection Time: 2.32843
Timestep Consumption Time: 2.62258
PPO Batch Consumption Time: 0.31408
Total Iteration Time: 4.95101

Cumulative Model Updates: 15,114
Cumulative Timesteps: 126,146,822

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 126146822...
Checkpoint 126146822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,808.49685
Policy Entropy: 1.19907
Value Function Loss: 0.09869

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.29595
Value Function Update Magnitude: 0.50631

Collected Steps per Second: 21,077.49439
Overall Steps per Second: 10,119.47565

Timestep Collection Time: 2.37277
Timestep Consumption Time: 2.56939
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 4.94215

Cumulative Model Updates: 15,120
Cumulative Timesteps: 126,196,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,273.37985
Policy Entropy: 1.19156
Value Function Loss: 0.10262

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.13036
Policy Update Magnitude: 0.30716
Value Function Update Magnitude: 0.46692

Collected Steps per Second: 21,394.31344
Overall Steps per Second: 10,070.69907

Timestep Collection Time: 2.33772
Timestep Consumption Time: 2.62856
PPO Batch Consumption Time: 0.31282
Total Iteration Time: 4.96629

Cumulative Model Updates: 15,126
Cumulative Timesteps: 126,246,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 126246848...
Checkpoint 126246848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,131.11557
Policy Entropy: 1.18811
Value Function Loss: 0.10720

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.28654
Value Function Update Magnitude: 0.42067

Collected Steps per Second: 20,741.35994
Overall Steps per Second: 10,110.22310

Timestep Collection Time: 2.41170
Timestep Consumption Time: 2.53596
PPO Batch Consumption Time: 0.30209
Total Iteration Time: 4.94767

Cumulative Model Updates: 15,132
Cumulative Timesteps: 126,296,870

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,437.78147
Policy Entropy: 1.18824
Value Function Loss: 0.10559

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10929
Policy Update Magnitude: 0.29577
Value Function Update Magnitude: 0.43523

Collected Steps per Second: 21,341.35702
Overall Steps per Second: 10,154.01900

Timestep Collection Time: 2.34399
Timestep Consumption Time: 2.58253
PPO Batch Consumption Time: 0.30582
Total Iteration Time: 4.92652

Cumulative Model Updates: 15,138
Cumulative Timesteps: 126,346,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 126346894...
Checkpoint 126346894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,399.74175
Policy Entropy: 1.19737
Value Function Loss: 0.10557

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.31798
Value Function Update Magnitude: 0.46326

Collected Steps per Second: 21,110.64952
Overall Steps per Second: 10,081.53604

Timestep Collection Time: 2.37008
Timestep Consumption Time: 2.59285
PPO Batch Consumption Time: 0.30230
Total Iteration Time: 4.96293

Cumulative Model Updates: 15,144
Cumulative Timesteps: 126,396,928

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,357.12533
Policy Entropy: 1.19670
Value Function Loss: 0.10162

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07341
Policy Update Magnitude: 0.33021
Value Function Update Magnitude: 0.46072

Collected Steps per Second: 20,878.65248
Overall Steps per Second: 10,030.78828

Timestep Collection Time: 2.39556
Timestep Consumption Time: 2.59069
PPO Batch Consumption Time: 0.30213
Total Iteration Time: 4.98625

Cumulative Model Updates: 15,150
Cumulative Timesteps: 126,446,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 126446944...
Checkpoint 126446944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,902.57072
Policy Entropy: 1.20459
Value Function Loss: 0.09978

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09138
Policy Update Magnitude: 0.32516
Value Function Update Magnitude: 0.44651

Collected Steps per Second: 20,826.62629
Overall Steps per Second: 9,926.84609

Timestep Collection Time: 2.40077
Timestep Consumption Time: 2.63607
PPO Batch Consumption Time: 0.31066
Total Iteration Time: 5.03685

Cumulative Model Updates: 15,156
Cumulative Timesteps: 126,496,944

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,529.83611
Policy Entropy: 1.20531
Value Function Loss: 0.10072

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.30103
Value Function Update Magnitude: 0.47162

Collected Steps per Second: 21,152.22257
Overall Steps per Second: 9,884.50460

Timestep Collection Time: 2.36420
Timestep Consumption Time: 2.69504
PPO Batch Consumption Time: 0.31747
Total Iteration Time: 5.05923

Cumulative Model Updates: 15,162
Cumulative Timesteps: 126,546,952

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 126546952...
Checkpoint 126546952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,941.42512
Policy Entropy: 1.20339
Value Function Loss: 0.10143

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.08022
Policy Update Magnitude: 0.30833
Value Function Update Magnitude: 0.53850

Collected Steps per Second: 20,879.64610
Overall Steps per Second: 9,909.87062

Timestep Collection Time: 2.39544
Timestep Consumption Time: 2.65165
PPO Batch Consumption Time: 0.30967
Total Iteration Time: 5.04709

Cumulative Model Updates: 15,168
Cumulative Timesteps: 126,596,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,544.09031
Policy Entropy: 1.19735
Value Function Loss: 0.10700

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.33017
Value Function Update Magnitude: 0.59832

Collected Steps per Second: 21,126.49941
Overall Steps per Second: 10,009.72737

Timestep Collection Time: 2.36764
Timestep Consumption Time: 2.62950
PPO Batch Consumption Time: 0.31290
Total Iteration Time: 4.99714

Cumulative Model Updates: 15,174
Cumulative Timesteps: 126,646,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 126646988...
Checkpoint 126646988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,442.05920
Policy Entropy: 1.19853
Value Function Loss: 0.10327

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.32070
Value Function Update Magnitude: 0.62243

Collected Steps per Second: 20,985.37420
Overall Steps per Second: 10,015.94772

Timestep Collection Time: 2.38280
Timestep Consumption Time: 2.60964
PPO Batch Consumption Time: 0.30870
Total Iteration Time: 4.99244

Cumulative Model Updates: 15,180
Cumulative Timesteps: 126,696,992

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,703.09448
Policy Entropy: 1.18386
Value Function Loss: 0.10456

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.28585
Value Function Update Magnitude: 0.65281

Collected Steps per Second: 21,181.86577
Overall Steps per Second: 10,159.57220

Timestep Collection Time: 2.36089
Timestep Consumption Time: 2.56137
PPO Batch Consumption Time: 0.30250
Total Iteration Time: 4.92225

Cumulative Model Updates: 15,186
Cumulative Timesteps: 126,747,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 126747000...
Checkpoint 126747000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,956.99794
Policy Entropy: 1.19217
Value Function Loss: 0.10193

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11418
Policy Update Magnitude: 0.30372
Value Function Update Magnitude: 0.66282

Collected Steps per Second: 20,948.04566
Overall Steps per Second: 10,034.38003

Timestep Collection Time: 2.38762
Timestep Consumption Time: 2.59684
PPO Batch Consumption Time: 0.31264
Total Iteration Time: 4.98446

Cumulative Model Updates: 15,192
Cumulative Timesteps: 126,797,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,277.00205
Policy Entropy: 1.18466
Value Function Loss: 0.09996

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.31157
Value Function Update Magnitude: 0.68935

Collected Steps per Second: 21,166.22675
Overall Steps per Second: 10,079.08262

Timestep Collection Time: 2.36244
Timestep Consumption Time: 2.59872
PPO Batch Consumption Time: 0.30964
Total Iteration Time: 4.96117

Cumulative Model Updates: 15,198
Cumulative Timesteps: 126,847,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 126847020...
Checkpoint 126847020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.73369
Policy Entropy: 1.18299
Value Function Loss: 0.09901

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.31489
Value Function Update Magnitude: 0.67728

Collected Steps per Second: 20,770.03904
Overall Steps per Second: 10,069.10017

Timestep Collection Time: 2.40760
Timestep Consumption Time: 2.55868
PPO Batch Consumption Time: 0.30396
Total Iteration Time: 4.96628

Cumulative Model Updates: 15,204
Cumulative Timesteps: 126,897,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,477.54932
Policy Entropy: 1.18933
Value Function Loss: 0.09945

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09010
Policy Update Magnitude: 0.31472
Value Function Update Magnitude: 0.57473

Collected Steps per Second: 21,739.27875
Overall Steps per Second: 10,193.36150

Timestep Collection Time: 2.30118
Timestep Consumption Time: 2.60652
PPO Batch Consumption Time: 0.30924
Total Iteration Time: 4.90770

Cumulative Model Updates: 15,210
Cumulative Timesteps: 126,947,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 126947052...
Checkpoint 126947052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,822.74807
Policy Entropy: 1.18035
Value Function Loss: 0.10281

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08195
Policy Update Magnitude: 0.32703
Value Function Update Magnitude: 0.52431

Collected Steps per Second: 20,887.81174
Overall Steps per Second: 10,044.95534

Timestep Collection Time: 2.39518
Timestep Consumption Time: 2.58543
PPO Batch Consumption Time: 0.30747
Total Iteration Time: 4.98061

Cumulative Model Updates: 15,216
Cumulative Timesteps: 126,997,082

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,447.86414
Policy Entropy: 1.19386
Value Function Loss: 0.10435

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.32591
Value Function Update Magnitude: 0.51438

Collected Steps per Second: 21,531.64303
Overall Steps per Second: 10,062.63273

Timestep Collection Time: 2.32291
Timestep Consumption Time: 2.64756
PPO Batch Consumption Time: 0.30908
Total Iteration Time: 4.97047

Cumulative Model Updates: 15,222
Cumulative Timesteps: 127,047,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 127047098...
Checkpoint 127047098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,606.36458
Policy Entropy: 1.18839
Value Function Loss: 0.10634

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.32253
Value Function Update Magnitude: 0.54287

Collected Steps per Second: 20,744.48299
Overall Steps per Second: 10,093.22924

Timestep Collection Time: 2.41201
Timestep Consumption Time: 2.54537
PPO Batch Consumption Time: 0.30163
Total Iteration Time: 4.95738

Cumulative Model Updates: 15,228
Cumulative Timesteps: 127,097,134

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,646.69460
Policy Entropy: 1.20062
Value Function Loss: 0.10731

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10034
Policy Update Magnitude: 0.32818
Value Function Update Magnitude: 0.59555

Collected Steps per Second: 21,675.66664
Overall Steps per Second: 10,150.43431

Timestep Collection Time: 2.30803
Timestep Consumption Time: 2.62063
PPO Batch Consumption Time: 0.31213
Total Iteration Time: 4.92866

Cumulative Model Updates: 15,234
Cumulative Timesteps: 127,147,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 127147162...
Checkpoint 127147162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,940.65141
Policy Entropy: 1.19199
Value Function Loss: 0.10615

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.32434
Value Function Update Magnitude: 0.55286

Collected Steps per Second: 20,858.59833
Overall Steps per Second: 10,128.25983

Timestep Collection Time: 2.39767
Timestep Consumption Time: 2.54020
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 4.93787

Cumulative Model Updates: 15,240
Cumulative Timesteps: 127,197,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,958.99714
Policy Entropy: 1.19349
Value Function Loss: 0.10390

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11504
Policy Update Magnitude: 0.29938
Value Function Update Magnitude: 0.55491

Collected Steps per Second: 21,285.60820
Overall Steps per Second: 10,128.35914

Timestep Collection Time: 2.35088
Timestep Consumption Time: 2.58970
PPO Batch Consumption Time: 0.30699
Total Iteration Time: 4.94058

Cumulative Model Updates: 15,246
Cumulative Timesteps: 127,247,214

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 127247214...
Checkpoint 127247214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.81927
Policy Entropy: 1.20266
Value Function Loss: 0.09888

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.31223
Value Function Update Magnitude: 0.55532

Collected Steps per Second: 20,997.61379
Overall Steps per Second: 10,143.48424

Timestep Collection Time: 2.38189
Timestep Consumption Time: 2.54876
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 4.93065

Cumulative Model Updates: 15,252
Cumulative Timesteps: 127,297,228

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,027.02103
Policy Entropy: 1.20563
Value Function Loss: 0.10573

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.33203
Value Function Update Magnitude: 0.51110

Collected Steps per Second: 21,543.33065
Overall Steps per Second: 10,096.92487

Timestep Collection Time: 2.32220
Timestep Consumption Time: 2.63257
PPO Batch Consumption Time: 0.31404
Total Iteration Time: 4.95478

Cumulative Model Updates: 15,258
Cumulative Timesteps: 127,347,256

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 127347256...
Checkpoint 127347256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070.81564
Policy Entropy: 1.20215
Value Function Loss: 0.10689

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.32894
Value Function Update Magnitude: 0.51252

Collected Steps per Second: 20,970.82516
Overall Steps per Second: 10,147.43777

Timestep Collection Time: 2.38455
Timestep Consumption Time: 2.54339
PPO Batch Consumption Time: 0.30043
Total Iteration Time: 4.92794

Cumulative Model Updates: 15,264
Cumulative Timesteps: 127,397,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,265.17565
Policy Entropy: 1.19901
Value Function Loss: 0.10879

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.31626
Value Function Update Magnitude: 0.49484

Collected Steps per Second: 21,609.01253
Overall Steps per Second: 10,122.37067

Timestep Collection Time: 2.31459
Timestep Consumption Time: 2.62655
PPO Batch Consumption Time: 0.31367
Total Iteration Time: 4.94113

Cumulative Model Updates: 15,270
Cumulative Timesteps: 127,447,278

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 127447278...
Checkpoint 127447278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,915.35403
Policy Entropy: 1.18696
Value Function Loss: 0.10533

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.31306
Value Function Update Magnitude: 0.53445

Collected Steps per Second: 20,678.94519
Overall Steps per Second: 9,951.02305

Timestep Collection Time: 2.41792
Timestep Consumption Time: 2.60669
PPO Batch Consumption Time: 0.30884
Total Iteration Time: 5.02461

Cumulative Model Updates: 15,276
Cumulative Timesteps: 127,497,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.54659
Policy Entropy: 1.19080
Value Function Loss: 0.10639

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.32069
Value Function Update Magnitude: 0.56116

Collected Steps per Second: 21,501.98150
Overall Steps per Second: 9,947.21588

Timestep Collection Time: 2.32611
Timestep Consumption Time: 2.70203
PPO Batch Consumption Time: 0.31204
Total Iteration Time: 5.02814

Cumulative Model Updates: 15,282
Cumulative Timesteps: 127,547,294

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 127547294...
Checkpoint 127547294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,364.22709
Policy Entropy: 1.17818
Value Function Loss: 0.10817

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07427
Policy Update Magnitude: 0.33118
Value Function Update Magnitude: 0.50502

Collected Steps per Second: 20,614.21357
Overall Steps per Second: 10,049.90864

Timestep Collection Time: 2.42687
Timestep Consumption Time: 2.55109
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 4.97796

Cumulative Model Updates: 15,288
Cumulative Timesteps: 127,597,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,447.87505
Policy Entropy: 1.17875
Value Function Loss: 0.11025

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06988
Policy Update Magnitude: 0.33786
Value Function Update Magnitude: 0.49921

Collected Steps per Second: 21,442.09772
Overall Steps per Second: 10,123.31514

Timestep Collection Time: 2.33186
Timestep Consumption Time: 2.60723
PPO Batch Consumption Time: 0.31070
Total Iteration Time: 4.93909

Cumulative Model Updates: 15,294
Cumulative Timesteps: 127,647,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 127647322...
Checkpoint 127647322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,340.39884
Policy Entropy: 1.17972
Value Function Loss: 0.10697

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.33560
Value Function Update Magnitude: 0.52923

Collected Steps per Second: 20,985.41115
Overall Steps per Second: 10,143.18151

Timestep Collection Time: 2.38270
Timestep Consumption Time: 2.54691
PPO Batch Consumption Time: 0.30043
Total Iteration Time: 4.92962

Cumulative Model Updates: 15,300
Cumulative Timesteps: 127,697,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,476.76966
Policy Entropy: 1.17918
Value Function Loss: 0.10968

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.31223
Value Function Update Magnitude: 0.47495

Collected Steps per Second: 21,598.70408
Overall Steps per Second: 10,163.44769

Timestep Collection Time: 2.31514
Timestep Consumption Time: 2.60485
PPO Batch Consumption Time: 0.31230
Total Iteration Time: 4.91998

Cumulative Model Updates: 15,306
Cumulative Timesteps: 127,747,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 127747328...
Checkpoint 127747328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,579.16436
Policy Entropy: 1.17662
Value Function Loss: 0.11201

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.28234
Value Function Update Magnitude: 0.42810

Collected Steps per Second: 20,640.13292
Overall Steps per Second: 9,953.98679

Timestep Collection Time: 2.42382
Timestep Consumption Time: 2.60210
PPO Batch Consumption Time: 0.30756
Total Iteration Time: 5.02593

Cumulative Model Updates: 15,312
Cumulative Timesteps: 127,797,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,859.47409
Policy Entropy: 1.19138
Value Function Loss: 0.11451

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.14063
Policy Update Magnitude: 0.27036
Value Function Update Magnitude: 0.51884

Collected Steps per Second: 21,344.72629
Overall Steps per Second: 10,123.55551

Timestep Collection Time: 2.34325
Timestep Consumption Time: 2.59731
PPO Batch Consumption Time: 0.30860
Total Iteration Time: 4.94056

Cumulative Model Updates: 15,318
Cumulative Timesteps: 127,847,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 127847372...
Checkpoint 127847372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.07298
Policy Entropy: 1.17992
Value Function Loss: 0.11663

Mean KL Divergence: 0.03697
SB3 Clip Fraction: 0.22060
Policy Update Magnitude: 0.26686
Value Function Update Magnitude: 0.55588

Collected Steps per Second: 20,769.37086
Overall Steps per Second: 9,991.99374

Timestep Collection Time: 2.40893
Timestep Consumption Time: 2.59828
PPO Batch Consumption Time: 0.31157
Total Iteration Time: 5.00721

Cumulative Model Updates: 15,324
Cumulative Timesteps: 127,897,404

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,131.16430
Policy Entropy: 1.18290
Value Function Loss: 0.11689

Mean KL Divergence: 0.03017
SB3 Clip Fraction: 0.21720
Policy Update Magnitude: 0.27036
Value Function Update Magnitude: 0.47774

Collected Steps per Second: 21,519.11158
Overall Steps per Second: 10,202.07597

Timestep Collection Time: 2.32398
Timestep Consumption Time: 2.57796
PPO Batch Consumption Time: 0.30152
Total Iteration Time: 4.90194

Cumulative Model Updates: 15,330
Cumulative Timesteps: 127,947,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 127947414...
Checkpoint 127947414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,987.58610
Policy Entropy: 1.18201
Value Function Loss: 0.11337

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.17125
Policy Update Magnitude: 0.28850
Value Function Update Magnitude: 0.49567

Collected Steps per Second: 19,389.88586
Overall Steps per Second: 9,542.05519

Timestep Collection Time: 2.57918
Timestep Consumption Time: 2.66183
PPO Batch Consumption Time: 0.31490
Total Iteration Time: 5.24101

Cumulative Model Updates: 15,336
Cumulative Timesteps: 127,997,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,671.66981
Policy Entropy: 1.18982
Value Function Loss: 0.10942

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.29053
Value Function Update Magnitude: 0.51294

Collected Steps per Second: 21,753.31133
Overall Steps per Second: 10,226.24159

Timestep Collection Time: 2.29979
Timestep Consumption Time: 2.59233
PPO Batch Consumption Time: 0.30936
Total Iteration Time: 4.89212

Cumulative Model Updates: 15,342
Cumulative Timesteps: 128,047,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 128047452...
Checkpoint 128047452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,743.43578
Policy Entropy: 1.20328
Value Function Loss: 0.10579

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13509
Policy Update Magnitude: 0.28527
Value Function Update Magnitude: 0.55000

Collected Steps per Second: 20,926.53326
Overall Steps per Second: 10,065.78899

Timestep Collection Time: 2.39065
Timestep Consumption Time: 2.57945
PPO Batch Consumption Time: 0.30551
Total Iteration Time: 4.97010

Cumulative Model Updates: 15,348
Cumulative Timesteps: 128,097,480

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.40023
Policy Entropy: 1.20706
Value Function Loss: 0.10853

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.31575
Value Function Update Magnitude: 0.57585

Collected Steps per Second: 21,786.93381
Overall Steps per Second: 10,278.46774

Timestep Collection Time: 2.29495
Timestep Consumption Time: 2.56958
PPO Batch Consumption Time: 0.30345
Total Iteration Time: 4.86454

Cumulative Model Updates: 15,354
Cumulative Timesteps: 128,147,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 128147480...
Checkpoint 128147480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,529.31398
Policy Entropy: 1.20938
Value Function Loss: 0.10176

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.33038
Value Function Update Magnitude: 0.62750

Collected Steps per Second: 20,362.75466
Overall Steps per Second: 9,929.52550

Timestep Collection Time: 2.45674
Timestep Consumption Time: 2.58137
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 5.03811

Cumulative Model Updates: 15,360
Cumulative Timesteps: 128,197,506

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,904.75463
Policy Entropy: 1.18406
Value Function Loss: 0.10373

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.28892
Value Function Update Magnitude: 0.58104

Collected Steps per Second: 21,541.49687
Overall Steps per Second: 10,067.84795

Timestep Collection Time: 2.32138
Timestep Consumption Time: 2.64552
PPO Batch Consumption Time: 0.31251
Total Iteration Time: 4.96690

Cumulative Model Updates: 15,366
Cumulative Timesteps: 128,247,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 128247512...
Checkpoint 128247512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,575.34456
Policy Entropy: 1.18229
Value Function Loss: 0.10494

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.29356
Value Function Update Magnitude: 0.46819

Collected Steps per Second: 20,965.98096
Overall Steps per Second: 10,073.21852

Timestep Collection Time: 2.38577
Timestep Consumption Time: 2.57987
PPO Batch Consumption Time: 0.30208
Total Iteration Time: 4.96564

Cumulative Model Updates: 15,372
Cumulative Timesteps: 128,297,532

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,188.88688
Policy Entropy: 1.18320
Value Function Loss: 0.10783

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.32152
Value Function Update Magnitude: 0.47394

Collected Steps per Second: 21,513.71393
Overall Steps per Second: 10,161.43504

Timestep Collection Time: 2.32475
Timestep Consumption Time: 2.59719
PPO Batch Consumption Time: 0.30754
Total Iteration Time: 4.92194

Cumulative Model Updates: 15,378
Cumulative Timesteps: 128,347,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 128347546...
Checkpoint 128347546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,385.53556
Policy Entropy: 1.18353
Value Function Loss: 0.10944

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.32400
Value Function Update Magnitude: 0.48338

Collected Steps per Second: 20,957.35332
Overall Steps per Second: 10,116.46536

Timestep Collection Time: 2.38656
Timestep Consumption Time: 2.55746
PPO Batch Consumption Time: 0.30173
Total Iteration Time: 4.94402

Cumulative Model Updates: 15,384
Cumulative Timesteps: 128,397,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.06839
Policy Entropy: 1.17185
Value Function Loss: 0.10793

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09939
Policy Update Magnitude: 0.31436
Value Function Update Magnitude: 0.52450

Collected Steps per Second: 21,484.07437
Overall Steps per Second: 10,143.85254

Timestep Collection Time: 2.32842
Timestep Consumption Time: 2.60304
PPO Batch Consumption Time: 0.31034
Total Iteration Time: 4.93146

Cumulative Model Updates: 15,390
Cumulative Timesteps: 128,447,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 128447586...
Checkpoint 128447586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,100.23579
Policy Entropy: 1.17584
Value Function Loss: 0.10775

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.29572
Value Function Update Magnitude: 0.49623

Collected Steps per Second: 20,856.83844
Overall Steps per Second: 10,126.75688

Timestep Collection Time: 2.39921
Timestep Consumption Time: 2.54215
PPO Batch Consumption Time: 0.30071
Total Iteration Time: 4.94136

Cumulative Model Updates: 15,396
Cumulative Timesteps: 128,497,626

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,163.58621
Policy Entropy: 1.17740
Value Function Loss: 0.10280

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.28083
Value Function Update Magnitude: 0.52153

Collected Steps per Second: 21,567.45930
Overall Steps per Second: 10,088.99942

Timestep Collection Time: 2.31923
Timestep Consumption Time: 2.63864
PPO Batch Consumption Time: 0.31000
Total Iteration Time: 4.95788

Cumulative Model Updates: 15,402
Cumulative Timesteps: 128,547,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 128547646...
Checkpoint 128547646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,432.97152
Policy Entropy: 1.19005
Value Function Loss: 0.10426

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.27449
Value Function Update Magnitude: 0.52483

Collected Steps per Second: 21,039.43542
Overall Steps per Second: 10,089.57406

Timestep Collection Time: 2.37773
Timestep Consumption Time: 2.58046
PPO Batch Consumption Time: 0.30280
Total Iteration Time: 4.95819

Cumulative Model Updates: 15,408
Cumulative Timesteps: 128,597,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,428.33818
Policy Entropy: 1.17296
Value Function Loss: 0.10318

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.26413
Value Function Update Magnitude: 0.56678

Collected Steps per Second: 21,635.83333
Overall Steps per Second: 10,187.38621

Timestep Collection Time: 2.31237
Timestep Consumption Time: 2.59861
PPO Batch Consumption Time: 0.30415
Total Iteration Time: 4.91098

Cumulative Model Updates: 15,414
Cumulative Timesteps: 128,647,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 128647702...
Checkpoint 128647702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,375.55765
Policy Entropy: 1.17892
Value Function Loss: 0.10369

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.13657
Policy Update Magnitude: 0.24986
Value Function Update Magnitude: 0.63734

Collected Steps per Second: 20,971.44575
Overall Steps per Second: 10,135.38714

Timestep Collection Time: 2.38429
Timestep Consumption Time: 2.54912
PPO Batch Consumption Time: 0.29993
Total Iteration Time: 4.93341

Cumulative Model Updates: 15,420
Cumulative Timesteps: 128,697,704

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,766.68024
Policy Entropy: 1.17443
Value Function Loss: 0.10270

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.24737
Value Function Update Magnitude: 0.66823

Collected Steps per Second: 21,651.32245
Overall Steps per Second: 10,131.24389

Timestep Collection Time: 2.30988
Timestep Consumption Time: 2.62653
PPO Batch Consumption Time: 0.31330
Total Iteration Time: 4.93641

Cumulative Model Updates: 15,426
Cumulative Timesteps: 128,747,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 128747716...
Checkpoint 128747716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852.73174
Policy Entropy: 1.19605
Value Function Loss: 0.10327

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13220
Policy Update Magnitude: 0.25461
Value Function Update Magnitude: 0.67550

Collected Steps per Second: 20,884.57127
Overall Steps per Second: 10,063.72343

Timestep Collection Time: 2.39430
Timestep Consumption Time: 2.57443
PPO Batch Consumption Time: 0.30677
Total Iteration Time: 4.96874

Cumulative Model Updates: 15,432
Cumulative Timesteps: 128,797,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,282.51186
Policy Entropy: 1.20661
Value Function Loss: 0.10189

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12385
Policy Update Magnitude: 0.25729
Value Function Update Magnitude: 0.62077

Collected Steps per Second: 21,327.21566
Overall Steps per Second: 10,144.41526

Timestep Collection Time: 2.34564
Timestep Consumption Time: 2.58574
PPO Batch Consumption Time: 0.30597
Total Iteration Time: 4.93138

Cumulative Model Updates: 15,438
Cumulative Timesteps: 128,847,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 128847746...
Checkpoint 128847746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,661.06845
Policy Entropy: 1.20824
Value Function Loss: 0.10487

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.29990
Value Function Update Magnitude: 0.63499

Collected Steps per Second: 20,913.36233
Overall Steps per Second: 10,127.14676

Timestep Collection Time: 2.39158
Timestep Consumption Time: 2.54722
PPO Batch Consumption Time: 0.30112
Total Iteration Time: 4.93880

Cumulative Model Updates: 15,444
Cumulative Timesteps: 128,897,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,449.71203
Policy Entropy: 1.19978
Value Function Loss: 0.10107

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.31834
Value Function Update Magnitude: 0.63801

Collected Steps per Second: 21,069.92400
Overall Steps per Second: 10,119.45470

Timestep Collection Time: 2.37305
Timestep Consumption Time: 2.56793
PPO Batch Consumption Time: 0.30455
Total Iteration Time: 4.94098

Cumulative Model Updates: 15,450
Cumulative Timesteps: 128,947,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 128947762...
Checkpoint 128947762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.87354
Policy Entropy: 1.18307
Value Function Loss: 0.10289

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.29780
Value Function Update Magnitude: 0.68594

Collected Steps per Second: 20,702.11195
Overall Steps per Second: 10,073.06079

Timestep Collection Time: 2.41724
Timestep Consumption Time: 2.55066
PPO Batch Consumption Time: 0.30294
Total Iteration Time: 4.96790

Cumulative Model Updates: 15,456
Cumulative Timesteps: 128,997,804

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,681.63710
Policy Entropy: 1.17813
Value Function Loss: 0.10229

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.30726
Value Function Update Magnitude: 0.69896

Collected Steps per Second: 21,459.08389
Overall Steps per Second: 10,185.13092

Timestep Collection Time: 2.33151
Timestep Consumption Time: 2.58075
PPO Batch Consumption Time: 0.30684
Total Iteration Time: 4.91226

Cumulative Model Updates: 15,462
Cumulative Timesteps: 129,047,836

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 129047836...
Checkpoint 129047836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,129.91432
Policy Entropy: 1.17791
Value Function Loss: 0.10602

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07057
Policy Update Magnitude: 0.33180
Value Function Update Magnitude: 0.68668

Collected Steps per Second: 20,870.38612
Overall Steps per Second: 10,119.39793

Timestep Collection Time: 2.39737
Timestep Consumption Time: 2.54700
PPO Batch Consumption Time: 0.30152
Total Iteration Time: 4.94437

Cumulative Model Updates: 15,468
Cumulative Timesteps: 129,097,870

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,275.18378
Policy Entropy: 1.17104
Value Function Loss: 0.10670

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06700
Policy Update Magnitude: 0.33949
Value Function Update Magnitude: 0.59866

Collected Steps per Second: 21,503.83824
Overall Steps per Second: 10,121.11595

Timestep Collection Time: 2.32517
Timestep Consumption Time: 2.61500
PPO Batch Consumption Time: 0.31252
Total Iteration Time: 4.94017

Cumulative Model Updates: 15,474
Cumulative Timesteps: 129,147,870

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 129147870...
Checkpoint 129147870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.91141
Policy Entropy: 1.17503
Value Function Loss: 0.10493

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.32330
Value Function Update Magnitude: 0.61107

Collected Steps per Second: 21,064.89062
Overall Steps per Second: 10,154.02395

Timestep Collection Time: 2.37419
Timestep Consumption Time: 2.55115
PPO Batch Consumption Time: 0.30018
Total Iteration Time: 4.92534

Cumulative Model Updates: 15,480
Cumulative Timesteps: 129,197,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,233.85277
Policy Entropy: 1.17842
Value Function Loss: 0.10222

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.27485
Value Function Update Magnitude: 0.66636

Collected Steps per Second: 21,416.86697
Overall Steps per Second: 10,110.74667

Timestep Collection Time: 2.33470
Timestep Consumption Time: 2.61073
PPO Batch Consumption Time: 0.31459
Total Iteration Time: 4.94543

Cumulative Model Updates: 15,486
Cumulative Timesteps: 129,247,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 129247884...
Checkpoint 129247884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,635.60003
Policy Entropy: 1.17744
Value Function Loss: 0.10180

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.16621
Policy Update Magnitude: 0.25100
Value Function Update Magnitude: 0.64285

Collected Steps per Second: 20,900.39916
Overall Steps per Second: 10,125.85099

Timestep Collection Time: 2.39239
Timestep Consumption Time: 2.54566
PPO Batch Consumption Time: 0.30084
Total Iteration Time: 4.93805

Cumulative Model Updates: 15,492
Cumulative Timesteps: 129,297,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,778.91643
Policy Entropy: 1.17441
Value Function Loss: 0.10674

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.14736
Policy Update Magnitude: 0.23320
Value Function Update Magnitude: 0.53981

Collected Steps per Second: 21,252.12023
Overall Steps per Second: 10,102.22994

Timestep Collection Time: 2.35346
Timestep Consumption Time: 2.59753
PPO Batch Consumption Time: 0.30902
Total Iteration Time: 4.95099

Cumulative Model Updates: 15,498
Cumulative Timesteps: 129,347,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 129347902...
Checkpoint 129347902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,029.96601
Policy Entropy: 1.15685
Value Function Loss: 0.11121

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11071
Policy Update Magnitude: 0.24008
Value Function Update Magnitude: 0.57034

Collected Steps per Second: 19,729.22378
Overall Steps per Second: 9,700.18812

Timestep Collection Time: 2.53492
Timestep Consumption Time: 2.62086
PPO Batch Consumption Time: 0.31161
Total Iteration Time: 5.15578

Cumulative Model Updates: 15,504
Cumulative Timesteps: 129,397,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,195.88132
Policy Entropy: 1.14315
Value Function Loss: 0.11691

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.24144
Value Function Update Magnitude: 0.51236

Collected Steps per Second: 21,305.84251
Overall Steps per Second: 10,185.40194

Timestep Collection Time: 2.34687
Timestep Consumption Time: 2.56231
PPO Batch Consumption Time: 0.30125
Total Iteration Time: 4.90918

Cumulative Model Updates: 15,510
Cumulative Timesteps: 129,447,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 129447916...
Checkpoint 129447916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,880.28327
Policy Entropy: 1.15434
Value Function Loss: 0.11648

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11755
Policy Update Magnitude: 0.25110
Value Function Update Magnitude: 0.50102

Collected Steps per Second: 21,035.23067
Overall Steps per Second: 10,146.29300

Timestep Collection Time: 2.37725
Timestep Consumption Time: 2.55125
PPO Batch Consumption Time: 0.30048
Total Iteration Time: 4.92850

Cumulative Model Updates: 15,516
Cumulative Timesteps: 129,497,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,262.71934
Policy Entropy: 1.15936
Value Function Loss: 0.11880

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.25786
Value Function Update Magnitude: 0.52832

Collected Steps per Second: 21,221.63477
Overall Steps per Second: 10,067.67034

Timestep Collection Time: 2.35769
Timestep Consumption Time: 2.61208
PPO Batch Consumption Time: 0.31227
Total Iteration Time: 4.96977

Cumulative Model Updates: 15,522
Cumulative Timesteps: 129,547,956

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 129547956...
Checkpoint 129547956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,909.10140
Policy Entropy: 1.16645
Value Function Loss: 0.12039

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.16762
Policy Update Magnitude: 0.24542
Value Function Update Magnitude: 0.54794

Collected Steps per Second: 20,965.13644
Overall Steps per Second: 10,115.66237

Timestep Collection Time: 2.38596
Timestep Consumption Time: 2.55904
PPO Batch Consumption Time: 0.30074
Total Iteration Time: 4.94500

Cumulative Model Updates: 15,528
Cumulative Timesteps: 129,597,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,967.90223
Policy Entropy: 1.17219
Value Function Loss: 0.12037

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.15594
Policy Update Magnitude: 0.28637
Value Function Update Magnitude: 0.53326

Collected Steps per Second: 21,509.39397
Overall Steps per Second: 10,333.78523

Timestep Collection Time: 2.32577
Timestep Consumption Time: 2.51524
PPO Batch Consumption Time: 0.30798
Total Iteration Time: 4.84101

Cumulative Model Updates: 15,534
Cumulative Timesteps: 129,648,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 129648004...
Checkpoint 129648004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,053.00977
Policy Entropy: 1.18887
Value Function Loss: 0.11446

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.12001
Policy Update Magnitude: 0.32205
Value Function Update Magnitude: 0.48648

Collected Steps per Second: 19,932.81434
Overall Steps per Second: 9,992.85714

Timestep Collection Time: 2.50893
Timestep Consumption Time: 2.49565
PPO Batch Consumption Time: 0.30052
Total Iteration Time: 5.00457

Cumulative Model Updates: 15,540
Cumulative Timesteps: 129,698,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,695.63008
Policy Entropy: 1.18264
Value Function Loss: 0.11021

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.14753
Policy Update Magnitude: 0.31591
Value Function Update Magnitude: 0.48680

Collected Steps per Second: 20,988.48541
Overall Steps per Second: 10,146.23112

Timestep Collection Time: 2.38331
Timestep Consumption Time: 2.54680
PPO Batch Consumption Time: 0.31062
Total Iteration Time: 4.93011

Cumulative Model Updates: 15,546
Cumulative Timesteps: 129,748,036

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 129748036...
Checkpoint 129748036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,488.58221
Policy Entropy: 1.17595
Value Function Loss: 0.11191

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.32598
Value Function Update Magnitude: 0.49492

Collected Steps per Second: 20,012.20163
Overall Steps per Second: 9,988.94074

Timestep Collection Time: 2.49918
Timestep Consumption Time: 2.50776
PPO Batch Consumption Time: 0.30256
Total Iteration Time: 5.00694

Cumulative Model Updates: 15,552
Cumulative Timesteps: 129,798,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,934.60262
Policy Entropy: 1.17745
Value Function Loss: 0.10971

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.34621
Value Function Update Magnitude: 0.50029

Collected Steps per Second: 20,662.72099
Overall Steps per Second: 10,180.62901

Timestep Collection Time: 2.42020
Timestep Consumption Time: 2.49187
PPO Batch Consumption Time: 0.30078
Total Iteration Time: 4.91207

Cumulative Model Updates: 15,558
Cumulative Timesteps: 129,848,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 129848058...
Checkpoint 129848058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.12710
Policy Entropy: 1.17562
Value Function Loss: 0.10918

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.14728
Policy Update Magnitude: 0.30592
Value Function Update Magnitude: 0.49286

Collected Steps per Second: 20,274.79566
Overall Steps per Second: 10,055.02957

Timestep Collection Time: 2.46612
Timestep Consumption Time: 2.50652
PPO Batch Consumption Time: 0.30387
Total Iteration Time: 4.97264

Cumulative Model Updates: 15,564
Cumulative Timesteps: 129,898,058

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,684.04294
Policy Entropy: 1.18159
Value Function Loss: 0.11253

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.12242
Policy Update Magnitude: 0.28095
Value Function Update Magnitude: 0.47748

Collected Steps per Second: 20,716.57017
Overall Steps per Second: 10,192.72624

Timestep Collection Time: 2.41440
Timestep Consumption Time: 2.49283
PPO Batch Consumption Time: 0.30096
Total Iteration Time: 4.90722

Cumulative Model Updates: 15,570
Cumulative Timesteps: 129,948,076

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 129948076...
Checkpoint 129948076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,688.40478
Policy Entropy: 1.18222
Value Function Loss: 0.11013

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.27886
Value Function Update Magnitude: 0.50949

Collected Steps per Second: 20,076.00678
Overall Steps per Second: 9,934.54403

Timestep Collection Time: 2.49322
Timestep Consumption Time: 2.54515
PPO Batch Consumption Time: 0.30953
Total Iteration Time: 5.03838

Cumulative Model Updates: 15,576
Cumulative Timesteps: 129,998,130

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,469.16317
Policy Entropy: 1.19200
Value Function Loss: 0.10858

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.32157
Value Function Update Magnitude: 0.56151

Collected Steps per Second: 20,810.31127
Overall Steps per Second: 10,218.89812

Timestep Collection Time: 2.40304
Timestep Consumption Time: 2.49064
PPO Batch Consumption Time: 0.29953
Total Iteration Time: 4.89368

Cumulative Model Updates: 15,582
Cumulative Timesteps: 130,048,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 130048138...
Checkpoint 130048138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,142.25125
Policy Entropy: 1.19301
Value Function Loss: 0.10463

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07220
Policy Update Magnitude: 0.33271
Value Function Update Magnitude: 0.55646

Collected Steps per Second: 19,824.70826
Overall Steps per Second: 9,871.16642

Timestep Collection Time: 2.52281
Timestep Consumption Time: 2.54386
PPO Batch Consumption Time: 0.30878
Total Iteration Time: 5.06668

Cumulative Model Updates: 15,588
Cumulative Timesteps: 130,098,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,584.96355
Policy Entropy: 1.19889
Value Function Loss: 0.10480

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08589
Policy Update Magnitude: 0.32577
Value Function Update Magnitude: 0.49953

Collected Steps per Second: 20,814.81917
Overall Steps per Second: 10,061.64397

Timestep Collection Time: 2.40233
Timestep Consumption Time: 2.56744
PPO Batch Consumption Time: 0.31426
Total Iteration Time: 4.96976

Cumulative Model Updates: 15,594
Cumulative Timesteps: 130,148,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 130148156...
Checkpoint 130148156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,103.00172
Policy Entropy: 1.19596
Value Function Loss: 0.10353

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.12123
Policy Update Magnitude: 0.28835
Value Function Update Magnitude: 0.47812

Collected Steps per Second: 20,172.60405
Overall Steps per Second: 9,913.44518

Timestep Collection Time: 2.48039
Timestep Consumption Time: 2.56689
PPO Batch Consumption Time: 0.31299
Total Iteration Time: 5.04729

Cumulative Model Updates: 15,600
Cumulative Timesteps: 130,198,192

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,626.00378
Policy Entropy: 1.19702
Value Function Loss: 0.10253

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.14961
Policy Update Magnitude: 0.25479
Value Function Update Magnitude: 0.46288

Collected Steps per Second: 20,730.73972
Overall Steps per Second: 10,108.51508

Timestep Collection Time: 2.41294
Timestep Consumption Time: 2.53556
PPO Batch Consumption Time: 0.30845
Total Iteration Time: 4.94850

Cumulative Model Updates: 15,606
Cumulative Timesteps: 130,248,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 130248214...
Checkpoint 130248214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,482.12596
Policy Entropy: 1.19198
Value Function Loss: 0.10388

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.24895
Value Function Update Magnitude: 0.47585

Collected Steps per Second: 20,109.74947
Overall Steps per Second: 10,041.39169

Timestep Collection Time: 2.48785
Timestep Consumption Time: 2.49453
PPO Batch Consumption Time: 0.30046
Total Iteration Time: 4.98238

Cumulative Model Updates: 15,612
Cumulative Timesteps: 130,298,244

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,199.56690
Policy Entropy: 1.18802
Value Function Loss: 0.11164

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.22644
Value Function Update Magnitude: 0.46723

Collected Steps per Second: 21,740.54357
Overall Steps per Second: 10,180.89433

Timestep Collection Time: 2.29985
Timestep Consumption Time: 2.61131
PPO Batch Consumption Time: 0.30952
Total Iteration Time: 4.91116

Cumulative Model Updates: 15,618
Cumulative Timesteps: 130,348,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 130348244...
Checkpoint 130348244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,104.24783
Policy Entropy: 1.18180
Value Function Loss: 0.11086

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.23506
Value Function Update Magnitude: 0.50691

Collected Steps per Second: 20,163.31682
Overall Steps per Second: 10,046.17324

Timestep Collection Time: 2.48124
Timestep Consumption Time: 2.49877
PPO Batch Consumption Time: 0.30128
Total Iteration Time: 4.98001

Cumulative Model Updates: 15,624
Cumulative Timesteps: 130,398,274

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,509.86154
Policy Entropy: 1.18191
Value Function Loss: 0.11096

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11916
Policy Update Magnitude: 0.24184
Value Function Update Magnitude: 0.49809

Collected Steps per Second: 21,097.17993
Overall Steps per Second: 10,176.49018

Timestep Collection Time: 2.37017
Timestep Consumption Time: 2.54350
PPO Batch Consumption Time: 0.31153
Total Iteration Time: 4.91368

Cumulative Model Updates: 15,630
Cumulative Timesteps: 130,448,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 130448278...
Checkpoint 130448278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,782.66867
Policy Entropy: 1.17455
Value Function Loss: 0.10590

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08065
Policy Update Magnitude: 0.28088
Value Function Update Magnitude: 0.51978

Collected Steps per Second: 20,416.77869
Overall Steps per Second: 9,952.92902

Timestep Collection Time: 2.45004
Timestep Consumption Time: 2.57581
PPO Batch Consumption Time: 0.30270
Total Iteration Time: 5.02586

Cumulative Model Updates: 15,636
Cumulative Timesteps: 130,498,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,297.74391
Policy Entropy: 1.17434
Value Function Loss: 0.10548

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.32220
Value Function Update Magnitude: 0.51449

Collected Steps per Second: 20,923.09474
Overall Steps per Second: 10,159.73960

Timestep Collection Time: 2.39009
Timestep Consumption Time: 2.53209
PPO Batch Consumption Time: 0.30511
Total Iteration Time: 4.92217

Cumulative Model Updates: 15,642
Cumulative Timesteps: 130,548,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 130548308...
Checkpoint 130548308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.97437
Policy Entropy: 1.17901
Value Function Loss: 0.10975

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.32473
Value Function Update Magnitude: 0.57587

Collected Steps per Second: 20,969.92067
Overall Steps per Second: 10,000.05358

Timestep Collection Time: 2.38523
Timestep Consumption Time: 2.61655
PPO Batch Consumption Time: 0.30842
Total Iteration Time: 5.00177

Cumulative Model Updates: 15,648
Cumulative Timesteps: 130,598,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,045.15771
Policy Entropy: 1.17386
Value Function Loss: 0.10711

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.29963
Value Function Update Magnitude: 0.68454

Collected Steps per Second: 19,887.98609
Overall Steps per Second: 9,715.52024

Timestep Collection Time: 2.51408
Timestep Consumption Time: 2.63232
PPO Batch Consumption Time: 0.30924
Total Iteration Time: 5.14640

Cumulative Model Updates: 15,654
Cumulative Timesteps: 130,648,326

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 130648326...
Checkpoint 130648326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,823.71205
Policy Entropy: 1.17212
Value Function Loss: 0.10911

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.31355
Value Function Update Magnitude: 0.71699

Collected Steps per Second: 20,856.10380
Overall Steps per Second: 9,945.48466

Timestep Collection Time: 2.39949
Timestep Consumption Time: 2.63234
PPO Batch Consumption Time: 0.30748
Total Iteration Time: 5.03183

Cumulative Model Updates: 15,660
Cumulative Timesteps: 130,698,370

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,278.06097
Policy Entropy: 1.17714
Value Function Loss: 0.10615

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07667
Policy Update Magnitude: 0.33453
Value Function Update Magnitude: 0.71256

Collected Steps per Second: 21,514.98431
Overall Steps per Second: 10,064.79936

Timestep Collection Time: 2.32536
Timestep Consumption Time: 2.64543
PPO Batch Consumption Time: 0.31074
Total Iteration Time: 4.97079

Cumulative Model Updates: 15,666
Cumulative Timesteps: 130,748,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 130748400...
Checkpoint 130748400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364.22509
Policy Entropy: 1.18044
Value Function Loss: 0.10693

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07988
Policy Update Magnitude: 0.34069
Value Function Update Magnitude: 0.70946

Collected Steps per Second: 20,891.98911
Overall Steps per Second: 9,961.44317

Timestep Collection Time: 2.39412
Timestep Consumption Time: 2.62704
PPO Batch Consumption Time: 0.30937
Total Iteration Time: 5.02116

Cumulative Model Updates: 15,672
Cumulative Timesteps: 130,798,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,338.23656
Policy Entropy: 1.18840
Value Function Loss: 0.10925

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08704
Policy Update Magnitude: 0.32169
Value Function Update Magnitude: 0.65568

Collected Steps per Second: 21,443.65097
Overall Steps per Second: 10,178.50234

Timestep Collection Time: 2.33225
Timestep Consumption Time: 2.58124
PPO Batch Consumption Time: 0.30148
Total Iteration Time: 4.91349

Cumulative Model Updates: 15,678
Cumulative Timesteps: 130,848,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 130848430...
Checkpoint 130848430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,707.84719
Policy Entropy: 1.18548
Value Function Loss: 0.10681

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08699
Policy Update Magnitude: 0.33052
Value Function Update Magnitude: 0.59004

Collected Steps per Second: 20,000.23437
Overall Steps per Second: 9,906.26959

Timestep Collection Time: 2.50037
Timestep Consumption Time: 2.54775
PPO Batch Consumption Time: 0.30876
Total Iteration Time: 5.04812

Cumulative Model Updates: 15,684
Cumulative Timesteps: 130,898,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,230.72684
Policy Entropy: 1.19411
Value Function Loss: 0.10797

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.29829
Value Function Update Magnitude: 0.58968

Collected Steps per Second: 20,972.59409
Overall Steps per Second: 10,138.22137

Timestep Collection Time: 2.38530
Timestep Consumption Time: 2.54909
PPO Batch Consumption Time: 0.31184
Total Iteration Time: 4.93440

Cumulative Model Updates: 15,690
Cumulative Timesteps: 130,948,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 130948464...
Checkpoint 130948464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,925.22017
Policy Entropy: 1.19372
Value Function Loss: 0.10332

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.28641
Value Function Update Magnitude: 0.62132

Collected Steps per Second: 20,612.35079
Overall Steps per Second: 9,978.34381

Timestep Collection Time: 2.42602
Timestep Consumption Time: 2.58543
PPO Batch Consumption Time: 0.30264
Total Iteration Time: 5.01145

Cumulative Model Updates: 15,696
Cumulative Timesteps: 130,998,470

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,904.64060
Policy Entropy: 1.19523
Value Function Loss: 0.10377

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10891
Policy Update Magnitude: 0.30108
Value Function Update Magnitude: 0.59213

Collected Steps per Second: 20,683.05102
Overall Steps per Second: 10,134.56732

Timestep Collection Time: 2.41802
Timestep Consumption Time: 2.51678
PPO Batch Consumption Time: 0.30364
Total Iteration Time: 4.93479

Cumulative Model Updates: 15,702
Cumulative Timesteps: 131,048,482

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 131048482...
Checkpoint 131048482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,541.20789
Policy Entropy: 1.18691
Value Function Loss: 0.10056

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.33341
Value Function Update Magnitude: 0.55314

Collected Steps per Second: 20,149.31587
Overall Steps per Second: 9,956.38369

Timestep Collection Time: 2.48227
Timestep Consumption Time: 2.54124
PPO Batch Consumption Time: 0.31113
Total Iteration Time: 5.02351

Cumulative Model Updates: 15,708
Cumulative Timesteps: 131,098,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,155.80621
Policy Entropy: 1.18988
Value Function Loss: 0.09901

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.35274
Value Function Update Magnitude: 0.64661

Collected Steps per Second: 20,666.66570
Overall Steps per Second: 10,092.86143

Timestep Collection Time: 2.41955
Timestep Consumption Time: 2.53484
PPO Batch Consumption Time: 0.30870
Total Iteration Time: 4.95439

Cumulative Model Updates: 15,714
Cumulative Timesteps: 131,148,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 131148502...
Checkpoint 131148502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,226.33033
Policy Entropy: 1.18532
Value Function Loss: 0.09884

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07843
Policy Update Magnitude: 0.34889
Value Function Update Magnitude: 0.71198

Collected Steps per Second: 20,658.08466
Overall Steps per Second: 10,003.30090

Timestep Collection Time: 2.42094
Timestep Consumption Time: 2.57861
PPO Batch Consumption Time: 0.30093
Total Iteration Time: 4.99955

Cumulative Model Updates: 15,720
Cumulative Timesteps: 131,198,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,750.92075
Policy Entropy: 1.18881
Value Function Loss: 0.10153

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10014
Policy Update Magnitude: 0.32821
Value Function Update Magnitude: 0.71647

Collected Steps per Second: 20,905.04045
Overall Steps per Second: 10,082.28375

Timestep Collection Time: 2.39234
Timestep Consumption Time: 2.56804
PPO Batch Consumption Time: 0.31453
Total Iteration Time: 4.96038

Cumulative Model Updates: 15,726
Cumulative Timesteps: 131,248,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 131248526...
Checkpoint 131248526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,049.30496
Policy Entropy: 1.17308
Value Function Loss: 0.09773

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.31379
Value Function Update Magnitude: 0.71937

Collected Steps per Second: 19,982.94776
Overall Steps per Second: 9,940.73092

Timestep Collection Time: 2.50383
Timestep Consumption Time: 2.52940
PPO Batch Consumption Time: 0.30982
Total Iteration Time: 5.03323

Cumulative Model Updates: 15,732
Cumulative Timesteps: 131,298,560

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,625.90832
Policy Entropy: 1.17930
Value Function Loss: 0.09760

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.29138
Value Function Update Magnitude: 0.70579

Collected Steps per Second: 19,986.32246
Overall Steps per Second: 9,876.23777

Timestep Collection Time: 2.50381
Timestep Consumption Time: 2.56310
PPO Batch Consumption Time: 0.31131
Total Iteration Time: 5.06691

Cumulative Model Updates: 15,738
Cumulative Timesteps: 131,348,602

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 131348602...
Checkpoint 131348602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,257.78022
Policy Entropy: 1.17237
Value Function Loss: 0.09685

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12072
Policy Update Magnitude: 0.29128
Value Function Update Magnitude: 0.61229

Collected Steps per Second: 20,987.06787
Overall Steps per Second: 10,055.73485

Timestep Collection Time: 2.38280
Timestep Consumption Time: 2.59028
PPO Batch Consumption Time: 0.30336
Total Iteration Time: 4.97308

Cumulative Model Updates: 15,744
Cumulative Timesteps: 131,398,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,489.59927
Policy Entropy: 1.17880
Value Function Loss: 0.10047

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11997
Policy Update Magnitude: 0.29770
Value Function Update Magnitude: 0.61570

Collected Steps per Second: 21,270.80741
Overall Steps per Second: 10,145.37814

Timestep Collection Time: 2.35139
Timestep Consumption Time: 2.57854
PPO Batch Consumption Time: 0.30044
Total Iteration Time: 4.92993

Cumulative Model Updates: 15,750
Cumulative Timesteps: 131,448,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 131448626...
Checkpoint 131448626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,700.82048
Policy Entropy: 1.17943
Value Function Loss: 0.10259

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.28199
Value Function Update Magnitude: 0.61656

Collected Steps per Second: 20,998.41099
Overall Steps per Second: 10,009.00835

Timestep Collection Time: 2.38123
Timestep Consumption Time: 2.61447
PPO Batch Consumption Time: 0.30993
Total Iteration Time: 4.99570

Cumulative Model Updates: 15,756
Cumulative Timesteps: 131,498,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,099.37552
Policy Entropy: 1.18636
Value Function Loss: 0.10478

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.26251
Value Function Update Magnitude: 0.59791

Collected Steps per Second: 20,413.91694
Overall Steps per Second: 10,015.55162

Timestep Collection Time: 2.44990
Timestep Consumption Time: 2.54354
PPO Batch Consumption Time: 0.30984
Total Iteration Time: 4.99343

Cumulative Model Updates: 15,762
Cumulative Timesteps: 131,548,640

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 131548640...
Checkpoint 131548640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,351.69613
Policy Entropy: 1.18613
Value Function Loss: 0.10514

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.26848
Value Function Update Magnitude: 0.57569

Collected Steps per Second: 20,036.57215
Overall Steps per Second: 9,888.38559

Timestep Collection Time: 2.49643
Timestep Consumption Time: 2.56202
PPO Batch Consumption Time: 0.30081
Total Iteration Time: 5.05846

Cumulative Model Updates: 15,768
Cumulative Timesteps: 131,598,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,379.79613
Policy Entropy: 1.17648
Value Function Loss: 0.10408

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.13892
Policy Update Magnitude: 0.27572
Value Function Update Magnitude: 0.56273

Collected Steps per Second: 20,458.09707
Overall Steps per Second: 10,096.15088

Timestep Collection Time: 2.44422
Timestep Consumption Time: 2.50856
PPO Batch Consumption Time: 0.30297
Total Iteration Time: 4.95278

Cumulative Model Updates: 15,774
Cumulative Timesteps: 131,648,664

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 131648664...
Checkpoint 131648664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,119.09831
Policy Entropy: 1.18451
Value Function Loss: 0.10183

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.15148
Policy Update Magnitude: 0.28263
Value Function Update Magnitude: 0.59203

Collected Steps per Second: 20,178.74957
Overall Steps per Second: 9,946.57260

Timestep Collection Time: 2.47974
Timestep Consumption Time: 2.55094
PPO Batch Consumption Time: 0.30979
Total Iteration Time: 5.03068

Cumulative Model Updates: 15,780
Cumulative Timesteps: 131,698,702

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,510.60031
Policy Entropy: 1.18325
Value Function Loss: 0.09794

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.17560
Policy Update Magnitude: 0.25548
Value Function Update Magnitude: 0.57095

Collected Steps per Second: 20,901.94627
Overall Steps per Second: 10,112.99612

Timestep Collection Time: 2.39298
Timestep Consumption Time: 2.55293
PPO Batch Consumption Time: 0.31183
Total Iteration Time: 4.94591

Cumulative Model Updates: 15,786
Cumulative Timesteps: 131,748,720

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 131748720...
Checkpoint 131748720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,941.42974
Policy Entropy: 1.18156
Value Function Loss: 0.09584

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13725
Policy Update Magnitude: 0.28024
Value Function Update Magnitude: 0.53444

Collected Steps per Second: 20,243.38450
Overall Steps per Second: 10,059.36858

Timestep Collection Time: 2.47044
Timestep Consumption Time: 2.50105
PPO Batch Consumption Time: 0.30125
Total Iteration Time: 4.97149

Cumulative Model Updates: 15,792
Cumulative Timesteps: 131,798,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,398.77392
Policy Entropy: 1.17395
Value Function Loss: 0.09666

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.14726
Policy Update Magnitude: 0.27878
Value Function Update Magnitude: 0.53231

Collected Steps per Second: 20,822.34356
Overall Steps per Second: 10,107.28781

Timestep Collection Time: 2.40261
Timestep Consumption Time: 2.54708
PPO Batch Consumption Time: 0.30906
Total Iteration Time: 4.94970

Cumulative Model Updates: 15,798
Cumulative Timesteps: 131,848,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 131848758...
Checkpoint 131848758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,516.61793
Policy Entropy: 1.16924
Value Function Loss: 0.10390

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.27767
Value Function Update Magnitude: 0.57292

Collected Steps per Second: 20,355.73749
Overall Steps per Second: 9,911.64111

Timestep Collection Time: 2.45739
Timestep Consumption Time: 2.58940
PPO Batch Consumption Time: 0.31511
Total Iteration Time: 5.04679

Cumulative Model Updates: 15,804
Cumulative Timesteps: 131,898,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,003.56102
Policy Entropy: 1.16211
Value Function Loss: 0.10358

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.28570
Value Function Update Magnitude: 0.68255

Collected Steps per Second: 20,694.11037
Overall Steps per Second: 10,033.88145

Timestep Collection Time: 2.41702
Timestep Consumption Time: 2.56789
PPO Batch Consumption Time: 0.31129
Total Iteration Time: 4.98491

Cumulative Model Updates: 15,810
Cumulative Timesteps: 131,948,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 131948798...
Checkpoint 131948798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,704.79223
Policy Entropy: 1.15717
Value Function Loss: 0.11163

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.29661
Value Function Update Magnitude: 0.64987

Collected Steps per Second: 20,020.57523
Overall Steps per Second: 9,978.78262

Timestep Collection Time: 2.49883
Timestep Consumption Time: 2.51461
PPO Batch Consumption Time: 0.30240
Total Iteration Time: 5.01344

Cumulative Model Updates: 15,816
Cumulative Timesteps: 131,998,826

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,131.44414
Policy Entropy: 1.15179
Value Function Loss: 0.11237

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.27899
Value Function Update Magnitude: 0.60517

Collected Steps per Second: 21,481.93474
Overall Steps per Second: 10,176.41839

Timestep Collection Time: 2.32782
Timestep Consumption Time: 2.58609
PPO Batch Consumption Time: 0.30312
Total Iteration Time: 4.91391

Cumulative Model Updates: 15,822
Cumulative Timesteps: 132,048,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 132048832...
Checkpoint 132048832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,938.59298
Policy Entropy: 1.15560
Value Function Loss: 0.11361

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.25486
Value Function Update Magnitude: 0.57007

Collected Steps per Second: 21,029.18239
Overall Steps per Second: 10,111.90767

Timestep Collection Time: 2.37907
Timestep Consumption Time: 2.56856
PPO Batch Consumption Time: 0.30122
Total Iteration Time: 4.94763

Cumulative Model Updates: 15,828
Cumulative Timesteps: 132,098,862

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.71956
Policy Entropy: 1.16234
Value Function Loss: 0.11605

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.13797
Policy Update Magnitude: 0.23722
Value Function Update Magnitude: 0.51011

Collected Steps per Second: 21,037.89767
Overall Steps per Second: 10,101.67250

Timestep Collection Time: 2.37676
Timestep Consumption Time: 2.57312
PPO Batch Consumption Time: 0.31499
Total Iteration Time: 4.94987

Cumulative Model Updates: 15,834
Cumulative Timesteps: 132,148,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 132148864...
Checkpoint 132148864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,714.62330
Policy Entropy: 1.16879
Value Function Loss: 0.11371

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12183
Policy Update Magnitude: 0.24975
Value Function Update Magnitude: 0.47600

Collected Steps per Second: 21,141.90199
Overall Steps per Second: 10,101.28105

Timestep Collection Time: 2.36544
Timestep Consumption Time: 2.58541
PPO Batch Consumption Time: 0.30310
Total Iteration Time: 4.95086

Cumulative Model Updates: 15,840
Cumulative Timesteps: 132,198,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.96013
Policy Entropy: 1.15826
Value Function Loss: 0.11641

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.11657
Policy Update Magnitude: 0.25845
Value Function Update Magnitude: 0.46610

Collected Steps per Second: 21,664.86740
Overall Steps per Second: 10,184.42446

Timestep Collection Time: 2.30871
Timestep Consumption Time: 2.60251
PPO Batch Consumption Time: 0.30639
Total Iteration Time: 4.91122

Cumulative Model Updates: 15,846
Cumulative Timesteps: 132,248,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 132248892...
Checkpoint 132248892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,149.95981
Policy Entropy: 1.16216
Value Function Loss: 0.11080

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11308
Policy Update Magnitude: 0.26677
Value Function Update Magnitude: 0.50216

Collected Steps per Second: 20,895.13198
Overall Steps per Second: 10,067.64626

Timestep Collection Time: 2.39319
Timestep Consumption Time: 2.57381
PPO Batch Consumption Time: 0.30268
Total Iteration Time: 4.96700

Cumulative Model Updates: 15,852
Cumulative Timesteps: 132,298,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,335.90391
Policy Entropy: 1.17037
Value Function Loss: 0.10725

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.11751
Policy Update Magnitude: 0.27897
Value Function Update Magnitude: 0.53482

Collected Steps per Second: 21,612.67050
Overall Steps per Second: 10,158.21365

Timestep Collection Time: 2.31383
Timestep Consumption Time: 2.60908
PPO Batch Consumption Time: 0.30790
Total Iteration Time: 4.92291

Cumulative Model Updates: 15,858
Cumulative Timesteps: 132,348,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 132348906...
Checkpoint 132348906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,240.53539
Policy Entropy: 1.18065
Value Function Loss: 0.10247

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.30431
Value Function Update Magnitude: 0.61244

Collected Steps per Second: 20,685.50830
Overall Steps per Second: 9,939.16253

Timestep Collection Time: 2.41744
Timestep Consumption Time: 2.61377
PPO Batch Consumption Time: 0.31104
Total Iteration Time: 5.03121

Cumulative Model Updates: 15,864
Cumulative Timesteps: 132,398,912

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,126.22599
Policy Entropy: 1.17610
Value Function Loss: 0.10217

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10096
Policy Update Magnitude: 0.31954
Value Function Update Magnitude: 0.62085

Collected Steps per Second: 21,669.81387
Overall Steps per Second: 10,287.24930

Timestep Collection Time: 2.30819
Timestep Consumption Time: 2.55395
PPO Batch Consumption Time: 0.29967
Total Iteration Time: 4.86214

Cumulative Model Updates: 15,870
Cumulative Timesteps: 132,448,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 132448930...
Checkpoint 132448930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.72235
Policy Entropy: 1.16900
Value Function Loss: 0.10581

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11785
Policy Update Magnitude: 0.29894
Value Function Update Magnitude: 0.66207

Collected Steps per Second: 20,931.99455
Overall Steps per Second: 10,014.27515

Timestep Collection Time: 2.38869
Timestep Consumption Time: 2.60418
PPO Batch Consumption Time: 0.30799
Total Iteration Time: 4.99287

Cumulative Model Updates: 15,876
Cumulative Timesteps: 132,498,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,810.94141
Policy Entropy: 1.16575
Value Function Loss: 0.11182

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.24246
Value Function Update Magnitude: 0.66608

Collected Steps per Second: 21,508.76393
Overall Steps per Second: 10,223.63193

Timestep Collection Time: 2.32538
Timestep Consumption Time: 2.56682
PPO Batch Consumption Time: 0.29979
Total Iteration Time: 4.89219

Cumulative Model Updates: 15,882
Cumulative Timesteps: 132,548,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 132548946...
Checkpoint 132548946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,367.89100
Policy Entropy: 1.16821
Value Function Loss: 0.11549

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.23796
Value Function Update Magnitude: 0.60861

Collected Steps per Second: 20,798.88682
Overall Steps per Second: 9,959.90213

Timestep Collection Time: 2.40494
Timestep Consumption Time: 2.61720
PPO Batch Consumption Time: 0.31109
Total Iteration Time: 5.02214

Cumulative Model Updates: 15,888
Cumulative Timesteps: 132,598,966

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,468.61100
Policy Entropy: 1.17675
Value Function Loss: 0.11642

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12152
Policy Update Magnitude: 0.22540
Value Function Update Magnitude: 0.66131

Collected Steps per Second: 21,539.98723
Overall Steps per Second: 10,213.64664

Timestep Collection Time: 2.32247
Timestep Consumption Time: 2.57549
PPO Batch Consumption Time: 0.30061
Total Iteration Time: 4.89796

Cumulative Model Updates: 15,894
Cumulative Timesteps: 132,648,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 132648992...
Checkpoint 132648992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,766.20871
Policy Entropy: 1.16810
Value Function Loss: 0.11281

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09166
Policy Update Magnitude: 0.26613
Value Function Update Magnitude: 0.71402

Collected Steps per Second: 20,754.30693
Overall Steps per Second: 9,926.11404

Timestep Collection Time: 2.40972
Timestep Consumption Time: 2.62871
PPO Batch Consumption Time: 0.30976
Total Iteration Time: 5.03843

Cumulative Model Updates: 15,900
Cumulative Timesteps: 132,699,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,307.58566
Policy Entropy: 1.16704
Value Function Loss: 0.11101

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10675
Policy Update Magnitude: 0.30454
Value Function Update Magnitude: 0.66877

Collected Steps per Second: 21,522.09955
Overall Steps per Second: 10,113.60237

Timestep Collection Time: 2.32347
Timestep Consumption Time: 2.62096
PPO Batch Consumption Time: 0.31166
Total Iteration Time: 4.94443

Cumulative Model Updates: 15,906
Cumulative Timesteps: 132,749,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 132749010...
Checkpoint 132749010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.74947
Policy Entropy: 1.15971
Value Function Loss: 0.11180

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.32348
Value Function Update Magnitude: 0.57920

Collected Steps per Second: 20,573.19697
Overall Steps per Second: 9,969.04761

Timestep Collection Time: 2.43151
Timestep Consumption Time: 2.58642
PPO Batch Consumption Time: 0.30310
Total Iteration Time: 5.01793

Cumulative Model Updates: 15,912
Cumulative Timesteps: 132,799,034

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,309.58031
Policy Entropy: 1.16188
Value Function Loss: 0.10951

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.32858
Value Function Update Magnitude: 0.57307

Collected Steps per Second: 21,439.00914
Overall Steps per Second: 10,437.58063

Timestep Collection Time: 2.33248
Timestep Consumption Time: 2.45848
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.79096

Cumulative Model Updates: 15,918
Cumulative Timesteps: 132,849,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 132849040...
Checkpoint 132849040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,425.96053
Policy Entropy: 1.16456
Value Function Loss: 0.11321

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09192
Policy Update Magnitude: 0.31753
Value Function Update Magnitude: 0.63162

Collected Steps per Second: 21,752.45434
Overall Steps per Second: 10,182.04782

Timestep Collection Time: 2.29923
Timestep Consumption Time: 2.61274
PPO Batch Consumption Time: 0.31058
Total Iteration Time: 4.91198

Cumulative Model Updates: 15,924
Cumulative Timesteps: 132,899,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,280.78308
Policy Entropy: 1.17439
Value Function Loss: 0.10698

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08187
Policy Update Magnitude: 0.32222
Value Function Update Magnitude: 0.65245

Collected Steps per Second: 21,169.63257
Overall Steps per Second: 10,298.14936

Timestep Collection Time: 2.36291
Timestep Consumption Time: 2.49446
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.85738

Cumulative Model Updates: 15,930
Cumulative Timesteps: 132,949,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 132949076...
Checkpoint 132949076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.52123
Policy Entropy: 1.17648
Value Function Loss: 0.10813

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07974
Policy Update Magnitude: 0.32011
Value Function Update Magnitude: 0.66929

Collected Steps per Second: 21,072.71054
Overall Steps per Second: 9,601.58382

Timestep Collection Time: 2.37274
Timestep Consumption Time: 2.83474
PPO Batch Consumption Time: 0.34814
Total Iteration Time: 5.20747

Cumulative Model Updates: 15,936
Cumulative Timesteps: 132,999,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,393.90714
Policy Entropy: 1.15562
Value Function Loss: 0.10729

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.29361
Value Function Update Magnitude: 0.65730

Collected Steps per Second: 17,752.35150
Overall Steps per Second: 8,837.26314

Timestep Collection Time: 2.81675
Timestep Consumption Time: 2.84156
PPO Batch Consumption Time: 0.34862
Total Iteration Time: 5.65831

Cumulative Model Updates: 15,942
Cumulative Timesteps: 133,049,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 133049080...
Checkpoint 133049080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,468.07848
Policy Entropy: 1.14004
Value Function Loss: 0.10912

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.26367
Value Function Update Magnitude: 0.65981

Collected Steps per Second: 17,124.16333
Overall Steps per Second: 8,412.96187

Timestep Collection Time: 2.92149
Timestep Consumption Time: 3.02505
PPO Batch Consumption Time: 0.36155
Total Iteration Time: 5.94654

Cumulative Model Updates: 15,948
Cumulative Timesteps: 133,099,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,128.54096
Policy Entropy: 1.13559
Value Function Loss: 0.10679

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.27456
Value Function Update Magnitude: 0.56477

Collected Steps per Second: 18,671.32626
Overall Steps per Second: 9,413.99181

Timestep Collection Time: 2.67812
Timestep Consumption Time: 2.63355
PPO Batch Consumption Time: 0.31244
Total Iteration Time: 5.31167

Cumulative Model Updates: 15,954
Cumulative Timesteps: 133,149,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 133149112...
Checkpoint 133149112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,088.30935
Policy Entropy: 1.16196
Value Function Loss: 0.10536

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.28339
Value Function Update Magnitude: 0.51300

Collected Steps per Second: 21,581.12909
Overall Steps per Second: 9,475.50791

Timestep Collection Time: 2.31869
Timestep Consumption Time: 2.96229
PPO Batch Consumption Time: 0.34853
Total Iteration Time: 5.28098

Cumulative Model Updates: 15,960
Cumulative Timesteps: 133,199,152

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,070.72447
Policy Entropy: 1.16068
Value Function Loss: 0.10427

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.28195
Value Function Update Magnitude: 0.49600

Collected Steps per Second: 18,608.91621
Overall Steps per Second: 9,317.43999

Timestep Collection Time: 2.68925
Timestep Consumption Time: 2.68175
PPO Batch Consumption Time: 0.31822
Total Iteration Time: 5.37100

Cumulative Model Updates: 15,966
Cumulative Timesteps: 133,249,196

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 133249196...
Checkpoint 133249196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,913.28822
Policy Entropy: 1.16895
Value Function Loss: 0.10226

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.15473
Policy Update Magnitude: 0.27007
Value Function Update Magnitude: 0.56446

Collected Steps per Second: 21,208.93563
Overall Steps per Second: 10,139.59442

Timestep Collection Time: 2.35769
Timestep Consumption Time: 2.57387
PPO Batch Consumption Time: 0.29939
Total Iteration Time: 4.93156

Cumulative Model Updates: 15,972
Cumulative Timesteps: 133,299,200

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,353.29490
Policy Entropy: 1.14415
Value Function Loss: 0.10795

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11711
Policy Update Magnitude: 0.27298
Value Function Update Magnitude: 0.63988

Collected Steps per Second: 20,809.39485
Overall Steps per Second: 10,060.61267

Timestep Collection Time: 2.40382
Timestep Consumption Time: 2.56824
PPO Batch Consumption Time: 0.29898
Total Iteration Time: 4.97206

Cumulative Model Updates: 15,978
Cumulative Timesteps: 133,349,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 133349222...
Checkpoint 133349222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,098.60106
Policy Entropy: 1.13314
Value Function Loss: 0.10805

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.29389
Value Function Update Magnitude: 0.70770

Collected Steps per Second: 21,347.70920
Overall Steps per Second: 10,232.17787

Timestep Collection Time: 2.34348
Timestep Consumption Time: 2.54580
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.88928

Cumulative Model Updates: 15,984
Cumulative Timesteps: 133,399,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,936.80749
Policy Entropy: 1.13124
Value Function Loss: 0.10618

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.26393
Value Function Update Magnitude: 0.74468

Collected Steps per Second: 21,076.88051
Overall Steps per Second: 10,077.79147

Timestep Collection Time: 2.37293
Timestep Consumption Time: 2.58986
PPO Batch Consumption Time: 0.30589
Total Iteration Time: 4.96279

Cumulative Model Updates: 15,990
Cumulative Timesteps: 133,449,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 133449264...
Checkpoint 133449264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,841.88533
Policy Entropy: 1.13341
Value Function Loss: 0.10766

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.26029
Value Function Update Magnitude: 0.70048

Collected Steps per Second: 21,604.48602
Overall Steps per Second: 10,537.87850

Timestep Collection Time: 2.31489
Timestep Consumption Time: 2.43104
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.74593

Cumulative Model Updates: 15,996
Cumulative Timesteps: 133,499,276

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,488.00252
Policy Entropy: 1.13894
Value Function Loss: 0.11147

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12430
Policy Update Magnitude: 0.32034
Value Function Update Magnitude: 0.62358

Collected Steps per Second: 21,760.14338
Overall Steps per Second: 10,380.44312

Timestep Collection Time: 2.29796
Timestep Consumption Time: 2.51917
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.81714

Cumulative Model Updates: 16,002
Cumulative Timesteps: 133,549,280

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 133549280...
Checkpoint 133549280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,708.85442
Policy Entropy: 1.13815
Value Function Loss: 0.10963

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.34681
Value Function Update Magnitude: 0.64589

Collected Steps per Second: 21,667.15988
Overall Steps per Second: 10,330.89052

Timestep Collection Time: 2.30801
Timestep Consumption Time: 2.53262
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.84063

Cumulative Model Updates: 16,008
Cumulative Timesteps: 133,599,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.28894
Policy Entropy: 1.13197
Value Function Loss: 0.10616

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.33773
Value Function Update Magnitude: 0.69123

Collected Steps per Second: 21,881.76721
Overall Steps per Second: 10,361.22354

Timestep Collection Time: 2.28501
Timestep Consumption Time: 2.54068
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.82568

Cumulative Model Updates: 16,014
Cumulative Timesteps: 133,649,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 133649288...
Checkpoint 133649288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,086.49511
Policy Entropy: 1.13219
Value Function Loss: 0.10902

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10692
Policy Update Magnitude: 0.30570
Value Function Update Magnitude: 0.62028

Collected Steps per Second: 21,540.19688
Overall Steps per Second: 10,283.34543

Timestep Collection Time: 2.32133
Timestep Consumption Time: 2.54109
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 4.86243

Cumulative Model Updates: 16,020
Cumulative Timesteps: 133,699,290

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,573.50706
Policy Entropy: 1.13985
Value Function Loss: 0.11191

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.28702
Value Function Update Magnitude: 0.56334

Collected Steps per Second: 21,625.35280
Overall Steps per Second: 10,338.66624

Timestep Collection Time: 2.31330
Timestep Consumption Time: 2.52543
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.83873

Cumulative Model Updates: 16,026
Cumulative Timesteps: 133,749,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 133749316...
Checkpoint 133749316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,020.83859
Policy Entropy: 1.15141
Value Function Loss: 0.11105

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.26736
Value Function Update Magnitude: 0.59915

Collected Steps per Second: 21,867.38323
Overall Steps per Second: 10,319.14066

Timestep Collection Time: 2.28706
Timestep Consumption Time: 2.55947
PPO Batch Consumption Time: 0.29857
Total Iteration Time: 4.84653

Cumulative Model Updates: 16,032
Cumulative Timesteps: 133,799,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,886.77515
Policy Entropy: 1.14605
Value Function Loss: 0.10681

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.25874
Value Function Update Magnitude: 0.61882

Collected Steps per Second: 21,945.69517
Overall Steps per Second: 10,424.24788

Timestep Collection Time: 2.27954
Timestep Consumption Time: 2.51947
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.79900

Cumulative Model Updates: 16,038
Cumulative Timesteps: 133,849,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 133849354...
Checkpoint 133849354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,858.31652
Policy Entropy: 1.14600
Value Function Loss: 0.10199

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.27089
Value Function Update Magnitude: 0.64708

Collected Steps per Second: 21,416.10471
Overall Steps per Second: 10,254.84493

Timestep Collection Time: 2.33553
Timestep Consumption Time: 2.54197
PPO Batch Consumption Time: 0.29619
Total Iteration Time: 4.87750

Cumulative Model Updates: 16,044
Cumulative Timesteps: 133,899,372

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,198.82606
Policy Entropy: 1.14263
Value Function Loss: 0.10145

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.27686
Value Function Update Magnitude: 0.60235

Collected Steps per Second: 20,980.43242
Overall Steps per Second: 10,107.48665

Timestep Collection Time: 2.38460
Timestep Consumption Time: 2.56519
PPO Batch Consumption Time: 0.30284
Total Iteration Time: 4.94980

Cumulative Model Updates: 16,050
Cumulative Timesteps: 133,949,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 133949402...
Checkpoint 133949402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,010.15070
Policy Entropy: 1.14192
Value Function Loss: 0.10280

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10998
Policy Update Magnitude: 0.28624
Value Function Update Magnitude: 0.56646

Collected Steps per Second: 21,516.98672
Overall Steps per Second: 10,293.45084

Timestep Collection Time: 2.32384
Timestep Consumption Time: 2.53381
PPO Batch Consumption Time: 0.30058
Total Iteration Time: 4.85765

Cumulative Model Updates: 16,056
Cumulative Timesteps: 133,999,404

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,207.91777
Policy Entropy: 1.12985
Value Function Loss: 0.10145

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.30012
Value Function Update Magnitude: 0.60517

Collected Steps per Second: 22,100.64619
Overall Steps per Second: 10,430.14640

Timestep Collection Time: 2.26401
Timestep Consumption Time: 2.53324
PPO Batch Consumption Time: 0.30148
Total Iteration Time: 4.79725

Cumulative Model Updates: 16,062
Cumulative Timesteps: 134,049,440

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 134049440...
Checkpoint 134049440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,309.65475
Policy Entropy: 1.12668
Value Function Loss: 0.10488

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.32416
Value Function Update Magnitude: 0.59602

Collected Steps per Second: 21,484.30922
Overall Steps per Second: 10,277.41816

Timestep Collection Time: 2.32784
Timestep Consumption Time: 2.53836
PPO Batch Consumption Time: 0.30173
Total Iteration Time: 4.86620

Cumulative Model Updates: 16,068
Cumulative Timesteps: 134,099,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,700.98983
Policy Entropy: 1.13039
Value Function Loss: 0.10062

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.28944
Value Function Update Magnitude: 0.68031

Collected Steps per Second: 22,137.34298
Overall Steps per Second: 10,437.15876

Timestep Collection Time: 2.25908
Timestep Consumption Time: 2.53246
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.79153

Cumulative Model Updates: 16,074
Cumulative Timesteps: 134,149,462

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 134149462...
Checkpoint 134149462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,170.63486
Policy Entropy: 1.13904
Value Function Loss: 0.10334

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.13636
Policy Update Magnitude: 0.26226
Value Function Update Magnitude: 0.73253

Collected Steps per Second: 21,700.56072
Overall Steps per Second: 10,458.00820

Timestep Collection Time: 2.30492
Timestep Consumption Time: 2.47783
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.78275

Cumulative Model Updates: 16,080
Cumulative Timesteps: 134,199,480

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,034.37065
Policy Entropy: 1.14123
Value Function Loss: 0.09651

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.28969
Value Function Update Magnitude: 0.76440

Collected Steps per Second: 21,993.03044
Overall Steps per Second: 10,393.58017

Timestep Collection Time: 2.27418
Timestep Consumption Time: 2.53803
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.81220

Cumulative Model Updates: 16,086
Cumulative Timesteps: 134,249,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 134249496...
Checkpoint 134249496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,896.45433
Policy Entropy: 1.13700
Value Function Loss: 0.09606

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.32335
Value Function Update Magnitude: 0.73920

Collected Steps per Second: 21,623.67602
Overall Steps per Second: 10,243.38955

Timestep Collection Time: 2.31330
Timestep Consumption Time: 2.57005
PPO Batch Consumption Time: 0.30777
Total Iteration Time: 4.88334

Cumulative Model Updates: 16,092
Cumulative Timesteps: 134,299,518

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,716.36580
Policy Entropy: 1.13783
Value Function Loss: 0.10314

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11435
Policy Update Magnitude: 0.30784
Value Function Update Magnitude: 0.69186

Collected Steps per Second: 21,850.96605
Overall Steps per Second: 10,464.26144

Timestep Collection Time: 2.28933
Timestep Consumption Time: 2.49113
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.78046

Cumulative Model Updates: 16,098
Cumulative Timesteps: 134,349,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 134349542...
Checkpoint 134349542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.37898
Policy Entropy: 1.13205
Value Function Loss: 0.10888

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10742
Policy Update Magnitude: 0.29919
Value Function Update Magnitude: 0.70894

Collected Steps per Second: 21,487.20016
Overall Steps per Second: 10,243.60372

Timestep Collection Time: 2.32799
Timestep Consumption Time: 2.55525
PPO Batch Consumption Time: 0.30501
Total Iteration Time: 4.88324

Cumulative Model Updates: 16,104
Cumulative Timesteps: 134,399,564

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,162.88131
Policy Entropy: 1.12805
Value Function Loss: 0.10805

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.30289
Value Function Update Magnitude: 0.68763

Collected Steps per Second: 21,680.88705
Overall Steps per Second: 10,423.58940

Timestep Collection Time: 2.30793
Timestep Consumption Time: 2.49253
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.80046

Cumulative Model Updates: 16,110
Cumulative Timesteps: 134,449,602

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 134449602...
Checkpoint 134449602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,107.96489
Policy Entropy: 1.13724
Value Function Loss: 0.10550

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.31076
Value Function Update Magnitude: 0.58291

Collected Steps per Second: 21,689.49945
Overall Steps per Second: 10,313.62457

Timestep Collection Time: 2.30637
Timestep Consumption Time: 2.54391
PPO Batch Consumption Time: 0.30351
Total Iteration Time: 4.85028

Cumulative Model Updates: 16,116
Cumulative Timesteps: 134,499,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,371.99853
Policy Entropy: 1.13759
Value Function Loss: 0.10255

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13117
Policy Update Magnitude: 0.29550
Value Function Update Magnitude: 0.58161

Collected Steps per Second: 21,788.70023
Overall Steps per Second: 10,329.53019

Timestep Collection Time: 2.29523
Timestep Consumption Time: 2.54623
PPO Batch Consumption Time: 0.30011
Total Iteration Time: 4.84146

Cumulative Model Updates: 16,122
Cumulative Timesteps: 134,549,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 134549636...
Checkpoint 134549636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,832.52960
Policy Entropy: 1.12573
Value Function Loss: 0.10697

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.25552
Value Function Update Magnitude: 0.56248

Collected Steps per Second: 21,531.80021
Overall Steps per Second: 10,244.40259

Timestep Collection Time: 2.32317
Timestep Consumption Time: 2.55969
PPO Batch Consumption Time: 0.30628
Total Iteration Time: 4.88286

Cumulative Model Updates: 16,128
Cumulative Timesteps: 134,599,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,593.58675
Policy Entropy: 1.13374
Value Function Loss: 0.10214

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.25786
Value Function Update Magnitude: 0.56285

Collected Steps per Second: 22,008.17176
Overall Steps per Second: 10,442.01816

Timestep Collection Time: 2.27297
Timestep Consumption Time: 2.51767
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.79064

Cumulative Model Updates: 16,134
Cumulative Timesteps: 134,649,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 134649682...
Checkpoint 134649682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,851.60222
Policy Entropy: 1.13272
Value Function Loss: 0.10044

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12338
Policy Update Magnitude: 0.25877
Value Function Update Magnitude: 0.62319

Collected Steps per Second: 21,373.49084
Overall Steps per Second: 10,161.67004

Timestep Collection Time: 2.34169
Timestep Consumption Time: 2.58369
PPO Batch Consumption Time: 0.30183
Total Iteration Time: 4.92537

Cumulative Model Updates: 16,140
Cumulative Timesteps: 134,699,732

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,699.70011
Policy Entropy: 1.14071
Value Function Loss: 0.09690

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11584
Policy Update Magnitude: 0.28399
Value Function Update Magnitude: 0.63320

Collected Steps per Second: 21,356.82502
Overall Steps per Second: 10,038.22192

Timestep Collection Time: 2.34164
Timestep Consumption Time: 2.64032
PPO Batch Consumption Time: 0.31393
Total Iteration Time: 4.98196

Cumulative Model Updates: 16,146
Cumulative Timesteps: 134,749,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 134749742...
Checkpoint 134749742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864.19966
Policy Entropy: 1.12474
Value Function Loss: 0.10019

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.27126
Value Function Update Magnitude: 0.68416

Collected Steps per Second: 21,309.89018
Overall Steps per Second: 10,244.66239

Timestep Collection Time: 2.34708
Timestep Consumption Time: 2.53507
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.88215

Cumulative Model Updates: 16,152
Cumulative Timesteps: 134,799,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,330.19327
Policy Entropy: 1.11974
Value Function Loss: 0.10362

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.25637
Value Function Update Magnitude: 0.71236

Collected Steps per Second: 21,817.23054
Overall Steps per Second: 10,386.45631

Timestep Collection Time: 2.29204
Timestep Consumption Time: 2.52250
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.81454

Cumulative Model Updates: 16,158
Cumulative Timesteps: 134,849,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 134849764...
Checkpoint 134849764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,881.54700
Policy Entropy: 1.11160
Value Function Loss: 0.09968

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.26916
Value Function Update Magnitude: 0.71198

Collected Steps per Second: 22,046.81968
Overall Steps per Second: 10,720.66842

Timestep Collection Time: 2.26790
Timestep Consumption Time: 2.39599
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.66389

Cumulative Model Updates: 16,164
Cumulative Timesteps: 134,899,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,186.38343
Policy Entropy: 1.11783
Value Function Loss: 0.09492

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.28462
Value Function Update Magnitude: 0.73437

Collected Steps per Second: 21,793.49260
Overall Steps per Second: 10,452.74986

Timestep Collection Time: 2.29435
Timestep Consumption Time: 2.48927
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.78362

Cumulative Model Updates: 16,170
Cumulative Timesteps: 134,949,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 134949766...
Checkpoint 134949766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,384.14559
Policy Entropy: 1.11575
Value Function Loss: 0.09475

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11817
Policy Update Magnitude: 0.29971
Value Function Update Magnitude: 0.72700

Collected Steps per Second: 21,316.63126
Overall Steps per Second: 10,194.53563

Timestep Collection Time: 2.34606
Timestep Consumption Time: 2.55951
PPO Batch Consumption Time: 0.30575
Total Iteration Time: 4.90557

Cumulative Model Updates: 16,176
Cumulative Timesteps: 134,999,776

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,965.67814
Policy Entropy: 1.11175
Value Function Loss: 0.09577

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.29902
Value Function Update Magnitude: 0.67514

Collected Steps per Second: 21,882.73733
Overall Steps per Second: 10,392.94542

Timestep Collection Time: 2.28491
Timestep Consumption Time: 2.52605
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.81096

Cumulative Model Updates: 16,182
Cumulative Timesteps: 135,049,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 135049776...
Checkpoint 135049776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,056.28058
Policy Entropy: 1.10712
Value Function Loss: 0.09861

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.27696
Value Function Update Magnitude: 0.69853

Collected Steps per Second: 21,541.15185
Overall Steps per Second: 10,265.52556

Timestep Collection Time: 2.32207
Timestep Consumption Time: 2.55055
PPO Batch Consumption Time: 0.29940
Total Iteration Time: 4.87262

Cumulative Model Updates: 16,188
Cumulative Timesteps: 135,099,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,492.64434
Policy Entropy: 1.10199
Value Function Loss: 0.09968

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.26787
Value Function Update Magnitude: 0.72486

Collected Steps per Second: 21,819.06428
Overall Steps per Second: 10,354.29699

Timestep Collection Time: 2.29277
Timestep Consumption Time: 2.53866
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.83142

Cumulative Model Updates: 16,194
Cumulative Timesteps: 135,149,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 135149822...
Checkpoint 135149822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,437.90574
Policy Entropy: 1.10027
Value Function Loss: 0.10255

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.26018
Value Function Update Magnitude: 0.71860

Collected Steps per Second: 21,568.49669
Overall Steps per Second: 10,295.85119

Timestep Collection Time: 2.31829
Timestep Consumption Time: 2.53823
PPO Batch Consumption Time: 0.29942
Total Iteration Time: 4.85652

Cumulative Model Updates: 16,200
Cumulative Timesteps: 135,199,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,901.88009
Policy Entropy: 1.09980
Value Function Loss: 0.10054

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.26387
Value Function Update Magnitude: 0.70767

Collected Steps per Second: 19,146.80313
Overall Steps per Second: 9,632.34978

Timestep Collection Time: 2.61140
Timestep Consumption Time: 2.57944
PPO Batch Consumption Time: 0.30432
Total Iteration Time: 5.19084

Cumulative Model Updates: 16,206
Cumulative Timesteps: 135,249,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 135249824...
Checkpoint 135249824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,718.98019
Policy Entropy: 1.10198
Value Function Loss: 0.09958

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.14957
Policy Update Magnitude: 0.24669
Value Function Update Magnitude: 0.66930

Collected Steps per Second: 21,425.36174
Overall Steps per Second: 10,232.91490

Timestep Collection Time: 2.33490
Timestep Consumption Time: 2.55384
PPO Batch Consumption Time: 0.30512
Total Iteration Time: 4.88873

Cumulative Model Updates: 16,212
Cumulative Timesteps: 135,299,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,357.38544
Policy Entropy: 1.09751
Value Function Loss: 0.09802

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.24163
Value Function Update Magnitude: 0.64740

Collected Steps per Second: 21,873.36775
Overall Steps per Second: 10,311.16806

Timestep Collection Time: 2.28652
Timestep Consumption Time: 2.56394
PPO Batch Consumption Time: 0.30305
Total Iteration Time: 4.85047

Cumulative Model Updates: 16,218
Cumulative Timesteps: 135,349,864

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 135349864...
Checkpoint 135349864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.54503
Policy Entropy: 1.09121
Value Function Loss: 0.09913

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10957
Policy Update Magnitude: 0.27674
Value Function Update Magnitude: 0.68971

Collected Steps per Second: 21,572.03219
Overall Steps per Second: 10,298.44231

Timestep Collection Time: 2.31828
Timestep Consumption Time: 2.53779
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.85607

Cumulative Model Updates: 16,224
Cumulative Timesteps: 135,399,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,633.75153
Policy Entropy: 1.08283
Value Function Loss: 0.10264

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.26951
Value Function Update Magnitude: 0.63528

Collected Steps per Second: 21,826.94012
Overall Steps per Second: 10,407.81870

Timestep Collection Time: 2.29102
Timestep Consumption Time: 2.51364
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.80466

Cumulative Model Updates: 16,230
Cumulative Timesteps: 135,449,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 135449880...
Checkpoint 135449880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,509.70203
Policy Entropy: 1.09550
Value Function Loss: 0.10141

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.27197
Value Function Update Magnitude: 0.68504

Collected Steps per Second: 21,307.80519
Overall Steps per Second: 10,279.05339

Timestep Collection Time: 2.34797
Timestep Consumption Time: 2.51921
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.86718

Cumulative Model Updates: 16,236
Cumulative Timesteps: 135,499,910

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,532.94895
Policy Entropy: 1.10268
Value Function Loss: 0.10347

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.25841
Value Function Update Magnitude: 0.68982

Collected Steps per Second: 21,698.71636
Overall Steps per Second: 10,409.14022

Timestep Collection Time: 2.30548
Timestep Consumption Time: 2.50049
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.80597

Cumulative Model Updates: 16,242
Cumulative Timesteps: 135,549,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 135549936...
Checkpoint 135549936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852.80769
Policy Entropy: 1.09925
Value Function Loss: 0.10157

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.17050
Policy Update Magnitude: 0.25456
Value Function Update Magnitude: 0.70287

Collected Steps per Second: 21,174.49431
Overall Steps per Second: 10,251.17595

Timestep Collection Time: 2.36190
Timestep Consumption Time: 2.51676
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.87866

Cumulative Model Updates: 16,248
Cumulative Timesteps: 135,599,948

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,076.93538
Policy Entropy: 1.09113
Value Function Loss: 0.10264

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.14378
Policy Update Magnitude: 0.28261
Value Function Update Magnitude: 0.71312

Collected Steps per Second: 21,883.79158
Overall Steps per Second: 10,491.08059

Timestep Collection Time: 2.28507
Timestep Consumption Time: 2.48145
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.76653

Cumulative Model Updates: 16,254
Cumulative Timesteps: 135,649,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 135649954...
Checkpoint 135649954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,841.73000
Policy Entropy: 1.09457
Value Function Loss: 0.10169

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.31237
Value Function Update Magnitude: 0.70354

Collected Steps per Second: 21,761.98867
Overall Steps per Second: 10,276.91222

Timestep Collection Time: 2.29924
Timestep Consumption Time: 2.56954
PPO Batch Consumption Time: 0.30346
Total Iteration Time: 4.86878

Cumulative Model Updates: 16,260
Cumulative Timesteps: 135,699,990

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,462.57581
Policy Entropy: 1.09593
Value Function Loss: 0.10607

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.32222
Value Function Update Magnitude: 0.66847

Collected Steps per Second: 21,872.16304
Overall Steps per Second: 10,350.74715

Timestep Collection Time: 2.28656
Timestep Consumption Time: 2.54517
PPO Batch Consumption Time: 0.29964
Total Iteration Time: 4.83173

Cumulative Model Updates: 16,266
Cumulative Timesteps: 135,750,002

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 135750002...
Checkpoint 135750002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,007.23122
Policy Entropy: 1.10241
Value Function Loss: 0.10578

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08036
Policy Update Magnitude: 0.33319
Value Function Update Magnitude: 0.68615

Collected Steps per Second: 21,433.06548
Overall Steps per Second: 10,194.62618

Timestep Collection Time: 2.33499
Timestep Consumption Time: 2.57407
PPO Batch Consumption Time: 0.30483
Total Iteration Time: 4.90906

Cumulative Model Updates: 16,272
Cumulative Timesteps: 135,800,048

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,641.43465
Policy Entropy: 1.10281
Value Function Loss: 0.10512

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.34308
Value Function Update Magnitude: 0.62256

Collected Steps per Second: 21,992.43977
Overall Steps per Second: 10,434.68574

Timestep Collection Time: 2.27451
Timestep Consumption Time: 2.51931
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.79382

Cumulative Model Updates: 16,278
Cumulative Timesteps: 135,850,070

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 135850070...
Checkpoint 135850070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591.86656
Policy Entropy: 1.10698
Value Function Loss: 0.10263

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.32687
Value Function Update Magnitude: 0.62348

Collected Steps per Second: 21,597.46104
Overall Steps per Second: 10,268.46830

Timestep Collection Time: 2.31666
Timestep Consumption Time: 2.55593
PPO Batch Consumption Time: 0.29818
Total Iteration Time: 4.87259

Cumulative Model Updates: 16,284
Cumulative Timesteps: 135,900,104

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,920.46852
Policy Entropy: 1.10095
Value Function Loss: 0.10383

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.28619
Value Function Update Magnitude: 0.65400

Collected Steps per Second: 21,514.66158
Overall Steps per Second: 10,341.71426

Timestep Collection Time: 2.32604
Timestep Consumption Time: 2.51300
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.83904

Cumulative Model Updates: 16,290
Cumulative Timesteps: 135,950,148

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 135950148...
Checkpoint 135950148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,273.44115
Policy Entropy: 1.08871
Value Function Loss: 0.10573

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.30360
Value Function Update Magnitude: 0.65495

Collected Steps per Second: 21,618.70345
Overall Steps per Second: 10,209.02889

Timestep Collection Time: 2.31318
Timestep Consumption Time: 2.58523
PPO Batch Consumption Time: 0.30679
Total Iteration Time: 4.89841

Cumulative Model Updates: 16,296
Cumulative Timesteps: 136,000,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,586.23270
Policy Entropy: 1.08977
Value Function Loss: 0.10265

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08900
Policy Update Magnitude: 0.32814
Value Function Update Magnitude: 0.64389

Collected Steps per Second: 21,819.52118
Overall Steps per Second: 10,466.59261

Timestep Collection Time: 2.29363
Timestep Consumption Time: 2.48786
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.78150

Cumulative Model Updates: 16,302
Cumulative Timesteps: 136,050,202

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 136050202...
Checkpoint 136050202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,586.26114
Policy Entropy: 1.09918
Value Function Loss: 0.09717

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.31461
Value Function Update Magnitude: 0.61264

Collected Steps per Second: 21,746.76169
Overall Steps per Second: 10,326.57744

Timestep Collection Time: 2.29947
Timestep Consumption Time: 2.54299
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.84246

Cumulative Model Updates: 16,308
Cumulative Timesteps: 136,100,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,857.80697
Policy Entropy: 1.09918
Value Function Loss: 0.09286

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.31407
Value Function Update Magnitude: 0.61940

Collected Steps per Second: 21,826.32308
Overall Steps per Second: 10,381.08255

Timestep Collection Time: 2.29118
Timestep Consumption Time: 2.52605
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.81722

Cumulative Model Updates: 16,314
Cumulative Timesteps: 136,150,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 136150216...
Checkpoint 136150216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,499.58750
Policy Entropy: 1.10400
Value Function Loss: 0.09352

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07616
Policy Update Magnitude: 0.32082
Value Function Update Magnitude: 0.65703

Collected Steps per Second: 22,297.92494
Overall Steps per Second: 10,771.03398

Timestep Collection Time: 2.24433
Timestep Consumption Time: 2.40183
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.64616

Cumulative Model Updates: 16,320
Cumulative Timesteps: 136,200,260

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,414.02821
Policy Entropy: 1.09658
Value Function Loss: 0.09327

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07847
Policy Update Magnitude: 0.33164
Value Function Update Magnitude: 0.67018

Collected Steps per Second: 21,822.77999
Overall Steps per Second: 10,436.15943

Timestep Collection Time: 2.29293
Timestep Consumption Time: 2.50175
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.79468

Cumulative Model Updates: 16,326
Cumulative Timesteps: 136,250,298

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 136250298...
Checkpoint 136250298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,063.32938
Policy Entropy: 1.10031
Value Function Loss: 0.09381

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09378
Policy Update Magnitude: 0.32278
Value Function Update Magnitude: 0.67229

Collected Steps per Second: 21,063.64458
Overall Steps per Second: 10,224.38426

Timestep Collection Time: 2.37518
Timestep Consumption Time: 2.51802
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.89320

Cumulative Model Updates: 16,332
Cumulative Timesteps: 136,300,328

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,473.74116
Policy Entropy: 1.09720
Value Function Loss: 0.10093

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11326
Policy Update Magnitude: 0.28726
Value Function Update Magnitude: 0.68945

Collected Steps per Second: 21,769.75530
Overall Steps per Second: 10,300.59971

Timestep Collection Time: 2.29879
Timestep Consumption Time: 2.55957
PPO Batch Consumption Time: 0.30261
Total Iteration Time: 4.85836

Cumulative Model Updates: 16,338
Cumulative Timesteps: 136,350,372

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 136350372...
Checkpoint 136350372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,927.42866
Policy Entropy: 1.10693
Value Function Loss: 0.09887

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.27193
Value Function Update Magnitude: 0.69420

Collected Steps per Second: 22,065.58393
Overall Steps per Second: 10,611.39543

Timestep Collection Time: 2.26688
Timestep Consumption Time: 2.44692
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.71380

Cumulative Model Updates: 16,344
Cumulative Timesteps: 136,400,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,262.21628
Policy Entropy: 1.09651
Value Function Loss: 0.10335

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.15920
Policy Update Magnitude: 0.25255
Value Function Update Magnitude: 0.66909

Collected Steps per Second: 21,932.63264
Overall Steps per Second: 10,284.76984

Timestep Collection Time: 2.28117
Timestep Consumption Time: 2.58350
PPO Batch Consumption Time: 0.30501
Total Iteration Time: 4.86467

Cumulative Model Updates: 16,350
Cumulative Timesteps: 136,450,424

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 136450424...
Checkpoint 136450424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,055.59887
Policy Entropy: 1.09834
Value Function Loss: 0.09596

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.25041
Value Function Update Magnitude: 0.65577

Collected Steps per Second: 21,637.74231
Overall Steps per Second: 10,243.64786

Timestep Collection Time: 2.31189
Timestep Consumption Time: 2.57153
PPO Batch Consumption Time: 0.30415
Total Iteration Time: 4.88342

Cumulative Model Updates: 16,356
Cumulative Timesteps: 136,500,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.98855
Policy Entropy: 1.09439
Value Function Loss: 0.09689

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.26019
Value Function Update Magnitude: 0.65354

Collected Steps per Second: 21,990.60099
Overall Steps per Second: 10,344.61018

Timestep Collection Time: 2.27415
Timestep Consumption Time: 2.56025
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 4.83440

Cumulative Model Updates: 16,362
Cumulative Timesteps: 136,550,458

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 136550458...
Checkpoint 136550458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,229.37032
Policy Entropy: 1.09636
Value Function Loss: 0.09899

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.27206
Value Function Update Magnitude: 0.56322

Collected Steps per Second: 21,389.21977
Overall Steps per Second: 10,204.98678

Timestep Collection Time: 2.33809
Timestep Consumption Time: 2.56245
PPO Batch Consumption Time: 0.29864
Total Iteration Time: 4.90055

Cumulative Model Updates: 16,368
Cumulative Timesteps: 136,600,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,542.84615
Policy Entropy: 1.09268
Value Function Loss: 0.10082

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.29695
Value Function Update Magnitude: 0.51109

Collected Steps per Second: 21,809.15809
Overall Steps per Second: 10,472.07063

Timestep Collection Time: 2.29335
Timestep Consumption Time: 2.48278
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.77613

Cumulative Model Updates: 16,374
Cumulative Timesteps: 136,650,484

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 136650484...
Checkpoint 136650484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,815.27943
Policy Entropy: 1.08342
Value Function Loss: 0.10527

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.30100
Value Function Update Magnitude: 0.48098

Collected Steps per Second: 21,540.54060
Overall Steps per Second: 10,191.51373

Timestep Collection Time: 2.32176
Timestep Consumption Time: 2.58546
PPO Batch Consumption Time: 0.30162
Total Iteration Time: 4.90722

Cumulative Model Updates: 16,380
Cumulative Timesteps: 136,700,496

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,696.17708
Policy Entropy: 1.08587
Value Function Loss: 0.10738

Mean KL Divergence: 0.03388
SB3 Clip Fraction: 0.21490
Policy Update Magnitude: 0.24289
Value Function Update Magnitude: 0.53609

Collected Steps per Second: 21,763.14554
Overall Steps per Second: 10,341.77768

Timestep Collection Time: 2.29783
Timestep Consumption Time: 2.53770
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.83553

Cumulative Model Updates: 16,386
Cumulative Timesteps: 136,750,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 136750504...
Checkpoint 136750504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,937.19573
Policy Entropy: 1.07774
Value Function Loss: 0.11404

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.16993
Policy Update Magnitude: 0.24247
Value Function Update Magnitude: 0.51509

Collected Steps per Second: 21,693.83289
Overall Steps per Second: 10,321.93897

Timestep Collection Time: 2.30582
Timestep Consumption Time: 2.54037
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.84618

Cumulative Model Updates: 16,392
Cumulative Timesteps: 136,800,526

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,458.83039
Policy Entropy: 1.08380
Value Function Loss: 0.11158

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12894
Policy Update Magnitude: 0.26732
Value Function Update Magnitude: 0.54893

Collected Steps per Second: 22,001.22440
Overall Steps per Second: 10,454.24187

Timestep Collection Time: 2.27278
Timestep Consumption Time: 2.51035
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.78313

Cumulative Model Updates: 16,398
Cumulative Timesteps: 136,850,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 136850530...
Checkpoint 136850530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,168.69262
Policy Entropy: 1.07725
Value Function Loss: 0.10781

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.28925
Value Function Update Magnitude: 0.62169

Collected Steps per Second: 21,159.28045
Overall Steps per Second: 10,194.13604

Timestep Collection Time: 2.36341
Timestep Consumption Time: 2.54216
PPO Batch Consumption Time: 0.30104
Total Iteration Time: 4.90557

Cumulative Model Updates: 16,404
Cumulative Timesteps: 136,900,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,539.02268
Policy Entropy: 1.08388
Value Function Loss: 0.10099

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.28882
Value Function Update Magnitude: 0.67078

Collected Steps per Second: 21,727.89787
Overall Steps per Second: 10,295.46435

Timestep Collection Time: 2.30193
Timestep Consumption Time: 2.55614
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.85806

Cumulative Model Updates: 16,410
Cumulative Timesteps: 136,950,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 136950554...
Checkpoint 136950554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,202.79701
Policy Entropy: 1.07844
Value Function Loss: 0.09947

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.27811
Value Function Update Magnitude: 0.69156

Collected Steps per Second: 21,614.07745
Overall Steps per Second: 10,158.62333

Timestep Collection Time: 2.31516
Timestep Consumption Time: 2.61071
PPO Batch Consumption Time: 0.30586
Total Iteration Time: 4.92586

Cumulative Model Updates: 16,416
Cumulative Timesteps: 137,000,594

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,813.32196
Policy Entropy: 1.08325
Value Function Loss: 0.09741

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.26555
Value Function Update Magnitude: 0.68111

Collected Steps per Second: 21,840.88849
Overall Steps per Second: 10,240.41995

Timestep Collection Time: 2.29011
Timestep Consumption Time: 2.59426
PPO Batch Consumption Time: 0.30484
Total Iteration Time: 4.88437

Cumulative Model Updates: 16,422
Cumulative Timesteps: 137,050,612

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 137050612...
Checkpoint 137050612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,539.06884
Policy Entropy: 1.08140
Value Function Loss: 0.09447

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.26356
Value Function Update Magnitude: 0.66960

Collected Steps per Second: 21,397.77310
Overall Steps per Second: 10,231.05909

Timestep Collection Time: 2.33772
Timestep Consumption Time: 2.55151
PPO Batch Consumption Time: 0.29917
Total Iteration Time: 4.88923

Cumulative Model Updates: 16,428
Cumulative Timesteps: 137,100,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,394.06108
Policy Entropy: 1.08021
Value Function Loss: 0.09291

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.26427
Value Function Update Magnitude: 0.64229

Collected Steps per Second: 21,646.00809
Overall Steps per Second: 10,343.05036

Timestep Collection Time: 2.31054
Timestep Consumption Time: 2.52498
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.83552

Cumulative Model Updates: 16,434
Cumulative Timesteps: 137,150,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 137150648...
Checkpoint 137150648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,772.79390
Policy Entropy: 1.07651
Value Function Loss: 0.09169

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.28071
Value Function Update Magnitude: 0.66426

Collected Steps per Second: 21,703.78628
Overall Steps per Second: 10,295.13616

Timestep Collection Time: 2.30411
Timestep Consumption Time: 2.55333
PPO Batch Consumption Time: 0.29795
Total Iteration Time: 4.85744

Cumulative Model Updates: 16,440
Cumulative Timesteps: 137,200,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,242.41583
Policy Entropy: 1.07314
Value Function Loss: 0.09629

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.30610
Value Function Update Magnitude: 0.66928

Collected Steps per Second: 21,864.67756
Overall Steps per Second: 10,390.66455

Timestep Collection Time: 2.28707
Timestep Consumption Time: 2.52552
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.81259

Cumulative Model Updates: 16,446
Cumulative Timesteps: 137,250,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 137250662...
Checkpoint 137250662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.87944
Policy Entropy: 1.07226
Value Function Loss: 0.10123

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.28577
Value Function Update Magnitude: 0.61620

Collected Steps per Second: 21,502.31158
Overall Steps per Second: 10,259.70059

Timestep Collection Time: 2.32542
Timestep Consumption Time: 2.54821
PPO Batch Consumption Time: 0.30323
Total Iteration Time: 4.87363

Cumulative Model Updates: 16,452
Cumulative Timesteps: 137,300,664

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,802.46027
Policy Entropy: 1.06179
Value Function Loss: 0.11096

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12814
Policy Update Magnitude: 0.25600
Value Function Update Magnitude: 0.61835

Collected Steps per Second: 21,825.63974
Overall Steps per Second: 10,431.78855

Timestep Collection Time: 2.29116
Timestep Consumption Time: 2.50246
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.79362

Cumulative Model Updates: 16,458
Cumulative Timesteps: 137,350,670

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 137350670...
Checkpoint 137350670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,895.94183
Policy Entropy: 1.06597
Value Function Loss: 0.11102

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10231
Policy Update Magnitude: 0.27121
Value Function Update Magnitude: 0.57398

Collected Steps per Second: 21,450.14689
Overall Steps per Second: 10,198.66482

Timestep Collection Time: 2.33248
Timestep Consumption Time: 2.57326
PPO Batch Consumption Time: 0.30309
Total Iteration Time: 4.90574

Cumulative Model Updates: 16,464
Cumulative Timesteps: 137,400,702

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,279.17464
Policy Entropy: 1.06749
Value Function Loss: 0.11044

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.30409
Value Function Update Magnitude: 0.60633

Collected Steps per Second: 21,969.81128
Overall Steps per Second: 10,518.87125

Timestep Collection Time: 2.27658
Timestep Consumption Time: 2.47830
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.75488

Cumulative Model Updates: 16,470
Cumulative Timesteps: 137,450,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 137450718...
Checkpoint 137450718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,615.15054
Policy Entropy: 1.08381
Value Function Loss: 0.10296

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.12017
Policy Update Magnitude: 0.28351
Value Function Update Magnitude: 0.57768

Collected Steps per Second: 20,822.90153
Overall Steps per Second: 10,191.68360

Timestep Collection Time: 2.40351
Timestep Consumption Time: 2.50716
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.91067

Cumulative Model Updates: 16,476
Cumulative Timesteps: 137,500,766

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,967.92794
Policy Entropy: 1.07762
Value Function Loss: 0.10235

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11705
Policy Update Magnitude: 0.25011
Value Function Update Magnitude: 0.59046

Collected Steps per Second: 21,726.02890
Overall Steps per Second: 10,372.06657

Timestep Collection Time: 2.30176
Timestep Consumption Time: 2.51966
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.82141

Cumulative Model Updates: 16,482
Cumulative Timesteps: 137,550,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 137550774...
Checkpoint 137550774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,015.14140
Policy Entropy: 1.08682
Value Function Loss: 0.10289

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.27584
Value Function Update Magnitude: 0.62500

Collected Steps per Second: 21,726.75231
Overall Steps per Second: 10,115.09355

Timestep Collection Time: 2.30315
Timestep Consumption Time: 2.64391
PPO Batch Consumption Time: 0.31787
Total Iteration Time: 4.94706

Cumulative Model Updates: 16,488
Cumulative Timesteps: 137,600,814

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,265.54945
Policy Entropy: 1.08741
Value Function Loss: 0.10241

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.31968
Value Function Update Magnitude: 0.67065

Collected Steps per Second: 22,122.11307
Overall Steps per Second: 10,219.62489

Timestep Collection Time: 2.26118
Timestep Consumption Time: 2.63352
PPO Batch Consumption Time: 0.30837
Total Iteration Time: 4.89470

Cumulative Model Updates: 16,494
Cumulative Timesteps: 137,650,836

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 137650836...
Checkpoint 137650836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,238.19173
Policy Entropy: 1.09558
Value Function Loss: 0.10027

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07367
Policy Update Magnitude: 0.33368
Value Function Update Magnitude: 0.62035

Collected Steps per Second: 21,478.14964
Overall Steps per Second: 10,183.25670

Timestep Collection Time: 2.32962
Timestep Consumption Time: 2.58393
PPO Batch Consumption Time: 0.30253
Total Iteration Time: 4.91356

Cumulative Model Updates: 16,500
Cumulative Timesteps: 137,700,872

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,330.75054
Policy Entropy: 1.07862
Value Function Loss: 0.10382

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08265
Policy Update Magnitude: 0.33185
Value Function Update Magnitude: 0.51304

Collected Steps per Second: 21,963.06838
Overall Steps per Second: 10,467.40911

Timestep Collection Time: 2.27664
Timestep Consumption Time: 2.50028
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.77692

Cumulative Model Updates: 16,506
Cumulative Timesteps: 137,750,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 137750874...
Checkpoint 137750874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,971.81453
Policy Entropy: 1.07653
Value Function Loss: 0.10556

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.31367
Value Function Update Magnitude: 0.51966

Collected Steps per Second: 21,605.36266
Overall Steps per Second: 10,262.03174

Timestep Collection Time: 2.31563
Timestep Consumption Time: 2.55962
PPO Batch Consumption Time: 0.30518
Total Iteration Time: 4.87525

Cumulative Model Updates: 16,512
Cumulative Timesteps: 137,800,904

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,912.74569
Policy Entropy: 1.07229
Value Function Loss: 0.10779

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11169
Policy Update Magnitude: 0.29103
Value Function Update Magnitude: 0.54562

Collected Steps per Second: 22,015.73398
Overall Steps per Second: 10,424.95600

Timestep Collection Time: 2.27147
Timestep Consumption Time: 2.52548
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.79695

Cumulative Model Updates: 16,518
Cumulative Timesteps: 137,850,912

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 137850912...
Checkpoint 137850912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,133.58620
Policy Entropy: 1.07602
Value Function Loss: 0.10086

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.26996
Value Function Update Magnitude: 0.55740

Collected Steps per Second: 21,373.66770
Overall Steps per Second: 10,169.33047

Timestep Collection Time: 2.34036
Timestep Consumption Time: 2.57855
PPO Batch Consumption Time: 0.30142
Total Iteration Time: 4.91891

Cumulative Model Updates: 16,524
Cumulative Timesteps: 137,900,934

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,250.37951
Policy Entropy: 1.06958
Value Function Loss: 0.10097

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11919
Policy Update Magnitude: 0.25087
Value Function Update Magnitude: 0.56468

Collected Steps per Second: 21,967.26645
Overall Steps per Second: 10,480.88420

Timestep Collection Time: 2.27739
Timestep Consumption Time: 2.49587
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.77326

Cumulative Model Updates: 16,530
Cumulative Timesteps: 137,950,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 137950962...
Checkpoint 137950962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,139.20267
Policy Entropy: 1.06684
Value Function Loss: 0.10141

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.25794
Value Function Update Magnitude: 0.49696

Collected Steps per Second: 21,413.09930
Overall Steps per Second: 10,197.62319

Timestep Collection Time: 2.33577
Timestep Consumption Time: 2.56891
PPO Batch Consumption Time: 0.30612
Total Iteration Time: 4.90467

Cumulative Model Updates: 16,536
Cumulative Timesteps: 138,000,978

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,302.64067
Policy Entropy: 1.05421
Value Function Loss: 0.10540

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.26301
Value Function Update Magnitude: 0.48050

Collected Steps per Second: 21,934.33084
Overall Steps per Second: 10,431.94488

Timestep Collection Time: 2.28044
Timestep Consumption Time: 2.51444
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.79489

Cumulative Model Updates: 16,542
Cumulative Timesteps: 138,050,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 138050998...
Checkpoint 138050998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,045.27471
Policy Entropy: 1.04826
Value Function Loss: 0.10476

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.26731
Value Function Update Magnitude: 0.51674

Collected Steps per Second: 21,246.12974
Overall Steps per Second: 10,255.38442

Timestep Collection Time: 2.35365
Timestep Consumption Time: 2.52242
PPO Batch Consumption Time: 0.29820
Total Iteration Time: 4.87607

Cumulative Model Updates: 16,548
Cumulative Timesteps: 138,101,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,223.98071
Policy Entropy: 1.05092
Value Function Loss: 0.10692

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.24980
Value Function Update Magnitude: 0.50231

Collected Steps per Second: 22,025.50576
Overall Steps per Second: 10,461.18750

Timestep Collection Time: 2.27173
Timestep Consumption Time: 2.51128
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.78301

Cumulative Model Updates: 16,554
Cumulative Timesteps: 138,151,040

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 138151040...
Checkpoint 138151040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.81269
Policy Entropy: 1.05538
Value Function Loss: 0.11445

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.15486
Policy Update Magnitude: 0.25771
Value Function Update Magnitude: 0.48292

Collected Steps per Second: 21,689.40604
Overall Steps per Second: 10,326.17974

Timestep Collection Time: 2.30610
Timestep Consumption Time: 2.53770
PPO Batch Consumption Time: 0.30231
Total Iteration Time: 4.84380

Cumulative Model Updates: 16,560
Cumulative Timesteps: 138,201,058

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,183.74043
Policy Entropy: 1.06082
Value Function Loss: 0.11610

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.29525
Value Function Update Magnitude: 0.52001

Collected Steps per Second: 21,918.98002
Overall Steps per Second: 10,234.40192

Timestep Collection Time: 2.28286
Timestep Consumption Time: 2.60633
PPO Batch Consumption Time: 0.31009
Total Iteration Time: 4.88920

Cumulative Model Updates: 16,566
Cumulative Timesteps: 138,251,096

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 138251096...
Checkpoint 138251096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,527.60855
Policy Entropy: 1.06162
Value Function Loss: 0.11857

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11702
Policy Update Magnitude: 0.32702
Value Function Update Magnitude: 0.57615

Collected Steps per Second: 21,154.30371
Overall Steps per Second: 10,332.18773

Timestep Collection Time: 2.36415
Timestep Consumption Time: 2.47626
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.84041

Cumulative Model Updates: 16,572
Cumulative Timesteps: 138,301,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,398.69810
Policy Entropy: 1.07080
Value Function Loss: 0.11540

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.33744
Value Function Update Magnitude: 0.53924

Collected Steps per Second: 21,780.65259
Overall Steps per Second: 10,401.85378

Timestep Collection Time: 2.29699
Timestep Consumption Time: 2.51273
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.80972

Cumulative Model Updates: 16,578
Cumulative Timesteps: 138,351,138

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 138351138...
Checkpoint 138351138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,608.46609
Policy Entropy: 1.07207
Value Function Loss: 0.11376

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.34018
Value Function Update Magnitude: 0.50447

Collected Steps per Second: 21,564.73061
Overall Steps per Second: 10,241.62770

Timestep Collection Time: 2.31897
Timestep Consumption Time: 2.56385
PPO Batch Consumption Time: 0.30656
Total Iteration Time: 4.88282

Cumulative Model Updates: 16,584
Cumulative Timesteps: 138,401,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,314.07703
Policy Entropy: 1.07879
Value Function Loss: 0.10973

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06678
Policy Update Magnitude: 0.32578
Value Function Update Magnitude: 0.59155

Collected Steps per Second: 21,884.26103
Overall Steps per Second: 10,463.49966

Timestep Collection Time: 2.28667
Timestep Consumption Time: 2.49586
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.78253

Cumulative Model Updates: 16,590
Cumulative Timesteps: 138,451,188

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 138451188...
Checkpoint 138451188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668.68157
Policy Entropy: 1.06997
Value Function Loss: 0.11432

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07526
Policy Update Magnitude: 0.32757
Value Function Update Magnitude: 0.62418

Collected Steps per Second: 21,408.71814
Overall Steps per Second: 10,198.96840

Timestep Collection Time: 2.33578
Timestep Consumption Time: 2.56727
PPO Batch Consumption Time: 0.30660
Total Iteration Time: 4.90304

Cumulative Model Updates: 16,596
Cumulative Timesteps: 138,501,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,643.90946
Policy Entropy: 1.06596
Value Function Loss: 0.11183

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07556
Policy Update Magnitude: 0.32860
Value Function Update Magnitude: 0.58742

Collected Steps per Second: 21,671.41222
Overall Steps per Second: 10,408.28597

Timestep Collection Time: 2.30848
Timestep Consumption Time: 2.49808
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.80656

Cumulative Model Updates: 16,602
Cumulative Timesteps: 138,551,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 138551222...
Checkpoint 138551222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,940.69297
Policy Entropy: 1.06013
Value Function Loss: 0.10835

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06452
Policy Update Magnitude: 0.33960
Value Function Update Magnitude: 0.59077

Collected Steps per Second: 21,202.63190
Overall Steps per Second: 10,218.51260

Timestep Collection Time: 2.35886
Timestep Consumption Time: 2.53559
PPO Batch Consumption Time: 0.29878
Total Iteration Time: 4.89445

Cumulative Model Updates: 16,608
Cumulative Timesteps: 138,601,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432.16523
Policy Entropy: 1.06138
Value Function Loss: 0.10872

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.33152
Value Function Update Magnitude: 0.61382

Collected Steps per Second: 21,881.03085
Overall Steps per Second: 10,436.25016

Timestep Collection Time: 2.28518
Timestep Consumption Time: 2.50601
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.79118

Cumulative Model Updates: 16,614
Cumulative Timesteps: 138,651,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 138651238...
Checkpoint 138651238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,961.61686
Policy Entropy: 1.06777
Value Function Loss: 0.10805

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06869
Policy Update Magnitude: 0.35310
Value Function Update Magnitude: 0.57076

Collected Steps per Second: 21,436.27040
Overall Steps per Second: 10,260.65691

Timestep Collection Time: 2.33324
Timestep Consumption Time: 2.54130
PPO Batch Consumption Time: 0.30126
Total Iteration Time: 4.87454

Cumulative Model Updates: 16,620
Cumulative Timesteps: 138,701,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,547.39136
Policy Entropy: 1.05422
Value Function Loss: 0.10495

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07625
Policy Update Magnitude: 0.35956
Value Function Update Magnitude: 0.63255

Collected Steps per Second: 22,100.20411
Overall Steps per Second: 10,443.41642

Timestep Collection Time: 2.26369
Timestep Consumption Time: 2.52670
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.79039

Cumulative Model Updates: 16,626
Cumulative Timesteps: 138,751,282

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 138751282...
Checkpoint 138751282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,585.69103
Policy Entropy: 1.05719
Value Function Loss: 0.09867

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.33121
Value Function Update Magnitude: 0.68170

Collected Steps per Second: 21,240.77771
Overall Steps per Second: 10,201.42439

Timestep Collection Time: 2.35481
Timestep Consumption Time: 2.54823
PPO Batch Consumption Time: 0.30070
Total Iteration Time: 4.90304

Cumulative Model Updates: 16,632
Cumulative Timesteps: 138,801,300

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,640.06142
Policy Entropy: 1.04872
Value Function Loss: 0.09768

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.28575
Value Function Update Magnitude: 0.71545

Collected Steps per Second: 22,080.44495
Overall Steps per Second: 10,477.79258

Timestep Collection Time: 2.26535
Timestep Consumption Time: 2.50855
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.77391

Cumulative Model Updates: 16,638
Cumulative Timesteps: 138,851,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 138851320...
Checkpoint 138851320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,668.20859
Policy Entropy: 1.04866
Value Function Loss: 0.09642

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.28540
Value Function Update Magnitude: 0.72356

Collected Steps per Second: 21,209.88647
Overall Steps per Second: 10,209.17999

Timestep Collection Time: 2.35767
Timestep Consumption Time: 2.54047
PPO Batch Consumption Time: 0.29620
Total Iteration Time: 4.89814

Cumulative Model Updates: 16,644
Cumulative Timesteps: 138,901,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,082.89233
Policy Entropy: 1.05221
Value Function Loss: 0.09850

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.31188
Value Function Update Magnitude: 0.72542

Collected Steps per Second: 21,641.82090
Overall Steps per Second: 10,422.79452

Timestep Collection Time: 2.31210
Timestep Consumption Time: 2.48873
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.80082

Cumulative Model Updates: 16,650
Cumulative Timesteps: 138,951,364

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 138951364...
Checkpoint 138951364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,658.23362
Policy Entropy: 1.05115
Value Function Loss: 0.09972

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.33723
Value Function Update Magnitude: 0.70239

Collected Steps per Second: 21,650.19210
Overall Steps per Second: 10,259.13639

Timestep Collection Time: 2.31083
Timestep Consumption Time: 2.56579
PPO Batch Consumption Time: 0.30669
Total Iteration Time: 4.87663

Cumulative Model Updates: 16,656
Cumulative Timesteps: 139,001,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,673.99295
Policy Entropy: 1.05584
Value Function Loss: 0.10333

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.30771
Value Function Update Magnitude: 0.71605

Collected Steps per Second: 22,002.00277
Overall Steps per Second: 10,431.46570

Timestep Collection Time: 2.27325
Timestep Consumption Time: 2.52148
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.79472

Cumulative Model Updates: 16,662
Cumulative Timesteps: 139,051,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 139051410...
Checkpoint 139051410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,411.27602
Policy Entropy: 1.05830
Value Function Loss: 0.10182

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.31006
Value Function Update Magnitude: 0.73874

Collected Steps per Second: 21,068.01800
Overall Steps per Second: 10,228.15009

Timestep Collection Time: 2.37516
Timestep Consumption Time: 2.51722
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.89238

Cumulative Model Updates: 16,668
Cumulative Timesteps: 139,101,450

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,030.69140
Policy Entropy: 1.06308
Value Function Loss: 0.10086

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.27317
Value Function Update Magnitude: 0.75562

Collected Steps per Second: 21,932.24845
Overall Steps per Second: 10,445.22871

Timestep Collection Time: 2.28084
Timestep Consumption Time: 2.50833
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.78917

Cumulative Model Updates: 16,674
Cumulative Timesteps: 139,151,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 139151474...
Checkpoint 139151474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,930.57801
Policy Entropy: 1.05474
Value Function Loss: 0.10172

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13085
Policy Update Magnitude: 0.26313
Value Function Update Magnitude: 0.72852

Collected Steps per Second: 21,905.75419
Overall Steps per Second: 10,663.70089

Timestep Collection Time: 2.28324
Timestep Consumption Time: 2.40707
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.69030

Cumulative Model Updates: 16,680
Cumulative Timesteps: 139,201,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.46775
Policy Entropy: 1.04783
Value Function Loss: 0.10481

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12301
Policy Update Magnitude: 0.26909
Value Function Update Magnitude: 0.74076

Collected Steps per Second: 22,200.17576
Overall Steps per Second: 10,415.32580

Timestep Collection Time: 2.25241
Timestep Consumption Time: 2.54859
PPO Batch Consumption Time: 0.29836
Total Iteration Time: 4.80100

Cumulative Model Updates: 16,686
Cumulative Timesteps: 139,251,494

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 139251494...
Checkpoint 139251494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,915.22911
Policy Entropy: 1.04044
Value Function Loss: 0.10562

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.11913
Policy Update Magnitude: 0.28594
Value Function Update Magnitude: 0.72122

Collected Steps per Second: 21,478.15363
Overall Steps per Second: 10,252.32685

Timestep Collection Time: 2.32823
Timestep Consumption Time: 2.54930
PPO Batch Consumption Time: 0.30722
Total Iteration Time: 4.87753

Cumulative Model Updates: 16,692
Cumulative Timesteps: 139,301,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,898.87997
Policy Entropy: 1.02921
Value Function Loss: 0.10654

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.30578
Value Function Update Magnitude: 0.75566

Collected Steps per Second: 22,047.59961
Overall Steps per Second: 10,415.62345

Timestep Collection Time: 2.26800
Timestep Consumption Time: 2.53286
PPO Batch Consumption Time: 0.29814
Total Iteration Time: 4.80086

Cumulative Model Updates: 16,698
Cumulative Timesteps: 139,351,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 139351504...
Checkpoint 139351504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,144.43817
Policy Entropy: 1.03405
Value Function Loss: 0.10203

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.30757
Value Function Update Magnitude: 0.78507

Collected Steps per Second: 22,160.59022
Overall Steps per Second: 10,661.52172

Timestep Collection Time: 2.25770
Timestep Consumption Time: 2.43506
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.69276

Cumulative Model Updates: 16,704
Cumulative Timesteps: 139,401,536

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,856.81768
Policy Entropy: 1.03550
Value Function Loss: 0.10446

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.31142
Value Function Update Magnitude: 0.78547

Collected Steps per Second: 21,936.52514
Overall Steps per Second: 10,471.74311

Timestep Collection Time: 2.27985
Timestep Consumption Time: 2.49605
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.77590

Cumulative Model Updates: 16,710
Cumulative Timesteps: 139,451,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 139451548...
Checkpoint 139451548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,982.04932
Policy Entropy: 1.03067
Value Function Loss: 0.10589

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11627
Policy Update Magnitude: 0.32421
Value Function Update Magnitude: 0.76734

Collected Steps per Second: 21,229.35841
Overall Steps per Second: 10,187.41764

Timestep Collection Time: 2.35551
Timestep Consumption Time: 2.55309
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.90860

Cumulative Model Updates: 16,716
Cumulative Timesteps: 139,501,554

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,757.67101
Policy Entropy: 1.04299
Value Function Loss: 0.10755

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11318
Policy Update Magnitude: 0.31815
Value Function Update Magnitude: 0.75595

Collected Steps per Second: 21,705.77526
Overall Steps per Second: 10,333.76746

Timestep Collection Time: 2.30353
Timestep Consumption Time: 2.53497
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.83851

Cumulative Model Updates: 16,722
Cumulative Timesteps: 139,551,554

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 139551554...
Checkpoint 139551554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.58274
Policy Entropy: 1.03693
Value Function Loss: 0.10940

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13449
Policy Update Magnitude: 0.30070
Value Function Update Magnitude: 0.75400

Collected Steps per Second: 21,279.91605
Overall Steps per Second: 10,320.89108

Timestep Collection Time: 2.34982
Timestep Consumption Time: 2.49511
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.84493

Cumulative Model Updates: 16,728
Cumulative Timesteps: 139,601,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,426.21370
Policy Entropy: 1.04534
Value Function Loss: 0.10560

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.15865
Policy Update Magnitude: 0.28159
Value Function Update Magnitude: 0.71461

Collected Steps per Second: 22,092.61239
Overall Steps per Second: 10,480.43728

Timestep Collection Time: 2.26519
Timestep Consumption Time: 2.50980
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.77499

Cumulative Model Updates: 16,734
Cumulative Timesteps: 139,651,602

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 139651602...
Checkpoint 139651602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,132.95949
Policy Entropy: 1.04434
Value Function Loss: 0.10549

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12042
Policy Update Magnitude: 0.29976
Value Function Update Magnitude: 0.69728

Collected Steps per Second: 21,213.53587
Overall Steps per Second: 10,168.67198

Timestep Collection Time: 2.35821
Timestep Consumption Time: 2.56141
PPO Batch Consumption Time: 0.30481
Total Iteration Time: 4.91962

Cumulative Model Updates: 16,740
Cumulative Timesteps: 139,701,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,624.00483
Policy Entropy: 1.05193
Value Function Loss: 0.10626

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.14198
Policy Update Magnitude: 0.27910
Value Function Update Magnitude: 0.69133

Collected Steps per Second: 22,069.66622
Overall Steps per Second: 10,402.81972

Timestep Collection Time: 2.26610
Timestep Consumption Time: 2.54145
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 4.80754

Cumulative Model Updates: 16,746
Cumulative Timesteps: 139,751,640

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 139751640...
Checkpoint 139751640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,236.59877
Policy Entropy: 1.04486
Value Function Loss: 0.11263

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.26931
Value Function Update Magnitude: 0.64686

Collected Steps per Second: 21,812.25015
Overall Steps per Second: 10,333.26174

Timestep Collection Time: 2.29302
Timestep Consumption Time: 2.54727
PPO Batch Consumption Time: 0.30487
Total Iteration Time: 4.84029

Cumulative Model Updates: 16,752
Cumulative Timesteps: 139,801,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,234.67417
Policy Entropy: 1.04886
Value Function Loss: 0.11684

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.27887
Value Function Update Magnitude: 0.59882

Collected Steps per Second: 20,276.92155
Overall Steps per Second: 9,988.12877

Timestep Collection Time: 2.46803
Timestep Consumption Time: 2.54232
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 5.01035

Cumulative Model Updates: 16,758
Cumulative Timesteps: 139,851,700

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 139851700...
Checkpoint 139851700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.08681
Policy Entropy: 1.05592
Value Function Loss: 0.11220

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11596
Policy Update Magnitude: 0.26353
Value Function Update Magnitude: 0.63932

Collected Steps per Second: 21,247.66052
Overall Steps per Second: 10,219.52591

Timestep Collection Time: 2.35405
Timestep Consumption Time: 2.54031
PPO Batch Consumption Time: 0.30037
Total Iteration Time: 4.89436

Cumulative Model Updates: 16,764
Cumulative Timesteps: 139,901,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,823.17284
Policy Entropy: 1.05619
Value Function Loss: 0.10835

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11280
Policy Update Magnitude: 0.26602
Value Function Update Magnitude: 0.58251

Collected Steps per Second: 22,168.48509
Overall Steps per Second: 10,441.27034

Timestep Collection Time: 2.25708
Timestep Consumption Time: 2.53506
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.79214

Cumulative Model Updates: 16,770
Cumulative Timesteps: 139,951,754

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 139951754...
Checkpoint 139951754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,692.11017
Policy Entropy: 1.05120
Value Function Loss: 0.10730

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.29758
Value Function Update Magnitude: 0.57539

Collected Steps per Second: 21,209.60999
Overall Steps per Second: 10,203.00114

Timestep Collection Time: 2.35874
Timestep Consumption Time: 2.54452
PPO Batch Consumption Time: 0.30011
Total Iteration Time: 4.90326

Cumulative Model Updates: 16,776
Cumulative Timesteps: 140,001,782

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,270.95707
Policy Entropy: 1.04871
Value Function Loss: 0.10930

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.31584
Value Function Update Magnitude: 0.61039

Collected Steps per Second: 22,052.81979
Overall Steps per Second: 10,493.17327

Timestep Collection Time: 2.26783
Timestep Consumption Time: 2.49832
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.76615

Cumulative Model Updates: 16,782
Cumulative Timesteps: 140,051,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 140051794...
Checkpoint 140051794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,369.79843
Policy Entropy: 1.07305
Value Function Loss: 0.10257

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.29422
Value Function Update Magnitude: 0.68767

Collected Steps per Second: 21,472.63413
Overall Steps per Second: 10,207.97395

Timestep Collection Time: 2.32957
Timestep Consumption Time: 2.57072
PPO Batch Consumption Time: 0.30653
Total Iteration Time: 4.90029

Cumulative Model Updates: 16,788
Cumulative Timesteps: 140,101,816

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,224.66464
Policy Entropy: 1.07679
Value Function Loss: 0.10031

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.28309
Value Function Update Magnitude: 0.68317

Collected Steps per Second: 22,029.40342
Overall Steps per Second: 10,425.47026

Timestep Collection Time: 2.27106
Timestep Consumption Time: 2.52777
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.79882

Cumulative Model Updates: 16,794
Cumulative Timesteps: 140,151,846

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 140151846...
Checkpoint 140151846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,407.38000
Policy Entropy: 1.07389
Value Function Loss: 0.10050

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.14839
Policy Update Magnitude: 0.27535
Value Function Update Magnitude: 0.68863

Collected Steps per Second: 20,962.66620
Overall Steps per Second: 10,157.42568

Timestep Collection Time: 2.38548
Timestep Consumption Time: 2.53762
PPO Batch Consumption Time: 0.29984
Total Iteration Time: 4.92310

Cumulative Model Updates: 16,800
Cumulative Timesteps: 140,201,852

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,200.30209
Policy Entropy: 1.05769
Value Function Loss: 0.10399

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.26707
Value Function Update Magnitude: 0.71089

Collected Steps per Second: 21,979.30011
Overall Steps per Second: 10,458.81531

Timestep Collection Time: 2.27496
Timestep Consumption Time: 2.50589
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.78085

Cumulative Model Updates: 16,806
Cumulative Timesteps: 140,251,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 140251854...
Checkpoint 140251854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,608.48312
Policy Entropy: 1.05777
Value Function Loss: 0.10471

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.27616
Value Function Update Magnitude: 0.61403

Collected Steps per Second: 21,743.13079
Overall Steps per Second: 10,590.37713

Timestep Collection Time: 2.30197
Timestep Consumption Time: 2.42421
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.72618

Cumulative Model Updates: 16,812
Cumulative Timesteps: 140,301,906

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,365.58323
Policy Entropy: 1.05165
Value Function Loss: 0.10699

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.14572
Policy Update Magnitude: 0.26863
Value Function Update Magnitude: 0.54121

Collected Steps per Second: 21,892.05447
Overall Steps per Second: 10,464.35239

Timestep Collection Time: 2.28448
Timestep Consumption Time: 2.49479
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.77927

Cumulative Model Updates: 16,818
Cumulative Timesteps: 140,351,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 140351918...
Checkpoint 140351918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,312.26402
Policy Entropy: 1.04108
Value Function Loss: 0.10774

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.30710
Value Function Update Magnitude: 0.52256

Collected Steps per Second: 21,803.45795
Overall Steps per Second: 10,302.53041

Timestep Collection Time: 2.29441
Timestep Consumption Time: 2.56129
PPO Batch Consumption Time: 0.30365
Total Iteration Time: 4.85570

Cumulative Model Updates: 16,824
Cumulative Timesteps: 140,401,944

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,126.54234
Policy Entropy: 1.03642
Value Function Loss: 0.11292

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09182
Policy Update Magnitude: 0.32688
Value Function Update Magnitude: 0.54863

Collected Steps per Second: 21,573.30209
Overall Steps per Second: 10,396.38613

Timestep Collection Time: 2.31768
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.80936

Cumulative Model Updates: 16,830
Cumulative Timesteps: 140,451,944

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 140451944...
Checkpoint 140451944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,107.39250
Policy Entropy: 1.03052
Value Function Loss: 0.10997

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08910
Policy Update Magnitude: 0.32858
Value Function Update Magnitude: 0.56874

Collected Steps per Second: 21,686.61891
Overall Steps per Second: 10,255.67109

Timestep Collection Time: 2.30649
Timestep Consumption Time: 2.57081
PPO Batch Consumption Time: 0.30609
Total Iteration Time: 4.87730

Cumulative Model Updates: 16,836
Cumulative Timesteps: 140,501,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,156.91450
Policy Entropy: 1.03721
Value Function Loss: 0.10977

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.32275
Value Function Update Magnitude: 0.53040

Collected Steps per Second: 21,937.24577
Overall Steps per Second: 10,457.80032

Timestep Collection Time: 2.27950
Timestep Consumption Time: 2.50219
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.78169

Cumulative Model Updates: 16,842
Cumulative Timesteps: 140,551,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 140551970...
Checkpoint 140551970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,440.82170
Policy Entropy: 1.04785
Value Function Loss: 0.10891

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08685
Policy Update Magnitude: 0.32254
Value Function Update Magnitude: 0.56908

Collected Steps per Second: 21,385.89404
Overall Steps per Second: 10,221.13758

Timestep Collection Time: 2.33799
Timestep Consumption Time: 2.55383
PPO Batch Consumption Time: 0.30457
Total Iteration Time: 4.89182

Cumulative Model Updates: 16,848
Cumulative Timesteps: 140,601,970

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,761.05544
Policy Entropy: 1.05151
Value Function Loss: 0.10822

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.29577
Value Function Update Magnitude: 0.59636

Collected Steps per Second: 21,852.96410
Overall Steps per Second: 10,431.26359

Timestep Collection Time: 2.28875
Timestep Consumption Time: 2.50607
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.79482

Cumulative Model Updates: 16,854
Cumulative Timesteps: 140,651,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 140651986...
Checkpoint 140651986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793.23410
Policy Entropy: 1.06093
Value Function Loss: 0.10775

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.26327
Value Function Update Magnitude: 0.60891

Collected Steps per Second: 21,435.67176
Overall Steps per Second: 10,260.82712

Timestep Collection Time: 2.33480
Timestep Consumption Time: 2.54278
PPO Batch Consumption Time: 0.30127
Total Iteration Time: 4.87758

Cumulative Model Updates: 16,860
Cumulative Timesteps: 140,702,034

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,118.98441
Policy Entropy: 1.04554
Value Function Loss: 0.10496

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.26261
Value Function Update Magnitude: 0.59914

Collected Steps per Second: 21,803.83763
Overall Steps per Second: 10,477.71336

Timestep Collection Time: 2.29455
Timestep Consumption Time: 2.48035
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.77490

Cumulative Model Updates: 16,866
Cumulative Timesteps: 140,752,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 140752064...
Checkpoint 140752064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,185.59268
Policy Entropy: 1.04520
Value Function Loss: 0.11010

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.26730
Value Function Update Magnitude: 0.53676

Collected Steps per Second: 21,549.19248
Overall Steps per Second: 10,253.70671

Timestep Collection Time: 2.32231
Timestep Consumption Time: 2.55826
PPO Batch Consumption Time: 0.30376
Total Iteration Time: 4.88058

Cumulative Model Updates: 16,872
Cumulative Timesteps: 140,802,108

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.47316
Policy Entropy: 1.03359
Value Function Loss: 0.11176

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.11994
Policy Update Magnitude: 0.27277
Value Function Update Magnitude: 0.48405

Collected Steps per Second: 21,543.68611
Overall Steps per Second: 10,284.01233

Timestep Collection Time: 2.32087
Timestep Consumption Time: 2.54105
PPO Batch Consumption Time: 0.31111
Total Iteration Time: 4.86192

Cumulative Model Updates: 16,878
Cumulative Timesteps: 140,852,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 140852108...
Checkpoint 140852108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,198.73663
Policy Entropy: 1.03389
Value Function Loss: 0.11817

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.27984
Value Function Update Magnitude: 0.47651

Collected Steps per Second: 21,150.91150
Overall Steps per Second: 10,307.92972

Timestep Collection Time: 2.36491
Timestep Consumption Time: 2.48766
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.85257

Cumulative Model Updates: 16,884
Cumulative Timesteps: 140,902,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,896.74882
Policy Entropy: 1.03572
Value Function Loss: 0.11393

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.29806
Value Function Update Magnitude: 0.53229

Collected Steps per Second: 21,952.38052
Overall Steps per Second: 10,471.31093

Timestep Collection Time: 2.27893
Timestep Consumption Time: 2.49869
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.77763

Cumulative Model Updates: 16,890
Cumulative Timesteps: 140,952,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 140952156...
Checkpoint 140952156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,637.16332
Policy Entropy: 1.04105
Value Function Loss: 0.11198

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.27733
Value Function Update Magnitude: 0.60897

Collected Steps per Second: 21,132.41761
Overall Steps per Second: 10,149.80210

Timestep Collection Time: 2.36736
Timestep Consumption Time: 2.56160
PPO Batch Consumption Time: 0.30255
Total Iteration Time: 4.92896

Cumulative Model Updates: 16,896
Cumulative Timesteps: 141,002,184

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,818.87608
Policy Entropy: 1.04225
Value Function Loss: 0.10736

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.27181
Value Function Update Magnitude: 0.62286

Collected Steps per Second: 21,285.66090
Overall Steps per Second: 10,202.03201

Timestep Collection Time: 2.35013
Timestep Consumption Time: 2.55321
PPO Batch Consumption Time: 0.30367
Total Iteration Time: 4.90334

Cumulative Model Updates: 16,902
Cumulative Timesteps: 141,052,208

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 141052208...
Checkpoint 141052208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,879.74188
Policy Entropy: 1.04729
Value Function Loss: 0.10485

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.30150
Value Function Update Magnitude: 0.61655

Collected Steps per Second: 21,566.47946
Overall Steps per Second: 10,436.05364

Timestep Collection Time: 2.32017
Timestep Consumption Time: 2.47455
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.79472

Cumulative Model Updates: 16,908
Cumulative Timesteps: 141,102,246

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,094.32264
Policy Entropy: 1.04510
Value Function Loss: 0.10213

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07387
Policy Update Magnitude: 0.33082
Value Function Update Magnitude: 0.64982

Collected Steps per Second: 21,993.87951
Overall Steps per Second: 10,483.51645

Timestep Collection Time: 2.27354
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.76977

Cumulative Model Updates: 16,914
Cumulative Timesteps: 141,152,250

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 141152250...
Checkpoint 141152250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.88308
Policy Entropy: 1.05126
Value Function Loss: 0.10520

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.32667
Value Function Update Magnitude: 0.68661

Collected Steps per Second: 22,085.85413
Overall Steps per Second: 10,725.26949

Timestep Collection Time: 2.26435
Timestep Consumption Time: 2.39847
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.66282

Cumulative Model Updates: 16,920
Cumulative Timesteps: 141,202,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,631.81501
Policy Entropy: 1.05389
Value Function Loss: 0.10608

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.07134
Policy Update Magnitude: 0.33315
Value Function Update Magnitude: 0.62066

Collected Steps per Second: 21,733.55537
Overall Steps per Second: 10,375.51349

Timestep Collection Time: 2.30179
Timestep Consumption Time: 2.51976
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.82154

Cumulative Model Updates: 16,926
Cumulative Timesteps: 141,252,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 141252286...
Checkpoint 141252286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,836.14095
Policy Entropy: 1.04904
Value Function Loss: 0.11000

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.32917
Value Function Update Magnitude: 0.51560

Collected Steps per Second: 21,874.32446
Overall Steps per Second: 10,670.60306

Timestep Collection Time: 2.28615
Timestep Consumption Time: 2.40037
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.68652

Cumulative Model Updates: 16,932
Cumulative Timesteps: 141,302,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,238.53731
Policy Entropy: 1.05330
Value Function Loss: 0.11087

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08904
Policy Update Magnitude: 0.31624
Value Function Update Magnitude: 0.48664

Collected Steps per Second: 21,994.44761
Overall Steps per Second: 10,471.83688

Timestep Collection Time: 2.27412
Timestep Consumption Time: 2.50231
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.77643

Cumulative Model Updates: 16,938
Cumulative Timesteps: 141,352,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 141352312...
Checkpoint 141352312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,950.07925
Policy Entropy: 1.04756
Value Function Loss: 0.11011

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11281
Policy Update Magnitude: 0.31141
Value Function Update Magnitude: 0.48959

Collected Steps per Second: 21,698.09249
Overall Steps per Second: 10,259.80796

Timestep Collection Time: 2.30444
Timestep Consumption Time: 2.56914
PPO Batch Consumption Time: 0.30570
Total Iteration Time: 4.87358

Cumulative Model Updates: 16,944
Cumulative Timesteps: 141,402,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,273.60626
Policy Entropy: 1.05184
Value Function Loss: 0.10787

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.27368
Value Function Update Magnitude: 0.62541

Collected Steps per Second: 21,811.10294
Overall Steps per Second: 10,425.31318

Timestep Collection Time: 2.29333
Timestep Consumption Time: 2.50461
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.79794

Cumulative Model Updates: 16,950
Cumulative Timesteps: 141,452,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 141452334...
Checkpoint 141452334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,533.20854
Policy Entropy: 1.05347
Value Function Loss: 0.10810

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.25760
Value Function Update Magnitude: 0.62697

Collected Steps per Second: 21,247.83866
Overall Steps per Second: 10,015.78465

Timestep Collection Time: 2.35450
Timestep Consumption Time: 2.64042
PPO Batch Consumption Time: 0.31868
Total Iteration Time: 4.99492

Cumulative Model Updates: 16,956
Cumulative Timesteps: 141,502,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.55584
Policy Entropy: 1.05528
Value Function Loss: 0.10895

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.25709
Value Function Update Magnitude: 0.55931

Collected Steps per Second: 19,858.56846
Overall Steps per Second: 9,371.25895

Timestep Collection Time: 2.51821
Timestep Consumption Time: 2.81811
PPO Batch Consumption Time: 0.33976
Total Iteration Time: 5.33632

Cumulative Model Updates: 16,962
Cumulative Timesteps: 141,552,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 141552370...
Checkpoint 141552370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,239.62635
Policy Entropy: 1.05274
Value Function Loss: 0.10869

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.25023
Value Function Update Magnitude: 0.57133

Collected Steps per Second: 20,340.48119
Overall Steps per Second: 9,696.19143

Timestep Collection Time: 2.45864
Timestep Consumption Time: 2.69905
PPO Batch Consumption Time: 0.33449
Total Iteration Time: 5.15770

Cumulative Model Updates: 16,968
Cumulative Timesteps: 141,602,380

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,071.31845
Policy Entropy: 1.05108
Value Function Loss: 0.10701

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.27111
Value Function Update Magnitude: 0.54386

Collected Steps per Second: 20,029.91395
Overall Steps per Second: 9,403.08845

Timestep Collection Time: 2.49776
Timestep Consumption Time: 2.82283
PPO Batch Consumption Time: 0.33816
Total Iteration Time: 5.32059

Cumulative Model Updates: 16,974
Cumulative Timesteps: 141,652,410

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 141652410...
Checkpoint 141652410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,554.03130
Policy Entropy: 1.05897
Value Function Loss: 0.11104

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.13528
Policy Update Magnitude: 0.26946
Value Function Update Magnitude: 0.54410

Collected Steps per Second: 20,515.73525
Overall Steps per Second: 9,740.77984

Timestep Collection Time: 2.43784
Timestep Consumption Time: 2.69666
PPO Batch Consumption Time: 0.33540
Total Iteration Time: 5.13450

Cumulative Model Updates: 16,980
Cumulative Timesteps: 141,702,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,764.67440
Policy Entropy: 1.06222
Value Function Loss: 0.10907

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.29159
Value Function Update Magnitude: 0.57904

Collected Steps per Second: 20,250.54021
Overall Steps per Second: 9,461.62631

Timestep Collection Time: 2.46996
Timestep Consumption Time: 2.81645
PPO Batch Consumption Time: 0.34492
Total Iteration Time: 5.28641

Cumulative Model Updates: 16,986
Cumulative Timesteps: 141,752,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 141752442...
Checkpoint 141752442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.63234
Policy Entropy: 1.05491
Value Function Loss: 0.10546

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.28341
Value Function Update Magnitude: 0.64481

Collected Steps per Second: 20,374.46582
Overall Steps per Second: 9,715.83711

Timestep Collection Time: 2.45552
Timestep Consumption Time: 2.69380
PPO Batch Consumption Time: 0.33424
Total Iteration Time: 5.14932

Cumulative Model Updates: 16,992
Cumulative Timesteps: 141,802,472

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,440.65855
Policy Entropy: 1.05246
Value Function Loss: 0.10189

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.29007
Value Function Update Magnitude: 0.66723

Collected Steps per Second: 19,943.30994
Overall Steps per Second: 9,401.25600

Timestep Collection Time: 2.50711
Timestep Consumption Time: 2.81133
PPO Batch Consumption Time: 0.34228
Total Iteration Time: 5.31844

Cumulative Model Updates: 16,998
Cumulative Timesteps: 141,852,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 141852472...
Checkpoint 141852472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,141.31141
Policy Entropy: 1.05844
Value Function Loss: 0.10197

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11241
Policy Update Magnitude: 0.28698
Value Function Update Magnitude: 0.62968

Collected Steps per Second: 19,508.10547
Overall Steps per Second: 9,788.28883

Timestep Collection Time: 2.56447
Timestep Consumption Time: 2.54653
PPO Batch Consumption Time: 0.30808
Total Iteration Time: 5.11101

Cumulative Model Updates: 17,004
Cumulative Timesteps: 141,902,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,697.91467
Policy Entropy: 1.05108
Value Function Loss: 0.10701

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.29338
Value Function Update Magnitude: 0.58620

Collected Steps per Second: 21,425.46750
Overall Steps per Second: 9,872.56241

Timestep Collection Time: 2.33414
Timestep Consumption Time: 2.73142
PPO Batch Consumption Time: 0.32482
Total Iteration Time: 5.06555

Cumulative Model Updates: 17,010
Cumulative Timesteps: 141,952,510

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 141952510...
Checkpoint 141952510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,175.48166
Policy Entropy: 1.05549
Value Function Loss: 0.10446

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12270
Policy Update Magnitude: 0.30178
Value Function Update Magnitude: 0.62393

Collected Steps per Second: 21,704.33334
Overall Steps per Second: 10,490.85381

Timestep Collection Time: 2.30498
Timestep Consumption Time: 2.46375
PPO Batch Consumption Time: 0.29866
Total Iteration Time: 4.76873

Cumulative Model Updates: 17,016
Cumulative Timesteps: 142,002,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,068.90578
Policy Entropy: 1.06173
Value Function Loss: 0.10549

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.15551
Policy Update Magnitude: 0.27905
Value Function Update Magnitude: 0.65569

Collected Steps per Second: 19,968.98504
Overall Steps per Second: 9,472.58233

Timestep Collection Time: 2.50498
Timestep Consumption Time: 2.77573
PPO Batch Consumption Time: 0.33186
Total Iteration Time: 5.28071

Cumulative Model Updates: 17,022
Cumulative Timesteps: 142,052,560

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 142052560...
Checkpoint 142052560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,064.72941
Policy Entropy: 1.07726
Value Function Loss: 0.10493

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.30236
Value Function Update Magnitude: 0.65441

Collected Steps per Second: 18,353.84431
Overall Steps per Second: 9,084.19593

Timestep Collection Time: 2.72499
Timestep Consumption Time: 2.78062
PPO Batch Consumption Time: 0.34580
Total Iteration Time: 5.50561

Cumulative Model Updates: 17,028
Cumulative Timesteps: 142,102,574

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.35182
Policy Entropy: 1.07565
Value Function Loss: 0.10821

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.12404
Policy Update Magnitude: 0.29397
Value Function Update Magnitude: 0.61971

Collected Steps per Second: 17,860.61375
Overall Steps per Second: 9,091.27861

Timestep Collection Time: 2.80136
Timestep Consumption Time: 2.70216
PPO Batch Consumption Time: 0.31418
Total Iteration Time: 5.50352

Cumulative Model Updates: 17,034
Cumulative Timesteps: 142,152,608

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 142152608...
Checkpoint 142152608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,529.49020
Policy Entropy: 1.06732
Value Function Loss: 0.10669

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.25800
Value Function Update Magnitude: 0.59177

Collected Steps per Second: 18,943.15957
Overall Steps per Second: 9,129.53557

Timestep Collection Time: 2.64000
Timestep Consumption Time: 2.83782
PPO Batch Consumption Time: 0.34474
Total Iteration Time: 5.47783

Cumulative Model Updates: 17,040
Cumulative Timesteps: 142,202,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,659.07063
Policy Entropy: 1.05492
Value Function Loss: 0.11397

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.26607
Value Function Update Magnitude: 0.52982

Collected Steps per Second: 20,917.10380
Overall Steps per Second: 10,019.35217

Timestep Collection Time: 2.39106
Timestep Consumption Time: 2.60068
PPO Batch Consumption Time: 0.32283
Total Iteration Time: 4.99174

Cumulative Model Updates: 17,046
Cumulative Timesteps: 142,252,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 142252632...
Checkpoint 142252632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,265.79280
Policy Entropy: 1.06448
Value Function Loss: 0.11091

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.29553
Value Function Update Magnitude: 0.62463

Collected Steps per Second: 20,931.06182
Overall Steps per Second: 10,158.88293

Timestep Collection Time: 2.38908
Timestep Consumption Time: 2.53331
PPO Batch Consumption Time: 0.31052
Total Iteration Time: 4.92239

Cumulative Model Updates: 17,052
Cumulative Timesteps: 142,302,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,397.25393
Policy Entropy: 1.06240
Value Function Loss: 0.10966

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08208
Policy Update Magnitude: 0.32622
Value Function Update Magnitude: 0.64759

Collected Steps per Second: 20,961.15910
Overall Steps per Second: 9,920.84887

Timestep Collection Time: 2.38556
Timestep Consumption Time: 2.65474
PPO Batch Consumption Time: 0.31886
Total Iteration Time: 5.04029

Cumulative Model Updates: 17,058
Cumulative Timesteps: 142,352,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 142352642...
Checkpoint 142352642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,500.38147
Policy Entropy: 1.05988
Value Function Loss: 0.10367

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.33909
Value Function Update Magnitude: 0.64515

Collected Steps per Second: 21,059.14889
Overall Steps per Second: 10,031.21714

Timestep Collection Time: 2.37683
Timestep Consumption Time: 2.61299
PPO Batch Consumption Time: 0.30736
Total Iteration Time: 4.98982

Cumulative Model Updates: 17,064
Cumulative Timesteps: 142,402,696

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.22229
Policy Entropy: 1.06497
Value Function Loss: 0.10202

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07552
Policy Update Magnitude: 0.33963
Value Function Update Magnitude: 0.61444

Collected Steps per Second: 21,192.45663
Overall Steps per Second: 10,079.25127

Timestep Collection Time: 2.35990
Timestep Consumption Time: 2.60198
PPO Batch Consumption Time: 0.30463
Total Iteration Time: 4.96188

Cumulative Model Updates: 17,070
Cumulative Timesteps: 142,452,708

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 142452708...
Checkpoint 142452708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.02591
Policy Entropy: 1.05672
Value Function Loss: 0.10750

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07321
Policy Update Magnitude: 0.33717
Value Function Update Magnitude: 0.55310

Collected Steps per Second: 20,495.55743
Overall Steps per Second: 9,815.73243

Timestep Collection Time: 2.44102
Timestep Consumption Time: 2.65590
PPO Batch Consumption Time: 0.31826
Total Iteration Time: 5.09692

Cumulative Model Updates: 17,076
Cumulative Timesteps: 142,502,738

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,035.03773
Policy Entropy: 1.05970
Value Function Loss: 0.10478

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07475
Policy Update Magnitude: 0.33347
Value Function Update Magnitude: 0.54686

Collected Steps per Second: 21,332.15905
Overall Steps per Second: 10,218.35672

Timestep Collection Time: 2.34538
Timestep Consumption Time: 2.55091
PPO Batch Consumption Time: 0.29930
Total Iteration Time: 4.89629

Cumulative Model Updates: 17,082
Cumulative Timesteps: 142,552,770

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 142552770...
Checkpoint 142552770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,863.06228
Policy Entropy: 1.05539
Value Function Loss: 0.10645

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.32626
Value Function Update Magnitude: 0.53664

Collected Steps per Second: 20,955.90766
Overall Steps per Second: 10,105.93969

Timestep Collection Time: 2.38787
Timestep Consumption Time: 2.56367
PPO Batch Consumption Time: 0.29930
Total Iteration Time: 4.95154

Cumulative Model Updates: 17,088
Cumulative Timesteps: 142,602,810

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,973.50586
Policy Entropy: 1.06895
Value Function Loss: 0.10521

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.28642
Value Function Update Magnitude: 0.55287

Collected Steps per Second: 21,292.52169
Overall Steps per Second: 10,204.81193

Timestep Collection Time: 2.34984
Timestep Consumption Time: 2.55314
PPO Batch Consumption Time: 0.29986
Total Iteration Time: 4.90298

Cumulative Model Updates: 17,094
Cumulative Timesteps: 142,652,844

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 142652844...
Checkpoint 142652844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,748.89163
Policy Entropy: 1.06334
Value Function Loss: 0.10854

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.13687
Policy Update Magnitude: 0.27918
Value Function Update Magnitude: 0.52928

Collected Steps per Second: 20,842.05138
Overall Steps per Second: 10,113.97812

Timestep Collection Time: 2.39948
Timestep Consumption Time: 2.54517
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 4.94464

Cumulative Model Updates: 17,100
Cumulative Timesteps: 142,702,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.62039
Policy Entropy: 1.04914
Value Function Loss: 0.10849

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.27991
Value Function Update Magnitude: 0.52572

Collected Steps per Second: 20,425.14998
Overall Steps per Second: 9,822.61394

Timestep Collection Time: 2.44933
Timestep Consumption Time: 2.64381
PPO Batch Consumption Time: 0.31093
Total Iteration Time: 5.09315

Cumulative Model Updates: 17,106
Cumulative Timesteps: 142,752,882

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 142752882...
Checkpoint 142752882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,945.14790
Policy Entropy: 1.03663
Value Function Loss: 0.10992

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.15714
Policy Update Magnitude: 0.26774
Value Function Update Magnitude: 0.58187

Collected Steps per Second: 20,501.43100
Overall Steps per Second: 9,918.91433

Timestep Collection Time: 2.43895
Timestep Consumption Time: 2.60212
PPO Batch Consumption Time: 0.30784
Total Iteration Time: 5.04108

Cumulative Model Updates: 17,112
Cumulative Timesteps: 142,802,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,022.10417
Policy Entropy: 1.04548
Value Function Loss: 0.10969

Mean KL Divergence: 0.02874
SB3 Clip Fraction: 0.20880
Policy Update Magnitude: 0.24492
Value Function Update Magnitude: 0.60418

Collected Steps per Second: 21,181.73978
Overall Steps per Second: 10,096.91842

Timestep Collection Time: 2.36071
Timestep Consumption Time: 2.59169
PPO Batch Consumption Time: 0.30589
Total Iteration Time: 4.95240

Cumulative Model Updates: 17,118
Cumulative Timesteps: 142,852,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 142852888...
Checkpoint 142852888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,558.04839
Policy Entropy: 1.06799
Value Function Loss: 0.11171

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.29048
Value Function Update Magnitude: 0.57473

Collected Steps per Second: 20,912.87895
Overall Steps per Second: 10,001.12813

Timestep Collection Time: 2.39087
Timestep Consumption Time: 2.60856
PPO Batch Consumption Time: 0.31074
Total Iteration Time: 4.99944

Cumulative Model Updates: 17,124
Cumulative Timesteps: 142,902,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,246.52444
Policy Entropy: 1.07130
Value Function Loss: 0.10935

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.33505
Value Function Update Magnitude: 0.51237

Collected Steps per Second: 21,175.61809
Overall Steps per Second: 10,131.96942

Timestep Collection Time: 2.36206
Timestep Consumption Time: 2.57460
PPO Batch Consumption Time: 0.30262
Total Iteration Time: 4.93665

Cumulative Model Updates: 17,130
Cumulative Timesteps: 142,952,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 142952906...
Checkpoint 142952906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,616.90939
Policy Entropy: 1.07743
Value Function Loss: 0.10495

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.34283
Value Function Update Magnitude: 0.52241

Collected Steps per Second: 20,858.57787
Overall Steps per Second: 10,181.54821

Timestep Collection Time: 2.39738
Timestep Consumption Time: 2.51405
PPO Batch Consumption Time: 0.30595
Total Iteration Time: 4.91143

Cumulative Model Updates: 17,136
Cumulative Timesteps: 143,002,912

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,608.26858
Policy Entropy: 1.07372
Value Function Loss: 0.09918

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.32556
Value Function Update Magnitude: 0.58305

Collected Steps per Second: 20,847.44749
Overall Steps per Second: 9,988.77750

Timestep Collection Time: 2.39933
Timestep Consumption Time: 2.60829
PPO Batch Consumption Time: 0.30937
Total Iteration Time: 5.00762

Cumulative Model Updates: 17,142
Cumulative Timesteps: 143,052,932

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 143052932...
Checkpoint 143052932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,167.17096
Policy Entropy: 1.07142
Value Function Loss: 0.10165

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.27352
Value Function Update Magnitude: 0.67508

Collected Steps per Second: 20,973.33656
Overall Steps per Second: 10,061.31541

Timestep Collection Time: 2.38512
Timestep Consumption Time: 2.58679
PPO Batch Consumption Time: 0.31927
Total Iteration Time: 4.97191

Cumulative Model Updates: 17,148
Cumulative Timesteps: 143,102,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,951.48416
Policy Entropy: 1.07985
Value Function Loss: 0.09821

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08035
Policy Update Magnitude: 0.29647
Value Function Update Magnitude: 0.64580

Collected Steps per Second: 21,252.68060
Overall Steps per Second: 9,916.62302

Timestep Collection Time: 2.35264
Timestep Consumption Time: 2.68939
PPO Batch Consumption Time: 0.32151
Total Iteration Time: 5.04204

Cumulative Model Updates: 17,154
Cumulative Timesteps: 143,152,956

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 143152956...
Checkpoint 143152956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,612.25686
Policy Entropy: 1.09313
Value Function Loss: 0.10393

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.34253
Value Function Update Magnitude: 0.64969

Collected Steps per Second: 20,923.79903
Overall Steps per Second: 10,077.74537

Timestep Collection Time: 2.39096
Timestep Consumption Time: 2.57324
PPO Batch Consumption Time: 0.30543
Total Iteration Time: 4.96421

Cumulative Model Updates: 17,160
Cumulative Timesteps: 143,202,984

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,147.41937
Policy Entropy: 1.08715
Value Function Loss: 0.10347

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.36124
Value Function Update Magnitude: 0.64473

Collected Steps per Second: 21,048.95059
Overall Steps per Second: 9,996.82005

Timestep Collection Time: 2.37694
Timestep Consumption Time: 2.62786
PPO Batch Consumption Time: 0.31176
Total Iteration Time: 5.00479

Cumulative Model Updates: 17,166
Cumulative Timesteps: 143,253,016

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 143253016...
Checkpoint 143253016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,660.15279
Policy Entropy: 1.09107
Value Function Loss: 0.10533

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08606
Policy Update Magnitude: 0.36768
Value Function Update Magnitude: 0.70831

Collected Steps per Second: 20,939.79656
Overall Steps per Second: 10,081.93258

Timestep Collection Time: 2.38866
Timestep Consumption Time: 2.57249
PPO Batch Consumption Time: 0.30344
Total Iteration Time: 4.96115

Cumulative Model Updates: 17,172
Cumulative Timesteps: 143,303,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,158.48939
Policy Entropy: 1.07335
Value Function Loss: 0.10750

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.36630
Value Function Update Magnitude: 0.69010

Collected Steps per Second: 21,558.29756
Overall Steps per Second: 10,190.46031

Timestep Collection Time: 2.31929
Timestep Consumption Time: 2.58726
PPO Batch Consumption Time: 0.30596
Total Iteration Time: 4.90655

Cumulative Model Updates: 17,178
Cumulative Timesteps: 143,353,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 143353034...
Checkpoint 143353034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,500.65576
Policy Entropy: 1.07766
Value Function Loss: 0.10930

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.35036
Value Function Update Magnitude: 0.65360

Collected Steps per Second: 20,913.95208
Overall Steps per Second: 10,051.05079

Timestep Collection Time: 2.39228
Timestep Consumption Time: 2.58551
PPO Batch Consumption Time: 0.30605
Total Iteration Time: 4.97779

Cumulative Model Updates: 17,184
Cumulative Timesteps: 143,403,066

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,245.85653
Policy Entropy: 1.07463
Value Function Loss: 0.11223

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11167
Policy Update Magnitude: 0.32340
Value Function Update Magnitude: 0.56859

Collected Steps per Second: 21,372.40486
Overall Steps per Second: 10,155.88353

Timestep Collection Time: 2.33956
Timestep Consumption Time: 2.58389
PPO Batch Consumption Time: 0.30844
Total Iteration Time: 4.92345

Cumulative Model Updates: 17,190
Cumulative Timesteps: 143,453,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 143453068...
Checkpoint 143453068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,729.05013
Policy Entropy: 1.07362
Value Function Loss: 0.11141

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.28407
Value Function Update Magnitude: 0.53030

Collected Steps per Second: 20,909.01088
Overall Steps per Second: 9,971.11925

Timestep Collection Time: 2.39131
Timestep Consumption Time: 2.62317
PPO Batch Consumption Time: 0.31195
Total Iteration Time: 5.01448

Cumulative Model Updates: 17,196
Cumulative Timesteps: 143,503,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,688.18661
Policy Entropy: 1.07687
Value Function Loss: 0.10807

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.28261
Value Function Update Magnitude: 0.50585

Collected Steps per Second: 20,958.42231
Overall Steps per Second: 10,058.85733

Timestep Collection Time: 2.38653
Timestep Consumption Time: 2.58600
PPO Batch Consumption Time: 0.30392
Total Iteration Time: 4.97253

Cumulative Model Updates: 17,202
Cumulative Timesteps: 143,553,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 143553086...
Checkpoint 143553086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,189.55101
Policy Entropy: 1.07801
Value Function Loss: 0.10633

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.15104
Policy Update Magnitude: 0.27011
Value Function Update Magnitude: 0.49400

Collected Steps per Second: 21,209.88898
Overall Steps per Second: 10,241.92514

Timestep Collection Time: 2.35815
Timestep Consumption Time: 2.52531
PPO Batch Consumption Time: 0.30793
Total Iteration Time: 4.88346

Cumulative Model Updates: 17,208
Cumulative Timesteps: 143,603,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,242.28836
Policy Entropy: 1.07306
Value Function Loss: 0.10516

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.27371
Value Function Update Magnitude: 0.50481

Collected Steps per Second: 21,100.92792
Overall Steps per Second: 10,060.31523

Timestep Collection Time: 2.37032
Timestep Consumption Time: 2.60129
PPO Batch Consumption Time: 0.31059
Total Iteration Time: 4.97161

Cumulative Model Updates: 17,214
Cumulative Timesteps: 143,653,118

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 143653118...
Checkpoint 143653118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,473.11862
Policy Entropy: 1.06932
Value Function Loss: 0.10497

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.28181
Value Function Update Magnitude: 0.49644

Collected Steps per Second: 20,773.20194
Overall Steps per Second: 9,781.51934

Timestep Collection Time: 2.40733
Timestep Consumption Time: 2.70517
PPO Batch Consumption Time: 0.31677
Total Iteration Time: 5.11250

Cumulative Model Updates: 17,220
Cumulative Timesteps: 143,703,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,753.74510
Policy Entropy: 1.05828
Value Function Loss: 0.11009

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.28096
Value Function Update Magnitude: 0.52001

Collected Steps per Second: 20,780.67291
Overall Steps per Second: 10,003.19840

Timestep Collection Time: 2.40685
Timestep Consumption Time: 2.59315
PPO Batch Consumption Time: 0.30954
Total Iteration Time: 5.00000

Cumulative Model Updates: 17,226
Cumulative Timesteps: 143,753,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 143753142...
Checkpoint 143753142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,942.63766
Policy Entropy: 1.05851
Value Function Loss: 0.10443

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.29194
Value Function Update Magnitude: 0.55823

Collected Steps per Second: 21,060.63487
Overall Steps per Second: 10,223.11639

Timestep Collection Time: 2.37429
Timestep Consumption Time: 2.51698
PPO Batch Consumption Time: 0.30593
Total Iteration Time: 4.89127

Cumulative Model Updates: 17,232
Cumulative Timesteps: 143,803,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,162.91623
Policy Entropy: 1.05624
Value Function Loss: 0.10384

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.29937
Value Function Update Magnitude: 0.56879

Collected Steps per Second: 20,977.68311
Overall Steps per Second: 10,020.43673

Timestep Collection Time: 2.38558
Timestep Consumption Time: 2.60861
PPO Batch Consumption Time: 0.30784
Total Iteration Time: 4.99419

Cumulative Model Updates: 17,238
Cumulative Timesteps: 143,853,190

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 143853190...
Checkpoint 143853190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,466.85271
Policy Entropy: 1.07012
Value Function Loss: 0.10420

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.29229
Value Function Update Magnitude: 0.62809

Collected Steps per Second: 20,591.06882
Overall Steps per Second: 9,824.32841

Timestep Collection Time: 2.42911
Timestep Consumption Time: 2.66213
PPO Batch Consumption Time: 0.32020
Total Iteration Time: 5.09124

Cumulative Model Updates: 17,244
Cumulative Timesteps: 143,903,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,201.62000
Policy Entropy: 1.06994
Value Function Loss: 0.10077

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.28121
Value Function Update Magnitude: 0.61107

Collected Steps per Second: 20,918.18737
Overall Steps per Second: 10,015.57373

Timestep Collection Time: 2.39237
Timestep Consumption Time: 2.60425
PPO Batch Consumption Time: 0.30789
Total Iteration Time: 4.99662

Cumulative Model Updates: 17,250
Cumulative Timesteps: 143,953,252

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 143953252...
Checkpoint 143953252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,122.00250
Policy Entropy: 1.06704
Value Function Loss: 0.10785

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12345
Policy Update Magnitude: 0.26922
Value Function Update Magnitude: 0.50005

Collected Steps per Second: 20,467.49169
Overall Steps per Second: 9,801.25450

Timestep Collection Time: 2.44309
Timestep Consumption Time: 2.65870
PPO Batch Consumption Time: 0.31849
Total Iteration Time: 5.10180

Cumulative Model Updates: 17,256
Cumulative Timesteps: 144,003,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,507.13440
Policy Entropy: 1.06992
Value Function Loss: 0.10839

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.28470
Value Function Update Magnitude: 0.48336

Collected Steps per Second: 21,045.22662
Overall Steps per Second: 10,071.15036

Timestep Collection Time: 2.37622
Timestep Consumption Time: 2.58925
PPO Batch Consumption Time: 0.30592
Total Iteration Time: 4.96547

Cumulative Model Updates: 17,262
Cumulative Timesteps: 144,053,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 144053264...
Checkpoint 144053264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,991.45249
Policy Entropy: 1.06338
Value Function Loss: 0.11385

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.27475
Value Function Update Magnitude: 0.49978

Collected Steps per Second: 21,220.31852
Overall Steps per Second: 10,268.95370

Timestep Collection Time: 2.35680
Timestep Consumption Time: 2.51342
PPO Batch Consumption Time: 0.30716
Total Iteration Time: 4.87021

Cumulative Model Updates: 17,268
Cumulative Timesteps: 144,103,276

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,818.58046
Policy Entropy: 1.07194
Value Function Loss: 0.10591

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.30225
Value Function Update Magnitude: 0.51939

Collected Steps per Second: 21,154.99254
Overall Steps per Second: 9,945.30322

Timestep Collection Time: 2.36379
Timestep Consumption Time: 2.66431
PPO Batch Consumption Time: 0.31288
Total Iteration Time: 5.02810

Cumulative Model Updates: 17,274
Cumulative Timesteps: 144,153,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 144153282...
Checkpoint 144153282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,633.84274
Policy Entropy: 1.07698
Value Function Loss: 0.10314

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10862
Policy Update Magnitude: 0.32728
Value Function Update Magnitude: 0.50411

Collected Steps per Second: 20,949.66481
Overall Steps per Second: 9,916.64821

Timestep Collection Time: 2.38763
Timestep Consumption Time: 2.65642
PPO Batch Consumption Time: 0.31698
Total Iteration Time: 5.04404

Cumulative Model Updates: 17,280
Cumulative Timesteps: 144,203,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,234.50380
Policy Entropy: 1.08064
Value Function Loss: 0.09935

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.32345
Value Function Update Magnitude: 0.54827

Collected Steps per Second: 21,284.59470
Overall Steps per Second: 10,003.97667

Timestep Collection Time: 2.34977
Timestep Consumption Time: 2.64964
PPO Batch Consumption Time: 0.31995
Total Iteration Time: 4.99941

Cumulative Model Updates: 17,286
Cumulative Timesteps: 144,253,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 144253316...
Checkpoint 144253316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,912.74232
Policy Entropy: 1.08279
Value Function Loss: 0.10192

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.32276
Value Function Update Magnitude: 0.53492

Collected Steps per Second: 21,338.90837
Overall Steps per Second: 10,291.59830

Timestep Collection Time: 2.34436
Timestep Consumption Time: 2.51650
PPO Batch Consumption Time: 0.30712
Total Iteration Time: 4.86086

Cumulative Model Updates: 17,292
Cumulative Timesteps: 144,303,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,954.45101
Policy Entropy: 1.07941
Value Function Loss: 0.10305

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.29463
Value Function Update Magnitude: 0.53716

Collected Steps per Second: 21,062.61122
Overall Steps per Second: 9,780.78817

Timestep Collection Time: 2.37473
Timestep Consumption Time: 2.73917
PPO Batch Consumption Time: 0.32505
Total Iteration Time: 5.11390

Cumulative Model Updates: 17,298
Cumulative Timesteps: 144,353,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 144353360...
Checkpoint 144353360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,196.17326
Policy Entropy: 1.08165
Value Function Loss: 0.10247

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13304
Policy Update Magnitude: 0.28937
Value Function Update Magnitude: 0.54900

Collected Steps per Second: 21,344.42571
Overall Steps per Second: 10,224.21985

Timestep Collection Time: 2.34338
Timestep Consumption Time: 2.54873
PPO Batch Consumption Time: 0.30931
Total Iteration Time: 4.89211

Cumulative Model Updates: 17,304
Cumulative Timesteps: 144,403,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,107.58021
Policy Entropy: 1.07778
Value Function Loss: 0.09893

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.13725
Policy Update Magnitude: 0.28761
Value Function Update Magnitude: 0.52306

Collected Steps per Second: 21,070.11766
Overall Steps per Second: 10,032.51341

Timestep Collection Time: 2.37398
Timestep Consumption Time: 2.61181
PPO Batch Consumption Time: 0.31002
Total Iteration Time: 4.98579

Cumulative Model Updates: 17,310
Cumulative Timesteps: 144,453,398

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 144453398...
Checkpoint 144453398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,126.18655
Policy Entropy: 1.08629
Value Function Loss: 0.09663

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.28436
Value Function Update Magnitude: 0.51879

Collected Steps per Second: 20,533.04413
Overall Steps per Second: 10,034.21367

Timestep Collection Time: 2.43676
Timestep Consumption Time: 2.54958
PPO Batch Consumption Time: 0.30000
Total Iteration Time: 4.98634

Cumulative Model Updates: 17,316
Cumulative Timesteps: 144,503,432

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,301.47842
Policy Entropy: 1.07385
Value Function Loss: 0.09871

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11746
Policy Update Magnitude: 0.28116
Value Function Update Magnitude: 0.52008

Collected Steps per Second: 20,867.67764
Overall Steps per Second: 9,894.93233

Timestep Collection Time: 2.39663
Timestep Consumption Time: 2.65768
PPO Batch Consumption Time: 0.31843
Total Iteration Time: 5.05430

Cumulative Model Updates: 17,322
Cumulative Timesteps: 144,553,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 144553444...
Checkpoint 144553444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,345.36121
Policy Entropy: 1.07676
Value Function Loss: 0.10148

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12408
Policy Update Magnitude: 0.29757
Value Function Update Magnitude: 0.52549

Collected Steps per Second: 20,925.85532
Overall Steps per Second: 10,007.92007

Timestep Collection Time: 2.39054
Timestep Consumption Time: 2.60791
PPO Batch Consumption Time: 0.31070
Total Iteration Time: 4.99844

Cumulative Model Updates: 17,328
Cumulative Timesteps: 144,603,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,952.52310
Policy Entropy: 1.07844
Value Function Loss: 0.10103

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.12159
Policy Update Magnitude: 0.31423
Value Function Update Magnitude: 0.55080

Collected Steps per Second: 21,238.28926
Overall Steps per Second: 10,185.70749

Timestep Collection Time: 2.35480
Timestep Consumption Time: 2.55521
PPO Batch Consumption Time: 0.30156
Total Iteration Time: 4.91002

Cumulative Model Updates: 17,334
Cumulative Timesteps: 144,653,480

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 144653480...
Checkpoint 144653480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,153.48949
Policy Entropy: 1.08451
Value Function Loss: 0.09695

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.31538
Value Function Update Magnitude: 0.63768

Collected Steps per Second: 21,070.08527
Overall Steps per Second: 10,125.39403

Timestep Collection Time: 2.37332
Timestep Consumption Time: 2.56535
PPO Batch Consumption Time: 0.30634
Total Iteration Time: 4.93867

Cumulative Model Updates: 17,340
Cumulative Timesteps: 144,703,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,377.43816
Policy Entropy: 1.08453
Value Function Loss: 0.09980

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.30109
Value Function Update Magnitude: 0.61703

Collected Steps per Second: 21,410.99044
Overall Steps per Second: 10,272.17758

Timestep Collection Time: 2.33544
Timestep Consumption Time: 2.53247
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.86791

Cumulative Model Updates: 17,346
Cumulative Timesteps: 144,753,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 144753490...
Checkpoint 144753490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,314.48169
Policy Entropy: 1.08442
Value Function Loss: 0.09772

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.33830
Value Function Update Magnitude: 0.55753

Collected Steps per Second: 21,325.66250
Overall Steps per Second: 10,205.71833

Timestep Collection Time: 2.34544
Timestep Consumption Time: 2.55554
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.90098

Cumulative Model Updates: 17,352
Cumulative Timesteps: 144,803,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,431.14046
Policy Entropy: 1.10167
Value Function Loss: 0.10111

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.12391
Policy Update Magnitude: 0.33643
Value Function Update Magnitude: 0.52309

Collected Steps per Second: 21,545.76105
Overall Steps per Second: 10,091.13633

Timestep Collection Time: 2.32176
Timestep Consumption Time: 2.63547
PPO Batch Consumption Time: 0.30956
Total Iteration Time: 4.95722

Cumulative Model Updates: 17,358
Cumulative Timesteps: 144,853,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 144853532...
Checkpoint 144853532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,094.42595
Policy Entropy: 1.09039
Value Function Loss: 0.09921

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.30455
Value Function Update Magnitude: 0.54607

Collected Steps per Second: 20,813.99359
Overall Steps per Second: 10,085.09140

Timestep Collection Time: 2.40319
Timestep Consumption Time: 2.55661
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.95980

Cumulative Model Updates: 17,364
Cumulative Timesteps: 144,903,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,301.86824
Policy Entropy: 1.08574
Value Function Loss: 0.10082

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13780
Policy Update Magnitude: 0.29488
Value Function Update Magnitude: 0.60322

Collected Steps per Second: 21,584.24063
Overall Steps per Second: 10,163.40608

Timestep Collection Time: 2.31752
Timestep Consumption Time: 2.60425
PPO Batch Consumption Time: 0.30953
Total Iteration Time: 4.92178

Cumulative Model Updates: 17,370
Cumulative Timesteps: 144,953,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 144953574...
Checkpoint 144953574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,832.13533
Policy Entropy: 1.07550
Value Function Loss: 0.10321

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.12392
Policy Update Magnitude: 0.30979
Value Function Update Magnitude: 0.63241

Collected Steps per Second: 20,868.10778
Overall Steps per Second: 10,178.71808

Timestep Collection Time: 2.39705
Timestep Consumption Time: 2.51732
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.91437

Cumulative Model Updates: 17,376
Cumulative Timesteps: 145,003,596

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,510.76364
Policy Entropy: 1.08465
Value Function Loss: 0.10454

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.30117
Value Function Update Magnitude: 0.65929

Collected Steps per Second: 21,029.22692
Overall Steps per Second: 9,926.66243

Timestep Collection Time: 2.37802
Timestep Consumption Time: 2.65972
PPO Batch Consumption Time: 0.32044
Total Iteration Time: 5.03775

Cumulative Model Updates: 17,382
Cumulative Timesteps: 145,053,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 145053604...
Checkpoint 145053604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,584.58248
Policy Entropy: 1.08069
Value Function Loss: 0.10222

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11774
Policy Update Magnitude: 0.29532
Value Function Update Magnitude: 0.66069

Collected Steps per Second: 20,851.58194
Overall Steps per Second: 10,073.44529

Timestep Collection Time: 2.39790
Timestep Consumption Time: 2.56565
PPO Batch Consumption Time: 0.30552
Total Iteration Time: 4.96355

Cumulative Model Updates: 17,388
Cumulative Timesteps: 145,103,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,339.26719
Policy Entropy: 1.08447
Value Function Loss: 0.09423

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09132
Policy Update Magnitude: 0.32775
Value Function Update Magnitude: 0.63795

Collected Steps per Second: 21,568.65138
Overall Steps per Second: 10,327.81982

Timestep Collection Time: 2.31938
Timestep Consumption Time: 2.52443
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.84381

Cumulative Model Updates: 17,394
Cumulative Timesteps: 145,153,630

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 145153630...
Checkpoint 145153630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,118.04217
Policy Entropy: 1.09461
Value Function Loss: 0.09179

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.33588
Value Function Update Magnitude: 0.58969

Collected Steps per Second: 21,143.17213
Overall Steps per Second: 10,174.76300

Timestep Collection Time: 2.36530
Timestep Consumption Time: 2.54980
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.91510

Cumulative Model Updates: 17,400
Cumulative Timesteps: 145,203,640

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,611.20889
Policy Entropy: 1.10735
Value Function Loss: 0.09678

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.33906
Value Function Update Magnitude: 0.52788

Collected Steps per Second: 21,699.73222
Overall Steps per Second: 10,221.21241

Timestep Collection Time: 2.30445
Timestep Consumption Time: 2.58792
PPO Batch Consumption Time: 0.30662
Total Iteration Time: 4.89237

Cumulative Model Updates: 17,406
Cumulative Timesteps: 145,253,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 145253646...
Checkpoint 145253646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,100.56584
Policy Entropy: 1.11044
Value Function Loss: 0.09783

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07182
Policy Update Magnitude: 0.34321
Value Function Update Magnitude: 0.54281

Collected Steps per Second: 20,288.50096
Overall Steps per Second: 9,786.33603

Timestep Collection Time: 2.46484
Timestep Consumption Time: 2.64514
PPO Batch Consumption Time: 0.30806
Total Iteration Time: 5.10998

Cumulative Model Updates: 17,412
Cumulative Timesteps: 145,303,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,320.40167
Policy Entropy: 1.10500
Value Function Loss: 0.09714

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07273
Policy Update Magnitude: 0.35152
Value Function Update Magnitude: 0.64810

Collected Steps per Second: 21,046.01178
Overall Steps per Second: 10,132.50717

Timestep Collection Time: 2.37660
Timestep Consumption Time: 2.55979
PPO Batch Consumption Time: 0.30116
Total Iteration Time: 4.93639

Cumulative Model Updates: 17,418
Cumulative Timesteps: 145,353,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 145353672...
Checkpoint 145353672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,481.12873
Policy Entropy: 1.10716
Value Function Loss: 0.09352

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.35193
Value Function Update Magnitude: 0.68527

Collected Steps per Second: 21,224.89028
Overall Steps per Second: 10,100.58504

Timestep Collection Time: 2.35676
Timestep Consumption Time: 2.59563
PPO Batch Consumption Time: 0.30873
Total Iteration Time: 4.95239

Cumulative Model Updates: 17,424
Cumulative Timesteps: 145,403,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,062.73609
Policy Entropy: 1.10705
Value Function Loss: 0.09759

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07544
Policy Update Magnitude: 0.35147
Value Function Update Magnitude: 0.68471

Collected Steps per Second: 21,519.72657
Overall Steps per Second: 10,295.09137

Timestep Collection Time: 2.32419
Timestep Consumption Time: 2.53404
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.85824

Cumulative Model Updates: 17,430
Cumulative Timesteps: 145,453,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 145453710...
Checkpoint 145453710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,890.93808
Policy Entropy: 1.10366
Value Function Loss: 0.10056

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11306
Policy Update Magnitude: 0.34787
Value Function Update Magnitude: 0.70186

Collected Steps per Second: 20,562.84320
Overall Steps per Second: 9,952.69773

Timestep Collection Time: 2.43303
Timestep Consumption Time: 2.59375
PPO Batch Consumption Time: 0.30795
Total Iteration Time: 5.02678

Cumulative Model Updates: 17,436
Cumulative Timesteps: 145,503,740

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,063.61605
Policy Entropy: 1.10078
Value Function Loss: 0.09993

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11657
Policy Update Magnitude: 0.32587
Value Function Update Magnitude: 0.72276

Collected Steps per Second: 21,096.95477
Overall Steps per Second: 10,168.57734

Timestep Collection Time: 2.37115
Timestep Consumption Time: 2.54832
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.91947

Cumulative Model Updates: 17,442
Cumulative Timesteps: 145,553,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 145553764...
Checkpoint 145553764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,520.01659
Policy Entropy: 1.10420
Value Function Loss: 0.09946

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.32954
Value Function Update Magnitude: 0.70816

Collected Steps per Second: 20,966.90238
Overall Steps per Second: 9,892.13690

Timestep Collection Time: 2.38528
Timestep Consumption Time: 2.67045
PPO Batch Consumption Time: 0.31749
Total Iteration Time: 5.05573

Cumulative Model Updates: 17,448
Cumulative Timesteps: 145,603,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,835.87572
Policy Entropy: 1.09373
Value Function Loss: 0.09849

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11322
Policy Update Magnitude: 0.32714
Value Function Update Magnitude: 0.67913

Collected Steps per Second: 21,214.30632
Overall Steps per Second: 9,958.18692

Timestep Collection Time: 2.35756
Timestep Consumption Time: 2.66484
PPO Batch Consumption Time: 0.31947
Total Iteration Time: 5.02240

Cumulative Model Updates: 17,454
Cumulative Timesteps: 145,653,790

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 145653790...
Checkpoint 145653790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,875.04497
Policy Entropy: 1.09604
Value Function Loss: 0.10174

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11489
Policy Update Magnitude: 0.31885
Value Function Update Magnitude: 0.57050

Collected Steps per Second: 21,145.99491
Overall Steps per Second: 10,329.36160

Timestep Collection Time: 2.36574
Timestep Consumption Time: 2.47734
PPO Batch Consumption Time: 0.30163
Total Iteration Time: 4.84309

Cumulative Model Updates: 17,460
Cumulative Timesteps: 145,703,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,111.78109
Policy Entropy: 1.09072
Value Function Loss: 0.10081

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.32457
Value Function Update Magnitude: 0.53621

Collected Steps per Second: 20,941.41897
Overall Steps per Second: 9,904.61141

Timestep Collection Time: 2.38971
Timestep Consumption Time: 2.66288
PPO Batch Consumption Time: 0.31569
Total Iteration Time: 5.05260

Cumulative Model Updates: 17,466
Cumulative Timesteps: 145,753,860

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 145753860...
Checkpoint 145753860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,407.81207
Policy Entropy: 1.09813
Value Function Loss: 0.10173

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07947
Policy Update Magnitude: 0.34847
Value Function Update Magnitude: 0.53912

Collected Steps per Second: 20,985.60606
Overall Steps per Second: 9,935.84211

Timestep Collection Time: 2.38354
Timestep Consumption Time: 2.65076
PPO Batch Consumption Time: 0.31911
Total Iteration Time: 5.03430

Cumulative Model Updates: 17,472
Cumulative Timesteps: 145,803,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,561.19398
Policy Entropy: 1.10349
Value Function Loss: 0.10327

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08320
Policy Update Magnitude: 0.35671
Value Function Update Magnitude: 0.64837

Collected Steps per Second: 21,266.48368
Overall Steps per Second: 10,049.17147

Timestep Collection Time: 2.35215
Timestep Consumption Time: 2.62557
PPO Batch Consumption Time: 0.31309
Total Iteration Time: 4.97772

Cumulative Model Updates: 17,478
Cumulative Timesteps: 145,853,902

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 145853902...
Checkpoint 145853902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.65404
Policy Entropy: 1.10957
Value Function Loss: 0.09691

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.07022
Policy Update Magnitude: 0.35904
Value Function Update Magnitude: 0.73027

Collected Steps per Second: 20,551.60900
Overall Steps per Second: 9,947.27930

Timestep Collection Time: 2.43329
Timestep Consumption Time: 2.59402
PPO Batch Consumption Time: 0.30899
Total Iteration Time: 5.02730

Cumulative Model Updates: 17,484
Cumulative Timesteps: 145,903,910

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,327.32325
Policy Entropy: 1.11796
Value Function Loss: 0.09713

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.34789
Value Function Update Magnitude: 0.74296

Collected Steps per Second: 20,976.37792
Overall Steps per Second: 10,093.44448

Timestep Collection Time: 2.38440
Timestep Consumption Time: 2.57090
PPO Batch Consumption Time: 0.30513
Total Iteration Time: 4.95530

Cumulative Model Updates: 17,490
Cumulative Timesteps: 145,953,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 145953926...
Checkpoint 145953926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,871.76981
Policy Entropy: 1.12861
Value Function Loss: 0.09515

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.29980
Value Function Update Magnitude: 0.70292

Collected Steps per Second: 20,827.66108
Overall Steps per Second: 9,821.38228

Timestep Collection Time: 2.40094
Timestep Consumption Time: 2.69060
PPO Batch Consumption Time: 0.32581
Total Iteration Time: 5.09154

Cumulative Model Updates: 17,496
Cumulative Timesteps: 146,003,932

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,402.50450
Policy Entropy: 1.12069
Value Function Loss: 0.09835

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12288
Policy Update Magnitude: 0.27659
Value Function Update Magnitude: 0.71094

Collected Steps per Second: 20,689.91160
Overall Steps per Second: 9,844.44928

Timestep Collection Time: 2.41780
Timestep Consumption Time: 2.66365
PPO Batch Consumption Time: 0.31492
Total Iteration Time: 5.08144

Cumulative Model Updates: 17,502
Cumulative Timesteps: 146,053,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 146053956...
Checkpoint 146053956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,553.01790
Policy Entropy: 1.12810
Value Function Loss: 0.09485

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12312
Policy Update Magnitude: 0.28218
Value Function Update Magnitude: 0.71728

Collected Steps per Second: 20,926.12145
Overall Steps per Second: 10,161.54987

Timestep Collection Time: 2.39012
Timestep Consumption Time: 2.53196
PPO Batch Consumption Time: 0.31096
Total Iteration Time: 4.92208

Cumulative Model Updates: 17,508
Cumulative Timesteps: 146,103,972

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,647.76483
Policy Entropy: 1.13364
Value Function Loss: 0.09417

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.30451
Value Function Update Magnitude: 0.68637

Collected Steps per Second: 21,373.47123
Overall Steps per Second: 10,032.39500

Timestep Collection Time: 2.33935
Timestep Consumption Time: 2.64451
PPO Batch Consumption Time: 0.31710
Total Iteration Time: 4.98385

Cumulative Model Updates: 17,514
Cumulative Timesteps: 146,153,972

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 146153972...
Checkpoint 146153972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,096.30763
Policy Entropy: 1.13916
Value Function Loss: 0.09304

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11612
Policy Update Magnitude: 0.30421
Value Function Update Magnitude: 0.75569

Collected Steps per Second: 20,772.02959
Overall Steps per Second: 10,163.68127

Timestep Collection Time: 2.40785
Timestep Consumption Time: 2.51320
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.92105

Cumulative Model Updates: 17,520
Cumulative Timesteps: 146,203,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,147.06826
Policy Entropy: 1.13897
Value Function Loss: 0.09080

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.31573
Value Function Update Magnitude: 0.75765

Collected Steps per Second: 21,397.84695
Overall Steps per Second: 10,051.56470

Timestep Collection Time: 2.33781
Timestep Consumption Time: 2.63893
PPO Batch Consumption Time: 0.31799
Total Iteration Time: 4.97674

Cumulative Model Updates: 17,526
Cumulative Timesteps: 146,254,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 146254012...
Checkpoint 146254012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,294.32041
Policy Entropy: 1.13925
Value Function Loss: 0.09408

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.36314
Value Function Update Magnitude: 0.68928

Collected Steps per Second: 21,149.39160
Overall Steps per Second: 10,218.55444

Timestep Collection Time: 2.36413
Timestep Consumption Time: 2.52893
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.89306

Cumulative Model Updates: 17,532
Cumulative Timesteps: 146,304,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,869.87176
Policy Entropy: 1.14083
Value Function Loss: 0.09807

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.37712
Value Function Update Magnitude: 0.65000

Collected Steps per Second: 20,981.84582
Overall Steps per Second: 9,885.55167

Timestep Collection Time: 2.38320
Timestep Consumption Time: 2.67509
PPO Batch Consumption Time: 0.31854
Total Iteration Time: 5.05829

Cumulative Model Updates: 17,538
Cumulative Timesteps: 146,354,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 146354016...
Checkpoint 146354016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,877.80145
Policy Entropy: 1.13622
Value Function Loss: 0.10099

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.35499
Value Function Update Magnitude: 0.64551

Collected Steps per Second: 20,823.76828
Overall Steps per Second: 9,861.13627

Timestep Collection Time: 2.40110
Timestep Consumption Time: 2.66931
PPO Batch Consumption Time: 0.32220
Total Iteration Time: 5.07041

Cumulative Model Updates: 17,544
Cumulative Timesteps: 146,404,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,362.38511
Policy Entropy: 1.14340
Value Function Loss: 0.10034

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10896
Policy Update Magnitude: 0.34629
Value Function Update Magnitude: 0.68064

Collected Steps per Second: 21,199.76495
Overall Steps per Second: 9,994.99551

Timestep Collection Time: 2.35918
Timestep Consumption Time: 2.64473
PPO Batch Consumption Time: 0.31370
Total Iteration Time: 5.00390

Cumulative Model Updates: 17,550
Cumulative Timesteps: 146,454,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 146454030...
Checkpoint 146454030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,368.83351
Policy Entropy: 1.14083
Value Function Loss: 0.09789

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11347
Policy Update Magnitude: 0.31392
Value Function Update Magnitude: 0.71656

Collected Steps per Second: 20,835.52096
Overall Steps per Second: 9,859.56397

Timestep Collection Time: 2.40176
Timestep Consumption Time: 2.67371
PPO Batch Consumption Time: 0.31673
Total Iteration Time: 5.07548

Cumulative Model Updates: 17,556
Cumulative Timesteps: 146,504,072

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,217.83892
Policy Entropy: 1.14447
Value Function Loss: 0.10099

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.31412
Value Function Update Magnitude: 0.62522

Collected Steps per Second: 21,639.89198
Overall Steps per Second: 10,162.45126

Timestep Collection Time: 2.31064
Timestep Consumption Time: 2.60963
PPO Batch Consumption Time: 0.30294
Total Iteration Time: 4.92027

Cumulative Model Updates: 17,562
Cumulative Timesteps: 146,554,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 146554074...
Checkpoint 146554074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,015.64202
Policy Entropy: 1.13225
Value Function Loss: 0.10452

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.14632
Policy Update Magnitude: 0.30147
Value Function Update Magnitude: 0.56753

Collected Steps per Second: 21,225.77199
Overall Steps per Second: 10,184.77546

Timestep Collection Time: 2.35629
Timestep Consumption Time: 2.55438
PPO Batch Consumption Time: 0.29654
Total Iteration Time: 4.91066

Cumulative Model Updates: 17,568
Cumulative Timesteps: 146,604,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,755.27039
Policy Entropy: 1.11579
Value Function Loss: 0.10709

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.14589
Policy Update Magnitude: 0.30774
Value Function Update Magnitude: 0.54569

Collected Steps per Second: 21,230.38546
Overall Steps per Second: 9,946.36996

Timestep Collection Time: 2.35643
Timestep Consumption Time: 2.67334
PPO Batch Consumption Time: 0.31532
Total Iteration Time: 5.02977

Cumulative Model Updates: 17,574
Cumulative Timesteps: 146,654,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 146654116...
Checkpoint 146654116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.18609
Policy Entropy: 1.11932
Value Function Loss: 0.11164

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.13840
Policy Update Magnitude: 0.30562
Value Function Update Magnitude: 0.53406

Collected Steps per Second: 21,292.33699
Overall Steps per Second: 10,233.46506

Timestep Collection Time: 2.34930
Timestep Consumption Time: 2.53878
PPO Batch Consumption Time: 0.30789
Total Iteration Time: 4.88808

Cumulative Model Updates: 17,580
Cumulative Timesteps: 146,704,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,322.45159
Policy Entropy: 1.12500
Value Function Loss: 0.10802

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.27860
Value Function Update Magnitude: 0.56885

Collected Steps per Second: 21,631.87501
Overall Steps per Second: 10,102.29003

Timestep Collection Time: 2.31159
Timestep Consumption Time: 2.63818
PPO Batch Consumption Time: 0.31534
Total Iteration Time: 4.94977

Cumulative Model Updates: 17,586
Cumulative Timesteps: 146,754,142

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 146754142...
Checkpoint 146754142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,957.98728
Policy Entropy: 1.13594
Value Function Loss: 0.10355

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.28415
Value Function Update Magnitude: 0.55210

Collected Steps per Second: 20,830.51755
Overall Steps per Second: 10,167.06745

Timestep Collection Time: 2.40090
Timestep Consumption Time: 2.51812
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 4.91902

Cumulative Model Updates: 17,592
Cumulative Timesteps: 146,804,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,576.95452
Policy Entropy: 1.14405
Value Function Loss: 0.09668

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.13220
Policy Update Magnitude: 0.27886
Value Function Update Magnitude: 0.54261

Collected Steps per Second: 21,549.83983
Overall Steps per Second: 10,139.09558

Timestep Collection Time: 2.32067
Timestep Consumption Time: 2.61173
PPO Batch Consumption Time: 0.31346
Total Iteration Time: 4.93239

Cumulative Model Updates: 17,598
Cumulative Timesteps: 146,854,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 146854164...
Checkpoint 146854164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,317.45118
Policy Entropy: 1.14560
Value Function Loss: 0.09982

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.27898
Value Function Update Magnitude: 0.51428

Collected Steps per Second: 20,740.92928
Overall Steps per Second: 10,007.58825

Timestep Collection Time: 2.41079
Timestep Consumption Time: 2.58562
PPO Batch Consumption Time: 0.30446
Total Iteration Time: 4.99641

Cumulative Model Updates: 17,604
Cumulative Timesteps: 146,904,166

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,524.76175
Policy Entropy: 1.14234
Value Function Loss: 0.10223

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.15814
Policy Update Magnitude: 0.26402
Value Function Update Magnitude: 0.57240

Collected Steps per Second: 21,065.22143
Overall Steps per Second: 10,056.77749

Timestep Collection Time: 2.37368
Timestep Consumption Time: 2.59829
PPO Batch Consumption Time: 0.30892
Total Iteration Time: 4.97197

Cumulative Model Updates: 17,610
Cumulative Timesteps: 146,954,168

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 146954168...
Checkpoint 146954168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,143.67954
Policy Entropy: 1.14829
Value Function Loss: 0.10442

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.15268
Policy Update Magnitude: 0.26597
Value Function Update Magnitude: 0.60891

Collected Steps per Second: 20,937.41051
Overall Steps per Second: 9,901.06047

Timestep Collection Time: 2.38845
Timestep Consumption Time: 2.66232
PPO Batch Consumption Time: 0.31590
Total Iteration Time: 5.05077

Cumulative Model Updates: 17,616
Cumulative Timesteps: 147,004,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,410.67116
Policy Entropy: 1.15388
Value Function Loss: 0.10590

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.27309
Value Function Update Magnitude: 0.58268

Collected Steps per Second: 21,367.16352
Overall Steps per Second: 10,009.77181

Timestep Collection Time: 2.34069
Timestep Consumption Time: 2.65582
PPO Batch Consumption Time: 0.32162
Total Iteration Time: 4.99652

Cumulative Model Updates: 17,622
Cumulative Timesteps: 147,054,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 147054190...
Checkpoint 147054190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,927.61577
Policy Entropy: 1.14963
Value Function Loss: 0.10745

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.28066
Value Function Update Magnitude: 0.52063

Collected Steps per Second: 21,247.25825
Overall Steps per Second: 10,256.00380

Timestep Collection Time: 2.35324
Timestep Consumption Time: 2.52195
PPO Batch Consumption Time: 0.30826
Total Iteration Time: 4.87519

Cumulative Model Updates: 17,628
Cumulative Timesteps: 147,104,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,168.05396
Policy Entropy: 1.13847
Value Function Loss: 0.10569

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.27959
Value Function Update Magnitude: 0.47802

Collected Steps per Second: 20,995.84605
Overall Steps per Second: 9,941.63243

Timestep Collection Time: 2.38152
Timestep Consumption Time: 2.64804
PPO Batch Consumption Time: 0.31827
Total Iteration Time: 5.02956

Cumulative Model Updates: 17,634
Cumulative Timesteps: 147,154,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 147154192...
Checkpoint 147154192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,540.69374
Policy Entropy: 1.13414
Value Function Loss: 0.10479

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.27642
Value Function Update Magnitude: 0.54547

Collected Steps per Second: 20,601.08432
Overall Steps per Second: 9,898.45711

Timestep Collection Time: 2.42822
Timestep Consumption Time: 2.62550
PPO Batch Consumption Time: 0.31578
Total Iteration Time: 5.05372

Cumulative Model Updates: 17,640
Cumulative Timesteps: 147,204,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,288.56560
Policy Entropy: 1.13637
Value Function Loss: 0.10362

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.14392
Policy Update Magnitude: 0.26713
Value Function Update Magnitude: 0.58170

Collected Steps per Second: 21,096.08329
Overall Steps per Second: 9,928.70061

Timestep Collection Time: 2.37011
Timestep Consumption Time: 2.66580
PPO Batch Consumption Time: 0.31804
Total Iteration Time: 5.03591

Cumulative Model Updates: 17,646
Cumulative Timesteps: 147,254,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 147254216...
Checkpoint 147254216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,676.50167
Policy Entropy: 1.13231
Value Function Loss: 0.10535

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.27904
Value Function Update Magnitude: 0.52967

Collected Steps per Second: 20,937.43373
Overall Steps per Second: 10,199.45781

Timestep Collection Time: 2.38950
Timestep Consumption Time: 2.51566
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 4.90516

Cumulative Model Updates: 17,652
Cumulative Timesteps: 147,304,246

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,533.56329
Policy Entropy: 1.12375
Value Function Loss: 0.10137

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.16021
Policy Update Magnitude: 0.29091
Value Function Update Magnitude: 0.56641

Collected Steps per Second: 21,371.86789
Overall Steps per Second: 10,032.06911

Timestep Collection Time: 2.33952
Timestep Consumption Time: 2.64449
PPO Batch Consumption Time: 0.31031
Total Iteration Time: 4.98402

Cumulative Model Updates: 17,658
Cumulative Timesteps: 147,354,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 147354246...
Checkpoint 147354246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,684.48752
Policy Entropy: 1.11289
Value Function Loss: 0.10368

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.31667
Value Function Update Magnitude: 0.64855

Collected Steps per Second: 20,951.86714
Overall Steps per Second: 9,934.92004

Timestep Collection Time: 2.38699
Timestep Consumption Time: 2.64697
PPO Batch Consumption Time: 0.31701
Total Iteration Time: 5.03396

Cumulative Model Updates: 17,664
Cumulative Timesteps: 147,404,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.62037
Policy Entropy: 1.11347
Value Function Loss: 0.10849

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10056
Policy Update Magnitude: 0.33373
Value Function Update Magnitude: 0.68023

Collected Steps per Second: 21,111.04969
Overall Steps per Second: 9,968.94583

Timestep Collection Time: 2.36985
Timestep Consumption Time: 2.64874
PPO Batch Consumption Time: 0.31961
Total Iteration Time: 5.01858

Cumulative Model Updates: 17,670
Cumulative Timesteps: 147,454,288

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 147454288...
Checkpoint 147454288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,707.17648
Policy Entropy: 1.10037
Value Function Loss: 0.10629

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.33510
Value Function Update Magnitude: 0.66469

Collected Steps per Second: 21,105.24967
Overall Steps per Second: 10,279.59217

Timestep Collection Time: 2.37145
Timestep Consumption Time: 2.49742
PPO Batch Consumption Time: 0.30336
Total Iteration Time: 4.86887

Cumulative Model Updates: 17,676
Cumulative Timesteps: 147,504,338

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,710.43758
Policy Entropy: 1.09774
Value Function Loss: 0.10651

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.07277
Policy Update Magnitude: 0.34200
Value Function Update Magnitude: 0.61869

Collected Steps per Second: 20,947.14621
Overall Steps per Second: 9,870.65822

Timestep Collection Time: 2.38782
Timestep Consumption Time: 2.67952
PPO Batch Consumption Time: 0.32091
Total Iteration Time: 5.06734

Cumulative Model Updates: 17,682
Cumulative Timesteps: 147,554,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 147554356...
Checkpoint 147554356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,099.06002
Policy Entropy: 1.10248
Value Function Loss: 0.09910

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08251
Policy Update Magnitude: 0.34900
Value Function Update Magnitude: 0.62637

Collected Steps per Second: 20,858.61704
Overall Steps per Second: 10,050.32820

Timestep Collection Time: 2.39795
Timestep Consumption Time: 2.57880
PPO Batch Consumption Time: 0.30662
Total Iteration Time: 4.97675

Cumulative Model Updates: 17,688
Cumulative Timesteps: 147,604,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.41397
Policy Entropy: 1.09507
Value Function Loss: 0.09947

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.11676
Policy Update Magnitude: 0.32113
Value Function Update Magnitude: 0.62507

Collected Steps per Second: 21,067.75896
Overall Steps per Second: 9,949.13529

Timestep Collection Time: 2.37339
Timestep Consumption Time: 2.65237
PPO Batch Consumption Time: 0.31920
Total Iteration Time: 5.02576

Cumulative Model Updates: 17,694
Cumulative Timesteps: 147,654,376

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 147654376...
Checkpoint 147654376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,283.10418
Policy Entropy: 1.10472
Value Function Loss: 0.09876

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.14327
Policy Update Magnitude: 0.30068
Value Function Update Magnitude: 0.60877

Collected Steps per Second: 20,923.10364
Overall Steps per Second: 10,025.11208

Timestep Collection Time: 2.39075
Timestep Consumption Time: 2.59892
PPO Batch Consumption Time: 0.30812
Total Iteration Time: 4.98967

Cumulative Model Updates: 17,700
Cumulative Timesteps: 147,704,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,420.06751
Policy Entropy: 1.11337
Value Function Loss: 0.10592

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.32872
Value Function Update Magnitude: 0.54480

Collected Steps per Second: 21,332.13471
Overall Steps per Second: 9,975.53877

Timestep Collection Time: 2.34491
Timestep Consumption Time: 2.66955
PPO Batch Consumption Time: 0.31792
Total Iteration Time: 5.01447

Cumulative Model Updates: 17,706
Cumulative Timesteps: 147,754,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 147754420...
Checkpoint 147754420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,612.39791
Policy Entropy: 1.11655
Value Function Loss: 0.10742

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11610
Policy Update Magnitude: 0.33920
Value Function Update Magnitude: 0.52022

Collected Steps per Second: 20,732.87758
Overall Steps per Second: 9,892.24651

Timestep Collection Time: 2.41211
Timestep Consumption Time: 2.64336
PPO Batch Consumption Time: 0.30842
Total Iteration Time: 5.05547

Cumulative Model Updates: 17,712
Cumulative Timesteps: 147,804,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,510.34870
Policy Entropy: 1.11556
Value Function Loss: 0.10870

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.34174
Value Function Update Magnitude: 0.52035

Collected Steps per Second: 21,572.26246
Overall Steps per Second: 10,071.76470

Timestep Collection Time: 2.31863
Timestep Consumption Time: 2.64753
PPO Batch Consumption Time: 0.31627
Total Iteration Time: 4.96616

Cumulative Model Updates: 17,718
Cumulative Timesteps: 147,854,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 147854448...
Checkpoint 147854448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,540.08518
Policy Entropy: 1.12232
Value Function Loss: 0.10643

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.33779
Value Function Update Magnitude: 0.53322

Collected Steps per Second: 21,027.41533
Overall Steps per Second: 9,971.79986

Timestep Collection Time: 2.37908
Timestep Consumption Time: 2.63766
PPO Batch Consumption Time: 0.31538
Total Iteration Time: 5.01675

Cumulative Model Updates: 17,724
Cumulative Timesteps: 147,904,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,818.82015
Policy Entropy: 1.11971
Value Function Loss: 0.10440

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.34605
Value Function Update Magnitude: 0.52215

Collected Steps per Second: 21,103.21028
Overall Steps per Second: 9,920.36080

Timestep Collection Time: 2.36988
Timestep Consumption Time: 2.67147
PPO Batch Consumption Time: 0.32225
Total Iteration Time: 5.04135

Cumulative Model Updates: 17,730
Cumulative Timesteps: 147,954,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 147954486...
Checkpoint 147954486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,842.49344
Policy Entropy: 1.11930
Value Function Loss: 0.10113

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.31600
Value Function Update Magnitude: 0.55177

Collected Steps per Second: 20,675.68838
Overall Steps per Second: 9,788.52004

Timestep Collection Time: 2.41840
Timestep Consumption Time: 2.68983
PPO Batch Consumption Time: 0.31960
Total Iteration Time: 5.10823

Cumulative Model Updates: 17,736
Cumulative Timesteps: 148,004,488

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,168.40215
Policy Entropy: 1.11885
Value Function Loss: 0.09736

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.25948
Value Function Update Magnitude: 0.54660

Collected Steps per Second: 21,114.55208
Overall Steps per Second: 10,019.61421

Timestep Collection Time: 2.36813
Timestep Consumption Time: 2.62228
PPO Batch Consumption Time: 0.31146
Total Iteration Time: 4.99041

Cumulative Model Updates: 17,742
Cumulative Timesteps: 148,054,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 148054490...
Checkpoint 148054490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,480.28501
Policy Entropy: 1.11791
Value Function Loss: 0.09443

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.26572
Value Function Update Magnitude: 0.58840

Collected Steps per Second: 21,258.40001
Overall Steps per Second: 10,346.87867

Timestep Collection Time: 2.35220
Timestep Consumption Time: 2.48056
PPO Batch Consumption Time: 0.30452
Total Iteration Time: 4.83276

Cumulative Model Updates: 17,748
Cumulative Timesteps: 148,104,494

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716.24776
Policy Entropy: 1.11564
Value Function Loss: 0.09551

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.25579
Value Function Update Magnitude: 0.64438

Collected Steps per Second: 21,734.80393
Overall Steps per Second: 10,189.68609

Timestep Collection Time: 2.30129
Timestep Consumption Time: 2.60740
PPO Batch Consumption Time: 0.30542
Total Iteration Time: 4.90869

Cumulative Model Updates: 17,754
Cumulative Timesteps: 148,154,512

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 148154512...
Checkpoint 148154512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,365.68011
Policy Entropy: 1.10969
Value Function Loss: 0.09683

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.26675
Value Function Update Magnitude: 0.66356

Collected Steps per Second: 19,492.36541
Overall Steps per Second: 9,678.04856

Timestep Collection Time: 2.56634
Timestep Consumption Time: 2.60247
PPO Batch Consumption Time: 0.30999
Total Iteration Time: 5.16881

Cumulative Model Updates: 17,760
Cumulative Timesteps: 148,204,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,332.52312
Policy Entropy: 1.11254
Value Function Loss: 0.09746

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.16262
Policy Update Magnitude: 0.25176
Value Function Update Magnitude: 0.66248

Collected Steps per Second: 20,957.29906
Overall Steps per Second: 9,950.47137

Timestep Collection Time: 2.38752
Timestep Consumption Time: 2.64098
PPO Batch Consumption Time: 0.31469
Total Iteration Time: 5.02851

Cumulative Model Updates: 17,766
Cumulative Timesteps: 148,254,572

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 148254572...
Checkpoint 148254572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,827.94511
Policy Entropy: 1.11973
Value Function Loss: 0.09312

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.14082
Policy Update Magnitude: 0.24385
Value Function Update Magnitude: 0.58071

Collected Steps per Second: 20,932.29768
Overall Steps per Second: 10,009.24740

Timestep Collection Time: 2.38884
Timestep Consumption Time: 2.60694
PPO Batch Consumption Time: 0.30902
Total Iteration Time: 4.99578

Cumulative Model Updates: 17,772
Cumulative Timesteps: 148,304,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,174.13365
Policy Entropy: 1.12104
Value Function Loss: 0.09760

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.24424
Value Function Update Magnitude: 0.54617

Collected Steps per Second: 21,097.33556
Overall Steps per Second: 9,864.88705

Timestep Collection Time: 2.37129
Timestep Consumption Time: 2.70003
PPO Batch Consumption Time: 0.31892
Total Iteration Time: 5.07132

Cumulative Model Updates: 17,778
Cumulative Timesteps: 148,354,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 148354604...
Checkpoint 148354604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,024.10451
Policy Entropy: 1.11123
Value Function Loss: 0.10476

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 0.28132
Value Function Update Magnitude: 0.61460

Collected Steps per Second: 20,837.79099
Overall Steps per Second: 9,940.49789

Timestep Collection Time: 2.40083
Timestep Consumption Time: 2.63192
PPO Batch Consumption Time: 0.31526
Total Iteration Time: 5.03275

Cumulative Model Updates: 17,784
Cumulative Timesteps: 148,404,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,082.37405
Policy Entropy: 1.11120
Value Function Loss: 0.10132

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.29095
Value Function Update Magnitude: 0.60600

Collected Steps per Second: 21,154.51483
Overall Steps per Second: 9,927.94305

Timestep Collection Time: 2.36545
Timestep Consumption Time: 2.67487
PPO Batch Consumption Time: 0.31725
Total Iteration Time: 5.04032

Cumulative Model Updates: 17,790
Cumulative Timesteps: 148,454,672

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 148454672...
Checkpoint 148454672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,478.89281
Policy Entropy: 1.10502
Value Function Loss: 0.09696

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.29653
Value Function Update Magnitude: 0.64572

Collected Steps per Second: 21,127.03278
Overall Steps per Second: 10,010.55863

Timestep Collection Time: 2.36711
Timestep Consumption Time: 2.62862
PPO Batch Consumption Time: 0.30709
Total Iteration Time: 4.99573

Cumulative Model Updates: 17,796
Cumulative Timesteps: 148,504,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,268.91599
Policy Entropy: 1.10610
Value Function Loss: 0.09068

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09092
Policy Update Magnitude: 0.32819
Value Function Update Magnitude: 0.60958

Collected Steps per Second: 21,102.79981
Overall Steps per Second: 10,081.82440

Timestep Collection Time: 2.36954
Timestep Consumption Time: 2.59027
PPO Batch Consumption Time: 0.30637
Total Iteration Time: 4.95982

Cumulative Model Updates: 17,802
Cumulative Timesteps: 148,554,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 148554686...
Checkpoint 148554686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,185.38382
Policy Entropy: 1.11001
Value Function Loss: 0.09378

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.34390
Value Function Update Magnitude: 0.66855

Collected Steps per Second: 20,787.70343
Overall Steps per Second: 9,826.41944

Timestep Collection Time: 2.40613
Timestep Consumption Time: 2.68402
PPO Batch Consumption Time: 0.32380
Total Iteration Time: 5.09016

Cumulative Model Updates: 17,808
Cumulative Timesteps: 148,604,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,804.60078
Policy Entropy: 1.11496
Value Function Loss: 0.09626

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08108
Policy Update Magnitude: 0.35604
Value Function Update Magnitude: 0.68649

Collected Steps per Second: 21,388.49504
Overall Steps per Second: 10,058.94088

Timestep Collection Time: 2.33789
Timestep Consumption Time: 2.63321
PPO Batch Consumption Time: 0.30780
Total Iteration Time: 4.97110

Cumulative Model Updates: 17,814
Cumulative Timesteps: 148,654,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 148654708...
Checkpoint 148654708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,546.90610
Policy Entropy: 1.11493
Value Function Loss: 0.09269

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07939
Policy Update Magnitude: 0.35054
Value Function Update Magnitude: 0.70367

Collected Steps per Second: 21,224.80525
Overall Steps per Second: 10,054.41475

Timestep Collection Time: 2.35696
Timestep Consumption Time: 2.61857
PPO Batch Consumption Time: 0.30719
Total Iteration Time: 4.97553

Cumulative Model Updates: 17,820
Cumulative Timesteps: 148,704,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,998.71904
Policy Entropy: 1.10978
Value Function Loss: 0.08782

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07522
Policy Update Magnitude: 0.34856
Value Function Update Magnitude: 0.68758

Collected Steps per Second: 21,099.55095
Overall Steps per Second: 9,885.82850

Timestep Collection Time: 2.37038
Timestep Consumption Time: 2.68878
PPO Batch Consumption Time: 0.31991
Total Iteration Time: 5.05916

Cumulative Model Updates: 17,826
Cumulative Timesteps: 148,754,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 148754748...
Checkpoint 148754748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,312.44489
Policy Entropy: 1.09538
Value Function Loss: 0.09101

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12321
Policy Update Magnitude: 0.30158
Value Function Update Magnitude: 0.67259

Collected Steps per Second: 20,797.86187
Overall Steps per Second: 9,952.10750

Timestep Collection Time: 2.40457
Timestep Consumption Time: 2.62049
PPO Batch Consumption Time: 0.30763
Total Iteration Time: 5.02507

Cumulative Model Updates: 17,832
Cumulative Timesteps: 148,804,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,804.17336
Policy Entropy: 1.08851
Value Function Loss: 0.09654

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11938
Policy Update Magnitude: 0.28645
Value Function Update Magnitude: 0.71142

Collected Steps per Second: 21,262.19183
Overall Steps per Second: 10,145.48659

Timestep Collection Time: 2.35234
Timestep Consumption Time: 2.57753
PPO Batch Consumption Time: 0.30515
Total Iteration Time: 4.92988

Cumulative Model Updates: 17,838
Cumulative Timesteps: 148,854,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 148854774...
Checkpoint 148854774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,712.53760
Policy Entropy: 1.09915
Value Function Loss: 0.10025

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.33622
Value Function Update Magnitude: 0.65317

Collected Steps per Second: 21,171.10900
Overall Steps per Second: 9,893.40785

Timestep Collection Time: 2.36190
Timestep Consumption Time: 2.69238
PPO Batch Consumption Time: 0.32143
Total Iteration Time: 5.05427

Cumulative Model Updates: 17,844
Cumulative Timesteps: 148,904,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,435.03052
Policy Entropy: 1.10657
Value Function Loss: 0.09989

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.15118
Policy Update Magnitude: 0.31112
Value Function Update Magnitude: 0.57081

Collected Steps per Second: 21,103.43378
Overall Steps per Second: 9,982.85478

Timestep Collection Time: 2.37051
Timestep Consumption Time: 2.64068
PPO Batch Consumption Time: 0.30719
Total Iteration Time: 5.01119

Cumulative Model Updates: 17,850
Cumulative Timesteps: 148,954,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 148954804...
Checkpoint 148954804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.41923
Policy Entropy: 1.09344
Value Function Loss: 0.10215

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.17169
Policy Update Magnitude: 0.26850
Value Function Update Magnitude: 0.54605

Collected Steps per Second: 21,156.31753
Overall Steps per Second: 10,211.55121

Timestep Collection Time: 2.36431
Timestep Consumption Time: 2.53407
PPO Batch Consumption Time: 0.30994
Total Iteration Time: 4.89837

Cumulative Model Updates: 17,856
Cumulative Timesteps: 149,004,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,251.37372
Policy Entropy: 1.09266
Value Function Loss: 0.10247

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.14107
Policy Update Magnitude: 0.28035
Value Function Update Magnitude: 0.54202

Collected Steps per Second: 20,969.75101
Overall Steps per Second: 10,054.51054

Timestep Collection Time: 2.38563
Timestep Consumption Time: 2.58985
PPO Batch Consumption Time: 0.30652
Total Iteration Time: 4.97548

Cumulative Model Updates: 17,862
Cumulative Timesteps: 149,054,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 149054850...
Checkpoint 149054850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,497.80121
Policy Entropy: 1.09081
Value Function Loss: 0.10109

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.15299
Policy Update Magnitude: 0.26479
Value Function Update Magnitude: 0.49566

Collected Steps per Second: 20,808.18934
Overall Steps per Second: 9,883.18929

Timestep Collection Time: 2.40357
Timestep Consumption Time: 2.65694
PPO Batch Consumption Time: 0.31971
Total Iteration Time: 5.06051

Cumulative Model Updates: 17,868
Cumulative Timesteps: 149,104,864

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,959.14592
Policy Entropy: 1.10310
Value Function Loss: 0.10078

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.27212
Value Function Update Magnitude: 0.54832

Collected Steps per Second: 21,092.78154
Overall Steps per Second: 9,944.23533

Timestep Collection Time: 2.37095
Timestep Consumption Time: 2.65809
PPO Batch Consumption Time: 0.31832
Total Iteration Time: 5.02904

Cumulative Model Updates: 17,874
Cumulative Timesteps: 149,154,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 149154874...
Checkpoint 149154874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.79296
Policy Entropy: 1.10574
Value Function Loss: 0.10264

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.26011
Value Function Update Magnitude: 0.57187

Collected Steps per Second: 20,702.46924
Overall Steps per Second: 9,776.49285

Timestep Collection Time: 2.41604
Timestep Consumption Time: 2.70011
PPO Batch Consumption Time: 0.32516
Total Iteration Time: 5.11615

Cumulative Model Updates: 17,880
Cumulative Timesteps: 149,204,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,082.16779
Policy Entropy: 1.09673
Value Function Loss: 0.10755

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.25179
Value Function Update Magnitude: 0.59107

Collected Steps per Second: 21,015.74769
Overall Steps per Second: 10,074.91039

Timestep Collection Time: 2.37993
Timestep Consumption Time: 2.58448
PPO Batch Consumption Time: 0.30472
Total Iteration Time: 4.96441

Cumulative Model Updates: 17,886
Cumulative Timesteps: 149,254,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 149254908...
Checkpoint 149254908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,840.19152
Policy Entropy: 1.10250
Value Function Loss: 0.10450

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10887
Policy Update Magnitude: 0.29333
Value Function Update Magnitude: 0.70700

Collected Steps per Second: 21,109.32041
Overall Steps per Second: 9,945.51190

Timestep Collection Time: 2.36891
Timestep Consumption Time: 2.65909
PPO Batch Consumption Time: 0.31642
Total Iteration Time: 5.02800

Cumulative Model Updates: 17,892
Cumulative Timesteps: 149,304,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,046.72160
Policy Entropy: 1.09925
Value Function Loss: 0.10152

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.33783
Value Function Update Magnitude: 0.71796

Collected Steps per Second: 21,023.49523
Overall Steps per Second: 9,877.61282

Timestep Collection Time: 2.37829
Timestep Consumption Time: 2.68366
PPO Batch Consumption Time: 0.31708
Total Iteration Time: 5.06195

Cumulative Model Updates: 17,898
Cumulative Timesteps: 149,354,914

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 149354914...
Checkpoint 149354914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,624.48020
Policy Entropy: 1.09677
Value Function Loss: 0.10219

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07439
Policy Update Magnitude: 0.35218
Value Function Update Magnitude: 0.74195

Collected Steps per Second: 20,939.30929
Overall Steps per Second: 9,827.73826

Timestep Collection Time: 2.38814
Timestep Consumption Time: 2.70011
PPO Batch Consumption Time: 0.32249
Total Iteration Time: 5.08825

Cumulative Model Updates: 17,904
Cumulative Timesteps: 149,404,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,311.62326
Policy Entropy: 1.09560
Value Function Loss: 0.09909

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.34895
Value Function Update Magnitude: 0.74950

Collected Steps per Second: 21,103.25325
Overall Steps per Second: 10,023.99160

Timestep Collection Time: 2.37148
Timestep Consumption Time: 2.62114
PPO Batch Consumption Time: 0.30596
Total Iteration Time: 4.99262

Cumulative Model Updates: 17,910
Cumulative Timesteps: 149,454,966

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 149454966...
Checkpoint 149454966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,497.84012
Policy Entropy: 1.09809
Value Function Loss: 0.09918

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07919
Policy Update Magnitude: 0.33721
Value Function Update Magnitude: 0.72707

Collected Steps per Second: 20,919.64723
Overall Steps per Second: 9,835.92579

Timestep Collection Time: 2.39096
Timestep Consumption Time: 2.69428
PPO Batch Consumption Time: 0.32088
Total Iteration Time: 5.08524

Cumulative Model Updates: 17,916
Cumulative Timesteps: 149,504,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,543.47298
Policy Entropy: 1.10675
Value Function Loss: 0.09889

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.10198
Policy Update Magnitude: 0.32842
Value Function Update Magnitude: 0.66256

Collected Steps per Second: 21,426.09810
Overall Steps per Second: 10,000.63209

Timestep Collection Time: 2.33491
Timestep Consumption Time: 2.66757
PPO Batch Consumption Time: 0.31946
Total Iteration Time: 5.00248

Cumulative Model Updates: 17,922
Cumulative Timesteps: 149,555,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 149555012...
Checkpoint 149555012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,679.25618
Policy Entropy: 1.10506
Value Function Loss: 0.10536

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.30622
Value Function Update Magnitude: 0.54927

Collected Steps per Second: 21,189.17720
Overall Steps per Second: 10,225.10967

Timestep Collection Time: 2.35979
Timestep Consumption Time: 2.53033
PPO Batch Consumption Time: 0.30661
Total Iteration Time: 4.89012

Cumulative Model Updates: 17,928
Cumulative Timesteps: 149,605,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,534.41864
Policy Entropy: 1.09927
Value Function Loss: 0.10835

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.30723
Value Function Update Magnitude: 0.52290

Collected Steps per Second: 20,406.81402
Overall Steps per Second: 9,899.53861

Timestep Collection Time: 2.45036
Timestep Consumption Time: 2.60079
PPO Batch Consumption Time: 0.31047
Total Iteration Time: 5.05114

Cumulative Model Updates: 17,934
Cumulative Timesteps: 149,655,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 149655018...
Checkpoint 149655018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,163.22220
Policy Entropy: 1.09154
Value Function Loss: 0.10480

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11657
Policy Update Magnitude: 0.28809
Value Function Update Magnitude: 0.52196

Collected Steps per Second: 20,837.02915
Overall Steps per Second: 9,875.91878

Timestep Collection Time: 2.39967
Timestep Consumption Time: 2.66335
PPO Batch Consumption Time: 0.31635
Total Iteration Time: 5.06302

Cumulative Model Updates: 17,940
Cumulative Timesteps: 149,705,020

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,423.01601
Policy Entropy: 1.09245
Value Function Loss: 0.10372

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11344
Policy Update Magnitude: 0.29912
Value Function Update Magnitude: 0.47377

Collected Steps per Second: 20,952.26195
Overall Steps per Second: 9,994.32987

Timestep Collection Time: 2.38657
Timestep Consumption Time: 2.61667
PPO Batch Consumption Time: 0.30868
Total Iteration Time: 5.00324

Cumulative Model Updates: 17,946
Cumulative Timesteps: 149,755,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 149755024...
Checkpoint 149755024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,664.67029
Policy Entropy: 1.10964
Value Function Loss: 0.10082

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.14323
Policy Update Magnitude: 0.27016
Value Function Update Magnitude: 0.56794

Collected Steps per Second: 21,139.79414
Overall Steps per Second: 10,276.58751

Timestep Collection Time: 2.36615
Timestep Consumption Time: 2.50122
PPO Batch Consumption Time: 0.30342
Total Iteration Time: 4.86737

Cumulative Model Updates: 17,952
Cumulative Timesteps: 149,805,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,956.32789
Policy Entropy: 1.10630
Value Function Loss: 0.10404

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.27074
Value Function Update Magnitude: 0.62501

Collected Steps per Second: 21,146.85243
Overall Steps per Second: 10,093.66707

Timestep Collection Time: 2.36470
Timestep Consumption Time: 2.58949
PPO Batch Consumption Time: 0.30312
Total Iteration Time: 4.95420

Cumulative Model Updates: 17,958
Cumulative Timesteps: 149,855,050

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 149855050...
Checkpoint 149855050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,614.50859
Policy Entropy: 1.10120
Value Function Loss: 0.09618

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.30240
Value Function Update Magnitude: 0.67423

Collected Steps per Second: 20,738.26929
Overall Steps per Second: 10,136.45739

Timestep Collection Time: 2.41226
Timestep Consumption Time: 2.52300
PPO Batch Consumption Time: 0.30424
Total Iteration Time: 4.93525

Cumulative Model Updates: 17,964
Cumulative Timesteps: 149,905,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,714.15252
Policy Entropy: 1.10235
Value Function Loss: 0.09679

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.30528
Value Function Update Magnitude: 0.68343

Collected Steps per Second: 20,978.70975
Overall Steps per Second: 9,934.20841

Timestep Collection Time: 2.38394
Timestep Consumption Time: 2.65038
PPO Batch Consumption Time: 0.31155
Total Iteration Time: 5.03432

Cumulative Model Updates: 17,970
Cumulative Timesteps: 149,955,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 149955088...
Checkpoint 149955088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,316.17546
Policy Entropy: 1.10452
Value Function Loss: 0.09592

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.31664
Value Function Update Magnitude: 0.65899

Collected Steps per Second: 20,589.58100
Overall Steps per Second: 10,093.36545

Timestep Collection Time: 2.42841
Timestep Consumption Time: 2.52534
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.95375

Cumulative Model Updates: 17,976
Cumulative Timesteps: 150,005,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,651.84733
Policy Entropy: 1.10747
Value Function Loss: 0.09995

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08438
Policy Update Magnitude: 0.35038
Value Function Update Magnitude: 0.67596

Collected Steps per Second: 21,447.41360
Overall Steps per Second: 10,239.12133

Timestep Collection Time: 2.33250
Timestep Consumption Time: 2.55328
PPO Batch Consumption Time: 0.30372
Total Iteration Time: 4.88577

Cumulative Model Updates: 17,982
Cumulative Timesteps: 150,055,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 150055114...
Checkpoint 150055114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,962.00290
Policy Entropy: 1.09607
Value Function Loss: 0.10435

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.34635
Value Function Update Magnitude: 0.60396

Collected Steps per Second: 20,862.64179
Overall Steps per Second: 9,891.61608

Timestep Collection Time: 2.39720
Timestep Consumption Time: 2.65880
PPO Batch Consumption Time: 0.31996
Total Iteration Time: 5.05600

Cumulative Model Updates: 17,988
Cumulative Timesteps: 150,105,126

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821.22476
Policy Entropy: 1.09359
Value Function Loss: 0.11216

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.15166
Policy Update Magnitude: 0.30043
Value Function Update Magnitude: 0.49760

Collected Steps per Second: 21,049.68066
Overall Steps per Second: 10,041.45978

Timestep Collection Time: 2.37571
Timestep Consumption Time: 2.60444
PPO Batch Consumption Time: 0.31049
Total Iteration Time: 4.98015

Cumulative Model Updates: 17,994
Cumulative Timesteps: 150,155,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 150155134...
Checkpoint 150155134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,007.67367
Policy Entropy: 1.10662
Value Function Loss: 0.11100

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.28777
Value Function Update Magnitude: 0.51177

Collected Steps per Second: 20,915.75467
Overall Steps per Second: 9,963.67251

Timestep Collection Time: 2.39064
Timestep Consumption Time: 2.62779
PPO Batch Consumption Time: 0.30980
Total Iteration Time: 5.01843

Cumulative Model Updates: 18,000
Cumulative Timesteps: 150,205,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,255.15472
Policy Entropy: 1.10793
Value Function Loss: 0.10680

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11732
Policy Update Magnitude: 0.30290
Value Function Update Magnitude: 0.53520

Collected Steps per Second: 21,104.88436
Overall Steps per Second: 9,851.30360

Timestep Collection Time: 2.37054
Timestep Consumption Time: 2.70797
PPO Batch Consumption Time: 0.31975
Total Iteration Time: 5.07852

Cumulative Model Updates: 18,006
Cumulative Timesteps: 150,255,166

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 150255166...
Checkpoint 150255166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.91210
Policy Entropy: 1.10161
Value Function Loss: 0.10028

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13598
Policy Update Magnitude: 0.29525
Value Function Update Magnitude: 0.54434

Collected Steps per Second: 20,782.91942
Overall Steps per Second: 10,205.27371

Timestep Collection Time: 2.40678
Timestep Consumption Time: 2.49460
PPO Batch Consumption Time: 0.30515
Total Iteration Time: 4.90139

Cumulative Model Updates: 18,012
Cumulative Timesteps: 150,305,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,673.57602
Policy Entropy: 1.09633
Value Function Loss: 0.10048

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.31705
Value Function Update Magnitude: 0.54381

Collected Steps per Second: 21,447.12318
Overall Steps per Second: 10,042.26167

Timestep Collection Time: 2.33309
Timestep Consumption Time: 2.64966
PPO Batch Consumption Time: 0.31683
Total Iteration Time: 4.98274

Cumulative Model Updates: 18,018
Cumulative Timesteps: 150,355,224

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 150355224...
Checkpoint 150355224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,096.42800
Policy Entropy: 1.09265
Value Function Loss: 0.10370

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07767
Policy Update Magnitude: 0.34575
Value Function Update Magnitude: 0.54716

Collected Steps per Second: 20,793.83112
Overall Steps per Second: 10,054.19675

Timestep Collection Time: 2.40456
Timestep Consumption Time: 2.56849
PPO Batch Consumption Time: 0.30598
Total Iteration Time: 4.97305

Cumulative Model Updates: 18,024
Cumulative Timesteps: 150,405,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,168.48376
Policy Entropy: 1.09416
Value Function Loss: 0.09658

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.34110
Value Function Update Magnitude: 0.59529

Collected Steps per Second: 21,109.36963
Overall Steps per Second: 9,892.80128

Timestep Collection Time: 2.36937
Timestep Consumption Time: 2.68642
PPO Batch Consumption Time: 0.31844
Total Iteration Time: 5.05580

Cumulative Model Updates: 18,030
Cumulative Timesteps: 150,455,240

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 150455240...
Checkpoint 150455240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,160.47276
Policy Entropy: 1.10265
Value Function Loss: 0.09723

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.11570
Policy Update Magnitude: 0.34332
Value Function Update Magnitude: 0.57910

Collected Steps per Second: 21,009.72759
Overall Steps per Second: 10,025.82266

Timestep Collection Time: 2.38128
Timestep Consumption Time: 2.60884
PPO Batch Consumption Time: 0.30536
Total Iteration Time: 4.99011

Cumulative Model Updates: 18,036
Cumulative Timesteps: 150,505,270

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,191.47106
Policy Entropy: 1.09300
Value Function Loss: 0.09363

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.34419
Value Function Update Magnitude: 0.58690

Collected Steps per Second: 21,305.44670
Overall Steps per Second: 10,108.92906

Timestep Collection Time: 2.34691
Timestep Consumption Time: 2.59941
PPO Batch Consumption Time: 0.30784
Total Iteration Time: 4.94632

Cumulative Model Updates: 18,042
Cumulative Timesteps: 150,555,272

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 150555272...
Checkpoint 150555272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,128.38259
Policy Entropy: 1.07753
Value Function Loss: 0.09865

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.34940
Value Function Update Magnitude: 0.62180

Collected Steps per Second: 21,014.22288
Overall Steps per Second: 9,976.90227

Timestep Collection Time: 2.38115
Timestep Consumption Time: 2.63424
PPO Batch Consumption Time: 0.31544
Total Iteration Time: 5.01538

Cumulative Model Updates: 18,048
Cumulative Timesteps: 150,605,310

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.91750
Policy Entropy: 1.06875
Value Function Loss: 0.09741

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.33859
Value Function Update Magnitude: 0.66619

Collected Steps per Second: 21,097.56957
Overall Steps per Second: 9,965.76328

Timestep Collection Time: 2.37117
Timestep Consumption Time: 2.64861
PPO Batch Consumption Time: 0.31983
Total Iteration Time: 5.01979

Cumulative Model Updates: 18,054
Cumulative Timesteps: 150,655,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 150655336...
Checkpoint 150655336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,033.82920
Policy Entropy: 1.06909
Value Function Loss: 0.09871

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09580
Policy Update Magnitude: 0.33026
Value Function Update Magnitude: 0.60926

Collected Steps per Second: 20,550.97963
Overall Steps per Second: 9,855.28735

Timestep Collection Time: 2.43327
Timestep Consumption Time: 2.64076
PPO Batch Consumption Time: 0.31835
Total Iteration Time: 5.07403

Cumulative Model Updates: 18,060
Cumulative Timesteps: 150,705,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.84509
Policy Entropy: 1.07189
Value Function Loss: 0.10044

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.32068
Value Function Update Magnitude: 0.49353

Collected Steps per Second: 21,148.51116
Overall Steps per Second: 9,941.93447

Timestep Collection Time: 2.36461
Timestep Consumption Time: 2.66540
PPO Batch Consumption Time: 0.32252
Total Iteration Time: 5.03001

Cumulative Model Updates: 18,066
Cumulative Timesteps: 150,755,350

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 150755350...
Checkpoint 150755350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,444.29176
Policy Entropy: 1.08005
Value Function Loss: 0.10238

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09746
Policy Update Magnitude: 0.32371
Value Function Update Magnitude: 0.46943

Collected Steps per Second: 20,374.38212
Overall Steps per Second: 9,796.72692

Timestep Collection Time: 2.45524
Timestep Consumption Time: 2.65096
PPO Batch Consumption Time: 0.31883
Total Iteration Time: 5.10620

Cumulative Model Updates: 18,072
Cumulative Timesteps: 150,805,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,302.88747
Policy Entropy: 1.08356
Value Function Loss: 0.10052

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10984
Policy Update Magnitude: 0.33508
Value Function Update Magnitude: 0.48220

Collected Steps per Second: 21,168.16251
Overall Steps per Second: 10,033.45676

Timestep Collection Time: 2.36204
Timestep Consumption Time: 2.62129
PPO Batch Consumption Time: 0.30555
Total Iteration Time: 4.98333

Cumulative Model Updates: 18,078
Cumulative Timesteps: 150,855,374

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 150855374...
Checkpoint 150855374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,383.98791
Policy Entropy: 1.09178
Value Function Loss: 0.10094

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11706
Policy Update Magnitude: 0.32386
Value Function Update Magnitude: 0.50832

Collected Steps per Second: 20,743.30781
Overall Steps per Second: 9,807.69150

Timestep Collection Time: 2.41071
Timestep Consumption Time: 2.68795
PPO Batch Consumption Time: 0.31658
Total Iteration Time: 5.09865

Cumulative Model Updates: 18,084
Cumulative Timesteps: 150,905,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,981.18761
Policy Entropy: 1.09341
Value Function Loss: 0.10314

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13181
Policy Update Magnitude: 0.31450
Value Function Update Magnitude: 0.52580

Collected Steps per Second: 21,652.73230
Overall Steps per Second: 10,197.36648

Timestep Collection Time: 2.31001
Timestep Consumption Time: 2.59498
PPO Batch Consumption Time: 0.30880
Total Iteration Time: 4.90499

Cumulative Model Updates: 18,090
Cumulative Timesteps: 150,955,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 150955398...
Checkpoint 150955398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,802.44169
Policy Entropy: 1.07895
Value Function Loss: 0.09913

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11842
Policy Update Magnitude: 0.28394
Value Function Update Magnitude: 0.50828

Collected Steps per Second: 21,342.48724
Overall Steps per Second: 10,468.49497

Timestep Collection Time: 2.34415
Timestep Consumption Time: 2.43495
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.77910

Cumulative Model Updates: 18,096
Cumulative Timesteps: 151,005,428

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,112.93168
Policy Entropy: 1.07360
Value Function Loss: 0.10155

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.30558
Value Function Update Magnitude: 0.51473

Collected Steps per Second: 21,588.47047
Overall Steps per Second: 10,170.56457

Timestep Collection Time: 2.31679
Timestep Consumption Time: 2.60093
PPO Batch Consumption Time: 0.31026
Total Iteration Time: 4.91772

Cumulative Model Updates: 18,102
Cumulative Timesteps: 151,055,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 151055444...
Checkpoint 151055444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,469.61148
Policy Entropy: 1.06438
Value Function Loss: 0.10358

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.14919
Policy Update Magnitude: 0.30586
Value Function Update Magnitude: 0.51445

Collected Steps per Second: 20,757.82367
Overall Steps per Second: 10,115.07695

Timestep Collection Time: 2.40940
Timestep Consumption Time: 2.53510
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.94450

Cumulative Model Updates: 18,108
Cumulative Timesteps: 151,105,458

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,335.66555
Policy Entropy: 1.06082
Value Function Loss: 0.10516

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.17013
Policy Update Magnitude: 0.29304
Value Function Update Magnitude: 0.55427

Collected Steps per Second: 21,736.77861
Overall Steps per Second: 10,250.05082

Timestep Collection Time: 2.30071
Timestep Consumption Time: 2.57829
PPO Batch Consumption Time: 0.30538
Total Iteration Time: 4.87900

Cumulative Model Updates: 18,114
Cumulative Timesteps: 151,155,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 151155468...
Checkpoint 151155468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,967.39112
Policy Entropy: 1.06053
Value Function Loss: 0.10348

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13272
Policy Update Magnitude: 0.31730
Value Function Update Magnitude: 0.51895

Collected Steps per Second: 21,029.93265
Overall Steps per Second: 9,890.54933

Timestep Collection Time: 2.37804
Timestep Consumption Time: 2.67830
PPO Batch Consumption Time: 0.31501
Total Iteration Time: 5.05634

Cumulative Model Updates: 18,120
Cumulative Timesteps: 151,205,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,541.45727
Policy Entropy: 1.06618
Value Function Loss: 0.09918

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.34794
Value Function Update Magnitude: 0.52467

Collected Steps per Second: 21,140.55375
Overall Steps per Second: 9,814.17530

Timestep Collection Time: 2.36645
Timestep Consumption Time: 2.73108
PPO Batch Consumption Time: 0.31716
Total Iteration Time: 5.09752

Cumulative Model Updates: 18,126
Cumulative Timesteps: 151,255,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 151255506...
Checkpoint 151255506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,904.71461
Policy Entropy: 1.06722
Value Function Loss: 0.09604

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10340
Policy Update Magnitude: 0.35701
Value Function Update Magnitude: 0.51883

Collected Steps per Second: 20,829.33333
Overall Steps per Second: 10,151.14802

Timestep Collection Time: 2.40104
Timestep Consumption Time: 2.52570
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.92673

Cumulative Model Updates: 18,132
Cumulative Timesteps: 151,305,518

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,746.04202
Policy Entropy: 1.08595
Value Function Loss: 0.09538

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.34611
Value Function Update Magnitude: 0.52439

Collected Steps per Second: 21,570.49895
Overall Steps per Second: 10,097.89194

Timestep Collection Time: 2.31900
Timestep Consumption Time: 2.63471
PPO Batch Consumption Time: 0.31643
Total Iteration Time: 4.95371

Cumulative Model Updates: 18,138
Cumulative Timesteps: 151,355,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 151355540...
Checkpoint 151355540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,217.41025
Policy Entropy: 1.08034
Value Function Loss: 0.09635

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.35091
Value Function Update Magnitude: 0.58737

Collected Steps per Second: 21,103.43149
Overall Steps per Second: 10,043.57260

Timestep Collection Time: 2.37070
Timestep Consumption Time: 2.61059
PPO Batch Consumption Time: 0.30912
Total Iteration Time: 4.98130

Cumulative Model Updates: 18,144
Cumulative Timesteps: 151,405,570

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,196.88098
Policy Entropy: 1.08289
Value Function Loss: 0.09401

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.34647
Value Function Update Magnitude: 0.64252

Collected Steps per Second: 20,994.85197
Overall Steps per Second: 9,987.31950

Timestep Collection Time: 2.38277
Timestep Consumption Time: 2.62618
PPO Batch Consumption Time: 0.30625
Total Iteration Time: 5.00895

Cumulative Model Updates: 18,150
Cumulative Timesteps: 151,455,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 151455596...
Checkpoint 151455596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,904.85427
Policy Entropy: 1.07434
Value Function Loss: 0.09489

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.33347
Value Function Update Magnitude: 0.66868

Collected Steps per Second: 20,587.22825
Overall Steps per Second: 9,894.92977

Timestep Collection Time: 2.42966
Timestep Consumption Time: 2.62545
PPO Batch Consumption Time: 0.31107
Total Iteration Time: 5.05511

Cumulative Model Updates: 18,156
Cumulative Timesteps: 151,505,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,074.70042
Policy Entropy: 1.06897
Value Function Loss: 0.09606

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.32789
Value Function Update Magnitude: 0.69515

Collected Steps per Second: 21,251.86248
Overall Steps per Second: 10,027.29104

Timestep Collection Time: 2.35405
Timestep Consumption Time: 2.63513
PPO Batch Consumption Time: 0.31132
Total Iteration Time: 4.98918

Cumulative Model Updates: 18,162
Cumulative Timesteps: 151,555,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 151555644...
Checkpoint 151555644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,469.05188
Policy Entropy: 1.07291
Value Function Loss: 0.09998

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.32438
Value Function Update Magnitude: 0.68909

Collected Steps per Second: 20,993.78267
Overall Steps per Second: 9,956.13543

Timestep Collection Time: 2.38223
Timestep Consumption Time: 2.64101
PPO Batch Consumption Time: 0.31493
Total Iteration Time: 5.02323

Cumulative Model Updates: 18,168
Cumulative Timesteps: 151,605,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,238.42199
Policy Entropy: 1.07375
Value Function Loss: 0.10198

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.30586
Value Function Update Magnitude: 0.67642

Collected Steps per Second: 21,014.29949
Overall Steps per Second: 9,918.09941

Timestep Collection Time: 2.37943
Timestep Consumption Time: 2.66206
PPO Batch Consumption Time: 0.31206
Total Iteration Time: 5.04149

Cumulative Model Updates: 18,174
Cumulative Timesteps: 151,655,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 151655658...
Checkpoint 151655658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,374.33608
Policy Entropy: 1.07911
Value Function Loss: 0.10235

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.29460
Value Function Update Magnitude: 0.56526

Collected Steps per Second: 20,830.43073
Overall Steps per Second: 10,197.42534

Timestep Collection Time: 2.40158
Timestep Consumption Time: 2.50417
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.90575

Cumulative Model Updates: 18,180
Cumulative Timesteps: 151,705,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,173.26173
Policy Entropy: 1.08844
Value Function Loss: 0.10370

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.28708
Value Function Update Magnitude: 0.54474

Collected Steps per Second: 21,302.60289
Overall Steps per Second: 10,046.68002

Timestep Collection Time: 2.34788
Timestep Consumption Time: 2.63048
PPO Batch Consumption Time: 0.30533
Total Iteration Time: 4.97836

Cumulative Model Updates: 18,186
Cumulative Timesteps: 151,755,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 151755700...
Checkpoint 151755700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,265.77439
Policy Entropy: 1.09241
Value Function Loss: 0.10433

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.28444
Value Function Update Magnitude: 0.54608

Collected Steps per Second: 20,954.72017
Overall Steps per Second: 9,894.37483

Timestep Collection Time: 2.38753
Timestep Consumption Time: 2.66888
PPO Batch Consumption Time: 0.31566
Total Iteration Time: 5.05641

Cumulative Model Updates: 18,192
Cumulative Timesteps: 151,805,730

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,568.12941
Policy Entropy: 1.10048
Value Function Loss: 0.10453

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.30093
Value Function Update Magnitude: 0.57747

Collected Steps per Second: 21,282.74281
Overall Steps per Second: 9,875.59565

Timestep Collection Time: 2.35054
Timestep Consumption Time: 2.71508
PPO Batch Consumption Time: 0.32801
Total Iteration Time: 5.06562

Cumulative Model Updates: 18,198
Cumulative Timesteps: 151,855,756

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 151855756...
Checkpoint 151855756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,947.21316
Policy Entropy: 1.09746
Value Function Loss: 0.09924

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11522
Policy Update Magnitude: 0.32288
Value Function Update Magnitude: 0.67010

Collected Steps per Second: 20,763.73146
Overall Steps per Second: 10,306.22204

Timestep Collection Time: 2.40843
Timestep Consumption Time: 2.44378
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 4.85221

Cumulative Model Updates: 18,204
Cumulative Timesteps: 151,905,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,806.46393
Policy Entropy: 1.09740
Value Function Loss: 0.09945

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.36272
Value Function Update Magnitude: 0.71516

Collected Steps per Second: 21,199.85555
Overall Steps per Second: 10,139.48192

Timestep Collection Time: 2.35983
Timestep Consumption Time: 2.57415
PPO Batch Consumption Time: 0.30257
Total Iteration Time: 4.93398

Cumulative Model Updates: 18,210
Cumulative Timesteps: 151,955,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 151955792...
Checkpoint 151955792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,700.35949
Policy Entropy: 1.09669
Value Function Loss: 0.10052

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.34613
Value Function Update Magnitude: 0.70991

Collected Steps per Second: 20,777.52640
Overall Steps per Second: 10,095.32008

Timestep Collection Time: 2.40674
Timestep Consumption Time: 2.54665
PPO Batch Consumption Time: 0.29760
Total Iteration Time: 4.95338

Cumulative Model Updates: 18,216
Cumulative Timesteps: 152,005,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,357.33749
Policy Entropy: 1.09937
Value Function Loss: 0.10295

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.32072
Value Function Update Magnitude: 0.63441

Collected Steps per Second: 21,188.25202
Overall Steps per Second: 10,155.38437

Timestep Collection Time: 2.36036
Timestep Consumption Time: 2.56431
PPO Batch Consumption Time: 0.29776
Total Iteration Time: 4.92468

Cumulative Model Updates: 18,222
Cumulative Timesteps: 152,055,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 152055810...
Checkpoint 152055810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,975.83942
Policy Entropy: 1.09891
Value Function Loss: 0.10465

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.30305
Value Function Update Magnitude: 0.57722

Collected Steps per Second: 21,101.44231
Overall Steps per Second: 10,128.43646

Timestep Collection Time: 2.37083
Timestep Consumption Time: 2.56853
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 4.93936

Cumulative Model Updates: 18,228
Cumulative Timesteps: 152,105,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,201.36988
Policy Entropy: 1.08634
Value Function Loss: 0.10740

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11446
Policy Update Magnitude: 0.32808
Value Function Update Magnitude: 0.56414

Collected Steps per Second: 21,733.92867
Overall Steps per Second: 10,239.51416

Timestep Collection Time: 2.30064
Timestep Consumption Time: 2.58260
PPO Batch Consumption Time: 0.30639
Total Iteration Time: 4.88324

Cumulative Model Updates: 18,234
Cumulative Timesteps: 152,155,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 152155840...
Checkpoint 152155840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,120.36257
Policy Entropy: 1.08114
Value Function Loss: 0.11231

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.34941
Value Function Update Magnitude: 0.52678

Collected Steps per Second: 20,619.05304
Overall Steps per Second: 10,065.26911

Timestep Collection Time: 2.42601
Timestep Consumption Time: 2.54375
PPO Batch Consumption Time: 0.29962
Total Iteration Time: 4.96976

Cumulative Model Updates: 18,240
Cumulative Timesteps: 152,205,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,458.74314
Policy Entropy: 1.07846
Value Function Loss: 0.11011

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.33515
Value Function Update Magnitude: 0.47219

Collected Steps per Second: 21,535.91979
Overall Steps per Second: 10,256.77118

Timestep Collection Time: 2.32245
Timestep Consumption Time: 2.55394
PPO Batch Consumption Time: 0.30138
Total Iteration Time: 4.87639

Cumulative Model Updates: 18,246
Cumulative Timesteps: 152,255,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 152255878...
Checkpoint 152255878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,688.89163
Policy Entropy: 1.08390
Value Function Loss: 0.10625

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11047
Policy Update Magnitude: 0.34987
Value Function Update Magnitude: 0.49160

Collected Steps per Second: 21,146.69432
Overall Steps per Second: 10,127.37079

Timestep Collection Time: 2.36548
Timestep Consumption Time: 2.57381
PPO Batch Consumption Time: 0.30628
Total Iteration Time: 4.93929

Cumulative Model Updates: 18,252
Cumulative Timesteps: 152,305,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,916.62354
Policy Entropy: 1.08320
Value Function Loss: 0.09986

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.36216
Value Function Update Magnitude: 0.51191

Collected Steps per Second: 21,203.70208
Overall Steps per Second: 10,221.42011

Timestep Collection Time: 2.35978
Timestep Consumption Time: 2.53543
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 4.89521

Cumulative Model Updates: 18,258
Cumulative Timesteps: 152,355,936

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 152355936...
Checkpoint 152355936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,600.98997
Policy Entropy: 1.07988
Value Function Loss: 0.09214

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.34285
Value Function Update Magnitude: 0.59378

Collected Steps per Second: 21,056.09254
Overall Steps per Second: 10,044.80478

Timestep Collection Time: 2.37537
Timestep Consumption Time: 2.60392
PPO Batch Consumption Time: 0.30537
Total Iteration Time: 4.97929

Cumulative Model Updates: 18,264
Cumulative Timesteps: 152,405,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,855.36965
Policy Entropy: 1.07574
Value Function Loss: 0.09185

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.28024
Value Function Update Magnitude: 0.68028

Collected Steps per Second: 21,576.34119
Overall Steps per Second: 10,244.67141

Timestep Collection Time: 2.31809
Timestep Consumption Time: 2.56405
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.88215

Cumulative Model Updates: 18,270
Cumulative Timesteps: 152,455,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 152455968...
Checkpoint 152455968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,820.94024
Policy Entropy: 1.06694
Value Function Loss: 0.09634

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11154
Policy Update Magnitude: 0.28800
Value Function Update Magnitude: 0.62470

Collected Steps per Second: 20,774.66786
Overall Steps per Second: 9,944.51773

Timestep Collection Time: 2.40793
Timestep Consumption Time: 2.62238
PPO Batch Consumption Time: 0.30993
Total Iteration Time: 5.03031

Cumulative Model Updates: 18,276
Cumulative Timesteps: 152,505,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,406.18703
Policy Entropy: 1.07472
Value Function Loss: 0.09888

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09859
Policy Update Magnitude: 0.33180
Value Function Update Magnitude: 0.52199

Collected Steps per Second: 21,338.47693
Overall Steps per Second: 10,121.31210

Timestep Collection Time: 2.34440
Timestep Consumption Time: 2.59824
PPO Batch Consumption Time: 0.30454
Total Iteration Time: 4.94264

Cumulative Model Updates: 18,282
Cumulative Timesteps: 152,556,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 152556018...
Checkpoint 152556018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,927.09962
Policy Entropy: 1.08391
Value Function Loss: 0.09722

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.30940
Value Function Update Magnitude: 0.52185

Collected Steps per Second: 20,793.96452
Overall Steps per Second: 9,944.00608

Timestep Collection Time: 2.40599
Timestep Consumption Time: 2.62518
PPO Batch Consumption Time: 0.30631
Total Iteration Time: 5.03117

Cumulative Model Updates: 18,288
Cumulative Timesteps: 152,606,048

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,572.83298
Policy Entropy: 1.08431
Value Function Loss: 0.09552

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.29962
Value Function Update Magnitude: 0.57886

Collected Steps per Second: 21,573.60193
Overall Steps per Second: 10,201.21927

Timestep Collection Time: 2.31783
Timestep Consumption Time: 2.58393
PPO Batch Consumption Time: 0.30793
Total Iteration Time: 4.90177

Cumulative Model Updates: 18,294
Cumulative Timesteps: 152,656,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 152656052...
Checkpoint 152656052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,509.91245
Policy Entropy: 1.07893
Value Function Loss: 0.09844

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.32755
Value Function Update Magnitude: 0.55170

Collected Steps per Second: 21,046.80731
Overall Steps per Second: 10,144.25616

Timestep Collection Time: 2.37699
Timestep Consumption Time: 2.55467
PPO Batch Consumption Time: 0.30121
Total Iteration Time: 4.93166

Cumulative Model Updates: 18,300
Cumulative Timesteps: 152,706,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,008.99034
Policy Entropy: 1.07289
Value Function Loss: 0.09933

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08758
Policy Update Magnitude: 0.33440
Value Function Update Magnitude: 0.58299

Collected Steps per Second: 21,722.58303
Overall Steps per Second: 10,341.57864

Timestep Collection Time: 2.30313
Timestep Consumption Time: 2.53462
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.83775

Cumulative Model Updates: 18,306
Cumulative Timesteps: 152,756,110

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 152756110...
Checkpoint 152756110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,366.01175
Policy Entropy: 1.07494
Value Function Loss: 0.09635

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.32007
Value Function Update Magnitude: 0.60487

Collected Steps per Second: 21,043.96539
Overall Steps per Second: 10,061.38555

Timestep Collection Time: 2.37778
Timestep Consumption Time: 2.59549
PPO Batch Consumption Time: 0.30481
Total Iteration Time: 4.97327

Cumulative Model Updates: 18,312
Cumulative Timesteps: 152,806,148

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.56239
Policy Entropy: 1.07087
Value Function Loss: 0.09750

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10662
Policy Update Magnitude: 0.31752
Value Function Update Magnitude: 0.57858

Collected Steps per Second: 21,320.22466
Overall Steps per Second: 10,269.77155

Timestep Collection Time: 2.34707
Timestep Consumption Time: 2.52549
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.87255

Cumulative Model Updates: 18,318
Cumulative Timesteps: 152,856,188

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 152856188...
Checkpoint 152856188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,992.41598
Policy Entropy: 1.07341
Value Function Loss: 0.09384

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.30332
Value Function Update Magnitude: 0.62163

Collected Steps per Second: 20,857.38202
Overall Steps per Second: 10,105.15944

Timestep Collection Time: 2.39800
Timestep Consumption Time: 2.55155
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.94955

Cumulative Model Updates: 18,324
Cumulative Timesteps: 152,906,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,580.29845
Policy Entropy: 1.06896
Value Function Loss: 0.09862

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.31385
Value Function Update Magnitude: 0.58372

Collected Steps per Second: 21,394.56103
Overall Steps per Second: 10,164.94456

Timestep Collection Time: 2.33844
Timestep Consumption Time: 2.58337
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 4.92182

Cumulative Model Updates: 18,330
Cumulative Timesteps: 152,956,234

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 152956234...
Checkpoint 152956234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,645.53270
Policy Entropy: 1.06795
Value Function Loss: 0.10063

Mean KL Divergence: 0.02107
SB3 Clip Fraction: 0.16469
Policy Update Magnitude: 0.29643
Value Function Update Magnitude: 0.58152

Collected Steps per Second: 21,114.64509
Overall Steps per Second: 10,160.26300

Timestep Collection Time: 2.36916
Timestep Consumption Time: 2.55433
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.92349

Cumulative Model Updates: 18,336
Cumulative Timesteps: 153,006,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,345.99666
Policy Entropy: 1.06401
Value Function Loss: 0.10140

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.32105
Value Function Update Magnitude: 0.63186

Collected Steps per Second: 21,540.04380
Overall Steps per Second: 10,090.93583

Timestep Collection Time: 2.32228
Timestep Consumption Time: 2.63484
PPO Batch Consumption Time: 0.31006
Total Iteration Time: 4.95712

Cumulative Model Updates: 18,342
Cumulative Timesteps: 153,056,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 153056280...
Checkpoint 153056280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,765.16327
Policy Entropy: 1.06790
Value Function Loss: 0.10070

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 0.33704
Value Function Update Magnitude: 0.72368

Collected Steps per Second: 20,927.76640
Overall Steps per Second: 10,064.52925

Timestep Collection Time: 2.39003
Timestep Consumption Time: 2.57970
PPO Batch Consumption Time: 0.30560
Total Iteration Time: 4.96973

Cumulative Model Updates: 18,348
Cumulative Timesteps: 153,106,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,930.18515
Policy Entropy: 1.07886
Value Function Loss: 0.09841

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13881
Policy Update Magnitude: 0.30092
Value Function Update Magnitude: 0.73414

Collected Steps per Second: 21,447.54730
Overall Steps per Second: 10,088.97222

Timestep Collection Time: 2.33127
Timestep Consumption Time: 2.62464
PPO Batch Consumption Time: 0.30842
Total Iteration Time: 4.95591

Cumulative Model Updates: 18,354
Cumulative Timesteps: 153,156,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 153156298...
Checkpoint 153156298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,332.71805
Policy Entropy: 1.07320
Value Function Loss: 0.10255

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.12370
Policy Update Magnitude: 0.28539
Value Function Update Magnitude: 0.70377

Collected Steps per Second: 21,081.37366
Overall Steps per Second: 10,187.08962

Timestep Collection Time: 2.37290
Timestep Consumption Time: 2.53763
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 4.91053

Cumulative Model Updates: 18,360
Cumulative Timesteps: 153,206,322

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,809.80052
Policy Entropy: 1.06959
Value Function Loss: 0.10394

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.26033
Value Function Update Magnitude: 0.58579

Collected Steps per Second: 21,629.48586
Overall Steps per Second: 10,235.25971

Timestep Collection Time: 2.31194
Timestep Consumption Time: 2.57372
PPO Batch Consumption Time: 0.30735
Total Iteration Time: 4.88566

Cumulative Model Updates: 18,366
Cumulative Timesteps: 153,256,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 153256328...
Checkpoint 153256328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,299.48872
Policy Entropy: 1.06876
Value Function Loss: 0.10315

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13892
Policy Update Magnitude: 0.24968
Value Function Update Magnitude: 0.58488

Collected Steps per Second: 21,031.30759
Overall Steps per Second: 10,119.30640

Timestep Collection Time: 2.37874
Timestep Consumption Time: 2.56508
PPO Batch Consumption Time: 0.30270
Total Iteration Time: 4.94382

Cumulative Model Updates: 18,372
Cumulative Timesteps: 153,306,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,082.00933
Policy Entropy: 1.07071
Value Function Loss: 0.10000

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.25901
Value Function Update Magnitude: 0.67502

Collected Steps per Second: 21,742.46514
Overall Steps per Second: 10,360.41142

Timestep Collection Time: 2.29992
Timestep Consumption Time: 2.52672
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.82664

Cumulative Model Updates: 18,378
Cumulative Timesteps: 153,356,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 153356362...
Checkpoint 153356362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,452.03711
Policy Entropy: 1.08720
Value Function Loss: 0.10377

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.25959
Value Function Update Magnitude: 0.70569

Collected Steps per Second: 21,124.62188
Overall Steps per Second: 10,212.26443

Timestep Collection Time: 2.36719
Timestep Consumption Time: 2.52947
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.89666

Cumulative Model Updates: 18,384
Cumulative Timesteps: 153,406,368

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,379.36215
Policy Entropy: 1.08883
Value Function Loss: 0.10852

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.26520
Value Function Update Magnitude: 0.61195

Collected Steps per Second: 21,517.88496
Overall Steps per Second: 10,214.66562

Timestep Collection Time: 2.32476
Timestep Consumption Time: 2.57251
PPO Batch Consumption Time: 0.30832
Total Iteration Time: 4.89727

Cumulative Model Updates: 18,390
Cumulative Timesteps: 153,456,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 153456392...
Checkpoint 153456392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,313.32525
Policy Entropy: 1.09429
Value Function Loss: 0.11506

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.26701
Value Function Update Magnitude: 0.56569

Collected Steps per Second: 20,950.96099
Overall Steps per Second: 10,113.71836

Timestep Collection Time: 2.38719
Timestep Consumption Time: 2.55797
PPO Batch Consumption Time: 0.30302
Total Iteration Time: 4.94516

Cumulative Model Updates: 18,396
Cumulative Timesteps: 153,506,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,095.67722
Policy Entropy: 1.08587
Value Function Loss: 0.11728

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.26244
Value Function Update Magnitude: 0.54352

Collected Steps per Second: 21,493.09160
Overall Steps per Second: 10,301.62815

Timestep Collection Time: 2.32652
Timestep Consumption Time: 2.52747
PPO Batch Consumption Time: 0.29782
Total Iteration Time: 4.85399

Cumulative Model Updates: 18,402
Cumulative Timesteps: 153,556,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 153556410...
Checkpoint 153556410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,086.80872
Policy Entropy: 1.08920
Value Function Loss: 0.11524

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.27956
Value Function Update Magnitude: 0.51847

Collected Steps per Second: 21,217.44599
Overall Steps per Second: 10,257.72240

Timestep Collection Time: 2.35731
Timestep Consumption Time: 2.51863
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.87594

Cumulative Model Updates: 18,408
Cumulative Timesteps: 153,606,426

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,576.01560
Policy Entropy: 1.09049
Value Function Loss: 0.10866

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.27825
Value Function Update Magnitude: 0.64849

Collected Steps per Second: 21,867.05014
Overall Steps per Second: 10,291.72897

Timestep Collection Time: 2.28719
Timestep Consumption Time: 2.57244
PPO Batch Consumption Time: 0.30496
Total Iteration Time: 4.85963

Cumulative Model Updates: 18,414
Cumulative Timesteps: 153,656,440

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 153656440...
Checkpoint 153656440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,238.71441
Policy Entropy: 1.09666
Value Function Loss: 0.10420

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.26628
Value Function Update Magnitude: 0.70962

Collected Steps per Second: 20,577.30451
Overall Steps per Second: 10,051.12565

Timestep Collection Time: 2.42986
Timestep Consumption Time: 2.54471
PPO Batch Consumption Time: 0.29882
Total Iteration Time: 4.97457

Cumulative Model Updates: 18,420
Cumulative Timesteps: 153,706,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,752.15366
Policy Entropy: 1.08303
Value Function Loss: 0.10765

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10131
Policy Update Magnitude: 0.29423
Value Function Update Magnitude: 0.70101

Collected Steps per Second: 21,303.81349
Overall Steps per Second: 10,046.03532

Timestep Collection Time: 2.34765
Timestep Consumption Time: 2.63083
PPO Batch Consumption Time: 0.31418
Total Iteration Time: 4.97848

Cumulative Model Updates: 18,426
Cumulative Timesteps: 153,756,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 153756454...
Checkpoint 153756454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,412.63244
Policy Entropy: 1.07689
Value Function Loss: 0.10705

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.31820
Value Function Update Magnitude: 0.63681

Collected Steps per Second: 20,744.03642
Overall Steps per Second: 10,151.05032

Timestep Collection Time: 2.41043
Timestep Consumption Time: 2.51537
PPO Batch Consumption Time: 0.29602
Total Iteration Time: 4.92580

Cumulative Model Updates: 18,432
Cumulative Timesteps: 153,806,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,224.75969
Policy Entropy: 1.08299
Value Function Loss: 0.10682

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.33349
Value Function Update Magnitude: 0.57126

Collected Steps per Second: 21,358.32143
Overall Steps per Second: 10,134.86556

Timestep Collection Time: 2.34185
Timestep Consumption Time: 2.59339
PPO Batch Consumption Time: 0.30981
Total Iteration Time: 4.93524

Cumulative Model Updates: 18,438
Cumulative Timesteps: 153,856,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 153856474...
Checkpoint 153856474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,049.47293
Policy Entropy: 1.08907
Value Function Loss: 0.10429

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.31240
Value Function Update Magnitude: 0.55169

Collected Steps per Second: 20,724.22941
Overall Steps per Second: 10,175.22348

Timestep Collection Time: 2.41370
Timestep Consumption Time: 2.50236
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.91606

Cumulative Model Updates: 18,444
Cumulative Timesteps: 153,906,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,106.51336
Policy Entropy: 1.07791
Value Function Loss: 0.10924

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.27932
Value Function Update Magnitude: 0.49296

Collected Steps per Second: 21,372.06669
Overall Steps per Second: 10,221.66342

Timestep Collection Time: 2.34063
Timestep Consumption Time: 2.55329
PPO Batch Consumption Time: 0.30316
Total Iteration Time: 4.89392

Cumulative Model Updates: 18,450
Cumulative Timesteps: 153,956,520

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 153956520...
Checkpoint 153956520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,648.88492
Policy Entropy: 1.07217
Value Function Loss: 0.10808

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.29567
Value Function Update Magnitude: 0.46756

Collected Steps per Second: 21,228.44199
Overall Steps per Second: 10,185.23946

Timestep Collection Time: 2.35571
Timestep Consumption Time: 2.55414
PPO Batch Consumption Time: 0.30339
Total Iteration Time: 4.90985

Cumulative Model Updates: 18,456
Cumulative Timesteps: 154,006,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,705.03556
Policy Entropy: 1.07424
Value Function Loss: 0.10215

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.12602
Policy Update Magnitude: 0.29439
Value Function Update Magnitude: 0.47232

Collected Steps per Second: 21,576.24170
Overall Steps per Second: 10,244.79702

Timestep Collection Time: 2.31792
Timestep Consumption Time: 2.56378
PPO Batch Consumption Time: 0.30055
Total Iteration Time: 4.88170

Cumulative Model Updates: 18,462
Cumulative Timesteps: 154,056,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 154056540...
Checkpoint 154056540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,929.37558
Policy Entropy: 1.07782
Value Function Loss: 0.09797

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12897
Policy Update Magnitude: 0.27427
Value Function Update Magnitude: 0.50072

Collected Steps per Second: 20,845.67449
Overall Steps per Second: 10,125.98911

Timestep Collection Time: 2.39915
Timestep Consumption Time: 2.53982
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.93897

Cumulative Model Updates: 18,468
Cumulative Timesteps: 154,106,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,439.48683
Policy Entropy: 1.07012
Value Function Loss: 0.09919

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11695
Policy Update Magnitude: 0.29484
Value Function Update Magnitude: 0.56085

Collected Steps per Second: 21,226.21812
Overall Steps per Second: 10,098.01096

Timestep Collection Time: 2.35756
Timestep Consumption Time: 2.59807
PPO Batch Consumption Time: 0.30112
Total Iteration Time: 4.95563

Cumulative Model Updates: 18,474
Cumulative Timesteps: 154,156,594

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 154156594...
Checkpoint 154156594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,936.24408
Policy Entropy: 1.05984
Value Function Loss: 0.10196

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12138
Policy Update Magnitude: 0.28522
Value Function Update Magnitude: 0.64147

Collected Steps per Second: 21,276.64008
Overall Steps per Second: 10,126.31131

Timestep Collection Time: 2.35141
Timestep Consumption Time: 2.58919
PPO Batch Consumption Time: 0.30143
Total Iteration Time: 4.94059

Cumulative Model Updates: 18,480
Cumulative Timesteps: 154,206,624

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.60705
Policy Entropy: 1.05197
Value Function Loss: 0.10188

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.30395
Value Function Update Magnitude: 0.66938

Collected Steps per Second: 21,392.90152
Overall Steps per Second: 10,138.80866

Timestep Collection Time: 2.33863
Timestep Consumption Time: 2.59588
PPO Batch Consumption Time: 0.31064
Total Iteration Time: 4.93450

Cumulative Model Updates: 18,486
Cumulative Timesteps: 154,256,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 154256654...
Checkpoint 154256654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,995.77715
Policy Entropy: 1.05565
Value Function Loss: 0.10471

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.14863
Policy Update Magnitude: 0.27081
Value Function Update Magnitude: 0.60223

Collected Steps per Second: 21,126.41724
Overall Steps per Second: 10,253.20702

Timestep Collection Time: 2.36917
Timestep Consumption Time: 2.51243
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.88159

Cumulative Model Updates: 18,492
Cumulative Timesteps: 154,306,706

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,571.35915
Policy Entropy: 1.07001
Value Function Loss: 0.10821

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.26964
Value Function Update Magnitude: 0.53322

Collected Steps per Second: 21,454.60414
Overall Steps per Second: 10,208.01802

Timestep Collection Time: 2.33097
Timestep Consumption Time: 2.56812
PPO Batch Consumption Time: 0.30373
Total Iteration Time: 4.89909

Cumulative Model Updates: 18,498
Cumulative Timesteps: 154,356,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 154356716...
Checkpoint 154356716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,806.09121
Policy Entropy: 1.07082
Value Function Loss: 0.10830

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.27993
Value Function Update Magnitude: 0.54286

Collected Steps per Second: 20,766.73278
Overall Steps per Second: 9,949.36658

Timestep Collection Time: 2.40905
Timestep Consumption Time: 2.61921
PPO Batch Consumption Time: 0.31523
Total Iteration Time: 5.02826

Cumulative Model Updates: 18,504
Cumulative Timesteps: 154,406,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,981.50151
Policy Entropy: 1.07895
Value Function Loss: 0.11003

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.32168
Value Function Update Magnitude: 0.51193

Collected Steps per Second: 21,341.57048
Overall Steps per Second: 10,152.48251

Timestep Collection Time: 2.34360
Timestep Consumption Time: 2.58288
PPO Batch Consumption Time: 0.30917
Total Iteration Time: 4.92648

Cumulative Model Updates: 18,510
Cumulative Timesteps: 154,456,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 154456760...
Checkpoint 154456760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.90846
Policy Entropy: 1.07175
Value Function Loss: 0.10768

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.36191
Value Function Update Magnitude: 0.62533

Collected Steps per Second: 21,054.28042
Overall Steps per Second: 10,168.49109

Timestep Collection Time: 2.37614
Timestep Consumption Time: 2.54376
PPO Batch Consumption Time: 0.29924
Total Iteration Time: 4.91990

Cumulative Model Updates: 18,516
Cumulative Timesteps: 154,506,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888.77923
Policy Entropy: 1.07287
Value Function Loss: 0.10867

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.36087
Value Function Update Magnitude: 0.68619

Collected Steps per Second: 21,393.07571
Overall Steps per Second: 10,222.01829

Timestep Collection Time: 2.33749
Timestep Consumption Time: 2.55450
PPO Batch Consumption Time: 0.30232
Total Iteration Time: 4.89199

Cumulative Model Updates: 18,522
Cumulative Timesteps: 154,556,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 154556794...
Checkpoint 154556794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,858.85080
Policy Entropy: 1.06509
Value Function Loss: 0.10934

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07646
Policy Update Magnitude: 0.36197
Value Function Update Magnitude: 0.58923

Collected Steps per Second: 21,171.15589
Overall Steps per Second: 10,133.31422

Timestep Collection Time: 2.36180
Timestep Consumption Time: 2.57262
PPO Batch Consumption Time: 0.30624
Total Iteration Time: 4.93442

Cumulative Model Updates: 18,528
Cumulative Timesteps: 154,606,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.38555
Policy Entropy: 1.05561
Value Function Loss: 0.11117

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.35221
Value Function Update Magnitude: 0.56148

Collected Steps per Second: 21,528.32516
Overall Steps per Second: 10,277.50412

Timestep Collection Time: 2.32354
Timestep Consumption Time: 2.54359
PPO Batch Consumption Time: 0.29826
Total Iteration Time: 4.86714

Cumulative Model Updates: 18,534
Cumulative Timesteps: 154,656,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 154656818...
Checkpoint 154656818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.83137
Policy Entropy: 1.06423
Value Function Loss: 0.11218

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08566
Policy Update Magnitude: 0.33981
Value Function Update Magnitude: 0.54430

Collected Steps per Second: 20,863.90659
Overall Steps per Second: 9,974.99270

Timestep Collection Time: 2.39677
Timestep Consumption Time: 2.61637
PPO Batch Consumption Time: 0.31090
Total Iteration Time: 5.01314

Cumulative Model Updates: 18,540
Cumulative Timesteps: 154,706,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,237.16396
Policy Entropy: 1.05971
Value Function Loss: 0.11389

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.35740
Value Function Update Magnitude: 0.56204

Collected Steps per Second: 21,258.61145
Overall Steps per Second: 10,088.21501

Timestep Collection Time: 2.35312
Timestep Consumption Time: 2.60554
PPO Batch Consumption Time: 0.30689
Total Iteration Time: 4.95866

Cumulative Model Updates: 18,546
Cumulative Timesteps: 154,756,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 154756848...
Checkpoint 154756848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,084.77259
Policy Entropy: 1.05865
Value Function Loss: 0.11450

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.35096
Value Function Update Magnitude: 0.53928

Collected Steps per Second: 21,116.58860
Overall Steps per Second: 10,097.82531

Timestep Collection Time: 2.36856
Timestep Consumption Time: 2.58458
PPO Batch Consumption Time: 0.30877
Total Iteration Time: 4.95315

Cumulative Model Updates: 18,552
Cumulative Timesteps: 154,806,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,481.42999
Policy Entropy: 1.06609
Value Function Loss: 0.11166

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.33900
Value Function Update Magnitude: 0.52309

Collected Steps per Second: 21,226.77828
Overall Steps per Second: 10,059.31222

Timestep Collection Time: 2.35665
Timestep Consumption Time: 2.61626
PPO Batch Consumption Time: 0.31068
Total Iteration Time: 4.97290

Cumulative Model Updates: 18,558
Cumulative Timesteps: 154,856,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 154856888...
Checkpoint 154856888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.49221
Policy Entropy: 1.06214
Value Function Loss: 0.11027

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12410
Policy Update Magnitude: 0.31039
Value Function Update Magnitude: 0.50317

Collected Steps per Second: 21,164.07220
Overall Steps per Second: 10,138.84585

Timestep Collection Time: 2.36391
Timestep Consumption Time: 2.57057
PPO Batch Consumption Time: 0.30337
Total Iteration Time: 4.93449

Cumulative Model Updates: 18,564
Cumulative Timesteps: 154,906,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,526.03714
Policy Entropy: 1.07290
Value Function Loss: 0.10911

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12324
Policy Update Magnitude: 0.31430
Value Function Update Magnitude: 0.52055

Collected Steps per Second: 21,108.44711
Overall Steps per Second: 10,076.51995

Timestep Collection Time: 2.36957
Timestep Consumption Time: 2.59424
PPO Batch Consumption Time: 0.30870
Total Iteration Time: 4.96382

Cumulative Model Updates: 18,570
Cumulative Timesteps: 154,956,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 154956936...
Checkpoint 154956936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,141.11563
Policy Entropy: 1.08035
Value Function Loss: 0.10665

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.30992
Value Function Update Magnitude: 0.52751

Collected Steps per Second: 20,738.43868
Overall Steps per Second: 9,960.29682

Timestep Collection Time: 2.41175
Timestep Consumption Time: 2.60978
PPO Batch Consumption Time: 0.30965
Total Iteration Time: 5.02154

Cumulative Model Updates: 18,576
Cumulative Timesteps: 155,006,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,974.09702
Policy Entropy: 1.08485
Value Function Loss: 0.10624

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12034
Policy Update Magnitude: 0.28541
Value Function Update Magnitude: 0.52586

Collected Steps per Second: 21,367.42369
Overall Steps per Second: 10,090.41367

Timestep Collection Time: 2.34076
Timestep Consumption Time: 2.61602
PPO Batch Consumption Time: 0.30562
Total Iteration Time: 4.95678

Cumulative Model Updates: 18,582
Cumulative Timesteps: 155,056,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 155056968...
Checkpoint 155056968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,544.41033
Policy Entropy: 1.07933
Value Function Loss: 0.10382

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.29475
Value Function Update Magnitude: 0.51160

Collected Steps per Second: 21,213.26235
Overall Steps per Second: 10,209.70505

Timestep Collection Time: 2.35730
Timestep Consumption Time: 2.54059
PPO Batch Consumption Time: 0.29918
Total Iteration Time: 4.89789

Cumulative Model Updates: 18,588
Cumulative Timesteps: 155,106,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683.03094
Policy Entropy: 1.07299
Value Function Loss: 0.10463

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.28738
Value Function Update Magnitude: 0.49176

Collected Steps per Second: 21,293.49602
Overall Steps per Second: 10,114.43875

Timestep Collection Time: 2.34907
Timestep Consumption Time: 2.59633
PPO Batch Consumption Time: 0.30693
Total Iteration Time: 4.94541

Cumulative Model Updates: 18,594
Cumulative Timesteps: 155,156,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 155156994...
Checkpoint 155156994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,751.45496
Policy Entropy: 1.08045
Value Function Loss: 0.10555

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.29255
Value Function Update Magnitude: 0.48708

Collected Steps per Second: 20,836.19075
Overall Steps per Second: 10,142.58723

Timestep Collection Time: 2.40092
Timestep Consumption Time: 2.53135
PPO Batch Consumption Time: 0.29731
Total Iteration Time: 4.93227

Cumulative Model Updates: 18,600
Cumulative Timesteps: 155,207,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,144.30784
Policy Entropy: 1.08814
Value Function Loss: 0.10537

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12086
Policy Update Magnitude: 0.28575
Value Function Update Magnitude: 0.49613

Collected Steps per Second: 21,096.88189
Overall Steps per Second: 10,148.88945

Timestep Collection Time: 2.37229
Timestep Consumption Time: 2.55908
PPO Batch Consumption Time: 0.30095
Total Iteration Time: 4.93138

Cumulative Model Updates: 18,606
Cumulative Timesteps: 155,257,068

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 155257068...
Checkpoint 155257068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,832.48438
Policy Entropy: 1.08426
Value Function Loss: 0.10544

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.28058
Value Function Update Magnitude: 0.54906

Collected Steps per Second: 21,005.25270
Overall Steps per Second: 10,184.43072

Timestep Collection Time: 2.38112
Timestep Consumption Time: 2.52991
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.91103

Cumulative Model Updates: 18,612
Cumulative Timesteps: 155,307,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.08516
Policy Entropy: 1.08426
Value Function Loss: 0.10454

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10836
Policy Update Magnitude: 0.31286
Value Function Update Magnitude: 0.51487

Collected Steps per Second: 21,590.14409
Overall Steps per Second: 10,219.70383

Timestep Collection Time: 2.31819
Timestep Consumption Time: 2.57921
PPO Batch Consumption Time: 0.30692
Total Iteration Time: 4.89740

Cumulative Model Updates: 18,618
Cumulative Timesteps: 155,357,134

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 155357134...
Checkpoint 155357134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,103.64788
Policy Entropy: 1.07477
Value Function Loss: 0.10231

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11639
Policy Update Magnitude: 0.32853
Value Function Update Magnitude: 0.56287

Collected Steps per Second: 21,250.45229
Overall Steps per Second: 10,047.74719

Timestep Collection Time: 2.35411
Timestep Consumption Time: 2.62471
PPO Batch Consumption Time: 0.31513
Total Iteration Time: 4.97883

Cumulative Model Updates: 18,624
Cumulative Timesteps: 155,407,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,288.26476
Policy Entropy: 1.07040
Value Function Loss: 0.10741

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.29580
Value Function Update Magnitude: 0.66118

Collected Steps per Second: 20,849.72336
Overall Steps per Second: 9,976.69146

Timestep Collection Time: 2.39869
Timestep Consumption Time: 2.61420
PPO Batch Consumption Time: 0.30939
Total Iteration Time: 5.01288

Cumulative Model Updates: 18,630
Cumulative Timesteps: 155,457,172

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 155457172...
Checkpoint 155457172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,733.15660
Policy Entropy: 1.06478
Value Function Loss: 0.10531

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14462
Policy Update Magnitude: 0.30370
Value Function Update Magnitude: 0.62692

Collected Steps per Second: 21,083.17255
Overall Steps per Second: 10,063.51889

Timestep Collection Time: 2.37203
Timestep Consumption Time: 2.59740
PPO Batch Consumption Time: 0.30847
Total Iteration Time: 4.96943

Cumulative Model Updates: 18,636
Cumulative Timesteps: 155,507,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,059.48860
Policy Entropy: 1.07027
Value Function Loss: 0.11006

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.14631
Policy Update Magnitude: 0.33737
Value Function Update Magnitude: 0.59753

Collected Steps per Second: 21,321.38806
Overall Steps per Second: 10,047.62123

Timestep Collection Time: 2.34572
Timestep Consumption Time: 2.63198
PPO Batch Consumption Time: 0.30662
Total Iteration Time: 4.97770

Cumulative Model Updates: 18,642
Cumulative Timesteps: 155,557,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 155557196...
Checkpoint 155557196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,657.22546
Policy Entropy: 1.07656
Value Function Loss: 0.10524

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.32673
Value Function Update Magnitude: 0.55412

Collected Steps per Second: 21,276.70524
Overall Steps per Second: 10,158.14015

Timestep Collection Time: 2.35121
Timestep Consumption Time: 2.57351
PPO Batch Consumption Time: 0.30627
Total Iteration Time: 4.92472

Cumulative Model Updates: 18,648
Cumulative Timesteps: 155,607,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,585.08486
Policy Entropy: 1.08636
Value Function Loss: 0.10149

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.34907
Value Function Update Magnitude: 0.57365

Collected Steps per Second: 21,045.91649
Overall Steps per Second: 10,170.61246

Timestep Collection Time: 2.37642
Timestep Consumption Time: 2.54108
PPO Batch Consumption Time: 0.29888
Total Iteration Time: 4.91750

Cumulative Model Updates: 18,654
Cumulative Timesteps: 155,657,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 155657236...
Checkpoint 155657236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,364.57499
Policy Entropy: 1.07063
Value Function Loss: 0.09933

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11632
Policy Update Magnitude: 0.34770
Value Function Update Magnitude: 0.58940

Collected Steps per Second: 21,108.94359
Overall Steps per Second: 10,084.72211

Timestep Collection Time: 2.36999
Timestep Consumption Time: 2.59078
PPO Batch Consumption Time: 0.30922
Total Iteration Time: 4.96077

Cumulative Model Updates: 18,660
Cumulative Timesteps: 155,707,264

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488.47169
Policy Entropy: 1.06920
Value Function Loss: 0.10150

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.12081
Policy Update Magnitude: 0.32866
Value Function Update Magnitude: 0.56639

Collected Steps per Second: 20,916.25092
Overall Steps per Second: 10,086.06863

Timestep Collection Time: 2.39068
Timestep Consumption Time: 2.56705
PPO Batch Consumption Time: 0.30298
Total Iteration Time: 4.95773

Cumulative Model Updates: 18,666
Cumulative Timesteps: 155,757,268

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 155757268...
Checkpoint 155757268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,622.09241
Policy Entropy: 1.06946
Value Function Loss: 0.10338

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.31731
Value Function Update Magnitude: 0.60331

Collected Steps per Second: 21,049.79828
Overall Steps per Second: 10,069.86984

Timestep Collection Time: 2.37551
Timestep Consumption Time: 2.59020
PPO Batch Consumption Time: 0.30845
Total Iteration Time: 4.96570

Cumulative Model Updates: 18,672
Cumulative Timesteps: 155,807,272

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,080.41164
Policy Entropy: 1.07348
Value Function Loss: 0.10260

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11080
Policy Update Magnitude: 0.31574
Value Function Update Magnitude: 0.61443

Collected Steps per Second: 21,165.29581
Overall Steps per Second: 9,905.06347

Timestep Collection Time: 2.36274
Timestep Consumption Time: 2.68600
PPO Batch Consumption Time: 0.31754
Total Iteration Time: 5.04873

Cumulative Model Updates: 18,678
Cumulative Timesteps: 155,857,280

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 155857280...
Checkpoint 155857280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,856.29395
Policy Entropy: 1.07197
Value Function Loss: 0.10357

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.35611
Value Function Update Magnitude: 0.60368

Collected Steps per Second: 20,246.00266
Overall Steps per Second: 9,902.70308

Timestep Collection Time: 2.47031
Timestep Consumption Time: 2.58023
PPO Batch Consumption Time: 0.30196
Total Iteration Time: 5.05054

Cumulative Model Updates: 18,684
Cumulative Timesteps: 155,907,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,167.07685
Policy Entropy: 1.06786
Value Function Loss: 0.10045

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08402
Policy Update Magnitude: 0.38330
Value Function Update Magnitude: 0.63769

Collected Steps per Second: 21,310.15294
Overall Steps per Second: 9,983.80262

Timestep Collection Time: 2.34658
Timestep Consumption Time: 2.66213
PPO Batch Consumption Time: 0.31706
Total Iteration Time: 5.00871

Cumulative Model Updates: 18,690
Cumulative Timesteps: 155,957,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 155957300...
Checkpoint 155957300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,611.07130
Policy Entropy: 1.05505
Value Function Loss: 0.09925

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.36371
Value Function Update Magnitude: 0.71506

Collected Steps per Second: 21,387.63646
Overall Steps per Second: 10,376.53898

Timestep Collection Time: 2.33836
Timestep Consumption Time: 2.48136
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.81972

Cumulative Model Updates: 18,696
Cumulative Timesteps: 156,007,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,561.03464
Policy Entropy: 1.05275
Value Function Loss: 0.10259

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.32354
Value Function Update Magnitude: 0.70343

Collected Steps per Second: 21,508.26077
Overall Steps per Second: 10,117.02544

Timestep Collection Time: 2.32543
Timestep Consumption Time: 2.61831
PPO Batch Consumption Time: 0.30807
Total Iteration Time: 4.94375

Cumulative Model Updates: 18,702
Cumulative Timesteps: 156,057,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 156057328...
Checkpoint 156057328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,434.72532
Policy Entropy: 1.05357
Value Function Loss: 0.10303

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.29458
Value Function Update Magnitude: 0.62864

Collected Steps per Second: 20,718.08934
Overall Steps per Second: 9,973.52805

Timestep Collection Time: 2.41489
Timestep Consumption Time: 2.60159
PPO Batch Consumption Time: 0.30784
Total Iteration Time: 5.01648

Cumulative Model Updates: 18,708
Cumulative Timesteps: 156,107,360

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.49745
Policy Entropy: 1.05346
Value Function Loss: 0.10605

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11664
Policy Update Magnitude: 0.29311
Value Function Update Magnitude: 0.55646

Collected Steps per Second: 21,521.00721
Overall Steps per Second: 10,168.10870

Timestep Collection Time: 2.32350
Timestep Consumption Time: 2.59423
PPO Batch Consumption Time: 0.30867
Total Iteration Time: 4.91773

Cumulative Model Updates: 18,714
Cumulative Timesteps: 156,157,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 156157364...
Checkpoint 156157364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,023.08025
Policy Entropy: 1.06057
Value Function Loss: 0.09894

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.28018
Value Function Update Magnitude: 0.55355

Collected Steps per Second: 21,357.58922
Overall Steps per Second: 10,341.94271

Timestep Collection Time: 2.34174
Timestep Consumption Time: 2.49429
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 4.83604

Cumulative Model Updates: 18,720
Cumulative Timesteps: 156,207,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,256.08068
Policy Entropy: 1.06069
Value Function Loss: 0.10428

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11397
Policy Update Magnitude: 0.29164
Value Function Update Magnitude: 0.53545

Collected Steps per Second: 21,292.07282
Overall Steps per Second: 10,032.85076

Timestep Collection Time: 2.34829
Timestep Consumption Time: 2.63534
PPO Batch Consumption Time: 0.31440
Total Iteration Time: 4.98363

Cumulative Model Updates: 18,726
Cumulative Timesteps: 156,257,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 156257378...
Checkpoint 156257378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,865.13810
Policy Entropy: 1.07485
Value Function Loss: 0.10095

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11798
Policy Update Magnitude: 0.27987
Value Function Update Magnitude: 0.61478

Collected Steps per Second: 20,572.83584
Overall Steps per Second: 9,824.93008

Timestep Collection Time: 2.43292
Timestep Consumption Time: 2.66147
PPO Batch Consumption Time: 0.32197
Total Iteration Time: 5.09439

Cumulative Model Updates: 18,732
Cumulative Timesteps: 156,307,430

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,201.18168
Policy Entropy: 1.06860
Value Function Loss: 0.10181

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.27354
Value Function Update Magnitude: 0.67547

Collected Steps per Second: 21,462.60013
Overall Steps per Second: 10,011.73400

Timestep Collection Time: 2.33066
Timestep Consumption Time: 2.66568
PPO Batch Consumption Time: 0.31681
Total Iteration Time: 4.99634

Cumulative Model Updates: 18,738
Cumulative Timesteps: 156,357,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 156357452...
Checkpoint 156357452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,350.48744
Policy Entropy: 1.08336
Value Function Loss: 0.10680

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.12183
Policy Update Magnitude: 0.28502
Value Function Update Magnitude: 0.61996

Collected Steps per Second: 20,905.73396
Overall Steps per Second: 10,033.81743

Timestep Collection Time: 2.39178
Timestep Consumption Time: 2.59156
PPO Batch Consumption Time: 0.30937
Total Iteration Time: 4.98335

Cumulative Model Updates: 18,744
Cumulative Timesteps: 156,407,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,732.18296
Policy Entropy: 1.08440
Value Function Loss: 0.11031

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11087
Policy Update Magnitude: 0.31887
Value Function Update Magnitude: 0.55049

Collected Steps per Second: 21,322.99698
Overall Steps per Second: 10,241.97170

Timestep Collection Time: 2.34564
Timestep Consumption Time: 2.53780
PPO Batch Consumption Time: 0.29993
Total Iteration Time: 4.88343

Cumulative Model Updates: 18,750
Cumulative Timesteps: 156,457,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 156457470...
Checkpoint 156457470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,163.08661
Policy Entropy: 1.07972
Value Function Loss: 0.11494

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.31706
Value Function Update Magnitude: 0.51049

Collected Steps per Second: 20,888.00765
Overall Steps per Second: 9,958.27196

Timestep Collection Time: 2.39410
Timestep Consumption Time: 2.62765
PPO Batch Consumption Time: 0.31602
Total Iteration Time: 5.02175

Cumulative Model Updates: 18,756
Cumulative Timesteps: 156,507,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,579.47977
Policy Entropy: 1.07968
Value Function Loss: 0.10924

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.10956
Policy Update Magnitude: 0.32003
Value Function Update Magnitude: 0.52849

Collected Steps per Second: 20,985.39821
Overall Steps per Second: 9,881.71069

Timestep Collection Time: 2.38337
Timestep Consumption Time: 2.67810
PPO Batch Consumption Time: 0.32211
Total Iteration Time: 5.06147

Cumulative Model Updates: 18,762
Cumulative Timesteps: 156,557,494

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 156557494...
Checkpoint 156557494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,819.71800
Policy Entropy: 1.07250
Value Function Loss: 0.10567

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.34283
Value Function Update Magnitude: 0.61468

Collected Steps per Second: 20,577.80115
Overall Steps per Second: 9,752.76676

Timestep Collection Time: 2.43048
Timestep Consumption Time: 2.69770
PPO Batch Consumption Time: 0.31969
Total Iteration Time: 5.12819

Cumulative Model Updates: 18,768
Cumulative Timesteps: 156,607,508

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,224.81951
Policy Entropy: 1.07040
Value Function Loss: 0.10379

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.07051
Policy Update Magnitude: 0.37124
Value Function Update Magnitude: 0.59618

Collected Steps per Second: 21,551.06874
Overall Steps per Second: 10,139.99134

Timestep Collection Time: 2.32156
Timestep Consumption Time: 2.61257
PPO Batch Consumption Time: 0.30460
Total Iteration Time: 4.93413

Cumulative Model Updates: 18,774
Cumulative Timesteps: 156,657,540

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 156657540...
Checkpoint 156657540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,307.39042
Policy Entropy: 1.08188
Value Function Loss: 0.10012

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06605
Policy Update Magnitude: 0.37642
Value Function Update Magnitude: 0.63733

Collected Steps per Second: 20,741.84971
Overall Steps per Second: 9,789.23959

Timestep Collection Time: 2.41184
Timestep Consumption Time: 2.69847
PPO Batch Consumption Time: 0.32006
Total Iteration Time: 5.11031

Cumulative Model Updates: 18,780
Cumulative Timesteps: 156,707,566

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197.96384
Policy Entropy: 1.07376
Value Function Loss: 0.09942

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06813
Policy Update Magnitude: 0.38396
Value Function Update Magnitude: 0.68017

Collected Steps per Second: 21,077.97790
Overall Steps per Second: 10,050.56495

Timestep Collection Time: 2.37252
Timestep Consumption Time: 2.60312
PPO Batch Consumption Time: 0.30264
Total Iteration Time: 4.97564

Cumulative Model Updates: 18,786
Cumulative Timesteps: 156,757,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 156757574...
Checkpoint 156757574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,948.55025
Policy Entropy: 1.06669
Value Function Loss: 0.10054

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07867
Policy Update Magnitude: 0.38515
Value Function Update Magnitude: 0.65391

Collected Steps per Second: 21,159.50805
Overall Steps per Second: 10,027.08958

Timestep Collection Time: 2.36395
Timestep Consumption Time: 2.62454
PPO Batch Consumption Time: 0.31243
Total Iteration Time: 4.98849

Cumulative Model Updates: 18,792
Cumulative Timesteps: 156,807,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,649.72736
Policy Entropy: 1.05656
Value Function Loss: 0.10060

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.35968
Value Function Update Magnitude: 0.64465

Collected Steps per Second: 21,151.28586
Overall Steps per Second: 9,964.84316

Timestep Collection Time: 2.36496
Timestep Consumption Time: 2.65489
PPO Batch Consumption Time: 0.31602
Total Iteration Time: 5.01985

Cumulative Model Updates: 18,798
Cumulative Timesteps: 156,857,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 156857616...
Checkpoint 156857616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,156.78396
Policy Entropy: 1.04928
Value Function Loss: 0.10017

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.32231
Value Function Update Magnitude: 0.61247

Collected Steps per Second: 20,660.48105
Overall Steps per Second: 9,986.64560

Timestep Collection Time: 2.42076
Timestep Consumption Time: 2.58733
PPO Batch Consumption Time: 0.30645
Total Iteration Time: 5.00809

Cumulative Model Updates: 18,804
Cumulative Timesteps: 156,907,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,056.27736
Policy Entropy: 1.05269
Value Function Loss: 0.10020

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10968
Policy Update Magnitude: 0.31293
Value Function Update Magnitude: 0.53395

Collected Steps per Second: 21,124.96654
Overall Steps per Second: 10,227.11690

Timestep Collection Time: 2.36819
Timestep Consumption Time: 2.52351
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.89170

Cumulative Model Updates: 18,810
Cumulative Timesteps: 156,957,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 156957658...
Checkpoint 156957658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,355.99235
Policy Entropy: 1.06275
Value Function Loss: 0.10094

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12190
Policy Update Magnitude: 0.30472
Value Function Update Magnitude: 0.60090

Collected Steps per Second: 21,616.21033
Overall Steps per Second: 10,090.85949

Timestep Collection Time: 2.31428
Timestep Consumption Time: 2.64327
PPO Batch Consumption Time: 0.30990
Total Iteration Time: 4.95756

Cumulative Model Updates: 18,816
Cumulative Timesteps: 157,007,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,359.50633
Policy Entropy: 1.06433
Value Function Loss: 0.09907

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.29757
Value Function Update Magnitude: 0.64813

Collected Steps per Second: 21,041.00826
Overall Steps per Second: 10,136.52285

Timestep Collection Time: 2.37707
Timestep Consumption Time: 2.55716
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.93424

Cumulative Model Updates: 18,822
Cumulative Timesteps: 157,057,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 157057700...
Checkpoint 157057700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,431.41426
Policy Entropy: 1.05814
Value Function Loss: 0.09851

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12081
Policy Update Magnitude: 0.29896
Value Function Update Magnitude: 0.61008

Collected Steps per Second: 21,457.77700
Overall Steps per Second: 10,192.26173

Timestep Collection Time: 2.33016
Timestep Consumption Time: 2.57553
PPO Batch Consumption Time: 0.30358
Total Iteration Time: 4.90568

Cumulative Model Updates: 18,828
Cumulative Timesteps: 157,107,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,193.40391
Policy Entropy: 1.06070
Value Function Loss: 0.09761

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.29930
Value Function Update Magnitude: 0.57047

Collected Steps per Second: 21,342.09351
Overall Steps per Second: 10,100.23568

Timestep Collection Time: 2.34382
Timestep Consumption Time: 2.60874
PPO Batch Consumption Time: 0.30847
Total Iteration Time: 4.95256

Cumulative Model Updates: 18,834
Cumulative Timesteps: 157,157,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 157157722...
Checkpoint 157157722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,598.51210
Policy Entropy: 1.05634
Value Function Loss: 0.09917

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.33059
Value Function Update Magnitude: 0.66356

Collected Steps per Second: 21,348.38493
Overall Steps per Second: 10,196.67848

Timestep Collection Time: 2.34238
Timestep Consumption Time: 2.56177
PPO Batch Consumption Time: 0.30268
Total Iteration Time: 4.90415

Cumulative Model Updates: 18,840
Cumulative Timesteps: 157,207,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,380.78186
Policy Entropy: 1.05756
Value Function Loss: 0.09611

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07633
Policy Update Magnitude: 0.35378
Value Function Update Magnitude: 0.72249

Collected Steps per Second: 21,405.62125
Overall Steps per Second: 10,086.26023

Timestep Collection Time: 2.33714
Timestep Consumption Time: 2.62287
PPO Batch Consumption Time: 0.30830
Total Iteration Time: 4.96001

Cumulative Model Updates: 18,846
Cumulative Timesteps: 157,257,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 157257756...
Checkpoint 157257756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.05352
Policy Entropy: 1.05735
Value Function Loss: 0.09875

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07364
Policy Update Magnitude: 0.36360
Value Function Update Magnitude: 0.63443

Collected Steps per Second: 21,142.05936
Overall Steps per Second: 10,167.29803

Timestep Collection Time: 2.36505
Timestep Consumption Time: 2.55288
PPO Batch Consumption Time: 0.30130
Total Iteration Time: 4.91792

Cumulative Model Updates: 18,852
Cumulative Timesteps: 157,307,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,192.17435
Policy Entropy: 1.06475
Value Function Loss: 0.09657

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.35853
Value Function Update Magnitude: 0.68212

Collected Steps per Second: 21,626.30038
Overall Steps per Second: 10,337.62190

Timestep Collection Time: 2.31385
Timestep Consumption Time: 2.52672
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.84057

Cumulative Model Updates: 18,858
Cumulative Timesteps: 157,357,798

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 157357798...
Checkpoint 157357798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,473.27087
Policy Entropy: 1.06655
Value Function Loss: 0.09503

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10743
Policy Update Magnitude: 0.33287
Value Function Update Magnitude: 0.62340

Collected Steps per Second: 21,276.47897
Overall Steps per Second: 10,337.58538

Timestep Collection Time: 2.35039
Timestep Consumption Time: 2.48710
PPO Batch Consumption Time: 0.30345
Total Iteration Time: 4.83749

Cumulative Model Updates: 18,864
Cumulative Timesteps: 157,407,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,546.72341
Policy Entropy: 1.06196
Value Function Loss: 0.09280

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.33776
Value Function Update Magnitude: 0.59045

Collected Steps per Second: 21,064.15324
Overall Steps per Second: 10,089.92954

Timestep Collection Time: 2.37484
Timestep Consumption Time: 2.58297
PPO Batch Consumption Time: 0.30707
Total Iteration Time: 4.95781

Cumulative Model Updates: 18,870
Cumulative Timesteps: 157,457,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 157457830...
Checkpoint 157457830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,987.90993
Policy Entropy: 1.04836
Value Function Loss: 0.09212

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.34965
Value Function Update Magnitude: 0.69269

Collected Steps per Second: 20,800.13566
Overall Steps per Second: 9,951.74440

Timestep Collection Time: 2.40604
Timestep Consumption Time: 2.62283
PPO Batch Consumption Time: 0.30743
Total Iteration Time: 5.02887

Cumulative Model Updates: 18,876
Cumulative Timesteps: 157,507,876

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,870.42308
Policy Entropy: 1.04291
Value Function Loss: 0.09655

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.35918
Value Function Update Magnitude: 0.64113

Collected Steps per Second: 21,107.56177
Overall Steps per Second: 9,868.24533

Timestep Collection Time: 2.37005
Timestep Consumption Time: 2.69934
PPO Batch Consumption Time: 0.31733
Total Iteration Time: 5.06939

Cumulative Model Updates: 18,882
Cumulative Timesteps: 157,557,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 157557902...
Checkpoint 157557902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,628.95561
Policy Entropy: 1.03981
Value Function Loss: 0.09850

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.35926
Value Function Update Magnitude: 0.61497

Collected Steps per Second: 21,310.89156
Overall Steps per Second: 10,265.12207

Timestep Collection Time: 2.34791
Timestep Consumption Time: 2.52646
PPO Batch Consumption Time: 0.30156
Total Iteration Time: 4.87437

Cumulative Model Updates: 18,888
Cumulative Timesteps: 157,607,938

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,552.37293
Policy Entropy: 1.05202
Value Function Loss: 0.09851

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.35770
Value Function Update Magnitude: 0.56572

Collected Steps per Second: 21,378.14145
Overall Steps per Second: 10,135.06019

Timestep Collection Time: 2.34015
Timestep Consumption Time: 2.59599
PPO Batch Consumption Time: 0.30267
Total Iteration Time: 4.93613

Cumulative Model Updates: 18,894
Cumulative Timesteps: 157,657,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 157657966...
Checkpoint 157657966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,294.79799
Policy Entropy: 1.05428
Value Function Loss: 0.09915

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07579
Policy Update Magnitude: 0.36339
Value Function Update Magnitude: 0.53280

Collected Steps per Second: 21,298.44439
Overall Steps per Second: 10,085.56026

Timestep Collection Time: 2.34778
Timestep Consumption Time: 2.61020
PPO Batch Consumption Time: 0.30778
Total Iteration Time: 4.95798

Cumulative Model Updates: 18,900
Cumulative Timesteps: 157,707,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,928.67814
Policy Entropy: 1.04372
Value Function Loss: 0.09987

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.35571
Value Function Update Magnitude: 0.56644

Collected Steps per Second: 21,198.70808
Overall Steps per Second: 10,057.77225

Timestep Collection Time: 2.35863
Timestep Consumption Time: 2.61265
PPO Batch Consumption Time: 0.30778
Total Iteration Time: 4.97128

Cumulative Model Updates: 18,906
Cumulative Timesteps: 157,757,970

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 157757970...
Checkpoint 157757970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,801.19444
Policy Entropy: 1.03587
Value Function Loss: 0.09730

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07628
Policy Update Magnitude: 0.34893
Value Function Update Magnitude: 0.56068

Collected Steps per Second: 21,322.24620
Overall Steps per Second: 10,134.12393

Timestep Collection Time: 2.34516
Timestep Consumption Time: 2.58906
PPO Batch Consumption Time: 0.30867
Total Iteration Time: 4.93422

Cumulative Model Updates: 18,912
Cumulative Timesteps: 157,807,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,838.49263
Policy Entropy: 1.03713
Value Function Loss: 0.09739

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07787
Policy Update Magnitude: 0.35995
Value Function Update Magnitude: 0.57449

Collected Steps per Second: 21,508.14896
Overall Steps per Second: 10,142.61082

Timestep Collection Time: 2.32535
Timestep Consumption Time: 2.60573
PPO Batch Consumption Time: 0.30615
Total Iteration Time: 4.93108

Cumulative Model Updates: 18,918
Cumulative Timesteps: 157,857,988

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 157857988...
Checkpoint 157857988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,389.55955
Policy Entropy: 1.04988
Value Function Loss: 0.09357

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07998
Policy Update Magnitude: 0.35855
Value Function Update Magnitude: 0.56976

Collected Steps per Second: 21,273.11343
Overall Steps per Second: 10,059.41173

Timestep Collection Time: 2.35048
Timestep Consumption Time: 2.62019
PPO Batch Consumption Time: 0.30472
Total Iteration Time: 4.97067

Cumulative Model Updates: 18,924
Cumulative Timesteps: 157,907,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,343.26318
Policy Entropy: 1.04476
Value Function Loss: 0.09397

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08872
Policy Update Magnitude: 0.35064
Value Function Update Magnitude: 0.59055

Collected Steps per Second: 21,689.44628
Overall Steps per Second: 10,288.98143

Timestep Collection Time: 2.30591
Timestep Consumption Time: 2.55501
PPO Batch Consumption Time: 0.30174
Total Iteration Time: 4.86093

Cumulative Model Updates: 18,930
Cumulative Timesteps: 157,958,004

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 157958004...
Checkpoint 157958004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,313.76137
Policy Entropy: 1.04581
Value Function Loss: 0.09713

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13106
Policy Update Magnitude: 0.30471
Value Function Update Magnitude: 0.69901

Collected Steps per Second: 20,982.52038
Overall Steps per Second: 9,963.53346

Timestep Collection Time: 2.38322
Timestep Consumption Time: 2.63568
PPO Batch Consumption Time: 0.31210
Total Iteration Time: 5.01890

Cumulative Model Updates: 18,936
Cumulative Timesteps: 158,008,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,913.70284
Policy Entropy: 1.03084
Value Function Loss: 0.09798

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12332
Policy Update Magnitude: 0.28434
Value Function Update Magnitude: 0.69938

Collected Steps per Second: 21,488.85864
Overall Steps per Second: 10,090.33299

Timestep Collection Time: 2.32725
Timestep Consumption Time: 2.62898
PPO Batch Consumption Time: 0.31476
Total Iteration Time: 4.95623

Cumulative Model Updates: 18,942
Cumulative Timesteps: 158,058,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 158058020...
Checkpoint 158058020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,925.10024
Policy Entropy: 1.03590
Value Function Loss: 0.09749

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.26914
Value Function Update Magnitude: 0.61340

Collected Steps per Second: 21,414.45647
Overall Steps per Second: 10,368.46055

Timestep Collection Time: 2.33683
Timestep Consumption Time: 2.48953
PPO Batch Consumption Time: 0.30128
Total Iteration Time: 4.82637

Cumulative Model Updates: 18,948
Cumulative Timesteps: 158,108,062

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,504.83333
Policy Entropy: 1.03776
Value Function Loss: 0.09450

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.27276
Value Function Update Magnitude: 0.67467

Collected Steps per Second: 21,520.87537
Overall Steps per Second: 10,065.48078

Timestep Collection Time: 2.32370
Timestep Consumption Time: 2.64457
PPO Batch Consumption Time: 0.31376
Total Iteration Time: 4.96827

Cumulative Model Updates: 18,954
Cumulative Timesteps: 158,158,070

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 158158070...
Checkpoint 158158070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,309.45879
Policy Entropy: 1.04146
Value Function Loss: 0.09316

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11757
Policy Update Magnitude: 0.27874
Value Function Update Magnitude: 0.74149

Collected Steps per Second: 20,778.82576
Overall Steps per Second: 9,804.44749

Timestep Collection Time: 2.40658
Timestep Consumption Time: 2.69375
PPO Batch Consumption Time: 0.32446
Total Iteration Time: 5.10034

Cumulative Model Updates: 18,960
Cumulative Timesteps: 158,208,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567.84756
Policy Entropy: 1.03639
Value Function Loss: 0.09631

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.27825
Value Function Update Magnitude: 0.74941

Collected Steps per Second: 21,286.36728
Overall Steps per Second: 10,112.17444

Timestep Collection Time: 2.34920
Timestep Consumption Time: 2.59593
PPO Batch Consumption Time: 0.30678
Total Iteration Time: 4.94513

Cumulative Model Updates: 18,966
Cumulative Timesteps: 158,258,082

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 158258082...
Checkpoint 158258082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.88819
Policy Entropy: 1.03489
Value Function Loss: 0.09535

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.26388
Value Function Update Magnitude: 0.72783

Collected Steps per Second: 20,581.26943
Overall Steps per Second: 9,953.47602

Timestep Collection Time: 2.43017
Timestep Consumption Time: 2.59481
PPO Batch Consumption Time: 0.31036
Total Iteration Time: 5.02498

Cumulative Model Updates: 18,972
Cumulative Timesteps: 158,308,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,245.87705
Policy Entropy: 1.03501
Value Function Loss: 0.09976

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.30009
Value Function Update Magnitude: 0.60319

Collected Steps per Second: 21,696.51419
Overall Steps per Second: 10,365.10189

Timestep Collection Time: 2.30526
Timestep Consumption Time: 2.52017
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.82542

Cumulative Model Updates: 18,978
Cumulative Timesteps: 158,358,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 158358114...
Checkpoint 158358114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,543.89686
Policy Entropy: 1.05048
Value Function Loss: 0.09662

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08873
Policy Update Magnitude: 0.34033
Value Function Update Magnitude: 0.53749

Collected Steps per Second: 21,266.89946
Overall Steps per Second: 10,158.05413

Timestep Collection Time: 2.35229
Timestep Consumption Time: 2.57247
PPO Batch Consumption Time: 0.29846
Total Iteration Time: 4.92476

Cumulative Model Updates: 18,984
Cumulative Timesteps: 158,408,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,172.99927
Policy Entropy: 1.05517
Value Function Loss: 0.10128

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.12042
Policy Update Magnitude: 0.31381
Value Function Update Magnitude: 0.56771

Collected Steps per Second: 21,519.07201
Overall Steps per Second: 10,161.92266

Timestep Collection Time: 2.32473
Timestep Consumption Time: 2.59816
PPO Batch Consumption Time: 0.31073
Total Iteration Time: 4.92289

Cumulative Model Updates: 18,990
Cumulative Timesteps: 158,458,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 158458166...
Checkpoint 158458166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,833.27790
Policy Entropy: 1.05513
Value Function Loss: 0.09885

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.29473
Value Function Update Magnitude: 0.63058

Collected Steps per Second: 21,245.26939
Overall Steps per Second: 10,227.06576

Timestep Collection Time: 2.35469
Timestep Consumption Time: 2.53684
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 4.89153

Cumulative Model Updates: 18,996
Cumulative Timesteps: 158,508,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.67727
Policy Entropy: 1.05219
Value Function Loss: 0.10080

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11869
Policy Update Magnitude: 0.28983
Value Function Update Magnitude: 0.57780

Collected Steps per Second: 21,190.93962
Overall Steps per Second: 10,155.16489

Timestep Collection Time: 2.35978
Timestep Consumption Time: 2.56441
PPO Batch Consumption Time: 0.30354
Total Iteration Time: 4.92419

Cumulative Model Updates: 19,002
Cumulative Timesteps: 158,558,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 158558198...
Checkpoint 158558198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,989.13845
Policy Entropy: 1.05616
Value Function Loss: 0.09760

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.29462
Value Function Update Magnitude: 0.55035

Collected Steps per Second: 21,120.03517
Overall Steps per Second: 10,082.70622

Timestep Collection Time: 2.36742
Timestep Consumption Time: 2.59157
PPO Batch Consumption Time: 0.30927
Total Iteration Time: 4.95899

Cumulative Model Updates: 19,008
Cumulative Timesteps: 158,608,198

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,061.78050
Policy Entropy: 1.05441
Value Function Loss: 0.09619

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.30490
Value Function Update Magnitude: 0.64077

Collected Steps per Second: 21,478.94387
Overall Steps per Second: 10,126.47589

Timestep Collection Time: 2.32916
Timestep Consumption Time: 2.61115
PPO Batch Consumption Time: 0.30697
Total Iteration Time: 4.94032

Cumulative Model Updates: 19,014
Cumulative Timesteps: 158,658,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 158658226...
Checkpoint 158658226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,537.88197
Policy Entropy: 1.05354
Value Function Loss: 0.10383

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12650
Policy Update Magnitude: 0.30770
Value Function Update Magnitude: 0.60466

Collected Steps per Second: 20,965.41570
Overall Steps per Second: 10,128.66400

Timestep Collection Time: 2.38631
Timestep Consumption Time: 2.55314
PPO Batch Consumption Time: 0.30078
Total Iteration Time: 4.93945

Cumulative Model Updates: 19,020
Cumulative Timesteps: 158,708,256

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719.65312
Policy Entropy: 1.04859
Value Function Loss: 0.10577

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.12834
Policy Update Magnitude: 0.31543
Value Function Update Magnitude: 0.55348

Collected Steps per Second: 20,952.08222
Overall Steps per Second: 9,867.41823

Timestep Collection Time: 2.38783
Timestep Consumption Time: 2.68239
PPO Batch Consumption Time: 0.32295
Total Iteration Time: 5.07022

Cumulative Model Updates: 19,026
Cumulative Timesteps: 158,758,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 158758286...
Checkpoint 158758286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,109.95743
Policy Entropy: 1.03624
Value Function Loss: 0.10352

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.34429
Value Function Update Magnitude: 0.53135

Collected Steps per Second: 21,054.45231
Overall Steps per Second: 10,127.92408

Timestep Collection Time: 2.37498
Timestep Consumption Time: 2.56226
PPO Batch Consumption Time: 0.31367
Total Iteration Time: 4.93724

Cumulative Model Updates: 19,032
Cumulative Timesteps: 158,808,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,415.73191
Policy Entropy: 1.04089
Value Function Loss: 0.10071

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08910
Policy Update Magnitude: 0.35745
Value Function Update Magnitude: 0.52898

Collected Steps per Second: 20,915.66513
Overall Steps per Second: 10,050.43809

Timestep Collection Time: 2.39094
Timestep Consumption Time: 2.58477
PPO Batch Consumption Time: 0.30544
Total Iteration Time: 4.97570

Cumulative Model Updates: 19,038
Cumulative Timesteps: 158,858,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 158858298...
Checkpoint 158858298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,559.48590
Policy Entropy: 1.03984
Value Function Loss: 0.09929

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.35325
Value Function Update Magnitude: 0.52870

Collected Steps per Second: 20,619.76243
Overall Steps per Second: 9,957.73003

Timestep Collection Time: 2.42486
Timestep Consumption Time: 2.59637
PPO Batch Consumption Time: 0.30416
Total Iteration Time: 5.02122

Cumulative Model Updates: 19,044
Cumulative Timesteps: 158,908,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,110.34348
Policy Entropy: 1.04745
Value Function Loss: 0.09727

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.35347
Value Function Update Magnitude: 0.63383

Collected Steps per Second: 21,512.53415
Overall Steps per Second: 10,109.38856

Timestep Collection Time: 2.32516
Timestep Consumption Time: 2.62272
PPO Batch Consumption Time: 0.30989
Total Iteration Time: 4.94788

Cumulative Model Updates: 19,050
Cumulative Timesteps: 158,958,318

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 158958318...
Checkpoint 158958318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,210.20628
Policy Entropy: 1.04247
Value Function Loss: 0.09518

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07464
Policy Update Magnitude: 0.35225
Value Function Update Magnitude: 0.73454

Collected Steps per Second: 21,075.45945
Overall Steps per Second: 9,981.03615

Timestep Collection Time: 2.37309
Timestep Consumption Time: 2.63781
PPO Batch Consumption Time: 0.30641
Total Iteration Time: 5.01090

Cumulative Model Updates: 19,056
Cumulative Timesteps: 159,008,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,409.74862
Policy Entropy: 1.04739
Value Function Loss: 0.09704

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07576
Policy Update Magnitude: 0.35683
Value Function Update Magnitude: 0.69102

Collected Steps per Second: 21,220.06056
Overall Steps per Second: 10,127.47858

Timestep Collection Time: 2.35692
Timestep Consumption Time: 2.58152
PPO Batch Consumption Time: 0.30513
Total Iteration Time: 4.93845

Cumulative Model Updates: 19,062
Cumulative Timesteps: 159,058,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 159058346...
Checkpoint 159058346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,643.71348
Policy Entropy: 1.04238
Value Function Loss: 0.09601

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.36022
Value Function Update Magnitude: 0.73010

Collected Steps per Second: 20,848.00192
Overall Steps per Second: 9,915.58427

Timestep Collection Time: 2.39841
Timestep Consumption Time: 2.64436
PPO Batch Consumption Time: 0.31819
Total Iteration Time: 5.04277

Cumulative Model Updates: 19,068
Cumulative Timesteps: 159,108,348

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,072.29528
Policy Entropy: 1.05176
Value Function Loss: 0.09225

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08669
Policy Update Magnitude: 0.35332
Value Function Update Magnitude: 0.68302

Collected Steps per Second: 21,176.02725
Overall Steps per Second: 9,984.48018

Timestep Collection Time: 2.36229
Timestep Consumption Time: 2.64788
PPO Batch Consumption Time: 0.31822
Total Iteration Time: 5.01018

Cumulative Model Updates: 19,074
Cumulative Timesteps: 159,158,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 159158372...
Checkpoint 159158372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,108.16137
Policy Entropy: 1.05412
Value Function Loss: 0.08920

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07511
Policy Update Magnitude: 0.35527
Value Function Update Magnitude: 0.62244

Collected Steps per Second: 21,103.79223
Overall Steps per Second: 10,166.85728

Timestep Collection Time: 2.36934
Timestep Consumption Time: 2.54880
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.91814

Cumulative Model Updates: 19,080
Cumulative Timesteps: 159,208,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,695.63692
Policy Entropy: 1.05824
Value Function Loss: 0.08879

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08230
Policy Update Magnitude: 0.35995
Value Function Update Magnitude: 0.56996

Collected Steps per Second: 21,577.56420
Overall Steps per Second: 10,208.50004

Timestep Collection Time: 2.31722
Timestep Consumption Time: 2.58066
PPO Batch Consumption Time: 0.30836
Total Iteration Time: 4.89788

Cumulative Model Updates: 19,086
Cumulative Timesteps: 159,258,374

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 159258374...
Checkpoint 159258374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,443.27913
Policy Entropy: 1.05978
Value Function Loss: 0.09473

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.35347
Value Function Update Magnitude: 0.55175

Collected Steps per Second: 20,985.95104
Overall Steps per Second: 9,989.41761

Timestep Collection Time: 2.38255
Timestep Consumption Time: 2.62275
PPO Batch Consumption Time: 0.31189
Total Iteration Time: 5.00530

Cumulative Model Updates: 19,092
Cumulative Timesteps: 159,308,374

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852.50099
Policy Entropy: 1.05722
Value Function Loss: 0.10406

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.12005
Policy Update Magnitude: 0.34388
Value Function Update Magnitude: 0.58407

Collected Steps per Second: 21,375.20819
Overall Steps per Second: 10,071.87668

Timestep Collection Time: 2.34028
Timestep Consumption Time: 2.62642
PPO Batch Consumption Time: 0.31046
Total Iteration Time: 4.96670

Cumulative Model Updates: 19,098
Cumulative Timesteps: 159,358,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 159358398...
Checkpoint 159358398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,812.34299
Policy Entropy: 1.05533
Value Function Loss: 0.10444

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.33991
Value Function Update Magnitude: 0.54374

Collected Steps per Second: 20,802.49893
Overall Steps per Second: 9,838.23800

Timestep Collection Time: 2.40404
Timestep Consumption Time: 2.67919
PPO Batch Consumption Time: 0.32460
Total Iteration Time: 5.08323

Cumulative Model Updates: 19,104
Cumulative Timesteps: 159,408,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,379.71775
Policy Entropy: 1.05380
Value Function Loss: 0.10064

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.33689
Value Function Update Magnitude: 0.62298

Collected Steps per Second: 21,269.36549
Overall Steps per Second: 10,128.19860

Timestep Collection Time: 2.35212
Timestep Consumption Time: 2.58736
PPO Batch Consumption Time: 0.30669
Total Iteration Time: 4.93948

Cumulative Model Updates: 19,110
Cumulative Timesteps: 159,458,436

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 159458436...
Checkpoint 159458436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,196.97671
Policy Entropy: 1.05988
Value Function Loss: 0.09539

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.34528
Value Function Update Magnitude: 0.60566

Collected Steps per Second: 20,285.50249
Overall Steps per Second: 9,820.98777

Timestep Collection Time: 2.46570
Timestep Consumption Time: 2.62727
PPO Batch Consumption Time: 0.31539
Total Iteration Time: 5.09297

Cumulative Model Updates: 19,116
Cumulative Timesteps: 159,508,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579.74372
Policy Entropy: 1.05874
Value Function Loss: 0.09836

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.34987
Value Function Update Magnitude: 0.54856

Collected Steps per Second: 21,760.82148
Overall Steps per Second: 10,171.04920

Timestep Collection Time: 2.29798
Timestep Consumption Time: 2.61852
PPO Batch Consumption Time: 0.31013
Total Iteration Time: 4.91650

Cumulative Model Updates: 19,122
Cumulative Timesteps: 159,558,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 159558460...
Checkpoint 159558460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.39998
Policy Entropy: 1.05421
Value Function Loss: 0.09934

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.34962
Value Function Update Magnitude: 0.59850

Collected Steps per Second: 21,112.02371
Overall Steps per Second: 10,234.87175

Timestep Collection Time: 2.36955
Timestep Consumption Time: 2.51825
PPO Batch Consumption Time: 0.30799
Total Iteration Time: 4.88780

Cumulative Model Updates: 19,128
Cumulative Timesteps: 159,608,486

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,337.22841
Policy Entropy: 1.04612
Value Function Loss: 0.09822

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.34441
Value Function Update Magnitude: 0.55876

Collected Steps per Second: 21,123.56852
Overall Steps per Second: 10,023.84794

Timestep Collection Time: 2.36702
Timestep Consumption Time: 2.62108
PPO Batch Consumption Time: 0.30821
Total Iteration Time: 4.98810

Cumulative Model Updates: 19,134
Cumulative Timesteps: 159,658,486

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 159658486...
Checkpoint 159658486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,783.96106
Policy Entropy: 1.06027
Value Function Loss: 0.09807

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10191
Policy Update Magnitude: 0.34358
Value Function Update Magnitude: 0.53896

Collected Steps per Second: 21,010.30558
Overall Steps per Second: 9,935.38149

Timestep Collection Time: 2.38112
Timestep Consumption Time: 2.65422
PPO Batch Consumption Time: 0.31235
Total Iteration Time: 5.03534

Cumulative Model Updates: 19,140
Cumulative Timesteps: 159,708,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,165.71188
Policy Entropy: 1.06460
Value Function Loss: 0.09947

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.33451
Value Function Update Magnitude: 0.62986

Collected Steps per Second: 21,202.01738
Overall Steps per Second: 10,048.82024

Timestep Collection Time: 2.35902
Timestep Consumption Time: 2.61828
PPO Batch Consumption Time: 0.30995
Total Iteration Time: 4.97730

Cumulative Model Updates: 19,146
Cumulative Timesteps: 159,758,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 159758530...
Checkpoint 159758530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,487.52393
Policy Entropy: 1.06085
Value Function Loss: 0.09845

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.28750
Value Function Update Magnitude: 0.56369

Collected Steps per Second: 20,969.04130
Overall Steps per Second: 9,927.12423

Timestep Collection Time: 2.38590
Timestep Consumption Time: 2.65383
PPO Batch Consumption Time: 0.31482
Total Iteration Time: 5.03973

Cumulative Model Updates: 19,152
Cumulative Timesteps: 159,808,560

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,248.34501
Policy Entropy: 1.06941
Value Function Loss: 0.09646

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.27549
Value Function Update Magnitude: 0.50502

Collected Steps per Second: 21,090.28448
Overall Steps per Second: 10,009.49644

Timestep Collection Time: 2.37180
Timestep Consumption Time: 2.62565
PPO Batch Consumption Time: 0.31640
Total Iteration Time: 4.99745

Cumulative Model Updates: 19,158
Cumulative Timesteps: 159,858,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 159858582...
Checkpoint 159858582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,833.96637
Policy Entropy: 1.06968
Value Function Loss: 0.10081

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.29386
Value Function Update Magnitude: 0.51408

Collected Steps per Second: 21,322.61809
Overall Steps per Second: 10,199.33684

Timestep Collection Time: 2.34502
Timestep Consumption Time: 2.55745
PPO Batch Consumption Time: 0.31123
Total Iteration Time: 4.90248

Cumulative Model Updates: 19,164
Cumulative Timesteps: 159,908,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,006.63999
Policy Entropy: 1.07104
Value Function Loss: 0.09814

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.31179
Value Function Update Magnitude: 0.52780

Collected Steps per Second: 21,091.43028
Overall Steps per Second: 9,914.47875

Timestep Collection Time: 2.37148
Timestep Consumption Time: 2.67346
PPO Batch Consumption Time: 0.32160
Total Iteration Time: 5.04494

Cumulative Model Updates: 19,170
Cumulative Timesteps: 159,958,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 159958602...
Checkpoint 159958602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,289.29837
Policy Entropy: 1.06995
Value Function Loss: 0.10503

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.31526
Value Function Update Magnitude: 0.57364

Collected Steps per Second: 21,268.58541
Overall Steps per Second: 10,306.90359

Timestep Collection Time: 2.35201
Timestep Consumption Time: 2.50143
PPO Batch Consumption Time: 0.30361
Total Iteration Time: 4.85345

Cumulative Model Updates: 19,176
Cumulative Timesteps: 160,008,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,996.60225
Policy Entropy: 1.07952
Value Function Loss: 0.10170

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.32993
Value Function Update Magnitude: 0.55014

Collected Steps per Second: 20,116.39264
Overall Steps per Second: 9,804.53945

Timestep Collection Time: 2.48554
Timestep Consumption Time: 2.61414
PPO Batch Consumption Time: 0.31107
Total Iteration Time: 5.09968

Cumulative Model Updates: 19,182
Cumulative Timesteps: 160,058,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 160058626...
Checkpoint 160058626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,002.66616
Policy Entropy: 1.08309
Value Function Loss: 0.10476

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 0.34651
Value Function Update Magnitude: 0.54719

Collected Steps per Second: 20,908.20037
Overall Steps per Second: 9,968.90022

Timestep Collection Time: 2.39141
Timestep Consumption Time: 2.62419
PPO Batch Consumption Time: 0.31276
Total Iteration Time: 5.01560

Cumulative Model Updates: 19,188
Cumulative Timesteps: 160,108,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,790.89486
Policy Entropy: 1.09209
Value Function Loss: 0.09901

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.36167
Value Function Update Magnitude: 0.61688

Collected Steps per Second: 21,531.39368
Overall Steps per Second: 10,062.43783

Timestep Collection Time: 2.32219
Timestep Consumption Time: 2.64678
PPO Batch Consumption Time: 0.31614
Total Iteration Time: 4.96897

Cumulative Model Updates: 19,194
Cumulative Timesteps: 160,158,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 160158626...
Checkpoint 160158626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,429.95475
Policy Entropy: 1.08074
Value Function Loss: 0.09757

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.35513
Value Function Update Magnitude: 0.72657

Collected Steps per Second: 21,013.69571
Overall Steps per Second: 10,037.68688

Timestep Collection Time: 2.38016
Timestep Consumption Time: 2.60266
PPO Batch Consumption Time: 0.30938
Total Iteration Time: 4.98282

Cumulative Model Updates: 19,200
Cumulative Timesteps: 160,208,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,479.06458
Policy Entropy: 1.08125
Value Function Loss: 0.09249

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08049
Policy Update Magnitude: 0.35118
Value Function Update Magnitude: 0.76630

Collected Steps per Second: 21,258.78902
Overall Steps per Second: 10,139.58991

Timestep Collection Time: 2.35197
Timestep Consumption Time: 2.57920
PPO Batch Consumption Time: 0.30586
Total Iteration Time: 4.93117

Cumulative Model Updates: 19,206
Cumulative Timesteps: 160,258,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 160258642...
Checkpoint 160258642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,392.54197
Policy Entropy: 1.07675
Value Function Loss: 0.09810

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.35604
Value Function Update Magnitude: 0.78892

Collected Steps per Second: 21,218.71500
Overall Steps per Second: 10,282.62819

Timestep Collection Time: 2.35764
Timestep Consumption Time: 2.50746
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.86510

Cumulative Model Updates: 19,212
Cumulative Timesteps: 160,308,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,686.43056
Policy Entropy: 1.07762
Value Function Loss: 0.09529

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.32284
Value Function Update Magnitude: 0.80346

Collected Steps per Second: 21,340.32974
Overall Steps per Second: 10,125.18544

Timestep Collection Time: 2.34345
Timestep Consumption Time: 2.59572
PPO Batch Consumption Time: 0.30776
Total Iteration Time: 4.93917

Cumulative Model Updates: 19,218
Cumulative Timesteps: 160,358,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 160358678...
Checkpoint 160358678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,435.15823
Policy Entropy: 1.08589
Value Function Loss: 0.10097

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.15000
Policy Update Magnitude: 0.29158
Value Function Update Magnitude: 0.75614

Collected Steps per Second: 21,372.71384
Overall Steps per Second: 10,290.13615

Timestep Collection Time: 2.33943
Timestep Consumption Time: 2.51959
PPO Batch Consumption Time: 0.30806
Total Iteration Time: 4.85902

Cumulative Model Updates: 19,224
Cumulative Timesteps: 160,408,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,778.38963
Policy Entropy: 1.09352
Value Function Loss: 0.09574

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.15000
Policy Update Magnitude: 0.28725
Value Function Update Magnitude: 0.75091

Collected Steps per Second: 20,900.93829
Overall Steps per Second: 10,102.35565

Timestep Collection Time: 2.39224
Timestep Consumption Time: 2.55710
PPO Batch Consumption Time: 0.30455
Total Iteration Time: 4.94934

Cumulative Model Updates: 19,230
Cumulative Timesteps: 160,458,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 160458678...
Checkpoint 160458678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,589.71457
Policy Entropy: 1.09570
Value Function Loss: 0.09395

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.14812
Policy Update Magnitude: 0.27833
Value Function Update Magnitude: 0.78484

Collected Steps per Second: 21,353.73636
Overall Steps per Second: 10,276.14705

Timestep Collection Time: 2.34198
Timestep Consumption Time: 2.52463
PPO Batch Consumption Time: 0.30770
Total Iteration Time: 4.86661

Cumulative Model Updates: 19,236
Cumulative Timesteps: 160,508,688

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,199.50595
Policy Entropy: 1.10681
Value Function Loss: 0.09280

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.16198
Policy Update Magnitude: 0.28155
Value Function Update Magnitude: 0.75005

Collected Steps per Second: 21,450.34072
Overall Steps per Second: 10,165.08264

Timestep Collection Time: 2.33264
Timestep Consumption Time: 2.58970
PPO Batch Consumption Time: 0.30086
Total Iteration Time: 4.92234

Cumulative Model Updates: 19,242
Cumulative Timesteps: 160,558,724

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 160558724...
Checkpoint 160558724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,021.72775
Policy Entropy: 1.10487
Value Function Loss: 0.09957

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.19208
Policy Update Magnitude: 0.28789
Value Function Update Magnitude: 0.66904

Collected Steps per Second: 21,345.03790
Overall Steps per Second: 10,227.93314

Timestep Collection Time: 2.34265
Timestep Consumption Time: 2.54631
PPO Batch Consumption Time: 0.29962
Total Iteration Time: 4.88896

Cumulative Model Updates: 19,248
Cumulative Timesteps: 160,608,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.88913
Policy Entropy: 1.09456
Value Function Loss: 0.10379

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.16703
Policy Update Magnitude: 0.29485
Value Function Update Magnitude: 0.53239

Collected Steps per Second: 20,632.71855
Overall Steps per Second: 9,784.86234

Timestep Collection Time: 2.42411
Timestep Consumption Time: 2.68746
PPO Batch Consumption Time: 0.31464
Total Iteration Time: 5.11157

Cumulative Model Updates: 19,254
Cumulative Timesteps: 160,658,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 160658744...
Checkpoint 160658744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,207.11511
Policy Entropy: 1.07857
Value Function Loss: 0.10625

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.29190
Value Function Update Magnitude: 0.53601

Collected Steps per Second: 20,990.75279
Overall Steps per Second: 9,950.65337

Timestep Collection Time: 2.38286
Timestep Consumption Time: 2.64375
PPO Batch Consumption Time: 0.30363
Total Iteration Time: 5.02660

Cumulative Model Updates: 19,260
Cumulative Timesteps: 160,708,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,587.98257
Policy Entropy: 1.07832
Value Function Loss: 0.10139

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.32218
Value Function Update Magnitude: 0.53777

Collected Steps per Second: 21,145.66027
Overall Steps per Second: 10,003.58051

Timestep Collection Time: 2.36493
Timestep Consumption Time: 2.63408
PPO Batch Consumption Time: 0.30563
Total Iteration Time: 4.99901

Cumulative Model Updates: 19,266
Cumulative Timesteps: 160,758,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 160758770...
Checkpoint 160758770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,508.42071
Policy Entropy: 1.07759
Value Function Loss: 0.09871

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.35906
Value Function Update Magnitude: 0.54639

Collected Steps per Second: 20,986.76661
Overall Steps per Second: 9,973.97159

Timestep Collection Time: 2.38303
Timestep Consumption Time: 2.63123
PPO Batch Consumption Time: 0.31673
Total Iteration Time: 5.01425

Cumulative Model Updates: 19,272
Cumulative Timesteps: 160,808,782

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,155.48759
Policy Entropy: 1.08403
Value Function Loss: 0.09476

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07411
Policy Update Magnitude: 0.36102
Value Function Update Magnitude: 0.51463

Collected Steps per Second: 21,336.83651
Overall Steps per Second: 9,925.22975

Timestep Collection Time: 2.34393
Timestep Consumption Time: 2.69495
PPO Batch Consumption Time: 0.32278
Total Iteration Time: 5.03888

Cumulative Model Updates: 19,278
Cumulative Timesteps: 160,858,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 160858794...
Checkpoint 160858794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,103.89884
Policy Entropy: 1.07885
Value Function Loss: 0.09434

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11615
Policy Update Magnitude: 0.34107
Value Function Update Magnitude: 0.50011

Collected Steps per Second: 21,212.72821
Overall Steps per Second: 10,310.47471

Timestep Collection Time: 2.35934
Timestep Consumption Time: 2.49475
PPO Batch Consumption Time: 0.30204
Total Iteration Time: 4.85409

Cumulative Model Updates: 19,284
Cumulative Timesteps: 160,908,842

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,020.08743
Policy Entropy: 1.07691
Value Function Loss: 0.09377

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.29463
Value Function Update Magnitude: 0.49306

Collected Steps per Second: 20,795.14915
Overall Steps per Second: 9,935.82089

Timestep Collection Time: 2.40479
Timestep Consumption Time: 2.62831
PPO Batch Consumption Time: 0.31289
Total Iteration Time: 5.03310

Cumulative Model Updates: 19,290
Cumulative Timesteps: 160,958,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 160958850...
Checkpoint 160958850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,312.15960
Policy Entropy: 1.07718
Value Function Loss: 0.09392

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11186
Policy Update Magnitude: 0.27988
Value Function Update Magnitude: 0.49895

Collected Steps per Second: 20,910.02369
Overall Steps per Second: 9,951.99083

Timestep Collection Time: 2.39225
Timestep Consumption Time: 2.63408
PPO Batch Consumption Time: 0.31559
Total Iteration Time: 5.02633

Cumulative Model Updates: 19,296
Cumulative Timesteps: 161,008,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,457.11282
Policy Entropy: 1.08607
Value Function Loss: 0.09605

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.29107
Value Function Update Magnitude: 0.50471

Collected Steps per Second: 21,244.34024
Overall Steps per Second: 10,128.00767

Timestep Collection Time: 2.35460
Timestep Consumption Time: 2.58437
PPO Batch Consumption Time: 0.30893
Total Iteration Time: 4.93898

Cumulative Model Updates: 19,302
Cumulative Timesteps: 161,058,894

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 161058894...
Checkpoint 161058894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,566.61887
Policy Entropy: 1.08575
Value Function Loss: 0.09675

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.31342
Value Function Update Magnitude: 0.51214

Collected Steps per Second: 20,530.45323
Overall Steps per Second: 9,942.36312

Timestep Collection Time: 2.43638
Timestep Consumption Time: 2.59462
PPO Batch Consumption Time: 0.30731
Total Iteration Time: 5.03100

Cumulative Model Updates: 19,308
Cumulative Timesteps: 161,108,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,530.62306
Policy Entropy: 1.08694
Value Function Loss: 0.09387

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.34914
Value Function Update Magnitude: 0.55314

Collected Steps per Second: 21,154.99360
Overall Steps per Second: 10,064.55793

Timestep Collection Time: 2.36360
Timestep Consumption Time: 2.60452
PPO Batch Consumption Time: 0.30996
Total Iteration Time: 4.96813

Cumulative Model Updates: 19,314
Cumulative Timesteps: 161,158,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 161158916...
Checkpoint 161158916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,840.46246
Policy Entropy: 1.08705
Value Function Loss: 0.09462

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.32610
Value Function Update Magnitude: 0.54430

Collected Steps per Second: 20,868.54763
Overall Steps per Second: 9,935.52930

Timestep Collection Time: 2.39681
Timestep Consumption Time: 2.63744
PPO Batch Consumption Time: 0.31697
Total Iteration Time: 5.03426

Cumulative Model Updates: 19,320
Cumulative Timesteps: 161,208,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,022.60765
Policy Entropy: 1.07648
Value Function Loss: 0.09977

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.30868
Value Function Update Magnitude: 0.53347

Collected Steps per Second: 21,343.91084
Overall Steps per Second: 10,067.10585

Timestep Collection Time: 2.34268
Timestep Consumption Time: 2.62419
PPO Batch Consumption Time: 0.31435
Total Iteration Time: 4.96687

Cumulative Model Updates: 19,326
Cumulative Timesteps: 161,258,936

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 161258936...
Checkpoint 161258936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,625.88430
Policy Entropy: 1.07994
Value Function Loss: 0.10359

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.34387
Value Function Update Magnitude: 0.52243

Collected Steps per Second: 20,915.81585
Overall Steps per Second: 10,168.08547

Timestep Collection Time: 2.39283
Timestep Consumption Time: 2.52924
PPO Batch Consumption Time: 0.30550
Total Iteration Time: 4.92207

Cumulative Model Updates: 19,332
Cumulative Timesteps: 161,308,984

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,185.37879
Policy Entropy: 1.08269
Value Function Loss: 0.09914

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.33934
Value Function Update Magnitude: 0.52668

Collected Steps per Second: 20,987.86858
Overall Steps per Second: 9,935.67344

Timestep Collection Time: 2.38261
Timestep Consumption Time: 2.65036
PPO Batch Consumption Time: 0.31913
Total Iteration Time: 5.03298

Cumulative Model Updates: 19,338
Cumulative Timesteps: 161,358,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 161358990...
Checkpoint 161358990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,700.10042
Policy Entropy: 1.08778
Value Function Loss: 0.10313

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09668
Policy Update Magnitude: 0.34376
Value Function Update Magnitude: 0.53382

Collected Steps per Second: 20,596.21743
Overall Steps per Second: 9,868.48257

Timestep Collection Time: 2.42899
Timestep Consumption Time: 2.64048
PPO Batch Consumption Time: 0.31793
Total Iteration Time: 5.06947

Cumulative Model Updates: 19,344
Cumulative Timesteps: 161,409,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,727.11817
Policy Entropy: 1.08602
Value Function Loss: 0.09745

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.32298
Value Function Update Magnitude: 0.55530

Collected Steps per Second: 21,400.83180
Overall Steps per Second: 9,920.35618

Timestep Collection Time: 2.33776
Timestep Consumption Time: 2.70541
PPO Batch Consumption Time: 0.31949
Total Iteration Time: 5.04317

Cumulative Model Updates: 19,350
Cumulative Timesteps: 161,459,048

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 161459048...
Checkpoint 161459048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018.25831
Policy Entropy: 1.07872
Value Function Loss: 0.09987

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.33006
Value Function Update Magnitude: 0.54888

Collected Steps per Second: 20,670.43804
Overall Steps per Second: 9,847.58934

Timestep Collection Time: 2.42007
Timestep Consumption Time: 2.65975
PPO Batch Consumption Time: 0.31259
Total Iteration Time: 5.07982

Cumulative Model Updates: 19,356
Cumulative Timesteps: 161,509,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,246.56037
Policy Entropy: 1.07787
Value Function Loss: 0.09405

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.34272
Value Function Update Magnitude: 0.54367

Collected Steps per Second: 21,327.15446
Overall Steps per Second: 10,014.64296

Timestep Collection Time: 2.34537
Timestep Consumption Time: 2.64932
PPO Batch Consumption Time: 0.31506
Total Iteration Time: 4.99469

Cumulative Model Updates: 19,362
Cumulative Timesteps: 161,559,092

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 161559092...
Checkpoint 161559092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,232.60415
Policy Entropy: 1.07134
Value Function Loss: 0.09668

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.34525
Value Function Update Magnitude: 0.53603

Collected Steps per Second: 20,902.47674
Overall Steps per Second: 9,897.26400

Timestep Collection Time: 2.39330
Timestep Consumption Time: 2.66122
PPO Batch Consumption Time: 0.32024
Total Iteration Time: 5.05453

Cumulative Model Updates: 19,368
Cumulative Timesteps: 161,609,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,429.96524
Policy Entropy: 1.08137
Value Function Loss: 0.09192

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07547
Policy Update Magnitude: 0.36165
Value Function Update Magnitude: 0.50898

Collected Steps per Second: 21,454.23986
Overall Steps per Second: 9,974.91114

Timestep Collection Time: 2.33110
Timestep Consumption Time: 2.68268
PPO Batch Consumption Time: 0.31592
Total Iteration Time: 5.01378

Cumulative Model Updates: 19,374
Cumulative Timesteps: 161,659,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 161659130...
Checkpoint 161659130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,556.88158
Policy Entropy: 1.08134
Value Function Loss: 0.09489

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.35945
Value Function Update Magnitude: 0.52016

Collected Steps per Second: 21,205.03300
Overall Steps per Second: 10,049.72195

Timestep Collection Time: 2.35859
Timestep Consumption Time: 2.61806
PPO Batch Consumption Time: 0.30985
Total Iteration Time: 4.97666

Cumulative Model Updates: 19,380
Cumulative Timesteps: 161,709,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,347.29277
Policy Entropy: 1.07943
Value Function Loss: 0.09821

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.34121
Value Function Update Magnitude: 0.51581

Collected Steps per Second: 21,640.85929
Overall Steps per Second: 10,099.06741

Timestep Collection Time: 2.31044
Timestep Consumption Time: 2.64051
PPO Batch Consumption Time: 0.31196
Total Iteration Time: 4.95095

Cumulative Model Updates: 19,386
Cumulative Timesteps: 161,759,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 161759144...
Checkpoint 161759144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,851.28316
Policy Entropy: 1.08346
Value Function Loss: 0.10065

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.33814
Value Function Update Magnitude: 0.51553

Collected Steps per Second: 20,940.73116
Overall Steps per Second: 10,003.48502

Timestep Collection Time: 2.38865
Timestep Consumption Time: 2.61161
PPO Batch Consumption Time: 0.31274
Total Iteration Time: 5.00026

Cumulative Model Updates: 19,392
Cumulative Timesteps: 161,809,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,326.44017
Policy Entropy: 1.07760
Value Function Loss: 0.09724

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.32216
Value Function Update Magnitude: 0.52561

Collected Steps per Second: 21,232.45273
Overall Steps per Second: 9,945.16281

Timestep Collection Time: 2.35555
Timestep Consumption Time: 2.67343
PPO Batch Consumption Time: 0.32021
Total Iteration Time: 5.02898

Cumulative Model Updates: 19,398
Cumulative Timesteps: 161,859,178

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 161859178...
Checkpoint 161859178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,719.87875
Policy Entropy: 1.08341
Value Function Loss: 0.09580

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.14278
Policy Update Magnitude: 0.29795
Value Function Update Magnitude: 0.61192

Collected Steps per Second: 20,441.61709
Overall Steps per Second: 9,703.00252

Timestep Collection Time: 2.44638
Timestep Consumption Time: 2.70749
PPO Batch Consumption Time: 0.32448
Total Iteration Time: 5.15387

Cumulative Model Updates: 19,404
Cumulative Timesteps: 161,909,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,998.93796
Policy Entropy: 1.09299
Value Function Loss: 0.09381

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.28635
Value Function Update Magnitude: 0.68680

Collected Steps per Second: 21,405.27894
Overall Steps per Second: 10,143.41048

Timestep Collection Time: 2.33671
Timestep Consumption Time: 2.59437
PPO Batch Consumption Time: 0.30346
Total Iteration Time: 4.93108

Cumulative Model Updates: 19,410
Cumulative Timesteps: 161,959,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 161959204...
Checkpoint 161959204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,145.03398
Policy Entropy: 1.07823
Value Function Loss: 0.09488

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.29262
Value Function Update Magnitude: 0.69301

Collected Steps per Second: 21,125.60919
Overall Steps per Second: 10,078.97867

Timestep Collection Time: 2.36765
Timestep Consumption Time: 2.59496
PPO Batch Consumption Time: 0.30778
Total Iteration Time: 4.96261

Cumulative Model Updates: 19,416
Cumulative Timesteps: 162,009,222

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,618.47797
Policy Entropy: 1.09117
Value Function Loss: 0.09663

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11972
Policy Update Magnitude: 0.31882
Value Function Update Magnitude: 0.62577

Collected Steps per Second: 21,411.11730
Overall Steps per Second: 10,155.55532

Timestep Collection Time: 2.33580
Timestep Consumption Time: 2.58880
PPO Batch Consumption Time: 0.30575
Total Iteration Time: 4.92460

Cumulative Model Updates: 19,422
Cumulative Timesteps: 162,059,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 162059234...
Checkpoint 162059234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,170.49050
Policy Entropy: 1.08432
Value Function Loss: 0.09683

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.35032
Value Function Update Magnitude: 0.62204

Collected Steps per Second: 20,889.23694
Overall Steps per Second: 10,123.59791

Timestep Collection Time: 2.39482
Timestep Consumption Time: 2.54670
PPO Batch Consumption Time: 0.30213
Total Iteration Time: 4.94152

Cumulative Model Updates: 19,428
Cumulative Timesteps: 162,109,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,625.78005
Policy Entropy: 1.08481
Value Function Loss: 0.10150

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.34019
Value Function Update Magnitude: 0.60723

Collected Steps per Second: 21,542.85439
Overall Steps per Second: 10,133.92127

Timestep Collection Time: 2.32216
Timestep Consumption Time: 2.61433
PPO Batch Consumption Time: 0.30722
Total Iteration Time: 4.93649

Cumulative Model Updates: 19,434
Cumulative Timesteps: 162,159,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 162159286...
Checkpoint 162159286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,025.55864
Policy Entropy: 1.09136
Value Function Loss: 0.09719

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.33604
Value Function Update Magnitude: 0.58697

Collected Steps per Second: 20,993.61057
Overall Steps per Second: 10,049.25000

Timestep Collection Time: 2.38320
Timestep Consumption Time: 2.59548
PPO Batch Consumption Time: 0.30604
Total Iteration Time: 4.97868

Cumulative Model Updates: 19,440
Cumulative Timesteps: 162,209,318

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,509.53971
Policy Entropy: 1.09822
Value Function Loss: 0.09598

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08268
Policy Update Magnitude: 0.34137
Value Function Update Magnitude: 0.56355

Collected Steps per Second: 21,464.33950
Overall Steps per Second: 10,139.89882

Timestep Collection Time: 2.33019
Timestep Consumption Time: 2.60240
PPO Batch Consumption Time: 0.30126
Total Iteration Time: 4.93259

Cumulative Model Updates: 19,446
Cumulative Timesteps: 162,259,334

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 162259334...
Checkpoint 162259334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,687.34037
Policy Entropy: 1.10826
Value Function Loss: 0.09234

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.35969
Value Function Update Magnitude: 0.62394

Collected Steps per Second: 21,046.63644
Overall Steps per Second: 9,829.73618

Timestep Collection Time: 2.37596
Timestep Consumption Time: 2.71126
PPO Batch Consumption Time: 0.32232
Total Iteration Time: 5.08722

Cumulative Model Updates: 19,452
Cumulative Timesteps: 162,309,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,206.15955
Policy Entropy: 1.10970
Value Function Loss: 0.09322

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08709
Policy Update Magnitude: 0.36244
Value Function Update Magnitude: 0.58115

Collected Steps per Second: 20,967.69488
Overall Steps per Second: 10,145.90895

Timestep Collection Time: 2.38548
Timestep Consumption Time: 2.54439
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.92987

Cumulative Model Updates: 19,458
Cumulative Timesteps: 162,359,358

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 162359358...
Checkpoint 162359358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,023.12216
Policy Entropy: 1.11034
Value Function Loss: 0.09457

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.34849
Value Function Update Magnitude: 0.59482

Collected Steps per Second: 21,167.82986
Overall Steps per Second: 10,302.99719

Timestep Collection Time: 2.36274
Timestep Consumption Time: 2.49158
PPO Batch Consumption Time: 0.30532
Total Iteration Time: 4.85432

Cumulative Model Updates: 19,464
Cumulative Timesteps: 162,409,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,694.97083
Policy Entropy: 1.10961
Value Function Loss: 0.09172

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.34456
Value Function Update Magnitude: 0.55244

Collected Steps per Second: 20,587.83721
Overall Steps per Second: 10,042.23828

Timestep Collection Time: 2.42930
Timestep Consumption Time: 2.55107
PPO Batch Consumption Time: 0.30816
Total Iteration Time: 4.98036

Cumulative Model Updates: 19,470
Cumulative Timesteps: 162,459,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 162459386...
Checkpoint 162459386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,248.19910
Policy Entropy: 1.09689
Value Function Loss: 0.09774

Mean KL Divergence: 0.02635
SB3 Clip Fraction: 0.18360
Policy Update Magnitude: 0.29713
Value Function Update Magnitude: 0.54491

Collected Steps per Second: 21,267.41114
Overall Steps per Second: 10,263.06329

Timestep Collection Time: 2.35130
Timestep Consumption Time: 2.52113
PPO Batch Consumption Time: 0.30845
Total Iteration Time: 4.87242

Cumulative Model Updates: 19,476
Cumulative Timesteps: 162,509,392

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764.34745
Policy Entropy: 1.09490
Value Function Loss: 0.10045

Mean KL Divergence: 0.02771
SB3 Clip Fraction: 0.20197
Policy Update Magnitude: 0.24257
Value Function Update Magnitude: 0.55782

Collected Steps per Second: 20,817.25343
Overall Steps per Second: 10,008.15761

Timestep Collection Time: 2.40310
Timestep Consumption Time: 2.59542
PPO Batch Consumption Time: 0.31002
Total Iteration Time: 4.99852

Cumulative Model Updates: 19,482
Cumulative Timesteps: 162,559,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 162559418...
Checkpoint 162559418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,894.53189
Policy Entropy: 1.10124
Value Function Loss: 0.10062

Mean KL Divergence: 0.02761
SB3 Clip Fraction: 0.20601
Policy Update Magnitude: 0.24181
Value Function Update Magnitude: 0.50794

Collected Steps per Second: 20,844.30043
Overall Steps per Second: 10,046.32028

Timestep Collection Time: 2.39979
Timestep Consumption Time: 2.57934
PPO Batch Consumption Time: 0.30191
Total Iteration Time: 4.97914

Cumulative Model Updates: 19,488
Cumulative Timesteps: 162,609,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,817.80051
Policy Entropy: 1.09195
Value Function Loss: 0.10510

Mean KL Divergence: 0.02280
SB3 Clip Fraction: 0.18155
Policy Update Magnitude: 0.23837
Value Function Update Magnitude: 0.46768

Collected Steps per Second: 21,507.11472
Overall Steps per Second: 10,200.04424

Timestep Collection Time: 2.32574
Timestep Consumption Time: 2.57816
PPO Batch Consumption Time: 0.30789
Total Iteration Time: 4.90390

Cumulative Model Updates: 19,494
Cumulative Timesteps: 162,659,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 162659460...
Checkpoint 162659460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,238.54859
Policy Entropy: 1.10474
Value Function Loss: 0.10707

Mean KL Divergence: 0.02727
SB3 Clip Fraction: 0.19218
Policy Update Magnitude: 0.26979
Value Function Update Magnitude: 0.52306

Collected Steps per Second: 21,072.93881
Overall Steps per Second: 10,087.89337

Timestep Collection Time: 2.37385
Timestep Consumption Time: 2.58497
PPO Batch Consumption Time: 0.30630
Total Iteration Time: 4.95882

Cumulative Model Updates: 19,500
Cumulative Timesteps: 162,709,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.87752
Policy Entropy: 1.09991
Value Function Loss: 0.11708

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.15897
Policy Update Magnitude: 0.28402
Value Function Update Magnitude: 0.55440

Collected Steps per Second: 21,460.19916
Overall Steps per Second: 10,059.76790

Timestep Collection Time: 2.32989
Timestep Consumption Time: 2.64040
PPO Batch Consumption Time: 0.31453
Total Iteration Time: 4.97029

Cumulative Model Updates: 19,506
Cumulative Timesteps: 162,759,484

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 162759484...
Checkpoint 162759484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.58568
Policy Entropy: 1.11415
Value Function Loss: 0.11898

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.15092
Policy Update Magnitude: 0.31149
Value Function Update Magnitude: 0.44379

Collected Steps per Second: 20,868.74802
Overall Steps per Second: 10,119.35325

Timestep Collection Time: 2.39631
Timestep Consumption Time: 2.54551
PPO Batch Consumption Time: 0.29939
Total Iteration Time: 4.94182

Cumulative Model Updates: 19,512
Cumulative Timesteps: 162,809,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,358.66448
Policy Entropy: 1.10904
Value Function Loss: 0.11936

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.31792
Value Function Update Magnitude: 0.38059

Collected Steps per Second: 21,741.11518
Overall Steps per Second: 10,245.04732

Timestep Collection Time: 2.30016
Timestep Consumption Time: 2.58103
PPO Batch Consumption Time: 0.30600
Total Iteration Time: 4.88119

Cumulative Model Updates: 19,518
Cumulative Timesteps: 162,859,500

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 162859500...
Checkpoint 162859500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,350.77909
Policy Entropy: 1.10777
Value Function Loss: 0.10864

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10715
Policy Update Magnitude: 0.34222
Value Function Update Magnitude: 0.41263

Collected Steps per Second: 21,171.58375
Overall Steps per Second: 10,099.30036

Timestep Collection Time: 2.36251
Timestep Consumption Time: 2.59011
PPO Batch Consumption Time: 0.30912
Total Iteration Time: 4.95262

Cumulative Model Updates: 19,524
Cumulative Timesteps: 162,909,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,567.92494
Policy Entropy: 1.09617
Value Function Loss: 0.10694

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.38112
Value Function Update Magnitude: 0.42937

Collected Steps per Second: 21,280.50118
Overall Steps per Second: 10,176.21723

Timestep Collection Time: 2.35079
Timestep Consumption Time: 2.56518
PPO Batch Consumption Time: 0.30379
Total Iteration Time: 4.91597

Cumulative Model Updates: 19,530
Cumulative Timesteps: 162,959,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 162959544...
Checkpoint 162959544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351.75765
Policy Entropy: 1.08589
Value Function Loss: 0.10494

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.38952
Value Function Update Magnitude: 0.42586

Collected Steps per Second: 21,094.41274
Overall Steps per Second: 9,923.88101

Timestep Collection Time: 2.37191
Timestep Consumption Time: 2.66987
PPO Batch Consumption Time: 0.32031
Total Iteration Time: 5.04178

Cumulative Model Updates: 19,536
Cumulative Timesteps: 163,009,578

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,468.80279
Policy Entropy: 1.10094
Value Function Loss: 0.10950

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.14527
Policy Update Magnitude: 0.34181
Value Function Update Magnitude: 0.42177

Collected Steps per Second: 21,022.63553
Overall Steps per Second: 10,022.39225

Timestep Collection Time: 2.37877
Timestep Consumption Time: 2.61086
PPO Batch Consumption Time: 0.30799
Total Iteration Time: 4.98963

Cumulative Model Updates: 19,542
Cumulative Timesteps: 163,059,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 163059586...
Checkpoint 163059586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,624.53415
Policy Entropy: 1.09531
Value Function Loss: 0.10802

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.34236
Value Function Update Magnitude: 0.39986

Collected Steps per Second: 20,843.45573
Overall Steps per Second: 9,868.52080

Timestep Collection Time: 2.39979
Timestep Consumption Time: 2.66885
PPO Batch Consumption Time: 0.32216
Total Iteration Time: 5.06864

Cumulative Model Updates: 19,548
Cumulative Timesteps: 163,109,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,717.43226
Policy Entropy: 1.09784
Value Function Loss: 0.11025

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.35313
Value Function Update Magnitude: 0.41362

Collected Steps per Second: 21,294.06656
Overall Steps per Second: 9,945.90099

Timestep Collection Time: 2.34835
Timestep Consumption Time: 2.67945
PPO Batch Consumption Time: 0.32057
Total Iteration Time: 5.02780

Cumulative Model Updates: 19,554
Cumulative Timesteps: 163,159,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 163159612...
Checkpoint 163159612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,170.10750
Policy Entropy: 1.09233
Value Function Loss: 0.10833

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.35623
Value Function Update Magnitude: 0.43708

Collected Steps per Second: 20,815.40528
Overall Steps per Second: 9,907.06369

Timestep Collection Time: 2.40312
Timestep Consumption Time: 2.64600
PPO Batch Consumption Time: 0.31589
Total Iteration Time: 5.04912

Cumulative Model Updates: 19,560
Cumulative Timesteps: 163,209,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,881.85739
Policy Entropy: 1.10189
Value Function Loss: 0.10535

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.32939
Value Function Update Magnitude: 0.44743

Collected Steps per Second: 21,031.84095
Overall Steps per Second: 9,969.45703

Timestep Collection Time: 2.37830
Timestep Consumption Time: 2.63903
PPO Batch Consumption Time: 0.31550
Total Iteration Time: 5.01732

Cumulative Model Updates: 19,566
Cumulative Timesteps: 163,259,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 163259654...
Checkpoint 163259654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,178.23354
Policy Entropy: 1.09335
Value Function Loss: 0.10617

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.34236
Value Function Update Magnitude: 0.44771

Collected Steps per Second: 20,870.97189
Overall Steps per Second: 9,905.92010

Timestep Collection Time: 2.39653
Timestep Consumption Time: 2.65277
PPO Batch Consumption Time: 0.31867
Total Iteration Time: 5.04930

Cumulative Model Updates: 19,572
Cumulative Timesteps: 163,309,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,001.79522
Policy Entropy: 1.10223
Value Function Loss: 0.10723

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.35618
Value Function Update Magnitude: 0.44222

Collected Steps per Second: 21,121.21592
Overall Steps per Second: 9,973.24231

Timestep Collection Time: 2.36899
Timestep Consumption Time: 2.64803
PPO Batch Consumption Time: 0.31576
Total Iteration Time: 5.01702

Cumulative Model Updates: 19,578
Cumulative Timesteps: 163,359,708

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 163359708...
Checkpoint 163359708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,587.82164
Policy Entropy: 1.09543
Value Function Loss: 0.11255

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.34307
Value Function Update Magnitude: 0.45880

Collected Steps per Second: 20,817.79399
Overall Steps per Second: 10,043.16699

Timestep Collection Time: 2.40304
Timestep Consumption Time: 2.57806
PPO Batch Consumption Time: 0.30558
Total Iteration Time: 4.98110

Cumulative Model Updates: 19,584
Cumulative Timesteps: 163,409,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,966.55736
Policy Entropy: 1.09271
Value Function Loss: 0.11032

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.14180
Policy Update Magnitude: 0.28950
Value Function Update Magnitude: 0.47182

Collected Steps per Second: 21,097.55459
Overall Steps per Second: 10,122.84013

Timestep Collection Time: 2.37051
Timestep Consumption Time: 2.57000
PPO Batch Consumption Time: 0.30343
Total Iteration Time: 4.94051

Cumulative Model Updates: 19,590
Cumulative Timesteps: 163,459,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 163459746...
Checkpoint 163459746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,437.20319
Policy Entropy: 1.10367
Value Function Loss: 0.10958

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.27643
Value Function Update Magnitude: 0.47233

Collected Steps per Second: 21,054.12937
Overall Steps per Second: 10,247.36192

Timestep Collection Time: 2.37683
Timestep Consumption Time: 2.50658
PPO Batch Consumption Time: 0.30590
Total Iteration Time: 4.88340

Cumulative Model Updates: 19,596
Cumulative Timesteps: 163,509,788

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,578.34032
Policy Entropy: 1.10781
Value Function Loss: 0.10727

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.30081
Value Function Update Magnitude: 0.47748

Collected Steps per Second: 21,353.02478
Overall Steps per Second: 10,117.48300

Timestep Collection Time: 2.34243
Timestep Consumption Time: 2.60129
PPO Batch Consumption Time: 0.30908
Total Iteration Time: 4.94372

Cumulative Model Updates: 19,602
Cumulative Timesteps: 163,559,806

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 163559806...
Checkpoint 163559806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,558.83448
Policy Entropy: 1.11021
Value Function Loss: 0.10503

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10531
Policy Update Magnitude: 0.31682
Value Function Update Magnitude: 0.49026

Collected Steps per Second: 21,009.28247
Overall Steps per Second: 9,993.76264

Timestep Collection Time: 2.38019
Timestep Consumption Time: 2.62354
PPO Batch Consumption Time: 0.31196
Total Iteration Time: 5.00372

Cumulative Model Updates: 19,608
Cumulative Timesteps: 163,609,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,990.71220
Policy Entropy: 1.10182
Value Function Loss: 0.11198

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13456
Policy Update Magnitude: 0.30142
Value Function Update Magnitude: 0.51792

Collected Steps per Second: 20,653.88297
Overall Steps per Second: 9,822.15134

Timestep Collection Time: 2.42143
Timestep Consumption Time: 2.67032
PPO Batch Consumption Time: 0.32015
Total Iteration Time: 5.09176

Cumulative Model Updates: 19,614
Cumulative Timesteps: 163,659,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 163659824...
Checkpoint 163659824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,346.00899
Policy Entropy: 1.10154
Value Function Loss: 0.10475

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.30768
Value Function Update Magnitude: 0.51950

Collected Steps per Second: 21,081.96213
Overall Steps per Second: 9,889.17338

Timestep Collection Time: 2.37302
Timestep Consumption Time: 2.68584
PPO Batch Consumption Time: 0.31859
Total Iteration Time: 5.05887

Cumulative Model Updates: 19,620
Cumulative Timesteps: 163,709,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,307.50334
Policy Entropy: 1.10927
Value Function Loss: 0.11010

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.14330
Policy Update Magnitude: 0.29187
Value Function Update Magnitude: 0.50519

Collected Steps per Second: 21,194.99916
Overall Steps per Second: 9,963.69494

Timestep Collection Time: 2.35914
Timestep Consumption Time: 2.65928
PPO Batch Consumption Time: 0.31976
Total Iteration Time: 5.01842

Cumulative Model Updates: 19,626
Cumulative Timesteps: 163,759,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 163759854...
Checkpoint 163759854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,483.43514
Policy Entropy: 1.10612
Value Function Loss: 0.10313

Mean KL Divergence: 0.02683
SB3 Clip Fraction: 0.19012
Policy Update Magnitude: 0.25752
Value Function Update Magnitude: 0.49941

Collected Steps per Second: 20,520.71741
Overall Steps per Second: 9,748.89186

Timestep Collection Time: 2.43705
Timestep Consumption Time: 2.69276
PPO Batch Consumption Time: 0.32645
Total Iteration Time: 5.12981

Cumulative Model Updates: 19,632
Cumulative Timesteps: 163,809,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,880.41345
Policy Entropy: 1.10107
Value Function Loss: 0.10516

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.15403
Policy Update Magnitude: 0.27692
Value Function Update Magnitude: 0.53324

Collected Steps per Second: 21,253.01869
Overall Steps per Second: 10,074.64772

Timestep Collection Time: 2.35317
Timestep Consumption Time: 2.61097
PPO Batch Consumption Time: 0.30978
Total Iteration Time: 4.96414

Cumulative Model Updates: 19,638
Cumulative Timesteps: 163,859,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 163859876...
Checkpoint 163859876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.96383
Policy Entropy: 1.10110
Value Function Loss: 0.10584

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.16532
Policy Update Magnitude: 0.28044
Value Function Update Magnitude: 0.55632

Collected Steps per Second: 20,977.01665
Overall Steps per Second: 10,055.99720

Timestep Collection Time: 2.38366
Timestep Consumption Time: 2.58870
PPO Batch Consumption Time: 0.30923
Total Iteration Time: 4.97236

Cumulative Model Updates: 19,644
Cumulative Timesteps: 163,909,878

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,552.54559
Policy Entropy: 1.10703
Value Function Loss: 0.10647

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.31106
Value Function Update Magnitude: 0.54919

Collected Steps per Second: 20,750.81214
Overall Steps per Second: 9,867.57570

Timestep Collection Time: 2.41032
Timestep Consumption Time: 2.65841
PPO Batch Consumption Time: 0.31914
Total Iteration Time: 5.06872

Cumulative Model Updates: 19,650
Cumulative Timesteps: 163,959,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 163959894...
Checkpoint 163959894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,537.49696
Policy Entropy: 1.11019
Value Function Loss: 0.10560

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11216
Policy Update Magnitude: 0.32736
Value Function Update Magnitude: 0.53478

Collected Steps per Second: 20,808.94882
Overall Steps per Second: 9,961.52574

Timestep Collection Time: 2.40291
Timestep Consumption Time: 2.61660
PPO Batch Consumption Time: 0.31081
Total Iteration Time: 5.01951

Cumulative Model Updates: 19,656
Cumulative Timesteps: 164,009,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,444.75176
Policy Entropy: 1.11454
Value Function Loss: 0.10068

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11594
Policy Update Magnitude: 0.32762
Value Function Update Magnitude: 0.53529

Collected Steps per Second: 21,123.95878
Overall Steps per Second: 10,043.32970

Timestep Collection Time: 2.36821
Timestep Consumption Time: 2.61281
PPO Batch Consumption Time: 0.30859
Total Iteration Time: 4.98102

Cumulative Model Updates: 19,662
Cumulative Timesteps: 164,059,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 164059922...
Checkpoint 164059922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,669.76740
Policy Entropy: 1.11737
Value Function Loss: 0.09670

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09663
Policy Update Magnitude: 0.31377
Value Function Update Magnitude: 0.50389

Collected Steps per Second: 21,485.15039
Overall Steps per Second: 10,242.05273

Timestep Collection Time: 2.32747
Timestep Consumption Time: 2.55495
PPO Batch Consumption Time: 0.30505
Total Iteration Time: 4.88242

Cumulative Model Updates: 19,668
Cumulative Timesteps: 164,109,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,243.09679
Policy Entropy: 1.12087
Value Function Loss: 0.09401

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.33591
Value Function Update Magnitude: 0.48440

Collected Steps per Second: 21,070.93736
Overall Steps per Second: 9,878.39792

Timestep Collection Time: 2.37417
Timestep Consumption Time: 2.69001
PPO Batch Consumption Time: 0.31946
Total Iteration Time: 5.06418

Cumulative Model Updates: 19,674
Cumulative Timesteps: 164,159,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 164159954...
Checkpoint 164159954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,356.36775
Policy Entropy: 1.11308
Value Function Loss: 0.08858

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.07252
Policy Update Magnitude: 0.35502
Value Function Update Magnitude: 0.51944

Collected Steps per Second: 20,911.49995
Overall Steps per Second: 10,113.62432

Timestep Collection Time: 2.39227
Timestep Consumption Time: 2.55412
PPO Batch Consumption Time: 0.30559
Total Iteration Time: 4.94640

Cumulative Model Updates: 19,680
Cumulative Timesteps: 164,209,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,576.44355
Policy Entropy: 1.10877
Value Function Loss: 0.09134

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07253
Policy Update Magnitude: 0.35815
Value Function Update Magnitude: 0.55892

Collected Steps per Second: 21,113.29099
Overall Steps per Second: 9,966.69798

Timestep Collection Time: 2.36950
Timestep Consumption Time: 2.65001
PPO Batch Consumption Time: 0.31447
Total Iteration Time: 5.01952

Cumulative Model Updates: 19,686
Cumulative Timesteps: 164,260,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 164260008...
Checkpoint 164260008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,702.82490
Policy Entropy: 1.10559
Value Function Loss: 0.09293

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 0.34897
Value Function Update Magnitude: 0.53678

Collected Steps per Second: 20,301.67534
Overall Steps per Second: 9,786.62860

Timestep Collection Time: 2.46334
Timestep Consumption Time: 2.64669
PPO Batch Consumption Time: 0.30945
Total Iteration Time: 5.11003

Cumulative Model Updates: 19,692
Cumulative Timesteps: 164,310,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,940.51369
Policy Entropy: 1.09339
Value Function Loss: 0.09672

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09195
Policy Update Magnitude: 0.34432
Value Function Update Magnitude: 0.50707

Collected Steps per Second: 21,449.10025
Overall Steps per Second: 10,097.21548

Timestep Collection Time: 2.33129
Timestep Consumption Time: 2.62097
PPO Batch Consumption Time: 0.30767
Total Iteration Time: 4.95226

Cumulative Model Updates: 19,698
Cumulative Timesteps: 164,360,022

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 164360022...
Checkpoint 164360022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,342.98676
Policy Entropy: 1.08833
Value Function Loss: 0.09628

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12203
Policy Update Magnitude: 0.31229
Value Function Update Magnitude: 0.61386

Collected Steps per Second: 20,649.30491
Overall Steps per Second: 9,874.58379

Timestep Collection Time: 2.42294
Timestep Consumption Time: 2.64381
PPO Batch Consumption Time: 0.31574
Total Iteration Time: 5.06675

Cumulative Model Updates: 19,704
Cumulative Timesteps: 164,410,054

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,510.68414
Policy Entropy: 1.09309
Value Function Loss: 0.09430

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.31920
Value Function Update Magnitude: 0.67330

Collected Steps per Second: 21,082.54092
Overall Steps per Second: 10,010.19535

Timestep Collection Time: 2.37201
Timestep Consumption Time: 2.62370
PPO Batch Consumption Time: 0.31158
Total Iteration Time: 4.99571

Cumulative Model Updates: 19,710
Cumulative Timesteps: 164,460,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 164460062...
Checkpoint 164460062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,025.60503
Policy Entropy: 1.08946
Value Function Loss: 0.09797

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12351
Policy Update Magnitude: 0.31315
Value Function Update Magnitude: 0.69234

Collected Steps per Second: 21,284.00925
Overall Steps per Second: 10,275.29553

Timestep Collection Time: 2.34965
Timestep Consumption Time: 2.51736
PPO Batch Consumption Time: 0.30561
Total Iteration Time: 4.86701

Cumulative Model Updates: 19,716
Cumulative Timesteps: 164,510,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,092.19936
Policy Entropy: 1.10431
Value Function Loss: 0.09999

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.12738
Policy Update Magnitude: 0.29793
Value Function Update Magnitude: 0.69936

Collected Steps per Second: 21,144.15167
Overall Steps per Second: 9,968.33011

Timestep Collection Time: 2.36538
Timestep Consumption Time: 2.65191
PPO Batch Consumption Time: 0.31428
Total Iteration Time: 5.01729

Cumulative Model Updates: 19,722
Cumulative Timesteps: 164,560,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 164560086...
Checkpoint 164560086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,413.92796
Policy Entropy: 1.10042
Value Function Loss: 0.09509

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.33508
Value Function Update Magnitude: 0.69574

Collected Steps per Second: 20,991.58343
Overall Steps per Second: 9,935.00640

Timestep Collection Time: 2.38200
Timestep Consumption Time: 2.65091
PPO Batch Consumption Time: 0.31250
Total Iteration Time: 5.03291

Cumulative Model Updates: 19,728
Cumulative Timesteps: 164,610,088

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,987.45960
Policy Entropy: 1.10862
Value Function Loss: 0.09176

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.35239
Value Function Update Magnitude: 0.69256

Collected Steps per Second: 21,438.97638
Overall Steps per Second: 10,126.58761

Timestep Collection Time: 2.33220
Timestep Consumption Time: 2.60530
PPO Batch Consumption Time: 0.30893
Total Iteration Time: 4.93750

Cumulative Model Updates: 19,734
Cumulative Timesteps: 164,660,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 164660088...
Checkpoint 164660088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,549.08865
Policy Entropy: 1.09537
Value Function Loss: 0.08697

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.33801
Value Function Update Magnitude: 0.68301

Collected Steps per Second: 20,810.28693
Overall Steps per Second: 9,946.14717

Timestep Collection Time: 2.40439
Timestep Consumption Time: 2.62630
PPO Batch Consumption Time: 0.30531
Total Iteration Time: 5.03069

Cumulative Model Updates: 19,740
Cumulative Timesteps: 164,710,124

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,932.09375
Policy Entropy: 1.08177
Value Function Loss: 0.09141

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.34517
Value Function Update Magnitude: 0.65406

Collected Steps per Second: 21,467.47434
Overall Steps per Second: 10,187.43479

Timestep Collection Time: 2.32966
Timestep Consumption Time: 2.57952
PPO Batch Consumption Time: 0.30563
Total Iteration Time: 4.90918

Cumulative Model Updates: 19,746
Cumulative Timesteps: 164,760,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 164760136...
Checkpoint 164760136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,878.56719
Policy Entropy: 1.07956
Value Function Loss: 0.08908

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.12144
Policy Update Magnitude: 0.31562
Value Function Update Magnitude: 0.62152

Collected Steps per Second: 20,568.04945
Overall Steps per Second: 10,109.65270

Timestep Collection Time: 2.43154
Timestep Consumption Time: 2.51542
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.94696

Cumulative Model Updates: 19,752
Cumulative Timesteps: 164,810,148

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,116.68724
Policy Entropy: 1.07265
Value Function Loss: 0.09212

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.14447
Policy Update Magnitude: 0.28500
Value Function Update Magnitude: 0.61753

Collected Steps per Second: 21,983.14122
Overall Steps per Second: 10,430.86194

Timestep Collection Time: 2.27583
Timestep Consumption Time: 2.52051
PPO Batch Consumption Time: 0.29584
Total Iteration Time: 4.79634

Cumulative Model Updates: 19,758
Cumulative Timesteps: 164,860,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 164860178...
Checkpoint 164860178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,643.49577
Policy Entropy: 1.06944
Value Function Loss: 0.09235

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.28228
Value Function Update Magnitude: 0.61135

Collected Steps per Second: 21,037.74545
Overall Steps per Second: 10,097.35140

Timestep Collection Time: 2.37735
Timestep Consumption Time: 2.57583
PPO Batch Consumption Time: 0.30336
Total Iteration Time: 4.95318

Cumulative Model Updates: 19,764
Cumulative Timesteps: 164,910,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,961.09890
Policy Entropy: 1.05859
Value Function Loss: 0.09492

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10601
Policy Update Magnitude: 0.29599
Value Function Update Magnitude: 0.56685

Collected Steps per Second: 21,279.18927
Overall Steps per Second: 10,135.57132

Timestep Collection Time: 2.35037
Timestep Consumption Time: 2.58413
PPO Batch Consumption Time: 0.30469
Total Iteration Time: 4.93450

Cumulative Model Updates: 19,770
Cumulative Timesteps: 164,960,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 164960206...
Checkpoint 164960206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,610.99868
Policy Entropy: 1.07262
Value Function Loss: 0.09248

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12276
Policy Update Magnitude: 0.28332
Value Function Update Magnitude: 0.57154

Collected Steps per Second: 20,829.73007
Overall Steps per Second: 9,851.65729

Timestep Collection Time: 2.40291
Timestep Consumption Time: 2.67765
PPO Batch Consumption Time: 0.31807
Total Iteration Time: 5.08057

Cumulative Model Updates: 19,776
Cumulative Timesteps: 165,010,258

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,028.83815
Policy Entropy: 1.07809
Value Function Loss: 0.09391

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.27009
Value Function Update Magnitude: 0.65386

Collected Steps per Second: 21,107.07735
Overall Steps per Second: 9,891.76735

Timestep Collection Time: 2.36925
Timestep Consumption Time: 2.68626
PPO Batch Consumption Time: 0.31752
Total Iteration Time: 5.05552

Cumulative Model Updates: 19,782
Cumulative Timesteps: 165,060,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 165060266...
Checkpoint 165060266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,008.62524
Policy Entropy: 1.09195
Value Function Loss: 0.08883

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.26561
Value Function Update Magnitude: 0.68108

Collected Steps per Second: 21,131.90961
Overall Steps per Second: 10,314.76027

Timestep Collection Time: 2.36609
Timestep Consumption Time: 2.48133
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.84742

Cumulative Model Updates: 19,788
Cumulative Timesteps: 165,110,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,222.99072
Policy Entropy: 1.07640
Value Function Loss: 0.09771

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13283
Policy Update Magnitude: 0.27314
Value Function Update Magnitude: 0.71542

Collected Steps per Second: 18,715.99353
Overall Steps per Second: 9,211.03293

Timestep Collection Time: 2.67376
Timestep Consumption Time: 2.75908
PPO Batch Consumption Time: 0.31946
Total Iteration Time: 5.43283

Cumulative Model Updates: 19,794
Cumulative Timesteps: 165,160,308

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 165160308...
Checkpoint 165160308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,686.26344
Policy Entropy: 1.07309
Value Function Loss: 0.09483

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.14828
Policy Update Magnitude: 0.29732
Value Function Update Magnitude: 0.70111

Collected Steps per Second: 20,234.22630
Overall Steps per Second: 9,783.11066

Timestep Collection Time: 2.47146
Timestep Consumption Time: 2.64021
PPO Batch Consumption Time: 0.30883
Total Iteration Time: 5.11167

Cumulative Model Updates: 19,800
Cumulative Timesteps: 165,210,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,706.72079
Policy Entropy: 1.06760
Value Function Loss: 0.09877

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.30117
Value Function Update Magnitude: 0.63848

Collected Steps per Second: 21,104.22260
Overall Steps per Second: 10,043.37872

Timestep Collection Time: 2.37071
Timestep Consumption Time: 2.61088
PPO Batch Consumption Time: 0.30889
Total Iteration Time: 4.98159

Cumulative Model Updates: 19,806
Cumulative Timesteps: 165,260,348

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 165260348...
Checkpoint 165260348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,534.39985
Policy Entropy: 1.07941
Value Function Loss: 0.09880

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.29640
Value Function Update Magnitude: 0.63838

Collected Steps per Second: 20,843.54294
Overall Steps per Second: 10,071.55650

Timestep Collection Time: 2.39950
Timestep Consumption Time: 2.56637
PPO Batch Consumption Time: 0.30424
Total Iteration Time: 4.96587

Cumulative Model Updates: 19,812
Cumulative Timesteps: 165,310,362

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,468.22498
Policy Entropy: 1.08319
Value Function Loss: 0.09490

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.27935
Value Function Update Magnitude: 0.69387

Collected Steps per Second: 21,103.61776
Overall Steps per Second: 9,895.91715

Timestep Collection Time: 2.36964
Timestep Consumption Time: 2.68376
PPO Batch Consumption Time: 0.31372
Total Iteration Time: 5.05340

Cumulative Model Updates: 19,818
Cumulative Timesteps: 165,360,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 165360370...
Checkpoint 165360370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,381.61078
Policy Entropy: 1.08198
Value Function Loss: 0.09305

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11268
Policy Update Magnitude: 0.29138
Value Function Update Magnitude: 0.58807

Collected Steps per Second: 20,910.70646
Overall Steps per Second: 9,927.63000

Timestep Collection Time: 2.39198
Timestep Consumption Time: 2.64628
PPO Batch Consumption Time: 0.31141
Total Iteration Time: 5.03826

Cumulative Model Updates: 19,824
Cumulative Timesteps: 165,410,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,450.88064
Policy Entropy: 1.08264
Value Function Loss: 0.09446

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.34243
Value Function Update Magnitude: 0.54079

Collected Steps per Second: 21,173.33013
Overall Steps per Second: 10,091.95264

Timestep Collection Time: 2.36354
Timestep Consumption Time: 2.59526
PPO Batch Consumption Time: 0.30751
Total Iteration Time: 4.95880

Cumulative Model Updates: 19,830
Cumulative Timesteps: 165,460,432

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 165460432...
Checkpoint 165460432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,265.47079
Policy Entropy: 1.08008
Value Function Loss: 0.09678

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.35938
Value Function Update Magnitude: 0.60498

Collected Steps per Second: 21,351.42096
Overall Steps per Second: 10,160.30333

Timestep Collection Time: 2.34214
Timestep Consumption Time: 2.57976
PPO Batch Consumption Time: 0.30017
Total Iteration Time: 4.92190

Cumulative Model Updates: 19,836
Cumulative Timesteps: 165,510,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551.54582
Policy Entropy: 1.07876
Value Function Loss: 0.09432

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.36903
Value Function Update Magnitude: 0.63916

Collected Steps per Second: 21,349.27467
Overall Steps per Second: 10,093.85770

Timestep Collection Time: 2.34266
Timestep Consumption Time: 2.61224
PPO Batch Consumption Time: 0.30890
Total Iteration Time: 4.95489

Cumulative Model Updates: 19,842
Cumulative Timesteps: 165,560,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 165560454...
Checkpoint 165560454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,420.20385
Policy Entropy: 1.07176
Value Function Loss: 0.09900

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.36535
Value Function Update Magnitude: 0.65624

Collected Steps per Second: 21,187.87308
Overall Steps per Second: 10,154.80209

Timestep Collection Time: 2.36211
Timestep Consumption Time: 2.56640
PPO Batch Consumption Time: 0.30227
Total Iteration Time: 4.92851

Cumulative Model Updates: 19,848
Cumulative Timesteps: 165,610,502

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,692.94626
Policy Entropy: 1.06729
Value Function Loss: 0.09769

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.35717
Value Function Update Magnitude: 0.74028

Collected Steps per Second: 21,416.93903
Overall Steps per Second: 9,974.14877

Timestep Collection Time: 2.33553
Timestep Consumption Time: 2.67943
PPO Batch Consumption Time: 0.32078
Total Iteration Time: 5.01496

Cumulative Model Updates: 19,854
Cumulative Timesteps: 165,660,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 165660522...
Checkpoint 165660522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,779.40415
Policy Entropy: 1.07416
Value Function Loss: 0.09716

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.34304
Value Function Update Magnitude: 0.79620

Collected Steps per Second: 20,728.87883
Overall Steps per Second: 9,923.87339

Timestep Collection Time: 2.41325
Timestep Consumption Time: 2.62752
PPO Batch Consumption Time: 0.31165
Total Iteration Time: 5.04077

Cumulative Model Updates: 19,860
Cumulative Timesteps: 165,710,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,294.70958
Policy Entropy: 1.07392
Value Function Loss: 0.09672

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.35819
Value Function Update Magnitude: 0.75387

Collected Steps per Second: 21,184.70648
Overall Steps per Second: 9,929.98042

Timestep Collection Time: 2.36151
Timestep Consumption Time: 2.67656
PPO Batch Consumption Time: 0.31821
Total Iteration Time: 5.03808

Cumulative Model Updates: 19,866
Cumulative Timesteps: 165,760,574

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 165760574...
Checkpoint 165760574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,227.13221
Policy Entropy: 1.07571
Value Function Loss: 0.09767

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.36601
Value Function Update Magnitude: 0.63230

Collected Steps per Second: 21,283.26579
Overall Steps per Second: 10,212.61896

Timestep Collection Time: 2.35030
Timestep Consumption Time: 2.54776
PPO Batch Consumption Time: 0.30577
Total Iteration Time: 4.89806

Cumulative Model Updates: 19,872
Cumulative Timesteps: 165,810,596

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,368.60995
Policy Entropy: 1.06920
Value Function Loss: 0.10360

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.34918
Value Function Update Magnitude: 0.61158

Collected Steps per Second: 21,372.20581
Overall Steps per Second: 10,029.37340

Timestep Collection Time: 2.34136
Timestep Consumption Time: 2.64799
PPO Batch Consumption Time: 0.31962
Total Iteration Time: 4.98934

Cumulative Model Updates: 19,878
Cumulative Timesteps: 165,860,636

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 165860636...
Checkpoint 165860636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,321.89849
Policy Entropy: 1.06837
Value Function Loss: 0.10019

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09884
Policy Update Magnitude: 0.34849
Value Function Update Magnitude: 0.62191

Collected Steps per Second: 21,064.47652
Overall Steps per Second: 10,312.61174

Timestep Collection Time: 2.37490
Timestep Consumption Time: 2.47605
PPO Batch Consumption Time: 0.30108
Total Iteration Time: 4.85095

Cumulative Model Updates: 19,884
Cumulative Timesteps: 165,910,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.36520
Policy Entropy: 1.06242
Value Function Loss: 0.10034

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.34198
Value Function Update Magnitude: 0.68692

Collected Steps per Second: 21,395.36981
Overall Steps per Second: 10,272.69473

Timestep Collection Time: 2.33752
Timestep Consumption Time: 2.53093
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.86844

Cumulative Model Updates: 19,890
Cumulative Timesteps: 165,960,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 165960674...
Checkpoint 165960674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,790.90284
Policy Entropy: 1.05867
Value Function Loss: 0.09519

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07633
Policy Update Magnitude: 0.34705
Value Function Update Magnitude: 0.76133

Collected Steps per Second: 20,989.52173
Overall Steps per Second: 10,125.20781

Timestep Collection Time: 2.38338
Timestep Consumption Time: 2.55736
PPO Batch Consumption Time: 0.30367
Total Iteration Time: 4.94074

Cumulative Model Updates: 19,896
Cumulative Timesteps: 166,010,700

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,648.04913
Policy Entropy: 1.06078
Value Function Loss: 0.09572

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09044
Policy Update Magnitude: 0.36608
Value Function Update Magnitude: 0.77676

Collected Steps per Second: 21,386.34732
Overall Steps per Second: 10,219.34500

Timestep Collection Time: 2.33822
Timestep Consumption Time: 2.55505
PPO Batch Consumption Time: 0.30219
Total Iteration Time: 4.89327

Cumulative Model Updates: 19,902
Cumulative Timesteps: 166,060,706

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 166060706...
Checkpoint 166060706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,283.82629
Policy Entropy: 1.06646
Value Function Loss: 0.09410

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.36773
Value Function Update Magnitude: 0.78301

Collected Steps per Second: 20,881.85708
Overall Steps per Second: 10,173.35791

Timestep Collection Time: 2.39548
Timestep Consumption Time: 2.52148
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.91696

Cumulative Model Updates: 19,908
Cumulative Timesteps: 166,110,728

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,548.10683
Policy Entropy: 1.06951
Value Function Loss: 0.09396

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.34585
Value Function Update Magnitude: 0.78505

Collected Steps per Second: 21,539.73488
Overall Steps per Second: 10,100.97664

Timestep Collection Time: 2.32194
Timestep Consumption Time: 2.62946
PPO Batch Consumption Time: 0.31550
Total Iteration Time: 4.95140

Cumulative Model Updates: 19,914
Cumulative Timesteps: 166,160,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 166160742...
Checkpoint 166160742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,805.38651
Policy Entropy: 1.07037
Value Function Loss: 0.09942

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.31348
Value Function Update Magnitude: 0.67697

Collected Steps per Second: 21,265.28894
Overall Steps per Second: 10,036.94038

Timestep Collection Time: 2.35200
Timestep Consumption Time: 2.63119
PPO Batch Consumption Time: 0.30844
Total Iteration Time: 4.98319

Cumulative Model Updates: 19,920
Cumulative Timesteps: 166,210,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,248.77055
Policy Entropy: 1.06269
Value Function Loss: 0.09950

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.34264
Value Function Update Magnitude: 0.62108

Collected Steps per Second: 21,284.22327
Overall Steps per Second: 10,166.35612

Timestep Collection Time: 2.35151
Timestep Consumption Time: 2.57159
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.92310

Cumulative Model Updates: 19,926
Cumulative Timesteps: 166,260,808

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 166260808...
Checkpoint 166260808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,996.49985
Policy Entropy: 1.06064
Value Function Loss: 0.10125

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.36301
Value Function Update Magnitude: 0.59281

Collected Steps per Second: 20,792.79279
Overall Steps per Second: 10,038.08439

Timestep Collection Time: 2.40526
Timestep Consumption Time: 2.57697
PPO Batch Consumption Time: 0.30614
Total Iteration Time: 4.98223

Cumulative Model Updates: 19,932
Cumulative Timesteps: 166,310,820

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,297.43282
Policy Entropy: 1.06905
Value Function Loss: 0.09941

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.35602
Value Function Update Magnitude: 0.59293

Collected Steps per Second: 21,149.42739
Overall Steps per Second: 10,019.26796

Timestep Collection Time: 2.36631
Timestep Consumption Time: 2.62867
PPO Batch Consumption Time: 0.30870
Total Iteration Time: 4.99498

Cumulative Model Updates: 19,938
Cumulative Timesteps: 166,360,866

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 166360866...
Checkpoint 166360866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.93755
Policy Entropy: 1.06940
Value Function Loss: 0.10173

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.36637
Value Function Update Magnitude: 0.55593

Collected Steps per Second: 20,710.73387
Overall Steps per Second: 9,954.11421

Timestep Collection Time: 2.41440
Timestep Consumption Time: 2.60905
PPO Batch Consumption Time: 0.30882
Total Iteration Time: 5.02345

Cumulative Model Updates: 19,944
Cumulative Timesteps: 166,410,870

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,568.67536
Policy Entropy: 1.07859
Value Function Loss: 0.09881

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08732
Policy Update Magnitude: 0.37344
Value Function Update Magnitude: 0.57952

Collected Steps per Second: 21,608.00079
Overall Steps per Second: 10,191.77700

Timestep Collection Time: 2.31442
Timestep Consumption Time: 2.59248
PPO Batch Consumption Time: 0.31055
Total Iteration Time: 4.90690

Cumulative Model Updates: 19,950
Cumulative Timesteps: 166,460,880

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 166460880...
Checkpoint 166460880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,767.94364
Policy Entropy: 1.06584
Value Function Loss: 0.09571

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09567
Policy Update Magnitude: 0.36446
Value Function Update Magnitude: 0.66249

Collected Steps per Second: 20,694.43773
Overall Steps per Second: 9,958.60446

Timestep Collection Time: 2.41640
Timestep Consumption Time: 2.60499
PPO Batch Consumption Time: 0.30786
Total Iteration Time: 5.02139

Cumulative Model Updates: 19,956
Cumulative Timesteps: 166,510,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,969.71229
Policy Entropy: 1.06439
Value Function Loss: 0.09349

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.34997
Value Function Update Magnitude: 0.75152

Collected Steps per Second: 21,038.05865
Overall Steps per Second: 10,022.24959

Timestep Collection Time: 2.37817
Timestep Consumption Time: 2.61393
PPO Batch Consumption Time: 0.30625
Total Iteration Time: 4.99209

Cumulative Model Updates: 19,962
Cumulative Timesteps: 166,560,918

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 166560918...
Checkpoint 166560918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,501.25378
Policy Entropy: 1.06223
Value Function Loss: 0.09350

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09803
Policy Update Magnitude: 0.36027
Value Function Update Magnitude: 0.79133

Collected Steps per Second: 21,296.92942
Overall Steps per Second: 10,180.31508

Timestep Collection Time: 2.34785
Timestep Consumption Time: 2.56379
PPO Batch Consumption Time: 0.30511
Total Iteration Time: 4.91164

Cumulative Model Updates: 19,968
Cumulative Timesteps: 166,610,920

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,208.33804
Policy Entropy: 1.06493
Value Function Loss: 0.10259

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09610
Policy Update Magnitude: 0.36689
Value Function Update Magnitude: 0.81284

Collected Steps per Second: 21,762.63508
Overall Steps per Second: 10,298.90906

Timestep Collection Time: 2.29834
Timestep Consumption Time: 2.55829
PPO Batch Consumption Time: 0.30023
Total Iteration Time: 4.85663

Cumulative Model Updates: 19,974
Cumulative Timesteps: 166,660,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 166660938...
Checkpoint 166660938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,222.33097
Policy Entropy: 1.07201
Value Function Loss: 0.10225

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 0.36194
Value Function Update Magnitude: 0.82757

Collected Steps per Second: 21,186.39312
Overall Steps per Second: 10,224.58714

Timestep Collection Time: 2.36133
Timestep Consumption Time: 2.53158
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.89291

Cumulative Model Updates: 19,980
Cumulative Timesteps: 166,710,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,010.58272
Policy Entropy: 1.07847
Value Function Loss: 0.10553

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.34066
Value Function Update Magnitude: 0.81564

Collected Steps per Second: 21,146.92743
Overall Steps per Second: 10,040.35329

Timestep Collection Time: 2.36554
Timestep Consumption Time: 2.61675
PPO Batch Consumption Time: 0.31323
Total Iteration Time: 4.98229

Cumulative Model Updates: 19,986
Cumulative Timesteps: 166,760,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 166760990...
Checkpoint 166760990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,788.83412
Policy Entropy: 1.07713
Value Function Loss: 0.10104

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10669
Policy Update Magnitude: 0.36933
Value Function Update Magnitude: 0.72403

Collected Steps per Second: 20,729.69968
Overall Steps per Second: 9,929.39093

Timestep Collection Time: 2.41335
Timestep Consumption Time: 2.62503
PPO Batch Consumption Time: 0.31027
Total Iteration Time: 5.03838

Cumulative Model Updates: 19,992
Cumulative Timesteps: 166,811,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,973.10838
Policy Entropy: 1.08000
Value Function Loss: 0.10356

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.38242
Value Function Update Magnitude: 0.64972

Collected Steps per Second: 21,300.96203
Overall Steps per Second: 10,296.95321

Timestep Collection Time: 2.34759
Timestep Consumption Time: 2.50879
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.85639

Cumulative Model Updates: 19,998
Cumulative Timesteps: 166,861,024

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 166861024...
Checkpoint 166861024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.54164
Policy Entropy: 1.07945
Value Function Loss: 0.09907

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.37206
Value Function Update Magnitude: 0.62655

Collected Steps per Second: 21,070.36849
Overall Steps per Second: 10,063.76993

Timestep Collection Time: 2.37423
Timestep Consumption Time: 2.59667
PPO Batch Consumption Time: 0.30805
Total Iteration Time: 4.97090

Cumulative Model Updates: 20,004
Cumulative Timesteps: 166,911,050

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,689.68986
Policy Entropy: 1.07554
Value Function Loss: 0.10295

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14868
Policy Update Magnitude: 0.32200
Value Function Update Magnitude: 0.59791

Collected Steps per Second: 21,494.82832
Overall Steps per Second: 10,111.45945

Timestep Collection Time: 2.32791
Timestep Consumption Time: 2.62073
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.94864

Cumulative Model Updates: 20,010
Cumulative Timesteps: 166,961,088

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 166961088...
Checkpoint 166961088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,092.83739
Policy Entropy: 1.06245
Value Function Loss: 0.09585

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.31128
Value Function Update Magnitude: 0.66814

Collected Steps per Second: 20,746.12628
Overall Steps per Second: 10,121.68795

Timestep Collection Time: 2.41057
Timestep Consumption Time: 2.53031
PPO Batch Consumption Time: 0.30542
Total Iteration Time: 4.94088

Cumulative Model Updates: 20,016
Cumulative Timesteps: 167,011,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,906.51603
Policy Entropy: 1.07133
Value Function Loss: 0.09975

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.31826
Value Function Update Magnitude: 0.62074

Collected Steps per Second: 21,319.43208
Overall Steps per Second: 10,201.26052

Timestep Collection Time: 2.34584
Timestep Consumption Time: 2.55669
PPO Batch Consumption Time: 0.30139
Total Iteration Time: 4.90253

Cumulative Model Updates: 20,022
Cumulative Timesteps: 167,061,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 167061110...
Checkpoint 167061110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,821.03635
Policy Entropy: 1.06601
Value Function Loss: 0.09799

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.35009
Value Function Update Magnitude: 0.53460

Collected Steps per Second: 20,534.74826
Overall Steps per Second: 9,965.49926

Timestep Collection Time: 2.43607
Timestep Consumption Time: 2.58365
PPO Batch Consumption Time: 0.30739
Total Iteration Time: 5.01972

Cumulative Model Updates: 20,028
Cumulative Timesteps: 167,111,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,383.56922
Policy Entropy: 1.05725
Value Function Loss: 0.10382

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.14701
Policy Update Magnitude: 0.33319
Value Function Update Magnitude: 0.53720

Collected Steps per Second: 21,257.97280
Overall Steps per Second: 10,244.88558

Timestep Collection Time: 2.35262
Timestep Consumption Time: 2.52903
PPO Batch Consumption Time: 0.29768
Total Iteration Time: 4.88166

Cumulative Model Updates: 20,034
Cumulative Timesteps: 167,161,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 167161146...
Checkpoint 167161146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,170.61793
Policy Entropy: 1.05704
Value Function Loss: 0.10234

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.30060
Value Function Update Magnitude: 0.55770

Collected Steps per Second: 21,307.08563
Overall Steps per Second: 10,070.34484

Timestep Collection Time: 2.34748
Timestep Consumption Time: 2.61938
PPO Batch Consumption Time: 0.30989
Total Iteration Time: 4.96686

Cumulative Model Updates: 20,040
Cumulative Timesteps: 167,211,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,782.97079
Policy Entropy: 1.06095
Value Function Loss: 0.09991

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.28185
Value Function Update Magnitude: 0.63181

Collected Steps per Second: 21,585.33709
Overall Steps per Second: 10,228.74871

Timestep Collection Time: 2.31694
Timestep Consumption Time: 2.57241
PPO Batch Consumption Time: 0.30449
Total Iteration Time: 4.88936

Cumulative Model Updates: 20,046
Cumulative Timesteps: 167,261,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 167261176...
Checkpoint 167261176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,225.17418
Policy Entropy: 1.07410
Value Function Loss: 0.09836

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.26718
Value Function Update Magnitude: 0.61556

Collected Steps per Second: 20,870.18316
Overall Steps per Second: 10,107.98407

Timestep Collection Time: 2.39672
Timestep Consumption Time: 2.55184
PPO Batch Consumption Time: 0.30019
Total Iteration Time: 4.94856

Cumulative Model Updates: 20,052
Cumulative Timesteps: 167,311,196

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,742.31203
Policy Entropy: 1.07329
Value Function Loss: 0.09482

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.27146
Value Function Update Magnitude: 0.57968

Collected Steps per Second: 21,399.73824
Overall Steps per Second: 10,018.94405

Timestep Collection Time: 2.33825
Timestep Consumption Time: 2.65609
PPO Batch Consumption Time: 0.31874
Total Iteration Time: 4.99434

Cumulative Model Updates: 20,058
Cumulative Timesteps: 167,361,234

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 167361234...
Checkpoint 167361234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,265.33244
Policy Entropy: 1.08229
Value Function Loss: 0.09799

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.30317
Value Function Update Magnitude: 0.59218

Collected Steps per Second: 21,333.92577
Overall Steps per Second: 10,274.83237

Timestep Collection Time: 2.34603
Timestep Consumption Time: 2.52510
PPO Batch Consumption Time: 0.30547
Total Iteration Time: 4.87113

Cumulative Model Updates: 20,064
Cumulative Timesteps: 167,411,284

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,448.11948
Policy Entropy: 1.08682
Value Function Loss: 0.09727

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.33920
Value Function Update Magnitude: 0.57008

Collected Steps per Second: 21,320.09695
Overall Steps per Second: 10,007.71324

Timestep Collection Time: 2.34755
Timestep Consumption Time: 2.65359
PPO Batch Consumption Time: 0.32076
Total Iteration Time: 5.00114

Cumulative Model Updates: 20,070
Cumulative Timesteps: 167,461,334

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 167461334...
Checkpoint 167461334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,756.77512
Policy Entropy: 1.07870
Value Function Loss: 0.10181

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10769
Policy Update Magnitude: 0.37582
Value Function Update Magnitude: 0.54154

Collected Steps per Second: 21,148.77504
Overall Steps per Second: 10,175.06321

Timestep Collection Time: 2.36487
Timestep Consumption Time: 2.55049
PPO Batch Consumption Time: 0.30207
Total Iteration Time: 4.91535

Cumulative Model Updates: 20,076
Cumulative Timesteps: 167,511,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,380.34354
Policy Entropy: 1.08029
Value Function Loss: 0.09524

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09166
Policy Update Magnitude: 0.36234
Value Function Update Magnitude: 0.52786

Collected Steps per Second: 20,630.75722
Overall Steps per Second: 9,983.19763

Timestep Collection Time: 2.42376
Timestep Consumption Time: 2.58506
PPO Batch Consumption Time: 0.30409
Total Iteration Time: 5.00882

Cumulative Model Updates: 20,082
Cumulative Timesteps: 167,561,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 167561352...
Checkpoint 167561352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,050.98174
Policy Entropy: 1.08025
Value Function Loss: 0.09814

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.33932
Value Function Update Magnitude: 0.59206

Collected Steps per Second: 20,541.80731
Overall Steps per Second: 9,864.14235

Timestep Collection Time: 2.43513
Timestep Consumption Time: 2.63596
PPO Batch Consumption Time: 0.31452
Total Iteration Time: 5.07109

Cumulative Model Updates: 20,088
Cumulative Timesteps: 167,611,374

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,484.01363
Policy Entropy: 1.07436
Value Function Loss: 0.09734

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12345
Policy Update Magnitude: 0.30693
Value Function Update Magnitude: 0.56140

Collected Steps per Second: 21,087.23852
Overall Steps per Second: 10,144.75962

Timestep Collection Time: 2.37129
Timestep Consumption Time: 2.55776
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.92905

Cumulative Model Updates: 20,094
Cumulative Timesteps: 167,661,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 167661378...
Checkpoint 167661378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,211.98151
Policy Entropy: 1.08638
Value Function Loss: 0.09962

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.34098
Value Function Update Magnitude: 0.56384

Collected Steps per Second: 20,613.07139
Overall Steps per Second: 10,137.43139

Timestep Collection Time: 2.42710
Timestep Consumption Time: 2.50807
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.93518

Cumulative Model Updates: 20,100
Cumulative Timesteps: 167,711,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,561.68894
Policy Entropy: 1.08920
Value Function Loss: 0.09779

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.35516
Value Function Update Magnitude: 0.58840

Collected Steps per Second: 21,364.18749
Overall Steps per Second: 10,002.80485

Timestep Collection Time: 2.34065
Timestep Consumption Time: 2.65855
PPO Batch Consumption Time: 0.32042
Total Iteration Time: 4.99920

Cumulative Model Updates: 20,106
Cumulative Timesteps: 167,761,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 167761414...
Checkpoint 167761414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.15784
Policy Entropy: 1.08859
Value Function Loss: 0.10226

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09873
Policy Update Magnitude: 0.36196
Value Function Update Magnitude: 0.59000

Collected Steps per Second: 20,523.30024
Overall Steps per Second: 9,875.80103

Timestep Collection Time: 2.43655
Timestep Consumption Time: 2.62694
PPO Batch Consumption Time: 0.31774
Total Iteration Time: 5.06349

Cumulative Model Updates: 20,112
Cumulative Timesteps: 167,811,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.38247
Policy Entropy: 1.07126
Value Function Loss: 0.10427

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.34927
Value Function Update Magnitude: 0.57278

Collected Steps per Second: 21,014.72468
Overall Steps per Second: 9,932.94922

Timestep Collection Time: 2.38024
Timestep Consumption Time: 2.65553
PPO Batch Consumption Time: 0.31615
Total Iteration Time: 5.03577

Cumulative Model Updates: 20,118
Cumulative Timesteps: 167,861,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 167861440...
Checkpoint 167861440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,369.37925
Policy Entropy: 1.07303
Value Function Loss: 0.10438

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.14253
Policy Update Magnitude: 0.32398
Value Function Update Magnitude: 0.56782

Collected Steps per Second: 20,729.33426
Overall Steps per Second: 9,999.97200

Timestep Collection Time: 2.41204
Timestep Consumption Time: 2.58797
PPO Batch Consumption Time: 0.31020
Total Iteration Time: 5.00001

Cumulative Model Updates: 20,124
Cumulative Timesteps: 167,911,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,009.80159
Policy Entropy: 1.08053
Value Function Loss: 0.10194

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.11945
Policy Update Magnitude: 0.33075
Value Function Update Magnitude: 0.56125

Collected Steps per Second: 21,129.84947
Overall Steps per Second: 10,014.88323

Timestep Collection Time: 2.36831
Timestep Consumption Time: 2.62845
PPO Batch Consumption Time: 0.31328
Total Iteration Time: 4.99676

Cumulative Model Updates: 20,130
Cumulative Timesteps: 167,961,482

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 167961482...
Checkpoint 167961482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,457.45413
Policy Entropy: 1.08537
Value Function Loss: 0.10064

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.12093
Policy Update Magnitude: 0.32714
Value Function Update Magnitude: 0.57698

Collected Steps per Second: 20,784.56884
Overall Steps per Second: 10,124.99952

Timestep Collection Time: 2.40582
Timestep Consumption Time: 2.53284
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.93867

Cumulative Model Updates: 20,136
Cumulative Timesteps: 168,011,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,722.23826
Policy Entropy: 1.10079
Value Function Loss: 0.10052

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11253
Policy Update Magnitude: 0.33121
Value Function Update Magnitude: 0.57360

Collected Steps per Second: 21,277.73247
Overall Steps per Second: 9,977.24016

Timestep Collection Time: 2.35091
Timestep Consumption Time: 2.66270
PPO Batch Consumption Time: 0.31917
Total Iteration Time: 5.01361

Cumulative Model Updates: 20,142
Cumulative Timesteps: 168,061,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 168061508...
Checkpoint 168061508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,204.18939
Policy Entropy: 1.09537
Value Function Loss: 0.09841

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.34250
Value Function Update Magnitude: 0.56712

Collected Steps per Second: 20,894.99912
Overall Steps per Second: 10,158.18523

Timestep Collection Time: 2.39311
Timestep Consumption Time: 2.52942
PPO Batch Consumption Time: 0.30825
Total Iteration Time: 4.92253

Cumulative Model Updates: 20,148
Cumulative Timesteps: 168,111,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,163.76141
Policy Entropy: 1.10287
Value Function Loss: 0.09533

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.32978
Value Function Update Magnitude: 0.67765

Collected Steps per Second: 21,194.29334
Overall Steps per Second: 9,916.96564

Timestep Collection Time: 2.35913
Timestep Consumption Time: 2.68274
PPO Batch Consumption Time: 0.31587
Total Iteration Time: 5.04186

Cumulative Model Updates: 20,154
Cumulative Timesteps: 168,161,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 168161512...
Checkpoint 168161512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,433.66148
Policy Entropy: 1.10106
Value Function Loss: 0.08877

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.32794
Value Function Update Magnitude: 0.71448

Collected Steps per Second: 21,534.39728
Overall Steps per Second: 10,238.08795

Timestep Collection Time: 2.32261
Timestep Consumption Time: 2.56268
PPO Batch Consumption Time: 0.30840
Total Iteration Time: 4.88529

Cumulative Model Updates: 20,160
Cumulative Timesteps: 168,211,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,663.05133
Policy Entropy: 1.10172
Value Function Loss: 0.08936

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.31384
Value Function Update Magnitude: 0.69177

Collected Steps per Second: 21,325.24751
Overall Steps per Second: 10,234.38104

Timestep Collection Time: 2.34511
Timestep Consumption Time: 2.54136
PPO Batch Consumption Time: 0.29706
Total Iteration Time: 4.88647

Cumulative Model Updates: 20,166
Cumulative Timesteps: 168,261,538

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 168261538...
Checkpoint 168261538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,560.50692
Policy Entropy: 1.09887
Value Function Loss: 0.08711

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12142
Policy Update Magnitude: 0.28140
Value Function Update Magnitude: 0.70153

Collected Steps per Second: 21,179.61474
Overall Steps per Second: 10,266.61294

Timestep Collection Time: 2.36293
Timestep Consumption Time: 2.51170
PPO Batch Consumption Time: 0.30704
Total Iteration Time: 4.87464

Cumulative Model Updates: 20,172
Cumulative Timesteps: 168,311,584

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,944.29098
Policy Entropy: 1.10537
Value Function Loss: 0.08933

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.30475
Value Function Update Magnitude: 0.68024

Collected Steps per Second: 21,481.14011
Overall Steps per Second: 10,217.19367

Timestep Collection Time: 2.32958
Timestep Consumption Time: 2.56824
PPO Batch Consumption Time: 0.30402
Total Iteration Time: 4.89782

Cumulative Model Updates: 20,178
Cumulative Timesteps: 168,361,626

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 168361626...
Checkpoint 168361626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,584.58266
Policy Entropy: 1.10210
Value Function Loss: 0.09258

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10542
Policy Update Magnitude: 0.33742
Value Function Update Magnitude: 0.55631

Collected Steps per Second: 21,212.28137
Overall Steps per Second: 9,970.24418

Timestep Collection Time: 2.35750
Timestep Consumption Time: 2.65822
PPO Batch Consumption Time: 0.32176
Total Iteration Time: 5.01572

Cumulative Model Updates: 20,184
Cumulative Timesteps: 168,411,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,639.08654
Policy Entropy: 1.09647
Value Function Loss: 0.09894

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13364
Policy Update Magnitude: 0.30877
Value Function Update Magnitude: 0.55154

Collected Steps per Second: 21,289.63881
Overall Steps per Second: 9,946.14269

Timestep Collection Time: 2.34950
Timestep Consumption Time: 2.67959
PPO Batch Consumption Time: 0.32038
Total Iteration Time: 5.02909

Cumulative Model Updates: 20,190
Cumulative Timesteps: 168,461,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 168461654...
Checkpoint 168461654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,511.03371
Policy Entropy: 1.08876
Value Function Loss: 0.09820

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.25528
Value Function Update Magnitude: 0.58251

Collected Steps per Second: 21,395.67622
Overall Steps per Second: 10,279.61413

Timestep Collection Time: 2.33879
Timestep Consumption Time: 2.52910
PPO Batch Consumption Time: 0.30542
Total Iteration Time: 4.86789

Cumulative Model Updates: 20,196
Cumulative Timesteps: 168,511,694

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,330.51614
Policy Entropy: 1.08267
Value Function Loss: 0.09403

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.25440
Value Function Update Magnitude: 0.58968

Collected Steps per Second: 21,302.27971
Overall Steps per Second: 9,995.77572

Timestep Collection Time: 2.34735
Timestep Consumption Time: 2.65516
PPO Batch Consumption Time: 0.30966
Total Iteration Time: 5.00251

Cumulative Model Updates: 20,202
Cumulative Timesteps: 168,561,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 168561698...
Checkpoint 168561698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,944.00714
Policy Entropy: 1.08791
Value Function Loss: 0.08854

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09329
Policy Update Magnitude: 0.29606
Value Function Update Magnitude: 0.60514

Collected Steps per Second: 21,007.58983
Overall Steps per Second: 10,003.94133

Timestep Collection Time: 2.38095
Timestep Consumption Time: 2.61888
PPO Batch Consumption Time: 0.31397
Total Iteration Time: 4.99983

Cumulative Model Updates: 20,208
Cumulative Timesteps: 168,611,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,714.34181
Policy Entropy: 1.08507
Value Function Loss: 0.08502

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09803
Policy Update Magnitude: 0.31234
Value Function Update Magnitude: 0.68972

Collected Steps per Second: 21,386.74139
Overall Steps per Second: 10,217.75753

Timestep Collection Time: 2.33808
Timestep Consumption Time: 2.55575
PPO Batch Consumption Time: 0.30183
Total Iteration Time: 4.89383

Cumulative Model Updates: 20,214
Cumulative Timesteps: 168,661,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 168661720...
Checkpoint 168661720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,979.15069
Policy Entropy: 1.09457
Value Function Loss: 0.08638

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.28296
Value Function Update Magnitude: 0.68997

Collected Steps per Second: 21,074.01020
Overall Steps per Second: 10,070.42208

Timestep Collection Time: 2.37335
Timestep Consumption Time: 2.59327
PPO Batch Consumption Time: 0.30712
Total Iteration Time: 4.96662

Cumulative Model Updates: 20,220
Cumulative Timesteps: 168,711,736

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,242.55051
Policy Entropy: 1.09085
Value Function Loss: 0.08760

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11805
Policy Update Magnitude: 0.25537
Value Function Update Magnitude: 0.68890

Collected Steps per Second: 21,353.87146
Overall Steps per Second: 10,078.05275

Timestep Collection Time: 2.34356
Timestep Consumption Time: 2.62209
PPO Batch Consumption Time: 0.30080
Total Iteration Time: 4.96564

Cumulative Model Updates: 20,226
Cumulative Timesteps: 168,761,780

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 168761780...
Checkpoint 168761780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,294.51747
Policy Entropy: 1.09387
Value Function Loss: 0.09195

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11046
Policy Update Magnitude: 0.26786
Value Function Update Magnitude: 0.74106

Collected Steps per Second: 21,321.33337
Overall Steps per Second: 10,420.44045

Timestep Collection Time: 2.34516
Timestep Consumption Time: 2.45329
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.79845

Cumulative Model Updates: 20,232
Cumulative Timesteps: 168,811,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,379.40246
Policy Entropy: 1.08690
Value Function Loss: 0.09177

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.27786
Value Function Update Magnitude: 0.74116

Collected Steps per Second: 21,267.46601
Overall Steps per Second: 10,146.05769

Timestep Collection Time: 2.35308
Timestep Consumption Time: 2.57928
PPO Batch Consumption Time: 0.30711
Total Iteration Time: 4.93236

Cumulative Model Updates: 20,238
Cumulative Timesteps: 168,861,826

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 168861826...
Checkpoint 168861826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,162.83562
Policy Entropy: 1.08807
Value Function Loss: 0.09287

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.28454
Value Function Update Magnitude: 0.68884

Collected Steps per Second: 21,269.55991
Overall Steps per Second: 10,227.42696

Timestep Collection Time: 2.35209
Timestep Consumption Time: 2.53946
PPO Batch Consumption Time: 0.31110
Total Iteration Time: 4.89155

Cumulative Model Updates: 20,244
Cumulative Timesteps: 168,911,854

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,360.49057
Policy Entropy: 1.08771
Value Function Loss: 0.09301

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.12205
Policy Update Magnitude: 0.31283
Value Function Update Magnitude: 0.77799

Collected Steps per Second: 21,170.03925
Overall Steps per Second: 10,018.83493

Timestep Collection Time: 2.36325
Timestep Consumption Time: 2.63035
PPO Batch Consumption Time: 0.31522
Total Iteration Time: 4.99359

Cumulative Model Updates: 20,250
Cumulative Timesteps: 168,961,884

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 168961884...
Checkpoint 168961884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,632.40328
Policy Entropy: 1.08075
Value Function Loss: 0.09403

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.14661
Policy Update Magnitude: 0.30148
Value Function Update Magnitude: 0.78343

Collected Steps per Second: 20,360.29550
Overall Steps per Second: 9,959.77405

Timestep Collection Time: 2.45694
Timestep Consumption Time: 2.56567
PPO Batch Consumption Time: 0.30243
Total Iteration Time: 5.02260

Cumulative Model Updates: 20,256
Cumulative Timesteps: 169,011,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,625.34066
Policy Entropy: 1.07708
Value Function Loss: 0.09199

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.15474
Policy Update Magnitude: 0.28760
Value Function Update Magnitude: 0.75796

Collected Steps per Second: 21,163.85283
Overall Steps per Second: 10,219.92388

Timestep Collection Time: 2.36365
Timestep Consumption Time: 2.53110
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.89475

Cumulative Model Updates: 20,262
Cumulative Timesteps: 169,061,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 169061932...
Checkpoint 169061932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,569.94673
Policy Entropy: 1.07979
Value Function Loss: 0.09167

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.15124
Policy Update Magnitude: 0.28141
Value Function Update Magnitude: 0.74641

Collected Steps per Second: 21,291.56994
Overall Steps per Second: 10,394.44761

Timestep Collection Time: 2.34900
Timestep Consumption Time: 2.46260
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.81161

Cumulative Model Updates: 20,268
Cumulative Timesteps: 169,111,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,023.27033
Policy Entropy: 1.08764
Value Function Loss: 0.08802

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.28986
Value Function Update Magnitude: 0.71087

Collected Steps per Second: 21,558.39409
Overall Steps per Second: 10,248.23463

Timestep Collection Time: 2.31965
Timestep Consumption Time: 2.56002
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.87967

Cumulative Model Updates: 20,274
Cumulative Timesteps: 169,161,954

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 169161954...
Checkpoint 169161954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,523.96150
Policy Entropy: 1.08939
Value Function Loss: 0.08606

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12653
Policy Update Magnitude: 0.29366
Value Function Update Magnitude: 0.70565

Collected Steps per Second: 20,916.01506
Overall Steps per Second: 9,893.08199

Timestep Collection Time: 2.39090
Timestep Consumption Time: 2.66395
PPO Batch Consumption Time: 0.31527
Total Iteration Time: 5.05485

Cumulative Model Updates: 20,280
Cumulative Timesteps: 169,211,962

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,835.84445
Policy Entropy: 1.09154
Value Function Loss: 0.09026

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.14876
Policy Update Magnitude: 0.29111
Value Function Update Magnitude: 0.66522

Collected Steps per Second: 21,005.74873
Overall Steps per Second: 9,895.99625

Timestep Collection Time: 2.38049
Timestep Consumption Time: 2.67246
PPO Batch Consumption Time: 0.32220
Total Iteration Time: 5.05295

Cumulative Model Updates: 20,286
Cumulative Timesteps: 169,261,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 169261966...
Checkpoint 169261966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,692.79192
Policy Entropy: 1.10676
Value Function Loss: 0.09108

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.14922
Policy Update Magnitude: 0.29785
Value Function Update Magnitude: 0.60698

Collected Steps per Second: 21,239.69844
Overall Steps per Second: 10,211.81411

Timestep Collection Time: 2.35559
Timestep Consumption Time: 2.54383
PPO Batch Consumption Time: 0.30902
Total Iteration Time: 4.89942

Cumulative Model Updates: 20,292
Cumulative Timesteps: 169,311,998

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,645.38338
Policy Entropy: 1.11283
Value Function Loss: 0.09270

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.33390
Value Function Update Magnitude: 0.64174

Collected Steps per Second: 20,969.40862
Overall Steps per Second: 9,907.90487

Timestep Collection Time: 2.38671
Timestep Consumption Time: 2.66461
PPO Batch Consumption Time: 0.30889
Total Iteration Time: 5.05132

Cumulative Model Updates: 20,298
Cumulative Timesteps: 169,362,046

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 169362046...
Checkpoint 169362046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,978.95944
Policy Entropy: 1.11548
Value Function Loss: 0.09111

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09940
Policy Update Magnitude: 0.36411
Value Function Update Magnitude: 0.65141

Collected Steps per Second: 20,760.26715
Overall Steps per Second: 9,901.48960

Timestep Collection Time: 2.40883
Timestep Consumption Time: 2.64172
PPO Batch Consumption Time: 0.31478
Total Iteration Time: 5.05055

Cumulative Model Updates: 20,304
Cumulative Timesteps: 169,412,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,923.62056
Policy Entropy: 1.10922
Value Function Loss: 0.09233

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.36105
Value Function Update Magnitude: 0.71009

Collected Steps per Second: 21,171.80211
Overall Steps per Second: 9,963.43051

Timestep Collection Time: 2.36258
Timestep Consumption Time: 2.65778
PPO Batch Consumption Time: 0.31658
Total Iteration Time: 5.02036

Cumulative Model Updates: 20,310
Cumulative Timesteps: 169,462,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 169462074...
Checkpoint 169462074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,841.39645
Policy Entropy: 1.09761
Value Function Loss: 0.09196

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08368
Policy Update Magnitude: 0.36809
Value Function Update Magnitude: 0.71049

Collected Steps per Second: 21,212.90388
Overall Steps per Second: 10,259.65313

Timestep Collection Time: 2.35753
Timestep Consumption Time: 2.51691
PPO Batch Consumption Time: 0.30715
Total Iteration Time: 4.87443

Cumulative Model Updates: 20,316
Cumulative Timesteps: 169,512,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.84827
Policy Entropy: 1.09598
Value Function Loss: 0.09669

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.36502
Value Function Update Magnitude: 0.69559

Collected Steps per Second: 21,332.12379
Overall Steps per Second: 10,048.84907

Timestep Collection Time: 2.34491
Timestep Consumption Time: 2.63297
PPO Batch Consumption Time: 0.31284
Total Iteration Time: 4.97788

Cumulative Model Updates: 20,322
Cumulative Timesteps: 169,562,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 169562106...
Checkpoint 169562106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,080.67545
Policy Entropy: 1.08316
Value Function Loss: 0.10471

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.33047
Value Function Update Magnitude: 0.57930

Collected Steps per Second: 20,611.67588
Overall Steps per Second: 9,866.10222

Timestep Collection Time: 2.42659
Timestep Consumption Time: 2.64289
PPO Batch Consumption Time: 0.31680
Total Iteration Time: 5.06948

Cumulative Model Updates: 20,328
Cumulative Timesteps: 169,612,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,464.06849
Policy Entropy: 1.09271
Value Function Loss: 0.10535

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.34329
Value Function Update Magnitude: 0.53719

Collected Steps per Second: 21,657.31872
Overall Steps per Second: 10,095.65768

Timestep Collection Time: 2.30970
Timestep Consumption Time: 2.64510
PPO Batch Consumption Time: 0.31654
Total Iteration Time: 4.95480

Cumulative Model Updates: 20,334
Cumulative Timesteps: 169,662,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 169662144...
Checkpoint 169662144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,269.75300
Policy Entropy: 1.09726
Value Function Loss: 0.09831

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.34815
Value Function Update Magnitude: 0.55342

Collected Steps per Second: 17,393.08856
Overall Steps per Second: 9,146.66330

Timestep Collection Time: 2.87643
Timestep Consumption Time: 2.59332
PPO Batch Consumption Time: 0.31010
Total Iteration Time: 5.46975

Cumulative Model Updates: 20,340
Cumulative Timesteps: 169,712,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,445.14835
Policy Entropy: 1.10914
Value Function Loss: 0.09532

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.35126
Value Function Update Magnitude: 0.52739

Collected Steps per Second: 18,731.92983
Overall Steps per Second: 9,562.71107

Timestep Collection Time: 2.67073
Timestep Consumption Time: 2.56084
PPO Batch Consumption Time: 0.30004
Total Iteration Time: 5.23157

Cumulative Model Updates: 20,346
Cumulative Timesteps: 169,762,202

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 169762202...
Checkpoint 169762202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,407.36172
Policy Entropy: 1.10415
Value Function Loss: 0.09451

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.33861
Value Function Update Magnitude: 0.51659

Collected Steps per Second: 20,110.93138
Overall Steps per Second: 9,772.00924

Timestep Collection Time: 2.48711
Timestep Consumption Time: 2.63139
PPO Batch Consumption Time: 0.31096
Total Iteration Time: 5.11850

Cumulative Model Updates: 20,352
Cumulative Timesteps: 169,812,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,411.92058
Policy Entropy: 1.10856
Value Function Loss: 0.09856

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08372
Policy Update Magnitude: 0.35474
Value Function Update Magnitude: 0.51308

Collected Steps per Second: 19,731.17409
Overall Steps per Second: 9,818.10696

Timestep Collection Time: 2.53558
Timestep Consumption Time: 2.56011
PPO Batch Consumption Time: 0.30089
Total Iteration Time: 5.09569

Cumulative Model Updates: 20,358
Cumulative Timesteps: 169,862,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 169862250...
Checkpoint 169862250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,370.89688
Policy Entropy: 1.10159
Value Function Loss: 0.10311

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.34954
Value Function Update Magnitude: 0.50608

Collected Steps per Second: 17,533.70215
Overall Steps per Second: 9,140.74628

Timestep Collection Time: 2.85313
Timestep Consumption Time: 2.61972
PPO Batch Consumption Time: 0.30846
Total Iteration Time: 5.47286

Cumulative Model Updates: 20,364
Cumulative Timesteps: 169,912,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,539.68597
Policy Entropy: 1.11297
Value Function Loss: 0.10395

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.34807
Value Function Update Magnitude: 0.52741

Collected Steps per Second: 19,538.15483
Overall Steps per Second: 9,484.81232

Timestep Collection Time: 2.55991
Timestep Consumption Time: 2.71336
PPO Batch Consumption Time: 0.31614
Total Iteration Time: 5.27327

Cumulative Model Updates: 20,370
Cumulative Timesteps: 169,962,292

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 169962292...
Checkpoint 169962292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,969.53472
Policy Entropy: 1.10739
Value Function Loss: 0.10049

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07311
Policy Update Magnitude: 0.36958
Value Function Update Magnitude: 0.59991

Collected Steps per Second: 19,666.41257
Overall Steps per Second: 9,608.79048

Timestep Collection Time: 2.54322
Timestep Consumption Time: 2.66201
PPO Batch Consumption Time: 0.31657
Total Iteration Time: 5.20523

Cumulative Model Updates: 20,376
Cumulative Timesteps: 170,012,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,933.00473
Policy Entropy: 1.09634
Value Function Loss: 0.09864

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.37754
Value Function Update Magnitude: 0.58175

Collected Steps per Second: 16,159.99428
Overall Steps per Second: 8,389.82506

Timestep Collection Time: 3.09505
Timestep Consumption Time: 2.86646
PPO Batch Consumption Time: 0.30414
Total Iteration Time: 5.96151

Cumulative Model Updates: 20,382
Cumulative Timesteps: 170,062,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 170062324...
Checkpoint 170062324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,572.62823
Policy Entropy: 1.09611
Value Function Loss: 0.09383

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.35451
Value Function Update Magnitude: 0.56440

Collected Steps per Second: 14,263.50989
Overall Steps per Second: 6,416.77935

Timestep Collection Time: 3.50587
Timestep Consumption Time: 4.28714
PPO Batch Consumption Time: 0.58344
Total Iteration Time: 7.79301

Cumulative Model Updates: 20,388
Cumulative Timesteps: 170,112,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,856.96344
Policy Entropy: 1.10451
Value Function Loss: 0.09368

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.33466
Value Function Update Magnitude: 0.54434

Collected Steps per Second: 14,419.21986
Overall Steps per Second: 6,396.56680

Timestep Collection Time: 3.46829
Timestep Consumption Time: 4.34997
PPO Batch Consumption Time: 0.59458
Total Iteration Time: 7.81826

Cumulative Model Updates: 20,394
Cumulative Timesteps: 170,162,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 170162340...
Checkpoint 170162340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,532.91210
Policy Entropy: 1.10156
Value Function Loss: 0.09304

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.28338
Value Function Update Magnitude: 0.53225

Collected Steps per Second: 14,468.71988
Overall Steps per Second: 6,875.69732

Timestep Collection Time: 3.45697
Timestep Consumption Time: 3.81763
PPO Batch Consumption Time: 0.50478
Total Iteration Time: 7.27461

Cumulative Model Updates: 20,400
Cumulative Timesteps: 170,212,358

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,375.58721
Policy Entropy: 1.09613
Value Function Loss: 0.09616

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.29544
Value Function Update Magnitude: 0.52893

Collected Steps per Second: 15,323.80754
Overall Steps per Second: 7,165.46971

Timestep Collection Time: 3.26512
Timestep Consumption Time: 3.71754
PPO Batch Consumption Time: 0.49453
Total Iteration Time: 6.98265

Cumulative Model Updates: 20,406
Cumulative Timesteps: 170,262,392

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 170262392...
Checkpoint 170262392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,035.96756
Policy Entropy: 1.08399
Value Function Loss: 0.09828

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10641
Policy Update Magnitude: 0.34205
Value Function Update Magnitude: 0.52115

Collected Steps per Second: 14,444.28501
Overall Steps per Second: 6,517.20203

Timestep Collection Time: 3.46296
Timestep Consumption Time: 4.21211
PPO Batch Consumption Time: 0.57491
Total Iteration Time: 7.67507

Cumulative Model Updates: 20,412
Cumulative Timesteps: 170,312,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,407.34951
Policy Entropy: 1.07823
Value Function Loss: 0.09814

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09866
Policy Update Magnitude: 0.34542
Value Function Update Magnitude: 0.57893

Collected Steps per Second: 14,638.45827
Overall Steps per Second: 6,410.40408

Timestep Collection Time: 3.41593
Timestep Consumption Time: 4.38451
PPO Batch Consumption Time: 0.59647
Total Iteration Time: 7.80044

Cumulative Model Updates: 20,418
Cumulative Timesteps: 170,362,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 170362416...
Checkpoint 170362416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,627.44543
Policy Entropy: 1.07333
Value Function Loss: 0.09584

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.36011
Value Function Update Magnitude: 0.56203

Collected Steps per Second: 15,154.33859
Overall Steps per Second: 6,955.84770

Timestep Collection Time: 3.30136
Timestep Consumption Time: 3.89114
PPO Batch Consumption Time: 0.51677
Total Iteration Time: 7.19251

Cumulative Model Updates: 20,424
Cumulative Timesteps: 170,412,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,080.52444
Policy Entropy: 1.07311
Value Function Loss: 0.10196

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.35236
Value Function Update Magnitude: 0.56369

Collected Steps per Second: 15,432.91216
Overall Steps per Second: 6,660.56832

Timestep Collection Time: 3.24048
Timestep Consumption Time: 4.26789
PPO Batch Consumption Time: 0.58644
Total Iteration Time: 7.50837

Cumulative Model Updates: 20,430
Cumulative Timesteps: 170,462,456

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 170462456...
Checkpoint 170462456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,111.95299
Policy Entropy: 1.07378
Value Function Loss: 0.09924

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09266
Policy Update Magnitude: 0.35774
Value Function Update Magnitude: 0.60196

Collected Steps per Second: 14,663.93072
Overall Steps per Second: 6,450.49137

Timestep Collection Time: 3.41055
Timestep Consumption Time: 4.34266
PPO Batch Consumption Time: 0.59653
Total Iteration Time: 7.75321

Cumulative Model Updates: 20,436
Cumulative Timesteps: 170,512,468

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,346.97759
Policy Entropy: 1.07520
Value Function Loss: 0.09481

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.35065
Value Function Update Magnitude: 0.64531

Collected Steps per Second: 15,639.68340
Overall Steps per Second: 7,410.17737

Timestep Collection Time: 3.19930
Timestep Consumption Time: 3.55304
PPO Batch Consumption Time: 0.46696
Total Iteration Time: 6.75233

Cumulative Model Updates: 20,442
Cumulative Timesteps: 170,562,504

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 170562504...
Checkpoint 170562504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,688.66369
Policy Entropy: 1.06874
Value Function Loss: 0.09480

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.15008
Policy Update Magnitude: 0.30686
Value Function Update Magnitude: 0.61905

Collected Steps per Second: 15,439.51218
Overall Steps per Second: 7,094.82375

Timestep Collection Time: 3.23883
Timestep Consumption Time: 3.80940
PPO Batch Consumption Time: 0.50920
Total Iteration Time: 7.04824

Cumulative Model Updates: 20,448
Cumulative Timesteps: 170,612,510

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,037.92410
Policy Entropy: 1.06831
Value Function Loss: 0.09523

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.29412
Value Function Update Magnitude: 0.60357

Collected Steps per Second: 15,429.48628
Overall Steps per Second: 7,105.39383

Timestep Collection Time: 3.24120
Timestep Consumption Time: 3.79712
PPO Batch Consumption Time: 0.50242
Total Iteration Time: 7.03831

Cumulative Model Updates: 20,454
Cumulative Timesteps: 170,662,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 170662520...
Checkpoint 170662520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,849.54128
Policy Entropy: 1.07630
Value Function Loss: 0.09357

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.32045
Value Function Update Magnitude: 0.70958

Collected Steps per Second: 15,003.17945
Overall Steps per Second: 6,985.51167

Timestep Collection Time: 3.33423
Timestep Consumption Time: 3.82688
PPO Batch Consumption Time: 0.51108
Total Iteration Time: 7.16111

Cumulative Model Updates: 20,460
Cumulative Timesteps: 170,712,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,729.49451
Policy Entropy: 1.08216
Value Function Loss: 0.09211

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.36264
Value Function Update Magnitude: 0.75020

Collected Steps per Second: 15,359.16389
Overall Steps per Second: 7,172.59654

Timestep Collection Time: 3.25760
Timestep Consumption Time: 3.71812
PPO Batch Consumption Time: 0.49332
Total Iteration Time: 6.97572

Cumulative Model Updates: 20,466
Cumulative Timesteps: 170,762,578

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 170762578...
Checkpoint 170762578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,709.08047
Policy Entropy: 1.09626
Value Function Loss: 0.09233

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.35477
Value Function Update Magnitude: 0.70645

Collected Steps per Second: 15,114.24014
Overall Steps per Second: 7,083.66085

Timestep Collection Time: 3.30959
Timestep Consumption Time: 3.75201
PPO Batch Consumption Time: 0.50031
Total Iteration Time: 7.06160

Cumulative Model Updates: 20,472
Cumulative Timesteps: 170,812,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,322.95882
Policy Entropy: 1.08884
Value Function Loss: 0.09588

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.30523
Value Function Update Magnitude: 0.62018

Collected Steps per Second: 15,195.14907
Overall Steps per Second: 7,115.64789

Timestep Collection Time: 3.29289
Timestep Consumption Time: 3.73893
PPO Batch Consumption Time: 0.49632
Total Iteration Time: 7.03183

Cumulative Model Updates: 20,478
Cumulative Timesteps: 170,862,636

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 170862636...
Checkpoint 170862636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.69824
Policy Entropy: 1.08868
Value Function Loss: 0.09462

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.29237
Value Function Update Magnitude: 0.62530

Collected Steps per Second: 15,340.15521
Overall Steps per Second: 6,933.50919

Timestep Collection Time: 3.26072
Timestep Consumption Time: 3.95352
PPO Batch Consumption Time: 0.52990
Total Iteration Time: 7.21424

Cumulative Model Updates: 20,484
Cumulative Timesteps: 170,912,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,573.89191
Policy Entropy: 1.07726
Value Function Loss: 0.09136

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.31057
Value Function Update Magnitude: 0.70992

Collected Steps per Second: 14,583.13894
Overall Steps per Second: 6,541.29191

Timestep Collection Time: 3.42944
Timestep Consumption Time: 4.21614
PPO Batch Consumption Time: 0.56499
Total Iteration Time: 7.64558

Cumulative Model Updates: 20,490
Cumulative Timesteps: 170,962,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 170962668...
Checkpoint 170962668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,349.12609
Policy Entropy: 1.08603
Value Function Loss: 0.09069

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.32347
Value Function Update Magnitude: 0.69674

Collected Steps per Second: 15,194.33212
Overall Steps per Second: 7,043.03553

Timestep Collection Time: 3.29096
Timestep Consumption Time: 3.80882
PPO Batch Consumption Time: 0.50370
Total Iteration Time: 7.09978

Cumulative Model Updates: 20,496
Cumulative Timesteps: 171,012,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,826.69127
Policy Entropy: 1.08529
Value Function Loss: 0.09588

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.29554
Value Function Update Magnitude: 0.65473

Collected Steps per Second: 15,298.72701
Overall Steps per Second: 7,174.68994

Timestep Collection Time: 3.26877
Timestep Consumption Time: 3.70129
PPO Batch Consumption Time: 0.48990
Total Iteration Time: 6.97006

Cumulative Model Updates: 20,502
Cumulative Timesteps: 171,062,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 171062680...
Checkpoint 171062680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,624.09566
Policy Entropy: 1.09052
Value Function Loss: 0.09167

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.15074
Policy Update Magnitude: 0.28166
Value Function Update Magnitude: 0.70901

Collected Steps per Second: 15,017.48271
Overall Steps per Second: 6,657.97788

Timestep Collection Time: 3.33012
Timestep Consumption Time: 4.18117
PPO Batch Consumption Time: 0.57253
Total Iteration Time: 7.51129

Cumulative Model Updates: 20,508
Cumulative Timesteps: 171,112,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,854.62405
Policy Entropy: 1.09687
Value Function Loss: 0.09269

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.27616
Value Function Update Magnitude: 0.67376

Collected Steps per Second: 14,697.36697
Overall Steps per Second: 6,804.74536

Timestep Collection Time: 3.40387
Timestep Consumption Time: 3.94805
PPO Batch Consumption Time: 0.53150
Total Iteration Time: 7.35193

Cumulative Model Updates: 20,514
Cumulative Timesteps: 171,162,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 171162718...
Checkpoint 171162718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,823.96704
Policy Entropy: 1.09227
Value Function Loss: 0.09442

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.25331
Value Function Update Magnitude: 0.60365

Collected Steps per Second: 15,159.49883
Overall Steps per Second: 7,066.95532

Timestep Collection Time: 3.29839
Timestep Consumption Time: 3.77707
PPO Batch Consumption Time: 0.49979
Total Iteration Time: 7.07547

Cumulative Model Updates: 20,520
Cumulative Timesteps: 171,212,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,365.92400
Policy Entropy: 1.09404
Value Function Loss: 0.09918

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.30895
Value Function Update Magnitude: 0.51285

Collected Steps per Second: 15,050.44785
Overall Steps per Second: 6,789.23913

Timestep Collection Time: 3.32389
Timestep Consumption Time: 4.04454
PPO Batch Consumption Time: 0.54143
Total Iteration Time: 7.36843

Cumulative Model Updates: 20,526
Cumulative Timesteps: 171,262,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 171262746...
Checkpoint 171262746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,036.48345
Policy Entropy: 1.10299
Value Function Loss: 0.10008

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.35100
Value Function Update Magnitude: 0.53093

Collected Steps per Second: 14,916.59409
Overall Steps per Second: 6,964.29567

Timestep Collection Time: 3.35398
Timestep Consumption Time: 3.82980
PPO Batch Consumption Time: 0.49959
Total Iteration Time: 7.18378

Cumulative Model Updates: 20,532
Cumulative Timesteps: 171,312,776

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,707.99209
Policy Entropy: 1.10406
Value Function Loss: 0.09366

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.34759
Value Function Update Magnitude: 0.53472

Collected Steps per Second: 14,273.49494
Overall Steps per Second: 6,853.61955

Timestep Collection Time: 3.50580
Timestep Consumption Time: 3.79545
PPO Batch Consumption Time: 0.50229
Total Iteration Time: 7.30125

Cumulative Model Updates: 20,538
Cumulative Timesteps: 171,362,816

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 171362816...
Checkpoint 171362816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,485.12485
Policy Entropy: 1.10571
Value Function Loss: 0.09051

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.34509
Value Function Update Magnitude: 0.51905

Collected Steps per Second: 14,902.58521
Overall Steps per Second: 6,892.63318

Timestep Collection Time: 3.35593
Timestep Consumption Time: 3.89993
PPO Batch Consumption Time: 0.52606
Total Iteration Time: 7.25586

Cumulative Model Updates: 20,544
Cumulative Timesteps: 171,412,828

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,178.51968
Policy Entropy: 1.10476
Value Function Loss: 0.09099

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.35176
Value Function Update Magnitude: 0.52882

Collected Steps per Second: 15,415.08230
Overall Steps per Second: 6,841.40386

Timestep Collection Time: 3.24423
Timestep Consumption Time: 4.06568
PPO Batch Consumption Time: 0.54130
Total Iteration Time: 7.30990

Cumulative Model Updates: 20,550
Cumulative Timesteps: 171,462,838

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 171462838...
Checkpoint 171462838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,709.24143
Policy Entropy: 1.10540
Value Function Loss: 0.09135

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08803
Policy Update Magnitude: 0.37201
Value Function Update Magnitude: 0.54315

Collected Steps per Second: 14,754.22433
Overall Steps per Second: 6,781.35195

Timestep Collection Time: 3.39022
Timestep Consumption Time: 3.98589
PPO Batch Consumption Time: 0.53217
Total Iteration Time: 7.37611

Cumulative Model Updates: 20,556
Cumulative Timesteps: 171,512,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,696.56368
Policy Entropy: 1.10845
Value Function Loss: 0.09182

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08250
Policy Update Magnitude: 0.38456
Value Function Update Magnitude: 0.57475

Collected Steps per Second: 14,995.97273
Overall Steps per Second: 6,922.24720

Timestep Collection Time: 3.33476
Timestep Consumption Time: 3.88948
PPO Batch Consumption Time: 0.51951
Total Iteration Time: 7.22424

Cumulative Model Updates: 20,562
Cumulative Timesteps: 171,562,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 171562866...
Checkpoint 171562866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,879.62437
Policy Entropy: 1.10833
Value Function Loss: 0.08800

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07971
Policy Update Magnitude: 0.39071
Value Function Update Magnitude: 0.57051

Collected Steps per Second: 14,567.89213
Overall Steps per Second: 6,880.57723

Timestep Collection Time: 3.43262
Timestep Consumption Time: 3.83509
PPO Batch Consumption Time: 0.50848
Total Iteration Time: 7.26770

Cumulative Model Updates: 20,568
Cumulative Timesteps: 171,612,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,722.50270
Policy Entropy: 1.09937
Value Function Loss: 0.08629

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09933
Policy Update Magnitude: 0.36631
Value Function Update Magnitude: 0.65821

Collected Steps per Second: 14,902.31818
Overall Steps per Second: 6,991.94163

Timestep Collection Time: 3.35720
Timestep Consumption Time: 3.79818
PPO Batch Consumption Time: 0.50247
Total Iteration Time: 7.15538

Cumulative Model Updates: 20,574
Cumulative Timesteps: 171,662,902

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 171662902...
Checkpoint 171662902 saved!
