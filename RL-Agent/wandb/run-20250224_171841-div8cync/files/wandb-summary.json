{"_step":13561,"Policy Entropy":3.498108426729838,"Collected Steps per Second":19792.890135543283,"_runtime":31932.6263705,"Timestep Consumption Time":2.5478465000014694,"Policy Update Magnitude":0.5790452361106873,"_timestamp":1.7404674541678994e+09,"Mean KL Divergence":0.010235403819630543,"Value Function Update Magnitude":0.7099905014038086,"Timestep Collection Time":2.5269679999983055,"PPO Batch Consumption Time":0.2954243818918864,"Total Iteration Time":5.074814499999775,"Cumulative Timesteps":339157858,"Value Function Loss":0.16118589788675308,"Overall Steps per Second":9855.729702041763,"SB3 Clip Fraction":0.10917999595403671,"x_vel":0.5691871118072268,"_wandb":{"runtime":31932},"Timesteps Collected":50016,"Policy Reward":7489.851303312332,"y_vel":55.45524469572357,"Cumulative Model Updates":40676,"z_vel":-2.9202383598854067}