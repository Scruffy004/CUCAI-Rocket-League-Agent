Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,499.37811
Policy Entropy: 1.93285
Value Function Loss: 0.10684

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.01009
Policy Update Magnitude: 0.22663
Value Function Update Magnitude: 0.12476

Collected Steps per Second: 17,974.75986
Overall Steps per Second: 11,975.94840

Timestep Collection Time: 2.78246
Timestep Consumption Time: 1.39375
PPO Batch Consumption Time: 0.37682
Total Iteration Time: 4.17620

Cumulative Model Updates: 105,010
Cumulative Timesteps: 875,869,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,270.78872
Policy Entropy: 1.86061
Value Function Loss: 0.09504

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.06425
Policy Update Magnitude: 0.25743
Value Function Update Magnitude: 0.11044

Collected Steps per Second: 20,439.45607
Overall Steps per Second: 13,124.97753

Timestep Collection Time: 2.44693
Timestep Consumption Time: 1.36366
PPO Batch Consumption Time: 0.31725
Total Iteration Time: 3.81060

Cumulative Model Updates: 105,012
Cumulative Timesteps: 875,919,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 875919284...
Checkpoint 875919284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,418.88849
Policy Entropy: 1.81721
Value Function Loss: 0.10518

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.50342
Value Function Update Magnitude: 0.18928

Collected Steps per Second: 18,652.85260
Overall Steps per Second: 11,226.15951

Timestep Collection Time: 2.68131
Timestep Consumption Time: 1.77382
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.45513

Cumulative Model Updates: 105,016
Cumulative Timesteps: 875,969,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,596.61189
Policy Entropy: 1.74546
Value Function Loss: 0.10255

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14999
Policy Update Magnitude: 0.69553
Value Function Update Magnitude: 0.24159

Collected Steps per Second: 20,056.72060
Overall Steps per Second: 10,236.95672

Timestep Collection Time: 2.49423
Timestep Consumption Time: 2.39258
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.88680

Cumulative Model Updates: 105,022
Cumulative Timesteps: 876,019,324

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 876019324...
Checkpoint 876019324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,948.86811
Policy Entropy: 1.73601
Value Function Loss: 0.09287

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.18375
Policy Update Magnitude: 0.61358
Value Function Update Magnitude: 0.25022

Collected Steps per Second: 20,615.10593
Overall Steps per Second: 10,239.38927

Timestep Collection Time: 2.42647
Timestep Consumption Time: 2.45878
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.88525

Cumulative Model Updates: 105,028
Cumulative Timesteps: 876,069,346

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,210.32080
Policy Entropy: 1.71276
Value Function Loss: 0.08608

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.19369
Policy Update Magnitude: 0.56943
Value Function Update Magnitude: 0.22090

Collected Steps per Second: 20,058.37439
Overall Steps per Second: 9,975.43519

Timestep Collection Time: 2.49342
Timestep Consumption Time: 2.52029
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 5.01372

Cumulative Model Updates: 105,034
Cumulative Timesteps: 876,119,360

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 876119360...
Checkpoint 876119360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,632.32221
Policy Entropy: 1.72003
Value Function Loss: 0.07740

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.18593
Policy Update Magnitude: 0.52617
Value Function Update Magnitude: 0.29550

Collected Steps per Second: 20,747.89605
Overall Steps per Second: 10,182.23579

Timestep Collection Time: 2.40998
Timestep Consumption Time: 2.50073
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.91071

Cumulative Model Updates: 105,040
Cumulative Timesteps: 876,169,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,515.95746
Policy Entropy: 1.70079
Value Function Loss: 0.07547

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.17404
Policy Update Magnitude: 0.54020
Value Function Update Magnitude: 0.37184

Collected Steps per Second: 21,258.68662
Overall Steps per Second: 10,371.85254

Timestep Collection Time: 2.35301
Timestep Consumption Time: 2.46985
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.82286

Cumulative Model Updates: 105,046
Cumulative Timesteps: 876,219,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 876219384...
Checkpoint 876219384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,643.27833
Policy Entropy: 1.69996
Value Function Loss: 0.07350

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.17196
Policy Update Magnitude: 0.56469
Value Function Update Magnitude: 0.33307

Collected Steps per Second: 20,786.00294
Overall Steps per Second: 10,296.44770

Timestep Collection Time: 2.40662
Timestep Consumption Time: 2.45176
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.85837

Cumulative Model Updates: 105,052
Cumulative Timesteps: 876,269,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,223.62382
Policy Entropy: 1.69447
Value Function Loss: 0.08285

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.16156
Policy Update Magnitude: 0.60387
Value Function Update Magnitude: 0.33283

Collected Steps per Second: 21,157.93964
Overall Steps per Second: 10,172.90190

Timestep Collection Time: 2.36365
Timestep Consumption Time: 2.55235
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.91600

Cumulative Model Updates: 105,058
Cumulative Timesteps: 876,319,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 876319418...
Checkpoint 876319418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,726.59870
Policy Entropy: 1.70094
Value Function Loss: 0.09049

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.15501
Policy Update Magnitude: 0.61809
Value Function Update Magnitude: 0.38450

Collected Steps per Second: 20,945.76861
Overall Steps per Second: 10,120.10913

Timestep Collection Time: 2.38826
Timestep Consumption Time: 2.55477
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.94303

Cumulative Model Updates: 105,064
Cumulative Timesteps: 876,369,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,628.22604
Policy Entropy: 1.69249
Value Function Loss: 0.08676

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.15275
Policy Update Magnitude: 0.59312
Value Function Update Magnitude: 0.38397

Collected Steps per Second: 21,306.95793
Overall Steps per Second: 10,309.53265

Timestep Collection Time: 2.34797
Timestep Consumption Time: 2.50463
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.85260

Cumulative Model Updates: 105,070
Cumulative Timesteps: 876,419,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 876419470...
Checkpoint 876419470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,013.07102
Policy Entropy: 1.68363
Value Function Loss: 0.07566

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.14191
Policy Update Magnitude: 0.57801
Value Function Update Magnitude: 0.56982

Collected Steps per Second: 20,791.49950
Overall Steps per Second: 10,236.21453

Timestep Collection Time: 2.40560
Timestep Consumption Time: 2.48058
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.88618

Cumulative Model Updates: 105,076
Cumulative Timesteps: 876,469,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,436.72490
Policy Entropy: 1.66795
Value Function Loss: 0.06696

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.13716
Policy Update Magnitude: 0.56996
Value Function Update Magnitude: 0.53882

Collected Steps per Second: 21,348.50812
Overall Steps per Second: 10,217.59572

Timestep Collection Time: 2.34227
Timestep Consumption Time: 2.55164
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.89391

Cumulative Model Updates: 105,082
Cumulative Timesteps: 876,519,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 876519490...
Checkpoint 876519490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,980.04681
Policy Entropy: 1.65691
Value Function Loss: 0.06732

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14191
Policy Update Magnitude: 0.56673
Value Function Update Magnitude: 0.49935

Collected Steps per Second: 20,993.67838
Overall Steps per Second: 10,123.92853

Timestep Collection Time: 2.38176
Timestep Consumption Time: 2.55723
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.93899

Cumulative Model Updates: 105,088
Cumulative Timesteps: 876,569,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,846.91710
Policy Entropy: 1.64743
Value Function Loss: 0.06887

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.56554
Value Function Update Magnitude: 0.40487

Collected Steps per Second: 20,570.62399
Overall Steps per Second: 10,031.76941

Timestep Collection Time: 2.43094
Timestep Consumption Time: 2.55382
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.98476

Cumulative Model Updates: 105,094
Cumulative Timesteps: 876,619,498

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 876619498...
Checkpoint 876619498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,680.46734
Policy Entropy: 1.63474
Value Function Loss: 0.07517

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14241
Policy Update Magnitude: 0.55488
Value Function Update Magnitude: 0.31266

Collected Steps per Second: 19,075.52925
Overall Steps per Second: 9,577.04060

Timestep Collection Time: 2.62126
Timestep Consumption Time: 2.59976
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 5.22103

Cumulative Model Updates: 105,100
Cumulative Timesteps: 876,669,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,747.91519
Policy Entropy: 1.62948
Value Function Loss: 0.07687

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.55327
Value Function Update Magnitude: 0.30763

Collected Steps per Second: 21,631.80958
Overall Steps per Second: 10,254.63609

Timestep Collection Time: 2.31243
Timestep Consumption Time: 2.56556
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.87799

Cumulative Model Updates: 105,106
Cumulative Timesteps: 876,719,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 876719522...
Checkpoint 876719522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,891.48467
Policy Entropy: 1.62862
Value Function Loss: 0.07744

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.15552
Policy Update Magnitude: 0.54488
Value Function Update Magnitude: 0.50123

Collected Steps per Second: 17,582.22504
Overall Steps per Second: 9,284.39850

Timestep Collection Time: 2.84458
Timestep Consumption Time: 2.54231
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 5.38689

Cumulative Model Updates: 105,112
Cumulative Timesteps: 876,769,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,858.14942
Policy Entropy: 1.64054
Value Function Loss: 0.07153

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.17193
Policy Update Magnitude: 0.49240
Value Function Update Magnitude: 0.54683

Collected Steps per Second: 20,968.98302
Overall Steps per Second: 10,208.78427

Timestep Collection Time: 2.38514
Timestep Consumption Time: 2.51397
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.89911

Cumulative Model Updates: 105,118
Cumulative Timesteps: 876,819,550

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 876819550...
Checkpoint 876819550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,816.18276
Policy Entropy: 1.64776
Value Function Loss: 0.07477

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.16581
Policy Update Magnitude: 0.53679
Value Function Update Magnitude: 0.55169

Collected Steps per Second: 20,241.87552
Overall Steps per Second: 9,928.00726

Timestep Collection Time: 2.47131
Timestep Consumption Time: 2.56736
PPO Batch Consumption Time: 0.29721
Total Iteration Time: 5.03867

Cumulative Model Updates: 105,124
Cumulative Timesteps: 876,869,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,120.99298
Policy Entropy: 1.63264
Value Function Loss: 0.07228

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.16545
Policy Update Magnitude: 0.54732
Value Function Update Magnitude: 0.43710

Collected Steps per Second: 21,121.54179
Overall Steps per Second: 10,212.81066

Timestep Collection Time: 2.36754
Timestep Consumption Time: 2.52886
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.89640

Cumulative Model Updates: 105,130
Cumulative Timesteps: 876,919,580

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 876919580...
Checkpoint 876919580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,069.62926
Policy Entropy: 1.64170
Value Function Loss: 0.08140

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.16177
Policy Update Magnitude: 0.54751
Value Function Update Magnitude: 0.36782

Collected Steps per Second: 20,306.37817
Overall Steps per Second: 9,902.72043

Timestep Collection Time: 2.46395
Timestep Consumption Time: 2.58860
PPO Batch Consumption Time: 0.30095
Total Iteration Time: 5.05255

Cumulative Model Updates: 105,136
Cumulative Timesteps: 876,969,614

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,696.90535
Policy Entropy: 1.65660
Value Function Loss: 0.08197

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.15223
Policy Update Magnitude: 0.55431
Value Function Update Magnitude: 0.38180

Collected Steps per Second: 21,098.38337
Overall Steps per Second: 10,136.61833

Timestep Collection Time: 2.37013
Timestep Consumption Time: 2.56307
PPO Batch Consumption Time: 0.29767
Total Iteration Time: 4.93320

Cumulative Model Updates: 105,142
Cumulative Timesteps: 877,019,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 877019620...
Checkpoint 877019620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,810.75026
Policy Entropy: 1.67308
Value Function Loss: 0.08063

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.14678
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.50529

Collected Steps per Second: 20,579.50361
Overall Steps per Second: 10,108.64029

Timestep Collection Time: 2.42989
Timestep Consumption Time: 2.51696
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.94686

Cumulative Model Updates: 105,148
Cumulative Timesteps: 877,069,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,583.67969
Policy Entropy: 1.64554
Value Function Loss: 0.07180

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.14782
Policy Update Magnitude: 0.56619
Value Function Update Magnitude: 0.47618

Collected Steps per Second: 21,024.95168
Overall Steps per Second: 10,070.70858

Timestep Collection Time: 2.37908
Timestep Consumption Time: 2.58780
PPO Batch Consumption Time: 0.30024
Total Iteration Time: 4.96688

Cumulative Model Updates: 105,154
Cumulative Timesteps: 877,119,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 877119646...
Checkpoint 877119646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,903.19973
Policy Entropy: 1.62355
Value Function Loss: 0.07373

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14491
Policy Update Magnitude: 0.55480
Value Function Update Magnitude: 0.36590

Collected Steps per Second: 20,560.44349
Overall Steps per Second: 10,075.93634

Timestep Collection Time: 2.43283
Timestep Consumption Time: 2.53148
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.96430

Cumulative Model Updates: 105,160
Cumulative Timesteps: 877,169,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,319.95840
Policy Entropy: 1.60244
Value Function Loss: 0.06745

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.53899
Value Function Update Magnitude: 0.32021

Collected Steps per Second: 21,049.81823
Overall Steps per Second: 10,011.46979

Timestep Collection Time: 2.37589
Timestep Consumption Time: 2.61958
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.99547

Cumulative Model Updates: 105,166
Cumulative Timesteps: 877,219,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 877219678...
Checkpoint 877219678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,252.36329
Policy Entropy: 1.60251
Value Function Loss: 0.06610

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.15447
Policy Update Magnitude: 0.52286
Value Function Update Magnitude: 0.29031

Collected Steps per Second: 19,332.56503
Overall Steps per Second: 9,631.83699

Timestep Collection Time: 2.58734
Timestep Consumption Time: 2.60585
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 5.19319

Cumulative Model Updates: 105,172
Cumulative Timesteps: 877,269,698

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,476.24881
Policy Entropy: 1.60294
Value Function Loss: 0.06085

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.16215
Policy Update Magnitude: 0.44514
Value Function Update Magnitude: 0.30375

Collected Steps per Second: 21,369.20753
Overall Steps per Second: 10,279.11446

Timestep Collection Time: 2.34056
Timestep Consumption Time: 2.52522
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.86579

Cumulative Model Updates: 105,178
Cumulative Timesteps: 877,319,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 877319714...
Checkpoint 877319714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,875.83452
Policy Entropy: 1.59208
Value Function Loss: 0.06823

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.45511
Value Function Update Magnitude: 0.36900

Collected Steps per Second: 19,874.12393
Overall Steps per Second: 9,762.93474

Timestep Collection Time: 2.51805
Timestep Consumption Time: 2.60787
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 5.12592

Cumulative Model Updates: 105,184
Cumulative Timesteps: 877,369,758

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,093.61699
Policy Entropy: 1.59414
Value Function Loss: 0.07013

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.15361
Policy Update Magnitude: 0.47658
Value Function Update Magnitude: 0.57322

Collected Steps per Second: 20,815.84861
Overall Steps per Second: 10,174.62073

Timestep Collection Time: 2.40317
Timestep Consumption Time: 2.51338
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.91655

Cumulative Model Updates: 105,190
Cumulative Timesteps: 877,419,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 877419782...
Checkpoint 877419782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,085.79390
Policy Entropy: 1.60268
Value Function Loss: 0.07663

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.16682
Policy Update Magnitude: 0.49167
Value Function Update Magnitude: 0.60895

Collected Steps per Second: 19,719.88599
Overall Steps per Second: 9,836.10258

Timestep Collection Time: 2.53642
Timestep Consumption Time: 2.54872
PPO Batch Consumption Time: 0.30086
Total Iteration Time: 5.08514

Cumulative Model Updates: 105,196
Cumulative Timesteps: 877,469,800

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,792.08843
Policy Entropy: 1.61325
Value Function Loss: 0.07594

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.14615
Policy Update Magnitude: 0.52673
Value Function Update Magnitude: 0.53292

Collected Steps per Second: 21,373.68232
Overall Steps per Second: 10,290.54105

Timestep Collection Time: 2.34035
Timestep Consumption Time: 2.52061
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.86097

Cumulative Model Updates: 105,202
Cumulative Timesteps: 877,519,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 877519822...
Checkpoint 877519822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,307.77942
Policy Entropy: 1.61099
Value Function Loss: 0.08372

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.14789
Policy Update Magnitude: 0.57504
Value Function Update Magnitude: 0.46188

Collected Steps per Second: 20,611.74920
Overall Steps per Second: 10,018.11364

Timestep Collection Time: 2.42667
Timestep Consumption Time: 2.56608
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.99276

Cumulative Model Updates: 105,208
Cumulative Timesteps: 877,569,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,670.25454
Policy Entropy: 1.59956
Value Function Loss: 0.08363

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.15124
Policy Update Magnitude: 0.56871
Value Function Update Magnitude: 0.41446

Collected Steps per Second: 21,198.16477
Overall Steps per Second: 10,262.81484

Timestep Collection Time: 2.35879
Timestep Consumption Time: 2.51336
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.87215

Cumulative Model Updates: 105,214
Cumulative Timesteps: 877,619,842

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 877619842...
Checkpoint 877619842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,899.18681
Policy Entropy: 1.60600
Value Function Loss: 0.08444

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.15192
Policy Update Magnitude: 0.58050
Value Function Update Magnitude: 0.35458

Collected Steps per Second: 20,308.06490
Overall Steps per Second: 9,907.53423

Timestep Collection Time: 2.46405
Timestep Consumption Time: 2.58666
PPO Batch Consumption Time: 0.30117
Total Iteration Time: 5.05070

Cumulative Model Updates: 105,220
Cumulative Timesteps: 877,669,882

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,713.25553
Policy Entropy: 1.60710
Value Function Loss: 0.08237

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.15356
Policy Update Magnitude: 0.58395
Value Function Update Magnitude: 0.32131

Collected Steps per Second: 21,347.66380
Overall Steps per Second: 10,305.96623

Timestep Collection Time: 2.34265
Timestep Consumption Time: 2.50988
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.85253

Cumulative Model Updates: 105,226
Cumulative Timesteps: 877,719,892

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 877719892...
Checkpoint 877719892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,279.85448
Policy Entropy: 1.61742
Value Function Loss: 0.07717

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.15365
Policy Update Magnitude: 0.57417
Value Function Update Magnitude: 0.34201

Collected Steps per Second: 18,342.95874
Overall Steps per Second: 9,333.10050

Timestep Collection Time: 2.72584
Timestep Consumption Time: 2.63143
PPO Batch Consumption Time: 0.30405
Total Iteration Time: 5.35728

Cumulative Model Updates: 105,232
Cumulative Timesteps: 877,769,892

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,604.69770
Policy Entropy: 1.59490
Value Function Loss: 0.07505

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.57007
Value Function Update Magnitude: 0.32967

Collected Steps per Second: 20,202.61843
Overall Steps per Second: 9,621.35815

Timestep Collection Time: 2.47532
Timestep Consumption Time: 2.72228
PPO Batch Consumption Time: 0.32252
Total Iteration Time: 5.19760

Cumulative Model Updates: 105,238
Cumulative Timesteps: 877,819,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 877819900...
Checkpoint 877819900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,350.05121
Policy Entropy: 1.58284
Value Function Loss: 0.07418

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.15476
Policy Update Magnitude: 0.55866
Value Function Update Magnitude: 0.35702

Collected Steps per Second: 18,283.62172
Overall Steps per Second: 9,019.12246

Timestep Collection Time: 2.73513
Timestep Consumption Time: 2.80954
PPO Batch Consumption Time: 0.33859
Total Iteration Time: 5.54466

Cumulative Model Updates: 105,244
Cumulative Timesteps: 877,869,908

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,031.13707
Policy Entropy: 1.57148
Value Function Loss: 0.06714

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.16773
Policy Update Magnitude: 0.49722
Value Function Update Magnitude: 0.45075

Collected Steps per Second: 18,390.60760
Overall Steps per Second: 9,246.13890

Timestep Collection Time: 2.72128
Timestep Consumption Time: 2.69136
PPO Batch Consumption Time: 0.30144
Total Iteration Time: 5.41264

Cumulative Model Updates: 105,250
Cumulative Timesteps: 877,919,954

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 877919954...
Checkpoint 877919954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,497.81780
Policy Entropy: 1.55773
Value Function Loss: 0.06667

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.16400
Policy Update Magnitude: 0.43016
Value Function Update Magnitude: 0.50632

Collected Steps per Second: 20,453.48231
Overall Steps per Second: 9,833.13690

Timestep Collection Time: 2.44516
Timestep Consumption Time: 2.64091
PPO Batch Consumption Time: 0.30655
Total Iteration Time: 5.08607

Cumulative Model Updates: 105,256
Cumulative Timesteps: 877,969,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,726.07376
Policy Entropy: 1.56584
Value Function Loss: 0.06394

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.14779
Policy Update Magnitude: 0.48013
Value Function Update Magnitude: 0.48933

Collected Steps per Second: 18,640.16155
Overall Steps per Second: 9,375.64915

Timestep Collection Time: 2.68431
Timestep Consumption Time: 2.65249
PPO Batch Consumption Time: 0.30230
Total Iteration Time: 5.33680

Cumulative Model Updates: 105,262
Cumulative Timesteps: 878,020,002

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 878020002...
Checkpoint 878020002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,835.67193
Policy Entropy: 1.55878
Value Function Loss: 0.06461

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.15125
Policy Update Magnitude: 0.50432
Value Function Update Magnitude: 0.56949

Collected Steps per Second: 20,109.38725
Overall Steps per Second: 10,009.84116

Timestep Collection Time: 2.48769
Timestep Consumption Time: 2.50999
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.99768

Cumulative Model Updates: 105,268
Cumulative Timesteps: 878,070,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,135.44696
Policy Entropy: 1.55342
Value Function Loss: 0.06599

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.14563
Policy Update Magnitude: 0.52743
Value Function Update Magnitude: 0.54281

Collected Steps per Second: 18,380.90788
Overall Steps per Second: 9,207.38539

Timestep Collection Time: 2.72098
Timestep Consumption Time: 2.71097
PPO Batch Consumption Time: 0.31830
Total Iteration Time: 5.43194

Cumulative Model Updates: 105,274
Cumulative Timesteps: 878,120,042

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 878120042...
Checkpoint 878120042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,918.60140
Policy Entropy: 1.54131
Value Function Loss: 0.06599

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.54252
Value Function Update Magnitude: 0.53287

Collected Steps per Second: 19,666.08942
Overall Steps per Second: 9,646.12926

Timestep Collection Time: 2.54275
Timestep Consumption Time: 2.64130
PPO Batch Consumption Time: 0.31025
Total Iteration Time: 5.18405

Cumulative Model Updates: 105,280
Cumulative Timesteps: 878,170,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,776.19150
Policy Entropy: 1.54180
Value Function Loss: 0.06437

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.14346
Policy Update Magnitude: 0.55449
Value Function Update Magnitude: 0.64607

Collected Steps per Second: 16,972.72379
Overall Steps per Second: 8,122.06434

Timestep Collection Time: 2.94779
Timestep Consumption Time: 3.21222
PPO Batch Consumption Time: 0.37779
Total Iteration Time: 6.16001

Cumulative Model Updates: 105,286
Cumulative Timesteps: 878,220,080

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 878220080...
Checkpoint 878220080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,189.39277
Policy Entropy: 1.54003
Value Function Loss: 0.06562

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.54629
Value Function Update Magnitude: 0.65201

Collected Steps per Second: 16,290.97949
Overall Steps per Second: 8,971.62924

Timestep Collection Time: 3.06943
Timestep Consumption Time: 2.50414
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 5.57357

Cumulative Model Updates: 105,292
Cumulative Timesteps: 878,270,084

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,600.52460
Policy Entropy: 1.54487
Value Function Loss: 0.07320

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.14276
Policy Update Magnitude: 0.56335
Value Function Update Magnitude: 0.58718

Collected Steps per Second: 18,123.81825
Overall Steps per Second: 9,187.99809

Timestep Collection Time: 2.76079
Timestep Consumption Time: 2.68501
PPO Batch Consumption Time: 0.30001
Total Iteration Time: 5.44580

Cumulative Model Updates: 105,298
Cumulative Timesteps: 878,320,120

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 878320120...
Checkpoint 878320120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,406.43409
Policy Entropy: 1.53978
Value Function Loss: 0.07548

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.17626
Policy Update Magnitude: 0.50239
Value Function Update Magnitude: 0.52617

Collected Steps per Second: 16,948.48970
Overall Steps per Second: 8,901.61966

Timestep Collection Time: 2.95082
Timestep Consumption Time: 2.66748
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 5.61830

Cumulative Model Updates: 105,304
Cumulative Timesteps: 878,370,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,841.04124
Policy Entropy: 1.53996
Value Function Loss: 0.06923

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.17240
Policy Update Magnitude: 0.46134
Value Function Update Magnitude: 0.56762

Collected Steps per Second: 16,304.14378
Overall Steps per Second: 8,895.88781

Timestep Collection Time: 3.06842
Timestep Consumption Time: 2.55530
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 5.62372

Cumulative Model Updates: 105,310
Cumulative Timesteps: 878,420,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 878420160...
Checkpoint 878420160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,879.79009
Policy Entropy: 1.53493
Value Function Loss: 0.06633

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.16228
Policy Update Magnitude: 0.48850
Value Function Update Magnitude: 0.56963

Collected Steps per Second: 17,716.37914
Overall Steps per Second: 9,165.31029

Timestep Collection Time: 2.82247
Timestep Consumption Time: 2.63332
PPO Batch Consumption Time: 0.31307
Total Iteration Time: 5.45579

Cumulative Model Updates: 105,316
Cumulative Timesteps: 878,470,164

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,164.53036
Policy Entropy: 1.54908
Value Function Loss: 0.07123

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.16468
Policy Update Magnitude: 0.52596
Value Function Update Magnitude: 0.42209

Collected Steps per Second: 16,585.69044
Overall Steps per Second: 8,956.87900

Timestep Collection Time: 3.01621
Timestep Consumption Time: 2.56899
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 5.58520

Cumulative Model Updates: 105,322
Cumulative Timesteps: 878,520,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 878520190...
Checkpoint 878520190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,732.06574
Policy Entropy: 1.55773
Value Function Loss: 0.08018

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.16200
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.39622

Collected Steps per Second: 14,744.75787
Overall Steps per Second: 8,337.00969

Timestep Collection Time: 3.39307
Timestep Consumption Time: 2.60788
PPO Batch Consumption Time: 0.30093
Total Iteration Time: 6.00095

Cumulative Model Updates: 105,328
Cumulative Timesteps: 878,570,220

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,407.80167
Policy Entropy: 1.55721
Value Function Loss: 0.07306

Mean KL Divergence: 0.02333
SB3 Clip Fraction: 0.18395
Policy Update Magnitude: 0.51974
Value Function Update Magnitude: 0.41491

Collected Steps per Second: 16,067.44293
Overall Steps per Second: 8,773.09750

Timestep Collection Time: 3.11412
Timestep Consumption Time: 2.58922
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 5.70334

Cumulative Model Updates: 105,334
Cumulative Timesteps: 878,620,256

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 878620256...
Checkpoint 878620256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,748.05715
Policy Entropy: 1.55001
Value Function Loss: 0.07068

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.17502
Policy Update Magnitude: 0.49255
Value Function Update Magnitude: 0.45132

Collected Steps per Second: 17,217.64448
Overall Steps per Second: 9,227.28063

Timestep Collection Time: 2.90574
Timestep Consumption Time: 2.51623
PPO Batch Consumption Time: 0.30758
Total Iteration Time: 5.42197

Cumulative Model Updates: 105,340
Cumulative Timesteps: 878,670,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,730.46401
Policy Entropy: 1.54872
Value Function Loss: 0.07133

Mean KL Divergence: 0.02412
SB3 Clip Fraction: 0.17877
Policy Update Magnitude: 0.47423
Value Function Update Magnitude: 0.49429

Collected Steps per Second: 17,822.97851
Overall Steps per Second: 9,179.55544

Timestep Collection Time: 2.80660
Timestep Consumption Time: 2.64268
PPO Batch Consumption Time: 0.30258
Total Iteration Time: 5.44928

Cumulative Model Updates: 105,346
Cumulative Timesteps: 878,720,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 878720308...
Checkpoint 878720308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,562.21359
Policy Entropy: 1.56165
Value Function Loss: 0.07709

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.16308
Policy Update Magnitude: 0.51506
Value Function Update Magnitude: 0.61462

Collected Steps per Second: 17,788.16270
Overall Steps per Second: 9,208.90032

Timestep Collection Time: 2.81108
Timestep Consumption Time: 2.61888
PPO Batch Consumption Time: 0.29960
Total Iteration Time: 5.42996

Cumulative Model Updates: 105,352
Cumulative Timesteps: 878,770,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,931.58467
Policy Entropy: 1.55240
Value Function Loss: 0.07758

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.16419
Policy Update Magnitude: 0.53148
Value Function Update Magnitude: 0.55522

Collected Steps per Second: 19,307.10771
Overall Steps per Second: 9,688.96948

Timestep Collection Time: 2.59107
Timestep Consumption Time: 2.57212
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 5.16319

Cumulative Model Updates: 105,358
Cumulative Timesteps: 878,820,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 878820338...
Checkpoint 878820338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,997.51170
Policy Entropy: 1.54418
Value Function Loss: 0.07933

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.17059
Policy Update Magnitude: 0.51942
Value Function Update Magnitude: 0.44964

Collected Steps per Second: 15,962.70129
Overall Steps per Second: 8,303.89659

Timestep Collection Time: 3.13431
Timestep Consumption Time: 2.89082
PPO Batch Consumption Time: 0.33462
Total Iteration Time: 6.02512

Cumulative Model Updates: 105,364
Cumulative Timesteps: 878,870,370

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,232.49289
Policy Entropy: 1.52809
Value Function Loss: 0.07666

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.16098
Policy Update Magnitude: 0.55947
Value Function Update Magnitude: 0.41660

Collected Steps per Second: 12,858.94559
Overall Steps per Second: 7,453.92123

Timestep Collection Time: 3.89068
Timestep Consumption Time: 2.82123
PPO Batch Consumption Time: 0.32141
Total Iteration Time: 6.71190

Cumulative Model Updates: 105,370
Cumulative Timesteps: 878,920,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 878920400...
Checkpoint 878920400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,448.60137
Policy Entropy: 1.53891
Value Function Loss: 0.07361

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.57771
Value Function Update Magnitude: 0.46505

Collected Steps per Second: 16,692.55673
Overall Steps per Second: 8,717.86284

Timestep Collection Time: 2.99607
Timestep Consumption Time: 2.74066
PPO Batch Consumption Time: 0.32419
Total Iteration Time: 5.73673

Cumulative Model Updates: 105,376
Cumulative Timesteps: 878,970,412

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,695.42988
Policy Entropy: 1.54319
Value Function Loss: 0.08013

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.15208
Policy Update Magnitude: 0.56974
Value Function Update Magnitude: 0.48220

Collected Steps per Second: 16,829.64866
Overall Steps per Second: 8,711.45580

Timestep Collection Time: 2.97237
Timestep Consumption Time: 2.76995
PPO Batch Consumption Time: 0.32153
Total Iteration Time: 5.74232

Cumulative Model Updates: 105,382
Cumulative Timesteps: 879,020,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 879020436...
Checkpoint 879020436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,060.81693
Policy Entropy: 1.55843
Value Function Loss: 0.08295

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.15094
Policy Update Magnitude: 0.58296
Value Function Update Magnitude: 0.53036

Collected Steps per Second: 17,523.31008
Overall Steps per Second: 9,250.46451

Timestep Collection Time: 2.85608
Timestep Consumption Time: 2.55424
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 5.41032

Cumulative Model Updates: 105,388
Cumulative Timesteps: 879,070,484

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,905.29639
Policy Entropy: 1.57040
Value Function Loss: 0.07294

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.14974
Policy Update Magnitude: 0.58157
Value Function Update Magnitude: 0.69134

Collected Steps per Second: 19,004.01604
Overall Steps per Second: 9,450.09845

Timestep Collection Time: 2.63250
Timestep Consumption Time: 2.66142
PPO Batch Consumption Time: 0.30425
Total Iteration Time: 5.29391

Cumulative Model Updates: 105,394
Cumulative Timesteps: 879,120,512

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 879120512...
Checkpoint 879120512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,588.78350
Policy Entropy: 1.57843
Value Function Loss: 0.06706

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.15388
Policy Update Magnitude: 0.56511
Value Function Update Magnitude: 0.72447

Collected Steps per Second: 17,773.18587
Overall Steps per Second: 9,261.92442

Timestep Collection Time: 2.81345
Timestep Consumption Time: 2.58543
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 5.39888

Cumulative Model Updates: 105,400
Cumulative Timesteps: 879,170,516

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,379.51163
Policy Entropy: 1.58093
Value Function Loss: 0.06698

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.15221
Policy Update Magnitude: 0.55680
Value Function Update Magnitude: 0.70393

Collected Steps per Second: 18,580.24631
Overall Steps per Second: 9,403.25783

Timestep Collection Time: 2.69211
Timestep Consumption Time: 2.62733
PPO Batch Consumption Time: 0.30394
Total Iteration Time: 5.31943

Cumulative Model Updates: 105,406
Cumulative Timesteps: 879,220,536

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 879220536...
Checkpoint 879220536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,281.68689
Policy Entropy: 1.57455
Value Function Loss: 0.07147

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.15718
Policy Update Magnitude: 0.54657
Value Function Update Magnitude: 0.67647

Collected Steps per Second: 18,342.55039
Overall Steps per Second: 9,353.57190

Timestep Collection Time: 2.72656
Timestep Consumption Time: 2.62028
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 5.34683

Cumulative Model Updates: 105,412
Cumulative Timesteps: 879,270,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,319.65503
Policy Entropy: 1.58411
Value Function Loss: 0.07773

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.16378
Policy Update Magnitude: 0.54270
Value Function Update Magnitude: 0.73262

Collected Steps per Second: 18,535.02848
Overall Steps per Second: 9,403.62452

Timestep Collection Time: 2.69781
Timestep Consumption Time: 2.61971
PPO Batch Consumption Time: 0.29902
Total Iteration Time: 5.31752

Cumulative Model Updates: 105,418
Cumulative Timesteps: 879,320,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 879320552...
Checkpoint 879320552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,760.24540
Policy Entropy: 1.57332
Value Function Loss: 0.08655

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.18234
Policy Update Magnitude: 0.58118
Value Function Update Magnitude: 0.57795

Collected Steps per Second: 17,981.35634
Overall Steps per Second: 9,371.08250

Timestep Collection Time: 2.78121
Timestep Consumption Time: 2.55542
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 5.33663

Cumulative Model Updates: 105,424
Cumulative Timesteps: 879,370,562

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,967.11976
Policy Entropy: 1.57941
Value Function Loss: 0.09640

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.18499
Policy Update Magnitude: 0.56431
Value Function Update Magnitude: 0.54362

Collected Steps per Second: 18,825.24594
Overall Steps per Second: 9,587.27160

Timestep Collection Time: 2.65707
Timestep Consumption Time: 2.56026
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 5.21733

Cumulative Model Updates: 105,430
Cumulative Timesteps: 879,420,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 879420582...
Checkpoint 879420582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,534.40457
Policy Entropy: 1.57563
Value Function Loss: 0.09209

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.16418
Policy Update Magnitude: 0.59009
Value Function Update Magnitude: 0.63070

Collected Steps per Second: 18,226.30026
Overall Steps per Second: 9,426.39413

Timestep Collection Time: 2.74362
Timestep Consumption Time: 2.56127
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 5.30489

Cumulative Model Updates: 105,436
Cumulative Timesteps: 879,470,588

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,583.99335
Policy Entropy: 1.57575
Value Function Loss: 0.08412

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.17224
Policy Update Magnitude: 0.56620
Value Function Update Magnitude: 0.64376

Collected Steps per Second: 18,708.53946
Overall Steps per Second: 9,652.75285

Timestep Collection Time: 2.67450
Timestep Consumption Time: 2.50910
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 5.18360

Cumulative Model Updates: 105,442
Cumulative Timesteps: 879,520,624

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 879520624...
Checkpoint 879520624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,715.90836
Policy Entropy: 1.55993
Value Function Loss: 0.07783

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.16817
Policy Update Magnitude: 0.54671
Value Function Update Magnitude: 0.51828

Collected Steps per Second: 18,253.45483
Overall Steps per Second: 9,394.38393

Timestep Collection Time: 2.74052
Timestep Consumption Time: 2.58436
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 5.32488

Cumulative Model Updates: 105,448
Cumulative Timesteps: 879,570,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,818.38633
Policy Entropy: 1.53971
Value Function Loss: 0.07215

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.17546
Policy Update Magnitude: 0.50597
Value Function Update Magnitude: 0.48508

Collected Steps per Second: 19,117.21561
Overall Steps per Second: 9,762.86017

Timestep Collection Time: 2.61639
Timestep Consumption Time: 2.50691
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 5.12329

Cumulative Model Updates: 105,454
Cumulative Timesteps: 879,620,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 879620666...
Checkpoint 879620666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,519.14366
Policy Entropy: 1.53331
Value Function Loss: 0.07123

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.17491
Policy Update Magnitude: 0.43632
Value Function Update Magnitude: 0.40550

Collected Steps per Second: 17,603.85608
Overall Steps per Second: 8,899.65890

Timestep Collection Time: 2.84131
Timestep Consumption Time: 2.77891
PPO Batch Consumption Time: 0.31488
Total Iteration Time: 5.62022

Cumulative Model Updates: 105,460
Cumulative Timesteps: 879,670,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,657.24356
Policy Entropy: 1.53619
Value Function Loss: 0.07537

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.16960
Policy Update Magnitude: 0.46867
Value Function Update Magnitude: 0.37740

Collected Steps per Second: 16,029.33971
Overall Steps per Second: 7,412.12181

Timestep Collection Time: 3.12178
Timestep Consumption Time: 3.62933
PPO Batch Consumption Time: 0.46883
Total Iteration Time: 6.75110

Cumulative Model Updates: 105,466
Cumulative Timesteps: 879,720,724

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 879720724...
Checkpoint 879720724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,543.98152
Policy Entropy: 1.56056
Value Function Loss: 0.08587

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.15817
Policy Update Magnitude: 0.50889
Value Function Update Magnitude: 0.42924

Collected Steps per Second: 15,088.55246
Overall Steps per Second: 6,548.14958

Timestep Collection Time: 3.31404
Timestep Consumption Time: 4.32232
PPO Batch Consumption Time: 0.58197
Total Iteration Time: 7.63636

Cumulative Model Updates: 105,472
Cumulative Timesteps: 879,770,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,729.87983
Policy Entropy: 1.57722
Value Function Loss: 0.09320

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.15872
Policy Update Magnitude: 0.58760
Value Function Update Magnitude: 0.38016

Collected Steps per Second: 6,774.48483
Overall Steps per Second: 3,467.87511

Timestep Collection Time: 7.38152
Timestep Consumption Time: 7.03826
PPO Batch Consumption Time: 0.99069
Total Iteration Time: 14.41978

Cumulative Model Updates: 105,478
Cumulative Timesteps: 879,820,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 879820734...
Checkpoint 879820734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,083.99884
Policy Entropy: 1.56868
Value Function Loss: 0.09310

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.17869
Policy Update Magnitude: 0.58096
Value Function Update Magnitude: 0.38946

Collected Steps per Second: 4,963.51780
Overall Steps per Second: 2,897.70382

Timestep Collection Time: 10.07552
Timestep Consumption Time: 7.18298
PPO Batch Consumption Time: 1.02780
Total Iteration Time: 17.25849

Cumulative Model Updates: 105,484
Cumulative Timesteps: 879,870,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,129.63653
Policy Entropy: 1.55999
Value Function Loss: 0.08438

Mean KL Divergence: 0.02443
SB3 Clip Fraction: 0.19364
Policy Update Magnitude: 0.49483
Value Function Update Magnitude: 0.50988

Collected Steps per Second: 4,881.99519
Overall Steps per Second: 2,878.76954

Timestep Collection Time: 10.24458
Timestep Consumption Time: 7.12881
PPO Batch Consumption Time: 1.01872
Total Iteration Time: 17.37339

Cumulative Model Updates: 105,490
Cumulative Timesteps: 879,920,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 879920758...
Checkpoint 879920758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,947.40491
Policy Entropy: 1.56541
Value Function Loss: 0.08078

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.16746
Policy Update Magnitude: 0.48415
Value Function Update Magnitude: 0.52114

Collected Steps per Second: 5,515.16182
Overall Steps per Second: 4,075.94254

Timestep Collection Time: 9.07063
Timestep Consumption Time: 3.20285
PPO Batch Consumption Time: 0.40440
Total Iteration Time: 12.27348

Cumulative Model Updates: 105,496
Cumulative Timesteps: 879,970,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,728.09918
Policy Entropy: 1.56130
Value Function Loss: 0.08217

Mean KL Divergence: 0.02487
SB3 Clip Fraction: 0.18838
Policy Update Magnitude: 0.48150
Value Function Update Magnitude: 0.52140

Collected Steps per Second: 15,407.09815
Overall Steps per Second: 7,715.24714

Timestep Collection Time: 3.24720
Timestep Consumption Time: 3.23736
PPO Batch Consumption Time: 0.40311
Total Iteration Time: 6.48456

Cumulative Model Updates: 105,502
Cumulative Timesteps: 880,020,814

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 880020814...
Checkpoint 880020814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,069.61785
Policy Entropy: 1.56457
Value Function Loss: 0.08399

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.17069
Policy Update Magnitude: 0.48837
Value Function Update Magnitude: 0.52600

Collected Steps per Second: 15,251.86847
Overall Steps per Second: 8,018.29032

Timestep Collection Time: 3.28012
Timestep Consumption Time: 2.95911
PPO Batch Consumption Time: 0.36810
Total Iteration Time: 6.23924

Cumulative Model Updates: 105,508
Cumulative Timesteps: 880,070,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,668.53322
Policy Entropy: 1.55635
Value Function Loss: 0.08726

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.15900
Policy Update Magnitude: 0.53215
Value Function Update Magnitude: 0.53692

Collected Steps per Second: 15,122.80200
Overall Steps per Second: 5,589.62007

Timestep Collection Time: 3.30653
Timestep Consumption Time: 5.63934
PPO Batch Consumption Time: 0.74861
Total Iteration Time: 8.94587

Cumulative Model Updates: 105,514
Cumulative Timesteps: 880,120,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 880120846...
Checkpoint 880120846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,632.61182
Policy Entropy: 1.56307
Value Function Loss: 0.08322

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.15967
Policy Update Magnitude: 0.54478
Value Function Update Magnitude: 0.55947

Collected Steps per Second: 13,839.13778
Overall Steps per Second: 7,363.10062

Timestep Collection Time: 3.61583
Timestep Consumption Time: 3.18022
PPO Batch Consumption Time: 0.38673
Total Iteration Time: 6.79605

Cumulative Model Updates: 105,520
Cumulative Timesteps: 880,170,886

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,449.07724
Policy Entropy: 1.56890
Value Function Loss: 0.09325

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.16103
Policy Update Magnitude: 0.54673
Value Function Update Magnitude: 0.47028

Collected Steps per Second: 14,387.71132
Overall Steps per Second: 7,684.85897

Timestep Collection Time: 3.47741
Timestep Consumption Time: 3.03305
PPO Batch Consumption Time: 0.36683
Total Iteration Time: 6.51046

Cumulative Model Updates: 105,526
Cumulative Timesteps: 880,220,918

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 880220918...
Checkpoint 880220918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,670.67782
Policy Entropy: 1.56025
Value Function Loss: 0.08738

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.16569
Policy Update Magnitude: 0.54702
Value Function Update Magnitude: 0.48009

Collected Steps per Second: 15,698.84976
Overall Steps per Second: 8,075.60690

Timestep Collection Time: 3.18597
Timestep Consumption Time: 3.00750
PPO Batch Consumption Time: 0.35851
Total Iteration Time: 6.19347

Cumulative Model Updates: 105,532
Cumulative Timesteps: 880,270,934

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,574.83189
Policy Entropy: 1.56307
Value Function Loss: 0.08970

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.16287
Policy Update Magnitude: 0.53547
Value Function Update Magnitude: 0.53395

Collected Steps per Second: 16,705.53713
Overall Steps per Second: 8,388.44727

Timestep Collection Time: 2.99362
Timestep Consumption Time: 2.96815
PPO Batch Consumption Time: 0.36389
Total Iteration Time: 5.96177

Cumulative Model Updates: 105,538
Cumulative Timesteps: 880,320,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 880320944...
Checkpoint 880320944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,828.34744
Policy Entropy: 1.56074
Value Function Loss: 0.08391

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.15807
Policy Update Magnitude: 0.57368
Value Function Update Magnitude: 0.43946

Collected Steps per Second: 15,927.43868
Overall Steps per Second: 8,092.27595

Timestep Collection Time: 3.14087
Timestep Consumption Time: 3.04108
PPO Batch Consumption Time: 0.36959
Total Iteration Time: 6.18194

Cumulative Model Updates: 105,544
Cumulative Timesteps: 880,370,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,275.40182
Policy Entropy: 1.58324
Value Function Loss: 0.08300

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.17174
Policy Update Magnitude: 0.53934
Value Function Update Magnitude: 0.39198

Collected Steps per Second: 15,249.26196
Overall Steps per Second: 7,762.05152

Timestep Collection Time: 3.28029
Timestep Consumption Time: 3.16414
PPO Batch Consumption Time: 0.38166
Total Iteration Time: 6.44443

Cumulative Model Updates: 105,550
Cumulative Timesteps: 880,420,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 880420992...
Checkpoint 880420992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,652.11517
Policy Entropy: 1.58858
Value Function Loss: 0.08506

Mean KL Divergence: 0.02143
SB3 Clip Fraction: 0.17690
Policy Update Magnitude: 0.47929
Value Function Update Magnitude: 0.42033

Collected Steps per Second: 15,732.30129
Overall Steps per Second: 8,085.11246

Timestep Collection Time: 3.17970
Timestep Consumption Time: 3.00747
PPO Batch Consumption Time: 0.36503
Total Iteration Time: 6.18717

Cumulative Model Updates: 105,556
Cumulative Timesteps: 880,471,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,422.90701
Policy Entropy: 1.59778
Value Function Loss: 0.08289

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.16860
Policy Update Magnitude: 0.47867
Value Function Update Magnitude: 0.49986

Collected Steps per Second: 15,655.47269
Overall Steps per Second: 8,082.19780

Timestep Collection Time: 3.19518
Timestep Consumption Time: 2.99398
PPO Batch Consumption Time: 0.36648
Total Iteration Time: 6.18916

Cumulative Model Updates: 105,562
Cumulative Timesteps: 880,521,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 880521038...
Checkpoint 880521038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,859.82899
Policy Entropy: 1.60422
Value Function Loss: 0.08416

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.16962
Policy Update Magnitude: 0.49711
Value Function Update Magnitude: 0.52281

Collected Steps per Second: 14,558.18425
Overall Steps per Second: 7,227.06571

Timestep Collection Time: 3.43683
Timestep Consumption Time: 3.48631
PPO Batch Consumption Time: 0.44320
Total Iteration Time: 6.92314

Cumulative Model Updates: 105,568
Cumulative Timesteps: 880,571,072

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,469.21708
Policy Entropy: 1.60209
Value Function Loss: 0.08442

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.17043
Policy Update Magnitude: 0.50215
Value Function Update Magnitude: 0.57177

Collected Steps per Second: 11,794.66752
Overall Steps per Second: 6,759.06789

Timestep Collection Time: 4.24056
Timestep Consumption Time: 3.15928
PPO Batch Consumption Time: 0.39142
Total Iteration Time: 7.39984

Cumulative Model Updates: 105,574
Cumulative Timesteps: 880,621,088

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 880621088...
Checkpoint 880621088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,955.70139
Policy Entropy: 1.60620
Value Function Loss: 0.08018

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.16718
Policy Update Magnitude: 0.50374
Value Function Update Magnitude: 0.55260

Collected Steps per Second: 15,676.59806
Overall Steps per Second: 7,997.21507

Timestep Collection Time: 3.19125
Timestep Consumption Time: 3.06442
PPO Batch Consumption Time: 0.37517
Total Iteration Time: 6.25568

Cumulative Model Updates: 105,580
Cumulative Timesteps: 880,671,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,650.01523
Policy Entropy: 1.60485
Value Function Loss: 0.07577

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.16981
Policy Update Magnitude: 0.49197
Value Function Update Magnitude: 0.66514

Collected Steps per Second: 16,707.66623
Overall Steps per Second: 8,175.22848

Timestep Collection Time: 2.99288
Timestep Consumption Time: 3.12365
PPO Batch Consumption Time: 0.37696
Total Iteration Time: 6.11653

Cumulative Model Updates: 105,586
Cumulative Timesteps: 880,721,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 880721120...
Checkpoint 880721120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,777.49905
Policy Entropy: 1.60263
Value Function Loss: 0.06810

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.16753
Policy Update Magnitude: 0.50053
Value Function Update Magnitude: 0.59473

Collected Steps per Second: 15,998.12952
Overall Steps per Second: 7,887.66603

Timestep Collection Time: 3.12562
Timestep Consumption Time: 3.21390
PPO Batch Consumption Time: 0.39771
Total Iteration Time: 6.33952

Cumulative Model Updates: 105,592
Cumulative Timesteps: 880,771,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,071.86778
Policy Entropy: 1.60636
Value Function Loss: 0.07704

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.15779
Policy Update Magnitude: 0.54969
Value Function Update Magnitude: 0.65008

Collected Steps per Second: 15,056.91030
Overall Steps per Second: 8,511.92443

Timestep Collection Time: 3.32073
Timestep Consumption Time: 2.55338
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 5.87411

Cumulative Model Updates: 105,598
Cumulative Timesteps: 880,821,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 880821124...
Checkpoint 880821124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,346.92589
Policy Entropy: 1.62106
Value Function Loss: 0.08512

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.15175
Policy Update Magnitude: 0.59823
Value Function Update Magnitude: 0.59625

Collected Steps per Second: 15,897.12499
Overall Steps per Second: 8,341.11578

Timestep Collection Time: 3.14661
Timestep Consumption Time: 2.85043
PPO Batch Consumption Time: 0.31788
Total Iteration Time: 5.99704

Cumulative Model Updates: 105,604
Cumulative Timesteps: 880,871,146

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,008.03972
Policy Entropy: 1.63214
Value Function Loss: 0.08478

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.15141
Policy Update Magnitude: 0.60243
Value Function Update Magnitude: 0.60626

Collected Steps per Second: 16,753.74757
Overall Steps per Second: 7,511.01060

Timestep Collection Time: 2.98596
Timestep Consumption Time: 3.67440
PPO Batch Consumption Time: 0.45090
Total Iteration Time: 6.66036

Cumulative Model Updates: 105,610
Cumulative Timesteps: 880,921,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 880921172...
Checkpoint 880921172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,921.47277
Policy Entropy: 1.63312
Value Function Loss: 0.08879

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.16495
Policy Update Magnitude: 0.59020
Value Function Update Magnitude: 0.68056

Collected Steps per Second: 17,430.10467
Overall Steps per Second: 7,634.40846

Timestep Collection Time: 2.86860
Timestep Consumption Time: 3.68070
PPO Batch Consumption Time: 0.45890
Total Iteration Time: 6.54930

Cumulative Model Updates: 105,616
Cumulative Timesteps: 880,971,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,628.19139
Policy Entropy: 1.62124
Value Function Loss: 0.09244

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.18512
Policy Update Magnitude: 0.55077
Value Function Update Magnitude: 0.62581

Collected Steps per Second: 12,875.18221
Overall Steps per Second: 5,597.27137

Timestep Collection Time: 3.88391
Timestep Consumption Time: 5.05009
PPO Batch Consumption Time: 0.66991
Total Iteration Time: 8.93400

Cumulative Model Updates: 105,622
Cumulative Timesteps: 881,021,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 881021178...
Checkpoint 881021178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,098.68357
Policy Entropy: 1.61194
Value Function Loss: 0.08695

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.17945
Policy Update Magnitude: 0.54524
Value Function Update Magnitude: 0.68271

Collected Steps per Second: 10,543.55588
Overall Steps per Second: 5,053.40255

Timestep Collection Time: 4.74280
Timestep Consumption Time: 5.15271
PPO Batch Consumption Time: 0.67146
Total Iteration Time: 9.89551

Cumulative Model Updates: 105,628
Cumulative Timesteps: 881,071,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,875.62723
Policy Entropy: 1.61846
Value Function Loss: 0.07825

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.18651
Policy Update Magnitude: 0.52943
Value Function Update Magnitude: 0.63790

Collected Steps per Second: 10,754.47185
Overall Steps per Second: 4,308.34187

Timestep Collection Time: 4.65090
Timestep Consumption Time: 6.95867
PPO Batch Consumption Time: 0.97260
Total Iteration Time: 11.60957

Cumulative Model Updates: 105,634
Cumulative Timesteps: 881,121,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 881121202...
Checkpoint 881121202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,906.07030
Policy Entropy: 1.61604
Value Function Loss: 0.06855

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.16420
Policy Update Magnitude: 0.48571
Value Function Update Magnitude: 0.53616

Collected Steps per Second: 5,335.32098
Overall Steps per Second: 2,978.94700

Timestep Collection Time: 9.37151
Timestep Consumption Time: 7.41295
PPO Batch Consumption Time: 1.02433
Total Iteration Time: 16.78445

Cumulative Model Updates: 105,640
Cumulative Timesteps: 881,171,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,889.59723
Policy Entropy: 1.61643
Value Function Loss: 0.07232

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.16374
Policy Update Magnitude: 0.47216
Value Function Update Magnitude: 0.39771

Collected Steps per Second: 5,044.55213
Overall Steps per Second: 2,901.43354

Timestep Collection Time: 9.91525
Timestep Consumption Time: 7.32381
PPO Batch Consumption Time: 1.02162
Total Iteration Time: 17.23906

Cumulative Model Updates: 105,646
Cumulative Timesteps: 881,221,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 881221220...
Checkpoint 881221220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,082.43287
Policy Entropy: 1.60745
Value Function Loss: 0.07009

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.49064
Value Function Update Magnitude: 0.51867

Collected Steps per Second: 4,903.11456
Overall Steps per Second: 2,881.51300

Timestep Collection Time: 10.19882
Timestep Consumption Time: 7.15525
PPO Batch Consumption Time: 0.99719
Total Iteration Time: 17.35408

Cumulative Model Updates: 105,652
Cumulative Timesteps: 881,271,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,068.52213
Policy Entropy: 1.62638
Value Function Loss: 0.07757

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.15317
Policy Update Magnitude: 0.55420
Value Function Update Magnitude: 0.56156

Collected Steps per Second: 5,061.87209
Overall Steps per Second: 2,962.39140

Timestep Collection Time: 9.88607
Timestep Consumption Time: 7.00637
PPO Batch Consumption Time: 0.98261
Total Iteration Time: 16.89243

Cumulative Model Updates: 105,658
Cumulative Timesteps: 881,321,268

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 881321268...
Checkpoint 881321268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,547.69824
Policy Entropy: 1.63623
Value Function Loss: 0.07780

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.14327
Policy Update Magnitude: 0.59467
Value Function Update Magnitude: 0.66030

Collected Steps per Second: 5,153.25855
Overall Steps per Second: 2,950.52591

Timestep Collection Time: 9.70687
Timestep Consumption Time: 7.24672
PPO Batch Consumption Time: 1.00243
Total Iteration Time: 16.95359

Cumulative Model Updates: 105,664
Cumulative Timesteps: 881,371,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,701.25676
Policy Entropy: 1.64589
Value Function Loss: 0.07901

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.14962
Policy Update Magnitude: 0.60222
Value Function Update Magnitude: 0.69703

Collected Steps per Second: 5,227.25804
Overall Steps per Second: 2,993.83162

Timestep Collection Time: 9.57060
Timestep Consumption Time: 7.13976
PPO Batch Consumption Time: 0.99996
Total Iteration Time: 16.71036

Cumulative Model Updates: 105,670
Cumulative Timesteps: 881,421,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 881421318...
Checkpoint 881421318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,259.52580
Policy Entropy: 1.62525
Value Function Loss: 0.07944

Mean KL Divergence: 0.02807
SB3 Clip Fraction: 0.17982
Policy Update Magnitude: 0.56483
Value Function Update Magnitude: 0.69609

Collected Steps per Second: 5,122.65565
Overall Steps per Second: 2,905.88223

Timestep Collection Time: 9.76095
Timestep Consumption Time: 7.44621
PPO Batch Consumption Time: 1.04725
Total Iteration Time: 17.20717

Cumulative Model Updates: 105,676
Cumulative Timesteps: 881,471,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,788.15591
Policy Entropy: 1.62775
Value Function Loss: 0.07880

Mean KL Divergence: 0.02632
SB3 Clip Fraction: 0.15049
Policy Update Magnitude: 0.52147
Value Function Update Magnitude: 0.61347

Collected Steps per Second: 4,795.71840
Overall Steps per Second: 2,839.72410

Timestep Collection Time: 10.42680
Timestep Consumption Time: 7.18195
PPO Batch Consumption Time: 1.00297
Total Iteration Time: 17.60875

Cumulative Model Updates: 105,682
Cumulative Timesteps: 881,521,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 881521324...
Checkpoint 881521324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,588.46748
Policy Entropy: 1.63762
Value Function Loss: 0.07736

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.55762
Value Function Update Magnitude: 0.48549

Collected Steps per Second: 4,851.22167
Overall Steps per Second: 2,846.77553

Timestep Collection Time: 10.30792
Timestep Consumption Time: 7.25792
PPO Batch Consumption Time: 1.01364
Total Iteration Time: 17.56584

Cumulative Model Updates: 105,688
Cumulative Timesteps: 881,571,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,636.35357
Policy Entropy: 1.65290
Value Function Loss: 0.07287

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.13456
Policy Update Magnitude: 0.56156
Value Function Update Magnitude: 0.56691

Collected Steps per Second: 5,298.19121
Overall Steps per Second: 2,985.41302

Timestep Collection Time: 9.44322
Timestep Consumption Time: 7.31560
PPO Batch Consumption Time: 1.03175
Total Iteration Time: 16.75882

Cumulative Model Updates: 105,694
Cumulative Timesteps: 881,621,362

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 881621362...
Checkpoint 881621362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,046.68677
Policy Entropy: 1.66549
Value Function Loss: 0.07621

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13772
Policy Update Magnitude: 0.57170
Value Function Update Magnitude: 0.64246

Collected Steps per Second: 4,962.48461
Overall Steps per Second: 2,903.12963

Timestep Collection Time: 10.08084
Timestep Consumption Time: 7.15091
PPO Batch Consumption Time: 1.00086
Total Iteration Time: 17.23175

Cumulative Model Updates: 105,700
Cumulative Timesteps: 881,671,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,268.34768
Policy Entropy: 1.66631
Value Function Loss: 0.07799

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.14120
Policy Update Magnitude: 0.58976
Value Function Update Magnitude: 0.63120

Collected Steps per Second: 4,876.44990
Overall Steps per Second: 2,858.90566

Timestep Collection Time: 10.25992
Timestep Consumption Time: 7.24048
PPO Batch Consumption Time: 1.02224
Total Iteration Time: 17.50040

Cumulative Model Updates: 105,706
Cumulative Timesteps: 881,721,420

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 881721420...
Checkpoint 881721420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,731.11720
Policy Entropy: 1.67377
Value Function Loss: 0.08811

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.14621
Policy Update Magnitude: 0.59142
Value Function Update Magnitude: 0.54011

Collected Steps per Second: 4,923.87198
Overall Steps per Second: 2,879.48872

Timestep Collection Time: 10.15623
Timestep Consumption Time: 7.21074
PPO Batch Consumption Time: 1.00641
Total Iteration Time: 17.36697

Cumulative Model Updates: 105,712
Cumulative Timesteps: 881,771,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,660.19723
Policy Entropy: 1.67218
Value Function Loss: 0.09359

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.14800
Policy Update Magnitude: 0.59651
Value Function Update Magnitude: 0.39140

Collected Steps per Second: 4,758.00610
Overall Steps per Second: 2,828.74240

Timestep Collection Time: 10.50860
Timestep Consumption Time: 7.16710
PPO Batch Consumption Time: 1.02203
Total Iteration Time: 17.67570

Cumulative Model Updates: 105,718
Cumulative Timesteps: 881,821,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 881821428...
Checkpoint 881821428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,875.10927
Policy Entropy: 1.67732
Value Function Loss: 0.08871

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.14682
Policy Update Magnitude: 0.57298
Value Function Update Magnitude: 0.51310

Collected Steps per Second: 5,125.68892
Overall Steps per Second: 3,011.05206

Timestep Collection Time: 9.75908
Timestep Consumption Time: 6.85372
PPO Batch Consumption Time: 0.97745
Total Iteration Time: 16.61280

Cumulative Model Updates: 105,724
Cumulative Timesteps: 881,871,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,438.09225
Policy Entropy: 1.66721
Value Function Loss: 0.08310

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.14483
Policy Update Magnitude: 0.56131
Value Function Update Magnitude: 0.56191

Collected Steps per Second: 5,141.92700
Overall Steps per Second: 3,047.52206

Timestep Collection Time: 9.72593
Timestep Consumption Time: 6.68413
PPO Batch Consumption Time: 0.95244
Total Iteration Time: 16.41005

Cumulative Model Updates: 105,730
Cumulative Timesteps: 881,921,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 881921460...
Checkpoint 881921460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,117.28499
Policy Entropy: 1.66805
Value Function Loss: 0.08327

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.17297
Policy Update Magnitude: 0.50453
Value Function Update Magnitude: 0.45635

Collected Steps per Second: 5,029.22304
Overall Steps per Second: 2,909.53784

Timestep Collection Time: 9.94388
Timestep Consumption Time: 7.24441
PPO Batch Consumption Time: 1.03482
Total Iteration Time: 17.18830

Cumulative Model Updates: 105,736
Cumulative Timesteps: 881,971,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,871.40970
Policy Entropy: 1.66503
Value Function Loss: 0.09020

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.16385
Policy Update Magnitude: 0.48631
Value Function Update Magnitude: 0.38240

Collected Steps per Second: 4,883.65238
Overall Steps per Second: 2,866.75497

Timestep Collection Time: 10.24029
Timestep Consumption Time: 7.20452
PPO Batch Consumption Time: 1.01333
Total Iteration Time: 17.44481

Cumulative Model Updates: 105,742
Cumulative Timesteps: 882,021,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 882021480...
Checkpoint 882021480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,970.15683
Policy Entropy: 1.66642
Value Function Loss: 0.08628

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.15814
Policy Update Magnitude: 0.52251
Value Function Update Magnitude: 0.36687

Collected Steps per Second: 4,814.55794
Overall Steps per Second: 2,854.90627

Timestep Collection Time: 10.38849
Timestep Consumption Time: 7.13082
PPO Batch Consumption Time: 1.00836
Total Iteration Time: 17.51931

Cumulative Model Updates: 105,748
Cumulative Timesteps: 882,071,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,976.25707
Policy Entropy: 1.66355
Value Function Loss: 0.08380

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.17430
Policy Update Magnitude: 0.56845
Value Function Update Magnitude: 0.55303

Collected Steps per Second: 4,972.62783
Overall Steps per Second: 2,878.44934

Timestep Collection Time: 10.05786
Timestep Consumption Time: 7.31747
PPO Batch Consumption Time: 1.02982
Total Iteration Time: 17.37533

Cumulative Model Updates: 105,754
Cumulative Timesteps: 882,121,510

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 882121510...
Checkpoint 882121510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,605.83355
Policy Entropy: 1.68895
Value Function Loss: 0.07960

Mean KL Divergence: 0.02303
SB3 Clip Fraction: 0.19034
Policy Update Magnitude: 0.56416
Value Function Update Magnitude: 0.67005

Collected Steps per Second: 5,013.49078
Overall Steps per Second: 2,893.00507

Timestep Collection Time: 9.97748
Timestep Consumption Time: 7.31319
PPO Batch Consumption Time: 1.03719
Total Iteration Time: 17.29067

Cumulative Model Updates: 105,760
Cumulative Timesteps: 882,171,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,400.57514
Policy Entropy: 1.69342
Value Function Loss: 0.08503

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.19074
Policy Update Magnitude: 0.53395
Value Function Update Magnitude: 0.60824

Collected Steps per Second: 5,031.42204
Overall Steps per Second: 2,873.20886

Timestep Collection Time: 9.93914
Timestep Consumption Time: 7.46579
PPO Batch Consumption Time: 1.06343
Total Iteration Time: 17.40493

Cumulative Model Updates: 105,766
Cumulative Timesteps: 882,221,540

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 882221540...
Checkpoint 882221540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,817.93336
Policy Entropy: 1.69517
Value Function Loss: 0.08409

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.18706
Policy Update Magnitude: 0.48270
Value Function Update Magnitude: 0.57877

Collected Steps per Second: 5,004.13461
Overall Steps per Second: 2,879.05807

Timestep Collection Time: 9.99573
Timestep Consumption Time: 7.37800
PPO Batch Consumption Time: 1.04365
Total Iteration Time: 17.37374

Cumulative Model Updates: 105,772
Cumulative Timesteps: 882,271,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,962.15620
Policy Entropy: 1.68643
Value Function Loss: 0.08768

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.14624
Policy Update Magnitude: 0.53749
Value Function Update Magnitude: 0.43933

Collected Steps per Second: 4,945.49002
Overall Steps per Second: 2,852.07203

Timestep Collection Time: 10.11993
Timestep Consumption Time: 7.42802
PPO Batch Consumption Time: 1.04541
Total Iteration Time: 17.54794

Cumulative Model Updates: 105,778
Cumulative Timesteps: 882,321,608

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 882321608...
Checkpoint 882321608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,739.19943
Policy Entropy: 1.68772
Value Function Loss: 0.09045

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.15121
Policy Update Magnitude: 0.58448
Value Function Update Magnitude: 0.41748

Collected Steps per Second: 4,983.08155
Overall Steps per Second: 2,868.32500

Timestep Collection Time: 10.03957
Timestep Consumption Time: 7.40197
PPO Batch Consumption Time: 1.05278
Total Iteration Time: 17.44154

Cumulative Model Updates: 105,784
Cumulative Timesteps: 882,371,636

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,090.63912
Policy Entropy: 1.68758
Value Function Loss: 0.08605

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.15209
Policy Update Magnitude: 0.58030
Value Function Update Magnitude: 0.36113

Collected Steps per Second: 5,120.54715
Overall Steps per Second: 2,933.42315

Timestep Collection Time: 9.76693
Timestep Consumption Time: 7.28210
PPO Batch Consumption Time: 1.02302
Total Iteration Time: 17.04902

Cumulative Model Updates: 105,790
Cumulative Timesteps: 882,421,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 882421648...
Checkpoint 882421648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,623.60061
Policy Entropy: 1.68107
Value Function Loss: 0.08518

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.58045
Value Function Update Magnitude: 0.38510

Collected Steps per Second: 5,111.04384
Overall Steps per Second: 2,914.21028

Timestep Collection Time: 9.78469
Timestep Consumption Time: 7.37604
PPO Batch Consumption Time: 1.04804
Total Iteration Time: 17.16074

Cumulative Model Updates: 105,796
Cumulative Timesteps: 882,471,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,785.21571
Policy Entropy: 1.67841
Value Function Loss: 0.08612

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14464
Policy Update Magnitude: 0.59503
Value Function Update Magnitude: 0.43393

Collected Steps per Second: 5,149.78104
Overall Steps per Second: 2,957.31159

Timestep Collection Time: 9.71109
Timestep Consumption Time: 7.19954
PPO Batch Consumption Time: 1.01573
Total Iteration Time: 16.91063

Cumulative Model Updates: 105,802
Cumulative Timesteps: 882,521,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 882521668...
Checkpoint 882521668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,261.51620
Policy Entropy: 1.69047
Value Function Loss: 0.08674

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.14477
Policy Update Magnitude: 0.60005
Value Function Update Magnitude: 0.55459

Collected Steps per Second: 5,146.89788
Overall Steps per Second: 2,966.12914

Timestep Collection Time: 9.71653
Timestep Consumption Time: 7.14383
PPO Batch Consumption Time: 1.00184
Total Iteration Time: 16.86036

Cumulative Model Updates: 105,808
Cumulative Timesteps: 882,571,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,366.91935
Policy Entropy: 1.70188
Value Function Loss: 0.08529

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.59005
Value Function Update Magnitude: 0.70515

Collected Steps per Second: 5,136.94540
Overall Steps per Second: 2,925.12423

Timestep Collection Time: 9.74159
Timestep Consumption Time: 7.36606
PPO Batch Consumption Time: 1.04164
Total Iteration Time: 17.10765

Cumulative Model Updates: 105,814
Cumulative Timesteps: 882,621,720

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 882621720...
Checkpoint 882621720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,435.59299
Policy Entropy: 1.69479
Value Function Loss: 0.07686

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.58832
Value Function Update Magnitude: 0.66480

Collected Steps per Second: 5,144.78760
Overall Steps per Second: 2,919.69784

Timestep Collection Time: 9.72052
Timestep Consumption Time: 7.40797
PPO Batch Consumption Time: 1.05400
Total Iteration Time: 17.12848

Cumulative Model Updates: 105,820
Cumulative Timesteps: 882,671,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,093.71698
Policy Entropy: 1.70288
Value Function Loss: 0.07701

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.58515
Value Function Update Magnitude: 0.71868

Collected Steps per Second: 5,099.04407
Overall Steps per Second: 2,915.94655

Timestep Collection Time: 9.81047
Timestep Consumption Time: 7.34486
PPO Batch Consumption Time: 1.03251
Total Iteration Time: 17.15532

Cumulative Model Updates: 105,826
Cumulative Timesteps: 882,721,754

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 882721754...
Checkpoint 882721754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,263.68285
Policy Entropy: 1.68760
Value Function Loss: 0.07589

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.58453
Value Function Update Magnitude: 0.74657

Collected Steps per Second: 5,072.26133
Overall Steps per Second: 2,882.00416

Timestep Collection Time: 9.86582
Timestep Consumption Time: 7.49779
PPO Batch Consumption Time: 1.04782
Total Iteration Time: 17.36361

Cumulative Model Updates: 105,832
Cumulative Timesteps: 882,771,796

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,714.12729
Policy Entropy: 1.68156
Value Function Loss: 0.07918

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.15384
Policy Update Magnitude: 0.56978
Value Function Update Magnitude: 0.76243

Collected Steps per Second: 4,941.91901
Overall Steps per Second: 2,855.31833

Timestep Collection Time: 10.12117
Timestep Consumption Time: 7.39632
PPO Batch Consumption Time: 1.03516
Total Iteration Time: 17.51749

Cumulative Model Updates: 105,838
Cumulative Timesteps: 882,821,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 882821814...
Checkpoint 882821814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,903.23232
Policy Entropy: 1.66551
Value Function Loss: 0.07796

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.14698
Policy Update Magnitude: 0.56652
Value Function Update Magnitude: 0.78859

Collected Steps per Second: 4,909.53350
Overall Steps per Second: 2,876.88413

Timestep Collection Time: 10.18427
Timestep Consumption Time: 7.19565
PPO Batch Consumption Time: 1.01086
Total Iteration Time: 17.37991

Cumulative Model Updates: 105,844
Cumulative Timesteps: 882,871,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,882.85736
Policy Entropy: 1.66214
Value Function Loss: 0.07316

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.14575
Policy Update Magnitude: 0.57815
Value Function Update Magnitude: 0.73808

Collected Steps per Second: 4,815.72013
Overall Steps per Second: 3,139.63607

Timestep Collection Time: 10.39097
Timestep Consumption Time: 5.54718
PPO Batch Consumption Time: 0.74493
Total Iteration Time: 15.93815

Cumulative Model Updates: 105,850
Cumulative Timesteps: 882,921,854

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 882921854...
Checkpoint 882921854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,011.73701
Policy Entropy: 1.65284
Value Function Loss: 0.06688

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.56357
Value Function Update Magnitude: 0.69592

Collected Steps per Second: 13,884.40880
Overall Steps per Second: 7,288.50162

Timestep Collection Time: 3.60174
Timestep Consumption Time: 3.25948
PPO Batch Consumption Time: 0.39708
Total Iteration Time: 6.86122

Cumulative Model Updates: 105,856
Cumulative Timesteps: 882,971,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,526.68989
Policy Entropy: 1.65106
Value Function Loss: 0.06916

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.56412
Value Function Update Magnitude: 0.58582

Collected Steps per Second: 15,193.12515
Overall Steps per Second: 7,668.10176

Timestep Collection Time: 3.29109
Timestep Consumption Time: 3.22969
PPO Batch Consumption Time: 0.40300
Total Iteration Time: 6.52078

Cumulative Model Updates: 105,862
Cumulative Timesteps: 883,021,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 883021864...
Checkpoint 883021864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,693.37142
Policy Entropy: 1.64309
Value Function Loss: 0.07205

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.14501
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.62853

Collected Steps per Second: 15,212.97758
Overall Steps per Second: 7,794.14071

Timestep Collection Time: 3.28851
Timestep Consumption Time: 3.13016
PPO Batch Consumption Time: 0.38220
Total Iteration Time: 6.41867

Cumulative Model Updates: 105,868
Cumulative Timesteps: 883,071,892

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,975.81943
Policy Entropy: 1.64905
Value Function Loss: 0.08108

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.56013
Value Function Update Magnitude: 0.58565

Collected Steps per Second: 14,991.18150
Overall Steps per Second: 7,632.01479

Timestep Collection Time: 3.33583
Timestep Consumption Time: 3.21657
PPO Batch Consumption Time: 0.39659
Total Iteration Time: 6.55240

Cumulative Model Updates: 105,874
Cumulative Timesteps: 883,121,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 883121900...
Checkpoint 883121900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,120.29544
Policy Entropy: 1.64335
Value Function Loss: 0.08256

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.57037
Value Function Update Magnitude: 0.45564

Collected Steps per Second: 14,164.81526
Overall Steps per Second: 7,227.18444

Timestep Collection Time: 3.53199
Timestep Consumption Time: 3.39048
PPO Batch Consumption Time: 0.41572
Total Iteration Time: 6.92247

Cumulative Model Updates: 105,880
Cumulative Timesteps: 883,171,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,584.62190
Policy Entropy: 1.65541
Value Function Loss: 0.08321

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.14417
Policy Update Magnitude: 0.55535
Value Function Update Magnitude: 0.39711

Collected Steps per Second: 14,430.53818
Overall Steps per Second: 7,309.32182

Timestep Collection Time: 3.46598
Timestep Consumption Time: 3.37679
PPO Batch Consumption Time: 0.41681
Total Iteration Time: 6.84277

Cumulative Model Updates: 105,886
Cumulative Timesteps: 883,221,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 883221946...
Checkpoint 883221946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,526.25739
Policy Entropy: 1.65102
Value Function Loss: 0.07321

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.14358
Policy Update Magnitude: 0.54897
Value Function Update Magnitude: 0.47014

Collected Steps per Second: 11,862.99142
Overall Steps per Second: 6,702.00449

Timestep Collection Time: 4.21513
Timestep Consumption Time: 3.24593
PPO Batch Consumption Time: 0.39457
Total Iteration Time: 7.46105

Cumulative Model Updates: 105,892
Cumulative Timesteps: 883,271,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,336.91415
Policy Entropy: 1.65752
Value Function Loss: 0.07460

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.46540

Collected Steps per Second: 15,055.61231
Overall Steps per Second: 7,461.76524

Timestep Collection Time: 3.32235
Timestep Consumption Time: 3.38116
PPO Batch Consumption Time: 0.41501
Total Iteration Time: 6.70351

Cumulative Model Updates: 105,898
Cumulative Timesteps: 883,321,970

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 883321970...
Checkpoint 883321970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,420.18741
Policy Entropy: 1.65093
Value Function Loss: 0.07172

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.54822
Value Function Update Magnitude: 0.38830

Collected Steps per Second: 14,697.89467
Overall Steps per Second: 7,382.44499

Timestep Collection Time: 3.40266
Timestep Consumption Time: 3.37179
PPO Batch Consumption Time: 0.42510
Total Iteration Time: 6.77445

Cumulative Model Updates: 105,904
Cumulative Timesteps: 883,371,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,695.36134
Policy Entropy: 1.65091
Value Function Loss: 0.07680

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.54786
Value Function Update Magnitude: 0.34926

Collected Steps per Second: 11,761.92321
Overall Steps per Second: 6,610.61794

Timestep Collection Time: 4.25322
Timestep Consumption Time: 3.31431
PPO Batch Consumption Time: 0.41432
Total Iteration Time: 7.56752

Cumulative Model Updates: 105,910
Cumulative Timesteps: 883,422,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 883422008...
Checkpoint 883422008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,655.73641
Policy Entropy: 1.65166
Value Function Loss: 0.07280

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.53606
Value Function Update Magnitude: 0.34733

Collected Steps per Second: 14,335.64379
Overall Steps per Second: 7,375.62723

Timestep Collection Time: 3.48921
Timestep Consumption Time: 3.29259
PPO Batch Consumption Time: 0.41308
Total Iteration Time: 6.78180

Cumulative Model Updates: 105,916
Cumulative Timesteps: 883,472,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,040.45128
Policy Entropy: 1.66874
Value Function Loss: 0.07434

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.15949
Policy Update Magnitude: 0.49188
Value Function Update Magnitude: 0.36977

Collected Steps per Second: 15,434.66977
Overall Steps per Second: 7,746.21488

Timestep Collection Time: 3.24127
Timestep Consumption Time: 3.21711
PPO Batch Consumption Time: 0.41015
Total Iteration Time: 6.45838

Cumulative Model Updates: 105,922
Cumulative Timesteps: 883,522,056

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 883522056...
Checkpoint 883522056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,950.78938
Policy Entropy: 1.66850
Value Function Loss: 0.07037

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.48626
Value Function Update Magnitude: 0.36986

Collected Steps per Second: 12,042.33553
Overall Steps per Second: 4,266.96447

Timestep Collection Time: 4.15468
Timestep Consumption Time: 7.57076
PPO Batch Consumption Time: 1.08353
Total Iteration Time: 11.72543

Cumulative Model Updates: 105,928
Cumulative Timesteps: 883,572,088

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,246.78524
Policy Entropy: 1.66808
Value Function Loss: 0.06980

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13359
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.39660

Collected Steps per Second: 12,235.88065
Overall Steps per Second: 7,172.29985

Timestep Collection Time: 4.08765
Timestep Consumption Time: 2.88585
PPO Batch Consumption Time: 0.33899
Total Iteration Time: 6.97350

Cumulative Model Updates: 105,934
Cumulative Timesteps: 883,622,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 883622104...
Checkpoint 883622104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,423.38249
Policy Entropy: 1.66477
Value Function Loss: 0.08088

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.14660
Policy Update Magnitude: 0.56420
Value Function Update Magnitude: 0.45019

Collected Steps per Second: 12,198.52657
Overall Steps per Second: 7,621.40492

Timestep Collection Time: 4.10131
Timestep Consumption Time: 2.46309
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 6.56441

Cumulative Model Updates: 105,940
Cumulative Timesteps: 883,672,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,522.04421
Policy Entropy: 1.66056
Value Function Loss: 0.08378

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.16102
Policy Update Magnitude: 0.55278
Value Function Update Magnitude: 0.54904

Collected Steps per Second: 18,969.68150
Overall Steps per Second: 9,784.45184

Timestep Collection Time: 2.63747
Timestep Consumption Time: 2.47595
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 5.11342

Cumulative Model Updates: 105,946
Cumulative Timesteps: 883,722,166

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 883722166...
Checkpoint 883722166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,339.21184
Policy Entropy: 1.66237
Value Function Loss: 0.08795

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.17138
Policy Update Magnitude: 0.48649
Value Function Update Magnitude: 0.49887

Collected Steps per Second: 18,008.10213
Overall Steps per Second: 9,401.77910

Timestep Collection Time: 2.77742
Timestep Consumption Time: 2.54243
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 5.31984

Cumulative Model Updates: 105,952
Cumulative Timesteps: 883,772,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,867.95278
Policy Entropy: 1.65168
Value Function Loss: 0.08667

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.16411
Policy Update Magnitude: 0.52903
Value Function Update Magnitude: 0.42501

Collected Steps per Second: 17,848.07530
Overall Steps per Second: 8,235.54875

Timestep Collection Time: 2.80198
Timestep Consumption Time: 3.27047
PPO Batch Consumption Time: 0.39279
Total Iteration Time: 6.07246

Cumulative Model Updates: 105,958
Cumulative Timesteps: 883,822,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 883822192...
Checkpoint 883822192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,348.86335
Policy Entropy: 1.64594
Value Function Loss: 0.08381

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.15956
Policy Update Magnitude: 0.56281
Value Function Update Magnitude: 0.40769

Collected Steps per Second: 13,975.42420
Overall Steps per Second: 7,158.46729

Timestep Collection Time: 3.58057
Timestep Consumption Time: 3.40975
PPO Batch Consumption Time: 0.41036
Total Iteration Time: 6.99032

Cumulative Model Updates: 105,964
Cumulative Timesteps: 883,872,232

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,641.63587
Policy Entropy: 1.65006
Value Function Loss: 0.08862

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.15921
Policy Update Magnitude: 0.57008
Value Function Update Magnitude: 0.48119

Collected Steps per Second: 14,220.03608
Overall Steps per Second: 7,421.57333

Timestep Collection Time: 3.51743
Timestep Consumption Time: 3.22211
PPO Batch Consumption Time: 0.40424
Total Iteration Time: 6.73954

Cumulative Model Updates: 105,970
Cumulative Timesteps: 883,922,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 883922250...
Checkpoint 883922250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,446.60223
Policy Entropy: 1.65210
Value Function Loss: 0.08257

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.16832
Policy Update Magnitude: 0.52072
Value Function Update Magnitude: 0.64898

Collected Steps per Second: 14,386.62404
Overall Steps per Second: 7,442.14558

Timestep Collection Time: 3.47684
Timestep Consumption Time: 3.24434
PPO Batch Consumption Time: 0.39045
Total Iteration Time: 6.72118

Cumulative Model Updates: 105,976
Cumulative Timesteps: 883,972,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,635.03323
Policy Entropy: 1.66204
Value Function Loss: 0.08101

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.16306
Policy Update Magnitude: 0.45868
Value Function Update Magnitude: 0.73741

Collected Steps per Second: 15,989.45224
Overall Steps per Second: 7,906.11588

Timestep Collection Time: 3.12969
Timestep Consumption Time: 3.19984
PPO Batch Consumption Time: 0.39796
Total Iteration Time: 6.32953

Cumulative Model Updates: 105,982
Cumulative Timesteps: 884,022,312

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 884022312...
Checkpoint 884022312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,198.88368
Policy Entropy: 1.65877
Value Function Loss: 0.07649

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.15421
Policy Update Magnitude: 0.46989
Value Function Update Magnitude: 0.59275

Collected Steps per Second: 14,067.89926
Overall Steps per Second: 4,881.95962

Timestep Collection Time: 3.55433
Timestep Consumption Time: 6.68787
PPO Batch Consumption Time: 0.95520
Total Iteration Time: 10.24220

Cumulative Model Updates: 105,988
Cumulative Timesteps: 884,072,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,284.50929
Policy Entropy: 1.65017
Value Function Loss: 0.08264

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.51711
Value Function Update Magnitude: 0.55049

Collected Steps per Second: 5,235.14478
Overall Steps per Second: 2,951.93142

Timestep Collection Time: 9.55274
Timestep Consumption Time: 7.38871
PPO Batch Consumption Time: 1.03264
Total Iteration Time: 16.94145

Cumulative Model Updates: 105,994
Cumulative Timesteps: 884,122,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 884122324...
Checkpoint 884122324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,887.76171
Policy Entropy: 1.65277
Value Function Loss: 0.08342

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.55674
Value Function Update Magnitude: 0.53347

Collected Steps per Second: 5,042.71465
Overall Steps per Second: 2,872.42898

Timestep Collection Time: 9.91767
Timestep Consumption Time: 7.49337
PPO Batch Consumption Time: 1.05121
Total Iteration Time: 17.41105

Cumulative Model Updates: 106,000
Cumulative Timesteps: 884,172,336

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,315.77915
Policy Entropy: 1.64786
Value Function Loss: 0.09320

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.58376
Value Function Update Magnitude: 0.46886

Collected Steps per Second: 5,017.50812
Overall Steps per Second: 2,913.30055

Timestep Collection Time: 9.97069
Timestep Consumption Time: 7.20159
PPO Batch Consumption Time: 1.01422
Total Iteration Time: 17.17228

Cumulative Model Updates: 106,006
Cumulative Timesteps: 884,222,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 884222364...
Checkpoint 884222364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,403.53235
Policy Entropy: 1.66521
Value Function Loss: 0.09645

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.15666
Policy Update Magnitude: 0.57595
Value Function Update Magnitude: 0.45333

Collected Steps per Second: 5,193.38669
Overall Steps per Second: 2,985.06672

Timestep Collection Time: 9.63225
Timestep Consumption Time: 7.12583
PPO Batch Consumption Time: 0.99812
Total Iteration Time: 16.75808

Cumulative Model Updates: 106,012
Cumulative Timesteps: 884,272,388

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,638.40768
Policy Entropy: 1.65708
Value Function Loss: 0.08928

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.17248
Policy Update Magnitude: 0.52232
Value Function Update Magnitude: 0.67487

Collected Steps per Second: 5,280.12441
Overall Steps per Second: 3,010.97502

Timestep Collection Time: 9.47402
Timestep Consumption Time: 7.13987
PPO Batch Consumption Time: 0.98777
Total Iteration Time: 16.61389

Cumulative Model Updates: 106,018
Cumulative Timesteps: 884,322,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 884322412...
Checkpoint 884322412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,255.26113
Policy Entropy: 1.65111
Value Function Loss: 0.08003

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.15569
Policy Update Magnitude: 0.52625
Value Function Update Magnitude: 0.69533

Collected Steps per Second: 5,062.82715
Overall Steps per Second: 2,956.25619

Timestep Collection Time: 9.87591
Timestep Consumption Time: 7.03738
PPO Batch Consumption Time: 0.97695
Total Iteration Time: 16.91328

Cumulative Model Updates: 106,024
Cumulative Timesteps: 884,372,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,040.95890
Policy Entropy: 1.64301
Value Function Loss: 0.07437

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.17139
Policy Update Magnitude: 0.48081
Value Function Update Magnitude: 0.55217

Collected Steps per Second: 5,044.47333
Overall Steps per Second: 2,961.81922

Timestep Collection Time: 9.91660
Timestep Consumption Time: 6.97302
PPO Batch Consumption Time: 0.97534
Total Iteration Time: 16.88962

Cumulative Model Updates: 106,030
Cumulative Timesteps: 884,422,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 884422436...
Checkpoint 884422436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,694.37278
Policy Entropy: 1.65030
Value Function Loss: 0.07159

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.17308
Policy Update Magnitude: 0.47633
Value Function Update Magnitude: 0.61814

Collected Steps per Second: 5,118.48499
Overall Steps per Second: 2,985.01858

Timestep Collection Time: 9.77125
Timestep Consumption Time: 6.98375
PPO Batch Consumption Time: 0.98368
Total Iteration Time: 16.75500

Cumulative Model Updates: 106,036
Cumulative Timesteps: 884,472,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,038.79341
Policy Entropy: 1.65504
Value Function Loss: 0.07150

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.16997
Policy Update Magnitude: 0.48403
Value Function Update Magnitude: 0.60410

Collected Steps per Second: 4,937.29190
Overall Steps per Second: 2,849.64547

Timestep Collection Time: 10.12903
Timestep Consumption Time: 7.42052
PPO Batch Consumption Time: 1.05117
Total Iteration Time: 17.54955

Cumulative Model Updates: 106,042
Cumulative Timesteps: 884,522,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 884522460...
Checkpoint 884522460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,790.39795
Policy Entropy: 1.65789
Value Function Loss: 0.07438

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.15625
Policy Update Magnitude: 0.52105
Value Function Update Magnitude: 0.52308

Collected Steps per Second: 4,833.35833
Overall Steps per Second: 2,780.69603

Timestep Collection Time: 10.34891
Timestep Consumption Time: 7.63939
PPO Batch Consumption Time: 1.08232
Total Iteration Time: 17.98830

Cumulative Model Updates: 106,048
Cumulative Timesteps: 884,572,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,659.29823
Policy Entropy: 1.65206
Value Function Loss: 0.07691

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.16804
Policy Update Magnitude: 0.55281
Value Function Update Magnitude: 0.57866

Collected Steps per Second: 5,010.31810
Overall Steps per Second: 2,878.86586

Timestep Collection Time: 9.98619
Timestep Consumption Time: 7.39357
PPO Batch Consumption Time: 1.04556
Total Iteration Time: 17.37976

Cumulative Model Updates: 106,054
Cumulative Timesteps: 884,622,514

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 884622514...
Checkpoint 884622514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,688.82053
Policy Entropy: 1.66326
Value Function Loss: 0.07537

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.16407
Policy Update Magnitude: 0.56359
Value Function Update Magnitude: 0.66477

Collected Steps per Second: 5,189.86324
Overall Steps per Second: 2,979.03050

Timestep Collection Time: 9.63918
Timestep Consumption Time: 7.15354
PPO Batch Consumption Time: 1.00890
Total Iteration Time: 16.79271

Cumulative Model Updates: 106,060
Cumulative Timesteps: 884,672,540

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,767.33097
Policy Entropy: 1.66913
Value Function Loss: 0.08019

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.16145
Policy Update Magnitude: 0.57161
Value Function Update Magnitude: 0.74108

Collected Steps per Second: 4,896.34359
Overall Steps per Second: 2,876.99386

Timestep Collection Time: 10.22028
Timestep Consumption Time: 7.17357
PPO Batch Consumption Time: 1.00712
Total Iteration Time: 17.39385

Cumulative Model Updates: 106,066
Cumulative Timesteps: 884,722,582

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 884722582...
Checkpoint 884722582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,665.04034
Policy Entropy: 1.67261
Value Function Loss: 0.08044

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.15108
Policy Update Magnitude: 0.57678
Value Function Update Magnitude: 0.73885

Collected Steps per Second: 4,978.48921
Overall Steps per Second: 2,919.49958

Timestep Collection Time: 10.04642
Timestep Consumption Time: 7.08528
PPO Batch Consumption Time: 0.99375
Total Iteration Time: 17.13170

Cumulative Model Updates: 106,072
Cumulative Timesteps: 884,772,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,542.53791
Policy Entropy: 1.65775
Value Function Loss: 0.07803

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.14542
Policy Update Magnitude: 0.57355
Value Function Update Magnitude: 0.71318

Collected Steps per Second: 5,102.51720
Overall Steps per Second: 2,999.71976

Timestep Collection Time: 9.80183
Timestep Consumption Time: 6.87106
PPO Batch Consumption Time: 0.96491
Total Iteration Time: 16.67289

Cumulative Model Updates: 106,078
Cumulative Timesteps: 884,822,612

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 884822612...
Checkpoint 884822612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,620.41850
Policy Entropy: 1.65752
Value Function Loss: 0.06962

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.57374
Value Function Update Magnitude: 0.62992

Collected Steps per Second: 5,115.73570
Overall Steps per Second: 2,964.95140

Timestep Collection Time: 9.78080
Timestep Consumption Time: 7.09502
PPO Batch Consumption Time: 1.00086
Total Iteration Time: 16.87582

Cumulative Model Updates: 106,084
Cumulative Timesteps: 884,872,648

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,217.13663
Policy Entropy: 1.66003
Value Function Loss: 0.06879

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.55115
Value Function Update Magnitude: 0.60430

Collected Steps per Second: 4,932.76825
Overall Steps per Second: 2,878.31128

Timestep Collection Time: 10.13873
Timestep Consumption Time: 7.23674
PPO Batch Consumption Time: 1.01084
Total Iteration Time: 17.37547

Cumulative Model Updates: 106,090
Cumulative Timesteps: 884,922,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 884922660...
Checkpoint 884922660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,448.37191
Policy Entropy: 1.67036
Value Function Loss: 0.06958

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.53760
Value Function Update Magnitude: 0.53177

Collected Steps per Second: 4,999.58180
Overall Steps per Second: 2,899.37607

Timestep Collection Time: 10.00604
Timestep Consumption Time: 7.24802
PPO Batch Consumption Time: 1.02908
Total Iteration Time: 17.25406

Cumulative Model Updates: 106,096
Cumulative Timesteps: 884,972,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,165.90010
Policy Entropy: 1.66502
Value Function Loss: 0.07221

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.56068
Value Function Update Magnitude: 0.61754

Collected Steps per Second: 5,078.28768
Overall Steps per Second: 2,899.46445

Timestep Collection Time: 9.85253
Timestep Consumption Time: 7.40376
PPO Batch Consumption Time: 1.04168
Total Iteration Time: 17.25629

Cumulative Model Updates: 106,102
Cumulative Timesteps: 885,022,720

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 885022720...
Checkpoint 885022720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,005.69861
Policy Entropy: 1.65640
Value Function Loss: 0.07291

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14200
Policy Update Magnitude: 0.56536
Value Function Update Magnitude: 0.65504

Collected Steps per Second: 5,151.79618
Overall Steps per Second: 2,911.60667

Timestep Collection Time: 9.71079
Timestep Consumption Time: 7.47148
PPO Batch Consumption Time: 1.03711
Total Iteration Time: 17.18227

Cumulative Model Updates: 106,108
Cumulative Timesteps: 885,072,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,925.61999
Policy Entropy: 1.65649
Value Function Loss: 0.07052

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14469
Policy Update Magnitude: 0.56580
Value Function Update Magnitude: 0.68608

Collected Steps per Second: 5,145.34050
Overall Steps per Second: 2,897.01297

Timestep Collection Time: 9.72725
Timestep Consumption Time: 7.54917
PPO Batch Consumption Time: 1.03322
Total Iteration Time: 17.27642

Cumulative Model Updates: 106,114
Cumulative Timesteps: 885,122,798

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 885122798...
Checkpoint 885122798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,204.94069
Policy Entropy: 1.65749
Value Function Loss: 0.07059

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.55890
Value Function Update Magnitude: 0.73417

Collected Steps per Second: 5,159.98966
Overall Steps per Second: 2,888.80677

Timestep Collection Time: 9.68994
Timestep Consumption Time: 7.61824
PPO Batch Consumption Time: 1.04705
Total Iteration Time: 17.30818

Cumulative Model Updates: 106,120
Cumulative Timesteps: 885,172,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,507.61608
Policy Entropy: 1.66544
Value Function Loss: 0.06599

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.14820
Policy Update Magnitude: 0.55147
Value Function Update Magnitude: 0.67805

Collected Steps per Second: 5,068.56187
Overall Steps per Second: 2,895.33942

Timestep Collection Time: 9.86552
Timestep Consumption Time: 7.40499
PPO Batch Consumption Time: 1.03473
Total Iteration Time: 17.27051

Cumulative Model Updates: 106,126
Cumulative Timesteps: 885,222,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 885222802...
Checkpoint 885222802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,233.68957
Policy Entropy: 1.65840
Value Function Loss: 0.07096

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.14192
Policy Update Magnitude: 0.55825
Value Function Update Magnitude: 0.55484

Collected Steps per Second: 4,980.32014
Overall Steps per Second: 2,870.81101

Timestep Collection Time: 10.04273
Timestep Consumption Time: 7.37953
PPO Batch Consumption Time: 1.04143
Total Iteration Time: 17.42225

Cumulative Model Updates: 106,132
Cumulative Timesteps: 885,272,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,016.51703
Policy Entropy: 1.65591
Value Function Loss: 0.06971

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.13778
Policy Update Magnitude: 0.55590
Value Function Update Magnitude: 0.53223

Collected Steps per Second: 5,335.50556
Overall Steps per Second: 2,991.82111

Timestep Collection Time: 9.37606
Timestep Consumption Time: 7.34486
PPO Batch Consumption Time: 1.01968
Total Iteration Time: 16.72092

Cumulative Model Updates: 106,138
Cumulative Timesteps: 885,322,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 885322844...
Checkpoint 885322844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,291.26447
Policy Entropy: 1.66061
Value Function Loss: 0.07410

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.55244
Value Function Update Magnitude: 0.63580

Collected Steps per Second: 7,670.07571
Overall Steps per Second: 5,031.50761

Timestep Collection Time: 6.52379
Timestep Consumption Time: 3.42114
PPO Batch Consumption Time: 0.42303
Total Iteration Time: 9.94493

Cumulative Model Updates: 106,144
Cumulative Timesteps: 885,372,882

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,918.23199
Policy Entropy: 1.66912
Value Function Loss: 0.08320

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13609
Policy Update Magnitude: 0.56275
Value Function Update Magnitude: 0.54838

Collected Steps per Second: 13,877.58755
Overall Steps per Second: 7,174.99862

Timestep Collection Time: 3.60466
Timestep Consumption Time: 3.36733
PPO Batch Consumption Time: 0.41464
Total Iteration Time: 6.97199

Cumulative Model Updates: 106,150
Cumulative Timesteps: 885,422,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 885422906...
Checkpoint 885422906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,967.43743
Policy Entropy: 1.67140
Value Function Loss: 0.08790

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.15152
Policy Update Magnitude: 0.56605
Value Function Update Magnitude: 0.70962

Collected Steps per Second: 14,155.84921
Overall Steps per Second: 7,277.05167

Timestep Collection Time: 3.53239
Timestep Consumption Time: 3.33907
PPO Batch Consumption Time: 0.41208
Total Iteration Time: 6.87146

Cumulative Model Updates: 106,156
Cumulative Timesteps: 885,472,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,587.85452
Policy Entropy: 1.66991
Value Function Loss: 0.08328

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.15380
Policy Update Magnitude: 0.56679
Value Function Update Magnitude: 0.81244

Collected Steps per Second: 13,951.77518
Overall Steps per Second: 7,180.79348

Timestep Collection Time: 3.58449
Timestep Consumption Time: 3.37992
PPO Batch Consumption Time: 0.41223
Total Iteration Time: 6.96441

Cumulative Model Updates: 106,162
Cumulative Timesteps: 885,522,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 885522920...
Checkpoint 885522920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,373.19151
Policy Entropy: 1.66878
Value Function Loss: 0.08076

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.17735
Policy Update Magnitude: 0.51236
Value Function Update Magnitude: 0.84754

Collected Steps per Second: 13,928.68814
Overall Steps per Second: 7,222.19171

Timestep Collection Time: 3.58986
Timestep Consumption Time: 3.33353
PPO Batch Consumption Time: 0.41582
Total Iteration Time: 6.92338

Cumulative Model Updates: 106,168
Cumulative Timesteps: 885,572,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,940.94940
Policy Entropy: 1.66689
Value Function Loss: 0.08141

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.17231
Policy Update Magnitude: 0.48828
Value Function Update Magnitude: 0.82690

Collected Steps per Second: 14,801.46122
Overall Steps per Second: 7,570.34624

Timestep Collection Time: 3.37953
Timestep Consumption Time: 3.22809
PPO Batch Consumption Time: 0.39450
Total Iteration Time: 6.60762

Cumulative Model Updates: 106,174
Cumulative Timesteps: 885,622,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 885622944...
Checkpoint 885622944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,124.65354
Policy Entropy: 1.67048
Value Function Loss: 0.08083

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.52657
Value Function Update Magnitude: 0.79746

Collected Steps per Second: 14,977.04944
Overall Steps per Second: 7,478.18870

Timestep Collection Time: 3.33924
Timestep Consumption Time: 3.34847
PPO Batch Consumption Time: 0.42084
Total Iteration Time: 6.68772

Cumulative Model Updates: 106,180
Cumulative Timesteps: 885,672,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,250.33597
Policy Entropy: 1.64971
Value Function Loss: 0.07660

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14270
Policy Update Magnitude: 0.57388
Value Function Update Magnitude: 0.77325

Collected Steps per Second: 14,788.73729
Overall Steps per Second: 6,690.57273

Timestep Collection Time: 3.38109
Timestep Consumption Time: 4.09241
PPO Batch Consumption Time: 0.54326
Total Iteration Time: 7.47350

Cumulative Model Updates: 106,186
Cumulative Timesteps: 885,722,958

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 885722958...
Checkpoint 885722958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,943.66396
Policy Entropy: 1.63508
Value Function Loss: 0.06771

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.15111
Policy Update Magnitude: 0.56638
Value Function Update Magnitude: 0.72587

Collected Steps per Second: 15,508.73459
Overall Steps per Second: 6,940.57406

Timestep Collection Time: 3.22515
Timestep Consumption Time: 3.98146
PPO Batch Consumption Time: 0.51688
Total Iteration Time: 7.20661

Cumulative Model Updates: 106,192
Cumulative Timesteps: 885,772,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,018.20281
Policy Entropy: 1.63146
Value Function Loss: 0.06827

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.56145
Value Function Update Magnitude: 0.67619

Collected Steps per Second: 16,897.82378
Overall Steps per Second: 7,408.54052

Timestep Collection Time: 2.95955
Timestep Consumption Time: 3.79076
PPO Batch Consumption Time: 0.47760
Total Iteration Time: 6.75032

Cumulative Model Updates: 106,198
Cumulative Timesteps: 885,822,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 885822986...
Checkpoint 885822986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,941.12559
Policy Entropy: 1.65160
Value Function Loss: 0.07396

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.13765
Policy Update Magnitude: 0.57629
Value Function Update Magnitude: 0.63432

Collected Steps per Second: 15,391.84503
Overall Steps per Second: 7,120.43930

Timestep Collection Time: 3.25029
Timestep Consumption Time: 3.77568
PPO Batch Consumption Time: 0.47788
Total Iteration Time: 7.02597

Cumulative Model Updates: 106,204
Cumulative Timesteps: 885,873,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,905.36292
Policy Entropy: 1.64399
Value Function Loss: 0.07489

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.58022
Value Function Update Magnitude: 0.69567

Collected Steps per Second: 15,211.25112
Overall Steps per Second: 6,720.56831

Timestep Collection Time: 3.28704
Timestep Consumption Time: 4.15281
PPO Batch Consumption Time: 0.54400
Total Iteration Time: 7.43985

Cumulative Model Updates: 106,210
Cumulative Timesteps: 885,923,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 885923014...
Checkpoint 885923014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,139.29072
Policy Entropy: 1.63548
Value Function Loss: 0.07511

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.14976
Policy Update Magnitude: 0.56151
Value Function Update Magnitude: 0.58180

Collected Steps per Second: 15,250.35739
Overall Steps per Second: 6,892.73878

Timestep Collection Time: 3.27953
Timestep Consumption Time: 3.97651
PPO Batch Consumption Time: 0.50562
Total Iteration Time: 7.25604

Cumulative Model Updates: 106,216
Cumulative Timesteps: 885,973,028

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,864.95514
Policy Entropy: 1.62966
Value Function Loss: 0.07899

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.56628
Value Function Update Magnitude: 0.67101

Collected Steps per Second: 14,967.25307
Overall Steps per Second: 7,389.22045

Timestep Collection Time: 3.34196
Timestep Consumption Time: 3.42736
PPO Batch Consumption Time: 0.41835
Total Iteration Time: 6.76932

Cumulative Model Updates: 106,222
Cumulative Timesteps: 886,023,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 886023048...
Checkpoint 886023048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,880.34700
Policy Entropy: 1.64214
Value Function Loss: 0.08200

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.57138
Value Function Update Magnitude: 0.75323

Collected Steps per Second: 16,135.43184
Overall Steps per Second: 7,851.53918

Timestep Collection Time: 3.10051
Timestep Consumption Time: 3.27124
PPO Batch Consumption Time: 0.39445
Total Iteration Time: 6.37174

Cumulative Model Updates: 106,228
Cumulative Timesteps: 886,073,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,959.73580
Policy Entropy: 1.63706
Value Function Loss: 0.07688

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.15544
Policy Update Magnitude: 0.57556
Value Function Update Magnitude: 0.72999

Collected Steps per Second: 17,195.44955
Overall Steps per Second: 7,999.64979

Timestep Collection Time: 2.90868
Timestep Consumption Time: 3.34360
PPO Batch Consumption Time: 0.40034
Total Iteration Time: 6.25227

Cumulative Model Updates: 106,234
Cumulative Timesteps: 886,123,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 886123092...
Checkpoint 886123092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,883.63482
Policy Entropy: 1.64186
Value Function Loss: 0.08606

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.16062
Policy Update Magnitude: 0.57965
Value Function Update Magnitude: 0.61742

Collected Steps per Second: 16,703.19614
Overall Steps per Second: 8,071.63549

Timestep Collection Time: 2.99512
Timestep Consumption Time: 3.20288
PPO Batch Consumption Time: 0.38969
Total Iteration Time: 6.19800

Cumulative Model Updates: 106,240
Cumulative Timesteps: 886,173,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,474.22160
Policy Entropy: 1.63234
Value Function Loss: 0.08238

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.15703
Policy Update Magnitude: 0.57161
Value Function Update Magnitude: 0.51585

Collected Steps per Second: 17,563.29572
Overall Steps per Second: 8,291.65124

Timestep Collection Time: 2.84730
Timestep Consumption Time: 3.18383
PPO Batch Consumption Time: 0.38364
Total Iteration Time: 6.03113

Cumulative Model Updates: 106,246
Cumulative Timesteps: 886,223,128

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 886223128...
Checkpoint 886223128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,689.73206
Policy Entropy: 1.63187
Value Function Loss: 0.08752

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.15937
Policy Update Magnitude: 0.57428
Value Function Update Magnitude: 0.45646

Collected Steps per Second: 17,144.75131
Overall Steps per Second: 8,334.41770

Timestep Collection Time: 2.91693
Timestep Consumption Time: 3.08349
PPO Batch Consumption Time: 0.37715
Total Iteration Time: 6.00042

Cumulative Model Updates: 106,252
Cumulative Timesteps: 886,273,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,135.21251
Policy Entropy: 1.62319
Value Function Loss: 0.07524

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.15353
Policy Update Magnitude: 0.55220
Value Function Update Magnitude: 0.50499

Collected Steps per Second: 17,215.62458
Overall Steps per Second: 8,295.25631

Timestep Collection Time: 2.90445
Timestep Consumption Time: 3.12333
PPO Batch Consumption Time: 0.37099
Total Iteration Time: 6.02778

Cumulative Model Updates: 106,258
Cumulative Timesteps: 886,323,140

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 886323140...
Checkpoint 886323140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,042.31505
Policy Entropy: 1.63099
Value Function Loss: 0.07062

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.14930
Policy Update Magnitude: 0.52686
Value Function Update Magnitude: 0.52023

Collected Steps per Second: 17,066.55132
Overall Steps per Second: 8,159.31007

Timestep Collection Time: 2.92971
Timestep Consumption Time: 3.19826
PPO Batch Consumption Time: 0.38914
Total Iteration Time: 6.12797

Cumulative Model Updates: 106,264
Cumulative Timesteps: 886,373,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 886373140...
Checkpoint 886373140 saved!
