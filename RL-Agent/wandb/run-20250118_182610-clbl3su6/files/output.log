Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,318.53925
Policy Entropy: 1.97947
Value Function Loss: 0.09525

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01291
Policy Update Magnitude: 0.18661
Value Function Update Magnitude: 0.17745

Collected Steps per Second: 7,084.13124
Overall Steps per Second: 4,005.84951

Timestep Collection Time: 7.05972
Timestep Consumption Time: 5.42502
PPO Batch Consumption Time: 2.09650
Total Iteration Time: 12.48474

Cumulative Model Updates: 86,380
Cumulative Timesteps: 720,513,578

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,087.64198
Policy Entropy: 1.93023
Value Function Loss: 0.09418

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 0.41832
Value Function Update Magnitude: 0.37419

Collected Steps per Second: 19,384.04641
Overall Steps per Second: 11,143.08306

Timestep Collection Time: 2.58078
Timestep Consumption Time: 1.90864
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.48942

Cumulative Model Updates: 86,384
Cumulative Timesteps: 720,563,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 720563604...
Checkpoint 720563604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,819.45051
Policy Entropy: 1.90949
Value Function Loss: 0.08991

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.61002
Value Function Update Magnitude: 0.44125

Collected Steps per Second: 19,091.20623
Overall Steps per Second: 9,828.92237

Timestep Collection Time: 2.62047
Timestep Consumption Time: 2.46940
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 5.08988

Cumulative Model Updates: 86,390
Cumulative Timesteps: 720,613,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,316.15999
Policy Entropy: 1.85881
Value Function Loss: 0.09802

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.15275
Policy Update Magnitude: 0.58171
Value Function Update Magnitude: 0.36177

Collected Steps per Second: 19,220.43901
Overall Steps per Second: 9,739.04925

Timestep Collection Time: 2.60233
Timestep Consumption Time: 2.53349
PPO Batch Consumption Time: 0.30245
Total Iteration Time: 5.13582

Cumulative Model Updates: 86,396
Cumulative Timesteps: 720,663,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 720663650...
Checkpoint 720663650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,470.18109
Policy Entropy: 1.85492
Value Function Loss: 0.09764

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.14158
Policy Update Magnitude: 0.56783
Value Function Update Magnitude: 0.34242

Collected Steps per Second: 19,453.10644
Overall Steps per Second: 9,710.01307

Timestep Collection Time: 2.57049
Timestep Consumption Time: 2.57925
PPO Batch Consumption Time: 0.29938
Total Iteration Time: 5.14974

Cumulative Model Updates: 86,402
Cumulative Timesteps: 720,713,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,475.88470
Policy Entropy: 1.84581
Value Function Loss: 0.09065

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.55779
Value Function Update Magnitude: 0.32434

Collected Steps per Second: 19,977.98628
Overall Steps per Second: 9,763.36800

Timestep Collection Time: 2.50426
Timestep Consumption Time: 2.62000
PPO Batch Consumption Time: 0.30662
Total Iteration Time: 5.12426

Cumulative Model Updates: 86,408
Cumulative Timesteps: 720,763,684

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 720763684...
Checkpoint 720763684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,997.13957
Policy Entropy: 1.84910
Value Function Loss: 0.08089

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13842
Policy Update Magnitude: 0.54159
Value Function Update Magnitude: 0.38748

Collected Steps per Second: 15,681.73013
Overall Steps per Second: 8,521.73381

Timestep Collection Time: 3.18842
Timestep Consumption Time: 2.67893
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 5.86735

Cumulative Model Updates: 86,414
Cumulative Timesteps: 720,813,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,900.51726
Policy Entropy: 1.85189
Value Function Loss: 0.08543

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.54992
Value Function Update Magnitude: 0.56173

Collected Steps per Second: 19,783.29832
Overall Steps per Second: 9,751.09725

Timestep Collection Time: 2.52789
Timestep Consumption Time: 2.60076
PPO Batch Consumption Time: 0.30090
Total Iteration Time: 5.12865

Cumulative Model Updates: 86,420
Cumulative Timesteps: 720,863,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 720863694...
Checkpoint 720863694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,260.53007
Policy Entropy: 1.85443
Value Function Loss: 0.08476

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.54980
Value Function Update Magnitude: 0.63288

Collected Steps per Second: 18,757.48953
Overall Steps per Second: 9,544.91391

Timestep Collection Time: 2.66731
Timestep Consumption Time: 2.57444
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 5.24174

Cumulative Model Updates: 86,426
Cumulative Timesteps: 720,913,726

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,394.91421
Policy Entropy: 1.84959
Value Function Loss: 0.08184

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.55450
Value Function Update Magnitude: 0.68976

Collected Steps per Second: 19,039.97035
Overall Steps per Second: 9,427.66082

Timestep Collection Time: 2.62753
Timestep Consumption Time: 2.67899
PPO Batch Consumption Time: 0.30322
Total Iteration Time: 5.30651

Cumulative Model Updates: 86,432
Cumulative Timesteps: 720,963,754

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 720963754...
Checkpoint 720963754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,354.58094
Policy Entropy: 1.84154
Value Function Loss: 0.08010

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.55429
Value Function Update Magnitude: 0.71707

Collected Steps per Second: 17,481.69848
Overall Steps per Second: 9,339.09487

Timestep Collection Time: 2.86036
Timestep Consumption Time: 2.49390
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 5.35427

Cumulative Model Updates: 86,438
Cumulative Timesteps: 721,013,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,699.61843
Policy Entropy: 1.84289
Value Function Loss: 0.08038

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.56056
Value Function Update Magnitude: 0.71698

Collected Steps per Second: 18,703.87684
Overall Steps per Second: 9,237.34562

Timestep Collection Time: 2.67367
Timestep Consumption Time: 2.74001
PPO Batch Consumption Time: 0.30970
Total Iteration Time: 5.41368

Cumulative Model Updates: 86,444
Cumulative Timesteps: 721,063,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 721063766...
Checkpoint 721063766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,841.36030
Policy Entropy: 1.85272
Value Function Loss: 0.08031

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.56276
Value Function Update Magnitude: 0.63203

Collected Steps per Second: 17,961.09373
Overall Steps per Second: 9,055.90809

Timestep Collection Time: 2.78457
Timestep Consumption Time: 2.73823
PPO Batch Consumption Time: 0.30084
Total Iteration Time: 5.52280

Cumulative Model Updates: 86,450
Cumulative Timesteps: 721,113,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,991.75918
Policy Entropy: 1.85538
Value Function Loss: 0.08112

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.55543
Value Function Update Magnitude: 0.60495

Collected Steps per Second: 19,182.88824
Overall Steps per Second: 9,721.17926

Timestep Collection Time: 2.60847
Timestep Consumption Time: 2.53885
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 5.14732

Cumulative Model Updates: 86,456
Cumulative Timesteps: 721,163,818

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 721163818...
Checkpoint 721163818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,384.85702
Policy Entropy: 1.85584
Value Function Loss: 0.07974

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.55457
Value Function Update Magnitude: 0.68155

Collected Steps per Second: 20,729.44120
Overall Steps per Second: 10,025.86845

Timestep Collection Time: 2.41232
Timestep Consumption Time: 2.57538
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.98770

Cumulative Model Updates: 86,462
Cumulative Timesteps: 721,213,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,347.75751
Policy Entropy: 1.85192
Value Function Loss: 0.07613

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.55289
Value Function Update Magnitude: 0.66506

Collected Steps per Second: 20,391.59459
Overall Steps per Second: 9,710.47328

Timestep Collection Time: 2.45336
Timestep Consumption Time: 2.69860
PPO Batch Consumption Time: 0.31117
Total Iteration Time: 5.15196

Cumulative Model Updates: 86,468
Cumulative Timesteps: 721,263,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 721263852...
Checkpoint 721263852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,822.26561
Policy Entropy: 1.82947
Value Function Loss: 0.07859

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.54944
Value Function Update Magnitude: 0.56096

Collected Steps per Second: 19,554.70238
Overall Steps per Second: 9,298.24485

Timestep Collection Time: 2.55754
Timestep Consumption Time: 2.82111
PPO Batch Consumption Time: 0.33048
Total Iteration Time: 5.37865

Cumulative Model Updates: 86,474
Cumulative Timesteps: 721,313,864

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,574.52243
Policy Entropy: 1.82045
Value Function Loss: 0.08548

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.55200
Value Function Update Magnitude: 0.51983

Collected Steps per Second: 20,381.50283
Overall Steps per Second: 10,212.55959

Timestep Collection Time: 2.45330
Timestep Consumption Time: 2.44283
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.89613

Cumulative Model Updates: 86,480
Cumulative Timesteps: 721,363,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 721363866...
Checkpoint 721363866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,698.88333
Policy Entropy: 1.80767
Value Function Loss: 0.08350

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.56186
Value Function Update Magnitude: 0.53532

Collected Steps per Second: 20,331.15074
Overall Steps per Second: 10,007.19644

Timestep Collection Time: 2.46056
Timestep Consumption Time: 2.53844
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.99900

Cumulative Model Updates: 86,486
Cumulative Timesteps: 721,413,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,761.75831
Policy Entropy: 1.83222
Value Function Loss: 0.08347

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.14819
Policy Update Magnitude: 0.52846
Value Function Update Magnitude: 0.58595

Collected Steps per Second: 19,158.89281
Overall Steps per Second: 9,742.87385

Timestep Collection Time: 2.61028
Timestep Consumption Time: 2.52271
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 5.13298

Cumulative Model Updates: 86,492
Cumulative Timesteps: 721,463,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 721463902...
Checkpoint 721463902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,249.89749
Policy Entropy: 1.83986
Value Function Loss: 0.08381

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.14882
Policy Update Magnitude: 0.46763
Value Function Update Magnitude: 0.63395

Collected Steps per Second: 20,972.62268
Overall Steps per Second: 10,152.18574

Timestep Collection Time: 2.38416
Timestep Consumption Time: 2.54109
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.92524

Cumulative Model Updates: 86,498
Cumulative Timesteps: 721,513,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,891.63733
Policy Entropy: 1.83294
Value Function Loss: 0.08426

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.53100
Value Function Update Magnitude: 0.61425

Collected Steps per Second: 20,649.79537
Overall Steps per Second: 10,018.58929

Timestep Collection Time: 2.42133
Timestep Consumption Time: 2.56939
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.99072

Cumulative Model Updates: 86,504
Cumulative Timesteps: 721,563,904

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 721563904...
Checkpoint 721563904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,706.68294
Policy Entropy: 1.81695
Value Function Loss: 0.08328

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.14919
Policy Update Magnitude: 0.54978
Value Function Update Magnitude: 0.61187

Collected Steps per Second: 20,462.55068
Overall Steps per Second: 9,919.66908

Timestep Collection Time: 2.44437
Timestep Consumption Time: 2.59794
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 5.04231

Cumulative Model Updates: 86,510
Cumulative Timesteps: 721,613,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,434.64614
Policy Entropy: 1.81199
Value Function Loss: 0.07965

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.54751
Value Function Update Magnitude: 0.67067

Collected Steps per Second: 20,574.88803
Overall Steps per Second: 9,948.27795

Timestep Collection Time: 2.43044
Timestep Consumption Time: 2.59616
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 5.02660

Cumulative Model Updates: 86,516
Cumulative Timesteps: 721,663,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 721663928...
Checkpoint 721663928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,203.93142
Policy Entropy: 1.82543
Value Function Loss: 0.08039

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.51989
Value Function Update Magnitude: 0.64848

Collected Steps per Second: 20,595.17460
Overall Steps per Second: 10,126.02518

Timestep Collection Time: 2.42824
Timestep Consumption Time: 2.51052
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.93876

Cumulative Model Updates: 86,522
Cumulative Timesteps: 721,713,938

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,132.90282
Policy Entropy: 1.82648
Value Function Loss: 0.08335

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.52843
Value Function Update Magnitude: 0.69909

Collected Steps per Second: 20,543.96027
Overall Steps per Second: 10,077.95475

Timestep Collection Time: 2.43468
Timestep Consumption Time: 2.52843
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.96311

Cumulative Model Updates: 86,528
Cumulative Timesteps: 721,763,956

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 721763956...
Checkpoint 721763956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,462.02216
Policy Entropy: 1.82418
Value Function Loss: 0.07993

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.51751
Value Function Update Magnitude: 0.70290

Collected Steps per Second: 20,345.84271
Overall Steps per Second: 9,871.78581

Timestep Collection Time: 2.45800
Timestep Consumption Time: 2.60796
PPO Batch Consumption Time: 0.29930
Total Iteration Time: 5.06595

Cumulative Model Updates: 86,534
Cumulative Timesteps: 721,813,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,292.06565
Policy Entropy: 1.81366
Value Function Loss: 0.08354

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.52340
Value Function Update Magnitude: 0.66183

Collected Steps per Second: 20,424.36224
Overall Steps per Second: 10,006.37866

Timestep Collection Time: 2.44913
Timestep Consumption Time: 2.54988
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.99901

Cumulative Model Updates: 86,540
Cumulative Timesteps: 721,863,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 721863988...
Checkpoint 721863988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,234.57676
Policy Entropy: 1.81164
Value Function Loss: 0.08356

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.52449
Value Function Update Magnitude: 0.61723

Collected Steps per Second: 20,731.34653
Overall Steps per Second: 9,623.12462

Timestep Collection Time: 2.41277
Timestep Consumption Time: 2.78512
PPO Batch Consumption Time: 0.32884
Total Iteration Time: 5.19790

Cumulative Model Updates: 86,546
Cumulative Timesteps: 721,914,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,125.75304
Policy Entropy: 1.80977
Value Function Loss: 0.07768

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.13759
Policy Update Magnitude: 0.52351
Value Function Update Magnitude: 0.66932

Collected Steps per Second: 15,003.08146
Overall Steps per Second: 8,402.50314

Timestep Collection Time: 3.33478
Timestep Consumption Time: 2.61963
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 5.95442

Cumulative Model Updates: 86,552
Cumulative Timesteps: 721,964,040

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 721964040...
Checkpoint 721964040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,257.06442
Policy Entropy: 1.81013
Value Function Loss: 0.07841

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.51481
Value Function Update Magnitude: 0.67655

Collected Steps per Second: 18,884.31557
Overall Steps per Second: 9,195.46047

Timestep Collection Time: 2.64802
Timestep Consumption Time: 2.79010
PPO Batch Consumption Time: 0.30956
Total Iteration Time: 5.43812

Cumulative Model Updates: 86,558
Cumulative Timesteps: 722,014,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,927.98564
Policy Entropy: 1.81101
Value Function Loss: 0.07220

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.54002
Value Function Update Magnitude: 0.64972

Collected Steps per Second: 16,922.03404
Overall Steps per Second: 9,021.11949

Timestep Collection Time: 2.95733
Timestep Consumption Time: 2.59010
PPO Batch Consumption Time: 0.30068
Total Iteration Time: 5.54743

Cumulative Model Updates: 86,564
Cumulative Timesteps: 722,064,090

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 722064090...
Checkpoint 722064090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,612.06613
Policy Entropy: 1.80695
Value Function Loss: 0.08190

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.14198
Policy Update Magnitude: 0.55398
Value Function Update Magnitude: 0.62231

Collected Steps per Second: 20,001.51809
Overall Steps per Second: 9,728.98359

Timestep Collection Time: 2.50051
Timestep Consumption Time: 2.64021
PPO Batch Consumption Time: 0.30617
Total Iteration Time: 5.14072

Cumulative Model Updates: 86,570
Cumulative Timesteps: 722,114,104

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,790.74391
Policy Entropy: 1.83295
Value Function Loss: 0.08135

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.56079
Value Function Update Magnitude: 0.61333

Collected Steps per Second: 20,809.15659
Overall Steps per Second: 10,039.71083

Timestep Collection Time: 2.40365
Timestep Consumption Time: 2.57836
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.98202

Cumulative Model Updates: 86,576
Cumulative Timesteps: 722,164,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 722164122...
Checkpoint 722164122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,741.81131
Policy Entropy: 1.82906
Value Function Loss: 0.08156

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.17138
Policy Update Magnitude: 0.49836
Value Function Update Magnitude: 0.59953

Collected Steps per Second: 19,437.70679
Overall Steps per Second: 9,785.26538

Timestep Collection Time: 2.57376
Timestep Consumption Time: 2.53882
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 5.11258

Cumulative Model Updates: 86,582
Cumulative Timesteps: 722,214,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,725.20791
Policy Entropy: 1.83060
Value Function Loss: 0.08201

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.16011
Policy Update Magnitude: 0.44794
Value Function Update Magnitude: 0.57265

Collected Steps per Second: 20,830.95030
Overall Steps per Second: 10,121.34281

Timestep Collection Time: 2.40152
Timestep Consumption Time: 2.54110
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.94262

Cumulative Model Updates: 86,588
Cumulative Timesteps: 722,264,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 722264176...
Checkpoint 722264176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,850.65280
Policy Entropy: 1.81805
Value Function Loss: 0.08766

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.16298
Policy Update Magnitude: 0.45625
Value Function Update Magnitude: 0.65197

Collected Steps per Second: 19,967.61161
Overall Steps per Second: 9,774.98367

Timestep Collection Time: 2.50516
Timestep Consumption Time: 2.61219
PPO Batch Consumption Time: 0.29897
Total Iteration Time: 5.11735

Cumulative Model Updates: 86,594
Cumulative Timesteps: 722,314,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,270.16533
Policy Entropy: 1.81632
Value Function Loss: 0.08488

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14933
Policy Update Magnitude: 0.49246
Value Function Update Magnitude: 0.66020

Collected Steps per Second: 20,662.03968
Overall Steps per Second: 10,031.88982

Timestep Collection Time: 2.42038
Timestep Consumption Time: 2.56472
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.98510

Cumulative Model Updates: 86,600
Cumulative Timesteps: 722,364,208

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 722364208...
Checkpoint 722364208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,611.44495
Policy Entropy: 1.83163
Value Function Loss: 0.08987

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.16450
Policy Update Magnitude: 0.50895
Value Function Update Magnitude: 0.60968

Collected Steps per Second: 20,173.30094
Overall Steps per Second: 9,823.37510

Timestep Collection Time: 2.47882
Timestep Consumption Time: 2.61169
PPO Batch Consumption Time: 0.30016
Total Iteration Time: 5.09051

Cumulative Model Updates: 86,606
Cumulative Timesteps: 722,414,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,742.90068
Policy Entropy: 1.83520
Value Function Loss: 0.08861

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.17392
Policy Update Magnitude: 0.46709
Value Function Update Magnitude: 0.58807

Collected Steps per Second: 21,034.97688
Overall Steps per Second: 10,089.44289

Timestep Collection Time: 2.37766
Timestep Consumption Time: 2.57940
PPO Batch Consumption Time: 0.29715
Total Iteration Time: 4.95706

Cumulative Model Updates: 86,612
Cumulative Timesteps: 722,464,228

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 722464228...
Checkpoint 722464228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,057.15827
Policy Entropy: 1.85082
Value Function Loss: 0.08766

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.15182
Policy Update Magnitude: 0.53159
Value Function Update Magnitude: 0.60666

Collected Steps per Second: 20,787.84088
Overall Steps per Second: 10,099.21744

Timestep Collection Time: 2.40621
Timestep Consumption Time: 2.54664
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.95286

Cumulative Model Updates: 86,618
Cumulative Timesteps: 722,514,248

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,001.15140
Policy Entropy: 1.85177
Value Function Loss: 0.08292

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.55070
Value Function Update Magnitude: 0.61051

Collected Steps per Second: 20,466.48306
Overall Steps per Second: 10,057.36241

Timestep Collection Time: 2.44321
Timestep Consumption Time: 2.52867
PPO Batch Consumption Time: 0.30368
Total Iteration Time: 4.97188

Cumulative Model Updates: 86,624
Cumulative Timesteps: 722,564,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 722564252...
Checkpoint 722564252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,764.33518
Policy Entropy: 1.85641
Value Function Loss: 0.07832

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.16126
Policy Update Magnitude: 0.52780
Value Function Update Magnitude: 0.71342

Collected Steps per Second: 20,073.57689
Overall Steps per Second: 9,918.37424

Timestep Collection Time: 2.49114
Timestep Consumption Time: 2.55062
PPO Batch Consumption Time: 0.30733
Total Iteration Time: 5.04175

Cumulative Model Updates: 86,630
Cumulative Timesteps: 722,614,258

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,563.76194
Policy Entropy: 1.85629
Value Function Loss: 0.08413

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.17370
Policy Update Magnitude: 0.49188
Value Function Update Magnitude: 0.76297

Collected Steps per Second: 20,686.45821
Overall Steps per Second: 10,228.26625

Timestep Collection Time: 2.41781
Timestep Consumption Time: 2.47216
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.88998

Cumulative Model Updates: 86,636
Cumulative Timesteps: 722,664,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 722664274...
Checkpoint 722664274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,938.67705
Policy Entropy: 1.84997
Value Function Loss: 0.09103

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.14738
Policy Update Magnitude: 0.53535
Value Function Update Magnitude: 0.81795

Collected Steps per Second: 19,977.84270
Overall Steps per Second: 9,990.72284

Timestep Collection Time: 2.50337
Timestep Consumption Time: 2.50247
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 5.00584

Cumulative Model Updates: 86,642
Cumulative Timesteps: 722,714,286

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,572.76511
Policy Entropy: 1.85950
Value Function Loss: 0.09303

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.14272
Policy Update Magnitude: 0.59011
Value Function Update Magnitude: 0.80733

Collected Steps per Second: 20,777.76801
Overall Steps per Second: 10,236.38260

Timestep Collection Time: 2.40651
Timestep Consumption Time: 2.47822
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.88473

Cumulative Model Updates: 86,648
Cumulative Timesteps: 722,764,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 722764288...
Checkpoint 722764288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,283.14078
Policy Entropy: 1.86547
Value Function Loss: 0.09927

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.60369
Value Function Update Magnitude: 0.76644

Collected Steps per Second: 19,740.42532
Overall Steps per Second: 9,953.93034

Timestep Collection Time: 2.53429
Timestep Consumption Time: 2.49166
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 5.02595

Cumulative Model Updates: 86,654
Cumulative Timesteps: 722,814,316

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,511.91291
Policy Entropy: 1.85765
Value Function Loss: 0.09515

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.14726
Policy Update Magnitude: 0.58579
Value Function Update Magnitude: 0.72381

Collected Steps per Second: 19,953.22518
Overall Steps per Second: 10,055.63957

Timestep Collection Time: 2.50656
Timestep Consumption Time: 2.46716
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.97373

Cumulative Model Updates: 86,660
Cumulative Timesteps: 722,864,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 722864330...
Checkpoint 722864330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,815.19799
Policy Entropy: 1.85511
Value Function Loss: 0.09353

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.57955
Value Function Update Magnitude: 0.62795

Collected Steps per Second: 20,501.38017
Overall Steps per Second: 10,241.13632

Timestep Collection Time: 2.44013
Timestep Consumption Time: 2.44468
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.88481

Cumulative Model Updates: 86,666
Cumulative Timesteps: 722,914,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,840.98726
Policy Entropy: 1.84445
Value Function Loss: 0.08572

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.14008
Policy Update Magnitude: 0.56889
Value Function Update Magnitude: 0.65280

Collected Steps per Second: 20,621.35577
Overall Steps per Second: 10,023.15391

Timestep Collection Time: 2.42496
Timestep Consumption Time: 2.56409
PPO Batch Consumption Time: 0.30957
Total Iteration Time: 4.98905

Cumulative Model Updates: 86,672
Cumulative Timesteps: 722,964,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 722964362...
Checkpoint 722964362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,175.75767
Policy Entropy: 1.83655
Value Function Loss: 0.08756

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.57169
Value Function Update Magnitude: 0.72648

Collected Steps per Second: 19,933.69574
Overall Steps per Second: 9,809.59190

Timestep Collection Time: 2.50832
Timestep Consumption Time: 2.58874
PPO Batch Consumption Time: 0.29982
Total Iteration Time: 5.09705

Cumulative Model Updates: 86,678
Cumulative Timesteps: 723,014,362

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,983.48600
Policy Entropy: 1.82658
Value Function Loss: 0.08831

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14735
Policy Update Magnitude: 0.57393
Value Function Update Magnitude: 0.77998

Collected Steps per Second: 17,626.80848
Overall Steps per Second: 8,867.84795

Timestep Collection Time: 2.83806
Timestep Consumption Time: 2.80322
PPO Batch Consumption Time: 0.32175
Total Iteration Time: 5.64128

Cumulative Model Updates: 86,684
Cumulative Timesteps: 723,064,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 723064388...
Checkpoint 723064388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,852.14164
Policy Entropy: 1.83641
Value Function Loss: 0.08968

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14805
Policy Update Magnitude: 0.57346
Value Function Update Magnitude: 0.80752

Collected Steps per Second: 18,807.74241
Overall Steps per Second: 9,365.51650

Timestep Collection Time: 2.65922
Timestep Consumption Time: 2.68100
PPO Batch Consumption Time: 0.32043
Total Iteration Time: 5.34023

Cumulative Model Updates: 86,690
Cumulative Timesteps: 723,114,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,527.82527
Policy Entropy: 1.84882
Value Function Loss: 0.08434

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14477
Policy Update Magnitude: 0.57306
Value Function Update Magnitude: 0.80504

Collected Steps per Second: 19,059.06347
Overall Steps per Second: 9,789.59517

Timestep Collection Time: 2.62353
Timestep Consumption Time: 2.48414
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 5.10767

Cumulative Model Updates: 86,696
Cumulative Timesteps: 723,164,404

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 723164404...
Checkpoint 723164404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,718.23093
Policy Entropy: 1.84624
Value Function Loss: 0.08455

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.14451
Policy Update Magnitude: 0.55658
Value Function Update Magnitude: 0.78942

Collected Steps per Second: 20,215.22254
Overall Steps per Second: 9,881.12841

Timestep Collection Time: 2.47477
Timestep Consumption Time: 2.58822
PPO Batch Consumption Time: 0.30452
Total Iteration Time: 5.06298

Cumulative Model Updates: 86,702
Cumulative Timesteps: 723,214,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,883.42223
Policy Entropy: 1.86020
Value Function Loss: 0.08942

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.15351
Policy Update Magnitude: 0.52731
Value Function Update Magnitude: 0.76491

Collected Steps per Second: 20,894.64257
Overall Steps per Second: 10,065.42222

Timestep Collection Time: 2.39296
Timestep Consumption Time: 2.57454
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.96750

Cumulative Model Updates: 86,708
Cumulative Timesteps: 723,264,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 723264432...
Checkpoint 723264432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,556.97465
Policy Entropy: 1.85954
Value Function Loss: 0.08885

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.16624
Policy Update Magnitude: 0.50342
Value Function Update Magnitude: 0.68033

Collected Steps per Second: 18,170.00268
Overall Steps per Second: 9,266.89062

Timestep Collection Time: 2.75201
Timestep Consumption Time: 2.64398
PPO Batch Consumption Time: 0.31227
Total Iteration Time: 5.39598

Cumulative Model Updates: 86,714
Cumulative Timesteps: 723,314,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,176.95048
Policy Entropy: 1.87223
Value Function Loss: 0.08720

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.16836
Policy Update Magnitude: 0.49238
Value Function Update Magnitude: 0.64600

Collected Steps per Second: 17,799.85316
Overall Steps per Second: 9,171.49115

Timestep Collection Time: 2.80969
Timestep Consumption Time: 2.64330
PPO Batch Consumption Time: 0.30395
Total Iteration Time: 5.45298

Cumulative Model Updates: 86,720
Cumulative Timesteps: 723,364,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 723364448...
Checkpoint 723364448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,668.24818
Policy Entropy: 1.85612
Value Function Loss: 0.07806

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.18028
Policy Update Magnitude: 0.47899
Value Function Update Magnitude: 0.73008

Collected Steps per Second: 20,898.19094
Overall Steps per Second: 10,286.50851

Timestep Collection Time: 2.39293
Timestep Consumption Time: 2.46858
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.86151

Cumulative Model Updates: 86,726
Cumulative Timesteps: 723,414,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,173.44897
Policy Entropy: 1.85646
Value Function Loss: 0.08244

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.17208
Policy Update Magnitude: 0.43941
Value Function Update Magnitude: 0.66677

Collected Steps per Second: 20,711.97850
Overall Steps per Second: 9,968.59174

Timestep Collection Time: 2.41532
Timestep Consumption Time: 2.60304
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 5.01836

Cumulative Model Updates: 86,732
Cumulative Timesteps: 723,464,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 723464482...
Checkpoint 723464482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,120.23649
Policy Entropy: 1.86397
Value Function Loss: 0.08457

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.16083
Policy Update Magnitude: 0.44751
Value Function Update Magnitude: 0.60139

Collected Steps per Second: 20,495.58933
Overall Steps per Second: 10,088.58129

Timestep Collection Time: 2.44101
Timestep Consumption Time: 2.51806
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.95907

Cumulative Model Updates: 86,738
Cumulative Timesteps: 723,514,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,404.46944
Policy Entropy: 1.88999
Value Function Loss: 0.09228

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.15351
Policy Update Magnitude: 0.49247
Value Function Update Magnitude: 0.51131

Collected Steps per Second: 20,598.31883
Overall Steps per Second: 9,909.83080

Timestep Collection Time: 2.42874
Timestep Consumption Time: 2.61958
PPO Batch Consumption Time: 0.30106
Total Iteration Time: 5.04832

Cumulative Model Updates: 86,744
Cumulative Timesteps: 723,564,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 723564540...
Checkpoint 723564540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,272.99241
Policy Entropy: 1.89570
Value Function Loss: 0.08601

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.15272
Policy Update Magnitude: 0.50608
Value Function Update Magnitude: 0.54551

Collected Steps per Second: 20,029.43026
Overall Steps per Second: 9,950.29725

Timestep Collection Time: 2.49723
Timestep Consumption Time: 2.52956
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 5.02678

Cumulative Model Updates: 86,750
Cumulative Timesteps: 723,614,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,773.34514
Policy Entropy: 1.90881
Value Function Loss: 0.08466

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.15671
Policy Update Magnitude: 0.48992
Value Function Update Magnitude: 0.65178

Collected Steps per Second: 20,878.42694
Overall Steps per Second: 10,087.80851

Timestep Collection Time: 2.39530
Timestep Consumption Time: 2.56217
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.95747

Cumulative Model Updates: 86,756
Cumulative Timesteps: 723,664,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 723664568...
Checkpoint 723664568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,301.55906
Policy Entropy: 1.89466
Value Function Loss: 0.08042

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.15540
Policy Update Magnitude: 0.49313
Value Function Update Magnitude: 0.73701

Collected Steps per Second: 20,374.41876
Overall Steps per Second: 9,975.12204

Timestep Collection Time: 2.45416
Timestep Consumption Time: 2.55851
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 5.01267

Cumulative Model Updates: 86,762
Cumulative Timesteps: 723,714,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,734.74799
Policy Entropy: 1.89676
Value Function Loss: 0.07851

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.53921
Value Function Update Magnitude: 0.78383

Collected Steps per Second: 20,423.97401
Overall Steps per Second: 10,242.63461

Timestep Collection Time: 2.44977
Timestep Consumption Time: 2.43511
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.88488

Cumulative Model Updates: 86,768
Cumulative Timesteps: 723,764,604

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 723764604...
Checkpoint 723764604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,415.55428
Policy Entropy: 1.87892
Value Function Loss: 0.07971

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.54552
Value Function Update Magnitude: 0.77642

Collected Steps per Second: 20,067.35988
Overall Steps per Second: 9,542.65076

Timestep Collection Time: 2.49211
Timestep Consumption Time: 2.74858
PPO Batch Consumption Time: 0.32564
Total Iteration Time: 5.24068

Cumulative Model Updates: 86,774
Cumulative Timesteps: 723,814,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,415.35860
Policy Entropy: 1.88640
Value Function Loss: 0.08290

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.15588
Policy Update Magnitude: 0.49747
Value Function Update Magnitude: 0.70562

Collected Steps per Second: 18,414.63777
Overall Steps per Second: 9,687.99860

Timestep Collection Time: 2.71577
Timestep Consumption Time: 2.44628
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 5.16206

Cumulative Model Updates: 86,780
Cumulative Timesteps: 723,864,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 723864624...
Checkpoint 723864624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,429.78862
Policy Entropy: 1.89536
Value Function Loss: 0.08457

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.15309
Policy Update Magnitude: 0.51637
Value Function Update Magnitude: 0.70048

Collected Steps per Second: 20,332.27757
Overall Steps per Second: 10,058.65498

Timestep Collection Time: 2.46052
Timestep Consumption Time: 2.51311
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.97363

Cumulative Model Updates: 86,786
Cumulative Timesteps: 723,914,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,937.36515
Policy Entropy: 1.90923
Value Function Loss: 0.08046

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.53520
Value Function Update Magnitude: 0.77846

Collected Steps per Second: 21,030.40140
Overall Steps per Second: 10,086.75382

Timestep Collection Time: 2.37922
Timestep Consumption Time: 2.58134
PPO Batch Consumption Time: 0.29777
Total Iteration Time: 4.96057

Cumulative Model Updates: 86,792
Cumulative Timesteps: 723,964,688

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 723964688...
Checkpoint 723964688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,234.44953
Policy Entropy: 1.89608
Value Function Loss: 0.07510

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.14169
Policy Update Magnitude: 0.56063
Value Function Update Magnitude: 0.77712

Collected Steps per Second: 20,870.48707
Overall Steps per Second: 10,310.13513

Timestep Collection Time: 2.39669
Timestep Consumption Time: 2.45485
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.85154

Cumulative Model Updates: 86,798
Cumulative Timesteps: 724,014,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,483.60591
Policy Entropy: 1.88267
Value Function Loss: 0.08232

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.15734
Policy Update Magnitude: 0.52627
Value Function Update Magnitude: 0.75524

Collected Steps per Second: 21,286.33103
Overall Steps per Second: 10,467.24728

Timestep Collection Time: 2.34921
Timestep Consumption Time: 2.42817
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.77738

Cumulative Model Updates: 86,804
Cumulative Timesteps: 724,064,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 724064714...
Checkpoint 724064714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,320.46962
Policy Entropy: 1.87009
Value Function Loss: 0.08606

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.17629
Policy Update Magnitude: 0.47380
Value Function Update Magnitude: 0.80364

Collected Steps per Second: 21,101.90066
Overall Steps per Second: 10,117.04190

Timestep Collection Time: 2.36993
Timestep Consumption Time: 2.57322
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.94314

Cumulative Model Updates: 86,810
Cumulative Timesteps: 724,114,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,302.78523
Policy Entropy: 1.88115
Value Function Loss: 0.09069

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.54165
Value Function Update Magnitude: 0.70661

Collected Steps per Second: 21,520.30942
Overall Steps per Second: 10,412.92742

Timestep Collection Time: 2.32478
Timestep Consumption Time: 2.47982
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.80460

Cumulative Model Updates: 86,816
Cumulative Timesteps: 724,164,754

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 724164754...
Checkpoint 724164754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,817.25554
Policy Entropy: 1.89401
Value Function Loss: 0.09209

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.15534
Policy Update Magnitude: 0.55842
Value Function Update Magnitude: 0.69846

Collected Steps per Second: 20,081.25753
Overall Steps per Second: 9,822.03851

Timestep Collection Time: 2.49008
Timestep Consumption Time: 2.60092
PPO Batch Consumption Time: 0.30287
Total Iteration Time: 5.09100

Cumulative Model Updates: 86,822
Cumulative Timesteps: 724,214,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,849.96442
Policy Entropy: 1.89987
Value Function Loss: 0.08900

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.16771
Policy Update Magnitude: 0.52181
Value Function Update Magnitude: 0.55598

Collected Steps per Second: 21,306.03870
Overall Steps per Second: 10,026.28572

Timestep Collection Time: 2.34713
Timestep Consumption Time: 2.64056
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.98769

Cumulative Model Updates: 86,828
Cumulative Timesteps: 724,264,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 724264766...
Checkpoint 724264766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,003.73271
Policy Entropy: 1.92349
Value Function Loss: 0.08794

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.16168
Policy Update Magnitude: 0.52452
Value Function Update Magnitude: 0.43603

Collected Steps per Second: 20,586.32535
Overall Steps per Second: 9,928.98333

Timestep Collection Time: 2.42909
Timestep Consumption Time: 2.60728
PPO Batch Consumption Time: 0.30861
Total Iteration Time: 5.03637

Cumulative Model Updates: 86,834
Cumulative Timesteps: 724,314,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,739.31311
Policy Entropy: 1.92290
Value Function Loss: 0.08879

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.14176
Policy Update Magnitude: 0.54346
Value Function Update Magnitude: 0.39906

Collected Steps per Second: 21,310.69013
Overall Steps per Second: 10,323.99718

Timestep Collection Time: 2.34624
Timestep Consumption Time: 2.49685
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.84309

Cumulative Model Updates: 86,840
Cumulative Timesteps: 724,364,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 724364772...
Checkpoint 724364772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,330.28259
Policy Entropy: 1.92315
Value Function Loss: 0.08800

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14305
Policy Update Magnitude: 0.55695
Value Function Update Magnitude: 0.43332

Collected Steps per Second: 20,061.41602
Overall Steps per Second: 9,832.21676

Timestep Collection Time: 2.49235
Timestep Consumption Time: 2.59298
PPO Batch Consumption Time: 0.30079
Total Iteration Time: 5.08532

Cumulative Model Updates: 86,846
Cumulative Timesteps: 724,414,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,633.90712
Policy Entropy: 1.89980
Value Function Loss: 0.08530

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.14058
Policy Update Magnitude: 0.56361
Value Function Update Magnitude: 0.61946

Collected Steps per Second: 20,908.33395
Overall Steps per Second: 10,044.25397

Timestep Collection Time: 2.39187
Timestep Consumption Time: 2.58710
PPO Batch Consumption Time: 0.29933
Total Iteration Time: 4.97897

Cumulative Model Updates: 86,852
Cumulative Timesteps: 724,464,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 724464782...
Checkpoint 724464782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,112.17041
Policy Entropy: 1.89642
Value Function Loss: 0.08791

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.57420
Value Function Update Magnitude: 0.55939

Collected Steps per Second: 20,539.71288
Overall Steps per Second: 10,079.52103

Timestep Collection Time: 2.43577
Timestep Consumption Time: 2.52776
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.96353

Cumulative Model Updates: 86,858
Cumulative Timesteps: 724,514,812

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,191.45943
Policy Entropy: 1.91247
Value Function Loss: 0.09022

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.57768
Value Function Update Magnitude: 0.55525

Collected Steps per Second: 21,131.01937
Overall Steps per Second: 10,198.36457

Timestep Collection Time: 2.36742
Timestep Consumption Time: 2.53788
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.90530

Cumulative Model Updates: 86,864
Cumulative Timesteps: 724,564,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 724564838...
Checkpoint 724564838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,342.08944
Policy Entropy: 1.92051
Value Function Loss: 0.08732

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.56956
Value Function Update Magnitude: 0.63542

Collected Steps per Second: 20,501.74384
Overall Steps per Second: 9,909.33672

Timestep Collection Time: 2.43950
Timestep Consumption Time: 2.60766
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 5.04716

Cumulative Model Updates: 86,870
Cumulative Timesteps: 724,614,852

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,220.26714
Policy Entropy: 1.92332
Value Function Loss: 0.08172

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.55308
Value Function Update Magnitude: 0.59306

Collected Steps per Second: 20,995.77062
Overall Steps per Second: 10,233.52233

Timestep Collection Time: 2.38210
Timestep Consumption Time: 2.50517
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.88727

Cumulative Model Updates: 86,876
Cumulative Timesteps: 724,664,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 724664866...
Checkpoint 724664866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,555.41228
Policy Entropy: 1.91976
Value Function Loss: 0.07907

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.12316
Policy Update Magnitude: 0.54820
Value Function Update Magnitude: 0.57629

Collected Steps per Second: 20,355.96280
Overall Steps per Second: 9,879.77767

Timestep Collection Time: 2.45736
Timestep Consumption Time: 2.60571
PPO Batch Consumption Time: 0.29900
Total Iteration Time: 5.06307

Cumulative Model Updates: 86,882
Cumulative Timesteps: 724,714,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,317.06071
Policy Entropy: 1.91164
Value Function Loss: 0.07801

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.55073
Value Function Update Magnitude: 0.65137

Collected Steps per Second: 21,622.06471
Overall Steps per Second: 10,355.38848

Timestep Collection Time: 2.31301
Timestep Consumption Time: 2.51656
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.82956

Cumulative Model Updates: 86,888
Cumulative Timesteps: 724,764,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 724764900...
Checkpoint 724764900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,163.62733
Policy Entropy: 1.89524
Value Function Loss: 0.08291

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.56053
Value Function Update Magnitude: 0.68006

Collected Steps per Second: 19,940.86930
Overall Steps per Second: 9,700.55433

Timestep Collection Time: 2.50902
Timestep Consumption Time: 2.64863
PPO Batch Consumption Time: 0.31069
Total Iteration Time: 5.15764

Cumulative Model Updates: 86,894
Cumulative Timesteps: 724,814,932

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,686.13857
Policy Entropy: 1.89448
Value Function Loss: 0.08151

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.56908
Value Function Update Magnitude: 0.70778

Collected Steps per Second: 21,790.28653
Overall Steps per Second: 10,259.84708

Timestep Collection Time: 2.29570
Timestep Consumption Time: 2.58000
PPO Batch Consumption Time: 0.29881
Total Iteration Time: 4.87571

Cumulative Model Updates: 86,900
Cumulative Timesteps: 724,864,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 724864956...
Checkpoint 724864956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,403.42253
Policy Entropy: 1.89524
Value Function Loss: 0.07910

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.55421
Value Function Update Magnitude: 0.68594

Collected Steps per Second: 20,743.97746
Overall Steps per Second: 10,157.88481

Timestep Collection Time: 2.41150
Timestep Consumption Time: 2.51315
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.92465

Cumulative Model Updates: 86,906
Cumulative Timesteps: 724,914,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,093.90225
Policy Entropy: 1.88933
Value Function Loss: 0.07608

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.53201
Value Function Update Magnitude: 0.54822

Collected Steps per Second: 21,546.40717
Overall Steps per Second: 10,238.04886

Timestep Collection Time: 2.32178
Timestep Consumption Time: 2.56450
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.88628

Cumulative Model Updates: 86,912
Cumulative Timesteps: 724,965,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 724965006...
Checkpoint 724965006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,358.37132
Policy Entropy: 1.89737
Value Function Loss: 0.07942

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.54280
Value Function Update Magnitude: 0.56331

Collected Steps per Second: 20,876.64456
Overall Steps per Second: 10,056.08814

Timestep Collection Time: 2.39531
Timestep Consumption Time: 2.57740
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.97271

Cumulative Model Updates: 86,918
Cumulative Timesteps: 725,015,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,651.78107
Policy Entropy: 1.88753
Value Function Loss: 0.08411

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.55058
Value Function Update Magnitude: 0.65348

Collected Steps per Second: 21,467.54448
Overall Steps per Second: 10,189.48225

Timestep Collection Time: 2.33040
Timestep Consumption Time: 2.57937
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.90977

Cumulative Model Updates: 86,924
Cumulative Timesteps: 725,065,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 725065040...
Checkpoint 725065040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,940.90566
Policy Entropy: 1.90408
Value Function Loss: 0.08825

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.54427
Value Function Update Magnitude: 0.55326

Collected Steps per Second: 21,166.32815
Overall Steps per Second: 10,072.86881

Timestep Collection Time: 2.36319
Timestep Consumption Time: 2.60263
PPO Batch Consumption Time: 0.30067
Total Iteration Time: 4.96581

Cumulative Model Updates: 86,930
Cumulative Timesteps: 725,115,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,788.63855
Policy Entropy: 1.90490
Value Function Loss: 0.09180

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.53088
Value Function Update Magnitude: 0.45723

Collected Steps per Second: 20,426.58844
Overall Steps per Second: 9,523.14809

Timestep Collection Time: 2.44818
Timestep Consumption Time: 2.80302
PPO Batch Consumption Time: 0.33354
Total Iteration Time: 5.25120

Cumulative Model Updates: 86,936
Cumulative Timesteps: 725,165,068

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 725165068...
Checkpoint 725165068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,366.63643
Policy Entropy: 1.91375
Value Function Loss: 0.08765

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.54469
Value Function Update Magnitude: 0.41097

Collected Steps per Second: 18,517.25774
Overall Steps per Second: 9,458.05325

Timestep Collection Time: 2.70116
Timestep Consumption Time: 2.58725
PPO Batch Consumption Time: 0.29706
Total Iteration Time: 5.28840

Cumulative Model Updates: 86,942
Cumulative Timesteps: 725,215,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,886.93074
Policy Entropy: 1.89140
Value Function Loss: 0.08215

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.55021
Value Function Update Magnitude: 0.39244

Collected Steps per Second: 21,032.50856
Overall Steps per Second: 9,870.27773

Timestep Collection Time: 2.37832
Timestep Consumption Time: 2.68962
PPO Batch Consumption Time: 0.29882
Total Iteration Time: 5.06794

Cumulative Model Updates: 86,948
Cumulative Timesteps: 725,265,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 725265108...
Checkpoint 725265108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,639.79089
Policy Entropy: 1.87937
Value Function Loss: 0.07637

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.54719
Value Function Update Magnitude: 0.40826

Collected Steps per Second: 20,018.03857
Overall Steps per Second: 10,104.50970

Timestep Collection Time: 2.49865
Timestep Consumption Time: 2.45142
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.95007

Cumulative Model Updates: 86,954
Cumulative Timesteps: 725,315,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,446.10648
Policy Entropy: 1.87386
Value Function Loss: 0.08267

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.55593
Value Function Update Magnitude: 0.36160

Collected Steps per Second: 20,945.28225
Overall Steps per Second: 10,006.22530

Timestep Collection Time: 2.38946
Timestep Consumption Time: 2.61222
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 5.00169

Cumulative Model Updates: 86,960
Cumulative Timesteps: 725,365,174

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 725365174...
Checkpoint 725365174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,536.75103
Policy Entropy: 1.89702
Value Function Loss: 0.08774

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12792
Policy Update Magnitude: 0.56508
Value Function Update Magnitude: 0.35691

Collected Steps per Second: 19,344.63447
Overall Steps per Second: 9,803.26312

Timestep Collection Time: 2.58583
Timestep Consumption Time: 2.51675
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 5.10259

Cumulative Model Updates: 86,966
Cumulative Timesteps: 725,415,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,689.78959
Policy Entropy: 1.91472
Value Function Loss: 0.09003

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.56389
Value Function Update Magnitude: 0.38740

Collected Steps per Second: 20,947.57370
Overall Steps per Second: 10,096.19704

Timestep Collection Time: 2.38806
Timestep Consumption Time: 2.56668
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.95474

Cumulative Model Updates: 86,972
Cumulative Timesteps: 725,465,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 725465220...
Checkpoint 725465220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,451.72961
Policy Entropy: 1.93117
Value Function Loss: 0.08570

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12997
Policy Update Magnitude: 0.56335
Value Function Update Magnitude: 0.39874

Collected Steps per Second: 20,422.58065
Overall Steps per Second: 10,012.40399

Timestep Collection Time: 2.44886
Timestep Consumption Time: 2.54615
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.99500

Cumulative Model Updates: 86,978
Cumulative Timesteps: 725,515,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,752.61648
Policy Entropy: 1.93189
Value Function Loss: 0.08176

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.55546
Value Function Update Magnitude: 0.38089

Collected Steps per Second: 21,680.15433
Overall Steps per Second: 10,186.79400

Timestep Collection Time: 2.30764
Timestep Consumption Time: 2.60362
PPO Batch Consumption Time: 0.29909
Total Iteration Time: 4.91126

Cumulative Model Updates: 86,984
Cumulative Timesteps: 725,565,262

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 725565262...
Checkpoint 725565262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,175.81089
Policy Entropy: 1.94183
Value Function Loss: 0.08406

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.54343
Value Function Update Magnitude: 0.38864

Collected Steps per Second: 19,916.64827
Overall Steps per Second: 9,889.17046

Timestep Collection Time: 2.51117
Timestep Consumption Time: 2.54629
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 5.05745

Cumulative Model Updates: 86,990
Cumulative Timesteps: 725,615,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,129.47793
Policy Entropy: 1.93533
Value Function Loss: 0.07971

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.15845
Policy Update Magnitude: 0.50490
Value Function Update Magnitude: 0.45822

Collected Steps per Second: 20,650.84338
Overall Steps per Second: 10,124.08910

Timestep Collection Time: 2.42237
Timestep Consumption Time: 2.51872
PPO Batch Consumption Time: 0.30022
Total Iteration Time: 4.94109

Cumulative Model Updates: 86,996
Cumulative Timesteps: 725,665,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 725665300...
Checkpoint 725665300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,282.20156
Policy Entropy: 1.92535
Value Function Loss: 0.07849

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.53648
Value Function Update Magnitude: 0.64173

Collected Steps per Second: 19,953.59320
Overall Steps per Second: 10,185.97084

Timestep Collection Time: 2.50692
Timestep Consumption Time: 2.40396
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.91087

Cumulative Model Updates: 87,002
Cumulative Timesteps: 725,715,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,381.43948
Policy Entropy: 1.90895
Value Function Loss: 0.08297

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.55840
Value Function Update Magnitude: 0.63728

Collected Steps per Second: 20,784.93205
Overall Steps per Second: 10,263.72327

Timestep Collection Time: 2.40636
Timestep Consumption Time: 2.46673
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.87309

Cumulative Model Updates: 87,008
Cumulative Timesteps: 725,765,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 725765338...
Checkpoint 725765338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,933.33844
Policy Entropy: 1.91110
Value Function Loss: 0.08526

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.56494
Value Function Update Magnitude: 0.59169

Collected Steps per Second: 19,165.71158
Overall Steps per Second: 9,951.54391

Timestep Collection Time: 2.61050
Timestep Consumption Time: 2.41707
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 5.02756

Cumulative Model Updates: 87,014
Cumulative Timesteps: 725,815,370

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,537.70801
Policy Entropy: 1.92039
Value Function Loss: 0.08791

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.55567
Value Function Update Magnitude: 0.62058

Collected Steps per Second: 20,172.74454
Overall Steps per Second: 9,999.40456

Timestep Collection Time: 2.48077
Timestep Consumption Time: 2.52392
PPO Batch Consumption Time: 0.30181
Total Iteration Time: 5.00470

Cumulative Model Updates: 87,020
Cumulative Timesteps: 725,865,414

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 725865414...
Checkpoint 725865414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,580.89474
Policy Entropy: 1.91886
Value Function Loss: 0.07545

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.54458
Value Function Update Magnitude: 0.68625

Collected Steps per Second: 19,716.17428
Overall Steps per Second: 9,992.31767

Timestep Collection Time: 2.53690
Timestep Consumption Time: 2.46874
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 5.00565

Cumulative Model Updates: 87,026
Cumulative Timesteps: 725,915,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,320.54917
Policy Entropy: 1.91679
Value Function Loss: 0.07247

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.53389
Value Function Update Magnitude: 0.65182

Collected Steps per Second: 20,934.18782
Overall Steps per Second: 10,185.63666

Timestep Collection Time: 2.38911
Timestep Consumption Time: 2.52114
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.91025

Cumulative Model Updates: 87,032
Cumulative Timesteps: 725,965,446

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 725965446...
Checkpoint 725965446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,324.90184
Policy Entropy: 1.91062
Value Function Loss: 0.07168

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13396
Policy Update Magnitude: 0.53133
Value Function Update Magnitude: 0.55426

Collected Steps per Second: 20,159.18698
Overall Steps per Second: 9,913.76640

Timestep Collection Time: 2.48165
Timestep Consumption Time: 2.56467
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 5.04632

Cumulative Model Updates: 87,038
Cumulative Timesteps: 726,015,474

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,903.18313
Policy Entropy: 1.91076
Value Function Loss: 0.07204

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.51272
Value Function Update Magnitude: 0.62954

Collected Steps per Second: 20,956.15836
Overall Steps per Second: 9,580.45882

Timestep Collection Time: 2.38622
Timestep Consumption Time: 2.83336
PPO Batch Consumption Time: 0.31483
Total Iteration Time: 5.21958

Cumulative Model Updates: 87,044
Cumulative Timesteps: 726,065,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 726065480...
Checkpoint 726065480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,314.95997
Policy Entropy: 1.91002
Value Function Loss: 0.07795

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.51681
Value Function Update Magnitude: 0.61481

Collected Steps per Second: 20,804.80001
Overall Steps per Second: 10,228.50868

Timestep Collection Time: 2.40406
Timestep Consumption Time: 2.48580
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.88986

Cumulative Model Updates: 87,050
Cumulative Timesteps: 726,115,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,270.22209
Policy Entropy: 1.91790
Value Function Loss: 0.07857

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.15382
Policy Update Magnitude: 0.49071
Value Function Update Magnitude: 0.63619

Collected Steps per Second: 20,988.02762
Overall Steps per Second: 9,962.09314

Timestep Collection Time: 2.38317
Timestep Consumption Time: 2.63766
PPO Batch Consumption Time: 0.30523
Total Iteration Time: 5.02083

Cumulative Model Updates: 87,056
Cumulative Timesteps: 726,165,514

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 726165514...
Checkpoint 726165514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,172.10571
Policy Entropy: 1.91356
Value Function Loss: 0.07725

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.13919
Policy Update Magnitude: 0.49270
Value Function Update Magnitude: 0.71691

Collected Steps per Second: 20,943.02037
Overall Steps per Second: 10,203.93239

Timestep Collection Time: 2.38858
Timestep Consumption Time: 2.51385
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.90242

Cumulative Model Updates: 87,062
Cumulative Timesteps: 726,215,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,330.42387
Policy Entropy: 1.92994
Value Function Loss: 0.07838

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.54162
Value Function Update Magnitude: 0.73695

Collected Steps per Second: 21,466.76787
Overall Steps per Second: 10,296.44131

Timestep Collection Time: 2.32937
Timestep Consumption Time: 2.52707
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.85644

Cumulative Model Updates: 87,068
Cumulative Timesteps: 726,265,542

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 726265542...
Checkpoint 726265542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,751.80604
Policy Entropy: 1.91996
Value Function Loss: 0.07805

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13603
Policy Update Magnitude: 0.55252
Value Function Update Magnitude: 0.66068

Collected Steps per Second: 20,709.62492
Overall Steps per Second: 9,969.18319

Timestep Collection Time: 2.41521
Timestep Consumption Time: 2.60206
PPO Batch Consumption Time: 0.30265
Total Iteration Time: 5.01726

Cumulative Model Updates: 87,074
Cumulative Timesteps: 726,315,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,047.31606
Policy Entropy: 1.93735
Value Function Loss: 0.08338

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.54794
Value Function Update Magnitude: 0.54042

Collected Steps per Second: 20,223.22775
Overall Steps per Second: 10,083.86311

Timestep Collection Time: 2.47329
Timestep Consumption Time: 2.48691
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.96020

Cumulative Model Updates: 87,080
Cumulative Timesteps: 726,365,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 726365578...
Checkpoint 726365578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,714.20424
Policy Entropy: 1.92636
Value Function Loss: 0.08626

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.55249
Value Function Update Magnitude: 0.44465

Collected Steps per Second: 20,871.20444
Overall Steps per Second: 10,163.68581

Timestep Collection Time: 2.39689
Timestep Consumption Time: 2.52514
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.92203

Cumulative Model Updates: 87,086
Cumulative Timesteps: 726,415,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,552.68503
Policy Entropy: 1.92916
Value Function Loss: 0.09132

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.57133
Value Function Update Magnitude: 0.43161

Collected Steps per Second: 20,865.82316
Overall Steps per Second: 10,336.88551

Timestep Collection Time: 2.39626
Timestep Consumption Time: 2.44078
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.83705

Cumulative Model Updates: 87,092
Cumulative Timesteps: 726,465,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 726465604...
Checkpoint 726465604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,464.16299
Policy Entropy: 1.94132
Value Function Loss: 0.08774

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.56671
Value Function Update Magnitude: 0.40709

Collected Steps per Second: 20,392.61365
Overall Steps per Second: 9,991.62086

Timestep Collection Time: 2.45363
Timestep Consumption Time: 2.55416
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 5.00780

Cumulative Model Updates: 87,098
Cumulative Timesteps: 726,515,640

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,396.11580
Policy Entropy: 1.95532
Value Function Loss: 0.08649

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.56058
Value Function Update Magnitude: 0.35987

Collected Steps per Second: 21,026.13721
Overall Steps per Second: 10,074.36080

Timestep Collection Time: 2.37866
Timestep Consumption Time: 2.58583
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.96448

Cumulative Model Updates: 87,104
Cumulative Timesteps: 726,565,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 726565654...
Checkpoint 726565654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,739.08330
Policy Entropy: 1.94646
Value Function Loss: 0.08313

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.55002
Value Function Update Magnitude: 0.38730

Collected Steps per Second: 19,841.59563
Overall Steps per Second: 9,829.46754

Timestep Collection Time: 2.52137
Timestep Consumption Time: 2.56822
PPO Batch Consumption Time: 0.29757
Total Iteration Time: 5.08959

Cumulative Model Updates: 87,110
Cumulative Timesteps: 726,615,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,776.65455
Policy Entropy: 1.93088
Value Function Loss: 0.07864

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.54216
Value Function Update Magnitude: 0.51382

Collected Steps per Second: 21,340.43378
Overall Steps per Second: 10,091.22099

Timestep Collection Time: 2.34306
Timestep Consumption Time: 2.61194
PPO Batch Consumption Time: 0.30119
Total Iteration Time: 4.95500

Cumulative Model Updates: 87,116
Cumulative Timesteps: 726,665,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 726665684...
Checkpoint 726665684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,706.19554
Policy Entropy: 1.91942
Value Function Loss: 0.07605

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.13079
Policy Update Magnitude: 0.52813
Value Function Update Magnitude: 0.50404

Collected Steps per Second: 20,578.43674
Overall Steps per Second: 10,114.42893

Timestep Collection Time: 2.43070
Timestep Consumption Time: 2.51471
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.94541

Cumulative Model Updates: 87,122
Cumulative Timesteps: 726,715,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,384.29383
Policy Entropy: 1.90928
Value Function Loss: 0.07563

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.16209
Policy Update Magnitude: 0.49635
Value Function Update Magnitude: 0.52798

Collected Steps per Second: 21,234.46444
Overall Steps per Second: 10,147.48339

Timestep Collection Time: 2.35560
Timestep Consumption Time: 2.57370
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.92930

Cumulative Model Updates: 87,128
Cumulative Timesteps: 726,765,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 726765724...
Checkpoint 726765724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,618.11864
Policy Entropy: 1.90784
Value Function Loss: 0.08023

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.15795
Policy Update Magnitude: 0.44694
Value Function Update Magnitude: 0.51088

Collected Steps per Second: 20,901.33333
Overall Steps per Second: 10,119.63565

Timestep Collection Time: 2.39286
Timestep Consumption Time: 2.54941
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.94227

Cumulative Model Updates: 87,134
Cumulative Timesteps: 726,815,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,946.56587
Policy Entropy: 1.90384
Value Function Loss: 0.07899

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.46380
Value Function Update Magnitude: 0.54717

Collected Steps per Second: 21,437.06343
Overall Steps per Second: 10,214.66337

Timestep Collection Time: 2.33278
Timestep Consumption Time: 2.56292
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.89571

Cumulative Model Updates: 87,140
Cumulative Timesteps: 726,865,746

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 726865746...
Checkpoint 726865746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,371.27154
Policy Entropy: 1.92156
Value Function Loss: 0.08657

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.15513
Policy Update Magnitude: 0.45862
Value Function Update Magnitude: 0.65435

Collected Steps per Second: 21,049.83728
Overall Steps per Second: 9,989.05099

Timestep Collection Time: 2.37627
Timestep Consumption Time: 2.63122
PPO Batch Consumption Time: 0.30575
Total Iteration Time: 5.00748

Cumulative Model Updates: 87,146
Cumulative Timesteps: 726,915,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,374.12110
Policy Entropy: 1.92800
Value Function Loss: 0.08587

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.16114
Policy Update Magnitude: 0.47166
Value Function Update Magnitude: 0.63128

Collected Steps per Second: 20,835.58738
Overall Steps per Second: 10,081.93172

Timestep Collection Time: 2.40032
Timestep Consumption Time: 2.56024
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.96056

Cumulative Model Updates: 87,152
Cumulative Timesteps: 726,965,778

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 726965778...
Checkpoint 726965778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,308.69318
Policy Entropy: 1.94814
Value Function Loss: 0.08872

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.16201
Policy Update Magnitude: 0.49094
Value Function Update Magnitude: 0.56661

Collected Steps per Second: 20,523.56303
Overall Steps per Second: 10,127.69749

Timestep Collection Time: 2.43671
Timestep Consumption Time: 2.50123
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.93794

Cumulative Model Updates: 87,158
Cumulative Timesteps: 727,015,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,765.33864
Policy Entropy: 1.93577
Value Function Loss: 0.09326

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.54766
Value Function Update Magnitude: 0.48185

Collected Steps per Second: 21,398.99868
Overall Steps per Second: 10,201.73301

Timestep Collection Time: 2.33787
Timestep Consumption Time: 2.56601
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.90387

Cumulative Model Updates: 87,164
Cumulative Timesteps: 727,065,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 727065816...
Checkpoint 727065816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,661.77504
Policy Entropy: 1.91929
Value Function Loss: 0.08617

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.57484
Value Function Update Magnitude: 0.47399

Collected Steps per Second: 21,216.32845
Overall Steps per Second: 10,042.10762

Timestep Collection Time: 2.35734
Timestep Consumption Time: 2.62309
PPO Batch Consumption Time: 0.30336
Total Iteration Time: 4.98043

Cumulative Model Updates: 87,170
Cumulative Timesteps: 727,115,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,705.59879
Policy Entropy: 1.91048
Value Function Loss: 0.08477

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.56521
Value Function Update Magnitude: 0.57137

Collected Steps per Second: 21,490.13042
Overall Steps per Second: 10,104.21854

Timestep Collection Time: 2.32814
Timestep Consumption Time: 2.62346
PPO Batch Consumption Time: 0.30399
Total Iteration Time: 4.95160

Cumulative Model Updates: 87,176
Cumulative Timesteps: 727,165,862

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 727165862...
Checkpoint 727165862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,497.08173
Policy Entropy: 1.90457
Value Function Loss: 0.07587

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.52256
Value Function Update Magnitude: 0.56852

Collected Steps per Second: 20,852.07655
Overall Steps per Second: 10,037.85878

Timestep Collection Time: 2.39909
Timestep Consumption Time: 2.58464
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 4.98373

Cumulative Model Updates: 87,182
Cumulative Timesteps: 727,215,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,803.28026
Policy Entropy: 1.90429
Value Function Loss: 0.07562

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.15818
Policy Update Magnitude: 0.47513
Value Function Update Magnitude: 0.57486

Collected Steps per Second: 21,342.84013
Overall Steps per Second: 10,284.09684

Timestep Collection Time: 2.34364
Timestep Consumption Time: 2.52018
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.86382

Cumulative Model Updates: 87,188
Cumulative Timesteps: 727,265,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 727265908...
Checkpoint 727265908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,873.57513
Policy Entropy: 1.93241
Value Function Loss: 0.08574

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.15021
Policy Update Magnitude: 0.44391
Value Function Update Magnitude: 0.45384

Collected Steps per Second: 20,552.23612
Overall Steps per Second: 9,996.45865

Timestep Collection Time: 2.43283
Timestep Consumption Time: 2.56895
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 5.00177

Cumulative Model Updates: 87,194
Cumulative Timesteps: 727,315,908

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,100.33475
Policy Entropy: 1.93901
Value Function Loss: 0.08950

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.14480
Policy Update Magnitude: 0.48585
Value Function Update Magnitude: 0.38201

Collected Steps per Second: 21,196.82076
Overall Steps per Second: 10,113.71694

Timestep Collection Time: 2.35988
Timestep Consumption Time: 2.58607
PPO Batch Consumption Time: 0.30292
Total Iteration Time: 4.94596

Cumulative Model Updates: 87,200
Cumulative Timesteps: 727,365,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 727365930...
Checkpoint 727365930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,257.06071
Policy Entropy: 1.93339
Value Function Loss: 0.09129

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.15680
Policy Update Magnitude: 0.50123
Value Function Update Magnitude: 0.35248

Collected Steps per Second: 20,909.62029
Overall Steps per Second: 10,201.35154

Timestep Collection Time: 2.39354
Timestep Consumption Time: 2.51248
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.90602

Cumulative Model Updates: 87,206
Cumulative Timesteps: 727,415,978

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,252.50465
Policy Entropy: 1.91747
Value Function Loss: 0.08172

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.17635
Policy Update Magnitude: 0.51939
Value Function Update Magnitude: 0.35231

Collected Steps per Second: 21,172.67601
Overall Steps per Second: 10,183.88475

Timestep Collection Time: 2.36220
Timestep Consumption Time: 2.54890
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.91109

Cumulative Model Updates: 87,212
Cumulative Timesteps: 727,465,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 727465992...
Checkpoint 727465992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,913.50406
Policy Entropy: 1.91394
Value Function Loss: 0.08507

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.16592
Policy Update Magnitude: 0.50616
Value Function Update Magnitude: 0.33331

Collected Steps per Second: 20,134.28385
Overall Steps per Second: 9,824.36671

Timestep Collection Time: 2.48402
Timestep Consumption Time: 2.60679
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 5.09081

Cumulative Model Updates: 87,218
Cumulative Timesteps: 727,516,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,745.24260
Policy Entropy: 1.92050
Value Function Loss: 0.09276

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.15492
Policy Update Magnitude: 0.52303
Value Function Update Magnitude: 0.30898

Collected Steps per Second: 21,653.01758
Overall Steps per Second: 10,312.57137

Timestep Collection Time: 2.30989
Timestep Consumption Time: 2.54012
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.85000

Cumulative Model Updates: 87,224
Cumulative Timesteps: 727,566,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 727566022...
Checkpoint 727566022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,222.48445
Policy Entropy: 1.90809
Value Function Loss: 0.09725

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.15186
Policy Update Magnitude: 0.55587
Value Function Update Magnitude: 0.28145

Collected Steps per Second: 20,909.37248
Overall Steps per Second: 10,193.51681

Timestep Collection Time: 2.39175
Timestep Consumption Time: 2.51431
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.90606

Cumulative Model Updates: 87,230
Cumulative Timesteps: 727,616,032

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,550.71273
Policy Entropy: 1.89900
Value Function Loss: 0.09594

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.56431
Value Function Update Magnitude: 0.30407

Collected Steps per Second: 21,161.44127
Overall Steps per Second: 10,138.77530

Timestep Collection Time: 2.36506
Timestep Consumption Time: 2.57124
PPO Batch Consumption Time: 0.29861
Total Iteration Time: 4.93630

Cumulative Model Updates: 87,236
Cumulative Timesteps: 727,666,080

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 727666080...
Checkpoint 727666080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,560.82671
Policy Entropy: 1.89460
Value Function Loss: 0.08677

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.55599
Value Function Update Magnitude: 0.28579

Collected Steps per Second: 20,138.44000
Overall Steps per Second: 9,833.47668

Timestep Collection Time: 2.48311
Timestep Consumption Time: 2.60217
PPO Batch Consumption Time: 0.30253
Total Iteration Time: 5.08528

Cumulative Model Updates: 87,242
Cumulative Timesteps: 727,716,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,658.48041
Policy Entropy: 1.89741
Value Function Loss: 0.08283

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.13148
Policy Update Magnitude: 0.54601
Value Function Update Magnitude: 0.38893

Collected Steps per Second: 21,153.02058
Overall Steps per Second: 10,102.58346

Timestep Collection Time: 2.36524
Timestep Consumption Time: 2.58716
PPO Batch Consumption Time: 0.29851
Total Iteration Time: 4.95240

Cumulative Model Updates: 87,248
Cumulative Timesteps: 727,766,118

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 727766118...
Checkpoint 727766118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,274.72113
Policy Entropy: 1.90142
Value Function Loss: 0.07615

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.53618
Value Function Update Magnitude: 0.57221

Collected Steps per Second: 20,416.19807
Overall Steps per Second: 10,108.03429

Timestep Collection Time: 2.45031
Timestep Consumption Time: 2.49882
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.94913

Cumulative Model Updates: 87,254
Cumulative Timesteps: 727,816,144

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,565.08211
Policy Entropy: 1.90763
Value Function Loss: 0.07413

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.15337
Policy Update Magnitude: 0.49541
Value Function Update Magnitude: 0.62396

Collected Steps per Second: 21,711.53256
Overall Steps per Second: 10,448.43040

Timestep Collection Time: 2.30311
Timestep Consumption Time: 2.48268
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.78579

Cumulative Model Updates: 87,260
Cumulative Timesteps: 727,866,148

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 727866148...
Checkpoint 727866148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,454.03072
Policy Entropy: 1.91066
Value Function Loss: 0.07932

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.15011
Policy Update Magnitude: 0.48896
Value Function Update Magnitude: 0.57574

Collected Steps per Second: 20,861.05594
Overall Steps per Second: 10,046.30967

Timestep Collection Time: 2.39681
Timestep Consumption Time: 2.58014
PPO Batch Consumption Time: 0.29733
Total Iteration Time: 4.97695

Cumulative Model Updates: 87,266
Cumulative Timesteps: 727,916,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,043.97118
Policy Entropy: 1.90661
Value Function Loss: 0.09069

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14684
Policy Update Magnitude: 0.53543
Value Function Update Magnitude: 0.41985

Collected Steps per Second: 21,734.38743
Overall Steps per Second: 10,293.58580

Timestep Collection Time: 2.30087
Timestep Consumption Time: 2.55730
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.85817

Cumulative Model Updates: 87,272
Cumulative Timesteps: 727,966,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 727966156...
Checkpoint 727966156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,667.40905
Policy Entropy: 1.91836
Value Function Loss: 0.09596

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.56712
Value Function Update Magnitude: 0.35578

Collected Steps per Second: 20,531.30466
Overall Steps per Second: 10,146.23798

Timestep Collection Time: 2.43657
Timestep Consumption Time: 2.49393
PPO Batch Consumption Time: 0.29768
Total Iteration Time: 4.93050

Cumulative Model Updates: 87,278
Cumulative Timesteps: 728,016,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,985.30744
Policy Entropy: 1.92651
Value Function Loss: 0.08636

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.14894
Policy Update Magnitude: 0.55280
Value Function Update Magnitude: 0.33556

Collected Steps per Second: 20,550.99944
Overall Steps per Second: 10,224.07610

Timestep Collection Time: 2.43453
Timestep Consumption Time: 2.45902
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.89355

Cumulative Model Updates: 87,284
Cumulative Timesteps: 728,066,214

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 728066214...
Checkpoint 728066214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,533.73662
Policy Entropy: 1.94030
Value Function Loss: 0.08513

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.14185
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.37130

Collected Steps per Second: 20,353.52390
Overall Steps per Second: 10,104.09667

Timestep Collection Time: 2.45835
Timestep Consumption Time: 2.49371
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.95205

Cumulative Model Updates: 87,290
Cumulative Timesteps: 728,116,250

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,616.42405
Policy Entropy: 1.92267
Value Function Loss: 0.08892

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.55552
Value Function Update Magnitude: 0.35667

Collected Steps per Second: 20,971.05932
Overall Steps per Second: 10,401.59614

Timestep Collection Time: 2.38538
Timestep Consumption Time: 2.42388
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.80926

Cumulative Model Updates: 87,296
Cumulative Timesteps: 728,166,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 728166274...
Checkpoint 728166274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,004.05270
Policy Entropy: 1.91262
Value Function Loss: 0.08574

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.15549
Policy Update Magnitude: 0.51235
Value Function Update Magnitude: 0.43750

Collected Steps per Second: 20,526.63839
Overall Steps per Second: 10,243.19385

Timestep Collection Time: 2.43713
Timestep Consumption Time: 2.44670
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.88383

Cumulative Model Updates: 87,302
Cumulative Timesteps: 728,216,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,723.86252
Policy Entropy: 1.90264
Value Function Loss: 0.09066

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.51615
Value Function Update Magnitude: 0.56643

Collected Steps per Second: 20,848.15443
Overall Steps per Second: 10,388.48145

Timestep Collection Time: 2.39973
Timestep Consumption Time: 2.41618
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.81591

Cumulative Model Updates: 87,308
Cumulative Timesteps: 728,266,330

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 728266330...
Checkpoint 728266330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,041.25097
Policy Entropy: 1.90397
Value Function Loss: 0.09024

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.13364
Policy Update Magnitude: 0.58134
Value Function Update Magnitude: 0.64503

Collected Steps per Second: 20,123.71170
Overall Steps per Second: 9,977.73473

Timestep Collection Time: 2.48533
Timestep Consumption Time: 2.52723
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 5.01256

Cumulative Model Updates: 87,314
Cumulative Timesteps: 728,316,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,601.52379
Policy Entropy: 1.91465
Value Function Loss: 0.09662

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.59686
Value Function Update Magnitude: 0.51468

Collected Steps per Second: 21,175.60585
Overall Steps per Second: 10,262.70208

Timestep Collection Time: 2.36291
Timestep Consumption Time: 2.51261
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.87552

Cumulative Model Updates: 87,320
Cumulative Timesteps: 728,366,380

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 728366380...
Checkpoint 728366380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,501.64591
Policy Entropy: 1.92528
Value Function Loss: 0.09301

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.58741
Value Function Update Magnitude: 0.49082

Collected Steps per Second: 20,584.54003
Overall Steps per Second: 10,106.04968

Timestep Collection Time: 2.42998
Timestep Consumption Time: 2.51953
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.94951

Cumulative Model Updates: 87,326
Cumulative Timesteps: 728,416,400

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,612.42039
Policy Entropy: 1.91830
Value Function Loss: 0.08198

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.57067
Value Function Update Magnitude: 0.56027

Collected Steps per Second: 21,603.71139
Overall Steps per Second: 10,186.79634

Timestep Collection Time: 2.31618
Timestep Consumption Time: 2.59587
PPO Batch Consumption Time: 0.30579
Total Iteration Time: 4.91204

Cumulative Model Updates: 87,332
Cumulative Timesteps: 728,466,438

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 728466438...
Checkpoint 728466438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,500.97811
Policy Entropy: 1.91059
Value Function Loss: 0.08308

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.56426
Value Function Update Magnitude: 0.54075

Collected Steps per Second: 20,763.93838
Overall Steps per Second: 10,123.63188

Timestep Collection Time: 2.40841
Timestep Consumption Time: 2.53132
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.93973

Cumulative Model Updates: 87,338
Cumulative Timesteps: 728,516,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,974.83533
Policy Entropy: 1.90464
Value Function Loss: 0.08288

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.56611
Value Function Update Magnitude: 0.57231

Collected Steps per Second: 21,099.20133
Overall Steps per Second: 10,080.04133

Timestep Collection Time: 2.37118
Timestep Consumption Time: 2.59209
PPO Batch Consumption Time: 0.29997
Total Iteration Time: 4.96327

Cumulative Model Updates: 87,344
Cumulative Timesteps: 728,566,476

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 728566476...
Checkpoint 728566476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,403.49244
Policy Entropy: 1.91656
Value Function Loss: 0.08924

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.56852
Value Function Update Magnitude: 0.55016

Collected Steps per Second: 20,480.38180
Overall Steps per Second: 9,915.96848

Timestep Collection Time: 2.44165
Timestep Consumption Time: 2.60132
PPO Batch Consumption Time: 0.30524
Total Iteration Time: 5.04298

Cumulative Model Updates: 87,350
Cumulative Timesteps: 728,616,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,693.79885
Policy Entropy: 1.92273
Value Function Loss: 0.08934

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.55615
Value Function Update Magnitude: 0.45923

Collected Steps per Second: 19,320.57485
Overall Steps per Second: 9,248.81105

Timestep Collection Time: 2.58843
Timestep Consumption Time: 2.81875
PPO Batch Consumption Time: 0.32614
Total Iteration Time: 5.40718

Cumulative Model Updates: 87,356
Cumulative Timesteps: 728,666,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 728666492...
Checkpoint 728666492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,588.31065
Policy Entropy: 1.91026
Value Function Loss: 0.09268

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.57050
Value Function Update Magnitude: 0.54092

Collected Steps per Second: 18,003.07035
Overall Steps per Second: 9,414.03514

Timestep Collection Time: 2.77786
Timestep Consumption Time: 2.53442
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 5.31228

Cumulative Model Updates: 87,362
Cumulative Timesteps: 728,716,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,563.68657
Policy Entropy: 1.91181
Value Function Loss: 0.08584

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14527
Policy Update Magnitude: 0.55667
Value Function Update Magnitude: 0.67355

Collected Steps per Second: 20,008.65008
Overall Steps per Second: 9,423.59630

Timestep Collection Time: 2.50102
Timestep Consumption Time: 2.80927
PPO Batch Consumption Time: 0.33101
Total Iteration Time: 5.31029

Cumulative Model Updates: 87,368
Cumulative Timesteps: 728,766,544

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 728766544...
Checkpoint 728766544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,881.42437
Policy Entropy: 1.89273
Value Function Loss: 0.08227

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.15228
Policy Update Magnitude: 0.54210
Value Function Update Magnitude: 0.73482

Collected Steps per Second: 19,383.45613
Overall Steps per Second: 9,300.92438

Timestep Collection Time: 2.58189
Timestep Consumption Time: 2.79886
PPO Batch Consumption Time: 0.32244
Total Iteration Time: 5.38076

Cumulative Model Updates: 87,374
Cumulative Timesteps: 728,816,590

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,840.02843
Policy Entropy: 1.90382
Value Function Loss: 0.07926

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.15921
Policy Update Magnitude: 0.51291
Value Function Update Magnitude: 0.75707

Collected Steps per Second: 18,351.74531
Overall Steps per Second: 9,327.20987

Timestep Collection Time: 2.72574
Timestep Consumption Time: 2.63728
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 5.36302

Cumulative Model Updates: 87,380
Cumulative Timesteps: 728,866,612

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 728866612...
Checkpoint 728866612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,252.26878
Policy Entropy: 1.89417
Value Function Loss: 0.08858

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.15948
Policy Update Magnitude: 0.51003
Value Function Update Magnitude: 0.74901

Collected Steps per Second: 21,190.11860
Overall Steps per Second: 10,054.71096

Timestep Collection Time: 2.36063
Timestep Consumption Time: 2.61435
PPO Batch Consumption Time: 0.30330
Total Iteration Time: 4.97498

Cumulative Model Updates: 87,386
Cumulative Timesteps: 728,916,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,683.27551
Policy Entropy: 1.91276
Value Function Loss: 0.09407

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14695
Policy Update Magnitude: 0.54247
Value Function Update Magnitude: 0.62890

Collected Steps per Second: 19,253.16153
Overall Steps per Second: 9,612.95644

Timestep Collection Time: 2.59937
Timestep Consumption Time: 2.60673
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 5.20610

Cumulative Model Updates: 87,392
Cumulative Timesteps: 728,966,680

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 728966680...
Checkpoint 728966680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,707.07161
Policy Entropy: 1.90797
Value Function Loss: 0.09441

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.57060
Value Function Update Magnitude: 0.62857

Collected Steps per Second: 18,352.86202
Overall Steps per Second: 9,641.72773

Timestep Collection Time: 2.72448
Timestep Consumption Time: 2.46152
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 5.18600

Cumulative Model Updates: 87,398
Cumulative Timesteps: 729,016,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,710.00299
Policy Entropy: 1.92161
Value Function Loss: 0.08978

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.58181
Value Function Update Magnitude: 0.67136

Collected Steps per Second: 21,388.68841
Overall Steps per Second: 10,258.46769

Timestep Collection Time: 2.33834
Timestep Consumption Time: 2.53705
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.87539

Cumulative Model Updates: 87,404
Cumulative Timesteps: 729,066,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 729066696...
Checkpoint 729066696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,331.83827
Policy Entropy: 1.90584
Value Function Loss: 0.08545

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.57780
Value Function Update Magnitude: 0.68850

Collected Steps per Second: 20,140.23926
Overall Steps per Second: 9,952.69664

Timestep Collection Time: 2.48378
Timestep Consumption Time: 2.54239
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 5.02618

Cumulative Model Updates: 87,410
Cumulative Timesteps: 729,116,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,530.19423
Policy Entropy: 1.91658
Value Function Loss: 0.09171

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.58015
Value Function Update Magnitude: 0.76056

Collected Steps per Second: 17,905.88880
Overall Steps per Second: 9,272.82619

Timestep Collection Time: 2.79338
Timestep Consumption Time: 2.60066
PPO Batch Consumption Time: 0.29751
Total Iteration Time: 5.39404

Cumulative Model Updates: 87,416
Cumulative Timesteps: 729,166,738

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 729166738...
Checkpoint 729166738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,092.15042
Policy Entropy: 1.90122
Value Function Loss: 0.09217

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.59206
Value Function Update Magnitude: 0.70193

Collected Steps per Second: 19,687.20194
Overall Steps per Second: 9,814.45552

Timestep Collection Time: 2.54145
Timestep Consumption Time: 2.55654
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 5.09799

Cumulative Model Updates: 87,422
Cumulative Timesteps: 729,216,772

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,637.19417
Policy Entropy: 1.89111
Value Function Loss: 0.09706

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.60203
Value Function Update Magnitude: 0.81413

Collected Steps per Second: 19,021.00480
Overall Steps per Second: 9,793.18008

Timestep Collection Time: 2.63067
Timestep Consumption Time: 2.47880
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 5.10947

Cumulative Model Updates: 87,428
Cumulative Timesteps: 729,266,810

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 729266810...
Checkpoint 729266810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,869.11669
Policy Entropy: 1.88092
Value Function Loss: 0.08468

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.59177
Value Function Update Magnitude: 0.82309

Collected Steps per Second: 19,079.64194
Overall Steps per Second: 9,870.53850

Timestep Collection Time: 2.62080
Timestep Consumption Time: 2.44518
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 5.06598

Cumulative Model Updates: 87,434
Cumulative Timesteps: 729,316,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,856.97925
Policy Entropy: 1.88687
Value Function Loss: 0.08801

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.59031
Value Function Update Magnitude: 0.65836

Collected Steps per Second: 21,344.43115
Overall Steps per Second: 10,299.01915

Timestep Collection Time: 2.34319
Timestep Consumption Time: 2.51300
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.85619

Cumulative Model Updates: 87,440
Cumulative Timesteps: 729,366,828

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 729366828...
Checkpoint 729366828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,413.98437
Policy Entropy: 1.89412
Value Function Loss: 0.08900

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.13895
Policy Update Magnitude: 0.58049
Value Function Update Magnitude: 0.50382

Collected Steps per Second: 20,717.42910
Overall Steps per Second: 10,273.07720

Timestep Collection Time: 2.41430
Timestep Consumption Time: 2.45455
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.86884

Cumulative Model Updates: 87,446
Cumulative Timesteps: 729,416,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,446.29003
Policy Entropy: 1.91943
Value Function Loss: 0.09281

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.58035
Value Function Update Magnitude: 0.43471

Collected Steps per Second: 20,984.79289
Overall Steps per Second: 10,120.03193

Timestep Collection Time: 2.38277
Timestep Consumption Time: 2.55812
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.94089

Cumulative Model Updates: 87,452
Cumulative Timesteps: 729,466,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 729466848...
Checkpoint 729466848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,469.11685
Policy Entropy: 1.91208
Value Function Loss: 0.08915

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.58018
Value Function Update Magnitude: 0.44686

Collected Steps per Second: 20,440.43138
Overall Steps per Second: 9,921.14208

Timestep Collection Time: 2.44672
Timestep Consumption Time: 2.59423
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 5.04095

Cumulative Model Updates: 87,458
Cumulative Timesteps: 729,516,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,374.01665
Policy Entropy: 1.92329
Value Function Loss: 0.09441

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.56285
Value Function Update Magnitude: 0.42594

Collected Steps per Second: 21,784.18634
Overall Steps per Second: 10,623.87107

Timestep Collection Time: 2.29671
Timestep Consumption Time: 2.41268
PPO Batch Consumption Time: 0.27635
Total Iteration Time: 4.70939

Cumulative Model Updates: 87,464
Cumulative Timesteps: 729,566,892

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 729566892...
Checkpoint 729566892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,314.85326
Policy Entropy: 1.93022
Value Function Loss: 0.09481

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.15284
Policy Update Magnitude: 0.52835
Value Function Update Magnitude: 0.46786

Collected Steps per Second: 19,596.17762
Overall Steps per Second: 9,846.73091

Timestep Collection Time: 2.55387
Timestep Consumption Time: 2.52863
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 5.08250

Cumulative Model Updates: 87,470
Cumulative Timesteps: 729,616,938

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,789.03980
Policy Entropy: 1.93331
Value Function Loss: 0.09633

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.53977
Value Function Update Magnitude: 0.41755

Collected Steps per Second: 21,511.97005
Overall Steps per Second: 10,365.17074

Timestep Collection Time: 2.32512
Timestep Consumption Time: 2.50046
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.82558

Cumulative Model Updates: 87,476
Cumulative Timesteps: 729,666,956

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 729666956...
Checkpoint 729666956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,639.17359
Policy Entropy: 1.91402
Value Function Loss: 0.09508

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.56368
Value Function Update Magnitude: 0.40936

Collected Steps per Second: 20,999.34261
Overall Steps per Second: 10,256.25143

Timestep Collection Time: 2.38122
Timestep Consumption Time: 2.49425
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.87547

Cumulative Model Updates: 87,482
Cumulative Timesteps: 729,716,960

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,449.49911
Policy Entropy: 1.91327
Value Function Loss: 0.09381

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.57457
Value Function Update Magnitude: 0.41863

Collected Steps per Second: 21,602.12304
Overall Steps per Second: 10,269.89309

Timestep Collection Time: 2.31468
Timestep Consumption Time: 2.55411
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.86879

Cumulative Model Updates: 87,488
Cumulative Timesteps: 729,766,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 729766962...
Checkpoint 729766962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,515.08307
Policy Entropy: 1.90653
Value Function Loss: 0.08730

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.57105
Value Function Update Magnitude: 0.51282

Collected Steps per Second: 19,042.31332
Overall Steps per Second: 9,549.36745

Timestep Collection Time: 2.62573
Timestep Consumption Time: 2.61022
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 5.23595

Cumulative Model Updates: 87,494
Cumulative Timesteps: 729,816,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,057.29400
Policy Entropy: 1.90901
Value Function Loss: 0.08243

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.55059
Value Function Update Magnitude: 0.55103

Collected Steps per Second: 18,618.42251
Overall Steps per Second: 9,657.01139

Timestep Collection Time: 2.68626
Timestep Consumption Time: 2.49277
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 5.17903

Cumulative Model Updates: 87,500
Cumulative Timesteps: 729,866,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 729866976...
Checkpoint 729866976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,396.85361
Policy Entropy: 1.90498
Value Function Loss: 0.08203

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12954
Policy Update Magnitude: 0.54796
Value Function Update Magnitude: 0.57193

Collected Steps per Second: 20,192.40018
Overall Steps per Second: 9,792.35889

Timestep Collection Time: 2.47737
Timestep Consumption Time: 2.63111
PPO Batch Consumption Time: 0.30449
Total Iteration Time: 5.10847

Cumulative Model Updates: 87,506
Cumulative Timesteps: 729,917,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,107.37053
Policy Entropy: 1.91878
Value Function Loss: 0.08037

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.55843
Value Function Update Magnitude: 0.56051

Collected Steps per Second: 20,783.32036
Overall Steps per Second: 10,097.37053

Timestep Collection Time: 2.40683
Timestep Consumption Time: 2.54713
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.95396

Cumulative Model Updates: 87,512
Cumulative Timesteps: 729,967,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 729967022...
Checkpoint 729967022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,308.88659
Policy Entropy: 1.93390
Value Function Loss: 0.08294

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.54158
Value Function Update Magnitude: 0.58273

Collected Steps per Second: 20,319.11933
Overall Steps per Second: 9,896.98069

Timestep Collection Time: 2.46251
Timestep Consumption Time: 2.59317
PPO Batch Consumption Time: 0.30334
Total Iteration Time: 5.05568

Cumulative Model Updates: 87,518
Cumulative Timesteps: 730,017,058

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,989.77678
Policy Entropy: 1.92936
Value Function Loss: 0.08209

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.53231
Value Function Update Magnitude: 0.62018

Collected Steps per Second: 21,805.17547
Overall Steps per Second: 10,364.31350

Timestep Collection Time: 2.29303
Timestep Consumption Time: 2.53121
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.82425

Cumulative Model Updates: 87,524
Cumulative Timesteps: 730,067,058

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 730067058...
Checkpoint 730067058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,247.67181
Policy Entropy: 1.93260
Value Function Loss: 0.08389

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.52066
Value Function Update Magnitude: 0.53438

Collected Steps per Second: 21,013.52525
Overall Steps per Second: 10,247.75329

Timestep Collection Time: 2.37980
Timestep Consumption Time: 2.50010
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.87990

Cumulative Model Updates: 87,530
Cumulative Timesteps: 730,117,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,674.79586
Policy Entropy: 1.92485
Value Function Loss: 0.08449

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.55081
Value Function Update Magnitude: 0.47237

Collected Steps per Second: 20,781.46712
Overall Steps per Second: 10,043.82139

Timestep Collection Time: 2.40599
Timestep Consumption Time: 2.57220
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 4.97818

Cumulative Model Updates: 87,536
Cumulative Timesteps: 730,167,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 730167066...
Checkpoint 730167066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,309.17927
Policy Entropy: 1.92899
Value Function Loss: 0.09435

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.56199
Value Function Update Magnitude: 0.35930

Collected Steps per Second: 20,510.72249
Overall Steps per Second: 10,104.83601

Timestep Collection Time: 2.43843
Timestep Consumption Time: 2.51108
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.94951

Cumulative Model Updates: 87,542
Cumulative Timesteps: 730,217,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,319.89653
Policy Entropy: 1.93103
Value Function Loss: 0.09850

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.14484
Policy Update Magnitude: 0.54643
Value Function Update Magnitude: 0.30730

Collected Steps per Second: 21,759.90496
Overall Steps per Second: 10,344.15254

Timestep Collection Time: 2.29891
Timestep Consumption Time: 2.53706
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.83597

Cumulative Model Updates: 87,548
Cumulative Timesteps: 730,267,104

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 730267104...
Checkpoint 730267104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,675.93621
Policy Entropy: 1.93261
Value Function Loss: 0.10060

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.17530
Policy Update Magnitude: 0.51090
Value Function Update Magnitude: 0.32244

Collected Steps per Second: 20,999.76430
Overall Steps per Second: 10,136.67300

Timestep Collection Time: 2.38146
Timestep Consumption Time: 2.55212
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.93357

Cumulative Model Updates: 87,554
Cumulative Timesteps: 730,317,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,260.81700
Policy Entropy: 1.93210
Value Function Loss: 0.09589

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.15193
Policy Update Magnitude: 0.55399
Value Function Update Magnitude: 0.37771

Collected Steps per Second: 21,779.12259
Overall Steps per Second: 10,242.62106

Timestep Collection Time: 2.29578
Timestep Consumption Time: 2.58579
PPO Batch Consumption Time: 0.30052
Total Iteration Time: 4.88156

Cumulative Model Updates: 87,560
Cumulative Timesteps: 730,367,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 730367114...
Checkpoint 730367114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,376.75733
Policy Entropy: 1.92970
Value Function Loss: 0.09201

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.57330
Value Function Update Magnitude: 0.57072

Collected Steps per Second: 19,756.83290
Overall Steps per Second: 9,989.69998

Timestep Collection Time: 2.53209
Timestep Consumption Time: 2.47567
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 5.00776

Cumulative Model Updates: 87,566
Cumulative Timesteps: 730,417,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,703.42316
Policy Entropy: 1.93289
Value Function Loss: 0.08715

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.56759
Value Function Update Magnitude: 0.70967

Collected Steps per Second: 20,841.43513
Overall Steps per Second: 10,256.10657

Timestep Collection Time: 2.39993
Timestep Consumption Time: 2.47697
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.87690

Cumulative Model Updates: 87,572
Cumulative Timesteps: 730,467,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 730467158...
Checkpoint 730467158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,459.48361
Policy Entropy: 1.91183
Value Function Loss: 0.08137

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12968
Policy Update Magnitude: 0.56581
Value Function Update Magnitude: 0.71046

Collected Steps per Second: 19,626.52156
Overall Steps per Second: 9,897.56715

Timestep Collection Time: 2.54818
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.30060
Total Iteration Time: 5.05296

Cumulative Model Updates: 87,578
Cumulative Timesteps: 730,517,170

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,696.75859
Policy Entropy: 1.90081
Value Function Loss: 0.07907

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.55626
Value Function Update Magnitude: 0.66943

Collected Steps per Second: 20,950.64866
Overall Steps per Second: 10,370.48022

Timestep Collection Time: 2.38847
Timestep Consumption Time: 2.43676
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.82523

Cumulative Model Updates: 87,584
Cumulative Timesteps: 730,567,210

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 730567210...
Checkpoint 730567210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,988.80695
Policy Entropy: 1.89705
Value Function Loss: 0.08078

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.14146
Policy Update Magnitude: 0.54135
Value Function Update Magnitude: 0.62198

Collected Steps per Second: 20,067.04075
Overall Steps per Second: 10,207.72744

Timestep Collection Time: 2.49195
Timestep Consumption Time: 2.40689
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.89884

Cumulative Model Updates: 87,590
Cumulative Timesteps: 730,617,216

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,049.70409
Policy Entropy: 1.92042
Value Function Loss: 0.07626

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.51593
Value Function Update Magnitude: 0.61403

Collected Steps per Second: 20,893.86992
Overall Steps per Second: 10,131.02796

Timestep Collection Time: 2.39353
Timestep Consumption Time: 2.54280
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.93632

Cumulative Model Updates: 87,596
Cumulative Timesteps: 730,667,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 730667226...
Checkpoint 730667226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,941.62122
Policy Entropy: 1.92360
Value Function Loss: 0.07933

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12836
Policy Update Magnitude: 0.53185
Value Function Update Magnitude: 0.49820

Collected Steps per Second: 18,195.29368
Overall Steps per Second: 8,992.81190

Timestep Collection Time: 2.74950
Timestep Consumption Time: 2.81361
PPO Batch Consumption Time: 0.32492
Total Iteration Time: 5.56311

Cumulative Model Updates: 87,602
Cumulative Timesteps: 730,717,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,920.02086
Policy Entropy: 1.92778
Value Function Loss: 0.08489

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.54131
Value Function Update Magnitude: 0.41851

Collected Steps per Second: 20,459.58639
Overall Steps per Second: 10,070.84831

Timestep Collection Time: 2.44462
Timestep Consumption Time: 2.52179
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.96641

Cumulative Model Updates: 87,608
Cumulative Timesteps: 730,767,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 730767270...
Checkpoint 730767270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,328.61727
Policy Entropy: 1.91233
Value Function Loss: 0.09167

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.55346
Value Function Update Magnitude: 0.45936

Collected Steps per Second: 20,647.95533
Overall Steps per Second: 10,114.00464

Timestep Collection Time: 2.42174
Timestep Consumption Time: 2.52229
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.94404

Cumulative Model Updates: 87,614
Cumulative Timesteps: 730,817,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,408.21298
Policy Entropy: 1.93081
Value Function Loss: 0.08941

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.55390
Value Function Update Magnitude: 0.47066

Collected Steps per Second: 20,853.13725
Overall Steps per Second: 10,140.15968

Timestep Collection Time: 2.39820
Timestep Consumption Time: 2.53367
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.93187

Cumulative Model Updates: 87,620
Cumulative Timesteps: 730,867,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 730867284...
Checkpoint 730867284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,821.03638
Policy Entropy: 1.93101
Value Function Loss: 0.09007

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13824
Policy Update Magnitude: 0.55111
Value Function Update Magnitude: 0.48480

Collected Steps per Second: 20,705.32760
Overall Steps per Second: 9,973.75189

Timestep Collection Time: 2.41522
Timestep Consumption Time: 2.59874
PPO Batch Consumption Time: 0.30151
Total Iteration Time: 5.01396

Cumulative Model Updates: 87,626
Cumulative Timesteps: 730,917,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,337.34496
Policy Entropy: 1.94349
Value Function Loss: 0.08675

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.54386
Value Function Update Magnitude: 0.55513

Collected Steps per Second: 21,144.48096
Overall Steps per Second: 10,240.19002

Timestep Collection Time: 2.36582
Timestep Consumption Time: 2.51925
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.88507

Cumulative Model Updates: 87,632
Cumulative Timesteps: 730,967,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 730967316...
Checkpoint 730967316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,070.86690
Policy Entropy: 1.92194
Value Function Loss: 0.08603

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.55615
Value Function Update Magnitude: 0.59023

Collected Steps per Second: 20,709.45752
Overall Steps per Second: 9,884.18182

Timestep Collection Time: 2.41494
Timestep Consumption Time: 2.64487
PPO Batch Consumption Time: 0.30914
Total Iteration Time: 5.05980

Cumulative Model Updates: 87,638
Cumulative Timesteps: 731,017,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,603.63402
Policy Entropy: 1.92731
Value Function Loss: 0.08353

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.55155
Value Function Update Magnitude: 0.67163

Collected Steps per Second: 21,516.74980
Overall Steps per Second: 10,286.65577

Timestep Collection Time: 2.32517
Timestep Consumption Time: 2.53842
PPO Batch Consumption Time: 0.29750
Total Iteration Time: 4.86358

Cumulative Model Updates: 87,644
Cumulative Timesteps: 731,067,358

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 731067358...
Checkpoint 731067358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,077.14417
Policy Entropy: 1.92230
Value Function Loss: 0.08783

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.56431
Value Function Update Magnitude: 0.70056

Collected Steps per Second: 20,265.11787
Overall Steps per Second: 10,039.12626

Timestep Collection Time: 2.46868
Timestep Consumption Time: 2.51463
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.98330

Cumulative Model Updates: 87,650
Cumulative Timesteps: 731,117,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,579.97998
Policy Entropy: 1.95163
Value Function Loss: 0.08379

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.56518
Value Function Update Magnitude: 0.70114

Collected Steps per Second: 21,446.54179
Overall Steps per Second: 10,052.95090

Timestep Collection Time: 2.33138
Timestep Consumption Time: 2.64229
PPO Batch Consumption Time: 0.30560
Total Iteration Time: 4.97366

Cumulative Model Updates: 87,656
Cumulative Timesteps: 731,167,386

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 731167386...
Checkpoint 731167386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,992.90743
Policy Entropy: 1.93847
Value Function Loss: 0.08399

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.56751
Value Function Update Magnitude: 0.68822

Collected Steps per Second: 20,947.98531
Overall Steps per Second: 10,181.37355

Timestep Collection Time: 2.38830
Timestep Consumption Time: 2.52558
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.91388

Cumulative Model Updates: 87,662
Cumulative Timesteps: 731,217,416

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,397.71597
Policy Entropy: 1.92845
Value Function Loss: 0.07719

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.55421
Value Function Update Magnitude: 0.71159

Collected Steps per Second: 21,106.81622
Overall Steps per Second: 10,133.93477

Timestep Collection Time: 2.36909
Timestep Consumption Time: 2.56522
PPO Batch Consumption Time: 0.30177
Total Iteration Time: 4.93431

Cumulative Model Updates: 87,668
Cumulative Timesteps: 731,267,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 731267420...
Checkpoint 731267420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,079.33105
Policy Entropy: 1.91075
Value Function Loss: 0.08428

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.17052
Policy Update Magnitude: 0.50025
Value Function Update Magnitude: 0.64316

Collected Steps per Second: 20,205.65783
Overall Steps per Second: 10,014.99265

Timestep Collection Time: 2.47525
Timestep Consumption Time: 2.51867
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.99391

Cumulative Model Updates: 87,674
Cumulative Timesteps: 731,317,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,625.18687
Policy Entropy: 1.91994
Value Function Loss: 0.08319

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.17193
Policy Update Magnitude: 0.48831
Value Function Update Magnitude: 0.70234

Collected Steps per Second: 21,312.38361
Overall Steps per Second: 10,044.31827

Timestep Collection Time: 2.34746
Timestep Consumption Time: 2.63346
PPO Batch Consumption Time: 0.30617
Total Iteration Time: 4.98093

Cumulative Model Updates: 87,680
Cumulative Timesteps: 731,367,464

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 731367464...
Checkpoint 731367464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,852.78615
Policy Entropy: 1.93978
Value Function Loss: 0.08487

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.17508
Policy Update Magnitude: 0.49022
Value Function Update Magnitude: 0.76617

Collected Steps per Second: 20,886.80621
Overall Steps per Second: 9,988.74055

Timestep Collection Time: 2.39510
Timestep Consumption Time: 2.61314
PPO Batch Consumption Time: 0.30459
Total Iteration Time: 5.00824

Cumulative Model Updates: 87,686
Cumulative Timesteps: 731,417,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,137.76838
Policy Entropy: 1.94885
Value Function Loss: 0.08443

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.52771
Value Function Update Magnitude: 0.71361

Collected Steps per Second: 21,284.26980
Overall Steps per Second: 10,202.15061

Timestep Collection Time: 2.35028
Timestep Consumption Time: 2.55300
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.90328

Cumulative Model Updates: 87,692
Cumulative Timesteps: 731,467,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 731467514...
Checkpoint 731467514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,959.63867
Policy Entropy: 1.94146
Value Function Loss: 0.08336

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.14920
Policy Update Magnitude: 0.56497
Value Function Update Magnitude: 0.69935

Collected Steps per Second: 20,723.31152
Overall Steps per Second: 9,977.24303

Timestep Collection Time: 2.41371
Timestep Consumption Time: 2.59970
PPO Batch Consumption Time: 0.30282
Total Iteration Time: 5.01341

Cumulative Model Updates: 87,698
Cumulative Timesteps: 731,517,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,545.60298
Policy Entropy: 1.93601
Value Function Loss: 0.07802

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.56301
Value Function Update Magnitude: 0.68914

Collected Steps per Second: 21,145.56750
Overall Steps per Second: 10,043.92662

Timestep Collection Time: 2.36589
Timestep Consumption Time: 2.61503
PPO Batch Consumption Time: 0.30449
Total Iteration Time: 4.98092

Cumulative Model Updates: 87,704
Cumulative Timesteps: 731,567,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 731567562...
Checkpoint 731567562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,307.43742
Policy Entropy: 1.93470
Value Function Loss: 0.07905

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.55189
Value Function Update Magnitude: 0.62869

Collected Steps per Second: 20,271.00290
Overall Steps per Second: 9,891.10961

Timestep Collection Time: 2.46796
Timestep Consumption Time: 2.58992
PPO Batch Consumption Time: 0.30202
Total Iteration Time: 5.05788

Cumulative Model Updates: 87,710
Cumulative Timesteps: 731,617,590

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,322.52812
Policy Entropy: 1.93627
Value Function Loss: 0.07864

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.56279
Value Function Update Magnitude: 0.55060

Collected Steps per Second: 18,212.66532
Overall Steps per Second: 9,479.56947

Timestep Collection Time: 2.74556
Timestep Consumption Time: 2.52936
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 5.27492

Cumulative Model Updates: 87,716
Cumulative Timesteps: 731,667,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 731667594...
Checkpoint 731667594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,037.97244
Policy Entropy: 1.91986
Value Function Loss: 0.08258

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.56246
Value Function Update Magnitude: 0.45616

Collected Steps per Second: 21,158.07457
Overall Steps per Second: 10,412.98496

Timestep Collection Time: 2.36354
Timestep Consumption Time: 2.43892
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.80247

Cumulative Model Updates: 87,722
Cumulative Timesteps: 731,717,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,996.31853
Policy Entropy: 1.92327
Value Function Loss: 0.08426

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.14814
Policy Update Magnitude: 0.55389
Value Function Update Magnitude: 0.42028

Collected Steps per Second: 22,467.25916
Overall Steps per Second: 10,480.41105

Timestep Collection Time: 2.22644
Timestep Consumption Time: 2.54646
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.77290

Cumulative Model Updates: 87,728
Cumulative Timesteps: 731,767,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 731767624...
Checkpoint 731767624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,267.84588
Policy Entropy: 1.91698
Value Function Loss: 0.08746

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.52808
Value Function Update Magnitude: 0.54737

Collected Steps per Second: 21,932.17150
Overall Steps per Second: 10,596.62288

Timestep Collection Time: 2.27994
Timestep Consumption Time: 2.43892
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.71886

Cumulative Model Updates: 87,734
Cumulative Timesteps: 731,817,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,495.65837
Policy Entropy: 1.92669
Value Function Loss: 0.08736

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13828
Policy Update Magnitude: 0.53956
Value Function Update Magnitude: 0.62537

Collected Steps per Second: 22,254.37573
Overall Steps per Second: 10,435.05531

Timestep Collection Time: 2.24873
Timestep Consumption Time: 2.54703
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.79576

Cumulative Model Updates: 87,740
Cumulative Timesteps: 731,867,672

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 731867672...
Checkpoint 731867672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,058.46202
Policy Entropy: 1.92350
Value Function Loss: 0.08474

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.54166
Value Function Update Magnitude: 0.66098

Collected Steps per Second: 21,716.17149
Overall Steps per Second: 10,532.82850

Timestep Collection Time: 2.30326
Timestep Consumption Time: 2.44551
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.74877

Cumulative Model Updates: 87,746
Cumulative Timesteps: 731,917,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,896.65708
Policy Entropy: 1.93613
Value Function Loss: 0.07873

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.13758
Policy Update Magnitude: 0.55509
Value Function Update Magnitude: 0.71535

Collected Steps per Second: 22,366.00024
Overall Steps per Second: 10,540.33042

Timestep Collection Time: 2.23571
Timestep Consumption Time: 2.50835
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.74406

Cumulative Model Updates: 87,752
Cumulative Timesteps: 731,967,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 731967694...
Checkpoint 731967694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,975.45624
Policy Entropy: 1.94642
Value Function Loss: 0.07889

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.14886
Policy Update Magnitude: 0.55354
Value Function Update Magnitude: 0.76356

Collected Steps per Second: 22,050.00414
Overall Steps per Second: 10,560.26959

Timestep Collection Time: 2.26848
Timestep Consumption Time: 2.46814
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.73662

Cumulative Model Updates: 87,758
Cumulative Timesteps: 732,017,714

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,880.75995
Policy Entropy: 1.95247
Value Function Loss: 0.07962

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.56217
Value Function Update Magnitude: 0.78002

Collected Steps per Second: 22,260.12809
Overall Steps per Second: 10,569.66902

Timestep Collection Time: 2.24662
Timestep Consumption Time: 2.48485
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.73146

Cumulative Model Updates: 87,764
Cumulative Timesteps: 732,067,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 732067724...
Checkpoint 732067724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,045.76326
Policy Entropy: 1.93532
Value Function Loss: 0.08215

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13308
Policy Update Magnitude: 0.57171
Value Function Update Magnitude: 0.78331

Collected Steps per Second: 21,662.33362
Overall Steps per Second: 10,367.83903

Timestep Collection Time: 2.30954
Timestep Consumption Time: 2.51596
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.82550

Cumulative Model Updates: 87,770
Cumulative Timesteps: 732,117,754

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,883.12503
Policy Entropy: 1.93703
Value Function Loss: 0.08564

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.57729
Value Function Update Magnitude: 0.77748

Collected Steps per Second: 22,331.50923
Overall Steps per Second: 10,648.83769

Timestep Collection Time: 2.23953
Timestep Consumption Time: 2.45695
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.69647

Cumulative Model Updates: 87,776
Cumulative Timesteps: 732,167,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 732167766...
Checkpoint 732167766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,770.73263
Policy Entropy: 1.92823
Value Function Loss: 0.08314

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.56675
Value Function Update Magnitude: 0.77461

Collected Steps per Second: 22,262.90643
Overall Steps per Second: 10,640.63363

Timestep Collection Time: 2.24652
Timestep Consumption Time: 2.45377
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.70028

Cumulative Model Updates: 87,782
Cumulative Timesteps: 732,217,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,482.44420
Policy Entropy: 1.92968
Value Function Loss: 0.08421

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.13126
Policy Update Magnitude: 0.55255
Value Function Update Magnitude: 0.73524

Collected Steps per Second: 22,174.16214
Overall Steps per Second: 10,534.56182

Timestep Collection Time: 2.25542
Timestep Consumption Time: 2.49200
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.74742

Cumulative Model Updates: 87,788
Cumulative Timesteps: 732,267,792

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 732267792...
Checkpoint 732267792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,404.29962
Policy Entropy: 1.91409
Value Function Loss: 0.08068

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.55672
Value Function Update Magnitude: 0.68499

Collected Steps per Second: 21,627.09600
Overall Steps per Second: 10,361.47228

Timestep Collection Time: 2.31210
Timestep Consumption Time: 2.51386
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.82596

Cumulative Model Updates: 87,794
Cumulative Timesteps: 732,317,796

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,548.26980
Policy Entropy: 1.92240
Value Function Loss: 0.07952

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.56592
Value Function Update Magnitude: 0.74930

Collected Steps per Second: 21,891.12577
Overall Steps per Second: 10,500.98041

Timestep Collection Time: 2.28485
Timestep Consumption Time: 2.47832
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.76317

Cumulative Model Updates: 87,800
Cumulative Timesteps: 732,367,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 732367814...
Checkpoint 732367814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,978.05208
Policy Entropy: 1.93320
Value Function Loss: 0.07750

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.14035
Policy Update Magnitude: 0.55803
Value Function Update Magnitude: 0.80685

Collected Steps per Second: 22,141.81525
Overall Steps per Second: 10,464.65148

Timestep Collection Time: 2.25962
Timestep Consumption Time: 2.52143
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.78105

Cumulative Model Updates: 87,806
Cumulative Timesteps: 732,417,846

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,506.08062
Policy Entropy: 1.93483
Value Function Loss: 0.08231

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.56609
Value Function Update Magnitude: 0.75130

Collected Steps per Second: 22,311.68566
Overall Steps per Second: 10,470.96657

Timestep Collection Time: 2.24178
Timestep Consumption Time: 2.53504
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.77683

Cumulative Model Updates: 87,812
Cumulative Timesteps: 732,467,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 732467864...
Checkpoint 732467864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,476.21539
Policy Entropy: 1.92419
Value Function Loss: 0.08325

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.15258
Policy Update Magnitude: 0.55887
Value Function Update Magnitude: 0.70899

Collected Steps per Second: 22,043.68503
Overall Steps per Second: 10,600.44234

Timestep Collection Time: 2.26822
Timestep Consumption Time: 2.44856
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.71678

Cumulative Model Updates: 87,818
Cumulative Timesteps: 732,517,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,935.28602
Policy Entropy: 1.91394
Value Function Loss: 0.08330

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.15339
Policy Update Magnitude: 0.51970
Value Function Update Magnitude: 0.76824

Collected Steps per Second: 22,061.02884
Overall Steps per Second: 10,435.65577

Timestep Collection Time: 2.26726
Timestep Consumption Time: 2.52573
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.79299

Cumulative Model Updates: 87,824
Cumulative Timesteps: 732,567,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 732567882...
Checkpoint 732567882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,468.62747
Policy Entropy: 1.90438
Value Function Loss: 0.07855

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.54904
Value Function Update Magnitude: 0.73853

Collected Steps per Second: 21,958.00720
Overall Steps per Second: 10,574.83874

Timestep Collection Time: 2.27744
Timestep Consumption Time: 2.45152
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.72896

Cumulative Model Updates: 87,830
Cumulative Timesteps: 732,617,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,928.33915
Policy Entropy: 1.91038
Value Function Loss: 0.08474

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.15470
Policy Update Magnitude: 0.54807
Value Function Update Magnitude: 0.70029

Collected Steps per Second: 22,255.19519
Overall Steps per Second: 10,527.26740

Timestep Collection Time: 2.24783
Timestep Consumption Time: 2.50421
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.75204

Cumulative Model Updates: 87,836
Cumulative Timesteps: 732,667,916

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 732667916...
Checkpoint 732667916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,580.48700
Policy Entropy: 1.92213
Value Function Loss: 0.08673

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.15530
Policy Update Magnitude: 0.53379
Value Function Update Magnitude: 0.66057

Collected Steps per Second: 22,039.21640
Overall Steps per Second: 10,586.49495

Timestep Collection Time: 2.27041
Timestep Consumption Time: 2.45618
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.72659

Cumulative Model Updates: 87,842
Cumulative Timesteps: 732,717,954

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,533.11765
Policy Entropy: 1.93034
Value Function Loss: 0.09365

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.18066
Policy Update Magnitude: 0.49732
Value Function Update Magnitude: 0.64546

Collected Steps per Second: 22,393.89943
Overall Steps per Second: 10,470.56712

Timestep Collection Time: 2.23329
Timestep Consumption Time: 2.54315
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.77644

Cumulative Model Updates: 87,848
Cumulative Timesteps: 732,767,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 732767966...
Checkpoint 732767966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,037.41159
Policy Entropy: 1.93314
Value Function Loss: 0.09245

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.15031
Policy Update Magnitude: 0.51289
Value Function Update Magnitude: 0.63137

Collected Steps per Second: 20,276.35662
Overall Steps per Second: 9,931.44808

Timestep Collection Time: 2.46819
Timestep Consumption Time: 2.57095
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 5.03914

Cumulative Model Updates: 87,854
Cumulative Timesteps: 732,818,012

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,813.40668
Policy Entropy: 1.93685
Value Function Loss: 0.09232

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.54428
Value Function Update Magnitude: 0.55491

Collected Steps per Second: 22,376.80164
Overall Steps per Second: 10,501.71087

Timestep Collection Time: 2.23508
Timestep Consumption Time: 2.52738
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.76246

Cumulative Model Updates: 87,860
Cumulative Timesteps: 732,868,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 732868026...
Checkpoint 732868026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,333.23098
Policy Entropy: 1.93976
Value Function Loss: 0.08821

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.15491
Policy Update Magnitude: 0.54263
Value Function Update Magnitude: 0.70107

Collected Steps per Second: 22,215.05321
Overall Steps per Second: 10,524.90983

Timestep Collection Time: 2.25136
Timestep Consumption Time: 2.50061
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.75196

Cumulative Model Updates: 87,866
Cumulative Timesteps: 732,918,040

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,606.56576
Policy Entropy: 1.93996
Value Function Loss: 0.08695

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.54427
Value Function Update Magnitude: 0.80498

Collected Steps per Second: 22,389.39229
Overall Steps per Second: 10,556.31404

Timestep Collection Time: 2.23445
Timestep Consumption Time: 2.50470
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.73915

Cumulative Model Updates: 87,872
Cumulative Timesteps: 732,968,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 732968068...
Checkpoint 732968068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,936.98206
Policy Entropy: 1.94397
Value Function Loss: 0.07961

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.54607
Value Function Update Magnitude: 0.85414

Collected Steps per Second: 21,829.15064
Overall Steps per Second: 10,569.43904

Timestep Collection Time: 2.29079
Timestep Consumption Time: 2.44040
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.73119

Cumulative Model Updates: 87,878
Cumulative Timesteps: 733,018,074

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,196.10768
Policy Entropy: 1.93032
Value Function Loss: 0.07600

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12598
Policy Update Magnitude: 0.55071
Value Function Update Magnitude: 0.80979

Collected Steps per Second: 22,344.05392
Overall Steps per Second: 10,488.30661

Timestep Collection Time: 2.23773
Timestep Consumption Time: 2.52948
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.76721

Cumulative Model Updates: 87,884
Cumulative Timesteps: 733,068,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 733068074...
Checkpoint 733068074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,356.48484
Policy Entropy: 1.93356
Value Function Loss: 0.07922

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.55393
Value Function Update Magnitude: 0.73109

Collected Steps per Second: 22,076.23152
Overall Steps per Second: 10,574.65121

Timestep Collection Time: 2.26506
Timestep Consumption Time: 2.46361
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.72867

Cumulative Model Updates: 87,890
Cumulative Timesteps: 733,118,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,942.22173
Policy Entropy: 1.93346
Value Function Loss: 0.08171

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.15715
Policy Update Magnitude: 0.54409
Value Function Update Magnitude: 0.78230

Collected Steps per Second: 22,409.79259
Overall Steps per Second: 10,492.32143

Timestep Collection Time: 2.23144
Timestep Consumption Time: 2.53453
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.76596

Cumulative Model Updates: 87,896
Cumulative Timesteps: 733,168,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 733168084...
Checkpoint 733168084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,348.55886
Policy Entropy: 1.94735
Value Function Loss: 0.08791

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.15842
Policy Update Magnitude: 0.50469
Value Function Update Magnitude: 0.77815

Collected Steps per Second: 22,209.10534
Overall Steps per Second: 10,617.48891

Timestep Collection Time: 2.25223
Timestep Consumption Time: 2.45887
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.71110

Cumulative Model Updates: 87,902
Cumulative Timesteps: 733,218,104

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,707.03424
Policy Entropy: 1.95377
Value Function Loss: 0.08285

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.16088
Policy Update Magnitude: 0.49363
Value Function Update Magnitude: 0.87789

Collected Steps per Second: 22,461.99327
Overall Steps per Second: 10,521.47306

Timestep Collection Time: 2.22661
Timestep Consumption Time: 2.52691
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.75352

Cumulative Model Updates: 87,908
Cumulative Timesteps: 733,268,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 733268118...
Checkpoint 733268118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,692.52526
Policy Entropy: 1.94150
Value Function Loss: 0.08538

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.51145
Value Function Update Magnitude: 0.85955

Collected Steps per Second: 21,911.11524
Overall Steps per Second: 10,560.54120

Timestep Collection Time: 2.28332
Timestep Consumption Time: 2.45413
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.73745

Cumulative Model Updates: 87,914
Cumulative Timesteps: 733,318,148

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,859.35202
Policy Entropy: 1.93462
Value Function Loss: 0.08200

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.55935
Value Function Update Magnitude: 0.84412

Collected Steps per Second: 22,451.07718
Overall Steps per Second: 10,508.49967

Timestep Collection Time: 2.22724
Timestep Consumption Time: 2.53119
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.75843

Cumulative Model Updates: 87,920
Cumulative Timesteps: 733,368,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 733368152...
Checkpoint 733368152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,176.69241
Policy Entropy: 1.93400
Value Function Loss: 0.08275

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.14590
Policy Update Magnitude: 0.57464
Value Function Update Magnitude: 0.81281

Collected Steps per Second: 21,782.03726
Overall Steps per Second: 10,538.46719

Timestep Collection Time: 2.29694
Timestep Consumption Time: 2.45062
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.74756

Cumulative Model Updates: 87,926
Cumulative Timesteps: 733,418,184

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,277.59028
Policy Entropy: 1.92851
Value Function Loss: 0.08103

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.57112
Value Function Update Magnitude: 0.72222

Collected Steps per Second: 21,627.94614
Overall Steps per Second: 10,475.95914

Timestep Collection Time: 2.31275
Timestep Consumption Time: 2.46199
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.77474

Cumulative Model Updates: 87,932
Cumulative Timesteps: 733,468,204

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 733468204...
Checkpoint 733468204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,549.65707
Policy Entropy: 1.92374
Value Function Loss: 0.07763

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13822
Policy Update Magnitude: 0.56494
Value Function Update Magnitude: 0.81627

Collected Steps per Second: 21,755.50207
Overall Steps per Second: 10,390.83341

Timestep Collection Time: 2.29891
Timestep Consumption Time: 2.51437
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.81328

Cumulative Model Updates: 87,938
Cumulative Timesteps: 733,518,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,642.66137
Policy Entropy: 1.91769
Value Function Loss: 0.07935

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13599
Policy Update Magnitude: 0.55272
Value Function Update Magnitude: 0.85191

Collected Steps per Second: 22,262.60940
Overall Steps per Second: 10,629.63487

Timestep Collection Time: 2.24637
Timestep Consumption Time: 2.45840
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.70477

Cumulative Model Updates: 87,944
Cumulative Timesteps: 733,568,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 733568228...
Checkpoint 733568228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,523.65688
Policy Entropy: 1.91212
Value Function Loss: 0.08040

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.55352
Value Function Update Magnitude: 0.77573

Collected Steps per Second: 21,676.81230
Overall Steps per Second: 10,319.29609

Timestep Collection Time: 2.30717
Timestep Consumption Time: 2.53929
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.84645

Cumulative Model Updates: 87,950
Cumulative Timesteps: 733,618,240

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,359.43368
Policy Entropy: 1.89964
Value Function Loss: 0.08589

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.56651
Value Function Update Magnitude: 0.71739

Collected Steps per Second: 22,450.85089
Overall Steps per Second: 10,478.74870

Timestep Collection Time: 2.22753
Timestep Consumption Time: 2.54498
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.77252

Cumulative Model Updates: 87,956
Cumulative Timesteps: 733,668,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 733668250...
Checkpoint 733668250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,366.65508
Policy Entropy: 1.90348
Value Function Loss: 0.08559

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.14198
Policy Update Magnitude: 0.53881
Value Function Update Magnitude: 0.64878

Collected Steps per Second: 21,955.26425
Overall Steps per Second: 10,551.76815

Timestep Collection Time: 2.27818
Timestep Consumption Time: 2.46207
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.74025

Cumulative Model Updates: 87,962
Cumulative Timesteps: 733,718,268

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,263.22585
Policy Entropy: 1.90961
Value Function Loss: 0.08789

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.16624
Policy Update Magnitude: 0.48961
Value Function Update Magnitude: 0.51343

Collected Steps per Second: 22,325.46827
Overall Steps per Second: 10,498.77715

Timestep Collection Time: 2.24004
Timestep Consumption Time: 2.52337
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.76341

Cumulative Model Updates: 87,968
Cumulative Timesteps: 733,768,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 733768278...
Checkpoint 733768278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,267.74768
Policy Entropy: 1.91491
Value Function Loss: 0.09175

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.14461
Policy Update Magnitude: 0.53385
Value Function Update Magnitude: 0.46312

Collected Steps per Second: 21,942.42941
Overall Steps per Second: 10,457.85896

Timestep Collection Time: 2.27878
Timestep Consumption Time: 2.50250
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.78128

Cumulative Model Updates: 87,974
Cumulative Timesteps: 733,818,280

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,455.89999
Policy Entropy: 1.91677
Value Function Loss: 0.08872

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.57540
Value Function Update Magnitude: 0.45063

Collected Steps per Second: 22,435.65757
Overall Steps per Second: 10,665.15216

Timestep Collection Time: 2.23011
Timestep Consumption Time: 2.46124
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.69135

Cumulative Model Updates: 87,980
Cumulative Timesteps: 733,868,314

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 733868314...
Checkpoint 733868314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,182.32747
Policy Entropy: 1.90169
Value Function Loss: 0.08919

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.14029
Policy Update Magnitude: 0.57837
Value Function Update Magnitude: 0.48361

Collected Steps per Second: 21,502.89658
Overall Steps per Second: 10,282.03519

Timestep Collection Time: 2.32592
Timestep Consumption Time: 2.53829
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.86421

Cumulative Model Updates: 87,986
Cumulative Timesteps: 733,918,328

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,826.24526
Policy Entropy: 1.91411
Value Function Loss: 0.09258

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.58911
Value Function Update Magnitude: 0.46066

Collected Steps per Second: 22,218.98204
Overall Steps per Second: 10,455.41211

Timestep Collection Time: 2.25159
Timestep Consumption Time: 2.53330
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.78489

Cumulative Model Updates: 87,992
Cumulative Timesteps: 733,968,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 733968356...
Checkpoint 733968356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,705.96673
Policy Entropy: 1.90902
Value Function Loss: 0.09587

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.59440
Value Function Update Magnitude: 0.41872

Collected Steps per Second: 21,980.22474
Overall Steps per Second: 10,568.57505

Timestep Collection Time: 2.27486
Timestep Consumption Time: 2.45633
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.73120

Cumulative Model Updates: 87,998
Cumulative Timesteps: 734,018,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,008.78779
Policy Entropy: 1.90760
Value Function Loss: 0.09836

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.59333
Value Function Update Magnitude: 0.45785

Collected Steps per Second: 22,073.49597
Overall Steps per Second: 10,498.28582

Timestep Collection Time: 2.26525
Timestep Consumption Time: 2.49762
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.76287

Cumulative Model Updates: 88,004
Cumulative Timesteps: 734,068,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 734068360...
Checkpoint 734068360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,998.65525
Policy Entropy: 1.90749
Value Function Loss: 0.09838

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.15297
Policy Update Magnitude: 0.57509
Value Function Update Magnitude: 0.48685

Collected Steps per Second: 21,248.54900
Overall Steps per Second: 10,307.31332

Timestep Collection Time: 2.35329
Timestep Consumption Time: 2.49802
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.85131

Cumulative Model Updates: 88,010
Cumulative Timesteps: 734,118,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,280.06707
Policy Entropy: 1.91485
Value Function Loss: 0.10349

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.16468
Policy Update Magnitude: 0.51771
Value Function Update Magnitude: 0.48955

Collected Steps per Second: 22,534.83424
Overall Steps per Second: 10,688.67853

Timestep Collection Time: 2.22047
Timestep Consumption Time: 2.46093
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.68140

Cumulative Model Updates: 88,016
Cumulative Timesteps: 734,168,402

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 734168402...
Checkpoint 734168402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,707.87808
Policy Entropy: 1.92056
Value Function Loss: 0.09504

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.16084
Policy Update Magnitude: 0.47272
Value Function Update Magnitude: 0.57784

Collected Steps per Second: 21,266.14679
Overall Steps per Second: 10,237.54474

Timestep Collection Time: 2.35125
Timestep Consumption Time: 2.53293
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.88418

Cumulative Model Updates: 88,022
Cumulative Timesteps: 734,218,404

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,676.17852
Policy Entropy: 1.93338
Value Function Loss: 0.08769

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.14469
Policy Update Magnitude: 0.48136
Value Function Update Magnitude: 0.69569

Collected Steps per Second: 22,585.98411
Overall Steps per Second: 10,558.98160

Timestep Collection Time: 2.21482
Timestep Consumption Time: 2.52275
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.73758

Cumulative Model Updates: 88,028
Cumulative Timesteps: 734,268,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 734268428...
Checkpoint 734268428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,592.39127
Policy Entropy: 1.92562
Value Function Loss: 0.08263

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.15628
Policy Update Magnitude: 0.48139
Value Function Update Magnitude: 0.66957

Collected Steps per Second: 21,162.16777
Overall Steps per Second: 10,536.54704

Timestep Collection Time: 2.36375
Timestep Consumption Time: 2.38373
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.74748

Cumulative Model Updates: 88,034
Cumulative Timesteps: 734,318,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,196.29914
Policy Entropy: 1.93746
Value Function Loss: 0.08582

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.16396
Policy Update Magnitude: 0.50306
Value Function Update Magnitude: 0.48631

Collected Steps per Second: 21,505.65290
Overall Steps per Second: 10,455.68835

Timestep Collection Time: 2.32506
Timestep Consumption Time: 2.45721
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.78228

Cumulative Model Updates: 88,040
Cumulative Timesteps: 734,368,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 734368452...
Checkpoint 734368452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,162.74243
Policy Entropy: 1.92743
Value Function Loss: 0.08248

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.14659
Policy Update Magnitude: 0.52862
Value Function Update Magnitude: 0.44938

Collected Steps per Second: 21,199.63925
Overall Steps per Second: 10,348.89392

Timestep Collection Time: 2.35853
Timestep Consumption Time: 2.47290
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.83143

Cumulative Model Updates: 88,046
Cumulative Timesteps: 734,418,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,886.66150
Policy Entropy: 1.92763
Value Function Loss: 0.08630

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.14836
Policy Update Magnitude: 0.55691
Value Function Update Magnitude: 0.40581

Collected Steps per Second: 21,892.06325
Overall Steps per Second: 10,742.59526

Timestep Collection Time: 2.28530
Timestep Consumption Time: 2.37186
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.65716

Cumulative Model Updates: 88,052
Cumulative Timesteps: 734,468,482

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 734468482...
Checkpoint 734468482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,822.51643
Policy Entropy: 1.91660
Value Function Loss: 0.08588

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13759
Policy Update Magnitude: 0.56593
Value Function Update Magnitude: 0.48556

Collected Steps per Second: 21,299.15205
Overall Steps per Second: 10,315.25663

Timestep Collection Time: 2.34864
Timestep Consumption Time: 2.50088
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.84952

Cumulative Model Updates: 88,058
Cumulative Timesteps: 734,518,506

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,755.37200
Policy Entropy: 1.92033
Value Function Loss: 0.08794

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.57299
Value Function Update Magnitude: 0.57135

Collected Steps per Second: 22,073.44790
Overall Steps per Second: 10,510.39324

Timestep Collection Time: 2.26616
Timestep Consumption Time: 2.49313
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.75929

Cumulative Model Updates: 88,064
Cumulative Timesteps: 734,568,528

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 734568528...
Checkpoint 734568528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,044.67412
Policy Entropy: 1.92557
Value Function Loss: 0.08516

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.57761
Value Function Update Magnitude: 0.63069

Collected Steps per Second: 21,972.85984
Overall Steps per Second: 10,515.92324

Timestep Collection Time: 2.27608
Timestep Consumption Time: 2.47975
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.75584

Cumulative Model Updates: 88,070
Cumulative Timesteps: 734,618,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,634.00235
Policy Entropy: 1.93373
Value Function Loss: 0.08485

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.57310
Value Function Update Magnitude: 0.58810

Collected Steps per Second: 22,322.53161
Overall Steps per Second: 10,583.52390

Timestep Collection Time: 2.24016
Timestep Consumption Time: 2.48473
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.72489

Cumulative Model Updates: 88,076
Cumulative Timesteps: 734,668,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 734668546...
Checkpoint 734668546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,465.54730
Policy Entropy: 1.95182
Value Function Loss: 0.08861

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.57690
Value Function Update Magnitude: 0.62434

Collected Steps per Second: 21,770.29386
Overall Steps per Second: 10,541.51155

Timestep Collection Time: 2.29882
Timestep Consumption Time: 2.44870
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.74752

Cumulative Model Updates: 88,082
Cumulative Timesteps: 734,718,592

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,957.95994
Policy Entropy: 1.95058
Value Function Loss: 0.08597

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.58009
Value Function Update Magnitude: 0.62338

Collected Steps per Second: 21,936.49713
Overall Steps per Second: 10,449.91457

Timestep Collection Time: 2.28022
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.78664

Cumulative Model Updates: 88,088
Cumulative Timesteps: 734,768,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 734768612...
Checkpoint 734768612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,562.64870
Policy Entropy: 1.95486
Value Function Loss: 0.09071

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.15800
Policy Update Magnitude: 0.53445
Value Function Update Magnitude: 0.57363

Collected Steps per Second: 22,002.37537
Overall Steps per Second: 10,648.22569

Timestep Collection Time: 2.27366
Timestep Consumption Time: 2.42440
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.69806

Cumulative Model Updates: 88,094
Cumulative Timesteps: 734,818,638

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,988.56644
Policy Entropy: 1.97506
Value Function Loss: 0.09823

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.15956
Policy Update Magnitude: 0.47555
Value Function Update Magnitude: 0.48959

Collected Steps per Second: 22,221.93388
Overall Steps per Second: 10,511.34980

Timestep Collection Time: 2.25039
Timestep Consumption Time: 2.50713
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.75752

Cumulative Model Updates: 88,100
Cumulative Timesteps: 734,868,646

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 734868646...
Checkpoint 734868646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,942.96877
Policy Entropy: 1.97428
Value Function Loss: 0.09830

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.15332
Policy Update Magnitude: 0.47303
Value Function Update Magnitude: 0.43143

Collected Steps per Second: 22,284.24467
Overall Steps per Second: 10,554.81907

Timestep Collection Time: 2.24464
Timestep Consumption Time: 2.49443
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.73907

Cumulative Model Updates: 88,106
Cumulative Timesteps: 734,918,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,491.85812
Policy Entropy: 1.96021
Value Function Loss: 0.10579

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13832
Policy Update Magnitude: 0.50455
Value Function Update Magnitude: 0.35156

Collected Steps per Second: 22,193.10818
Overall Steps per Second: 10,503.13733

Timestep Collection Time: 2.25313
Timestep Consumption Time: 2.50773
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.76086

Cumulative Model Updates: 88,112
Cumulative Timesteps: 734,968,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 734968670...
Checkpoint 734968670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,418.63931
Policy Entropy: 1.93978
Value Function Loss: 0.09737

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.53647
Value Function Update Magnitude: 0.42562

Collected Steps per Second: 21,971.51856
Overall Steps per Second: 10,539.18101

Timestep Collection Time: 2.27640
Timestep Consumption Time: 2.46932
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.74572

Cumulative Model Updates: 88,118
Cumulative Timesteps: 735,018,686

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,675.99386
Policy Entropy: 1.94085
Value Function Loss: 0.10071

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.15647
Policy Update Magnitude: 0.53074
Value Function Update Magnitude: 0.37917

Collected Steps per Second: 21,836.03560
Overall Steps per Second: 10,470.80316

Timestep Collection Time: 2.29126
Timestep Consumption Time: 2.48698
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.77824

Cumulative Model Updates: 88,124
Cumulative Timesteps: 735,068,718

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 735068718...
Checkpoint 735068718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,487.41861
Policy Entropy: 1.95958
Value Function Loss: 0.09375

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.55021
Value Function Update Magnitude: 0.42871

Collected Steps per Second: 22,150.22825
Overall Steps per Second: 10,617.10597

Timestep Collection Time: 2.25831
Timestep Consumption Time: 2.45315
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.71145

Cumulative Model Updates: 88,130
Cumulative Timesteps: 735,118,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,044.12488
Policy Entropy: 1.95219
Value Function Loss: 0.09016

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.57737
Value Function Update Magnitude: 0.65829

Collected Steps per Second: 22,242.92818
Overall Steps per Second: 10,501.01676

Timestep Collection Time: 2.24916
Timestep Consumption Time: 2.51495
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.76411

Cumulative Model Updates: 88,136
Cumulative Timesteps: 735,168,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 735168768...
Checkpoint 735168768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,712.01794
Policy Entropy: 1.96323
Value Function Loss: 0.08557

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.58284
Value Function Update Magnitude: 0.63399

Collected Steps per Second: 21,897.02959
Overall Steps per Second: 10,579.68600

Timestep Collection Time: 2.28433
Timestep Consumption Time: 2.44360
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.72793

Cumulative Model Updates: 88,142
Cumulative Timesteps: 735,218,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,306.08875
Policy Entropy: 1.96300
Value Function Loss: 0.08632

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.56299
Value Function Update Magnitude: 0.56889

Collected Steps per Second: 21,933.41510
Overall Steps per Second: 10,555.22671

Timestep Collection Time: 2.27999
Timestep Consumption Time: 2.45776
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.73775

Cumulative Model Updates: 88,148
Cumulative Timesteps: 735,268,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 735268796...
Checkpoint 735268796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,391.92198
Policy Entropy: 1.97500
Value Function Loss: 0.08936

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.54406
Value Function Update Magnitude: 0.56237

Collected Steps per Second: 22,111.07535
Overall Steps per Second: 10,608.61813

Timestep Collection Time: 2.26167
Timestep Consumption Time: 2.45223
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.71390

Cumulative Model Updates: 88,154
Cumulative Timesteps: 735,318,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,738.43029
Policy Entropy: 1.97788
Value Function Loss: 0.09554

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.16142
Policy Update Magnitude: 0.51070
Value Function Update Magnitude: 0.53006

Collected Steps per Second: 22,112.57299
Overall Steps per Second: 10,410.86903

Timestep Collection Time: 2.26324
Timestep Consumption Time: 2.54385
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.80709

Cumulative Model Updates: 88,160
Cumulative Timesteps: 735,368,850

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 735368850...
Checkpoint 735368850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,829.65382
Policy Entropy: 1.97611
Value Function Loss: 0.09572

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.16692
Policy Update Magnitude: 0.51341
Value Function Update Magnitude: 0.45062

Collected Steps per Second: 21,497.85101
Overall Steps per Second: 10,317.67809

Timestep Collection Time: 2.32591
Timestep Consumption Time: 2.52034
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.84625

Cumulative Model Updates: 88,166
Cumulative Timesteps: 735,418,852

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,894.90946
Policy Entropy: 1.95823
Value Function Loss: 0.09150

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.16006
Policy Update Magnitude: 0.54745
Value Function Update Magnitude: 0.38980

Collected Steps per Second: 22,538.31791
Overall Steps per Second: 10,565.27070

Timestep Collection Time: 2.21969
Timestep Consumption Time: 2.51545
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.73514

Cumulative Model Updates: 88,172
Cumulative Timesteps: 735,468,880

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 735468880...
Checkpoint 735468880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,063.74489
Policy Entropy: 1.95005
Value Function Loss: 0.08909

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.16836
Policy Update Magnitude: 0.53269
Value Function Update Magnitude: 0.39600

Collected Steps per Second: 22,077.73767
Overall Steps per Second: 10,469.33945

Timestep Collection Time: 2.26554
Timestep Consumption Time: 2.51203
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.77757

Cumulative Model Updates: 88,178
Cumulative Timesteps: 735,518,898

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,613.20298
Policy Entropy: 1.94752
Value Function Loss: 0.08508

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.16882
Policy Update Magnitude: 0.50480
Value Function Update Magnitude: 0.62619

Collected Steps per Second: 22,335.75831
Overall Steps per Second: 10,448.41839

Timestep Collection Time: 2.23982
Timestep Consumption Time: 2.54828
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.78809

Cumulative Model Updates: 88,184
Cumulative Timesteps: 735,568,926

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 735568926...
Checkpoint 735568926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,516.18975
Policy Entropy: 1.96010
Value Function Loss: 0.08421

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.16158
Policy Update Magnitude: 0.47823
Value Function Update Magnitude: 0.74776

Collected Steps per Second: 21,913.51928
Overall Steps per Second: 10,577.51547

Timestep Collection Time: 2.28252
Timestep Consumption Time: 2.44619
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.72871

Cumulative Model Updates: 88,190
Cumulative Timesteps: 735,618,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,187.84834
Policy Entropy: 1.97549
Value Function Loss: 0.09229

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.16001
Policy Update Magnitude: 0.51477
Value Function Update Magnitude: 0.74092

Collected Steps per Second: 21,875.29125
Overall Steps per Second: 10,508.61128

Timestep Collection Time: 2.28651
Timestep Consumption Time: 2.47321
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.75972

Cumulative Model Updates: 88,196
Cumulative Timesteps: 735,668,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 735668962...
Checkpoint 735668962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,754.81632
Policy Entropy: 1.96488
Value Function Loss: 0.09405

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.14781
Policy Update Magnitude: 0.52360
Value Function Update Magnitude: 0.75570

Collected Steps per Second: 21,700.35709
Overall Steps per Second: 10,376.30765

Timestep Collection Time: 2.30475
Timestep Consumption Time: 2.51526
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.82002

Cumulative Model Updates: 88,202
Cumulative Timesteps: 735,718,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,210.05681
Policy Entropy: 1.94739
Value Function Loss: 0.09339

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.56227
Value Function Update Magnitude: 0.69116

Collected Steps per Second: 22,439.11905
Overall Steps per Second: 10,660.67272

Timestep Collection Time: 2.22923
Timestep Consumption Time: 2.46297
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.69220

Cumulative Model Updates: 88,208
Cumulative Timesteps: 735,768,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 735768998...
Checkpoint 735768998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,180.86796
Policy Entropy: 1.93526
Value Function Loss: 0.09728

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.57654
Value Function Update Magnitude: 0.61577

Collected Steps per Second: 21,551.28661
Overall Steps per Second: 10,377.36155

Timestep Collection Time: 2.32005
Timestep Consumption Time: 2.49813
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.81818

Cumulative Model Updates: 88,214
Cumulative Timesteps: 735,818,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,329.50947
Policy Entropy: 1.93840
Value Function Loss: 0.10214

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.59576
Value Function Update Magnitude: 0.63021

Collected Steps per Second: 22,281.12022
Overall Steps per Second: 10,508.23574

Timestep Collection Time: 2.24486
Timestep Consumption Time: 2.51503
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.75989

Cumulative Model Updates: 88,220
Cumulative Timesteps: 735,869,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 735869016...
Checkpoint 735869016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,828.50605
Policy Entropy: 1.95057
Value Function Loss: 0.10064

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.15151
Policy Update Magnitude: 0.59527
Value Function Update Magnitude: 0.65693

Collected Steps per Second: 22,146.54882
Overall Steps per Second: 10,490.32667

Timestep Collection Time: 2.25995
Timestep Consumption Time: 2.51112
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.77106

Cumulative Model Updates: 88,226
Cumulative Timesteps: 735,919,066

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,500.77535
Policy Entropy: 1.94689
Value Function Loss: 0.09740

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.16804
Policy Update Magnitude: 0.54118
Value Function Update Magnitude: 0.66503

Collected Steps per Second: 22,306.49875
Overall Steps per Second: 10,424.47298

Timestep Collection Time: 2.24159
Timestep Consumption Time: 2.55501
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.79660

Cumulative Model Updates: 88,232
Cumulative Timesteps: 735,969,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 735969068...
Checkpoint 735969068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,995.63215
Policy Entropy: 1.96908
Value Function Loss: 0.09944

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.16277
Policy Update Magnitude: 0.52591
Value Function Update Magnitude: 0.76884

Collected Steps per Second: 21,638.55541
Overall Steps per Second: 10,226.77446

Timestep Collection Time: 2.31171
Timestep Consumption Time: 2.57957
PPO Batch Consumption Time: 0.29851
Total Iteration Time: 4.89128

Cumulative Model Updates: 88,238
Cumulative Timesteps: 736,019,090

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,251.32196
Policy Entropy: 1.95694
Value Function Loss: 0.09791

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.16344
Policy Update Magnitude: 0.51667
Value Function Update Magnitude: 0.81911

Collected Steps per Second: 21,579.23037
Overall Steps per Second: 10,522.17547

Timestep Collection Time: 2.31797
Timestep Consumption Time: 2.43580
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.75377

Cumulative Model Updates: 88,244
Cumulative Timesteps: 736,069,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 736069110...
Checkpoint 736069110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,693.87943
Policy Entropy: 1.96464
Value Function Loss: 0.09944

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.17115
Policy Update Magnitude: 0.50965
Value Function Update Magnitude: 0.83209

Collected Steps per Second: 22,061.73783
Overall Steps per Second: 10,568.02176

Timestep Collection Time: 2.26646
Timestep Consumption Time: 2.46499
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.73144

Cumulative Model Updates: 88,250
Cumulative Timesteps: 736,119,112

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,785.91980
Policy Entropy: 1.92600
Value Function Loss: 0.09099

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.16359
Policy Update Magnitude: 0.52427
Value Function Update Magnitude: 0.79858

Collected Steps per Second: 22,374.09159
Overall Steps per Second: 10,460.19656

Timestep Collection Time: 2.23473
Timestep Consumption Time: 2.54530
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.78002

Cumulative Model Updates: 88,256
Cumulative Timesteps: 736,169,112

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 736169112...
Checkpoint 736169112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,261.09511
Policy Entropy: 1.95821
Value Function Loss: 0.09044

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.15337
Policy Update Magnitude: 0.52800
Value Function Update Magnitude: 0.77980

Collected Steps per Second: 21,776.27483
Overall Steps per Second: 10,584.91864

Timestep Collection Time: 2.29709
Timestep Consumption Time: 2.42869
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.72578

Cumulative Model Updates: 88,262
Cumulative Timesteps: 736,219,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,660.33936
Policy Entropy: 1.97043
Value Function Loss: 0.09002

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14466
Policy Update Magnitude: 0.53746
Value Function Update Magnitude: 0.78471

Collected Steps per Second: 22,213.89815
Overall Steps per Second: 10,526.07526

Timestep Collection Time: 2.25210
Timestep Consumption Time: 2.50066
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.75277

Cumulative Model Updates: 88,268
Cumulative Timesteps: 736,269,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 736269162...
Checkpoint 736269162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,647.12097
Policy Entropy: 1.98419
Value Function Loss: 0.09359

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.15620
Policy Update Magnitude: 0.55363
Value Function Update Magnitude: 0.75486

Collected Steps per Second: 21,848.81374
Overall Steps per Second: 10,572.38417

Timestep Collection Time: 2.28855
Timestep Consumption Time: 2.44095
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.72949

Cumulative Model Updates: 88,274
Cumulative Timesteps: 736,319,164

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,516.80025
Policy Entropy: 1.95869
Value Function Loss: 0.09906

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.15742
Policy Update Magnitude: 0.56681
Value Function Update Magnitude: 0.64996

Collected Steps per Second: 22,270.73730
Overall Steps per Second: 10,522.23351

Timestep Collection Time: 2.24627
Timestep Consumption Time: 2.50805
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.75431

Cumulative Model Updates: 88,280
Cumulative Timesteps: 736,369,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 736369190...
Checkpoint 736369190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,006.28414
Policy Entropy: 1.95548
Value Function Loss: 0.09565

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.17688
Policy Update Magnitude: 0.53688
Value Function Update Magnitude: 0.73142

Collected Steps per Second: 21,761.75081
Overall Steps per Second: 10,525.39262

Timestep Collection Time: 2.29862
Timestep Consumption Time: 2.45389
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.75251

Cumulative Model Updates: 88,286
Cumulative Timesteps: 736,419,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,914.11779
Policy Entropy: 1.95374
Value Function Loss: 0.09477

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.15103
Policy Update Magnitude: 0.51135
Value Function Update Magnitude: 0.69609

Collected Steps per Second: 22,171.66641
Overall Steps per Second: 10,631.77732

Timestep Collection Time: 2.25603
Timestep Consumption Time: 2.44873
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.70476

Cumulative Model Updates: 88,292
Cumulative Timesteps: 736,469,232

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 736469232...
Checkpoint 736469232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,725.09810
Policy Entropy: 1.95123
Value Function Loss: 0.09385

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.16899
Policy Update Magnitude: 0.52046
Value Function Update Magnitude: 0.66764

Collected Steps per Second: 21,888.92694
Overall Steps per Second: 10,543.36625

Timestep Collection Time: 2.28453
Timestep Consumption Time: 2.45835
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.74289

Cumulative Model Updates: 88,298
Cumulative Timesteps: 736,519,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,615.72328
Policy Entropy: 1.95550
Value Function Loss: 0.09374

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.15640
Policy Update Magnitude: 0.47029
Value Function Update Magnitude: 0.71041

Collected Steps per Second: 22,349.11010
Overall Steps per Second: 10,433.12773

Timestep Collection Time: 2.23758
Timestep Consumption Time: 2.55561
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.79319

Cumulative Model Updates: 88,304
Cumulative Timesteps: 736,569,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 736569246...
Checkpoint 736569246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,161.78724
Policy Entropy: 1.95496
Value Function Loss: 0.09415

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.51934
Value Function Update Magnitude: 0.69753

Collected Steps per Second: 21,224.07977
Overall Steps per Second: 10,200.90472

Timestep Collection Time: 2.35685
Timestep Consumption Time: 2.54683
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.90368

Cumulative Model Updates: 88,310
Cumulative Timesteps: 736,619,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,588.56293
Policy Entropy: 1.95641
Value Function Loss: 0.09377

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.57926
Value Function Update Magnitude: 0.70952

Collected Steps per Second: 22,183.01958
Overall Steps per Second: 10,356.40541

Timestep Collection Time: 2.25416
Timestep Consumption Time: 2.57416
PPO Batch Consumption Time: 0.29948
Total Iteration Time: 4.82832

Cumulative Model Updates: 88,316
Cumulative Timesteps: 736,669,272

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 736669272...
Checkpoint 736669272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,527.89541
Policy Entropy: 1.94277
Value Function Loss: 0.09398

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.59943
Value Function Update Magnitude: 0.65892

Collected Steps per Second: 21,723.88004
Overall Steps per Second: 10,338.72254

Timestep Collection Time: 2.30272
Timestep Consumption Time: 2.53579
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.83851

Cumulative Model Updates: 88,322
Cumulative Timesteps: 736,719,296

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,964.27533
Policy Entropy: 1.94094
Value Function Loss: 0.09357

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.58826
Value Function Update Magnitude: 0.65530

Collected Steps per Second: 22,178.63713
Overall Steps per Second: 10,495.28209

Timestep Collection Time: 2.25623
Timestep Consumption Time: 2.51163
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.76786

Cumulative Model Updates: 88,328
Cumulative Timesteps: 736,769,336

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 736769336...
Checkpoint 736769336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,483.04034
Policy Entropy: 1.93628
Value Function Loss: 0.09184

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.59248
Value Function Update Magnitude: 0.67171

Collected Steps per Second: 21,692.91035
Overall Steps per Second: 10,504.88160

Timestep Collection Time: 2.30499
Timestep Consumption Time: 2.45489
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.75988

Cumulative Model Updates: 88,334
Cumulative Timesteps: 736,819,338

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,252.27181
Policy Entropy: 1.94705
Value Function Loss: 0.09830

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.14120
Policy Update Magnitude: 0.58697
Value Function Update Magnitude: 0.64249

Collected Steps per Second: 22,213.06090
Overall Steps per Second: 10,528.59912

Timestep Collection Time: 2.25174
Timestep Consumption Time: 2.49894
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.75068

Cumulative Model Updates: 88,340
Cumulative Timesteps: 736,869,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 736869356...
Checkpoint 736869356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,162.50691
Policy Entropy: 1.95104
Value Function Loss: 0.09364

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.58138
Value Function Update Magnitude: 0.71295

Collected Steps per Second: 21,442.31770
Overall Steps per Second: 10,289.01234

Timestep Collection Time: 2.33352
Timestep Consumption Time: 2.52954
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.86305

Cumulative Model Updates: 88,346
Cumulative Timesteps: 736,919,392

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,918.70607
Policy Entropy: 1.95109
Value Function Loss: 0.09146

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.57811
Value Function Update Magnitude: 0.77657

Collected Steps per Second: 22,375.28195
Overall Steps per Second: 10,522.59465

Timestep Collection Time: 2.23640
Timestep Consumption Time: 2.51908
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.75548

Cumulative Model Updates: 88,352
Cumulative Timesteps: 736,969,432

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 736969432...
Checkpoint 736969432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,138.32905
Policy Entropy: 1.93022
Value Function Loss: 0.08982

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.58647
Value Function Update Magnitude: 0.68620

Collected Steps per Second: 21,914.72474
Overall Steps per Second: 10,553.90563

Timestep Collection Time: 2.28349
Timestep Consumption Time: 2.45807
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.74156

Cumulative Model Updates: 88,358
Cumulative Timesteps: 737,019,474

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,228.45221
Policy Entropy: 1.93028
Value Function Loss: 0.09424

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.15314
Policy Update Magnitude: 0.55980
Value Function Update Magnitude: 0.64363

Collected Steps per Second: 21,769.84079
Overall Steps per Second: 10,424.53025

Timestep Collection Time: 2.29777
Timestep Consumption Time: 2.50072
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.79849

Cumulative Model Updates: 88,364
Cumulative Timesteps: 737,069,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 737069496...
Checkpoint 737069496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,301.31785
Policy Entropy: 1.92916
Value Function Loss: 0.09186

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.57973
Value Function Update Magnitude: 0.69589

Collected Steps per Second: 22,034.41205
Overall Steps per Second: 10,595.39365

Timestep Collection Time: 2.27045
Timestep Consumption Time: 2.45123
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.72167

Cumulative Model Updates: 88,370
Cumulative Timesteps: 737,119,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,544.81472
Policy Entropy: 1.94812
Value Function Loss: 0.09048

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.15501
Policy Update Magnitude: 0.57415
Value Function Update Magnitude: 0.68845

Collected Steps per Second: 22,421.38594
Overall Steps per Second: 10,466.99478

Timestep Collection Time: 2.23046
Timestep Consumption Time: 2.54742
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.77788

Cumulative Model Updates: 88,376
Cumulative Timesteps: 737,169,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 737169534...
Checkpoint 737169534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,989.03165
Policy Entropy: 1.93798
Value Function Loss: 0.09250

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.15779
Policy Update Magnitude: 0.52341
Value Function Update Magnitude: 0.63844

Collected Steps per Second: 21,335.51036
Overall Steps per Second: 10,280.06143

Timestep Collection Time: 2.34595
Timestep Consumption Time: 2.52289
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.86884

Cumulative Model Updates: 88,382
Cumulative Timesteps: 737,219,586

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,064.45176
Policy Entropy: 1.95736
Value Function Loss: 0.09754

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.14877
Policy Update Magnitude: 0.49135
Value Function Update Magnitude: 0.59141

Collected Steps per Second: 22,136.87960
Overall Steps per Second: 10,415.69501

Timestep Collection Time: 2.25876
Timestep Consumption Time: 2.54188
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.80064

Cumulative Model Updates: 88,388
Cumulative Timesteps: 737,269,588

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 737269588...
Checkpoint 737269588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,170.21161
Policy Entropy: 1.94768
Value Function Loss: 0.09858

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.50697
Value Function Update Magnitude: 0.70325

Collected Steps per Second: 18,291.26452
Overall Steps per Second: 9,412.25484

Timestep Collection Time: 2.73409
Timestep Consumption Time: 2.57919
PPO Batch Consumption Time: 0.29796
Total Iteration Time: 5.31329

Cumulative Model Updates: 88,394
Cumulative Timesteps: 737,319,598

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,532.15044
Policy Entropy: 1.97808
Value Function Loss: 0.10302

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.15651
Policy Update Magnitude: 0.48307
Value Function Update Magnitude: 0.74615

Collected Steps per Second: 21,925.15179
Overall Steps per Second: 10,488.40506

Timestep Collection Time: 2.28085
Timestep Consumption Time: 2.48708
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.76793

Cumulative Model Updates: 88,400
Cumulative Timesteps: 737,369,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 737369606...
Checkpoint 737369606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,865.94634
Policy Entropy: 1.96960
Value Function Loss: 0.09495

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.17772
Policy Update Magnitude: 0.46968
Value Function Update Magnitude: 0.74665

Collected Steps per Second: 21,045.00401
Overall Steps per Second: 10,266.34056

Timestep Collection Time: 2.37615
Timestep Consumption Time: 2.49472
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.87087

Cumulative Model Updates: 88,406
Cumulative Timesteps: 737,419,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,943.15515
Policy Entropy: 1.96468
Value Function Loss: 0.09968

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.15777
Policy Update Magnitude: 0.53141
Value Function Update Magnitude: 0.74830

Collected Steps per Second: 22,322.03113
Overall Steps per Second: 10,507.99943

Timestep Collection Time: 2.24119
Timestep Consumption Time: 2.51975
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.76094

Cumulative Model Updates: 88,412
Cumulative Timesteps: 737,469,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 737469640...
Checkpoint 737469640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,733.05145
Policy Entropy: 1.93563
Value Function Loss: 0.09155

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.57623
Value Function Update Magnitude: 0.76999

Collected Steps per Second: 22,267.11283
Overall Steps per Second: 10,518.80274

Timestep Collection Time: 2.24600
Timestep Consumption Time: 2.50853
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.75453

Cumulative Model Updates: 88,418
Cumulative Timesteps: 737,519,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,168.54268
Policy Entropy: 1.93422
Value Function Loss: 0.09964

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.16629
Policy Update Magnitude: 0.51346
Value Function Update Magnitude: 0.77622

Collected Steps per Second: 22,648.49611
Overall Steps per Second: 10,574.12262

Timestep Collection Time: 2.20765
Timestep Consumption Time: 2.52087
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.72852

Cumulative Model Updates: 88,424
Cumulative Timesteps: 737,569,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 737569652...
Checkpoint 737569652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,212.06810
Policy Entropy: 1.93463
Value Function Loss: 0.10150

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.15728
Policy Update Magnitude: 0.49089
Value Function Update Magnitude: 0.75025

Collected Steps per Second: 21,793.44719
Overall Steps per Second: 10,536.47702

Timestep Collection Time: 2.29555
Timestep Consumption Time: 2.45252
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.74808

Cumulative Model Updates: 88,430
Cumulative Timesteps: 737,619,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,179.99649
Policy Entropy: 1.92575
Value Function Loss: 0.10484

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.16203
Policy Update Magnitude: 0.50532
Value Function Update Magnitude: 0.71089

Collected Steps per Second: 22,108.44631
Overall Steps per Second: 10,429.50476

Timestep Collection Time: 2.26230
Timestep Consumption Time: 2.53332
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.79563

Cumulative Model Updates: 88,436
Cumulative Timesteps: 737,669,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 737669696...
Checkpoint 737669696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,658.80891
Policy Entropy: 1.93609
Value Function Loss: 0.09693

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.15327
Policy Update Magnitude: 0.50199
Value Function Update Magnitude: 0.74206

Collected Steps per Second: 21,485.44497
Overall Steps per Second: 10,292.35508

Timestep Collection Time: 2.32939
Timestep Consumption Time: 2.53325
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.86264

Cumulative Model Updates: 88,442
Cumulative Timesteps: 737,719,744

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,476.39031
Policy Entropy: 1.95576
Value Function Loss: 0.09973

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.15473
Policy Update Magnitude: 0.51607
Value Function Update Magnitude: 0.77857

Collected Steps per Second: 22,234.30938
Overall Steps per Second: 10,415.06050

Timestep Collection Time: 2.24959
Timestep Consumption Time: 2.55288
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.80247

Cumulative Model Updates: 88,448
Cumulative Timesteps: 737,769,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 737769762...
Checkpoint 737769762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,253.12218
Policy Entropy: 1.95540
Value Function Loss: 0.09531

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.15287
Policy Update Magnitude: 0.50840
Value Function Update Magnitude: 0.76306

Collected Steps per Second: 21,807.53262
Overall Steps per Second: 10,520.40056

Timestep Collection Time: 2.29480
Timestep Consumption Time: 2.46205
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.75685

Cumulative Model Updates: 88,454
Cumulative Timesteps: 737,819,806

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,492.66230
Policy Entropy: 1.97891
Value Function Loss: 0.10548

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13983
Policy Update Magnitude: 0.55524
Value Function Update Magnitude: 0.78426

Collected Steps per Second: 22,155.72406
Overall Steps per Second: 10,623.67668

Timestep Collection Time: 2.25901
Timestep Consumption Time: 2.45217
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.71117

Cumulative Model Updates: 88,460
Cumulative Timesteps: 737,869,856

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 737869856...
Checkpoint 737869856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,663.64102
Policy Entropy: 1.95956
Value Function Loss: 0.09948

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.15012
Policy Update Magnitude: 0.57586
Value Function Update Magnitude: 0.78775

Collected Steps per Second: 22,036.38563
Overall Steps per Second: 10,527.14025

Timestep Collection Time: 2.27015
Timestep Consumption Time: 2.48194
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.75210

Cumulative Model Updates: 88,466
Cumulative Timesteps: 737,919,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,769.29094
Policy Entropy: 1.95622
Value Function Loss: 0.09694

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14940
Policy Update Magnitude: 0.57733
Value Function Update Magnitude: 0.78125

Collected Steps per Second: 22,518.64581
Overall Steps per Second: 10,430.57740

Timestep Collection Time: 2.22163
Timestep Consumption Time: 2.57466
PPO Batch Consumption Time: 0.29748
Total Iteration Time: 4.79628

Cumulative Model Updates: 88,472
Cumulative Timesteps: 737,969,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 737969910...
Checkpoint 737969910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,795.03187
Policy Entropy: 1.93662
Value Function Loss: 0.08997

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.15124
Policy Update Magnitude: 0.58367
Value Function Update Magnitude: 0.75945

Collected Steps per Second: 21,007.47259
Overall Steps per Second: 10,283.11159

Timestep Collection Time: 2.38125
Timestep Consumption Time: 2.48343
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.86468

Cumulative Model Updates: 88,478
Cumulative Timesteps: 738,019,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,293.78494
Policy Entropy: 1.95564
Value Function Loss: 0.09589

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.15346
Policy Update Magnitude: 0.58074
Value Function Update Magnitude: 0.65157

Collected Steps per Second: 22,255.44933
Overall Steps per Second: 10,539.80591

Timestep Collection Time: 2.24763
Timestep Consumption Time: 2.49838
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.74601

Cumulative Model Updates: 88,484
Cumulative Timesteps: 738,069,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 738069956...
Checkpoint 738069956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,486.98163
Policy Entropy: 1.97336
Value Function Loss: 0.10614

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.15451
Policy Update Magnitude: 0.57940
Value Function Update Magnitude: 0.53933

Collected Steps per Second: 22,121.23107
Overall Steps per Second: 10,572.25595

Timestep Collection Time: 2.26163
Timestep Consumption Time: 2.47057
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.73220

Cumulative Model Updates: 88,490
Cumulative Timesteps: 738,119,986

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,546.19277
Policy Entropy: 1.95748
Value Function Loss: 0.10900

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.59613
Value Function Update Magnitude: 0.51918

Collected Steps per Second: 22,579.74616
Overall Steps per Second: 10,505.51583

Timestep Collection Time: 2.21499
Timestep Consumption Time: 2.54574
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.76074

Cumulative Model Updates: 88,496
Cumulative Timesteps: 738,170,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 738170000...
Checkpoint 738170000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,655.59674
Policy Entropy: 1.96280
Value Function Loss: 0.11202

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.61190
Value Function Update Magnitude: 0.60767

Collected Steps per Second: 21,900.35130
Overall Steps per Second: 10,540.70063

Timestep Collection Time: 2.28307
Timestep Consumption Time: 2.46045
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.74352

Cumulative Model Updates: 88,502
Cumulative Timesteps: 738,220,000

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,357.75815
Policy Entropy: 1.95746
Value Function Loss: 0.10621

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.60485
Value Function Update Magnitude: 0.72979

Collected Steps per Second: 22,386.06865
Overall Steps per Second: 10,482.11768

Timestep Collection Time: 2.23425
Timestep Consumption Time: 2.53731
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.77155

Cumulative Model Updates: 88,508
Cumulative Timesteps: 738,270,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 738270016...
Checkpoint 738270016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,086.63921
Policy Entropy: 1.96944
Value Function Loss: 0.10335

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14600
Policy Update Magnitude: 0.58050
Value Function Update Magnitude: 0.75947

Collected Steps per Second: 21,849.70228
Overall Steps per Second: 10,605.78865

Timestep Collection Time: 2.28836
Timestep Consumption Time: 2.42605
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.71441

Cumulative Model Updates: 88,514
Cumulative Timesteps: 738,320,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,858.32366
Policy Entropy: 1.96717
Value Function Loss: 0.09572

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14526
Policy Update Magnitude: 0.54891
Value Function Update Magnitude: 0.64346

Collected Steps per Second: 20,856.51917
Overall Steps per Second: 10,072.33919

Timestep Collection Time: 2.39963
Timestep Consumption Time: 2.56922
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.96886

Cumulative Model Updates: 88,520
Cumulative Timesteps: 738,370,064

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 738370064...
Checkpoint 738370064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,628.72244
Policy Entropy: 1.96667
Value Function Loss: 0.09500

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.50781
Value Function Update Magnitude: 0.61267

Collected Steps per Second: 20,050.63250
Overall Steps per Second: 9,855.87012

Timestep Collection Time: 2.49448
Timestep Consumption Time: 2.58026
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 5.07474

Cumulative Model Updates: 88,526
Cumulative Timesteps: 738,420,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,029.92967
Policy Entropy: 1.96434
Value Function Loss: 0.09540

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.53764
Value Function Update Magnitude: 0.68443

Collected Steps per Second: 22,245.81078
Overall Steps per Second: 10,444.57429

Timestep Collection Time: 2.24779
Timestep Consumption Time: 2.53976
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.78756

Cumulative Model Updates: 88,532
Cumulative Timesteps: 738,470,084

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 738470084...
Checkpoint 738470084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,905.74744
Policy Entropy: 1.95606
Value Function Loss: 0.09745

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.53383
Value Function Update Magnitude: 0.77129

Collected Steps per Second: 22,003.86614
Overall Steps per Second: 10,565.97313

Timestep Collection Time: 2.27296
Timestep Consumption Time: 2.46053
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.73350

Cumulative Model Updates: 88,538
Cumulative Timesteps: 738,520,098

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,718.70085
Policy Entropy: 1.95740
Value Function Loss: 0.10253

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.51726
Value Function Update Magnitude: 0.80791

Collected Steps per Second: 22,411.92005
Overall Steps per Second: 10,556.94757

Timestep Collection Time: 2.23221
Timestep Consumption Time: 2.50666
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.73887

Cumulative Model Updates: 88,544
Cumulative Timesteps: 738,570,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 738570126...
Checkpoint 738570126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,112.66017
Policy Entropy: 1.94667
Value Function Loss: 0.10397

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.49586
Value Function Update Magnitude: 0.74594

Collected Steps per Second: 21,865.42847
Overall Steps per Second: 10,447.78327

Timestep Collection Time: 2.28745
Timestep Consumption Time: 2.49979
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.78724

Cumulative Model Updates: 88,550
Cumulative Timesteps: 738,620,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,926.81498
Policy Entropy: 1.94726
Value Function Loss: 0.10335

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.15634
Policy Update Magnitude: 0.52733
Value Function Update Magnitude: 0.75273

Collected Steps per Second: 21,790.70841
Overall Steps per Second: 10,560.54321

Timestep Collection Time: 2.29593
Timestep Consumption Time: 2.44151
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.73745

Cumulative Model Updates: 88,556
Cumulative Timesteps: 738,670,172

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 738670172...
Checkpoint 738670172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,842.66150
Policy Entropy: 1.96082
Value Function Loss: 0.11072

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.16269
Policy Update Magnitude: 0.56852
Value Function Update Magnitude: 0.72829

Collected Steps per Second: 22,164.76065
Overall Steps per Second: 10,643.16361

Timestep Collection Time: 2.25646
Timestep Consumption Time: 2.44270
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.69917

Cumulative Model Updates: 88,562
Cumulative Timesteps: 738,720,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,246.51277
Policy Entropy: 1.98331
Value Function Loss: 0.11528

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.15666
Policy Update Magnitude: 0.58590
Value Function Update Magnitude: 0.73705

Collected Steps per Second: 22,115.80098
Overall Steps per Second: 10,470.47737

Timestep Collection Time: 2.26110
Timestep Consumption Time: 2.51481
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.77590

Cumulative Model Updates: 88,568
Cumulative Timesteps: 738,770,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 738770192...
Checkpoint 738770192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,964.57388
Policy Entropy: 2.00533
Value Function Loss: 0.11393

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.15380
Policy Update Magnitude: 0.58895
Value Function Update Magnitude: 0.82202

Collected Steps per Second: 21,891.77617
Overall Steps per Second: 10,609.78270

Timestep Collection Time: 2.28460
Timestep Consumption Time: 2.42935
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.71395

Cumulative Model Updates: 88,574
Cumulative Timesteps: 738,820,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,823.06398
Policy Entropy: 1.99694
Value Function Loss: 0.10316

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.14651
Policy Update Magnitude: 0.57789
Value Function Update Magnitude: 0.80962

Collected Steps per Second: 22,485.91540
Overall Steps per Second: 10,582.05558

Timestep Collection Time: 2.22468
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.72725

Cumulative Model Updates: 88,580
Cumulative Timesteps: 738,870,230

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 738870230...
Checkpoint 738870230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,389.10988
Policy Entropy: 1.97962
Value Function Loss: 0.09732

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.57148
Value Function Update Magnitude: 0.75674

Collected Steps per Second: 22,171.27972
Overall Steps per Second: 10,567.16310

Timestep Collection Time: 2.25544
Timestep Consumption Time: 2.47677
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.73221

Cumulative Model Updates: 88,586
Cumulative Timesteps: 738,920,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,162.29863
Policy Entropy: 1.98423
Value Function Loss: 0.09478

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.56842
Value Function Update Magnitude: 0.70696

Collected Steps per Second: 22,517.90432
Overall Steps per Second: 10,484.22351

Timestep Collection Time: 2.22046
Timestep Consumption Time: 2.54862
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.76907

Cumulative Model Updates: 88,592
Cumulative Timesteps: 738,970,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 738970236...
Checkpoint 738970236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,884.23301
Policy Entropy: 1.98071
Value Function Loss: 0.09786

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.56486
Value Function Update Magnitude: 0.70706

Collected Steps per Second: 21,790.10523
Overall Steps per Second: 10,511.52090

Timestep Collection Time: 2.29572
Timestep Consumption Time: 2.46325
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.75897

Cumulative Model Updates: 88,598
Cumulative Timesteps: 739,020,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,884.72622
Policy Entropy: 1.98595
Value Function Loss: 0.09705

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.57574
Value Function Update Magnitude: 0.73986

Collected Steps per Second: 22,399.24425
Overall Steps per Second: 10,554.57621

Timestep Collection Time: 2.23356
Timestep Consumption Time: 2.50657
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.74012

Cumulative Model Updates: 88,604
Cumulative Timesteps: 739,070,290

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 739070290...
Checkpoint 739070290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,663.21966
Policy Entropy: 1.98931
Value Function Loss: 0.10316

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.57307
Value Function Update Magnitude: 0.72126

Collected Steps per Second: 21,862.97165
Overall Steps per Second: 10,565.30662

Timestep Collection Time: 2.28834
Timestep Consumption Time: 2.44697
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.73531

Cumulative Model Updates: 88,610
Cumulative Timesteps: 739,120,320

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,496.71685
Policy Entropy: 2.01653
Value Function Loss: 0.11472

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.58842
Value Function Update Magnitude: 0.61260

Collected Steps per Second: 22,120.89694
Overall Steps per Second: 10,496.98789

Timestep Collection Time: 2.26121
Timestep Consumption Time: 2.50397
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.76518

Cumulative Model Updates: 88,616
Cumulative Timesteps: 739,170,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 739170340...
Checkpoint 739170340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,512.76867
Policy Entropy: 2.03930
Value Function Loss: 0.11769

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.13508
Policy Update Magnitude: 0.58708
Value Function Update Magnitude: 0.56437

Collected Steps per Second: 21,555.64767
Overall Steps per Second: 10,284.14871

Timestep Collection Time: 2.31967
Timestep Consumption Time: 2.54238
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.86205

Cumulative Model Updates: 88,622
Cumulative Timesteps: 739,220,342

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,853.60263
Policy Entropy: 2.00867
Value Function Loss: 0.11211

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.58745
Value Function Update Magnitude: 0.65197

Collected Steps per Second: 22,345.38768
Overall Steps per Second: 10,332.13155

Timestep Collection Time: 2.23912
Timestep Consumption Time: 2.60344
PPO Batch Consumption Time: 0.30248
Total Iteration Time: 4.84256

Cumulative Model Updates: 88,628
Cumulative Timesteps: 739,270,376

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 739270376...
Checkpoint 739270376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,311.03053
Policy Entropy: 1.99295
Value Function Loss: 0.09903

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.57372
Value Function Update Magnitude: 0.72816

Collected Steps per Second: 21,752.08150
Overall Steps per Second: 10,471.90901

Timestep Collection Time: 2.29946
Timestep Consumption Time: 2.47694
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.77640

Cumulative Model Updates: 88,634
Cumulative Timesteps: 739,320,394

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,377.24541
Policy Entropy: 1.98220
Value Function Loss: 0.09160

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.56951
Value Function Update Magnitude: 0.74769

Collected Steps per Second: 22,735.40308
Overall Steps per Second: 10,674.56123

Timestep Collection Time: 2.19939
Timestep Consumption Time: 2.48502
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.68441

Cumulative Model Updates: 88,640
Cumulative Timesteps: 739,370,398

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 739370398...
Checkpoint 739370398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,850.40443
Policy Entropy: 1.97735
Value Function Loss: 0.09414

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.58037
Value Function Update Magnitude: 0.66415

Collected Steps per Second: 21,682.12539
Overall Steps per Second: 10,358.03980

Timestep Collection Time: 2.30651
Timestep Consumption Time: 2.52163
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.82813

Cumulative Model Updates: 88,646
Cumulative Timesteps: 739,420,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,947.81278
Policy Entropy: 1.93869
Value Function Loss: 0.09851

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.13227
Policy Update Magnitude: 0.58134
Value Function Update Magnitude: 0.58379

Collected Steps per Second: 21,275.64732
Overall Steps per Second: 10,285.40455

Timestep Collection Time: 2.35104
Timestep Consumption Time: 2.51216
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.86320

Cumulative Model Updates: 88,652
Cumulative Timesteps: 739,470,428

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 739470428...
Checkpoint 739470428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,773.79483
Policy Entropy: 1.93154
Value Function Loss: 0.09657

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.57829
Value Function Update Magnitude: 0.65977

Collected Steps per Second: 21,716.83014
Overall Steps per Second: 10,580.40882

Timestep Collection Time: 2.30393
Timestep Consumption Time: 2.42500
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.72893

Cumulative Model Updates: 88,658
Cumulative Timesteps: 739,520,462

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,240.06871
Policy Entropy: 1.96000
Value Function Loss: 0.10109

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.58546
Value Function Update Magnitude: 0.67748

Collected Steps per Second: 22,136.29401
Overall Steps per Second: 10,486.83494

Timestep Collection Time: 2.25928
Timestep Consumption Time: 2.50975
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.76903

Cumulative Model Updates: 88,664
Cumulative Timesteps: 739,570,474

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 739570474...
Checkpoint 739570474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,245.43559
Policy Entropy: 1.97343
Value Function Loss: 0.09581

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.57706
Value Function Update Magnitude: 0.67827

Collected Steps per Second: 22,134.76074
Overall Steps per Second: 10,597.49558

Timestep Collection Time: 2.25943
Timestep Consumption Time: 2.45980
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.71923

Cumulative Model Updates: 88,670
Cumulative Timesteps: 739,620,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,862.33966
Policy Entropy: 1.98333
Value Function Loss: 0.08990

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.56078
Value Function Update Magnitude: 0.68302

Collected Steps per Second: 21,939.69585
Overall Steps per Second: 10,552.70310

Timestep Collection Time: 2.27934
Timestep Consumption Time: 2.45954
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.73888

Cumulative Model Updates: 88,676
Cumulative Timesteps: 739,670,494

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 739670494...
Checkpoint 739670494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,494.43965
Policy Entropy: 1.97146
Value Function Loss: 0.08810

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.56210
Value Function Update Magnitude: 0.62780

Collected Steps per Second: 21,775.29325
Overall Steps per Second: 10,588.87705

Timestep Collection Time: 2.29710
Timestep Consumption Time: 2.42673
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.72382

Cumulative Model Updates: 88,682
Cumulative Timesteps: 739,720,514

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,322.05654
Policy Entropy: 1.97503
Value Function Loss: 0.09553

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.57670
Value Function Update Magnitude: 0.67860

Collected Steps per Second: 21,957.19155
Overall Steps per Second: 10,491.73499

Timestep Collection Time: 2.27953
Timestep Consumption Time: 2.49109
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.77061

Cumulative Model Updates: 88,688
Cumulative Timesteps: 739,770,566

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 739770566...
Checkpoint 739770566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,773.40907
Policy Entropy: 1.97166
Value Function Loss: 0.09715

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.59207
Value Function Update Magnitude: 0.67573

Collected Steps per Second: 22,264.62127
Overall Steps per Second: 10,627.79057

Timestep Collection Time: 2.24581
Timestep Consumption Time: 2.45903
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.70483

Cumulative Model Updates: 88,694
Cumulative Timesteps: 739,820,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,084.51387
Policy Entropy: 1.98136
Value Function Loss: 0.10781

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.59761
Value Function Update Magnitude: 0.59088

Collected Steps per Second: 21,817.93621
Overall Steps per Second: 10,543.71775

Timestep Collection Time: 2.29188
Timestep Consumption Time: 2.45066
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.74254

Cumulative Model Updates: 88,700
Cumulative Timesteps: 739,870,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 739870572...
Checkpoint 739870572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,589.78346
Policy Entropy: 1.97460
Value Function Loss: 0.10489

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.58177
Value Function Update Magnitude: 0.58848

Collected Steps per Second: 21,749.01149
Overall Steps per Second: 10,358.65674

Timestep Collection Time: 2.29997
Timestep Consumption Time: 2.52904
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.82900

Cumulative Model Updates: 88,706
Cumulative Timesteps: 739,920,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,132.39831
Policy Entropy: 1.97525
Value Function Loss: 0.10519

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.15610
Policy Update Magnitude: 0.52181
Value Function Update Magnitude: 0.57246

Collected Steps per Second: 22,543.60269
Overall Steps per Second: 10,712.70361

Timestep Collection Time: 2.21890
Timestep Consumption Time: 2.45051
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.66941

Cumulative Model Updates: 88,712
Cumulative Timesteps: 739,970,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 739970616...
Checkpoint 739970616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,478.18125
Policy Entropy: 1.94845
Value Function Loss: 0.09670

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.16263
Policy Update Magnitude: 0.48227
Value Function Update Magnitude: 0.56294

Collected Steps per Second: 21,895.12475
Overall Steps per Second: 10,555.51566

Timestep Collection Time: 2.28507
Timestep Consumption Time: 2.45482
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.73989

Cumulative Model Updates: 88,718
Cumulative Timesteps: 740,020,648

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,691.72718
Policy Entropy: 1.93240
Value Function Loss: 0.09390

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.16087
Policy Update Magnitude: 0.49119
Value Function Update Magnitude: 0.58663

Collected Steps per Second: 22,232.35217
Overall Steps per Second: 10,493.08258

Timestep Collection Time: 2.24987
Timestep Consumption Time: 2.51708
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.76695

Cumulative Model Updates: 88,724
Cumulative Timesteps: 740,070,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 740070668...
Checkpoint 740070668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,359.19783
Policy Entropy: 1.93116
Value Function Loss: 0.09359

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.15990
Policy Update Magnitude: 0.50519
Value Function Update Magnitude: 0.70565

Collected Steps per Second: 21,573.29219
Overall Steps per Second: 10,265.00798

Timestep Collection Time: 2.31814
Timestep Consumption Time: 2.55375
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.87189

Cumulative Model Updates: 88,730
Cumulative Timesteps: 740,120,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,775.72459
Policy Entropy: 1.93980
Value Function Loss: 0.08613

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13916
Policy Update Magnitude: 0.53956
Value Function Update Magnitude: 0.64225

Collected Steps per Second: 21,983.87275
Overall Steps per Second: 10,392.42709

Timestep Collection Time: 2.27640
Timestep Consumption Time: 2.53903
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.81543

Cumulative Model Updates: 88,736
Cumulative Timesteps: 740,170,722

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 740170722...
Checkpoint 740170722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,491.82173
Policy Entropy: 1.93725
Value Function Loss: 0.08858

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.56720
Value Function Update Magnitude: 0.54987

Collected Steps per Second: 21,247.36102
Overall Steps per Second: 10,247.40416

Timestep Collection Time: 2.35446
Timestep Consumption Time: 2.52736
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.88182

Cumulative Model Updates: 88,742
Cumulative Timesteps: 740,220,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,724.18533
Policy Entropy: 1.93097
Value Function Loss: 0.08968

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.54667
Value Function Update Magnitude: 0.59618

Collected Steps per Second: 22,124.63373
Overall Steps per Second: 10,425.37085

Timestep Collection Time: 2.26047
Timestep Consumption Time: 2.53668
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.79714

Cumulative Model Updates: 88,748
Cumulative Timesteps: 740,270,760

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 740270760...
Checkpoint 740270760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,668.08454
Policy Entropy: 1.93217
Value Function Loss: 0.09714

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.15623
Policy Update Magnitude: 0.50533
Value Function Update Magnitude: 0.61632

Collected Steps per Second: 21,624.81240
Overall Steps per Second: 10,307.04986

Timestep Collection Time: 2.31410
Timestep Consumption Time: 2.54102
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.85512

Cumulative Model Updates: 88,754
Cumulative Timesteps: 740,320,802

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,741.21069
Policy Entropy: 1.93720
Value Function Loss: 0.09759

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.15740
Policy Update Magnitude: 0.50793
Value Function Update Magnitude: 0.71381

Collected Steps per Second: 22,340.00245
Overall Steps per Second: 10,479.57543

Timestep Collection Time: 2.23841
Timestep Consumption Time: 2.53335
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.77176

Cumulative Model Updates: 88,760
Cumulative Timesteps: 740,370,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 740370808...
Checkpoint 740370808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,692.82541
Policy Entropy: 1.92995
Value Function Loss: 0.09203

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.15719
Policy Update Magnitude: 0.52189
Value Function Update Magnitude: 0.75195

Collected Steps per Second: 22,152.26790
Overall Steps per Second: 10,528.50116

Timestep Collection Time: 2.25792
Timestep Consumption Time: 2.49281
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.75072

Cumulative Model Updates: 88,766
Cumulative Timesteps: 740,420,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,531.83367
Policy Entropy: 1.92148
Value Function Loss: 0.09120

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.54157
Value Function Update Magnitude: 0.73211

Collected Steps per Second: 22,096.87433
Overall Steps per Second: 10,435.91079

Timestep Collection Time: 2.26303
Timestep Consumption Time: 2.52869
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.79172

Cumulative Model Updates: 88,772
Cumulative Timesteps: 740,470,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 740470832...
Checkpoint 740470832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,281.76887
Policy Entropy: 1.92216
Value Function Loss: 0.08977

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.57568
Value Function Update Magnitude: 0.73065

Collected Steps per Second: 21,606.70754
Overall Steps per Second: 10,380.98954

Timestep Collection Time: 2.31437
Timestep Consumption Time: 2.50270
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.81707

Cumulative Model Updates: 88,778
Cumulative Timesteps: 740,520,838

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,553.20485
Policy Entropy: 1.94366
Value Function Loss: 0.09157

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.56176
Value Function Update Magnitude: 0.67974

Collected Steps per Second: 22,460.62510
Overall Steps per Second: 10,482.22005

Timestep Collection Time: 2.22728
Timestep Consumption Time: 2.54519
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.77246

Cumulative Model Updates: 88,784
Cumulative Timesteps: 740,570,864

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 740570864...
Checkpoint 740570864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,399.49754
Policy Entropy: 1.95818
Value Function Loss: 0.09271

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.15540
Policy Update Magnitude: 0.49888
Value Function Update Magnitude: 0.71115

Collected Steps per Second: 21,665.63998
Overall Steps per Second: 10,464.40216

Timestep Collection Time: 2.30808
Timestep Consumption Time: 2.47060
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.77868

Cumulative Model Updates: 88,790
Cumulative Timesteps: 740,620,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,177.42568
Policy Entropy: 1.95182
Value Function Loss: 0.09810

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.14844
Policy Update Magnitude: 0.50203
Value Function Update Magnitude: 0.74559

Collected Steps per Second: 22,128.69615
Overall Steps per Second: 10,435.01476

Timestep Collection Time: 2.26014
Timestep Consumption Time: 2.53276
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.79290

Cumulative Model Updates: 88,796
Cumulative Timesteps: 740,670,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 740670884...
Checkpoint 740670884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,646.00212
Policy Entropy: 1.93096
Value Function Loss: 0.10189

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.55199
Value Function Update Magnitude: 0.72273

Collected Steps per Second: 21,722.67664
Overall Steps per Second: 10,531.61908

Timestep Collection Time: 2.30183
Timestep Consumption Time: 2.44596
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.74780

Cumulative Model Updates: 88,802
Cumulative Timesteps: 740,720,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,820.44302
Policy Entropy: 1.92056
Value Function Loss: 0.09729

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.14090
Policy Update Magnitude: 0.57683
Value Function Update Magnitude: 0.75734

Collected Steps per Second: 22,289.18355
Overall Steps per Second: 10,519.54010

Timestep Collection Time: 2.24405
Timestep Consumption Time: 2.51072
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.75477

Cumulative Model Updates: 88,808
Cumulative Timesteps: 740,770,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 740770904...
Checkpoint 740770904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,370.21793
Policy Entropy: 1.90956
Value Function Loss: 0.09262

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.58357
Value Function Update Magnitude: 0.78067

Collected Steps per Second: 21,796.64436
Overall Steps per Second: 10,380.47449

Timestep Collection Time: 2.29604
Timestep Consumption Time: 2.52513
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.82117

Cumulative Model Updates: 88,814
Cumulative Timesteps: 740,820,950

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,690.05176
Policy Entropy: 1.92416
Value Function Loss: 0.09266

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.57880
Value Function Update Magnitude: 0.77055

Collected Steps per Second: 22,549.21946
Overall Steps per Second: 10,717.29607

Timestep Collection Time: 2.21826
Timestep Consumption Time: 2.44896
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.66722

Cumulative Model Updates: 88,820
Cumulative Timesteps: 740,870,970

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 740870970...
Checkpoint 740870970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,624.35916
Policy Entropy: 1.89885
Value Function Loss: 0.09300

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.55977
Value Function Update Magnitude: 0.74750

Collected Steps per Second: 21,057.55476
Overall Steps per Second: 10,389.48590

Timestep Collection Time: 2.37587
Timestep Consumption Time: 2.43958
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.81545

Cumulative Model Updates: 88,826
Cumulative Timesteps: 740,921,000

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,820.79355
Policy Entropy: 1.91885
Value Function Loss: 0.09504

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.16040
Policy Update Magnitude: 0.50276
Value Function Update Magnitude: 0.69388

Collected Steps per Second: 21,661.58351
Overall Steps per Second: 10,671.29139

Timestep Collection Time: 2.30906
Timestep Consumption Time: 2.37809
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.68716

Cumulative Model Updates: 88,832
Cumulative Timesteps: 740,971,018

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 740971018...
Checkpoint 740971018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,999.36570
Policy Entropy: 1.88768
Value Function Loss: 0.08754

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.14473
Policy Update Magnitude: 0.52080
Value Function Update Magnitude: 0.69944

Collected Steps per Second: 21,280.47870
Overall Steps per Second: 10,442.77085

Timestep Collection Time: 2.35070
Timestep Consumption Time: 2.43960
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.79030

Cumulative Model Updates: 88,838
Cumulative Timesteps: 741,021,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,205.71651
Policy Entropy: 1.90606
Value Function Loss: 0.09105

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.56786
Value Function Update Magnitude: 0.65375

Collected Steps per Second: 21,363.90469
Overall Steps per Second: 10,468.98074

Timestep Collection Time: 2.34077
Timestep Consumption Time: 2.43601
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.77678

Cumulative Model Updates: 88,844
Cumulative Timesteps: 741,071,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 741071050...
Checkpoint 741071050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,516.74459
Policy Entropy: 1.91013
Value Function Loss: 0.09505

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.14617
Policy Update Magnitude: 0.58932
Value Function Update Magnitude: 0.63008

Collected Steps per Second: 21,131.61809
Overall Steps per Second: 10,498.34852

Timestep Collection Time: 2.36688
Timestep Consumption Time: 2.39730
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.76418

Cumulative Model Updates: 88,850
Cumulative Timesteps: 741,121,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,360.90411
Policy Entropy: 1.93072
Value Function Loss: 0.09826

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14689
Policy Update Magnitude: 0.58610
Value Function Update Magnitude: 0.63887

Collected Steps per Second: 21,625.57889
Overall Steps per Second: 10,497.91817

Timestep Collection Time: 2.31282
Timestep Consumption Time: 2.45156
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.76437

Cumulative Model Updates: 88,856
Cumulative Timesteps: 741,171,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 741171082...
Checkpoint 741171082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,247.09657
Policy Entropy: 1.93719
Value Function Loss: 0.09320

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.15404
Policy Update Magnitude: 0.53734
Value Function Update Magnitude: 0.63922

Collected Steps per Second: 21,438.33132
Overall Steps per Second: 10,364.55632

Timestep Collection Time: 2.33302
Timestep Consumption Time: 2.49266
PPO Batch Consumption Time: 0.29918
Total Iteration Time: 4.82568

Cumulative Model Updates: 88,862
Cumulative Timesteps: 741,221,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,867.21691
Policy Entropy: 1.92789
Value Function Loss: 0.09849

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.15877
Policy Update Magnitude: 0.49047
Value Function Update Magnitude: 0.52989

Collected Steps per Second: 21,724.39443
Overall Steps per Second: 10,567.33635

Timestep Collection Time: 2.30285
Timestep Consumption Time: 2.43136
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.73421

Cumulative Model Updates: 88,868
Cumulative Timesteps: 741,271,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 741271126...
Checkpoint 741271126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,787.21201
Policy Entropy: 1.94339
Value Function Loss: 0.10282

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.54427
Value Function Update Magnitude: 0.50483

Collected Steps per Second: 21,025.79690
Overall Steps per Second: 10,371.19759

Timestep Collection Time: 2.37870
Timestep Consumption Time: 2.44370
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.82239

Cumulative Model Updates: 88,874
Cumulative Timesteps: 741,321,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,481.18197
Policy Entropy: 1.94243
Value Function Loss: 0.09537

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.58357
Value Function Update Magnitude: 0.53751

Collected Steps per Second: 21,849.09082
Overall Steps per Second: 10,608.30283

Timestep Collection Time: 2.28907
Timestep Consumption Time: 2.42554
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.71461

Cumulative Model Updates: 88,880
Cumulative Timesteps: 741,371,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 741371154...
Checkpoint 741371154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,264.65512
Policy Entropy: 1.92960
Value Function Loss: 0.09217

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.57491
Value Function Update Magnitude: 0.52269

Collected Steps per Second: 21,379.10762
Overall Steps per Second: 10,425.98868

Timestep Collection Time: 2.33920
Timestep Consumption Time: 2.45747
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.79667

Cumulative Model Updates: 88,886
Cumulative Timesteps: 741,421,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,938.14821
Policy Entropy: 1.92700
Value Function Loss: 0.09294

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.56736
Value Function Update Magnitude: 0.54704

Collected Steps per Second: 21,578.85567
Overall Steps per Second: 10,456.10596

Timestep Collection Time: 2.31718
Timestep Consumption Time: 2.46491
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.78209

Cumulative Model Updates: 88,892
Cumulative Timesteps: 741,471,166

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 741471166...
Checkpoint 741471166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,063.11417
Policy Entropy: 1.91864
Value Function Loss: 0.09150

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.57137
Value Function Update Magnitude: 0.62865

Collected Steps per Second: 21,625.05116
Overall Steps per Second: 10,532.16763

Timestep Collection Time: 2.31250
Timestep Consumption Time: 2.43562
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.74812

Cumulative Model Updates: 88,898
Cumulative Timesteps: 741,521,174

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,524.72331
Policy Entropy: 1.91539
Value Function Loss: 0.09394

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.15715
Policy Update Magnitude: 0.56308
Value Function Update Magnitude: 0.72862

Collected Steps per Second: 22,101.21742
Overall Steps per Second: 10,521.43844

Timestep Collection Time: 2.26250
Timestep Consumption Time: 2.49008
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.75258

Cumulative Model Updates: 88,904
Cumulative Timesteps: 741,571,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 741571178...
Checkpoint 741571178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,042.01279
Policy Entropy: 1.90594
Value Function Loss: 0.08733

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.51096
Value Function Update Magnitude: 0.66628

Collected Steps per Second: 22,080.65804
Overall Steps per Second: 10,642.01069

Timestep Collection Time: 2.26587
Timestep Consumption Time: 2.43549
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.70137

Cumulative Model Updates: 88,910
Cumulative Timesteps: 741,621,210

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,647.17393
Policy Entropy: 1.89965
Value Function Loss: 0.09695

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.15068
Policy Update Magnitude: 0.52305
Value Function Update Magnitude: 0.61582

Collected Steps per Second: 22,175.33263
Overall Steps per Second: 10,499.93724

Timestep Collection Time: 2.25485
Timestep Consumption Time: 2.50728
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.76212

Cumulative Model Updates: 88,916
Cumulative Timesteps: 741,671,212

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 741671212...
Checkpoint 741671212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,290.82776
Policy Entropy: 1.91686
Value Function Loss: 0.09427

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.15869
Policy Update Magnitude: 0.53237
Value Function Update Magnitude: 0.58264

Collected Steps per Second: 21,658.35849
Overall Steps per Second: 10,564.53065

Timestep Collection Time: 2.30913
Timestep Consumption Time: 2.42482
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.73395

Cumulative Model Updates: 88,922
Cumulative Timesteps: 741,721,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,551.61489
Policy Entropy: 1.92680
Value Function Loss: 0.09266

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.15688
Policy Update Magnitude: 0.50432
Value Function Update Magnitude: 0.52843

Collected Steps per Second: 22,365.06418
Overall Steps per Second: 10,497.68496

Timestep Collection Time: 2.23661
Timestep Consumption Time: 2.52844
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.76505

Cumulative Model Updates: 88,928
Cumulative Timesteps: 741,771,246

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 741771246...
Checkpoint 741771246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,362.45669
Policy Entropy: 1.92203
Value Function Loss: 0.09056

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14450
Policy Update Magnitude: 0.54836
Value Function Update Magnitude: 0.55996

Collected Steps per Second: 21,762.71936
Overall Steps per Second: 10,328.23828

Timestep Collection Time: 2.29861
Timestep Consumption Time: 2.54481
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.84342

Cumulative Model Updates: 88,934
Cumulative Timesteps: 741,821,270

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,174.78667
Policy Entropy: 1.90268
Value Function Loss: 0.09659

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.57859
Value Function Update Magnitude: 0.53336

Collected Steps per Second: 22,025.76337
Overall Steps per Second: 10,353.42602

Timestep Collection Time: 2.27070
Timestep Consumption Time: 2.55997
PPO Batch Consumption Time: 0.30272
Total Iteration Time: 4.83067

Cumulative Model Updates: 88,940
Cumulative Timesteps: 741,871,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 741871284...
Checkpoint 741871284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,960.71744
Policy Entropy: 1.90336
Value Function Loss: 0.10029

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.59337
Value Function Update Magnitude: 0.47711

Collected Steps per Second: 21,798.18180
Overall Steps per Second: 10,450.79914

Timestep Collection Time: 2.29487
Timestep Consumption Time: 2.49175
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.78662

Cumulative Model Updates: 88,946
Cumulative Timesteps: 741,921,308

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,135.92342
Policy Entropy: 1.89317
Value Function Loss: 0.10295

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.60573
Value Function Update Magnitude: 0.47456

Collected Steps per Second: 22,498.22374
Overall Steps per Second: 10,620.15990

Timestep Collection Time: 2.22391
Timestep Consumption Time: 2.48732
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.71123

Cumulative Model Updates: 88,952
Cumulative Timesteps: 741,971,342

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 741971342...
Checkpoint 741971342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,260.56729
Policy Entropy: 1.89346
Value Function Loss: 0.09624

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.14030
Policy Update Magnitude: 0.58939
Value Function Update Magnitude: 0.47099

Collected Steps per Second: 21,958.36051
Overall Steps per Second: 10,582.33076

Timestep Collection Time: 2.27767
Timestep Consumption Time: 2.44851
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.72618

Cumulative Model Updates: 88,958
Cumulative Timesteps: 742,021,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,916.79411
Policy Entropy: 1.88204
Value Function Loss: 0.09743

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.15633
Policy Update Magnitude: 0.54766
Value Function Update Magnitude: 0.50581

Collected Steps per Second: 22,424.72243
Overall Steps per Second: 10,550.50625

Timestep Collection Time: 2.23040
Timestep Consumption Time: 2.51023
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.74063

Cumulative Model Updates: 88,964
Cumulative Timesteps: 742,071,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 742071372...
Checkpoint 742071372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,949.97687
Policy Entropy: 1.90161
Value Function Loss: 0.09998

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.57619
Value Function Update Magnitude: 0.55199

Collected Steps per Second: 21,639.34823
Overall Steps per Second: 10,366.87099

Timestep Collection Time: 2.31199
Timestep Consumption Time: 2.51396
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.82595

Cumulative Model Updates: 88,970
Cumulative Timesteps: 742,121,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,344.58698
Policy Entropy: 1.89618
Value Function Loss: 0.09566

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.15649
Policy Update Magnitude: 0.56547
Value Function Update Magnitude: 0.59580

Collected Steps per Second: 22,187.25717
Overall Steps per Second: 10,651.22519

Timestep Collection Time: 2.25400
Timestep Consumption Time: 2.44124
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.69523

Cumulative Model Updates: 88,976
Cumulative Timesteps: 742,171,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 742171412...
Checkpoint 742171412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,088.83055
Policy Entropy: 1.88466
Value Function Loss: 0.09292

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.15726
Policy Update Magnitude: 0.49521
Value Function Update Magnitude: 0.53731

Collected Steps per Second: 22,045.33426
Overall Steps per Second: 10,619.39321

Timestep Collection Time: 2.26923
Timestep Consumption Time: 2.44158
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.71082

Cumulative Model Updates: 88,982
Cumulative Timesteps: 742,221,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,849.03124
Policy Entropy: 1.87055
Value Function Loss: 0.08586

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.15500
Policy Update Magnitude: 0.48557
Value Function Update Magnitude: 0.44434

Collected Steps per Second: 21,851.52914
Overall Steps per Second: 10,531.33730

Timestep Collection Time: 2.28890
Timestep Consumption Time: 2.46035
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.74925

Cumulative Model Updates: 88,988
Cumulative Timesteps: 742,271,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 742271454...
Checkpoint 742271454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,757.23567
Policy Entropy: 1.87747
Value Function Loss: 0.08916

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14418
Policy Update Magnitude: 0.48275
Value Function Update Magnitude: 0.44805

Collected Steps per Second: 21,912.32179
Overall Steps per Second: 10,589.93965

Timestep Collection Time: 2.28210
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.72203

Cumulative Model Updates: 88,994
Cumulative Timesteps: 742,321,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,548.36861
Policy Entropy: 1.88706
Value Function Loss: 0.08967

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.15172
Policy Update Magnitude: 0.49440
Value Function Update Magnitude: 0.63946

Collected Steps per Second: 22,285.05635
Overall Steps per Second: 10,507.30501

Timestep Collection Time: 2.24563
Timestep Consumption Time: 2.51715
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.76278

Cumulative Model Updates: 89,000
Cumulative Timesteps: 742,371,504

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 742371504...
Checkpoint 742371504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,424.95025
Policy Entropy: 1.88335
Value Function Loss: 0.08972

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.16105
Policy Update Magnitude: 0.51607
Value Function Update Magnitude: 0.69269

Collected Steps per Second: 21,701.11261
Overall Steps per Second: 10,396.39747

Timestep Collection Time: 2.30458
Timestep Consumption Time: 2.50593
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.81051

Cumulative Model Updates: 89,006
Cumulative Timesteps: 742,421,516

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,790.47083
Policy Entropy: 1.87262
Value Function Loss: 0.08958

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.16825
Policy Update Magnitude: 0.49012
Value Function Update Magnitude: 0.71901

Collected Steps per Second: 22,395.67547
Overall Steps per Second: 10,661.25532

Timestep Collection Time: 2.23329
Timestep Consumption Time: 2.45809
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.69138

Cumulative Model Updates: 89,012
Cumulative Timesteps: 742,471,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 742471532...
Checkpoint 742471532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,628.75485
Policy Entropy: 1.89152
Value Function Loss: 0.09207

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.14833
Policy Update Magnitude: 0.51575
Value Function Update Magnitude: 0.77160

Collected Steps per Second: 22,072.76590
Overall Steps per Second: 10,547.50487

Timestep Collection Time: 2.26605
Timestep Consumption Time: 2.47611
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.74216

Cumulative Model Updates: 89,018
Cumulative Timesteps: 742,521,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,935.80036
Policy Entropy: 1.89722
Value Function Loss: 0.09203

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.15286
Policy Update Magnitude: 0.54030
Value Function Update Magnitude: 0.74936

Collected Steps per Second: 22,190.09097
Overall Steps per Second: 10,418.89479

Timestep Collection Time: 2.25326
Timestep Consumption Time: 2.54572
PPO Batch Consumption Time: 0.29961
Total Iteration Time: 4.79897

Cumulative Model Updates: 89,024
Cumulative Timesteps: 742,571,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 742571550...
Checkpoint 742571550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,546.15817
Policy Entropy: 1.89513
Value Function Loss: 0.09608

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.15047
Policy Update Magnitude: 0.55755
Value Function Update Magnitude: 0.76433

Collected Steps per Second: 21,904.19544
Overall Steps per Second: 10,386.99650

Timestep Collection Time: 2.28367
Timestep Consumption Time: 2.53216
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.81583

Cumulative Model Updates: 89,030
Cumulative Timesteps: 742,621,572

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,739.99636
Policy Entropy: 1.88742
Value Function Loss: 0.09264

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.14477
Policy Update Magnitude: 0.57784
Value Function Update Magnitude: 0.77187

Collected Steps per Second: 22,408.30001
Overall Steps per Second: 10,508.48107

Timestep Collection Time: 2.23221
Timestep Consumption Time: 2.52776
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.75996

Cumulative Model Updates: 89,036
Cumulative Timesteps: 742,671,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 742671592...
Checkpoint 742671592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,995.60946
Policy Entropy: 1.87894
Value Function Loss: 0.10010

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.58957
Value Function Update Magnitude: 0.76499

Collected Steps per Second: 22,002.34058
Overall Steps per Second: 10,589.13290

Timestep Collection Time: 2.27294
Timestep Consumption Time: 2.44983
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.72277

Cumulative Model Updates: 89,042
Cumulative Timesteps: 742,721,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,697.25652
Policy Entropy: 1.87829
Value Function Loss: 0.09480

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.14270
Policy Update Magnitude: 0.59589
Value Function Update Magnitude: 0.71017

Collected Steps per Second: 22,203.13821
Overall Steps per Second: 10,433.58460

Timestep Collection Time: 2.25320
Timestep Consumption Time: 2.54171
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.79490

Cumulative Model Updates: 89,048
Cumulative Timesteps: 742,771,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 742771630...
Checkpoint 742771630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,221.30297
Policy Entropy: 1.87514
Value Function Loss: 0.09045

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.57279
Value Function Update Magnitude: 0.80301

Collected Steps per Second: 21,613.63644
Overall Steps per Second: 10,327.97866

Timestep Collection Time: 2.31456
Timestep Consumption Time: 2.52918
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.84374

Cumulative Model Updates: 89,054
Cumulative Timesteps: 742,821,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,723.53631
Policy Entropy: 1.87863
Value Function Loss: 0.08432

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.57774
Value Function Update Magnitude: 0.74357

Collected Steps per Second: 22,378.49474
Overall Steps per Second: 10,545.79173

Timestep Collection Time: 2.23554
Timestep Consumption Time: 2.50834
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.74388

Cumulative Model Updates: 89,060
Cumulative Timesteps: 742,871,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 742871684...
Checkpoint 742871684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,730.41826
Policy Entropy: 1.86832
Value Function Loss: 0.08861

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.58034
Value Function Update Magnitude: 0.65704

Collected Steps per Second: 22,168.53100
Overall Steps per Second: 10,456.04336

Timestep Collection Time: 2.25644
Timestep Consumption Time: 2.52759
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.78403

Cumulative Model Updates: 89,066
Cumulative Timesteps: 742,921,706

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,339.16565
Policy Entropy: 1.86961
Value Function Loss: 0.09311

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.14498
Policy Update Magnitude: 0.58624
Value Function Update Magnitude: 0.62471

Collected Steps per Second: 22,268.17369
Overall Steps per Second: 10,457.86359

Timestep Collection Time: 2.24590
Timestep Consumption Time: 2.53634
PPO Batch Consumption Time: 0.29577
Total Iteration Time: 4.78224

Cumulative Model Updates: 89,072
Cumulative Timesteps: 742,971,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 742971718...
Checkpoint 742971718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,947.94827
Policy Entropy: 1.87741
Value Function Loss: 0.09620

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.59009
Value Function Update Magnitude: 0.65768

Collected Steps per Second: 21,973.34662
Overall Steps per Second: 10,418.65191

Timestep Collection Time: 2.27567
Timestep Consumption Time: 2.52380
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.79947

Cumulative Model Updates: 89,078
Cumulative Timesteps: 743,021,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,104.22715
Policy Entropy: 1.86199
Value Function Loss: 0.09458

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.14294
Policy Update Magnitude: 0.57719
Value Function Update Magnitude: 0.61381

Collected Steps per Second: 22,280.03111
Overall Steps per Second: 10,635.26971

Timestep Collection Time: 2.24614
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.70548

Cumulative Model Updates: 89,084
Cumulative Timesteps: 743,071,766

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 743071766...
Checkpoint 743071766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,725.35119
Policy Entropy: 1.85336
Value Function Loss: 0.09031

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.55647
Value Function Update Magnitude: 0.48504

Collected Steps per Second: 21,837.81974
Overall Steps per Second: 10,416.33630

Timestep Collection Time: 2.29052
Timestep Consumption Time: 2.51155
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.80207

Cumulative Model Updates: 89,090
Cumulative Timesteps: 743,121,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,535.03740
Policy Entropy: 1.84091
Value Function Loss: 0.09209

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.16286
Policy Update Magnitude: 0.53607
Value Function Update Magnitude: 0.55842

Collected Steps per Second: 22,550.22513
Overall Steps per Second: 10,644.04156

Timestep Collection Time: 2.21789
Timestep Consumption Time: 2.48089
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.69878

Cumulative Model Updates: 89,096
Cumulative Timesteps: 743,171,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 743171800...
Checkpoint 743171800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,201.80485
Policy Entropy: 1.85977
Value Function Loss: 0.09498

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.18841
Policy Update Magnitude: 0.46756
Value Function Update Magnitude: 0.56112

Collected Steps per Second: 21,828.40958
Overall Steps per Second: 10,235.25111

Timestep Collection Time: 2.29059
Timestep Consumption Time: 2.59449
PPO Batch Consumption Time: 0.30665
Total Iteration Time: 4.88508

Cumulative Model Updates: 89,102
Cumulative Timesteps: 743,221,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,872.60744
Policy Entropy: 1.88476
Value Function Loss: 0.09504

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.14634
Policy Update Magnitude: 0.47929
Value Function Update Magnitude: 0.60177

Collected Steps per Second: 21,720.36416
Overall Steps per Second: 10,488.16003

Timestep Collection Time: 2.30328
Timestep Consumption Time: 2.46667
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.76995

Cumulative Model Updates: 89,108
Cumulative Timesteps: 743,271,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 743271828...
Checkpoint 743271828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,976.80821
Policy Entropy: 1.87568
Value Function Loss: 0.09326

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.54124
Value Function Update Magnitude: 0.75022

Collected Steps per Second: 21,651.77463
Overall Steps per Second: 10,275.33418

Timestep Collection Time: 2.31067
Timestep Consumption Time: 2.55828
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.86894

Cumulative Model Updates: 89,114
Cumulative Timesteps: 743,321,858

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,164.46336
Policy Entropy: 1.86984
Value Function Loss: 0.09250

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.14755
Policy Update Magnitude: 0.56599
Value Function Update Magnitude: 0.77995

Collected Steps per Second: 22,212.65607
Overall Steps per Second: 10,431.58863

Timestep Collection Time: 2.25169
Timestep Consumption Time: 2.54298
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.79467

Cumulative Model Updates: 89,120
Cumulative Timesteps: 743,371,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 743371874...
Checkpoint 743371874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,594.31461
Policy Entropy: 1.84705
Value Function Loss: 0.08741

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.52954
Value Function Update Magnitude: 0.73635

Collected Steps per Second: 22,039.94661
Overall Steps per Second: 10,581.88171

Timestep Collection Time: 2.27079
Timestep Consumption Time: 2.45881
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.72959

Cumulative Model Updates: 89,126
Cumulative Timesteps: 743,421,922

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,669.38235
Policy Entropy: 1.85242
Value Function Loss: 0.08633

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.15594
Policy Update Magnitude: 0.52301
Value Function Update Magnitude: 0.69148

Collected Steps per Second: 22,030.81734
Overall Steps per Second: 10,580.51212

Timestep Collection Time: 2.27064
Timestep Consumption Time: 2.45730
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.72794

Cumulative Model Updates: 89,132
Cumulative Timesteps: 743,471,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 743471946...
Checkpoint 743471946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,269.46033
Policy Entropy: 1.86307
Value Function Loss: 0.09019

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.17348
Policy Update Magnitude: 0.50246
Value Function Update Magnitude: 0.68689

Collected Steps per Second: 21,807.66473
Overall Steps per Second: 10,531.40014

Timestep Collection Time: 2.29396
Timestep Consumption Time: 2.45621
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.75018

Cumulative Model Updates: 89,138
Cumulative Timesteps: 743,521,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,703.37019
Policy Entropy: 1.87327
Value Function Loss: 0.09058

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.17451
Policy Update Magnitude: 0.52662
Value Function Update Magnitude: 0.70719

Collected Steps per Second: 22,265.06518
Overall Steps per Second: 10,488.30029

Timestep Collection Time: 2.24702
Timestep Consumption Time: 2.52306
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.77008

Cumulative Model Updates: 89,144
Cumulative Timesteps: 743,572,002

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 743572002...
Checkpoint 743572002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,230.92379
Policy Entropy: 1.87195
Value Function Loss: 0.08426

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.15375
Policy Update Magnitude: 0.56646
Value Function Update Magnitude: 0.73498

Collected Steps per Second: 22,042.76049
Overall Steps per Second: 10,598.14637

Timestep Collection Time: 2.26877
Timestep Consumption Time: 2.44998
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.71875

Cumulative Model Updates: 89,150
Cumulative Timesteps: 743,622,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,805.04374
Policy Entropy: 1.88937
Value Function Loss: 0.08222

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.14169
Policy Update Magnitude: 0.57052
Value Function Update Magnitude: 0.75927

Collected Steps per Second: 22,015.16381
Overall Steps per Second: 10,510.63857

Timestep Collection Time: 2.27225
Timestep Consumption Time: 2.48712
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.75937

Cumulative Model Updates: 89,156
Cumulative Timesteps: 743,672,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 743672036...
Checkpoint 743672036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,528.47541
Policy Entropy: 1.89631
Value Function Loss: 0.08115

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.53591
Value Function Update Magnitude: 0.77554

Collected Steps per Second: 21,604.24471
Overall Steps per Second: 10,356.73414

Timestep Collection Time: 2.31584
Timestep Consumption Time: 2.51503
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.83087

Cumulative Model Updates: 89,162
Cumulative Timesteps: 743,722,068

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,828.45652
Policy Entropy: 1.92352
Value Function Loss: 0.08602

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.14904
Policy Update Magnitude: 0.53169
Value Function Update Magnitude: 0.78535

Collected Steps per Second: 22,512.63551
Overall Steps per Second: 10,661.40640

Timestep Collection Time: 2.22195
Timestep Consumption Time: 2.46992
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.69188

Cumulative Model Updates: 89,168
Cumulative Timesteps: 743,772,090

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 743772090...
Checkpoint 743772090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,121.44862
Policy Entropy: 1.89650
Value Function Loss: 0.09096

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.16219
Policy Update Magnitude: 0.50667
Value Function Update Magnitude: 0.72130

Collected Steps per Second: 21,550.80655
Overall Steps per Second: 10,240.12195

Timestep Collection Time: 2.32056
Timestep Consumption Time: 2.56317
PPO Batch Consumption Time: 0.29752
Total Iteration Time: 4.88373

Cumulative Model Updates: 89,174
Cumulative Timesteps: 743,822,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,362.87995
Policy Entropy: 1.89867
Value Function Loss: 0.09848

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.16279
Policy Update Magnitude: 0.51197
Value Function Update Magnitude: 0.68392

Collected Steps per Second: 21,953.84863
Overall Steps per Second: 10,339.03329

Timestep Collection Time: 2.27778
Timestep Consumption Time: 2.55884
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.83662

Cumulative Model Updates: 89,180
Cumulative Timesteps: 743,872,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 743872106...
Checkpoint 743872106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,872.23154
Policy Entropy: 1.88891
Value Function Loss: 0.10161

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.16445
Policy Update Magnitude: 0.52402
Value Function Update Magnitude: 0.74012

Collected Steps per Second: 21,805.36286
Overall Steps per Second: 10,352.47701

Timestep Collection Time: 2.29393
Timestep Consumption Time: 2.53776
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.83169

Cumulative Model Updates: 89,186
Cumulative Timesteps: 743,922,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,505.52861
Policy Entropy: 1.90293
Value Function Loss: 0.09675

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.15821
Policy Update Magnitude: 0.50094
Value Function Update Magnitude: 0.61957

Collected Steps per Second: 22,081.77637
Overall Steps per Second: 10,450.84705

Timestep Collection Time: 2.26558
Timestep Consumption Time: 2.52140
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.78698

Cumulative Model Updates: 89,192
Cumulative Timesteps: 743,972,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 743972154...
Checkpoint 743972154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,450.81959
Policy Entropy: 1.89335
Value Function Loss: 0.10261

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.16751
Policy Update Magnitude: 0.50648
Value Function Update Magnitude: 0.50154

Collected Steps per Second: 21,566.21161
Overall Steps per Second: 10,302.04822

Timestep Collection Time: 2.31844
Timestep Consumption Time: 2.53496
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.85340

Cumulative Model Updates: 89,198
Cumulative Timesteps: 744,022,154

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,874.93112
Policy Entropy: 1.89728
Value Function Loss: 0.09740

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.15726
Policy Update Magnitude: 0.50829
Value Function Update Magnitude: 0.44387

Collected Steps per Second: 22,527.34078
Overall Steps per Second: 10,592.46440

Timestep Collection Time: 2.21988
Timestep Consumption Time: 2.50121
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.72109

Cumulative Model Updates: 89,204
Cumulative Timesteps: 744,072,162

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 744072162...
Checkpoint 744072162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,326.95048
Policy Entropy: 1.89280
Value Function Loss: 0.09560

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.15961
Policy Update Magnitude: 0.50174
Value Function Update Magnitude: 0.45251

Collected Steps per Second: 22,110.98453
Overall Steps per Second: 10,454.00951

Timestep Collection Time: 2.26204
Timestep Consumption Time: 2.52234
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.78438

Cumulative Model Updates: 89,210
Cumulative Timesteps: 744,122,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,545.62843
Policy Entropy: 1.89630
Value Function Loss: 0.08924

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.53052
Value Function Update Magnitude: 0.48248

Collected Steps per Second: 22,327.28486
Overall Steps per Second: 10,486.11947

Timestep Collection Time: 2.24156
Timestep Consumption Time: 2.53122
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.77279

Cumulative Model Updates: 89,216
Cumulative Timesteps: 744,172,226

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 744172226...
Checkpoint 744172226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,535.45161
Policy Entropy: 1.89249
Value Function Loss: 0.09073

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.56927
Value Function Update Magnitude: 0.54713

Collected Steps per Second: 21,675.92170
Overall Steps per Second: 10,488.21445

Timestep Collection Time: 2.30754
Timestep Consumption Time: 2.46143
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.76897

Cumulative Model Updates: 89,222
Cumulative Timesteps: 744,222,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,378.20120
Policy Entropy: 1.87250
Value Function Loss: 0.08970

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.15969
Policy Update Magnitude: 0.52435
Value Function Update Magnitude: 0.57066

Collected Steps per Second: 22,348.93948
Overall Steps per Second: 10,540.49982

Timestep Collection Time: 2.23832
Timestep Consumption Time: 2.50757
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.74589

Cumulative Model Updates: 89,228
Cumulative Timesteps: 744,272,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 744272268...
Checkpoint 744272268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,797.00023
Policy Entropy: 1.86626
Value Function Loss: 0.09056

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14556
Policy Update Magnitude: 0.51703
Value Function Update Magnitude: 0.60283

Collected Steps per Second: 21,763.92761
Overall Steps per Second: 10,559.77289

Timestep Collection Time: 2.29830
Timestep Consumption Time: 2.43855
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.73684

Cumulative Model Updates: 89,234
Cumulative Timesteps: 744,322,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,726.01861
Policy Entropy: 1.87507
Value Function Loss: 0.09364

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.14159
Policy Update Magnitude: 0.56068
Value Function Update Magnitude: 0.58438

Collected Steps per Second: 22,127.61161
Overall Steps per Second: 10,498.92586

Timestep Collection Time: 2.26070
Timestep Consumption Time: 2.50397
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.76468

Cumulative Model Updates: 89,240
Cumulative Timesteps: 744,372,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 744372312...
Checkpoint 744372312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,445.28037
Policy Entropy: 1.87385
Value Function Loss: 0.09752

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.16268
Policy Update Magnitude: 0.54603
Value Function Update Magnitude: 0.50023

Collected Steps per Second: 21,723.39545
Overall Steps per Second: 10,343.42388

Timestep Collection Time: 2.30295
Timestep Consumption Time: 2.53374
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.83670

Cumulative Model Updates: 89,246
Cumulative Timesteps: 744,422,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,340.64497
Policy Entropy: 1.86566
Value Function Loss: 0.09977

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.17573
Policy Update Magnitude: 0.50009
Value Function Update Magnitude: 0.42511

Collected Steps per Second: 22,359.86180
Overall Steps per Second: 10,501.39842

Timestep Collection Time: 2.23678
Timestep Consumption Time: 2.52583
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.76260

Cumulative Model Updates: 89,252
Cumulative Timesteps: 744,472,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 744472354...
Checkpoint 744472354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,412.64626
Policy Entropy: 1.85752
Value Function Loss: 0.09762

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.15929
Policy Update Magnitude: 0.49364
Value Function Update Magnitude: 0.39059

Collected Steps per Second: 21,767.91037
Overall Steps per Second: 10,372.85487

Timestep Collection Time: 2.29742
Timestep Consumption Time: 2.52382
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.82124

Cumulative Model Updates: 89,258
Cumulative Timesteps: 744,522,364

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,383.03138
Policy Entropy: 1.86993
Value Function Loss: 0.09438

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.53934
Value Function Update Magnitude: 0.46682

Collected Steps per Second: 22,152.97492
Overall Steps per Second: 10,553.57534

Timestep Collection Time: 2.25803
Timestep Consumption Time: 2.48179
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.73982

Cumulative Model Updates: 89,264
Cumulative Timesteps: 744,572,386

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 744572386...
Checkpoint 744572386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,039.23417
Policy Entropy: 1.89397
Value Function Loss: 0.09403

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.15270
Policy Update Magnitude: 0.54721
Value Function Update Magnitude: 0.56121

Collected Steps per Second: 21,646.77574
Overall Steps per Second: 10,351.70864

Timestep Collection Time: 2.31000
Timestep Consumption Time: 2.52051
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.83051

Cumulative Model Updates: 89,270
Cumulative Timesteps: 744,622,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,062.06775
Policy Entropy: 1.90617
Value Function Loss: 0.09861

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.15032
Policy Update Magnitude: 0.54332
Value Function Update Magnitude: 0.64344

Collected Steps per Second: 22,559.51030
Overall Steps per Second: 10,752.92201

Timestep Collection Time: 2.21804
Timestep Consumption Time: 2.43539
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.65343

Cumulative Model Updates: 89,276
Cumulative Timesteps: 744,672,428

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 744672428...
Checkpoint 744672428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,612.40789
Policy Entropy: 1.90544
Value Function Loss: 0.10418

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.15358
Policy Update Magnitude: 0.56828
Value Function Update Magnitude: 0.67898

Collected Steps per Second: 21,992.81242
Overall Steps per Second: 10,575.08068

Timestep Collection Time: 2.27456
Timestep Consumption Time: 2.45580
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.73037

Cumulative Model Updates: 89,282
Cumulative Timesteps: 744,722,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,779.33148
Policy Entropy: 1.90409
Value Function Loss: 0.10227

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14983
Policy Update Magnitude: 0.59242
Value Function Update Magnitude: 0.68569

Collected Steps per Second: 22,433.24481
Overall Steps per Second: 10,537.85705

Timestep Collection Time: 2.22892
Timestep Consumption Time: 2.51606
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.74499

Cumulative Model Updates: 89,288
Cumulative Timesteps: 744,772,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 744772454...
Checkpoint 744772454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,630.85061
Policy Entropy: 1.89588
Value Function Loss: 0.09871

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.14378
Policy Update Magnitude: 0.59641
Value Function Update Magnitude: 0.68427

Collected Steps per Second: 21,348.83659
Overall Steps per Second: 10,258.65277

Timestep Collection Time: 2.34411
Timestep Consumption Time: 2.53411
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.87822

Cumulative Model Updates: 89,294
Cumulative Timesteps: 744,822,498

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,360.98389
Policy Entropy: 1.89693
Value Function Loss: 0.09040

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.57683
Value Function Update Magnitude: 0.73601

Collected Steps per Second: 22,470.14106
Overall Steps per Second: 10,515.80941

Timestep Collection Time: 2.22553
Timestep Consumption Time: 2.52998
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.75551

Cumulative Model Updates: 89,300
Cumulative Timesteps: 744,872,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 744872506...
Checkpoint 744872506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,217.40566
Policy Entropy: 1.89562
Value Function Loss: 0.08935

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.14554
Policy Update Magnitude: 0.54842
Value Function Update Magnitude: 0.69505

Collected Steps per Second: 21,919.25010
Overall Steps per Second: 10,587.02572

Timestep Collection Time: 2.28165
Timestep Consumption Time: 2.44225
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.72390

Cumulative Model Updates: 89,306
Cumulative Timesteps: 744,922,518

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,775.07256
Policy Entropy: 1.91090
Value Function Loss: 0.09599

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.15046
Policy Update Magnitude: 0.52446
Value Function Update Magnitude: 0.65443

Collected Steps per Second: 22,324.00765
Overall Steps per Second: 10,483.42193

Timestep Collection Time: 2.24073
Timestep Consumption Time: 2.53081
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.77153

Cumulative Model Updates: 89,312
Cumulative Timesteps: 744,972,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 744972540...
Checkpoint 744972540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,498.14391
Policy Entropy: 1.91278
Value Function Loss: 0.10513

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.16301
Policy Update Magnitude: 0.53565
Value Function Update Magnitude: 0.69331

Collected Steps per Second: 21,788.49558
Overall Steps per Second: 10,511.70423

Timestep Collection Time: 2.29589
Timestep Consumption Time: 2.46300
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.75889

Cumulative Model Updates: 89,318
Cumulative Timesteps: 745,022,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,099.47042
Policy Entropy: 1.91431
Value Function Loss: 0.10471

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.16435
Policy Update Magnitude: 0.53442
Value Function Update Magnitude: 0.81127

Collected Steps per Second: 22,413.16846
Overall Steps per Second: 10,550.96085

Timestep Collection Time: 2.23163
Timestep Consumption Time: 2.50898
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.74061

Cumulative Model Updates: 89,324
Cumulative Timesteps: 745,072,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 745072582...
Checkpoint 745072582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,371.76412
Policy Entropy: 1.91694
Value Function Loss: 0.10008

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.15793
Policy Update Magnitude: 0.53904
Value Function Update Magnitude: 0.75572

Collected Steps per Second: 22,125.40000
Overall Steps per Second: 10,606.81248

Timestep Collection Time: 2.26057
Timestep Consumption Time: 2.45489
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.71546

Cumulative Model Updates: 89,330
Cumulative Timesteps: 745,122,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,386.34164
Policy Entropy: 1.91274
Value Function Loss: 0.10736

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.16552
Policy Update Magnitude: 0.52624
Value Function Update Magnitude: 0.61475

Collected Steps per Second: 21,745.37000
Overall Steps per Second: 10,322.94031

Timestep Collection Time: 2.30054
Timestep Consumption Time: 2.54556
PPO Batch Consumption Time: 0.30046
Total Iteration Time: 4.84610

Cumulative Model Updates: 89,336
Cumulative Timesteps: 745,172,624

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 745172624...
Checkpoint 745172624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,136.87288
Policy Entropy: 1.92931
Value Function Loss: 0.10966

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.17502
Policy Update Magnitude: 0.55332
Value Function Update Magnitude: 0.63733

Collected Steps per Second: 21,834.48632
Overall Steps per Second: 10,439.43600

Timestep Collection Time: 2.29032
Timestep Consumption Time: 2.49998
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.79030

Cumulative Model Updates: 89,342
Cumulative Timesteps: 745,222,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,402.85749
Policy Entropy: 1.90061
Value Function Loss: 0.10229

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.16000
Policy Update Magnitude: 0.52301
Value Function Update Magnitude: 0.75076

Collected Steps per Second: 22,290.33033
Overall Steps per Second: 10,533.37069

Timestep Collection Time: 2.24447
Timestep Consumption Time: 2.50520
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.74967

Cumulative Model Updates: 89,348
Cumulative Timesteps: 745,272,662

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 745272662...
Checkpoint 745272662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,165.61726
Policy Entropy: 1.90123
Value Function Loss: 0.09690

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.16119
Policy Update Magnitude: 0.51303
Value Function Update Magnitude: 0.69926

Collected Steps per Second: 22,080.90572
Overall Steps per Second: 10,455.82650

Timestep Collection Time: 2.26503
Timestep Consumption Time: 2.51833
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.78336

Cumulative Model Updates: 89,354
Cumulative Timesteps: 745,322,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,271.35908
Policy Entropy: 1.88647
Value Function Loss: 0.09460

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.15639
Policy Update Magnitude: 0.50659
Value Function Update Magnitude: 0.65253

Collected Steps per Second: 21,922.01528
Overall Steps per Second: 10,416.85391

Timestep Collection Time: 2.28136
Timestep Consumption Time: 2.51971
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.80107

Cumulative Model Updates: 89,360
Cumulative Timesteps: 745,372,688

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 745372688...
Checkpoint 745372688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,139.48109
Policy Entropy: 1.92754
Value Function Loss: 0.10110

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.14635
Policy Update Magnitude: 0.51535
Value Function Update Magnitude: 0.65619

Collected Steps per Second: 21,536.90429
Overall Steps per Second: 10,382.88837

Timestep Collection Time: 2.32243
Timestep Consumption Time: 2.49492
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.81735

Cumulative Model Updates: 89,366
Cumulative Timesteps: 745,422,706

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,425.22789
Policy Entropy: 1.93243
Value Function Loss: 0.10074

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.15103
Policy Update Magnitude: 0.54365
Value Function Update Magnitude: 0.75161

Collected Steps per Second: 21,991.15041
Overall Steps per Second: 10,500.22808

Timestep Collection Time: 2.27373
Timestep Consumption Time: 2.48826
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.76199

Cumulative Model Updates: 89,372
Cumulative Timesteps: 745,472,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 745472708...
Checkpoint 745472708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,950.24089
Policy Entropy: 1.93371
Value Function Loss: 0.09685

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.15915
Policy Update Magnitude: 0.51407
Value Function Update Magnitude: 0.76337

Collected Steps per Second: 22,166.18014
Overall Steps per Second: 10,438.79114

Timestep Collection Time: 2.25632
Timestep Consumption Time: 2.53485
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.79117

Cumulative Model Updates: 89,378
Cumulative Timesteps: 745,522,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,688.12875
Policy Entropy: 1.94443
Value Function Loss: 0.09925

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13680
Policy Update Magnitude: 0.50662
Value Function Update Magnitude: 0.63184

Collected Steps per Second: 22,351.72121
Overall Steps per Second: 10,410.37781

Timestep Collection Time: 2.23777
Timestep Consumption Time: 2.56686
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.80463

Cumulative Model Updates: 89,384
Cumulative Timesteps: 745,572,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 745572740...
Checkpoint 745572740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,574.60790
Policy Entropy: 1.94356
Value Function Loss: 0.10544

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.56180
Value Function Update Magnitude: 0.52399

Collected Steps per Second: 21,468.11827
Overall Steps per Second: 10,369.80309

Timestep Collection Time: 2.32941
Timestep Consumption Time: 2.49306
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.82246

Cumulative Model Updates: 89,390
Cumulative Timesteps: 745,622,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,272.77077
Policy Entropy: 1.95307
Value Function Loss: 0.10488

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.57798
Value Function Update Magnitude: 0.46638

Collected Steps per Second: 22,110.21419
Overall Steps per Second: 10,440.15660

Timestep Collection Time: 2.26194
Timestep Consumption Time: 2.52841
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.79035

Cumulative Model Updates: 89,396
Cumulative Timesteps: 745,672,760

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 745672760...
Checkpoint 745672760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,783.72140
Policy Entropy: 1.93593
Value Function Loss: 0.09881

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.58017
Value Function Update Magnitude: 0.64022

Collected Steps per Second: 21,945.51774
Overall Steps per Second: 10,517.15763

Timestep Collection Time: 2.27974
Timestep Consumption Time: 2.47725
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.75699

Cumulative Model Updates: 89,402
Cumulative Timesteps: 745,722,790

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,329.08345
Policy Entropy: 1.94908
Value Function Loss: 0.09053

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.58459
Value Function Update Magnitude: 0.66949

Collected Steps per Second: 22,277.19422
Overall Steps per Second: 10,464.25594

Timestep Collection Time: 2.24615
Timestep Consumption Time: 2.53565
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.78180

Cumulative Model Updates: 89,408
Cumulative Timesteps: 745,772,828

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 745772828...
Checkpoint 745772828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,641.04487
Policy Entropy: 1.95465
Value Function Loss: 0.09577

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.58165
Value Function Update Magnitude: 0.68558

Collected Steps per Second: 21,015.18453
Overall Steps per Second: 10,043.03435

Timestep Collection Time: 2.37961
Timestep Consumption Time: 2.59976
PPO Batch Consumption Time: 0.30847
Total Iteration Time: 4.97937

Cumulative Model Updates: 89,414
Cumulative Timesteps: 745,822,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,620.94234
Policy Entropy: 1.94280
Value Function Loss: 0.09795

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12956
Policy Update Magnitude: 0.58713
Value Function Update Magnitude: 0.74637

Collected Steps per Second: 22,403.23558
Overall Steps per Second: 10,657.92831

Timestep Collection Time: 2.23307
Timestep Consumption Time: 2.46090
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.69397

Cumulative Model Updates: 89,420
Cumulative Timesteps: 745,872,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 745872864...
Checkpoint 745872864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,233.43411
Policy Entropy: 1.93983
Value Function Loss: 0.10091

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.59193
Value Function Update Magnitude: 0.73674

Collected Steps per Second: 22,017.08302
Overall Steps per Second: 10,591.01473

Timestep Collection Time: 2.27269
Timestep Consumption Time: 2.45188
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.72457

Cumulative Model Updates: 89,426
Cumulative Timesteps: 745,922,902

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,286.86947
Policy Entropy: 1.92423
Value Function Loss: 0.10431

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.16204
Policy Update Magnitude: 0.56206
Value Function Update Magnitude: 0.64852

Collected Steps per Second: 22,435.81131
Overall Steps per Second: 10,478.88768

Timestep Collection Time: 2.22903
Timestep Consumption Time: 2.54343
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.77245

Cumulative Model Updates: 89,432
Cumulative Timesteps: 745,972,912

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 745972912...
Checkpoint 745972912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,227.70122
Policy Entropy: 1.94159
Value Function Loss: 0.10448

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.15768
Policy Update Magnitude: 0.52443
Value Function Update Magnitude: 0.59789

Collected Steps per Second: 21,791.39165
Overall Steps per Second: 10,598.75372

Timestep Collection Time: 2.29503
Timestep Consumption Time: 2.42363
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.71867

Cumulative Model Updates: 89,438
Cumulative Timesteps: 746,022,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,424.73726
Policy Entropy: 1.92846
Value Function Loss: 0.09724

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.17375
Policy Update Magnitude: 0.48656
Value Function Update Magnitude: 0.64813

Collected Steps per Second: 22,267.54197
Overall Steps per Second: 10,489.54326

Timestep Collection Time: 2.24641
Timestep Consumption Time: 2.52234
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.76875

Cumulative Model Updates: 89,444
Cumulative Timesteps: 746,072,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 746072946...
Checkpoint 746072946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,058.41843
Policy Entropy: 1.93677
Value Function Loss: 0.09667

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.15258
Policy Update Magnitude: 0.49864
Value Function Update Magnitude: 0.71806

Collected Steps per Second: 22,129.44504
Overall Steps per Second: 10,708.55212

Timestep Collection Time: 2.26052
Timestep Consumption Time: 2.41089
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.67141

Cumulative Model Updates: 89,450
Cumulative Timesteps: 746,122,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,648.82888
Policy Entropy: 1.92926
Value Function Loss: 0.08836

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.50071
Value Function Update Magnitude: 0.71265

Collected Steps per Second: 22,141.67503
Overall Steps per Second: 10,199.29900

Timestep Collection Time: 2.25927
Timestep Consumption Time: 2.64538
PPO Batch Consumption Time: 0.31125
Total Iteration Time: 4.90465

Cumulative Model Updates: 89,456
Cumulative Timesteps: 746,172,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 746172994...
Checkpoint 746172994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,115.86296
Policy Entropy: 1.93518
Value Function Loss: 0.09632

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.15218
Policy Update Magnitude: 0.52118
Value Function Update Magnitude: 0.63027

Collected Steps per Second: 20,191.12663
Overall Steps per Second: 9,929.67417

Timestep Collection Time: 2.47723
Timestep Consumption Time: 2.56000
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 5.03722

Cumulative Model Updates: 89,462
Cumulative Timesteps: 746,223,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,420.20820
Policy Entropy: 1.93967
Value Function Loss: 0.09477

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.14298
Policy Update Magnitude: 0.57553
Value Function Update Magnitude: 0.67198

Collected Steps per Second: 22,764.52377
Overall Steps per Second: 10,554.25524

Timestep Collection Time: 2.19640
Timestep Consumption Time: 2.54103
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.73743

Cumulative Model Updates: 89,468
Cumulative Timesteps: 746,273,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 746273012...
Checkpoint 746273012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,682.83171
Policy Entropy: 1.93933
Value Function Loss: 0.09678

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.57095
Value Function Update Magnitude: 0.78953

Collected Steps per Second: 22,013.55851
Overall Steps per Second: 10,591.13834

Timestep Collection Time: 2.27242
Timestep Consumption Time: 2.45078
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.72319

Cumulative Model Updates: 89,474
Cumulative Timesteps: 746,323,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,328.85044
Policy Entropy: 1.94195
Value Function Loss: 0.09834

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.58571
Value Function Update Magnitude: 0.79034

Collected Steps per Second: 22,608.21643
Overall Steps per Second: 10,566.64589

Timestep Collection Time: 2.21265
Timestep Consumption Time: 2.52149
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.73414

Cumulative Model Updates: 89,480
Cumulative Timesteps: 746,373,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 746373060...
Checkpoint 746373060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,820.91163
Policy Entropy: 1.93056
Value Function Loss: 0.09555

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.59222
Value Function Update Magnitude: 0.83878

Collected Steps per Second: 21,959.15762
Overall Steps per Second: 10,559.53078

Timestep Collection Time: 2.27768
Timestep Consumption Time: 2.45889
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.73657

Cumulative Model Updates: 89,486
Cumulative Timesteps: 746,423,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,349.77092
Policy Entropy: 1.93218
Value Function Loss: 0.08806

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.56352
Value Function Update Magnitude: 0.85569

Collected Steps per Second: 22,845.47257
Overall Steps per Second: 10,569.84011

Timestep Collection Time: 2.18949
Timestep Consumption Time: 2.54284
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.73233

Cumulative Model Updates: 89,492
Cumulative Timesteps: 746,473,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 746473096...
Checkpoint 746473096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,068.13486
Policy Entropy: 1.92590
Value Function Loss: 0.08231

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.55446
Value Function Update Magnitude: 0.79287

Collected Steps per Second: 22,138.05108
Overall Steps per Second: 10,553.18835

Timestep Collection Time: 2.25892
Timestep Consumption Time: 2.47975
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.73866

Cumulative Model Updates: 89,498
Cumulative Timesteps: 746,523,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,185.92535
Policy Entropy: 1.91512
Value Function Loss: 0.08416

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.12277
Policy Update Magnitude: 0.56144
Value Function Update Magnitude: 0.77087

Collected Steps per Second: 22,558.18879
Overall Steps per Second: 10,553.12219

Timestep Collection Time: 2.21782
Timestep Consumption Time: 2.52296
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.74078

Cumulative Model Updates: 89,504
Cumulative Timesteps: 746,573,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 746573134...
Checkpoint 746573134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,002.84101
Policy Entropy: 1.91891
Value Function Loss: 0.08706

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.51791
Value Function Update Magnitude: 0.71540

Collected Steps per Second: 21,922.94549
Overall Steps per Second: 10,575.39103

Timestep Collection Time: 2.28190
Timestep Consumption Time: 2.44851
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.73042

Cumulative Model Updates: 89,510
Cumulative Timesteps: 746,623,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,903.37567
Policy Entropy: 1.91309
Value Function Loss: 0.08906

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.15754
Policy Update Magnitude: 0.46656
Value Function Update Magnitude: 0.65797

Collected Steps per Second: 22,700.00595
Overall Steps per Second: 10,761.80711

Timestep Collection Time: 2.20273
Timestep Consumption Time: 2.44351
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.64625

Cumulative Model Updates: 89,516
Cumulative Timesteps: 746,673,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 746673162...
Checkpoint 746673162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,667.82377
Policy Entropy: 1.91168
Value Function Loss: 0.08856

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.46446
Value Function Update Magnitude: 0.72113

Collected Steps per Second: 22,176.02414
Overall Steps per Second: 10,635.41364

Timestep Collection Time: 2.25469
Timestep Consumption Time: 2.44659
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.70127

Cumulative Model Updates: 89,522
Cumulative Timesteps: 746,723,162

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,977.20489
Policy Entropy: 1.90732
Value Function Loss: 0.08751

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.51900
Value Function Update Magnitude: 0.72084

Collected Steps per Second: 21,810.38114
Overall Steps per Second: 10,579.55741

Timestep Collection Time: 2.29285
Timestep Consumption Time: 2.43400
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.72685

Cumulative Model Updates: 89,528
Cumulative Timesteps: 746,773,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 746773170...
Checkpoint 746773170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,258.70589
Policy Entropy: 1.91091
Value Function Loss: 0.09318

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.57600
Value Function Update Magnitude: 0.66714

Collected Steps per Second: 22,024.16263
Overall Steps per Second: 10,526.79930

Timestep Collection Time: 2.27051
Timestep Consumption Time: 2.47985
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.75035

Cumulative Model Updates: 89,534
Cumulative Timesteps: 746,823,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,472.31046
Policy Entropy: 1.90304
Value Function Loss: 0.09060

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.58735
Value Function Update Magnitude: 0.62021

Collected Steps per Second: 22,426.66789
Overall Steps per Second: 10,530.21911

Timestep Collection Time: 2.22985
Timestep Consumption Time: 2.51915
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.74900

Cumulative Model Updates: 89,540
Cumulative Timesteps: 746,873,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 746873184...
Checkpoint 746873184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,756.08042
Policy Entropy: 1.91267
Value Function Loss: 0.08714

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14847
Policy Update Magnitude: 0.55457
Value Function Update Magnitude: 0.63519

Collected Steps per Second: 21,906.88762
Overall Steps per Second: 10,575.91820

Timestep Collection Time: 2.28248
Timestep Consumption Time: 2.44543
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.72791

Cumulative Model Updates: 89,546
Cumulative Timesteps: 746,923,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,711.76927
Policy Entropy: 1.91882
Value Function Loss: 0.09051

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.15719
Policy Update Magnitude: 0.50474
Value Function Update Magnitude: 0.56760

Collected Steps per Second: 22,272.77441
Overall Steps per Second: 10,496.22585

Timestep Collection Time: 2.24507
Timestep Consumption Time: 2.51893
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.76400

Cumulative Model Updates: 89,552
Cumulative Timesteps: 746,973,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 746973190...
Checkpoint 746973190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,143.99437
Policy Entropy: 1.92140
Value Function Loss: 0.09284

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.16001
Policy Update Magnitude: 0.51829
Value Function Update Magnitude: 0.52472

Collected Steps per Second: 22,115.10162
Overall Steps per Second: 10,601.49723

Timestep Collection Time: 2.26216
Timestep Consumption Time: 2.45679
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.71896

Cumulative Model Updates: 89,558
Cumulative Timesteps: 747,023,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,486.13620
Policy Entropy: 1.91791
Value Function Loss: 0.10170

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.14486
Policy Update Magnitude: 0.55477
Value Function Update Magnitude: 0.60287

Collected Steps per Second: 22,363.60379
Overall Steps per Second: 10,516.89978

Timestep Collection Time: 2.23631
Timestep Consumption Time: 2.51908
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.75539

Cumulative Model Updates: 89,564
Cumulative Timesteps: 747,073,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 747073230...
Checkpoint 747073230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,879.97404
Policy Entropy: 1.92592
Value Function Loss: 0.09660

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.59305
Value Function Update Magnitude: 0.71649

Collected Steps per Second: 21,747.97159
Overall Steps per Second: 10,558.58093

Timestep Collection Time: 2.30026
Timestep Consumption Time: 2.43769
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.73795

Cumulative Model Updates: 89,570
Cumulative Timesteps: 747,123,256

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,060.04003
Policy Entropy: 1.92206
Value Function Loss: 0.09392

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.59203
Value Function Update Magnitude: 0.75963

Collected Steps per Second: 22,485.70204
Overall Steps per Second: 10,545.56899

Timestep Collection Time: 2.22488
Timestep Consumption Time: 2.51910
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.74398

Cumulative Model Updates: 89,576
Cumulative Timesteps: 747,173,284

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 747173284...
Checkpoint 747173284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,388.40097
Policy Entropy: 1.90775
Value Function Loss: 0.09418

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.57857
Value Function Update Magnitude: 0.73621

Collected Steps per Second: 22,218.21699
Overall Steps per Second: 10,634.22617

Timestep Collection Time: 2.25095
Timestep Consumption Time: 2.45198
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.70293

Cumulative Model Updates: 89,582
Cumulative Timesteps: 747,223,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,365.82296
Policy Entropy: 1.88659
Value Function Loss: 0.09517

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.58899
Value Function Update Magnitude: 0.71391

Collected Steps per Second: 22,045.39717
Overall Steps per Second: 10,466.82451

Timestep Collection Time: 2.26995
Timestep Consumption Time: 2.51106
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.78101

Cumulative Model Updates: 89,588
Cumulative Timesteps: 747,273,338

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 747273338...
Checkpoint 747273338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,091.31871
Policy Entropy: 1.89581
Value Function Loss: 0.09589

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.58540
Value Function Update Magnitude: 0.78113

Collected Steps per Second: 22,130.18046
Overall Steps per Second: 10,592.80839

Timestep Collection Time: 2.26108
Timestep Consumption Time: 2.46270
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.72377

Cumulative Model Updates: 89,594
Cumulative Timesteps: 747,323,376

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,337.88725
Policy Entropy: 1.90195
Value Function Loss: 0.09194

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.16009
Policy Update Magnitude: 0.52164
Value Function Update Magnitude: 0.72271

Collected Steps per Second: 22,359.48441
Overall Steps per Second: 10,485.05606

Timestep Collection Time: 2.23690
Timestep Consumption Time: 2.53331
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.77022

Cumulative Model Updates: 89,600
Cumulative Timesteps: 747,373,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 747373392...
Checkpoint 747373392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,620.60704
Policy Entropy: 1.91246
Value Function Loss: 0.08659

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.15868
Policy Update Magnitude: 0.50165
Value Function Update Magnitude: 0.72479

Collected Steps per Second: 22,014.86177
Overall Steps per Second: 10,600.23924

Timestep Collection Time: 2.27328
Timestep Consumption Time: 2.44793
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.72121

Cumulative Model Updates: 89,606
Cumulative Timesteps: 747,423,438

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,385.36474
Policy Entropy: 1.89805
Value Function Loss: 0.08565

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.54043
Value Function Update Magnitude: 0.76171

Collected Steps per Second: 22,342.03116
Overall Steps per Second: 10,498.03358

Timestep Collection Time: 2.23847
Timestep Consumption Time: 2.52547
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.76394

Cumulative Model Updates: 89,612
Cumulative Timesteps: 747,473,450

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 747473450...
Checkpoint 747473450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,133.75107
Policy Entropy: 1.89324
Value Function Loss: 0.08943

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.14159
Policy Update Magnitude: 0.57640
Value Function Update Magnitude: 0.70312

Collected Steps per Second: 21,417.35180
Overall Steps per Second: 10,612.07761

Timestep Collection Time: 2.33596
Timestep Consumption Time: 2.37848
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.71444

Cumulative Model Updates: 89,618
Cumulative Timesteps: 747,523,480

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,410.36323
Policy Entropy: 1.88560
Value Function Loss: 0.09382

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.15610
Policy Update Magnitude: 0.54109
Value Function Update Magnitude: 0.65529

Collected Steps per Second: 21,316.61260
Overall Steps per Second: 10,465.65774

Timestep Collection Time: 2.34625
Timestep Consumption Time: 2.43262
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.77887

Cumulative Model Updates: 89,624
Cumulative Timesteps: 747,573,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 747573494...
Checkpoint 747573494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,369.68437
Policy Entropy: 1.89020
Value Function Loss: 0.09129

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13888
Policy Update Magnitude: 0.52903
Value Function Update Magnitude: 0.65935

Collected Steps per Second: 21,329.65145
Overall Steps per Second: 10,626.84087

Timestep Collection Time: 2.34547
Timestep Consumption Time: 2.36223
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.70770

Cumulative Model Updates: 89,630
Cumulative Timesteps: 747,623,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,441.95215
Policy Entropy: 1.89781
Value Function Loss: 0.09017

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.15626
Policy Update Magnitude: 0.50659
Value Function Update Magnitude: 0.64095

Collected Steps per Second: 21,709.57804
Overall Steps per Second: 10,529.31276

Timestep Collection Time: 2.30313
Timestep Consumption Time: 2.44552
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.74865

Cumulative Model Updates: 89,636
Cumulative Timesteps: 747,673,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 747673522...
Checkpoint 747673522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,972.72829
Policy Entropy: 1.89216
Value Function Loss: 0.09267

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.16482
Policy Update Magnitude: 0.47577
Value Function Update Magnitude: 0.70631

Collected Steps per Second: 21,549.14423
Overall Steps per Second: 10,592.99468

Timestep Collection Time: 2.32148
Timestep Consumption Time: 2.40107
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.72255

Cumulative Model Updates: 89,642
Cumulative Timesteps: 747,723,548

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,486.82133
Policy Entropy: 1.89390
Value Function Loss: 0.09754

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14551
Policy Update Magnitude: 0.55652
Value Function Update Magnitude: 0.70666

Collected Steps per Second: 21,833.80004
Overall Steps per Second: 10,556.89655

Timestep Collection Time: 2.29131
Timestep Consumption Time: 2.44758
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.73889

Cumulative Model Updates: 89,648
Cumulative Timesteps: 747,773,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 747773576...
Checkpoint 747773576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,475.61431
Policy Entropy: 1.88727
Value Function Loss: 0.09537

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.16383
Policy Update Magnitude: 0.56159
Value Function Update Magnitude: 0.69913

Collected Steps per Second: 21,305.30714
Overall Steps per Second: 10,468.93023

Timestep Collection Time: 2.34824
Timestep Consumption Time: 2.43066
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.77890

Cumulative Model Updates: 89,654
Cumulative Timesteps: 747,823,606

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,964.52214
Policy Entropy: 1.88576
Value Function Loss: 0.09071

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.15305
Policy Update Magnitude: 0.55703
Value Function Update Magnitude: 0.68693

Collected Steps per Second: 22,087.43374
Overall Steps per Second: 10,541.24970

Timestep Collection Time: 2.26572
Timestep Consumption Time: 2.48172
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.74744

Cumulative Model Updates: 89,660
Cumulative Timesteps: 747,873,650

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 747873650...
Checkpoint 747873650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,268.17448
Policy Entropy: 1.88503
Value Function Loss: 0.08869

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.15060
Policy Update Magnitude: 0.54025
Value Function Update Magnitude: 0.73633

Collected Steps per Second: 21,767.11184
Overall Steps per Second: 10,595.42774

Timestep Collection Time: 2.29741
Timestep Consumption Time: 2.42236
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.71977

Cumulative Model Updates: 89,666
Cumulative Timesteps: 747,923,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,912.78488
Policy Entropy: 1.88231
Value Function Loss: 0.09262

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.15799
Policy Update Magnitude: 0.50764
Value Function Update Magnitude: 0.81419

Collected Steps per Second: 22,250.18926
Overall Steps per Second: 10,507.60313

Timestep Collection Time: 2.24852
Timestep Consumption Time: 2.51279
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.76131

Cumulative Model Updates: 89,672
Cumulative Timesteps: 747,973,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 747973688...
Checkpoint 747973688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,604.49469
Policy Entropy: 1.88455
Value Function Loss: 0.09552

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.53005
Value Function Update Magnitude: 0.72978

Collected Steps per Second: 21,910.53791
Overall Steps per Second: 10,619.93865

Timestep Collection Time: 2.28228
Timestep Consumption Time: 2.42641
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.70869

Cumulative Model Updates: 89,678
Cumulative Timesteps: 748,023,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,185.55653
Policy Entropy: 1.87036
Value Function Loss: 0.09368

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.16491
Policy Update Magnitude: 0.51595
Value Function Update Magnitude: 0.68628

Collected Steps per Second: 22,199.42149
Overall Steps per Second: 10,531.30998

Timestep Collection Time: 2.25285
Timestep Consumption Time: 2.49604
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.74889

Cumulative Model Updates: 89,684
Cumulative Timesteps: 748,073,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 748073706...
Checkpoint 748073706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,526.11837
Policy Entropy: 1.87586
Value Function Loss: 0.08545

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15826
Policy Update Magnitude: 0.51295
Value Function Update Magnitude: 0.72851

Collected Steps per Second: 22,199.53024
Overall Steps per Second: 10,576.45238

Timestep Collection Time: 2.25356
Timestep Consumption Time: 2.47657
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.73013

Cumulative Model Updates: 89,690
Cumulative Timesteps: 748,123,734

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,860.15253
Policy Entropy: 1.88027
Value Function Loss: 0.08933

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.15530
Policy Update Magnitude: 0.52898
Value Function Update Magnitude: 0.71527

Collected Steps per Second: 22,380.99021
Overall Steps per Second: 10,513.73794

Timestep Collection Time: 2.23422
Timestep Consumption Time: 2.52185
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.75606

Cumulative Model Updates: 89,696
Cumulative Timesteps: 748,173,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 748173738...
Checkpoint 748173738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,892.86996
Policy Entropy: 1.89317
Value Function Loss: 0.09401

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.14851
Policy Update Magnitude: 0.53122
Value Function Update Magnitude: 0.61271

Collected Steps per Second: 21,979.56917
Overall Steps per Second: 10,583.81153

Timestep Collection Time: 2.27566
Timestep Consumption Time: 2.45024
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.72590

Cumulative Model Updates: 89,702
Cumulative Timesteps: 748,223,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,767.44424
Policy Entropy: 1.89457
Value Function Loss: 0.09969

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.16043
Policy Update Magnitude: 0.52829
Value Function Update Magnitude: 0.52080

Collected Steps per Second: 22,432.26328
Overall Steps per Second: 10,645.33791

Timestep Collection Time: 2.22991
Timestep Consumption Time: 2.46905
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.69896

Cumulative Model Updates: 89,708
Cumulative Timesteps: 748,273,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 748273778...
Checkpoint 748273778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,515.33739
Policy Entropy: 1.89875
Value Function Loss: 0.09825

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.15655
Policy Update Magnitude: 0.52082
Value Function Update Magnitude: 0.48228

Collected Steps per Second: 22,238.57336
Overall Steps per Second: 10,515.38221

Timestep Collection Time: 2.24871
Timestep Consumption Time: 2.50699
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.75570

Cumulative Model Updates: 89,714
Cumulative Timesteps: 748,323,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,389.75895
Policy Entropy: 1.89389
Value Function Loss: 0.10081

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.16722
Policy Update Magnitude: 0.54141
Value Function Update Magnitude: 0.50237

Collected Steps per Second: 22,495.02694
Overall Steps per Second: 10,555.81458

Timestep Collection Time: 2.22378
Timestep Consumption Time: 2.51522
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.73900

Cumulative Model Updates: 89,720
Cumulative Timesteps: 748,373,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 748373810...
Checkpoint 748373810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,512.19191
Policy Entropy: 1.88703
Value Function Loss: 0.10394

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.15528
Policy Update Magnitude: 0.57604
Value Function Update Magnitude: 0.51595

Collected Steps per Second: 22,064.14589
Overall Steps per Second: 10,516.76160

Timestep Collection Time: 2.26694
Timestep Consumption Time: 2.48909
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.75603

Cumulative Model Updates: 89,726
Cumulative Timesteps: 748,423,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,688.40336
Policy Entropy: 1.88923
Value Function Loss: 0.10165

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.14638
Policy Update Magnitude: 0.60141
Value Function Update Magnitude: 0.60563

Collected Steps per Second: 22,100.01292
Overall Steps per Second: 10,468.34182

Timestep Collection Time: 2.26308
Timestep Consumption Time: 2.51457
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.77764

Cumulative Model Updates: 89,732
Cumulative Timesteps: 748,473,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 748473842...
Checkpoint 748473842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,824.41775
Policy Entropy: 1.88524
Value Function Loss: 0.09908

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.60540
Value Function Update Magnitude: 0.71418

Collected Steps per Second: 22,012.30037
Overall Steps per Second: 10,626.59395

Timestep Collection Time: 2.27164
Timestep Consumption Time: 2.43391
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.70555

Cumulative Model Updates: 89,738
Cumulative Timesteps: 748,523,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,018.89679
Policy Entropy: 1.88413
Value Function Loss: 0.10004

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.61774
Value Function Update Magnitude: 0.62456

Collected Steps per Second: 22,577.17245
Overall Steps per Second: 10,796.86400

Timestep Collection Time: 2.21525
Timestep Consumption Time: 2.41702
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.63227

Cumulative Model Updates: 89,744
Cumulative Timesteps: 748,573,860

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 748573860...
Checkpoint 748573860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,396.13307
Policy Entropy: 1.88642
Value Function Loss: 0.10474

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.61878
Value Function Update Magnitude: 0.55747

Collected Steps per Second: 21,842.42787
Overall Steps per Second: 10,433.66764

Timestep Collection Time: 2.28995
Timestep Consumption Time: 2.50396
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.79390

Cumulative Model Updates: 89,750
Cumulative Timesteps: 748,623,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,265.68125
Policy Entropy: 1.89518
Value Function Loss: 0.11306

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.62386
Value Function Update Magnitude: 0.43152

Collected Steps per Second: 22,594.95493
Overall Steps per Second: 10,718.54875

Timestep Collection Time: 2.21306
Timestep Consumption Time: 2.45212
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.66518

Cumulative Model Updates: 89,756
Cumulative Timesteps: 748,673,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 748673882...
Checkpoint 748673882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,504.70539
Policy Entropy: 1.88766
Value Function Loss: 0.11108

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.62013
Value Function Update Magnitude: 0.35728

Collected Steps per Second: 22,081.81731
Overall Steps per Second: 10,613.92591

Timestep Collection Time: 2.26557
Timestep Consumption Time: 2.44786
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.71343

Cumulative Model Updates: 89,762
Cumulative Timesteps: 748,723,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,386.20747
Policy Entropy: 1.88585
Value Function Loss: 0.10960

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13908
Policy Update Magnitude: 0.61368
Value Function Update Magnitude: 0.38484

Collected Steps per Second: 22,702.35053
Overall Steps per Second: 10,556.58669

Timestep Collection Time: 2.20286
Timestep Consumption Time: 2.53447
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.73733

Cumulative Model Updates: 89,768
Cumulative Timesteps: 748,773,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 748773920...
Checkpoint 748773920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,728.88238
Policy Entropy: 1.88248
Value Function Loss: 0.09948

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.60872
Value Function Update Magnitude: 0.43026

Collected Steps per Second: 22,243.58298
Overall Steps per Second: 10,539.79230

Timestep Collection Time: 2.24784
Timestep Consumption Time: 2.49609
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.74393

Cumulative Model Updates: 89,774
Cumulative Timesteps: 748,823,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,616.62871
Policy Entropy: 1.88807
Value Function Loss: 0.08926

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.59185
Value Function Update Magnitude: 0.54506

Collected Steps per Second: 22,405.56538
Overall Steps per Second: 10,513.14031

Timestep Collection Time: 2.23186
Timestep Consumption Time: 2.52467
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.75652

Cumulative Model Updates: 89,780
Cumulative Timesteps: 748,873,926

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 748873926...
Checkpoint 748873926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,720.47631
Policy Entropy: 1.88723
Value Function Loss: 0.08518

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.58428
Value Function Update Magnitude: 0.58127

Collected Steps per Second: 21,969.23508
Overall Steps per Second: 10,586.11583

Timestep Collection Time: 2.27637
Timestep Consumption Time: 2.44775
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.72411

Cumulative Model Updates: 89,786
Cumulative Timesteps: 748,923,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,123.92995
Policy Entropy: 1.88196
Value Function Loss: 0.08661

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.57863
Value Function Update Magnitude: 0.63105

Collected Steps per Second: 22,604.49675
Overall Steps per Second: 10,614.66771

Timestep Collection Time: 2.21221
Timestep Consumption Time: 2.49881
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.71103

Cumulative Model Updates: 89,792
Cumulative Timesteps: 748,973,942

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 748973942...
Checkpoint 748973942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,753.62035
Policy Entropy: 1.88790
Value Function Loss: 0.08955

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13432
Policy Update Magnitude: 0.58566
Value Function Update Magnitude: 0.70163

Collected Steps per Second: 21,989.32310
Overall Steps per Second: 10,473.24647

Timestep Collection Time: 2.27401
Timestep Consumption Time: 2.50044
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.77445

Cumulative Model Updates: 89,798
Cumulative Timesteps: 749,023,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,609.52858
Policy Entropy: 1.88611
Value Function Loss: 0.09348

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13560
Policy Update Magnitude: 0.59842
Value Function Update Magnitude: 0.71445

Collected Steps per Second: 22,289.15971
Overall Steps per Second: 10,488.00135

Timestep Collection Time: 2.24405
Timestep Consumption Time: 2.52502
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.76907

Cumulative Model Updates: 89,804
Cumulative Timesteps: 749,073,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 749073964...
Checkpoint 749073964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,558.27536
Policy Entropy: 1.89064
Value Function Loss: 0.09386

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.60137
Value Function Update Magnitude: 0.73253

Collected Steps per Second: 21,814.38255
Overall Steps per Second: 10,575.72901

Timestep Collection Time: 2.29307
Timestep Consumption Time: 2.43681
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.72989

Cumulative Model Updates: 89,810
Cumulative Timesteps: 749,123,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,677.41148
Policy Entropy: 1.89277
Value Function Loss: 0.09653

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12511
Policy Update Magnitude: 0.60459
Value Function Update Magnitude: 0.66703

Collected Steps per Second: 22,494.83472
Overall Steps per Second: 10,539.48829

Timestep Collection Time: 2.22282
Timestep Consumption Time: 2.52143
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.74425

Cumulative Model Updates: 89,816
Cumulative Timesteps: 749,173,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 749173988...
Checkpoint 749173988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,153.99282
Policy Entropy: 1.90142
Value Function Loss: 0.10075

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.61491
Value Function Update Magnitude: 0.70805

Collected Steps per Second: 22,337.32451
Overall Steps per Second: 10,597.62610

Timestep Collection Time: 2.23903
Timestep Consumption Time: 2.48033
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.71936

Cumulative Model Updates: 89,822
Cumulative Timesteps: 749,224,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,756.04856
Policy Entropy: 1.89137
Value Function Loss: 0.09831

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.61528
Value Function Update Magnitude: 0.69996

Collected Steps per Second: 22,545.95079
Overall Steps per Second: 10,658.91593

Timestep Collection Time: 2.21973
Timestep Consumption Time: 2.47549
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.69522

Cumulative Model Updates: 89,828
Cumulative Timesteps: 749,274,048

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 749274048...
Checkpoint 749274048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,133.43975
Policy Entropy: 1.88773
Value Function Loss: 0.09433

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.60733
Value Function Update Magnitude: 0.73347

Collected Steps per Second: 21,769.62034
Overall Steps per Second: 10,596.78645

Timestep Collection Time: 2.29705
Timestep Consumption Time: 2.42192
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.71898

Cumulative Model Updates: 89,834
Cumulative Timesteps: 749,324,054

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,187.43279
Policy Entropy: 1.87936
Value Function Loss: 0.08720

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.59422
Value Function Update Magnitude: 0.77677

Collected Steps per Second: 21,640.37878
Overall Steps per Second: 10,652.94482

Timestep Collection Time: 2.31188
Timestep Consumption Time: 2.38447
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.69635

Cumulative Model Updates: 89,840
Cumulative Timesteps: 749,374,084

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 749374084...
Checkpoint 749374084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,965.12878
Policy Entropy: 1.87938
Value Function Loss: 0.08600

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.59162
Value Function Update Magnitude: 0.75205

Collected Steps per Second: 21,220.14564
Overall Steps per Second: 10,586.02969

Timestep Collection Time: 2.35625
Timestep Consumption Time: 2.36695
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.72321

Cumulative Model Updates: 89,846
Cumulative Timesteps: 749,424,084

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,907.88994
Policy Entropy: 1.87567
Value Function Loss: 0.08752

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.58982
Value Function Update Magnitude: 0.70256

Collected Steps per Second: 21,670.92831
Overall Steps per Second: 10,557.96874

Timestep Collection Time: 2.30807
Timestep Consumption Time: 2.42940
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.73746

Cumulative Model Updates: 89,852
Cumulative Timesteps: 749,474,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 749474102...
Checkpoint 749474102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,071.92888
Policy Entropy: 1.87037
Value Function Loss: 0.08276

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.58409
Value Function Update Magnitude: 0.62907

Collected Steps per Second: 21,594.61951
Overall Steps per Second: 10,682.10657

Timestep Collection Time: 2.31734
Timestep Consumption Time: 2.36732
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.68466

Cumulative Model Updates: 89,858
Cumulative Timesteps: 749,524,144

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,843.65548
Policy Entropy: 1.87760
Value Function Loss: 0.08615

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.15510
Policy Update Magnitude: 0.55768
Value Function Update Magnitude: 0.58446

Collected Steps per Second: 21,740.18119
Overall Steps per Second: 10,544.67919

Timestep Collection Time: 2.30062
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.74325

Cumulative Model Updates: 89,864
Cumulative Timesteps: 749,574,160

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 749574160...
Checkpoint 749574160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,906.80575
Policy Entropy: 1.86384
Value Function Loss: 0.08716

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.15036
Policy Update Magnitude: 0.49772
Value Function Update Magnitude: 0.59322

Collected Steps per Second: 21,785.77772
Overall Steps per Second: 10,536.84854

Timestep Collection Time: 2.29553
Timestep Consumption Time: 2.45067
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.74620

Cumulative Model Updates: 89,870
Cumulative Timesteps: 749,624,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,915.99062
Policy Entropy: 1.85339
Value Function Loss: 0.09407

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.16326
Policy Update Magnitude: 0.46790
Value Function Update Magnitude: 0.60474

Collected Steps per Second: 22,547.54323
Overall Steps per Second: 10,667.77985

Timestep Collection Time: 2.21780
Timestep Consumption Time: 2.46977
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.68757

Cumulative Model Updates: 89,876
Cumulative Timesteps: 749,674,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 749674176...
Checkpoint 749674176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,432.95414
Policy Entropy: 1.85791
Value Function Loss: 0.09034

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.15743
Policy Update Magnitude: 0.46563
Value Function Update Magnitude: 0.63082

Collected Steps per Second: 21,871.04905
Overall Steps per Second: 10,494.49600

Timestep Collection Time: 2.28695
Timestep Consumption Time: 2.47917
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.76612

Cumulative Model Updates: 89,882
Cumulative Timesteps: 749,724,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,751.04671
Policy Entropy: 1.86612
Value Function Loss: 0.09047

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.15961
Policy Update Magnitude: 0.48682
Value Function Update Magnitude: 0.74552

Collected Steps per Second: 22,252.60515
Overall Steps per Second: 10,578.50574

Timestep Collection Time: 2.24783
Timestep Consumption Time: 2.48063
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.72846

Cumulative Model Updates: 89,888
Cumulative Timesteps: 749,774,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 749774214...
Checkpoint 749774214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,503.19848
Policy Entropy: 1.86141
Value Function Loss: 0.09221

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.15423
Policy Update Magnitude: 0.51102
Value Function Update Magnitude: 0.80182

Collected Steps per Second: 22,226.42399
Overall Steps per Second: 10,575.63351

Timestep Collection Time: 2.24984
Timestep Consumption Time: 2.47857
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.72842

Cumulative Model Updates: 89,894
Cumulative Timesteps: 749,824,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,879.60979
Policy Entropy: 1.85958
Value Function Loss: 0.09884

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.16023
Policy Update Magnitude: 0.50396
Value Function Update Magnitude: 0.80222

Collected Steps per Second: 22,541.44340
Overall Steps per Second: 10,811.09757

Timestep Collection Time: 2.21858
Timestep Consumption Time: 2.40722
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.62580

Cumulative Model Updates: 89,900
Cumulative Timesteps: 749,874,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 749874230...
Checkpoint 749874230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,277.94944
Policy Entropy: 1.86334
Value Function Loss: 0.10621

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.16683
Policy Update Magnitude: 0.52142
Value Function Update Magnitude: 0.71724

Collected Steps per Second: 22,375.71787
Overall Steps per Second: 10,564.84748

Timestep Collection Time: 2.23600
Timestep Consumption Time: 2.49971
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.73570

Cumulative Model Updates: 89,906
Cumulative Timesteps: 749,924,262

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,158.36041
Policy Entropy: 1.87492
Value Function Loss: 0.10455

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.15884
Policy Update Magnitude: 0.52578
Value Function Update Magnitude: 0.73597

Collected Steps per Second: 22,101.67149
Overall Steps per Second: 10,425.57975

Timestep Collection Time: 2.26363
Timestep Consumption Time: 2.53514
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.79877

Cumulative Model Updates: 89,912
Cumulative Timesteps: 749,974,292

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 749974292...
Checkpoint 749974292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,298.44816
Policy Entropy: 1.86737
Value Function Loss: 0.10365

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14353
Policy Update Magnitude: 0.56830
Value Function Update Magnitude: 0.77250

Collected Steps per Second: 21,861.16712
Overall Steps per Second: 10,620.38494

Timestep Collection Time: 2.28780
Timestep Consumption Time: 2.42144
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.70925

Cumulative Model Updates: 89,918
Cumulative Timesteps: 750,024,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,145.33253
Policy Entropy: 1.88637
Value Function Loss: 0.09410

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.59701
Value Function Update Magnitude: 0.81230

Collected Steps per Second: 22,319.12900
Overall Steps per Second: 10,532.48004

Timestep Collection Time: 2.24032
Timestep Consumption Time: 2.50709
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.74741

Cumulative Model Updates: 89,924
Cumulative Timesteps: 750,074,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 750074308...
Checkpoint 750074308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,988.09281
Policy Entropy: 1.87402
Value Function Loss: 0.08853

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.59016
Value Function Update Magnitude: 0.78821

Collected Steps per Second: 22,419.33060
Overall Steps per Second: 10,634.63787

Timestep Collection Time: 2.23084
Timestep Consumption Time: 2.47209
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.70293

Cumulative Model Updates: 89,930
Cumulative Timesteps: 750,124,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,415.21538
Policy Entropy: 1.88261
Value Function Loss: 0.09065

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.59408
Value Function Update Magnitude: 0.70409

Collected Steps per Second: 22,267.21242
Overall Steps per Second: 10,447.14481

Timestep Collection Time: 2.24671
Timestep Consumption Time: 2.54197
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.78868

Cumulative Model Updates: 89,936
Cumulative Timesteps: 750,174,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 750174350...
Checkpoint 750174350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,417.94892
Policy Entropy: 1.86556
Value Function Loss: 0.08962

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.14054
Policy Update Magnitude: 0.57705
Value Function Update Magnitude: 0.66756

Collected Steps per Second: 22,443.86053
Overall Steps per Second: 10,718.02845

Timestep Collection Time: 2.22992
Timestep Consumption Time: 2.43960
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.66952

Cumulative Model Updates: 89,942
Cumulative Timesteps: 750,224,398

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,320.71841
Policy Entropy: 1.87718
Value Function Loss: 0.09060

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.57539
Value Function Update Magnitude: 0.70964

Collected Steps per Second: 22,443.32032
Overall Steps per Second: 10,552.70126

Timestep Collection Time: 2.22881
Timestep Consumption Time: 2.51139
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.74021

Cumulative Model Updates: 89,948
Cumulative Timesteps: 750,274,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 750274420...
Checkpoint 750274420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,020.29215
Policy Entropy: 1.87336
Value Function Loss: 0.08859

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.58877
Value Function Update Magnitude: 0.69828

Collected Steps per Second: 22,376.14509
Overall Steps per Second: 10,629.55004

Timestep Collection Time: 2.23506
Timestep Consumption Time: 2.46994
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.70500

Cumulative Model Updates: 89,954
Cumulative Timesteps: 750,324,432

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,315.41171
Policy Entropy: 1.87978
Value Function Loss: 0.09318

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.59953
Value Function Update Magnitude: 0.65020

Collected Steps per Second: 22,676.36707
Overall Steps per Second: 10,728.51954

Timestep Collection Time: 2.20600
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.66271

Cumulative Model Updates: 89,960
Cumulative Timesteps: 750,374,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 750374456...
Checkpoint 750374456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,838.04082
Policy Entropy: 1.88133
Value Function Loss: 0.09871

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.58635
Value Function Update Magnitude: 0.55020

Collected Steps per Second: 21,919.25160
Overall Steps per Second: 9,931.54463

Timestep Collection Time: 2.28156
Timestep Consumption Time: 2.75391
PPO Batch Consumption Time: 0.32907
Total Iteration Time: 5.03547

Cumulative Model Updates: 89,966
Cumulative Timesteps: 750,424,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,886.84127
Policy Entropy: 1.87067
Value Function Loss: 0.09780

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.15475
Policy Update Magnitude: 0.54456
Value Function Update Magnitude: 0.45596

Collected Steps per Second: 9,136.91506
Overall Steps per Second: 5,880.78917

Timestep Collection Time: 5.47340
Timestep Consumption Time: 3.03056
PPO Batch Consumption Time: 0.33096
Total Iteration Time: 8.50396

Cumulative Model Updates: 89,972
Cumulative Timesteps: 750,474,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 750474476...
Checkpoint 750474476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,044.54327
Policy Entropy: 1.87036
Value Function Loss: 0.08952

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.53979
Value Function Update Magnitude: 0.50491

Collected Steps per Second: 20,533.09028
Overall Steps per Second: 10,028.96836

Timestep Collection Time: 2.43617
Timestep Consumption Time: 2.55159
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.98775

Cumulative Model Updates: 89,978
Cumulative Timesteps: 750,524,498

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,170.19987
Policy Entropy: 1.86245
Value Function Loss: 0.08572

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.15576
Policy Update Magnitude: 0.50822
Value Function Update Magnitude: 0.57412

Collected Steps per Second: 22,163.81608
Overall Steps per Second: 10,364.83013

Timestep Collection Time: 2.25737
Timestep Consumption Time: 2.56972
PPO Batch Consumption Time: 0.29901
Total Iteration Time: 4.82709

Cumulative Model Updates: 89,984
Cumulative Timesteps: 750,574,530

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 750574530...
Checkpoint 750574530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,826.98512
Policy Entropy: 1.85315
Value Function Loss: 0.08797

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.15807
Policy Update Magnitude: 0.47506
Value Function Update Magnitude: 0.60077

Collected Steps per Second: 21,616.21457
Overall Steps per Second: 10,376.35906

Timestep Collection Time: 2.31410
Timestep Consumption Time: 2.50667
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.82077

Cumulative Model Updates: 89,990
Cumulative Timesteps: 750,624,552

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,582.46621
Policy Entropy: 1.85550
Value Function Loss: 0.09127

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.15264
Policy Update Magnitude: 0.49341
Value Function Update Magnitude: 0.71267

Collected Steps per Second: 22,397.48046
Overall Steps per Second: 10,745.37818

Timestep Collection Time: 2.23355
Timestep Consumption Time: 2.42203
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.65558

Cumulative Model Updates: 89,996
Cumulative Timesteps: 750,674,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 750674578...
Checkpoint 750674578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,952.85952
Policy Entropy: 1.85412
Value Function Loss: 0.09019

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.15364
Policy Update Magnitude: 0.46933
Value Function Update Magnitude: 0.75387

Collected Steps per Second: 21,237.46633
Overall Steps per Second: 10,238.11541

Timestep Collection Time: 2.35471
Timestep Consumption Time: 2.52979
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.88449

Cumulative Model Updates: 90,002
Cumulative Timesteps: 750,724,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,198.79800
Policy Entropy: 1.86165
Value Function Loss: 0.09222

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.51235
Value Function Update Magnitude: 0.72508

Collected Steps per Second: 22,114.99026
Overall Steps per Second: 10,501.72377

Timestep Collection Time: 2.26245
Timestep Consumption Time: 2.50191
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.76436

Cumulative Model Updates: 90,008
Cumulative Timesteps: 750,774,620

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 750774620...
Checkpoint 750774620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,500.17099
Policy Entropy: 1.87324
Value Function Loss: 0.09131

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13808
Policy Update Magnitude: 0.57663
Value Function Update Magnitude: 0.65879

Collected Steps per Second: 22,091.57515
Overall Steps per Second: 10,621.50633

Timestep Collection Time: 2.26430
Timestep Consumption Time: 2.44520
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.70950

Cumulative Model Updates: 90,014
Cumulative Timesteps: 750,824,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,881.88141
Policy Entropy: 1.88358
Value Function Loss: 0.09156

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.58961
Value Function Update Magnitude: 0.68419

Collected Steps per Second: 22,179.56364
Overall Steps per Second: 10,441.58964

Timestep Collection Time: 2.25496
Timestep Consumption Time: 2.53492
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.78988

Cumulative Model Updates: 90,020
Cumulative Timesteps: 750,874,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 750874656...
Checkpoint 750874656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,394.68044
Policy Entropy: 1.87742
Value Function Loss: 0.09168

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.58367
Value Function Update Magnitude: 0.70049

Collected Steps per Second: 21,819.21513
Overall Steps per Second: 10,552.07292

Timestep Collection Time: 2.29165
Timestep Consumption Time: 2.44695
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.73859

Cumulative Model Updates: 90,026
Cumulative Timesteps: 750,924,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,889.49121
Policy Entropy: 1.85286
Value Function Loss: 0.08893

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.58273
Value Function Update Magnitude: 0.65822

Collected Steps per Second: 22,312.12470
Overall Steps per Second: 10,468.20766

Timestep Collection Time: 2.24201
Timestep Consumption Time: 2.53665
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.77866

Cumulative Model Updates: 90,032
Cumulative Timesteps: 750,974,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 750974682...
Checkpoint 750974682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,655.74405
Policy Entropy: 1.85285
Value Function Loss: 0.08940

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.58550
Value Function Update Magnitude: 0.62662

Collected Steps per Second: 21,937.88224
Overall Steps per Second: 10,562.12535

Timestep Collection Time: 2.27962
Timestep Consumption Time: 2.45522
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.73484

Cumulative Model Updates: 90,038
Cumulative Timesteps: 751,024,692

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,537.77981
Policy Entropy: 1.84502
Value Function Loss: 0.09067

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.57644
Value Function Update Magnitude: 0.58439

Collected Steps per Second: 22,076.56729
Overall Steps per Second: 10,538.56380

Timestep Collection Time: 2.26575
Timestep Consumption Time: 2.48063
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.74638

Cumulative Model Updates: 90,044
Cumulative Timesteps: 751,074,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 751074712...
Checkpoint 751074712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,891.76202
Policy Entropy: 1.84639
Value Function Loss: 0.09223

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.58798
Value Function Update Magnitude: 0.57524

Collected Steps per Second: 21,548.13698
Overall Steps per Second: 10,358.82378

Timestep Collection Time: 2.32150
Timestep Consumption Time: 2.50762
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.82912

Cumulative Model Updates: 90,050
Cumulative Timesteps: 751,124,736

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,684.04467
Policy Entropy: 1.84547
Value Function Loss: 0.08585

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.57673
Value Function Update Magnitude: 0.61082

Collected Steps per Second: 21,934.37119
Overall Steps per Second: 10,351.47469

Timestep Collection Time: 2.27998
Timestep Consumption Time: 2.55121
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.83120

Cumulative Model Updates: 90,056
Cumulative Timesteps: 751,174,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 751174746...
Checkpoint 751174746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,680.49333
Policy Entropy: 1.84184
Value Function Loss: 0.08871

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.58597
Value Function Update Magnitude: 0.69029

Collected Steps per Second: 21,911.80882
Overall Steps per Second: 10,564.29194

Timestep Collection Time: 2.28260
Timestep Consumption Time: 2.45183
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.73444

Cumulative Model Updates: 90,062
Cumulative Timesteps: 751,224,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,981.35907
Policy Entropy: 1.84771
Value Function Loss: 0.08871

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.59808
Value Function Update Magnitude: 0.75816

Collected Steps per Second: 22,291.32617
Overall Steps per Second: 10,480.22298

Timestep Collection Time: 2.24338
Timestep Consumption Time: 2.52827
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.77165

Cumulative Model Updates: 90,068
Cumulative Timesteps: 751,274,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 751274770...
Checkpoint 751274770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,283.91591
Policy Entropy: 1.86046
Value Function Loss: 0.09505

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.60052
Value Function Update Magnitude: 0.72827

Collected Steps per Second: 21,709.24919
Overall Steps per Second: 10,407.35636

Timestep Collection Time: 2.30390
Timestep Consumption Time: 2.50193
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.80583

Cumulative Model Updates: 90,074
Cumulative Timesteps: 751,324,786

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,706.43338
Policy Entropy: 1.86520
Value Function Loss: 0.09724

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.60562
Value Function Update Magnitude: 0.67912

Collected Steps per Second: 22,459.91518
Overall Steps per Second: 10,638.41800

Timestep Collection Time: 2.22735
Timestep Consumption Time: 2.47505
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.70239

Cumulative Model Updates: 90,080
Cumulative Timesteps: 751,374,812

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 751374812...
Checkpoint 751374812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,233.23071
Policy Entropy: 1.85880
Value Function Loss: 0.09264

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.59594
Value Function Update Magnitude: 0.67029

Collected Steps per Second: 21,951.44492
Overall Steps per Second: 10,438.71397

Timestep Collection Time: 2.27876
Timestep Consumption Time: 2.51321
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.79197

Cumulative Model Updates: 90,086
Cumulative Timesteps: 751,424,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,428.68548
Policy Entropy: 1.85200
Value Function Loss: 0.08966

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.59336
Value Function Update Magnitude: 0.63498

Collected Steps per Second: 22,629.91757
Overall Steps per Second: 10,753.69412

Timestep Collection Time: 2.20955
Timestep Consumption Time: 2.44020
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.64975

Cumulative Model Updates: 90,092
Cumulative Timesteps: 751,474,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 751474836...
Checkpoint 751474836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,616.71638
Policy Entropy: 1.85492
Value Function Loss: 0.08707

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.56561
Value Function Update Magnitude: 0.60507

Collected Steps per Second: 21,743.45531
Overall Steps per Second: 10,538.82148

Timestep Collection Time: 2.30065
Timestep Consumption Time: 2.44599
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.74664

Cumulative Model Updates: 90,098
Cumulative Timesteps: 751,524,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,157.49770
Policy Entropy: 1.85827
Value Function Loss: 0.09422

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.14126
Policy Update Magnitude: 0.57371
Value Function Update Magnitude: 0.67660

Collected Steps per Second: 22,273.30822
Overall Steps per Second: 10,493.74275

Timestep Collection Time: 2.24493
Timestep Consumption Time: 2.52001
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.76493

Cumulative Model Updates: 90,104
Cumulative Timesteps: 751,574,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 751574862...
Checkpoint 751574862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,676.92914
Policy Entropy: 1.85586
Value Function Loss: 0.08849

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.15566
Policy Update Magnitude: 0.52176
Value Function Update Magnitude: 0.71939

Collected Steps per Second: 21,801.05200
Overall Steps per Second: 10,409.44807

Timestep Collection Time: 2.29393
Timestep Consumption Time: 2.51036
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.80429

Cumulative Model Updates: 90,110
Cumulative Timesteps: 751,624,872

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,740.46056
Policy Entropy: 1.84809
Value Function Loss: 0.08534

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.15305
Policy Update Magnitude: 0.47385
Value Function Update Magnitude: 0.70317

Collected Steps per Second: 22,471.69095
Overall Steps per Second: 10,698.77944

Timestep Collection Time: 2.22502
Timestep Consumption Time: 2.44841
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.67343

Cumulative Model Updates: 90,116
Cumulative Timesteps: 751,674,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 751674872...
Checkpoint 751674872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,895.46451
Policy Entropy: 1.84087
Value Function Loss: 0.07603

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13668
Policy Update Magnitude: 0.49569
Value Function Update Magnitude: 0.65787

Collected Steps per Second: 21,547.37641
Overall Steps per Second: 10,369.59577

Timestep Collection Time: 2.32186
Timestep Consumption Time: 2.50282
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.82468

Cumulative Model Updates: 90,122
Cumulative Timesteps: 751,724,902

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,397.78644
Policy Entropy: 1.84017
Value Function Loss: 0.08054

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.53123
Value Function Update Magnitude: 0.64091

Collected Steps per Second: 21,843.42066
Overall Steps per Second: 10,387.86485

Timestep Collection Time: 2.28966
Timestep Consumption Time: 2.52500
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.81466

Cumulative Model Updates: 90,128
Cumulative Timesteps: 751,774,916

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 751774916...
Checkpoint 751774916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,245.86079
Policy Entropy: 1.83877
Value Function Loss: 0.08540

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.53237
Value Function Update Magnitude: 0.59152

Collected Steps per Second: 20,375.30603
Overall Steps per Second: 10,245.58650

Timestep Collection Time: 2.45552
Timestep Consumption Time: 2.42775
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.88327

Cumulative Model Updates: 90,134
Cumulative Timesteps: 751,824,948

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,652.81400
Policy Entropy: 1.84580
Value Function Loss: 0.08881

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.13076
Policy Update Magnitude: 0.57008
Value Function Update Magnitude: 0.56167

Collected Steps per Second: 21,574.12902
Overall Steps per Second: 10,546.04632

Timestep Collection Time: 2.31852
Timestep Consumption Time: 2.42449
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.74301

Cumulative Model Updates: 90,140
Cumulative Timesteps: 751,874,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 751874968...
Checkpoint 751874968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,080.87057
Policy Entropy: 1.85799
Value Function Loss: 0.08767

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.57624
Value Function Update Magnitude: 0.48681

Collected Steps per Second: 21,284.99303
Overall Steps per Second: 10,419.51909

Timestep Collection Time: 2.34954
Timestep Consumption Time: 2.45010
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.79965

Cumulative Model Updates: 90,146
Cumulative Timesteps: 751,924,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,256.55175
Policy Entropy: 1.86573
Value Function Loss: 0.08677

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.13106
Policy Update Magnitude: 0.57949
Value Function Update Magnitude: 0.61305

Collected Steps per Second: 21,661.65732
Overall Steps per Second: 10,494.31207

Timestep Collection Time: 2.30832
Timestep Consumption Time: 2.45636
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.76468

Cumulative Model Updates: 90,152
Cumulative Timesteps: 751,974,980

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 751974980...
Checkpoint 751974980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,565.99804
Policy Entropy: 1.87216
Value Function Loss: 0.09226

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.58534
Value Function Update Magnitude: 0.65160

Collected Steps per Second: 21,078.61816
Overall Steps per Second: 10,533.42514

Timestep Collection Time: 2.37264
Timestep Consumption Time: 2.37529
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.74793

Cumulative Model Updates: 90,158
Cumulative Timesteps: 752,024,992

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,631.80792
Policy Entropy: 1.86219
Value Function Loss: 0.09301

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13763
Policy Update Magnitude: 0.58556
Value Function Update Magnitude: 0.65331

Collected Steps per Second: 21,607.33421
Overall Steps per Second: 10,561.27462

Timestep Collection Time: 2.31449
Timestep Consumption Time: 2.42073
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.73522

Cumulative Model Updates: 90,164
Cumulative Timesteps: 752,075,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 752075002...
Checkpoint 752075002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,264.98225
Policy Entropy: 1.86279
Value Function Loss: 0.09306

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.57962
Value Function Update Magnitude: 0.62907

Collected Steps per Second: 21,219.88764
Overall Steps per Second: 10,567.53867

Timestep Collection Time: 2.35637
Timestep Consumption Time: 2.37529
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.73166

Cumulative Model Updates: 90,170
Cumulative Timesteps: 752,125,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,487.68291
Policy Entropy: 1.84865
Value Function Loss: 0.08949

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.56659
Value Function Update Magnitude: 0.57408

Collected Steps per Second: 21,725.46879
Overall Steps per Second: 10,566.85906

Timestep Collection Time: 2.30191
Timestep Consumption Time: 2.43081
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.73272

Cumulative Model Updates: 90,176
Cumulative Timesteps: 752,175,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 752175014...
Checkpoint 752175014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,130.66592
Policy Entropy: 1.84566
Value Function Loss: 0.08482

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.56168
Value Function Update Magnitude: 0.54177

Collected Steps per Second: 21,999.44025
Overall Steps per Second: 10,560.42485

Timestep Collection Time: 2.27279
Timestep Consumption Time: 2.46187
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.73466

Cumulative Model Updates: 90,182
Cumulative Timesteps: 752,225,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,150.16299
Policy Entropy: 1.84365
Value Function Loss: 0.08398

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.56348
Value Function Update Magnitude: 0.60134

Collected Steps per Second: 22,379.04609
Overall Steps per Second: 10,583.38447

Timestep Collection Time: 2.23468
Timestep Consumption Time: 2.49065
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.72533

Cumulative Model Updates: 90,188
Cumulative Timesteps: 752,275,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 752275024...
Checkpoint 752275024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,952.43198
Policy Entropy: 1.85138
Value Function Loss: 0.08300

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.57400
Value Function Update Magnitude: 0.63280

Collected Steps per Second: 21,420.58195
Overall Steps per Second: 10,508.76620

Timestep Collection Time: 2.33486
Timestep Consumption Time: 2.42441
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.75926

Cumulative Model Updates: 90,194
Cumulative Timesteps: 752,325,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,518.62049
Policy Entropy: 1.83409
Value Function Loss: 0.08457

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.56516
Value Function Update Magnitude: 0.68148

Collected Steps per Second: 22,079.32278
Overall Steps per Second: 10,427.48390

Timestep Collection Time: 2.26565
Timestep Consumption Time: 2.53167
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.79732

Cumulative Model Updates: 90,200
Cumulative Timesteps: 752,375,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 752375062...
Checkpoint 752375062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,869.29969
Policy Entropy: 1.81577
Value Function Loss: 0.08368

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.57345
Value Function Update Magnitude: 0.70450

Collected Steps per Second: 21,710.09605
Overall Steps per Second: 10,239.82085

Timestep Collection Time: 2.30409
Timestep Consumption Time: 2.58096
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.88505

Cumulative Model Updates: 90,206
Cumulative Timesteps: 752,425,084

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,270.78761
Policy Entropy: 1.79418
Value Function Loss: 0.08618

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.57638
Value Function Update Magnitude: 0.69454

Collected Steps per Second: 21,972.49454
Overall Steps per Second: 10,484.70344

Timestep Collection Time: 2.27676
Timestep Consumption Time: 2.49458
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.77133

Cumulative Model Updates: 90,212
Cumulative Timesteps: 752,475,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 752475110...
Checkpoint 752475110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,793.92129
Policy Entropy: 1.81095
Value Function Loss: 0.08468

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.15715
Policy Update Magnitude: 0.55721
Value Function Update Magnitude: 0.68076

Collected Steps per Second: 21,673.81878
Overall Steps per Second: 10,512.45762

Timestep Collection Time: 2.30813
Timestep Consumption Time: 2.45060
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.75873

Cumulative Model Updates: 90,218
Cumulative Timesteps: 752,525,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,026.79086
Policy Entropy: 1.80674
Value Function Loss: 0.08514

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.16252
Policy Update Magnitude: 0.50571
Value Function Update Magnitude: 0.66771

Collected Steps per Second: 22,231.50929
Overall Steps per Second: 10,537.23981

Timestep Collection Time: 2.25068
Timestep Consumption Time: 2.49781
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.74849

Cumulative Model Updates: 90,224
Cumulative Timesteps: 752,575,172

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 752575172...
Checkpoint 752575172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,926.76879
Policy Entropy: 1.81536
Value Function Loss: 0.08582

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.49869
Value Function Update Magnitude: 0.68681

Collected Steps per Second: 21,846.29670
Overall Steps per Second: 10,558.88184

Timestep Collection Time: 2.29073
Timestep Consumption Time: 2.44879
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.73952

Cumulative Model Updates: 90,230
Cumulative Timesteps: 752,625,216

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,955.01722
Policy Entropy: 1.80383
Value Function Loss: 0.08598

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.14282
Policy Update Magnitude: 0.52586
Value Function Update Magnitude: 0.70056

Collected Steps per Second: 22,106.42903
Overall Steps per Second: 10,552.26591

Timestep Collection Time: 2.26233
Timestep Consumption Time: 2.47713
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.73946

Cumulative Model Updates: 90,236
Cumulative Timesteps: 752,675,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 752675228...
Checkpoint 752675228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,156.52626
Policy Entropy: 1.80562
Value Function Loss: 0.09571

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.57222
Value Function Update Magnitude: 0.71634

Collected Steps per Second: 21,659.97912
Overall Steps per Second: 10,352.70376

Timestep Collection Time: 2.30914
Timestep Consumption Time: 2.52206
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.83120

Cumulative Model Updates: 90,242
Cumulative Timesteps: 752,725,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,400.75102
Policy Entropy: 1.80257
Value Function Loss: 0.09183

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.56708
Value Function Update Magnitude: 0.68185

Collected Steps per Second: 22,494.75588
Overall Steps per Second: 10,682.68200

Timestep Collection Time: 2.22292
Timestep Consumption Time: 2.45793
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.68085

Cumulative Model Updates: 90,248
Cumulative Timesteps: 752,775,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 752775248...
Checkpoint 752775248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,317.56069
Policy Entropy: 1.80480
Value Function Loss: 0.08713

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.17239
Policy Update Magnitude: 0.50536
Value Function Update Magnitude: 0.65779

Collected Steps per Second: 22,031.21185
Overall Steps per Second: 10,468.83704

Timestep Collection Time: 2.27078
Timestep Consumption Time: 2.50798
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.77875

Cumulative Model Updates: 90,254
Cumulative Timesteps: 752,825,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,162.12379
Policy Entropy: 1.80462
Value Function Loss: 0.08502

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.14632
Policy Update Magnitude: 0.45218
Value Function Update Magnitude: 0.67467

Collected Steps per Second: 22,482.88559
Overall Steps per Second: 10,696.48431

Timestep Collection Time: 2.22498
Timestep Consumption Time: 2.45170
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.67668

Cumulative Model Updates: 90,260
Cumulative Timesteps: 752,875,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 752875300...
Checkpoint 752875300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,446.66524
Policy Entropy: 1.80902
Value Function Loss: 0.08673

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.49703
Value Function Update Magnitude: 0.74595

Collected Steps per Second: 22,000.98559
Overall Steps per Second: 10,450.65154

Timestep Collection Time: 2.27335
Timestep Consumption Time: 2.51257
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.78592

Cumulative Model Updates: 90,266
Cumulative Timesteps: 752,925,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,766.35451
Policy Entropy: 1.80789
Value Function Loss: 0.08333

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.54830
Value Function Update Magnitude: 0.69325

Collected Steps per Second: 21,419.17267
Overall Steps per Second: 10,254.06829

Timestep Collection Time: 2.33473
Timestep Consumption Time: 2.54216
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.87689

Cumulative Model Updates: 90,272
Cumulative Timesteps: 752,975,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 752975324...
Checkpoint 752975324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,591.26870
Policy Entropy: 1.81286
Value Function Loss: 0.08114

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.55294
Value Function Update Magnitude: 0.64806

Collected Steps per Second: 21,805.37141
Overall Steps per Second: 10,526.74821

Timestep Collection Time: 2.29393
Timestep Consumption Time: 2.45777
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.75170

Cumulative Model Updates: 90,278
Cumulative Timesteps: 753,025,344

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,569.43170
Policy Entropy: 1.83179
Value Function Loss: 0.08360

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.13220
Policy Update Magnitude: 0.56496
Value Function Update Magnitude: 0.62875

Collected Steps per Second: 21,939.52953
Overall Steps per Second: 10,454.61759

Timestep Collection Time: 2.27908
Timestep Consumption Time: 2.50368
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.78277

Cumulative Model Updates: 90,284
Cumulative Timesteps: 753,075,346

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 753075346...
Checkpoint 753075346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,674.63291
Policy Entropy: 1.83738
Value Function Loss: 0.08585

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.13210
Policy Update Magnitude: 0.57795
Value Function Update Magnitude: 0.51517

Collected Steps per Second: 21,378.40368
Overall Steps per Second: 10,339.83571

Timestep Collection Time: 2.34031
Timestep Consumption Time: 2.49846
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.83876

Cumulative Model Updates: 90,290
Cumulative Timesteps: 753,125,378

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,607.88598
Policy Entropy: 1.83716
Value Function Loss: 0.08950

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.57819
Value Function Update Magnitude: 0.46456

Collected Steps per Second: 22,103.87478
Overall Steps per Second: 10,412.69737

Timestep Collection Time: 2.26322
Timestep Consumption Time: 2.54110
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.80433

Cumulative Model Updates: 90,296
Cumulative Timesteps: 753,175,404

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 753175404...
Checkpoint 753175404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,251.66956
Policy Entropy: 1.81082
Value Function Loss: 0.08091

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.14583
Policy Update Magnitude: 0.57213
Value Function Update Magnitude: 0.59753

Collected Steps per Second: 22,016.73562
Overall Steps per Second: 10,582.17353

Timestep Collection Time: 2.27236
Timestep Consumption Time: 2.45540
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.72776

Cumulative Model Updates: 90,302
Cumulative Timesteps: 753,225,434

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,150.89226
Policy Entropy: 1.81111
Value Function Loss: 0.08264

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14616
Policy Update Magnitude: 0.56781
Value Function Update Magnitude: 0.62872

Collected Steps per Second: 22,237.29298
Overall Steps per Second: 10,533.00278

Timestep Collection Time: 2.25027
Timestep Consumption Time: 2.50051
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.75078

Cumulative Model Updates: 90,308
Cumulative Timesteps: 753,275,474

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 753275474...
Checkpoint 753275474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,465.18838
Policy Entropy: 1.81324
Value Function Loss: 0.08854

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.15855
Policy Update Magnitude: 0.55758
Value Function Update Magnitude: 0.56990

Collected Steps per Second: 22,077.44033
Overall Steps per Second: 10,577.29703

Timestep Collection Time: 2.26476
Timestep Consumption Time: 2.46235
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.72711

Cumulative Model Updates: 90,314
Cumulative Timesteps: 753,325,474

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,832.19648
Policy Entropy: 1.81325
Value Function Loss: 0.09089

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.17650
Policy Update Magnitude: 0.50601
Value Function Update Magnitude: 0.62244

Collected Steps per Second: 22,348.19723
Overall Steps per Second: 10,486.52810

Timestep Collection Time: 2.23767
Timestep Consumption Time: 2.53111
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.76879

Cumulative Model Updates: 90,320
Cumulative Timesteps: 753,375,482

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 753375482...
Checkpoint 753375482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,252.12853
Policy Entropy: 1.81634
Value Function Loss: 0.08520

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.15617
Policy Update Magnitude: 0.46659
Value Function Update Magnitude: 0.70006

Collected Steps per Second: 21,637.45531
Overall Steps per Second: 10,347.05088

Timestep Collection Time: 2.31173
Timestep Consumption Time: 2.52250
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.83423

Cumulative Model Updates: 90,326
Cumulative Timesteps: 753,425,502

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,650.69026
Policy Entropy: 1.81939
Value Function Loss: 0.08239

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.48354
Value Function Update Magnitude: 0.66938

Collected Steps per Second: 22,170.36685
Overall Steps per Second: 10,422.96041

Timestep Collection Time: 2.25580
Timestep Consumption Time: 2.54245
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.79825

Cumulative Model Updates: 90,332
Cumulative Timesteps: 753,475,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 753475514...
Checkpoint 753475514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,722.70438
Policy Entropy: 1.82378
Value Function Loss: 0.08586

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.15047
Policy Update Magnitude: 0.49072
Value Function Update Magnitude: 0.63538

Collected Steps per Second: 21,970.83272
Overall Steps per Second: 10,565.92026

Timestep Collection Time: 2.27629
Timestep Consumption Time: 2.45704
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.73333

Cumulative Model Updates: 90,338
Cumulative Timesteps: 753,525,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,215.50407
Policy Entropy: 1.82072
Value Function Loss: 0.08584

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.17302
Policy Update Magnitude: 0.48817
Value Function Update Magnitude: 0.67445

Collected Steps per Second: 21,883.26109
Overall Steps per Second: 10,416.93206

Timestep Collection Time: 2.28503
Timestep Consumption Time: 2.51523
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.80026

Cumulative Model Updates: 90,344
Cumulative Timesteps: 753,575,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 753575530...
Checkpoint 753575530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,010.46580
Policy Entropy: 1.82477
Value Function Loss: 0.08135

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.16695
Policy Update Magnitude: 0.51034
Value Function Update Magnitude: 0.67700

Collected Steps per Second: 21,802.71075
Overall Steps per Second: 10,408.34269

Timestep Collection Time: 2.29439
Timestep Consumption Time: 2.51175
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.80614

Cumulative Model Updates: 90,350
Cumulative Timesteps: 753,625,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,284.91861
Policy Entropy: 1.82090
Value Function Loss: 0.08281

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.14875
Policy Update Magnitude: 0.53092
Value Function Update Magnitude: 0.57268

Collected Steps per Second: 22,590.85063
Overall Steps per Second: 10,689.63677

Timestep Collection Time: 2.21355
Timestep Consumption Time: 2.46444
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.67799

Cumulative Model Updates: 90,356
Cumulative Timesteps: 753,675,560

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 753675560...
Checkpoint 753675560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,025.65010
Policy Entropy: 1.81357
Value Function Loss: 0.08395

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.50290

Collected Steps per Second: 21,966.65226
Overall Steps per Second: 10,441.15727

Timestep Collection Time: 2.27672
Timestep Consumption Time: 2.51317
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.78989

Cumulative Model Updates: 90,362
Cumulative Timesteps: 753,725,572

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,277.23719
Policy Entropy: 1.80249
Value Function Loss: 0.08489

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.55718
Value Function Update Magnitude: 0.51702

Collected Steps per Second: 22,372.74006
Overall Steps per Second: 10,650.84460

Timestep Collection Time: 2.23647
Timestep Consumption Time: 2.46137
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.69784

Cumulative Model Updates: 90,368
Cumulative Timesteps: 753,775,608

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 753775608...
Checkpoint 753775608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,790.47286
Policy Entropy: 1.80377
Value Function Loss: 0.08111

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.55649
Value Function Update Magnitude: 0.59927

Collected Steps per Second: 21,763.78770
Overall Steps per Second: 10,320.21347

Timestep Collection Time: 2.29776
Timestep Consumption Time: 2.54787
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.84564

Cumulative Model Updates: 90,374
Cumulative Timesteps: 753,825,616

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,227.10798
Policy Entropy: 1.82093
Value Function Loss: 0.08511

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.54121
Value Function Update Magnitude: 0.57648

Collected Steps per Second: 22,037.77317
Overall Steps per Second: 10,402.13347

Timestep Collection Time: 2.26956
Timestep Consumption Time: 2.53869
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.80824

Cumulative Model Updates: 90,380
Cumulative Timesteps: 753,875,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 753875632...
Checkpoint 753875632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,130.96543
Policy Entropy: 1.84852
Value Function Loss: 0.09562

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.55742
Value Function Update Magnitude: 0.63364

Collected Steps per Second: 21,073.00087
Overall Steps per Second: 10,153.15180

Timestep Collection Time: 2.37375
Timestep Consumption Time: 2.55300
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.92675

Cumulative Model Updates: 90,386
Cumulative Timesteps: 753,925,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,353.06556
Policy Entropy: 1.85456
Value Function Loss: 0.09509

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.58391
Value Function Update Magnitude: 0.70537

Collected Steps per Second: 22,382.80531
Overall Steps per Second: 10,449.66091

Timestep Collection Time: 2.23466
Timestep Consumption Time: 2.55191
PPO Batch Consumption Time: 0.29581
Total Iteration Time: 4.78657

Cumulative Model Updates: 90,392
Cumulative Timesteps: 753,975,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 753975672...
Checkpoint 753975672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,879.22743
Policy Entropy: 1.85428
Value Function Loss: 0.09507

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.14538
Policy Update Magnitude: 0.58762
Value Function Update Magnitude: 0.66180

Collected Steps per Second: 21,478.93212
Overall Steps per Second: 10,269.08287

Timestep Collection Time: 2.32805
Timestep Consumption Time: 2.54132
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.86937

Cumulative Model Updates: 90,398
Cumulative Timesteps: 754,025,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,271.24215
Policy Entropy: 1.84718
Value Function Loss: 0.09326

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.14124
Policy Update Magnitude: 0.59040
Value Function Update Magnitude: 0.61167

Collected Steps per Second: 22,353.26418
Overall Steps per Second: 10,587.30360

Timestep Collection Time: 2.23708
Timestep Consumption Time: 2.48613
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.72320

Cumulative Model Updates: 90,404
Cumulative Timesteps: 754,075,682

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 754075682...
Checkpoint 754075682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,821.22547
Policy Entropy: 1.84592
Value Function Loss: 0.09791

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.16814
Policy Update Magnitude: 0.56632
Value Function Update Magnitude: 0.66261

Collected Steps per Second: 21,855.90664
Overall Steps per Second: 10,442.39139

Timestep Collection Time: 2.28890
Timestep Consumption Time: 2.50176
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.79067

Cumulative Model Updates: 90,410
Cumulative Timesteps: 754,125,708

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,523.46367
Policy Entropy: 1.84593
Value Function Loss: 0.08834

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.16290
Policy Update Magnitude: 0.50040
Value Function Update Magnitude: 0.62923

Collected Steps per Second: 22,374.25971
Overall Steps per Second: 10,461.18400

Timestep Collection Time: 2.23632
Timestep Consumption Time: 2.54670
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.78301

Cumulative Model Updates: 90,416
Cumulative Timesteps: 754,175,744

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 754175744...
Checkpoint 754175744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,283.41496
Policy Entropy: 1.84513
Value Function Loss: 0.08883

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.46220
Value Function Update Magnitude: 0.60867

Collected Steps per Second: 21,308.24644
Overall Steps per Second: 10,231.75684

Timestep Collection Time: 2.34811
Timestep Consumption Time: 2.54196
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.89007

Cumulative Model Updates: 90,422
Cumulative Timesteps: 754,225,778

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,044.40753
Policy Entropy: 1.84594
Value Function Loss: 0.08557

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.14476
Policy Update Magnitude: 0.46586
Value Function Update Magnitude: 0.65879

Collected Steps per Second: 22,645.42988
Overall Steps per Second: 10,811.49686

Timestep Collection Time: 2.20883
Timestep Consumption Time: 2.41772
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.62656

Cumulative Model Updates: 90,428
Cumulative Timesteps: 754,275,798

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 754275798...
Checkpoint 754275798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,968.35572
Policy Entropy: 1.83929
Value Function Loss: 0.08620

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.15473
Policy Update Magnitude: 0.44333
Value Function Update Magnitude: 0.68293

Collected Steps per Second: 21,763.73758
Overall Steps per Second: 10,382.72285

Timestep Collection Time: 2.29758
Timestep Consumption Time: 2.51849
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.81608

Cumulative Model Updates: 90,434
Cumulative Timesteps: 754,325,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,037.94452
Policy Entropy: 1.83068
Value Function Loss: 0.08300

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.15866
Policy Update Magnitude: 0.47529
Value Function Update Magnitude: 0.67836

Collected Steps per Second: 22,623.03543
Overall Steps per Second: 10,564.92724

Timestep Collection Time: 2.21076
Timestep Consumption Time: 2.52321
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.73397

Cumulative Model Updates: 90,440
Cumulative Timesteps: 754,375,816

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 754375816...
Checkpoint 754375816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,775.95002
Policy Entropy: 1.82172
Value Function Loss: 0.08284

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.15118
Policy Update Magnitude: 0.52558
Value Function Update Magnitude: 0.67972

Collected Steps per Second: 21,345.81566
Overall Steps per Second: 10,362.33602

Timestep Collection Time: 2.34341
Timestep Consumption Time: 2.48388
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.82729

Cumulative Model Updates: 90,446
Cumulative Timesteps: 754,425,838

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,952.87563
Policy Entropy: 1.82136
Value Function Loss: 0.08277

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.15621
Policy Update Magnitude: 0.55708
Value Function Update Magnitude: 0.59038

Collected Steps per Second: 22,414.38636
Overall Steps per Second: 10,500.25479

Timestep Collection Time: 2.23169
Timestep Consumption Time: 2.53219
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.76388

Cumulative Model Updates: 90,452
Cumulative Timesteps: 754,475,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 754475860...
Checkpoint 754475860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,132.61759
Policy Entropy: 1.83205
Value Function Loss: 0.08708

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.55392
Value Function Update Magnitude: 0.55658

Collected Steps per Second: 21,869.03743
Overall Steps per Second: 10,575.65435

Timestep Collection Time: 2.28808
Timestep Consumption Time: 2.44336
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.73143

Cumulative Model Updates: 90,458
Cumulative Timesteps: 754,525,898

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,626.77016
Policy Entropy: 1.82823
Value Function Loss: 0.08636

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.56554
Value Function Update Magnitude: 0.54278

Collected Steps per Second: 22,574.78207
Overall Steps per Second: 10,508.21826

Timestep Collection Time: 2.21495
Timestep Consumption Time: 2.54342
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.75837

Cumulative Model Updates: 90,464
Cumulative Timesteps: 754,575,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 754575900...
Checkpoint 754575900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,009.09301
Policy Entropy: 1.83017
Value Function Loss: 0.08229

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.56474
Value Function Update Magnitude: 0.56908

Collected Steps per Second: 21,606.79494
Overall Steps per Second: 10,285.95172

Timestep Collection Time: 2.31548
Timestep Consumption Time: 2.54844
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.86392

Cumulative Model Updates: 90,470
Cumulative Timesteps: 754,625,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,258.03932
Policy Entropy: 1.82126
Value Function Loss: 0.08400

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13720
Policy Update Magnitude: 0.56907
Value Function Update Magnitude: 0.61308

Collected Steps per Second: 22,334.42320
Overall Steps per Second: 10,472.23696

Timestep Collection Time: 2.23959
Timestep Consumption Time: 2.53685
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.77644

Cumulative Model Updates: 90,476
Cumulative Timesteps: 754,675,950

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 754675950...
Checkpoint 754675950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,339.18348
Policy Entropy: 1.82808
Value Function Loss: 0.08825

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.58038
Value Function Update Magnitude: 0.59262

Collected Steps per Second: 21,964.79984
Overall Steps per Second: 10,522.77384

Timestep Collection Time: 2.27673
Timestep Consumption Time: 2.47563
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.75236

Cumulative Model Updates: 90,482
Cumulative Timesteps: 754,725,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,935.52598
Policy Entropy: 1.85223
Value Function Loss: 0.10225

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14861
Policy Update Magnitude: 0.58626
Value Function Update Magnitude: 0.57149

Collected Steps per Second: 21,971.35261
Overall Steps per Second: 10,450.80984

Timestep Collection Time: 2.27578
Timestep Consumption Time: 2.50873
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.78451

Cumulative Model Updates: 90,488
Cumulative Timesteps: 754,775,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 754775960...
Checkpoint 754775960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,939.78105
Policy Entropy: 1.86855
Value Function Loss: 0.10880

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.57118
Value Function Update Magnitude: 0.47086

Collected Steps per Second: 22,048.55636
Overall Steps per Second: 10,561.82402

Timestep Collection Time: 2.26908
Timestep Consumption Time: 2.46779
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.73687

Cumulative Model Updates: 90,494
Cumulative Timesteps: 754,825,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,261.43252
Policy Entropy: 1.86267
Value Function Loss: 0.10226

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.58231
Value Function Update Magnitude: 0.51313

Collected Steps per Second: 21,965.97014
Overall Steps per Second: 10,557.52402

Timestep Collection Time: 2.27716
Timestep Consumption Time: 2.46069
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.73785

Cumulative Model Updates: 90,500
Cumulative Timesteps: 754,876,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 754876010...
Checkpoint 754876010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,713.81297
Policy Entropy: 1.84267
Value Function Loss: 0.09004

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.57698
Value Function Update Magnitude: 0.59924

Collected Steps per Second: 21,512.57317
Overall Steps per Second: 10,310.70956

Timestep Collection Time: 2.32450
Timestep Consumption Time: 2.52541
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.84991

Cumulative Model Updates: 90,506
Cumulative Timesteps: 754,926,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,484.07913
Policy Entropy: 1.83341
Value Function Loss: 0.08693

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.57316
Value Function Update Magnitude: 0.70177

Collected Steps per Second: 22,358.47689
Overall Steps per Second: 10,516.72871

Timestep Collection Time: 2.23700
Timestep Consumption Time: 2.51885
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.75585

Cumulative Model Updates: 90,512
Cumulative Timesteps: 754,976,032

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 754976032...
Checkpoint 754976032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,532.69671
Policy Entropy: 1.84637
Value Function Loss: 0.09094

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.15177
Policy Update Magnitude: 0.56693
Value Function Update Magnitude: 0.71897

Collected Steps per Second: 22,110.75867
Overall Steps per Second: 10,352.96892

Timestep Collection Time: 2.26189
Timestep Consumption Time: 2.56881
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.83069

Cumulative Model Updates: 90,518
Cumulative Timesteps: 755,026,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,012.03418
Policy Entropy: 1.85399
Value Function Loss: 0.09485

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.56051
Value Function Update Magnitude: 0.68194

Collected Steps per Second: 22,005.46629
Overall Steps per Second: 10,572.13560

Timestep Collection Time: 2.27225
Timestep Consumption Time: 2.45735
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.72960

Cumulative Model Updates: 90,524
Cumulative Timesteps: 755,076,046

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 755076046...
Checkpoint 755076046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,291.06371
Policy Entropy: 1.84178
Value Function Loss: 0.09681

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.14202
Policy Update Magnitude: 0.56164
Value Function Update Magnitude: 0.60965

Collected Steps per Second: 21,480.79334
Overall Steps per Second: 10,410.47868

Timestep Collection Time: 2.32952
Timestep Consumption Time: 2.47717
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.80670

Cumulative Model Updates: 90,530
Cumulative Timesteps: 755,126,086

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,623.64102
Policy Entropy: 1.84642
Value Function Loss: 0.09335

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.17450
Policy Update Magnitude: 0.50702
Value Function Update Magnitude: 0.56602

Collected Steps per Second: 22,420.66618
Overall Steps per Second: 10,609.16503

Timestep Collection Time: 2.23044
Timestep Consumption Time: 2.48322
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.71366

Cumulative Model Updates: 90,536
Cumulative Timesteps: 755,176,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 755176094...
Checkpoint 755176094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,799.85370
Policy Entropy: 1.83497
Value Function Loss: 0.08735

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.15365
Policy Update Magnitude: 0.51351
Value Function Update Magnitude: 0.62976

Collected Steps per Second: 21,843.75659
Overall Steps per Second: 10,382.63877

Timestep Collection Time: 2.29072
Timestep Consumption Time: 2.52867
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.81939

Cumulative Model Updates: 90,542
Cumulative Timesteps: 755,226,132

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,702.34337
Policy Entropy: 1.84121
Value Function Loss: 0.08026

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.54734
Value Function Update Magnitude: 0.62340

Collected Steps per Second: 22,257.40490
Overall Steps per Second: 10,464.32721

Timestep Collection Time: 2.24662
Timestep Consumption Time: 2.53190
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.77852

Cumulative Model Updates: 90,548
Cumulative Timesteps: 755,276,136

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 755276136...
Checkpoint 755276136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,349.92369
Policy Entropy: 1.83042
Value Function Loss: 0.08070

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.55618
Value Function Update Magnitude: 0.63821

Collected Steps per Second: 21,715.88574
Overall Steps per Second: 10,537.01984

Timestep Collection Time: 2.30375
Timestep Consumption Time: 2.44408
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.74783

Cumulative Model Updates: 90,554
Cumulative Timesteps: 755,326,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,189.66024
Policy Entropy: 1.82512
Value Function Loss: 0.08151

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.56555
Value Function Update Magnitude: 0.65238

Collected Steps per Second: 21,747.66361
Overall Steps per Second: 10,499.04606

Timestep Collection Time: 2.29947
Timestep Consumption Time: 2.46363
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.76310

Cumulative Model Updates: 90,560
Cumulative Timesteps: 755,376,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 755376172...
Checkpoint 755376172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,787.69540
Policy Entropy: 1.82554
Value Function Loss: 0.08293

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.57115
Value Function Update Magnitude: 0.61861

Collected Steps per Second: 21,849.25855
Overall Steps per Second: 10,318.28584

Timestep Collection Time: 2.28923
Timestep Consumption Time: 2.55828
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.84751

Cumulative Model Updates: 90,566
Cumulative Timesteps: 755,426,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,557.18083
Policy Entropy: 1.83381
Value Function Loss: 0.08936

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13546
Policy Update Magnitude: 0.57331
Value Function Update Magnitude: 0.59674

Collected Steps per Second: 22,363.64518
Overall Steps per Second: 10,518.69284

Timestep Collection Time: 2.23613
Timestep Consumption Time: 2.51807
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.75420

Cumulative Model Updates: 90,572
Cumulative Timesteps: 755,476,198

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 755476198...
Checkpoint 755476198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,560.92093
Policy Entropy: 1.84701
Value Function Loss: 0.09535

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.14324
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.66082

Collected Steps per Second: 21,642.62459
Overall Steps per Second: 10,474.84001

Timestep Collection Time: 2.31164
Timestep Consumption Time: 2.46456
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.77621

Cumulative Model Updates: 90,578
Cumulative Timesteps: 755,526,228

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,931.49359
Policy Entropy: 1.86415
Value Function Loss: 0.09434

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14042
Policy Update Magnitude: 0.57923
Value Function Update Magnitude: 0.72554

Collected Steps per Second: 22,107.54075
Overall Steps per Second: 10,456.58461

Timestep Collection Time: 2.26176
Timestep Consumption Time: 2.52011
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.78187

Cumulative Model Updates: 90,584
Cumulative Timesteps: 755,576,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 755576230...
Checkpoint 755576230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,978.44326
Policy Entropy: 1.86870
Value Function Loss: 0.08917

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13509
Policy Update Magnitude: 0.58032
Value Function Update Magnitude: 0.76882

Collected Steps per Second: 21,870.97698
Overall Steps per Second: 10,563.30762

Timestep Collection Time: 2.28668
Timestep Consumption Time: 2.44782
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.73450

Cumulative Model Updates: 90,590
Cumulative Timesteps: 755,626,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,303.99860
Policy Entropy: 1.85249
Value Function Loss: 0.08333

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12937
Policy Update Magnitude: 0.57716
Value Function Update Magnitude: 0.75063

Collected Steps per Second: 22,232.46870
Overall Steps per Second: 10,390.68390

Timestep Collection Time: 2.25031
Timestep Consumption Time: 2.56458
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.81489

Cumulative Model Updates: 90,596
Cumulative Timesteps: 755,676,272

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 755676272...
Checkpoint 755676272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,064.69492
Policy Entropy: 1.84483
Value Function Loss: 0.08017

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.57017
Value Function Update Magnitude: 0.65313

Collected Steps per Second: 21,374.85005
Overall Steps per Second: 10,315.00387

Timestep Collection Time: 2.33948
Timestep Consumption Time: 2.50841
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.84789

Cumulative Model Updates: 90,602
Cumulative Timesteps: 755,726,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,329.21503
Policy Entropy: 1.83573
Value Function Loss: 0.08151

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.56379
Value Function Update Magnitude: 0.56139

Collected Steps per Second: 22,284.34985
Overall Steps per Second: 10,473.41546

Timestep Collection Time: 2.24516
Timestep Consumption Time: 2.53188
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.77705

Cumulative Model Updates: 90,608
Cumulative Timesteps: 755,776,310

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 755776310...
Checkpoint 755776310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,434.89983
Policy Entropy: 1.85462
Value Function Loss: 0.08329

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.15681
Policy Update Magnitude: 0.54832
Value Function Update Magnitude: 0.53141

Collected Steps per Second: 21,859.50872
Overall Steps per Second: 10,430.85649

Timestep Collection Time: 2.28752
Timestep Consumption Time: 2.50634
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.79385

Cumulative Model Updates: 90,614
Cumulative Timesteps: 755,826,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,094.81755
Policy Entropy: 1.84231
Value Function Loss: 0.08265

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.14334
Policy Update Magnitude: 0.54376
Value Function Update Magnitude: 0.58354

Collected Steps per Second: 22,587.73028
Overall Steps per Second: 10,661.29177

Timestep Collection Time: 2.21368
Timestep Consumption Time: 2.47637
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.69005

Cumulative Model Updates: 90,620
Cumulative Timesteps: 755,876,316

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 755876316...
Checkpoint 755876316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,867.00409
Policy Entropy: 1.84303
Value Function Loss: 0.08316

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.56258
Value Function Update Magnitude: 0.67388

Collected Steps per Second: 21,830.86843
Overall Steps per Second: 10,424.02266

Timestep Collection Time: 2.29098
Timestep Consumption Time: 2.50698
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.79796

Cumulative Model Updates: 90,626
Cumulative Timesteps: 755,926,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,811.56462
Policy Entropy: 1.83426
Value Function Loss: 0.08443

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.16077
Policy Update Magnitude: 0.53038
Value Function Update Magnitude: 0.62357

Collected Steps per Second: 22,177.90189
Overall Steps per Second: 10,474.98135

Timestep Collection Time: 2.25540
Timestep Consumption Time: 2.51979
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.77519

Cumulative Model Updates: 90,632
Cumulative Timesteps: 755,976,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 755976350...
Checkpoint 755976350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,345.16415
Policy Entropy: 1.84826
Value Function Loss: 0.08643

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.17895
Policy Update Magnitude: 0.49933
Value Function Update Magnitude: 0.63173

Collected Steps per Second: 22,029.67017
Overall Steps per Second: 10,422.81570

Timestep Collection Time: 2.27103
Timestep Consumption Time: 2.52902
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.80005

Cumulative Model Updates: 90,638
Cumulative Timesteps: 756,026,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,851.40318
Policy Entropy: 1.85631
Value Function Loss: 0.09152

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.17278
Policy Update Magnitude: 0.47879
Value Function Update Magnitude: 0.58928

Collected Steps per Second: 21,890.75078
Overall Steps per Second: 10,459.11420

Timestep Collection Time: 2.28425
Timestep Consumption Time: 2.49665
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.78090

Cumulative Model Updates: 90,644
Cumulative Timesteps: 756,076,384

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 756076384...
Checkpoint 756076384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,208.40838
Policy Entropy: 1.85815
Value Function Loss: 0.09012

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.15684
Policy Update Magnitude: 0.48935
Value Function Update Magnitude: 0.63705

Collected Steps per Second: 21,796.53675
Overall Steps per Second: 10,402.70708

Timestep Collection Time: 2.29504
Timestep Consumption Time: 2.51370
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.80875

Cumulative Model Updates: 90,650
Cumulative Timesteps: 756,126,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,283.46419
Policy Entropy: 1.86653
Value Function Loss: 0.08596

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.53206
Value Function Update Magnitude: 0.66909

Collected Steps per Second: 22,429.18159
Overall Steps per Second: 10,683.55970

Timestep Collection Time: 2.23075
Timestep Consumption Time: 2.45252
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.68327

Cumulative Model Updates: 90,656
Cumulative Timesteps: 756,176,442

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 756176442...
Checkpoint 756176442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,349.44473
Policy Entropy: 1.86217
Value Function Loss: 0.08516

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.55953
Value Function Update Magnitude: 0.64866

Collected Steps per Second: 21,631.06743
Overall Steps per Second: 10,566.88304

Timestep Collection Time: 2.31214
Timestep Consumption Time: 2.42095
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.73309

Cumulative Model Updates: 90,662
Cumulative Timesteps: 756,226,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,481.42524
Policy Entropy: 1.85923
Value Function Loss: 0.08559

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.56357
Value Function Update Magnitude: 0.50795

Collected Steps per Second: 22,391.70379
Overall Steps per Second: 10,538.12236

Timestep Collection Time: 2.23404
Timestep Consumption Time: 2.51291
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.74696

Cumulative Model Updates: 90,668
Cumulative Timesteps: 756,276,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 756276480...
Checkpoint 756276480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,633.77276
Policy Entropy: 1.85817
Value Function Loss: 0.09044

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.56787
Value Function Update Magnitude: 0.57000

Collected Steps per Second: 21,926.87032
Overall Steps per Second: 10,446.64189

Timestep Collection Time: 2.28040
Timestep Consumption Time: 2.50602
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.78642

Cumulative Model Updates: 90,674
Cumulative Timesteps: 756,326,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,173.70489
Policy Entropy: 1.85753
Value Function Loss: 0.08352

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.56561
Value Function Update Magnitude: 0.61388

Collected Steps per Second: 22,146.47900
Overall Steps per Second: 10,548.96392

Timestep Collection Time: 2.25851
Timestep Consumption Time: 2.48300
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.74151

Cumulative Model Updates: 90,680
Cumulative Timesteps: 756,376,500

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 756376500...
Checkpoint 756376500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,546.97999
Policy Entropy: 1.84773
Value Function Loss: 0.08128

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.55729
Value Function Update Magnitude: 0.57126

Collected Steps per Second: 21,888.61240
Overall Steps per Second: 10,398.76524

Timestep Collection Time: 2.28466
Timestep Consumption Time: 2.52437
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.80903

Cumulative Model Updates: 90,686
Cumulative Timesteps: 756,426,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,509.18385
Policy Entropy: 1.83532
Value Function Loss: 0.08000

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.16628
Policy Update Magnitude: 0.53829
Value Function Update Magnitude: 0.59903

Collected Steps per Second: 22,229.81243
Overall Steps per Second: 10,479.99553

Timestep Collection Time: 2.24968
Timestep Consumption Time: 2.52227
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.77195

Cumulative Model Updates: 90,692
Cumulative Timesteps: 756,476,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 756476518...
Checkpoint 756476518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,930.67980
Policy Entropy: 1.82848
Value Function Loss: 0.08412

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.17292
Policy Update Magnitude: 0.49342
Value Function Update Magnitude: 0.64163

Collected Steps per Second: 21,644.27909
Overall Steps per Second: 10,491.54631

Timestep Collection Time: 2.31156
Timestep Consumption Time: 2.45723
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.76879

Cumulative Model Updates: 90,698
Cumulative Timesteps: 756,526,550

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,306.41607
Policy Entropy: 1.83136
Value Function Loss: 0.08765

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.15637
Policy Update Magnitude: 0.45321
Value Function Update Magnitude: 0.67686

Collected Steps per Second: 22,018.23453
Overall Steps per Second: 10,435.30848

Timestep Collection Time: 2.27085
Timestep Consumption Time: 2.52058
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.79143

Cumulative Model Updates: 90,704
Cumulative Timesteps: 756,576,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 756576550...
Checkpoint 756576550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,398.81618
Policy Entropy: 1.83332
Value Function Loss: 0.09416

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.16384
Policy Update Magnitude: 0.45495
Value Function Update Magnitude: 0.63951

Collected Steps per Second: 21,918.95908
Overall Steps per Second: 10,424.14997

Timestep Collection Time: 2.28250
Timestep Consumption Time: 2.51693
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.79943

Cumulative Model Updates: 90,710
Cumulative Timesteps: 756,626,580

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,981.80312
Policy Entropy: 1.83947
Value Function Loss: 0.09607

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.16173
Policy Update Magnitude: 0.52978
Value Function Update Magnitude: 0.68159

Collected Steps per Second: 22,199.07618
Overall Steps per Second: 10,553.82208

Timestep Collection Time: 2.25352
Timestep Consumption Time: 2.48657
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.74008

Cumulative Model Updates: 90,716
Cumulative Timesteps: 756,676,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 756676606...
Checkpoint 756676606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,294.43363
Policy Entropy: 1.83793
Value Function Loss: 0.08883

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.14818
Policy Update Magnitude: 0.55078
Value Function Update Magnitude: 0.73606

Collected Steps per Second: 21,484.11501
Overall Steps per Second: 10,373.73232

Timestep Collection Time: 2.32954
Timestep Consumption Time: 2.49496
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.82449

Cumulative Model Updates: 90,722
Cumulative Timesteps: 756,726,654

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,910.72752
Policy Entropy: 1.83533
Value Function Loss: 0.08370

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.55978
Value Function Update Magnitude: 0.68112

Collected Steps per Second: 22,289.81880
Overall Steps per Second: 10,419.09737

Timestep Collection Time: 2.24416
Timestep Consumption Time: 2.55683
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.80099

Cumulative Model Updates: 90,728
Cumulative Timesteps: 756,776,676

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 756776676...
Checkpoint 756776676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,624.13618
Policy Entropy: 1.82731
Value Function Loss: 0.07984

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.12191
Policy Update Magnitude: 0.56605
Value Function Update Magnitude: 0.58024

Collected Steps per Second: 21,157.48813
Overall Steps per Second: 10,210.92041

Timestep Collection Time: 2.36389
Timestep Consumption Time: 2.53420
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.89809

Cumulative Model Updates: 90,734
Cumulative Timesteps: 756,826,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,916.00501
Policy Entropy: 1.85385
Value Function Loss: 0.08125

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.12762
Policy Update Magnitude: 0.56389
Value Function Update Magnitude: 0.55855

Collected Steps per Second: 22,369.60940
Overall Steps per Second: 10,462.46182

Timestep Collection Time: 2.23553
Timestep Consumption Time: 2.54422
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.77975

Cumulative Model Updates: 90,740
Cumulative Timesteps: 756,876,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 756876698...
Checkpoint 756876698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,758.05363
Policy Entropy: 1.85463
Value Function Loss: 0.08397

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.55643
Value Function Update Magnitude: 0.55182

Collected Steps per Second: 21,564.21458
Overall Steps per Second: 10,315.87211

Timestep Collection Time: 2.31884
Timestep Consumption Time: 2.52845
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.84729

Cumulative Model Updates: 90,746
Cumulative Timesteps: 756,926,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,826.90188
Policy Entropy: 1.84387
Value Function Loss: 0.08304

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.56377
Value Function Update Magnitude: 0.51911

Collected Steps per Second: 22,334.29202
Overall Steps per Second: 10,297.26080

Timestep Collection Time: 2.23987
Timestep Consumption Time: 2.61831
PPO Batch Consumption Time: 0.30645
Total Iteration Time: 4.85819

Cumulative Model Updates: 90,752
Cumulative Timesteps: 756,976,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 756976728...
Checkpoint 756976728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,266.30295
Policy Entropy: 1.81326
Value Function Loss: 0.08831

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.57200
Value Function Update Magnitude: 0.47167

Collected Steps per Second: 21,502.02204
Overall Steps per Second: 10,370.32494

Timestep Collection Time: 2.32601
Timestep Consumption Time: 2.49679
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.82280

Cumulative Model Updates: 90,758
Cumulative Timesteps: 757,026,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,586.17173
Policy Entropy: 1.83052
Value Function Loss: 0.08903

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.56965
Value Function Update Magnitude: 0.43595

Collected Steps per Second: 22,726.47852
Overall Steps per Second: 10,741.82998

Timestep Collection Time: 2.20060
Timestep Consumption Time: 2.45521
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.65582

Cumulative Model Updates: 90,764
Cumulative Timesteps: 757,076,754

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 757076754...
Checkpoint 757076754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,817.69961
Policy Entropy: 1.82341
Value Function Loss: 0.08663

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.56649
Value Function Update Magnitude: 0.57391

Collected Steps per Second: 21,929.10726
Overall Steps per Second: 10,434.93660

Timestep Collection Time: 2.28071
Timestep Consumption Time: 2.51222
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.79294

Cumulative Model Updates: 90,770
Cumulative Timesteps: 757,126,768

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,426.16092
Policy Entropy: 1.84691
Value Function Loss: 0.08431

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.55650
Value Function Update Magnitude: 0.61958

Collected Steps per Second: 22,501.90233
Overall Steps per Second: 10,737.35649

Timestep Collection Time: 2.22372
Timestep Consumption Time: 2.43646
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.66018

Cumulative Model Updates: 90,776
Cumulative Timesteps: 757,176,806

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 757176806...
Checkpoint 757176806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,247.26929
Policy Entropy: 1.85154
Value Function Loss: 0.08674

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.54395
Value Function Update Magnitude: 0.61622

Collected Steps per Second: 21,833.53109
Overall Steps per Second: 10,598.50346

Timestep Collection Time: 2.29033
Timestep Consumption Time: 2.42788
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.71821

Cumulative Model Updates: 90,782
Cumulative Timesteps: 757,226,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,481.82502
Policy Entropy: 1.84957
Value Function Loss: 0.08872

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.54237
Value Function Update Magnitude: 0.53952

Collected Steps per Second: 22,239.96802
Overall Steps per Second: 10,476.95367

Timestep Collection Time: 2.24829
Timestep Consumption Time: 2.52428
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.77257

Cumulative Model Updates: 90,788
Cumulative Timesteps: 757,276,814

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 757276814...
Checkpoint 757276814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,041.51839
Policy Entropy: 1.83941
Value Function Loss: 0.09003

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.44394

Collected Steps per Second: 21,971.64480
Overall Steps per Second: 10,594.97492

Timestep Collection Time: 2.27666
Timestep Consumption Time: 2.44463
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.72129

Cumulative Model Updates: 90,794
Cumulative Timesteps: 757,326,836

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,136.41344
Policy Entropy: 1.82923
Value Function Loss: 0.09229

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.55432
Value Function Update Magnitude: 0.54204

Collected Steps per Second: 22,353.31359
Overall Steps per Second: 10,514.09134

Timestep Collection Time: 2.23725
Timestep Consumption Time: 2.51922
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.75647

Cumulative Model Updates: 90,800
Cumulative Timesteps: 757,376,846

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 757376846...
Checkpoint 757376846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,074.00345
Policy Entropy: 1.83637
Value Function Loss: 0.09023

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.54202
Value Function Update Magnitude: 0.61932

Collected Steps per Second: 21,764.88881
Overall Steps per Second: 10,397.94053

Timestep Collection Time: 2.29820
Timestep Consumption Time: 2.51237
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.81057

Cumulative Model Updates: 90,806
Cumulative Timesteps: 757,426,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,074.82976
Policy Entropy: 1.82990
Value Function Loss: 0.08825

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.53302
Value Function Update Magnitude: 0.56325

Collected Steps per Second: 22,436.96043
Overall Steps per Second: 10,781.14003

Timestep Collection Time: 2.22882
Timestep Consumption Time: 2.40965
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.63847

Cumulative Model Updates: 90,812
Cumulative Timesteps: 757,476,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 757476874...
Checkpoint 757476874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,898.78047
Policy Entropy: 1.83476
Value Function Loss: 0.08003

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.14843
Policy Update Magnitude: 0.51898
Value Function Update Magnitude: 0.61469

Collected Steps per Second: 21,941.19068
Overall Steps per Second: 10,554.01575

Timestep Collection Time: 2.27882
Timestep Consumption Time: 2.45871
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.73753

Cumulative Model Updates: 90,818
Cumulative Timesteps: 757,526,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,141.65313
Policy Entropy: 1.84904
Value Function Loss: 0.07640

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.50858
Value Function Update Magnitude: 0.61591

Collected Steps per Second: 22,497.50861
Overall Steps per Second: 10,617.47269

Timestep Collection Time: 2.22336
Timestep Consumption Time: 2.48774
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.71110

Cumulative Model Updates: 90,824
Cumulative Timesteps: 757,576,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 757576894...
Checkpoint 757576894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,069.76725
Policy Entropy: 1.84103
Value Function Loss: 0.07702

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.49518
Value Function Update Magnitude: 0.56237

Collected Steps per Second: 22,056.24537
Overall Steps per Second: 10,325.09861

Timestep Collection Time: 2.26820
Timestep Consumption Time: 2.57708
PPO Batch Consumption Time: 0.30135
Total Iteration Time: 4.84528

Cumulative Model Updates: 90,830
Cumulative Timesteps: 757,626,922

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,540.42398
Policy Entropy: 1.85116
Value Function Loss: 0.08363

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.15510
Policy Update Magnitude: 0.47791
Value Function Update Magnitude: 0.54852

Collected Steps per Second: 22,299.17267
Overall Steps per Second: 10,510.91584

Timestep Collection Time: 2.24268
Timestep Consumption Time: 2.51523
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.75791

Cumulative Model Updates: 90,836
Cumulative Timesteps: 757,676,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 757676932...
Checkpoint 757676932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,154.32276
Policy Entropy: 1.84070
Value Function Loss: 0.08822

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.15221
Policy Update Magnitude: 0.47559
Value Function Update Magnitude: 0.65117

Collected Steps per Second: 21,551.13615
Overall Steps per Second: 10,300.93153

Timestep Collection Time: 2.32016
Timestep Consumption Time: 2.53397
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.85412

Cumulative Model Updates: 90,842
Cumulative Timesteps: 757,726,934

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,207.96379
Policy Entropy: 1.84175
Value Function Loss: 0.08619

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.14722
Policy Update Magnitude: 0.46752
Value Function Update Magnitude: 0.61186

Collected Steps per Second: 22,401.66992
Overall Steps per Second: 10,488.74036

Timestep Collection Time: 2.23224
Timestep Consumption Time: 2.53534
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.76759

Cumulative Model Updates: 90,848
Cumulative Timesteps: 757,776,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 757776940...
Checkpoint 757776940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,617.55050
Policy Entropy: 1.83874
Value Function Loss: 0.08680

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.46283
Value Function Update Magnitude: 0.46902

Collected Steps per Second: 21,850.99863
Overall Steps per Second: 10,590.45054

Timestep Collection Time: 2.28905
Timestep Consumption Time: 2.43389
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.72293

Cumulative Model Updates: 90,854
Cumulative Timesteps: 757,826,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,709.23192
Policy Entropy: 1.85007
Value Function Loss: 0.08193

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.51304
Value Function Update Magnitude: 0.43259

Collected Steps per Second: 22,153.35423
Overall Steps per Second: 10,471.43530

Timestep Collection Time: 2.25727
Timestep Consumption Time: 2.51820
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.77547

Cumulative Model Updates: 90,860
Cumulative Timesteps: 757,876,964

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 757876964...
Checkpoint 757876964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,330.44777
Policy Entropy: 1.86043
Value Function Loss: 0.08626

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.55290
Value Function Update Magnitude: 0.38011

Collected Steps per Second: 21,625.43783
Overall Steps per Second: 10,567.70952

Timestep Collection Time: 2.31218
Timestep Consumption Time: 2.41940
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.73158

Cumulative Model Updates: 90,866
Cumulative Timesteps: 757,926,966

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,901.19682
Policy Entropy: 1.85623
Value Function Loss: 0.08706

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.56140
Value Function Update Magnitude: 0.31434

Collected Steps per Second: 22,396.11780
Overall Steps per Second: 10,507.60291

Timestep Collection Time: 2.23387
Timestep Consumption Time: 2.52745
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.76131

Cumulative Model Updates: 90,872
Cumulative Timesteps: 757,976,996

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 757976996...
Checkpoint 757976996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,031.71252
Policy Entropy: 1.84647
Value Function Loss: 0.08943

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.55824
Value Function Update Magnitude: 0.29745

Collected Steps per Second: 21,678.73983
Overall Steps per Second: 10,365.21876

Timestep Collection Time: 2.30751
Timestep Consumption Time: 2.51863
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.82614

Cumulative Model Updates: 90,878
Cumulative Timesteps: 758,027,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,394.97464
Policy Entropy: 1.83743
Value Function Loss: 0.08523

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.55032
Value Function Update Magnitude: 0.36804

Collected Steps per Second: 22,216.11970
Overall Steps per Second: 10,456.93834

Timestep Collection Time: 2.25080
Timestep Consumption Time: 2.53110
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.78190

Cumulative Model Updates: 90,884
Cumulative Timesteps: 758,077,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 758077024...
Checkpoint 758077024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,807.14133
Policy Entropy: 1.84664
Value Function Loss: 0.07877

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.54528
Value Function Update Magnitude: 0.51068

Collected Steps per Second: 21,759.55302
Overall Steps per Second: 10,561.18423

Timestep Collection Time: 2.29839
Timestep Consumption Time: 2.43706
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.73545

Cumulative Model Updates: 90,890
Cumulative Timesteps: 758,127,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,146.53490
Policy Entropy: 1.84672
Value Function Loss: 0.07825

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12493
Policy Update Magnitude: 0.55498
Value Function Update Magnitude: 0.60754

Collected Steps per Second: 22,229.14617
Overall Steps per Second: 10,460.45342

Timestep Collection Time: 2.24984
Timestep Consumption Time: 2.53122
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.78105

Cumulative Model Updates: 90,896
Cumulative Timesteps: 758,177,048

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 758177048...
Checkpoint 758177048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,901.66075
Policy Entropy: 1.85365
Value Function Loss: 0.07988

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.53655
Value Function Update Magnitude: 0.63199

Collected Steps per Second: 21,763.89839
Overall Steps per Second: 10,514.77203

Timestep Collection Time: 2.29803
Timestep Consumption Time: 2.45852
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.75655

Cumulative Model Updates: 90,902
Cumulative Timesteps: 758,227,062

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,393.99958
Policy Entropy: 1.84575
Value Function Loss: 0.08850

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.15244
Policy Update Magnitude: 0.49899
Value Function Update Magnitude: 0.65963

Collected Steps per Second: 22,055.96240
Overall Steps per Second: 10,361.14175

Timestep Collection Time: 2.26823
Timestep Consumption Time: 2.56020
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.82843

Cumulative Model Updates: 90,908
Cumulative Timesteps: 758,277,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 758277090...
Checkpoint 758277090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,966.24214
Policy Entropy: 1.86813
Value Function Loss: 0.09373

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.14869
Policy Update Magnitude: 0.47328
Value Function Update Magnitude: 0.73915

Collected Steps per Second: 21,752.57924
Overall Steps per Second: 10,304.48021

Timestep Collection Time: 2.29987
Timestep Consumption Time: 2.55511
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.85498

Cumulative Model Updates: 90,914
Cumulative Timesteps: 758,327,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,767.01818
Policy Entropy: 1.89496
Value Function Loss: 0.10055

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.15184
Policy Update Magnitude: 0.49056
Value Function Update Magnitude: 0.70681

Collected Steps per Second: 22,293.20856
Overall Steps per Second: 10,494.53007

Timestep Collection Time: 2.24337
Timestep Consumption Time: 2.52216
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.76553

Cumulative Model Updates: 90,920
Cumulative Timesteps: 758,377,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 758377130...
Checkpoint 758377130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,442.72217
Policy Entropy: 1.92675
Value Function Loss: 0.10644

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.15442
Policy Update Magnitude: 0.52084
Value Function Update Magnitude: 0.69025

Collected Steps per Second: 22,102.62125
Overall Steps per Second: 10,681.13055

Timestep Collection Time: 2.26236
Timestep Consumption Time: 2.41917
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.68153

Cumulative Model Updates: 90,926
Cumulative Timesteps: 758,427,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,399.86294
Policy Entropy: 1.94263
Value Function Loss: 0.10080

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.15761
Policy Update Magnitude: 0.52384
Value Function Update Magnitude: 0.63213

Collected Steps per Second: 22,083.57414
Overall Steps per Second: 10,421.58179

Timestep Collection Time: 2.26530
Timestep Consumption Time: 2.53493
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.80023

Cumulative Model Updates: 90,932
Cumulative Timesteps: 758,477,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 758477160...
Checkpoint 758477160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,641.67127
Policy Entropy: 1.92028
Value Function Loss: 0.10192

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.16358
Policy Update Magnitude: 0.52236
Value Function Update Magnitude: 0.63839

Collected Steps per Second: 21,536.72962
Overall Steps per Second: 10,564.88912

Timestep Collection Time: 2.32254
Timestep Consumption Time: 2.41201
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.73455

Cumulative Model Updates: 90,938
Cumulative Timesteps: 758,527,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,906.53959
Policy Entropy: 1.88994
Value Function Loss: 0.10117

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.16196
Policy Update Magnitude: 0.56437
Value Function Update Magnitude: 0.64310

Collected Steps per Second: 22,273.04935
Overall Steps per Second: 10,518.63364

Timestep Collection Time: 2.24648
Timestep Consumption Time: 2.51041
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.75689

Cumulative Model Updates: 90,944
Cumulative Timesteps: 758,577,216

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 758577216...
Checkpoint 758577216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,574.42004
Policy Entropy: 1.87297
Value Function Loss: 0.10281

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.16883
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.60599

Collected Steps per Second: 21,832.55563
Overall Steps per Second: 10,620.76896

Timestep Collection Time: 2.29144
Timestep Consumption Time: 2.41895
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.71039

Cumulative Model Updates: 90,950
Cumulative Timesteps: 758,627,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,387.29258
Policy Entropy: 1.87925
Value Function Loss: 0.10182

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.16803
Policy Update Magnitude: 0.52138
Value Function Update Magnitude: 0.59049

Collected Steps per Second: 22,391.22996
Overall Steps per Second: 10,575.34653

Timestep Collection Time: 2.23462
Timestep Consumption Time: 2.49676
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.73138

Cumulative Model Updates: 90,956
Cumulative Timesteps: 758,677,280

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 758677280...
Checkpoint 758677280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,970.88431
Policy Entropy: 1.87506
Value Function Loss: 0.10253

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.16340
Policy Update Magnitude: 0.53878
Value Function Update Magnitude: 0.53340

Collected Steps per Second: 21,560.67695
Overall Steps per Second: 10,497.81444

Timestep Collection Time: 2.32108
Timestep Consumption Time: 2.44601
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.76709

Cumulative Model Updates: 90,962
Cumulative Timesteps: 758,727,324

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,671.11023
Policy Entropy: 1.88627
Value Function Loss: 0.10209

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.57660
Value Function Update Magnitude: 0.50530

Collected Steps per Second: 22,412.00865
Overall Steps per Second: 10,517.96477

Timestep Collection Time: 2.23202
Timestep Consumption Time: 2.52404
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.75605

Cumulative Model Updates: 90,968
Cumulative Timesteps: 758,777,348

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 758777348...
Checkpoint 758777348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,337.76778
Policy Entropy: 1.87657
Value Function Loss: 0.09743

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.60145
Value Function Update Magnitude: 0.48719

Collected Steps per Second: 21,810.32595
Overall Steps per Second: 10,566.47289

Timestep Collection Time: 2.29323
Timestep Consumption Time: 2.44024
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.73346

Cumulative Model Updates: 90,974
Cumulative Timesteps: 758,827,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,470.60116
Policy Entropy: 1.86134
Value Function Loss: 0.09441

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.60660
Value Function Update Magnitude: 0.51849

Collected Steps per Second: 22,348.22642
Overall Steps per Second: 10,499.44205

Timestep Collection Time: 2.23740
Timestep Consumption Time: 2.52494
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.76235

Cumulative Model Updates: 90,980
Cumulative Timesteps: 758,877,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 758877366...
Checkpoint 758877366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,936.36243
Policy Entropy: 1.83229
Value Function Loss: 0.09310

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.15383
Policy Update Magnitude: 0.60003
Value Function Update Magnitude: 0.44952

Collected Steps per Second: 21,500.34239
Overall Steps per Second: 10,189.69242

Timestep Collection Time: 2.32657
Timestep Consumption Time: 2.58251
PPO Batch Consumption Time: 0.30191
Total Iteration Time: 4.90908

Cumulative Model Updates: 90,986
Cumulative Timesteps: 758,927,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,949.56672
Policy Entropy: 1.84492
Value Function Loss: 0.09687

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.16879
Policy Update Magnitude: 0.54309
Value Function Update Magnitude: 0.39675

Collected Steps per Second: 21,992.57573
Overall Steps per Second: 10,409.29593

Timestep Collection Time: 2.27440
Timestep Consumption Time: 2.53092
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.80532

Cumulative Model Updates: 90,992
Cumulative Timesteps: 758,977,408

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 758977408...
Checkpoint 758977408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,271.80712
Policy Entropy: 1.84294
Value Function Loss: 0.09615

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.14498
Policy Update Magnitude: 0.55630
Value Function Update Magnitude: 0.38433

Collected Steps per Second: 21,842.86484
Overall Steps per Second: 10,380.40946

Timestep Collection Time: 2.28963
Timestep Consumption Time: 2.52830
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.81792

Cumulative Model Updates: 90,998
Cumulative Timesteps: 759,027,420

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,556.38699
Policy Entropy: 1.84522
Value Function Loss: 0.09121

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.14220
Policy Update Magnitude: 0.57132
Value Function Update Magnitude: 0.44032

Collected Steps per Second: 22,279.86370
Overall Steps per Second: 10,510.56477

Timestep Collection Time: 2.24418
Timestep Consumption Time: 2.51294
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.75712

Cumulative Model Updates: 91,004
Cumulative Timesteps: 759,077,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 759077420...
Checkpoint 759077420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,715.51421
Policy Entropy: 1.85375
Value Function Loss: 0.09694

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.58004
Value Function Update Magnitude: 0.48326

Collected Steps per Second: 21,488.43914
Overall Steps per Second: 10,496.42751

Timestep Collection Time: 2.32776
Timestep Consumption Time: 2.43767
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.76543

Cumulative Model Updates: 91,010
Cumulative Timesteps: 759,127,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,458.94946
Policy Entropy: 1.87153
Value Function Loss: 0.09560

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.14024
Policy Update Magnitude: 0.56857
Value Function Update Magnitude: 0.46435

Collected Steps per Second: 22,373.48245
Overall Steps per Second: 10,488.35158

Timestep Collection Time: 2.23524
Timestep Consumption Time: 2.53291
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.76815

Cumulative Model Updates: 91,016
Cumulative Timesteps: 759,177,450

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 759177450...
Checkpoint 759177450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,503.63800
Policy Entropy: 1.89075
Value Function Loss: 0.09472

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.56759
Value Function Update Magnitude: 0.44160

Collected Steps per Second: 21,591.95082
Overall Steps per Second: 10,483.60898

Timestep Collection Time: 2.31586
Timestep Consumption Time: 2.45387
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.76973

Cumulative Model Updates: 91,022
Cumulative Timesteps: 759,227,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,453.13242
Policy Entropy: 1.88607
Value Function Loss: 0.08802

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.56260
Value Function Update Magnitude: 0.42804

Collected Steps per Second: 21,800.37676
Overall Steps per Second: 10,510.92284

Timestep Collection Time: 2.29455
Timestep Consumption Time: 2.46450
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.75905

Cumulative Model Updates: 91,028
Cumulative Timesteps: 759,277,476

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 759277476...
Checkpoint 759277476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,543.55575
Policy Entropy: 1.88060
Value Function Loss: 0.08858

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12324
Policy Update Magnitude: 0.57405
Value Function Update Magnitude: 0.42569

Collected Steps per Second: 21,649.84942
Overall Steps per Second: 10,342.57307

Timestep Collection Time: 2.31032
Timestep Consumption Time: 2.52581
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.83613

Cumulative Model Updates: 91,034
Cumulative Timesteps: 759,327,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,902.38983
Policy Entropy: 1.87686
Value Function Loss: 0.08922

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.57265
Value Function Update Magnitude: 0.41152

Collected Steps per Second: 22,483.10441
Overall Steps per Second: 10,564.95654

Timestep Collection Time: 2.22505
Timestep Consumption Time: 2.51004
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.73509

Cumulative Model Updates: 91,040
Cumulative Timesteps: 759,377,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 759377520...
Checkpoint 759377520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,752.66943
Policy Entropy: 1.88287
Value Function Loss: 0.09355

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.57469
Value Function Update Magnitude: 0.39737

Collected Steps per Second: 21,939.14252
Overall Steps per Second: 10,444.68516

Timestep Collection Time: 2.28031
Timestep Consumption Time: 2.50950
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.78980

Cumulative Model Updates: 91,046
Cumulative Timesteps: 759,427,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,348.44087
Policy Entropy: 1.87926
Value Function Loss: 0.09780

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.58109
Value Function Update Magnitude: 0.49353

Collected Steps per Second: 22,228.04852
Overall Steps per Second: 10,529.31072

Timestep Collection Time: 2.24995
Timestep Consumption Time: 2.49984
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.74979

Cumulative Model Updates: 91,052
Cumulative Timesteps: 759,477,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 759477560...
Checkpoint 759477560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,857.16023
Policy Entropy: 1.88566
Value Function Loss: 0.09844

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.58879
Value Function Update Magnitude: 0.58008

Collected Steps per Second: 21,888.41337
Overall Steps per Second: 10,541.73848

Timestep Collection Time: 2.28559
Timestep Consumption Time: 2.46011
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.74571

Cumulative Model Updates: 91,058
Cumulative Timesteps: 759,527,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,915.74455
Policy Entropy: 1.88100
Value Function Loss: 0.09505

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.15010
Policy Update Magnitude: 0.58410
Value Function Update Magnitude: 0.66835

Collected Steps per Second: 22,061.95213
Overall Steps per Second: 10,398.09527

Timestep Collection Time: 2.26680
Timestep Consumption Time: 2.54274
PPO Batch Consumption Time: 0.29718
Total Iteration Time: 4.80953

Cumulative Model Updates: 91,064
Cumulative Timesteps: 759,577,598

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 759577598...
Checkpoint 759577598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,916.84299
Policy Entropy: 1.86525
Value Function Loss: 0.08332

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.57739
Value Function Update Magnitude: 0.71964

Collected Steps per Second: 21,423.76387
Overall Steps per Second: 10,167.20611

Timestep Collection Time: 2.33516
Timestep Consumption Time: 2.58536
PPO Batch Consumption Time: 0.30133
Total Iteration Time: 4.92053

Cumulative Model Updates: 91,070
Cumulative Timesteps: 759,627,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,302.72921
Policy Entropy: 1.87167
Value Function Loss: 0.08402

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.58321
Value Function Update Magnitude: 0.65479

Collected Steps per Second: 22,445.84784
Overall Steps per Second: 10,617.35679

Timestep Collection Time: 2.22794
Timestep Consumption Time: 2.48208
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.71002

Cumulative Model Updates: 91,076
Cumulative Timesteps: 759,677,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 759677634...
Checkpoint 759677634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,910.56284
Policy Entropy: 1.89928
Value Function Loss: 0.09291

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.58889
Value Function Update Magnitude: 0.58343

Collected Steps per Second: 22,011.86937
Overall Steps per Second: 10,679.27951

Timestep Collection Time: 2.27232
Timestep Consumption Time: 2.41133
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.68365

Cumulative Model Updates: 91,082
Cumulative Timesteps: 759,727,652

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,774.86919
Policy Entropy: 1.90479
Value Function Loss: 0.09422

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.58504
Value Function Update Magnitude: 0.59087

Collected Steps per Second: 22,510.54225
Overall Steps per Second: 10,577.85242

Timestep Collection Time: 2.22118
Timestep Consumption Time: 2.50568
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.72686

Cumulative Model Updates: 91,088
Cumulative Timesteps: 759,777,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 759777652...
Checkpoint 759777652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,214.73526
Policy Entropy: 1.91837
Value Function Loss: 0.09534

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.58043
Value Function Update Magnitude: 0.64179

Collected Steps per Second: 22,073.39328
Overall Steps per Second: 10,477.73288

Timestep Collection Time: 2.26608
Timestep Consumption Time: 2.50786
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.77393

Cumulative Model Updates: 91,094
Cumulative Timesteps: 759,827,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,624.33985
Policy Entropy: 1.89886
Value Function Loss: 0.08978

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.14270
Policy Update Magnitude: 0.55768
Value Function Update Magnitude: 0.65782

Collected Steps per Second: 22,433.29137
Overall Steps per Second: 10,453.37026

Timestep Collection Time: 2.22963
Timestep Consumption Time: 2.55524
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.78487

Cumulative Model Updates: 91,100
Cumulative Timesteps: 759,877,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 759877690...
Checkpoint 759877690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,136.55832
Policy Entropy: 1.92444
Value Function Loss: 0.09916

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.14446
Policy Update Magnitude: 0.52009
Value Function Update Magnitude: 0.67318

Collected Steps per Second: 21,604.58646
Overall Steps per Second: 10,535.68412

Timestep Collection Time: 2.31432
Timestep Consumption Time: 2.43145
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.74578

Cumulative Model Updates: 91,106
Cumulative Timesteps: 759,927,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,310.25318
Policy Entropy: 1.90905
Value Function Loss: 0.09400

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.56775
Value Function Update Magnitude: 0.68456

Collected Steps per Second: 22,177.98862
Overall Steps per Second: 10,594.23832

Timestep Collection Time: 2.25530
Timestep Consumption Time: 2.46595
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.72125

Cumulative Model Updates: 91,112
Cumulative Timesteps: 759,977,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 759977708...
Checkpoint 759977708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,197.88371
Policy Entropy: 1.89844
Value Function Loss: 0.09050

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.58731
Value Function Update Magnitude: 0.69463

Collected Steps per Second: 21,780.50516
Overall Steps per Second: 10,515.82693

Timestep Collection Time: 2.29756
Timestep Consumption Time: 2.46117
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.75873

Cumulative Model Updates: 91,118
Cumulative Timesteps: 760,027,750

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,059.62573
Policy Entropy: 1.91161
Value Function Loss: 0.08759

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.15533
Policy Update Magnitude: 0.54301
Value Function Update Magnitude: 0.64422

Collected Steps per Second: 22,402.39384
Overall Steps per Second: 10,515.36095

Timestep Collection Time: 2.23280
Timestep Consumption Time: 2.52405
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.75685

Cumulative Model Updates: 91,124
Cumulative Timesteps: 760,077,770

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 760077770...
Checkpoint 760077770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,249.65008
Policy Entropy: 1.92222
Value Function Loss: 0.08852

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.15362
Policy Update Magnitude: 0.49790
Value Function Update Magnitude: 0.63354

Collected Steps per Second: 21,960.31601
Overall Steps per Second: 10,636.85048

Timestep Collection Time: 2.27774
Timestep Consumption Time: 2.42477
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.70252

Cumulative Model Updates: 91,130
Cumulative Timesteps: 760,127,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,694.15702
Policy Entropy: 1.93348
Value Function Loss: 0.09652

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.15398
Policy Update Magnitude: 0.51595
Value Function Update Magnitude: 0.59079

Collected Steps per Second: 22,256.84378
Overall Steps per Second: 10,477.37314

Timestep Collection Time: 2.24677
Timestep Consumption Time: 2.52599
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.77276

Cumulative Model Updates: 91,136
Cumulative Timesteps: 760,177,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 760177796...
Checkpoint 760177796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,149.07806
Policy Entropy: 1.91277
Value Function Loss: 0.09342

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.16074
Policy Update Magnitude: 0.54526
Value Function Update Magnitude: 0.68259

Collected Steps per Second: 21,995.37144
Overall Steps per Second: 10,573.49408

Timestep Collection Time: 2.27375
Timestep Consumption Time: 2.45619
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.72994

Cumulative Model Updates: 91,142
Cumulative Timesteps: 760,227,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,291.66579
Policy Entropy: 1.90639
Value Function Loss: 0.09364

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.57059
Value Function Update Magnitude: 0.75600

Collected Steps per Second: 21,962.13093
Overall Steps per Second: 10,347.92482

Timestep Collection Time: 2.27801
Timestep Consumption Time: 2.55677
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 4.83479

Cumulative Model Updates: 91,148
Cumulative Timesteps: 760,277,838

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 760277838...
Checkpoint 760277838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,030.51911
Policy Entropy: 1.91527
Value Function Loss: 0.09091

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13994
Policy Update Magnitude: 0.59481
Value Function Update Magnitude: 0.76212

Collected Steps per Second: 22,078.71299
Overall Steps per Second: 10,445.55619

Timestep Collection Time: 2.26616
Timestep Consumption Time: 2.52381
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.78998

Cumulative Model Updates: 91,154
Cumulative Timesteps: 760,327,872

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,885.79149
Policy Entropy: 1.91851
Value Function Loss: 0.09136

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.58943
Value Function Update Magnitude: 0.69451

Collected Steps per Second: 22,159.15657
Overall Steps per Second: 10,539.83991

Timestep Collection Time: 2.25758
Timestep Consumption Time: 2.48880
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.74637

Cumulative Model Updates: 91,160
Cumulative Timesteps: 760,377,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 760377898...
Checkpoint 760377898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,294.49235
Policy Entropy: 1.91613
Value Function Loss: 0.09191

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.59436
Value Function Update Magnitude: 0.57285

Collected Steps per Second: 21,651.65415
Overall Steps per Second: 10,470.12581

Timestep Collection Time: 2.31022
Timestep Consumption Time: 2.46719
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.77740

Cumulative Model Updates: 91,166
Cumulative Timesteps: 760,427,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,975.65086
Policy Entropy: 1.88706
Value Function Loss: 0.08849

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12998
Policy Update Magnitude: 0.59101
Value Function Update Magnitude: 0.52111

Collected Steps per Second: 22,266.49713
Overall Steps per Second: 10,460.17555

Timestep Collection Time: 2.24562
Timestep Consumption Time: 2.53461
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.78023

Cumulative Model Updates: 91,172
Cumulative Timesteps: 760,477,920

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 760477920...
Checkpoint 760477920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,671.34089
Policy Entropy: 1.88966
Value Function Loss: 0.09479

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.60650
Value Function Update Magnitude: 0.47301

Collected Steps per Second: 21,183.29832
Overall Steps per Second: 10,241.79543

Timestep Collection Time: 2.36044
Timestep Consumption Time: 2.52171
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.88215

Cumulative Model Updates: 91,178
Cumulative Timesteps: 760,527,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,432.95513
Policy Entropy: 1.87968
Value Function Loss: 0.08752

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.60862
Value Function Update Magnitude: 0.58480

Collected Steps per Second: 22,290.15892
Overall Steps per Second: 10,443.26002

Timestep Collection Time: 2.24323
Timestep Consumption Time: 2.54474
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.78797

Cumulative Model Updates: 91,184
Cumulative Timesteps: 760,577,924

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 760577924...
Checkpoint 760577924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,201.87240
Policy Entropy: 1.89203
Value Function Loss: 0.09000

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14616
Policy Update Magnitude: 0.57707
Value Function Update Magnitude: 0.69957

Collected Steps per Second: 21,570.89334
Overall Steps per Second: 10,302.04610

Timestep Collection Time: 2.31896
Timestep Consumption Time: 2.53658
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.85554

Cumulative Model Updates: 91,190
Cumulative Timesteps: 760,627,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,216.68761
Policy Entropy: 1.88594
Value Function Loss: 0.08753

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13899
Policy Update Magnitude: 0.54753
Value Function Update Magnitude: 0.61554

Collected Steps per Second: 22,418.18204
Overall Steps per Second: 10,754.50494

Timestep Collection Time: 2.23167
Timestep Consumption Time: 2.42033
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.65200

Cumulative Model Updates: 91,196
Cumulative Timesteps: 760,677,976

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 760677976...
Checkpoint 760677976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,271.36506
Policy Entropy: 1.87955
Value Function Loss: 0.09642

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.14288
Policy Update Magnitude: 0.55732
Value Function Update Magnitude: 0.49947

Collected Steps per Second: 21,960.84452
Overall Steps per Second: 10,603.36029

Timestep Collection Time: 2.27733
Timestep Consumption Time: 2.43929
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.71662

Cumulative Model Updates: 91,202
Cumulative Timesteps: 760,727,988

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,249.30324
Policy Entropy: 1.88159
Value Function Loss: 0.09696

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.16015
Policy Update Magnitude: 0.51336
Value Function Update Magnitude: 0.54392

Collected Steps per Second: 22,401.13102
Overall Steps per Second: 10,531.48736

Timestep Collection Time: 2.23373
Timestep Consumption Time: 2.51755
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.75128

Cumulative Model Updates: 91,208
Cumulative Timesteps: 760,778,026

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 760778026...
Checkpoint 760778026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,140.25606
Policy Entropy: 1.87519
Value Function Loss: 0.09381

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.14701
Policy Update Magnitude: 0.55226
Value Function Update Magnitude: 0.58596

Collected Steps per Second: 21,623.60663
Overall Steps per Second: 10,344.48111

Timestep Collection Time: 2.31247
Timestep Consumption Time: 2.52141
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.83388

Cumulative Model Updates: 91,214
Cumulative Timesteps: 760,828,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,508.40182
Policy Entropy: 1.88053
Value Function Loss: 0.08987

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.58057
Value Function Update Magnitude: 0.62055

Collected Steps per Second: 22,418.46687
Overall Steps per Second: 10,665.50731

Timestep Collection Time: 2.23057
Timestep Consumption Time: 2.45800
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.68857

Cumulative Model Updates: 91,220
Cumulative Timesteps: 760,878,036

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 760878036...
Checkpoint 760878036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,725.48759
Policy Entropy: 1.86595
Value Function Loss: 0.08950

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.58693
Value Function Update Magnitude: 0.62582

Collected Steps per Second: 21,634.95330
Overall Steps per Second: 10,179.86007

Timestep Collection Time: 2.31126
Timestep Consumption Time: 2.60079
PPO Batch Consumption Time: 0.30716
Total Iteration Time: 4.91205

Cumulative Model Updates: 91,226
Cumulative Timesteps: 760,928,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,798.49112
Policy Entropy: 1.86882
Value Function Loss: 0.08743

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.57793
Value Function Update Magnitude: 0.71199

Collected Steps per Second: 22,383.81648
Overall Steps per Second: 10,548.98159

Timestep Collection Time: 2.23411
Timestep Consumption Time: 2.50644
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.74055

Cumulative Model Updates: 91,232
Cumulative Timesteps: 760,978,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 760978048...
Checkpoint 760978048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,238.81517
Policy Entropy: 1.86871
Value Function Loss: 0.08804

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.58752
Value Function Update Magnitude: 0.68314

Collected Steps per Second: 21,799.04151
Overall Steps per Second: 10,586.96778

Timestep Collection Time: 2.29460
Timestep Consumption Time: 2.43008
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.72468

Cumulative Model Updates: 91,238
Cumulative Timesteps: 761,028,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,108.08138
Policy Entropy: 1.86696
Value Function Loss: 0.08901

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13705
Policy Update Magnitude: 0.58887
Value Function Update Magnitude: 0.55622

Collected Steps per Second: 22,424.75535
Overall Steps per Second: 10,541.09626

Timestep Collection Time: 2.23057
Timestep Consumption Time: 2.51467
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.74524

Cumulative Model Updates: 91,244
Cumulative Timesteps: 761,078,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 761078088...
Checkpoint 761078088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,314.07464
Policy Entropy: 1.86597
Value Function Loss: 0.09312

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.57662
Value Function Update Magnitude: 0.69414

Collected Steps per Second: 21,612.42001
Overall Steps per Second: 10,354.75461

Timestep Collection Time: 2.31358
Timestep Consumption Time: 2.51532
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.82889

Cumulative Model Updates: 91,250
Cumulative Timesteps: 761,128,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,031.13824
Policy Entropy: 1.85670
Value Function Loss: 0.09204

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.60386
Value Function Update Magnitude: 0.77374

Collected Steps per Second: 22,335.77209
Overall Steps per Second: 10,653.66604

Timestep Collection Time: 2.24062
Timestep Consumption Time: 2.45692
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.69754

Cumulative Model Updates: 91,256
Cumulative Timesteps: 761,178,136

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 761178136...
Checkpoint 761178136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,301.39089
Policy Entropy: 1.87616
Value Function Loss: 0.09564

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.60213
Value Function Update Magnitude: 0.74402

Collected Steps per Second: 21,399.59183
Overall Steps per Second: 10,353.34168

Timestep Collection Time: 2.33733
Timestep Consumption Time: 2.49376
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.83110

Cumulative Model Updates: 91,262
Cumulative Timesteps: 761,228,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,711.48724
Policy Entropy: 1.88974
Value Function Loss: 0.09198

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.59629
Value Function Update Magnitude: 0.78284

Collected Steps per Second: 22,372.97428
Overall Steps per Second: 10,495.17763

Timestep Collection Time: 2.23627
Timestep Consumption Time: 2.53087
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.76714

Cumulative Model Updates: 91,268
Cumulative Timesteps: 761,278,186

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 761278186...
Checkpoint 761278186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,065.44570
Policy Entropy: 1.89400
Value Function Loss: 0.08590

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.59559
Value Function Update Magnitude: 0.72607

Collected Steps per Second: 22,136.94644
Overall Steps per Second: 10,545.24704

Timestep Collection Time: 2.25957
Timestep Consumption Time: 2.48380
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.74337

Cumulative Model Updates: 91,274
Cumulative Timesteps: 761,328,206

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,621.94934
Policy Entropy: 1.89976
Value Function Loss: 0.08628

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13656
Policy Update Magnitude: 0.58499
Value Function Update Magnitude: 0.60782

Collected Steps per Second: 22,556.65505
Overall Steps per Second: 10,516.72255

Timestep Collection Time: 2.21797
Timestep Consumption Time: 2.53921
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.75719

Cumulative Model Updates: 91,280
Cumulative Timesteps: 761,378,236

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 761378236...
Checkpoint 761378236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,458.03369
Policy Entropy: 1.89283
Value Function Loss: 0.09138

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.56582
Value Function Update Magnitude: 0.63264

Collected Steps per Second: 21,559.93812
Overall Steps per Second: 10,477.17150

Timestep Collection Time: 2.31995
Timestep Consumption Time: 2.45405
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.77400

Cumulative Model Updates: 91,286
Cumulative Timesteps: 761,428,254

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,660.60889
Policy Entropy: 1.89320
Value Function Loss: 0.09460

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.58166
Value Function Update Magnitude: 0.60219

Collected Steps per Second: 22,265.74830
Overall Steps per Second: 10,567.40252

Timestep Collection Time: 2.24560
Timestep Consumption Time: 2.48593
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.73153

Cumulative Model Updates: 91,292
Cumulative Timesteps: 761,478,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 761478254...
Checkpoint 761478254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,991.79102
Policy Entropy: 1.88668
Value Function Loss: 0.09230

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.14720
Policy Update Magnitude: 0.54759
Value Function Update Magnitude: 0.53211

Collected Steps per Second: 21,956.94185
Overall Steps per Second: 10,651.77315

Timestep Collection Time: 2.27828
Timestep Consumption Time: 2.41803
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.69631

Cumulative Model Updates: 91,298
Cumulative Timesteps: 761,528,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,330.02605
Policy Entropy: 1.88277
Value Function Loss: 0.09308

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.15017
Policy Update Magnitude: 0.52327
Value Function Update Magnitude: 0.48080

Collected Steps per Second: 21,885.86946
Overall Steps per Second: 10,335.53356

Timestep Collection Time: 2.28568
Timestep Consumption Time: 2.55433
PPO Batch Consumption Time: 0.29784
Total Iteration Time: 4.84000

Cumulative Model Updates: 91,304
Cumulative Timesteps: 761,578,302

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 761578302...
Checkpoint 761578302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,479.86677
Policy Entropy: 1.87748
Value Function Loss: 0.09209

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.14883
Policy Update Magnitude: 0.48835
Value Function Update Magnitude: 0.41459

Collected Steps per Second: 21,244.39092
Overall Steps per Second: 10,214.13070

Timestep Collection Time: 2.35375
Timestep Consumption Time: 2.54182
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.89557

Cumulative Model Updates: 91,310
Cumulative Timesteps: 761,628,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,192.39641
Policy Entropy: 1.88858
Value Function Loss: 0.09528

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.15674
Policy Update Magnitude: 0.47774
Value Function Update Magnitude: 0.37398

Collected Steps per Second: 22,198.62014
Overall Steps per Second: 10,509.75638

Timestep Collection Time: 2.25347
Timestep Consumption Time: 2.50629
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.75977

Cumulative Model Updates: 91,316
Cumulative Timesteps: 761,678,330

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 761678330...
Checkpoint 761678330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,314.21456
Policy Entropy: 1.88306
Value Function Loss: 0.09342

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.49838
Value Function Update Magnitude: 0.35376

Collected Steps per Second: 22,002.39865
Overall Steps per Second: 10,585.79435

Timestep Collection Time: 2.27302
Timestep Consumption Time: 2.45142
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.72444

Cumulative Model Updates: 91,322
Cumulative Timesteps: 761,728,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,891.67536
Policy Entropy: 1.89841
Value Function Loss: 0.09272

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.14064
Policy Update Magnitude: 0.55833
Value Function Update Magnitude: 0.39045

Collected Steps per Second: 22,288.03930
Overall Steps per Second: 10,509.02413

Timestep Collection Time: 2.24336
Timestep Consumption Time: 2.51446
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.75782

Cumulative Model Updates: 91,328
Cumulative Timesteps: 761,778,342

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 761778342...
Checkpoint 761778342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,069.08081
Policy Entropy: 1.88945
Value Function Loss: 0.09401

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.54672
Value Function Update Magnitude: 0.39139

Collected Steps per Second: 21,473.31005
Overall Steps per Second: 10,289.16345

Timestep Collection Time: 2.33052
Timestep Consumption Time: 2.53324
PPO Batch Consumption Time: 0.29836
Total Iteration Time: 4.86376

Cumulative Model Updates: 91,334
Cumulative Timesteps: 761,828,386

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,962.33771
Policy Entropy: 1.90077
Value Function Loss: 0.09393

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.54690
Value Function Update Magnitude: 0.42821

Collected Steps per Second: 21,954.20908
Overall Steps per Second: 10,375.05395

Timestep Collection Time: 2.27792
Timestep Consumption Time: 2.54229
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.82022

Cumulative Model Updates: 91,340
Cumulative Timesteps: 761,878,396

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 761878396...
Checkpoint 761878396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,320.62093
Policy Entropy: 1.89556
Value Function Loss: 0.08860

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.55908
Value Function Update Magnitude: 0.56096

Collected Steps per Second: 21,903.47569
Overall Steps per Second: 10,599.69320

Timestep Collection Time: 2.28430
Timestep Consumption Time: 2.43603
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.72033

Cumulative Model Updates: 91,346
Cumulative Timesteps: 761,928,430

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,448.56305
Policy Entropy: 1.90434
Value Function Loss: 0.08490

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.56860
Value Function Update Magnitude: 0.66804

Collected Steps per Second: 22,320.75300
Overall Steps per Second: 10,504.09775

Timestep Collection Time: 2.24016
Timestep Consumption Time: 2.52008
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.76024

Cumulative Model Updates: 91,352
Cumulative Timesteps: 761,978,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 761978432...
Checkpoint 761978432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,582.36437
Policy Entropy: 1.88783
Value Function Loss: 0.08695

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.57424
Value Function Update Magnitude: 0.62126

Collected Steps per Second: 21,462.49107
Overall Steps per Second: 10,375.19602

Timestep Collection Time: 2.33095
Timestep Consumption Time: 2.49093
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.82188

Cumulative Model Updates: 91,358
Cumulative Timesteps: 762,028,460

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,863.13708
Policy Entropy: 1.88628
Value Function Loss: 0.09025

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.57875
Value Function Update Magnitude: 0.68726

Collected Steps per Second: 22,540.73359
Overall Steps per Second: 10,692.01029

Timestep Collection Time: 2.22034
Timestep Consumption Time: 2.46054
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.68088

Cumulative Model Updates: 91,364
Cumulative Timesteps: 762,078,508

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 762078508...
Checkpoint 762078508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,392.71611
Policy Entropy: 1.88409
Value Function Loss: 0.09365

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.57645
Value Function Update Magnitude: 0.65566

Collected Steps per Second: 21,961.71351
Overall Steps per Second: 10,633.37500

Timestep Collection Time: 2.27833
Timestep Consumption Time: 2.42723
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.70556

Cumulative Model Updates: 91,370
Cumulative Timesteps: 762,128,544

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,090.74848
Policy Entropy: 1.89657
Value Function Loss: 0.09649

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14863
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.53553

Collected Steps per Second: 22,228.98925
Overall Steps per Second: 10,488.73724

Timestep Collection Time: 2.25012
Timestep Consumption Time: 2.51861
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.76873

Cumulative Model Updates: 91,376
Cumulative Timesteps: 762,178,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 762178562...
Checkpoint 762178562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,032.81281
Policy Entropy: 1.90808
Value Function Loss: 0.09869

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.16358
Policy Update Magnitude: 0.50566
Value Function Update Magnitude: 0.47256

Collected Steps per Second: 21,673.60031
Overall Steps per Second: 10,481.67763

Timestep Collection Time: 2.30843
Timestep Consumption Time: 2.46485
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.77328

Cumulative Model Updates: 91,382
Cumulative Timesteps: 762,228,594

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,483.80867
Policy Entropy: 1.90542
Value Function Loss: 0.09316

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.15708
Policy Update Magnitude: 0.48952
Value Function Update Magnitude: 0.41332

Collected Steps per Second: 22,243.54350
Overall Steps per Second: 10,607.90444

Timestep Collection Time: 2.24856
Timestep Consumption Time: 2.46641
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.71497

Cumulative Model Updates: 91,388
Cumulative Timesteps: 762,278,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 762278610...
Checkpoint 762278610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,419.03380
Policy Entropy: 1.92863
Value Function Loss: 0.09425

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.52828
Value Function Update Magnitude: 0.42711

Collected Steps per Second: 21,530.60172
Overall Steps per Second: 10,307.94602

Timestep Collection Time: 2.32348
Timestep Consumption Time: 2.52967
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.85315

Cumulative Model Updates: 91,394
Cumulative Timesteps: 762,328,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,881.05282
Policy Entropy: 1.91428
Value Function Loss: 0.09327

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.56753
Value Function Update Magnitude: 0.39320

Collected Steps per Second: 22,199.05863
Overall Steps per Second: 10,452.90655

Timestep Collection Time: 2.25325
Timestep Consumption Time: 2.53202
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.78527

Cumulative Model Updates: 91,400
Cumulative Timesteps: 762,378,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 762378656...
Checkpoint 762378656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,226.11274
Policy Entropy: 1.91310
Value Function Loss: 0.09024

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.13919
Policy Update Magnitude: 0.57193
Value Function Update Magnitude: 0.49766

Collected Steps per Second: 21,936.11734
Overall Steps per Second: 10,550.73259

Timestep Collection Time: 2.28053
Timestep Consumption Time: 2.46094
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.74147

Cumulative Model Updates: 91,406
Cumulative Timesteps: 762,428,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,311.92677
Policy Entropy: 1.89832
Value Function Loss: 0.08803

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.56769
Value Function Update Magnitude: 0.56403

Collected Steps per Second: 22,116.35054
Overall Steps per Second: 10,442.25468

Timestep Collection Time: 2.26158
Timestep Consumption Time: 2.52838
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.78996

Cumulative Model Updates: 91,412
Cumulative Timesteps: 762,478,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 762478700...
Checkpoint 762478700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,656.34280
Policy Entropy: 1.90548
Value Function Loss: 0.08749

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.56311
Value Function Update Magnitude: 0.64453

Collected Steps per Second: 21,645.75307
Overall Steps per Second: 10,354.87383

Timestep Collection Time: 2.31122
Timestep Consumption Time: 2.52013
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.83135

Cumulative Model Updates: 91,418
Cumulative Timesteps: 762,528,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,029.61525
Policy Entropy: 1.89754
Value Function Loss: 0.08445

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.57016
Value Function Update Magnitude: 0.67499

Collected Steps per Second: 22,693.03639
Overall Steps per Second: 10,705.10023

Timestep Collection Time: 2.20499
Timestep Consumption Time: 2.46923
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.67422

Cumulative Model Updates: 91,424
Cumulative Timesteps: 762,578,766

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 762578766...
Checkpoint 762578766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,087.68908
Policy Entropy: 1.88455
Value Function Loss: 0.08343

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.57299
Value Function Update Magnitude: 0.62942

Collected Steps per Second: 21,804.27499
Overall Steps per Second: 10,399.47722

Timestep Collection Time: 2.29423
Timestep Consumption Time: 2.51601
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.81024

Cumulative Model Updates: 91,430
Cumulative Timesteps: 762,628,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,125.86635
Policy Entropy: 1.87924
Value Function Loss: 0.08648

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.58222
Value Function Update Magnitude: 0.59624

Collected Steps per Second: 21,904.38197
Overall Steps per Second: 10,352.29521

Timestep Collection Time: 2.28283
Timestep Consumption Time: 2.54740
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.83023

Cumulative Model Updates: 91,436
Cumulative Timesteps: 762,678,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 762678794...
Checkpoint 762678794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,106.98390
Policy Entropy: 1.87694
Value Function Loss: 0.08824

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.16732
Policy Update Magnitude: 0.54949
Value Function Update Magnitude: 0.64224

Collected Steps per Second: 21,813.84729
Overall Steps per Second: 10,573.22989

Timestep Collection Time: 2.29414
Timestep Consumption Time: 2.43895
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.73309

Cumulative Model Updates: 91,442
Cumulative Timesteps: 762,728,838

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,825.42447
Policy Entropy: 1.88801
Value Function Loss: 0.08409

Mean KL Divergence: 0.02783
SB3 Clip Fraction: 0.20380
Policy Update Magnitude: 0.46524
Value Function Update Magnitude: 0.69971

Collected Steps per Second: 22,279.80460
Overall Steps per Second: 10,466.52791

Timestep Collection Time: 2.24598
Timestep Consumption Time: 2.53497
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.78096

Cumulative Model Updates: 91,448
Cumulative Timesteps: 762,778,878

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 762778878...
Checkpoint 762778878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,999.33930
Policy Entropy: 1.89091
Value Function Loss: 0.08636

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.16730
Policy Update Magnitude: 0.42099
Value Function Update Magnitude: 0.69243

Collected Steps per Second: 21,936.28260
Overall Steps per Second: 10,156.43880

Timestep Collection Time: 2.28024
Timestep Consumption Time: 2.64471
PPO Batch Consumption Time: 0.31325
Total Iteration Time: 4.92495

Cumulative Model Updates: 91,454
Cumulative Timesteps: 762,828,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,569.70077
Policy Entropy: 1.88695
Value Function Loss: 0.08089

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.14563
Policy Update Magnitude: 0.45304
Value Function Update Magnitude: 0.55050

Collected Steps per Second: 21,759.85466
Overall Steps per Second: 10,513.53882

Timestep Collection Time: 2.29956
Timestep Consumption Time: 2.45983
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.75939

Cumulative Model Updates: 91,460
Cumulative Timesteps: 762,878,936

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 762878936...
Checkpoint 762878936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,509.99805
Policy Entropy: 1.89325
Value Function Loss: 0.08066

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.15449
Policy Update Magnitude: 0.48682
Value Function Update Magnitude: 0.43672

Collected Steps per Second: 21,661.54296
Overall Steps per Second: 10,356.06139

Timestep Collection Time: 2.30962
Timestep Consumption Time: 2.52136
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.83099

Cumulative Model Updates: 91,466
Cumulative Timesteps: 762,928,966

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,346.79251
Policy Entropy: 1.89439
Value Function Loss: 0.07983

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.53758
Value Function Update Magnitude: 0.49044

Collected Steps per Second: 22,529.63056
Overall Steps per Second: 10,715.80341

Timestep Collection Time: 2.21992
Timestep Consumption Time: 2.44739
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.66731

Cumulative Model Updates: 91,472
Cumulative Timesteps: 762,978,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 762978980...
Checkpoint 762978980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,060.78727
Policy Entropy: 1.90149
Value Function Loss: 0.08459

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.15869
Policy Update Magnitude: 0.55455
Value Function Update Magnitude: 0.51115

Collected Steps per Second: 22,001.51288
Overall Steps per Second: 10,469.25608

Timestep Collection Time: 2.27275
Timestep Consumption Time: 2.50352
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.77627

Cumulative Model Updates: 91,478
Cumulative Timesteps: 763,028,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,098.84698
Policy Entropy: 1.91511
Value Function Loss: 0.09142

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.16508
Policy Update Magnitude: 0.56779
Value Function Update Magnitude: 0.46945

Collected Steps per Second: 22,654.03002
Overall Steps per Second: 10,743.69969

Timestep Collection Time: 2.20835
Timestep Consumption Time: 2.44815
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.65650

Cumulative Model Updates: 91,484
Cumulative Timesteps: 763,079,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 763079012...
Checkpoint 763079012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,173.04185
Policy Entropy: 1.91511
Value Function Loss: 0.09757

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.17455
Policy Update Magnitude: 0.53953
Value Function Update Magnitude: 0.45754

Collected Steps per Second: 22,049.69966
Overall Steps per Second: 10,592.50546

Timestep Collection Time: 2.26797
Timestep Consumption Time: 2.45311
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.72107

Cumulative Model Updates: 91,490
Cumulative Timesteps: 763,129,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,319.28151
Policy Entropy: 1.91984
Value Function Loss: 0.10245

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.15545
Policy Update Magnitude: 0.55363
Value Function Update Magnitude: 0.41837

Collected Steps per Second: 22,543.00069
Overall Steps per Second: 10,520.42705

Timestep Collection Time: 2.21825
Timestep Consumption Time: 2.53498
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.75323

Cumulative Model Updates: 91,496
Cumulative Timesteps: 763,179,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 763179026...
Checkpoint 763179026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,048.86644
Policy Entropy: 1.90866
Value Function Loss: 0.10677

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.15542
Policy Update Magnitude: 0.55253
Value Function Update Magnitude: 0.36768

Collected Steps per Second: 21,722.25710
Overall Steps per Second: 10,567.25979

Timestep Collection Time: 2.30206
Timestep Consumption Time: 2.43010
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.73216

Cumulative Model Updates: 91,502
Cumulative Timesteps: 763,229,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,371.17177
Policy Entropy: 1.91194
Value Function Loss: 0.09992

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.15299
Policy Update Magnitude: 0.54636
Value Function Update Magnitude: 0.33333

Collected Steps per Second: 22,359.79605
Overall Steps per Second: 10,438.73980

Timestep Collection Time: 2.23625
Timestep Consumption Time: 2.55380
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.79004

Cumulative Model Updates: 91,508
Cumulative Timesteps: 763,279,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 763279034...
Checkpoint 763279034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,724.73516
Policy Entropy: 1.89754
Value Function Loss: 0.09915

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.16221
Policy Update Magnitude: 0.54357
Value Function Update Magnitude: 0.32953

Collected Steps per Second: 22,430.06919
Overall Steps per Second: 10,715.68341

Timestep Collection Time: 2.22942
Timestep Consumption Time: 2.43720
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.66662

Cumulative Model Updates: 91,514
Cumulative Timesteps: 763,329,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,941.04073
Policy Entropy: 1.89493
Value Function Loss: 0.09038

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.16408
Policy Update Magnitude: 0.52191
Value Function Update Magnitude: 0.43428

Collected Steps per Second: 22,685.99021
Overall Steps per Second: 10,747.83258

Timestep Collection Time: 2.20427
Timestep Consumption Time: 2.44839
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.65266

Cumulative Model Updates: 91,520
Cumulative Timesteps: 763,379,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 763379046...
Checkpoint 763379046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,756.59680
Policy Entropy: 1.88991
Value Function Loss: 0.08735

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14346
Policy Update Magnitude: 0.56717
Value Function Update Magnitude: 0.62136

Collected Steps per Second: 21,725.51014
Overall Steps per Second: 10,335.81058

Timestep Collection Time: 2.30347
Timestep Consumption Time: 2.53834
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.84181

Cumulative Model Updates: 91,526
Cumulative Timesteps: 763,429,090

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,582.54490
Policy Entropy: 1.90393
Value Function Loss: 0.08216

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.56815
Value Function Update Magnitude: 0.66628

Collected Steps per Second: 22,687.16537
Overall Steps per Second: 10,766.91818

Timestep Collection Time: 2.20459
Timestep Consumption Time: 2.44075
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.64534

Cumulative Model Updates: 91,532
Cumulative Timesteps: 763,479,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 763479106...
Checkpoint 763479106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,543.65541
Policy Entropy: 1.90637
Value Function Loss: 0.08578

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.56748
Value Function Update Magnitude: 0.60564

Collected Steps per Second: 22,164.51613
Overall Steps per Second: 10,645.96147

Timestep Collection Time: 2.25703
Timestep Consumption Time: 2.44203
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.69906

Cumulative Model Updates: 91,538
Cumulative Timesteps: 763,529,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,670.57268
Policy Entropy: 1.89022
Value Function Loss: 0.09099

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.13489
Policy Update Magnitude: 0.57147
Value Function Update Magnitude: 0.53658

Collected Steps per Second: 22,478.33940
Overall Steps per Second: 10,531.35363

Timestep Collection Time: 2.22472
Timestep Consumption Time: 2.52377
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.74849

Cumulative Model Updates: 91,544
Cumulative Timesteps: 763,579,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 763579140...
Checkpoint 763579140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,040.55426
Policy Entropy: 1.88044
Value Function Loss: 0.09131

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.57450
Value Function Update Magnitude: 0.51189

Collected Steps per Second: 21,817.62555
Overall Steps per Second: 10,631.04106

Timestep Collection Time: 2.29319
Timestep Consumption Time: 2.41303
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.70622

Cumulative Model Updates: 91,550
Cumulative Timesteps: 763,629,172

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,338.76255
Policy Entropy: 1.87302
Value Function Loss: 0.08645

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.57460
Value Function Update Magnitude: 0.53702

Collected Steps per Second: 22,511.59443
Overall Steps per Second: 10,508.11959

Timestep Collection Time: 2.22214
Timestep Consumption Time: 2.53837
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.76051

Cumulative Model Updates: 91,556
Cumulative Timesteps: 763,679,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 763679196...
Checkpoint 763679196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,953.25800
Policy Entropy: 1.88393
Value Function Loss: 0.08834

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.57409
Value Function Update Magnitude: 0.59986

Collected Steps per Second: 21,613.55912
Overall Steps per Second: 10,511.20432

Timestep Collection Time: 2.31355
Timestep Consumption Time: 2.44366
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.75721

Cumulative Model Updates: 91,562
Cumulative Timesteps: 763,729,200

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,474.40558
Policy Entropy: 1.88555
Value Function Loss: 0.08443

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.57612
Value Function Update Magnitude: 0.63456

Collected Steps per Second: 22,629.29319
Overall Steps per Second: 10,508.11007

Timestep Collection Time: 2.21085
Timestep Consumption Time: 2.55023
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.76108

Cumulative Model Updates: 91,568
Cumulative Timesteps: 763,779,230

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 763779230...
Checkpoint 763779230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,316.39447
Policy Entropy: 1.89678
Value Function Loss: 0.08455

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.56773
Value Function Update Magnitude: 0.53716

Collected Steps per Second: 21,815.90988
Overall Steps per Second: 10,581.74969

Timestep Collection Time: 2.29200
Timestep Consumption Time: 2.43331
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.72531

Cumulative Model Updates: 91,574
Cumulative Timesteps: 763,829,232

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,770.15726
Policy Entropy: 1.88922
Value Function Loss: 0.07849

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.55746
Value Function Update Magnitude: 0.47475

Collected Steps per Second: 22,314.27194
Overall Steps per Second: 10,556.48326

Timestep Collection Time: 2.24161
Timestep Consumption Time: 2.49671
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.73832

Cumulative Model Updates: 91,580
Cumulative Timesteps: 763,879,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 763879252...
Checkpoint 763879252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,243.93168
Policy Entropy: 1.88797
Value Function Loss: 0.07523

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.55674
Value Function Update Magnitude: 0.50114

Collected Steps per Second: 21,643.90911
Overall Steps per Second: 10,531.95599

Timestep Collection Time: 2.31132
Timestep Consumption Time: 2.43860
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.74992

Cumulative Model Updates: 91,586
Cumulative Timesteps: 763,929,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,238.37947
Policy Entropy: 1.86684
Value Function Loss: 0.07878

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.55538
Value Function Update Magnitude: 0.58543

Collected Steps per Second: 22,703.34088
Overall Steps per Second: 10,579.76767

Timestep Collection Time: 2.20408
Timestep Consumption Time: 2.52570
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.72978

Cumulative Model Updates: 91,592
Cumulative Timesteps: 763,979,318

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 763979318...
Checkpoint 763979318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,522.18269
Policy Entropy: 1.86309
Value Function Loss: 0.07845

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12814
Policy Update Magnitude: 0.56807
Value Function Update Magnitude: 0.65080

Collected Steps per Second: 21,456.61351
Overall Steps per Second: 10,328.37506

Timestep Collection Time: 2.33150
Timestep Consumption Time: 2.51205
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.84355

Cumulative Model Updates: 91,598
Cumulative Timesteps: 764,029,344

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,314.30010
Policy Entropy: 1.84982
Value Function Loss: 0.07535

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.56071
Value Function Update Magnitude: 0.63853

Collected Steps per Second: 22,538.78528
Overall Steps per Second: 10,757.67803

Timestep Collection Time: 2.21946
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.65007

Cumulative Model Updates: 91,604
Cumulative Timesteps: 764,079,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 764079368...
Checkpoint 764079368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,474.98742
Policy Entropy: 1.86414
Value Function Loss: 0.07717

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.56829
Value Function Update Magnitude: 0.62041

Collected Steps per Second: 22,087.93131
Overall Steps per Second: 10,601.56146

Timestep Collection Time: 2.26440
Timestep Consumption Time: 2.45339
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.71780

Cumulative Model Updates: 91,610
Cumulative Timesteps: 764,129,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,498.83450
Policy Entropy: 1.86288
Value Function Loss: 0.07530

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.56652
Value Function Update Magnitude: 0.64610

Collected Steps per Second: 22,603.02205
Overall Steps per Second: 10,573.94757

Timestep Collection Time: 2.21254
Timestep Consumption Time: 2.51701
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.72955

Cumulative Model Updates: 91,616
Cumulative Timesteps: 764,179,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 764179394...
Checkpoint 764179394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,705.13843
Policy Entropy: 1.88736
Value Function Loss: 0.08198

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12865
Policy Update Magnitude: 0.56369
Value Function Update Magnitude: 0.59665

Collected Steps per Second: 21,849.96804
Overall Steps per Second: 10,564.87859

Timestep Collection Time: 2.28897
Timestep Consumption Time: 2.44501
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.73399

Cumulative Model Updates: 91,622
Cumulative Timesteps: 764,229,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,827.70923
Policy Entropy: 1.87465
Value Function Loss: 0.08611

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.57411
Value Function Update Magnitude: 0.56830

Collected Steps per Second: 22,518.69800
Overall Steps per Second: 10,598.07424

Timestep Collection Time: 2.22073
Timestep Consumption Time: 2.49786
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.71859

Cumulative Model Updates: 91,628
Cumulative Timesteps: 764,279,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 764279416...
Checkpoint 764279416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,450.64939
Policy Entropy: 1.87786
Value Function Loss: 0.09653

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.57451
Value Function Update Magnitude: 0.60625

Collected Steps per Second: 22,367.79624
Overall Steps per Second: 10,528.90192

Timestep Collection Time: 2.23688
Timestep Consumption Time: 2.51519
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.75206

Cumulative Model Updates: 91,634
Cumulative Timesteps: 764,329,450

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,791.37013
Policy Entropy: 1.86736
Value Function Loss: 0.09267

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.57724
Value Function Update Magnitude: 0.56246

Collected Steps per Second: 22,571.98028
Overall Steps per Second: 10,789.26844

Timestep Collection Time: 2.21629
Timestep Consumption Time: 2.42036
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.63664

Cumulative Model Updates: 91,640
Cumulative Timesteps: 764,379,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 764379476...
Checkpoint 764379476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,444.64406
Policy Entropy: 1.86424
Value Function Loss: 0.09785

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.58621
Value Function Update Magnitude: 0.46316

Collected Steps per Second: 21,751.19943
Overall Steps per Second: 10,377.60618

Timestep Collection Time: 2.29946
Timestep Consumption Time: 2.52015
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.81961

Cumulative Model Updates: 91,646
Cumulative Timesteps: 764,429,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,814.38285
Policy Entropy: 1.85648
Value Function Loss: 0.09343

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.57308
Value Function Update Magnitude: 0.56558

Collected Steps per Second: 22,538.88952
Overall Steps per Second: 10,733.01916

Timestep Collection Time: 2.21936
Timestep Consumption Time: 2.44121
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.66057

Cumulative Model Updates: 91,652
Cumulative Timesteps: 764,479,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 764479514...
Checkpoint 764479514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,810.44362
Policy Entropy: 1.86105
Value Function Loss: 0.09020

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.55678
Value Function Update Magnitude: 0.66842

Collected Steps per Second: 22,057.97512
Overall Steps per Second: 10,645.09692

Timestep Collection Time: 2.26721
Timestep Consumption Time: 2.43073
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.69794

Cumulative Model Updates: 91,658
Cumulative Timesteps: 764,529,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,087.52426
Policy Entropy: 1.86817
Value Function Loss: 0.08401

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12834
Policy Update Magnitude: 0.56483
Value Function Update Magnitude: 0.63359

Collected Steps per Second: 22,407.47085
Overall Steps per Second: 10,529.24352

Timestep Collection Time: 2.23229
Timestep Consumption Time: 2.51829
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.75058

Cumulative Model Updates: 91,664
Cumulative Timesteps: 764,579,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 764579544...
Checkpoint 764579544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,874.10516
Policy Entropy: 1.85456
Value Function Loss: 0.08390

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12828
Policy Update Magnitude: 0.56985
Value Function Update Magnitude: 0.59876

Collected Steps per Second: 21,958.37486
Overall Steps per Second: 10,578.90234

Timestep Collection Time: 2.27822
Timestep Consumption Time: 2.45063
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.72885

Cumulative Model Updates: 91,670
Cumulative Timesteps: 764,629,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,141.96636
Policy Entropy: 1.85188
Value Function Loss: 0.08252

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.55676
Value Function Update Magnitude: 0.58456

Collected Steps per Second: 22,181.55923
Overall Steps per Second: 10,535.28940

Timestep Collection Time: 2.25458
Timestep Consumption Time: 2.49233
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.74690

Cumulative Model Updates: 91,676
Cumulative Timesteps: 764,679,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 764679580...
Checkpoint 764679580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,822.14388
Policy Entropy: 1.85776
Value Function Loss: 0.08368

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.15558
Policy Update Magnitude: 0.48767
Value Function Update Magnitude: 0.56959

Collected Steps per Second: 22,248.99419
Overall Steps per Second: 10,678.47601

Timestep Collection Time: 2.24837
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.68456

Cumulative Model Updates: 91,682
Cumulative Timesteps: 764,729,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,028.48158
Policy Entropy: 1.87379
Value Function Loss: 0.08040

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.47951
Value Function Update Magnitude: 0.56626

Collected Steps per Second: 22,491.58734
Overall Steps per Second: 10,573.61636

Timestep Collection Time: 2.22501
Timestep Consumption Time: 2.50790
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.73291

Cumulative Model Updates: 91,688
Cumulative Timesteps: 764,779,648

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 764779648...
Checkpoint 764779648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,092.00115
Policy Entropy: 1.88188
Value Function Loss: 0.08057

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.46565
Value Function Update Magnitude: 0.55032

Collected Steps per Second: 22,317.69863
Overall Steps per Second: 10,588.94069

Timestep Collection Time: 2.24055
Timestep Consumption Time: 2.48173
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.72229

Cumulative Model Updates: 91,694
Cumulative Timesteps: 764,829,652

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,819.73175
Policy Entropy: 1.89832
Value Function Loss: 0.08615

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.15036
Policy Update Magnitude: 0.49069
Value Function Update Magnitude: 0.68948

Collected Steps per Second: 22,655.53729
Overall Steps per Second: 10,728.05989

Timestep Collection Time: 2.20811
Timestep Consumption Time: 2.45498
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.66310

Cumulative Model Updates: 91,700
Cumulative Timesteps: 764,879,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 764879678...
Checkpoint 764879678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,005.04768
Policy Entropy: 1.89716
Value Function Loss: 0.08714

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.52871
Value Function Update Magnitude: 0.70761

Collected Steps per Second: 21,662.38844
Overall Steps per Second: 10,625.39379

Timestep Collection Time: 2.30898
Timestep Consumption Time: 2.39842
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.70740

Cumulative Model Updates: 91,706
Cumulative Timesteps: 764,929,696

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,926.42900
Policy Entropy: 1.88768
Value Function Loss: 0.09234

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.57206
Value Function Update Magnitude: 0.67223

Collected Steps per Second: 22,591.70440
Overall Steps per Second: 10,634.70981

Timestep Collection Time: 2.21426
Timestep Consumption Time: 2.48958
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.70384

Cumulative Model Updates: 91,712
Cumulative Timesteps: 764,979,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 764979720...
Checkpoint 764979720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,844.60383
Policy Entropy: 1.89326
Value Function Loss: 0.09112

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.58634
Value Function Update Magnitude: 0.69481

Collected Steps per Second: 21,912.42956
Overall Steps per Second: 10,584.12340

Timestep Collection Time: 2.28300
Timestep Consumption Time: 2.44352
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.72651

Cumulative Model Updates: 91,718
Cumulative Timesteps: 765,029,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,621.10326
Policy Entropy: 1.89811
Value Function Loss: 0.09200

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.58217
Value Function Update Magnitude: 0.71973

Collected Steps per Second: 22,328.01857
Overall Steps per Second: 10,533.81956

Timestep Collection Time: 2.24095
Timestep Consumption Time: 2.50908
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.75003

Cumulative Model Updates: 91,724
Cumulative Timesteps: 765,079,782

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 765079782...
Checkpoint 765079782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,784.57758
Policy Entropy: 1.90588
Value Function Loss: 0.08552

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.57843
Value Function Update Magnitude: 0.72009

Collected Steps per Second: 21,992.35405
Overall Steps per Second: 10,530.25401

Timestep Collection Time: 2.27370
Timestep Consumption Time: 2.47490
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.74860

Cumulative Model Updates: 91,730
Cumulative Timesteps: 765,129,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,014.94432
Policy Entropy: 1.91091
Value Function Loss: 0.08330

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.56836
Value Function Update Magnitude: 0.70383

Collected Steps per Second: 22,442.51999
Overall Steps per Second: 10,528.95138

Timestep Collection Time: 2.22845
Timestep Consumption Time: 2.52150
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.74995

Cumulative Model Updates: 91,736
Cumulative Timesteps: 765,179,798

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 765179798...
Checkpoint 765179798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,408.01467
Policy Entropy: 1.91329
Value Function Loss: 0.08772

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.56611
Value Function Update Magnitude: 0.70607

Collected Steps per Second: 22,145.03234
Overall Steps per Second: 10,504.47769

Timestep Collection Time: 2.25838
Timestep Consumption Time: 2.50263
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.76102

Cumulative Model Updates: 91,742
Cumulative Timesteps: 765,229,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,685.85374
Policy Entropy: 1.92645
Value Function Loss: 0.09285

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.57820
Value Function Update Magnitude: 0.70626

Collected Steps per Second: 22,725.94080
Overall Steps per Second: 10,692.14085

Timestep Collection Time: 2.20118
Timestep Consumption Time: 2.47739
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.67858

Cumulative Model Updates: 91,748
Cumulative Timesteps: 765,279,834

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 765279834...
Checkpoint 765279834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,916.22275
Policy Entropy: 1.90489
Value Function Loss: 0.09312

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.14484
Policy Update Magnitude: 0.58131
Value Function Update Magnitude: 0.70154

Collected Steps per Second: 21,986.37216
Overall Steps per Second: 10,472.69471

Timestep Collection Time: 2.27514
Timestep Consumption Time: 2.50128
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.77642

Cumulative Model Updates: 91,754
Cumulative Timesteps: 765,329,856

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,071.74201
Policy Entropy: 1.91249
Value Function Loss: 0.08868

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13899
Policy Update Magnitude: 0.58195
Value Function Update Magnitude: 0.70349

Collected Steps per Second: 22,697.91866
Overall Steps per Second: 10,614.82099

Timestep Collection Time: 2.20381
Timestep Consumption Time: 2.50865
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.71247

Cumulative Model Updates: 91,760
Cumulative Timesteps: 765,379,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 765379878...
Checkpoint 765379878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,448.37874
Policy Entropy: 1.88533
Value Function Loss: 0.08456

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.57028
Value Function Update Magnitude: 0.63633

Collected Steps per Second: 22,307.19763
Overall Steps per Second: 10,511.81578

Timestep Collection Time: 2.24250
Timestep Consumption Time: 2.51633
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.75884

Cumulative Model Updates: 91,766
Cumulative Timesteps: 765,429,902

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,930.43611
Policy Entropy: 1.88381
Value Function Loss: 0.09453

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.55442
Value Function Update Magnitude: 0.54586

Collected Steps per Second: 22,165.76651
Overall Steps per Second: 10,466.38089

Timestep Collection Time: 2.25573
Timestep Consumption Time: 2.52147
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.77720

Cumulative Model Updates: 91,772
Cumulative Timesteps: 765,479,902

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 765479902...
Checkpoint 765479902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,709.53290
Policy Entropy: 1.87630
Value Function Loss: 0.09799

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.53041
Value Function Update Magnitude: 0.55388

Collected Steps per Second: 21,883.44222
Overall Steps per Second: 10,554.75541

Timestep Collection Time: 2.28483
Timestep Consumption Time: 2.45237
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.73720

Cumulative Model Updates: 91,778
Cumulative Timesteps: 765,529,902

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,361.80199
Policy Entropy: 1.88213
Value Function Loss: 0.09597

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14877
Policy Update Magnitude: 0.48770
Value Function Update Magnitude: 0.57953

Collected Steps per Second: 22,535.26962
Overall Steps per Second: 10,522.79268

Timestep Collection Time: 2.22079
Timestep Consumption Time: 2.53518
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.75596

Cumulative Model Updates: 91,784
Cumulative Timesteps: 765,579,948

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 765579948...
Checkpoint 765579948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,703.08724
Policy Entropy: 1.88606
Value Function Loss: 0.09072

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.54376
Value Function Update Magnitude: 0.58533

Collected Steps per Second: 21,984.84648
Overall Steps per Second: 10,568.90590

Timestep Collection Time: 2.27493
Timestep Consumption Time: 2.45725
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.73218

Cumulative Model Updates: 91,790
Cumulative Timesteps: 765,629,962

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,784.19715
Policy Entropy: 1.87011
Value Function Loss: 0.09130

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.15737
Policy Update Magnitude: 0.51253
Value Function Update Magnitude: 0.68044

Collected Steps per Second: 22,513.23341
Overall Steps per Second: 10,636.53229

Timestep Collection Time: 2.22216
Timestep Consumption Time: 2.48125
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.70341

Cumulative Model Updates: 91,796
Cumulative Timesteps: 765,679,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 765679990...
Checkpoint 765679990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,204.62171
Policy Entropy: 1.87044
Value Function Loss: 0.09162

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.15815
Policy Update Magnitude: 0.50560
Value Function Update Magnitude: 0.76776

Collected Steps per Second: 21,995.26269
Overall Steps per Second: 10,488.88344

Timestep Collection Time: 2.27458
Timestep Consumption Time: 2.49523
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.76981

Cumulative Model Updates: 91,802
Cumulative Timesteps: 765,730,020

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,013.44373
Policy Entropy: 1.87479
Value Function Loss: 0.08955

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.15334
Policy Update Magnitude: 0.53862
Value Function Update Magnitude: 0.80588

Collected Steps per Second: 22,726.01143
Overall Steps per Second: 10,605.37113

Timestep Collection Time: 2.20012
Timestep Consumption Time: 2.51447
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.71459

Cumulative Model Updates: 91,808
Cumulative Timesteps: 765,780,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 765780020...
Checkpoint 765780020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,260.76644
Policy Entropy: 1.90179
Value Function Loss: 0.08883

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.15369
Policy Update Magnitude: 0.53083
Value Function Update Magnitude: 0.86048

Collected Steps per Second: 22,112.57072
Overall Steps per Second: 10,456.47107

Timestep Collection Time: 2.26161
Timestep Consumption Time: 2.52107
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.78268

Cumulative Model Updates: 91,814
Cumulative Timesteps: 765,830,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,358.87227
Policy Entropy: 1.90299
Value Function Loss: 0.08786

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.15829
Policy Update Magnitude: 0.52813
Value Function Update Magnitude: 0.81990

Collected Steps per Second: 22,338.62794
Overall Steps per Second: 10,477.97604

Timestep Collection Time: 2.23845
Timestep Consumption Time: 2.53384
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.77230

Cumulative Model Updates: 91,820
Cumulative Timesteps: 765,880,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 765880034...
Checkpoint 765880034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,491.09233
Policy Entropy: 1.91031
Value Function Loss: 0.08479

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.14926
Policy Update Magnitude: 0.53321
Value Function Update Magnitude: 0.78059

Collected Steps per Second: 21,913.87195
Overall Steps per Second: 10,606.01263

Timestep Collection Time: 2.28212
Timestep Consumption Time: 2.43313
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.71525

Cumulative Model Updates: 91,826
Cumulative Timesteps: 765,930,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,525.44472
Policy Entropy: 1.91183
Value Function Loss: 0.08810

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.15383
Policy Update Magnitude: 0.53722
Value Function Update Magnitude: 0.80960

Collected Steps per Second: 22,059.14234
Overall Steps per Second: 10,457.97534

Timestep Collection Time: 2.26718
Timestep Consumption Time: 2.51501
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.78219

Cumulative Model Updates: 91,832
Cumulative Timesteps: 765,980,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 765980056...
Checkpoint 765980056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,178.98672
Policy Entropy: 1.92710
Value Function Loss: 0.08539

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.17407
Policy Update Magnitude: 0.52133
Value Function Update Magnitude: 0.77231

Collected Steps per Second: 21,515.90496
Overall Steps per Second: 10,314.83854

Timestep Collection Time: 2.32423
Timestep Consumption Time: 2.52393
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.84816

Cumulative Model Updates: 91,838
Cumulative Timesteps: 766,030,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,086.00176
Policy Entropy: 1.92514
Value Function Loss: 0.08775

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.16383
Policy Update Magnitude: 0.48543
Value Function Update Magnitude: 0.67049

Collected Steps per Second: 22,645.02432
Overall Steps per Second: 10,748.38863

Timestep Collection Time: 2.20861
Timestep Consumption Time: 2.44455
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.65316

Cumulative Model Updates: 91,844
Cumulative Timesteps: 766,080,078

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 766080078...
Checkpoint 766080078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,328.22574
Policy Entropy: 1.91531
Value Function Loss: 0.08808

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.14715
Policy Update Magnitude: 0.49905
Value Function Update Magnitude: 0.72576

Collected Steps per Second: 21,817.77567
Overall Steps per Second: 10,419.60598

Timestep Collection Time: 2.29382
Timestep Consumption Time: 2.50924
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.80306

Cumulative Model Updates: 91,850
Cumulative Timesteps: 766,130,124

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,408.20061
Policy Entropy: 1.90508
Value Function Loss: 0.09011

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.14283
Policy Update Magnitude: 0.49199
Value Function Update Magnitude: 0.82783

Collected Steps per Second: 22,535.40456
Overall Steps per Second: 10,730.50122

Timestep Collection Time: 2.22095
Timestep Consumption Time: 2.44332
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.66427

Cumulative Model Updates: 91,856
Cumulative Timesteps: 766,180,174

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 766180174...
Checkpoint 766180174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,910.78763
Policy Entropy: 1.88952
Value Function Loss: 0.08837

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.75476

Collected Steps per Second: 21,966.47574
Overall Steps per Second: 10,586.46896

Timestep Collection Time: 2.27656
Timestep Consumption Time: 2.44721
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.72377

Cumulative Model Updates: 91,862
Cumulative Timesteps: 766,230,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,699.85474
Policy Entropy: 1.88447
Value Function Loss: 0.09089

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.58724
Value Function Update Magnitude: 0.74613

Collected Steps per Second: 22,518.37826
Overall Steps per Second: 10,651.20701

Timestep Collection Time: 2.22059
Timestep Consumption Time: 2.47409
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.69468

Cumulative Model Updates: 91,868
Cumulative Timesteps: 766,280,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 766280186...
Checkpoint 766280186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,362.77314
Policy Entropy: 1.88101
Value Function Loss: 0.08588

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.59099
Value Function Update Magnitude: 0.81279

Collected Steps per Second: 21,992.60725
Overall Steps per Second: 10,516.67005

Timestep Collection Time: 2.27431
Timestep Consumption Time: 2.48176
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.75607

Cumulative Model Updates: 91,874
Cumulative Timesteps: 766,330,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,906.77486
Policy Entropy: 1.89710
Value Function Loss: 0.09034

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.59050
Value Function Update Magnitude: 0.76640

Collected Steps per Second: 22,439.54112
Overall Steps per Second: 10,547.09474

Timestep Collection Time: 2.22866
Timestep Consumption Time: 2.51293
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.74159

Cumulative Model Updates: 91,880
Cumulative Timesteps: 766,380,214

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 766380214...
Checkpoint 766380214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,574.48303
Policy Entropy: 1.90330
Value Function Loss: 0.08710

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.59136
Value Function Update Magnitude: 0.72442

Collected Steps per Second: 22,305.05555
Overall Steps per Second: 10,505.79643

Timestep Collection Time: 2.24209
Timestep Consumption Time: 2.51814
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.76023

Cumulative Model Updates: 91,886
Cumulative Timesteps: 766,430,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,331.17704
Policy Entropy: 1.90820
Value Function Loss: 0.08483

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.58913
Value Function Update Magnitude: 0.80420

Collected Steps per Second: 22,473.64228
Overall Steps per Second: 10,527.83816

Timestep Collection Time: 2.22492
Timestep Consumption Time: 2.52459
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.74950

Cumulative Model Updates: 91,892
Cumulative Timesteps: 766,480,226

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 766480226...
Checkpoint 766480226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,637.05141
Policy Entropy: 1.89912
Value Function Loss: 0.08048

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.58634
Value Function Update Magnitude: 0.75866

Collected Steps per Second: 21,961.37514
Overall Steps per Second: 10,626.26561

Timestep Collection Time: 2.27691
Timestep Consumption Time: 2.42879
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.70570

Cumulative Model Updates: 91,898
Cumulative Timesteps: 766,530,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,915.23654
Policy Entropy: 1.89806
Value Function Loss: 0.08513

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13902
Policy Update Magnitude: 0.57118
Value Function Update Magnitude: 0.73933

Collected Steps per Second: 22,713.37040
Overall Steps per Second: 10,759.99847

Timestep Collection Time: 2.20205
Timestep Consumption Time: 2.44628
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.64833

Cumulative Model Updates: 91,904
Cumulative Timesteps: 766,580,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 766580246...
Checkpoint 766580246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,855.15703
Policy Entropy: 1.90626
Value Function Loss: 0.08335

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.16154
Policy Update Magnitude: 0.50991
Value Function Update Magnitude: 0.76324

Collected Steps per Second: 22,348.38175
Overall Steps per Second: 10,662.17059

Timestep Collection Time: 2.23792
Timestep Consumption Time: 2.45286
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.69079

Cumulative Model Updates: 91,910
Cumulative Timesteps: 766,630,260

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,563.13303
Policy Entropy: 1.92000
Value Function Loss: 0.08417

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.15102
Policy Update Magnitude: 0.47275
Value Function Update Magnitude: 0.73508

Collected Steps per Second: 22,449.92680
Overall Steps per Second: 10,534.80543

Timestep Collection Time: 2.22825
Timestep Consumption Time: 2.52020
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.74845

Cumulative Model Updates: 91,916
Cumulative Timesteps: 766,680,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 766680284...
Checkpoint 766680284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,035.85361
Policy Entropy: 1.91770
Value Function Loss: 0.08211

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.47416
Value Function Update Magnitude: 0.68447

Collected Steps per Second: 21,930.14083
Overall Steps per Second: 10,592.27497

Timestep Collection Time: 2.28124
Timestep Consumption Time: 2.44182
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.72306

Cumulative Model Updates: 91,922
Cumulative Timesteps: 766,730,312

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,088.13682
Policy Entropy: 1.90463
Value Function Loss: 0.08817

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.52824
Value Function Update Magnitude: 0.70384

Collected Steps per Second: 22,472.36356
Overall Steps per Second: 10,606.19481

Timestep Collection Time: 2.22513
Timestep Consumption Time: 2.48947
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.71460

Cumulative Model Updates: 91,928
Cumulative Timesteps: 766,780,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 766780316...
Checkpoint 766780316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,424.95742
Policy Entropy: 1.88345
Value Function Loss: 0.09064

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.15317
Policy Update Magnitude: 0.56411
Value Function Update Magnitude: 0.70389

Collected Steps per Second: 22,111.17131
Overall Steps per Second: 10,517.80554

Timestep Collection Time: 2.26239
Timestep Consumption Time: 2.49374
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.75613

Cumulative Model Updates: 91,934
Cumulative Timesteps: 766,830,340

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,780.05195
Policy Entropy: 1.88238
Value Function Loss: 0.09304

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.16645
Policy Update Magnitude: 0.52153
Value Function Update Magnitude: 0.63374

Collected Steps per Second: 22,374.08447
Overall Steps per Second: 10,483.26660

Timestep Collection Time: 2.23482
Timestep Consumption Time: 2.53488
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.76970

Cumulative Model Updates: 91,940
Cumulative Timesteps: 766,880,342

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 766880342...
Checkpoint 766880342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,883.32664
Policy Entropy: 1.86603
Value Function Loss: 0.08976

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.14840
Policy Update Magnitude: 0.53722
Value Function Update Magnitude: 0.70584

Collected Steps per Second: 21,679.26456
Overall Steps per Second: 10,543.79474

Timestep Collection Time: 2.30635
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.74213

Cumulative Model Updates: 91,946
Cumulative Timesteps: 766,930,342

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,456.04327
Policy Entropy: 1.88281
Value Function Loss: 0.08697

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.58350
Value Function Update Magnitude: 0.73315

Collected Steps per Second: 22,437.03724
Overall Steps per Second: 10,522.89179

Timestep Collection Time: 2.22935
Timestep Consumption Time: 2.52410
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.75345

Cumulative Model Updates: 91,952
Cumulative Timesteps: 766,980,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 766980362...
Checkpoint 766980362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,938.75614
Policy Entropy: 1.86827
Value Function Loss: 0.09027

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.59498
Value Function Update Magnitude: 0.71773

Collected Steps per Second: 22,096.39699
Overall Steps per Second: 10,642.51979

Timestep Collection Time: 2.26390
Timestep Consumption Time: 2.43649
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.70039

Cumulative Model Updates: 91,958
Cumulative Timesteps: 767,030,386

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,224.23117
Policy Entropy: 1.90132
Value Function Loss: 0.08844

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13912
Policy Update Magnitude: 0.59620
Value Function Update Magnitude: 0.70762

Collected Steps per Second: 22,309.88668
Overall Steps per Second: 10,483.41981

Timestep Collection Time: 2.24241
Timestep Consumption Time: 2.52969
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.77211

Cumulative Model Updates: 91,964
Cumulative Timesteps: 767,080,414

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 767080414...
Checkpoint 767080414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,388.12160
Policy Entropy: 1.89313
Value Function Loss: 0.08911

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.14350
Policy Update Magnitude: 0.59592
Value Function Update Magnitude: 0.74592

Collected Steps per Second: 21,922.97953
Overall Steps per Second: 10,584.32084

Timestep Collection Time: 2.28108
Timestep Consumption Time: 2.44365
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.72472

Cumulative Model Updates: 91,970
Cumulative Timesteps: 767,130,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,779.85214
Policy Entropy: 1.88373
Value Function Loss: 0.08764

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.60409
Value Function Update Magnitude: 0.74161

Collected Steps per Second: 20,884.90060
Overall Steps per Second: 10,173.52957

Timestep Collection Time: 2.39541
Timestep Consumption Time: 2.52205
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.91747

Cumulative Model Updates: 91,976
Cumulative Timesteps: 767,180,450

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 767180450...
Checkpoint 767180450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,191.62279
Policy Entropy: 1.86368
Value Function Loss: 0.08768

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.60474
Value Function Update Magnitude: 0.72270

Collected Steps per Second: 22,365.58425
Overall Steps per Second: 10,598.63748

Timestep Collection Time: 2.23737
Timestep Consumption Time: 2.48400
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.72136

Cumulative Model Updates: 91,982
Cumulative Timesteps: 767,230,490

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,144.30570
Policy Entropy: 1.84686
Value Function Loss: 0.08592

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.60463
Value Function Update Magnitude: 0.75774

Collected Steps per Second: 22,225.27919
Overall Steps per Second: 10,503.19447

Timestep Collection Time: 2.24987
Timestep Consumption Time: 2.51097
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.76084

Cumulative Model Updates: 91,988
Cumulative Timesteps: 767,280,494

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 767280494...
Checkpoint 767280494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,597.16875
Policy Entropy: 1.85916
Value Function Loss: 0.08739

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.61074
Value Function Update Magnitude: 0.77262

Collected Steps per Second: 21,963.82423
Overall Steps per Second: 10,551.56723

Timestep Collection Time: 2.27756
Timestep Consumption Time: 2.46334
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.74091

Cumulative Model Updates: 91,994
Cumulative Timesteps: 767,330,518

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,643.88171
Policy Entropy: 1.85556
Value Function Loss: 0.08489

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13402
Policy Update Magnitude: 0.60415
Value Function Update Magnitude: 0.73752

Collected Steps per Second: 22,391.87773
Overall Steps per Second: 10,508.72655

Timestep Collection Time: 2.23429
Timestep Consumption Time: 2.52651
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.76081

Cumulative Model Updates: 92,000
Cumulative Timesteps: 767,380,548

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 767380548...
Checkpoint 767380548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,793.11827
Policy Entropy: 1.86589
Value Function Loss: 0.08123

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.59268
Value Function Update Magnitude: 0.66009

Collected Steps per Second: 21,809.66008
Overall Steps per Second: 10,541.00878

Timestep Collection Time: 2.29275
Timestep Consumption Time: 2.45101
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.74376

Cumulative Model Updates: 92,006
Cumulative Timesteps: 767,430,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,112.29341
Policy Entropy: 1.85167
Value Function Loss: 0.08076

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.57160
Value Function Update Magnitude: 0.62859

Collected Steps per Second: 22,529.14210
Overall Steps per Second: 10,567.11329

Timestep Collection Time: 2.22041
Timestep Consumption Time: 2.51352
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.73393

Cumulative Model Updates: 92,012
Cumulative Timesteps: 767,480,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 767480576...
Checkpoint 767480576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,038.22306
Policy Entropy: 1.86927
Value Function Loss: 0.08218

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.56801
Value Function Update Magnitude: 0.67795

Collected Steps per Second: 22,085.02217
Overall Steps per Second: 10,537.41357

Timestep Collection Time: 2.26443
Timestep Consumption Time: 2.48152
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.74595

Cumulative Model Updates: 92,018
Cumulative Timesteps: 767,530,586

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,559.57238
Policy Entropy: 1.85345
Value Function Loss: 0.08279

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.57371
Value Function Update Magnitude: 0.69407

Collected Steps per Second: 22,188.05998
Overall Steps per Second: 10,446.80486

Timestep Collection Time: 2.25428
Timestep Consumption Time: 2.53360
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.78788

Cumulative Model Updates: 92,024
Cumulative Timesteps: 767,580,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 767580604...
Checkpoint 767580604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,673.35209
Policy Entropy: 1.87716
Value Function Loss: 0.08342

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.57889
Value Function Update Magnitude: 0.71456

Collected Steps per Second: 21,819.35042
Overall Steps per Second: 10,555.60735

Timestep Collection Time: 2.29209
Timestep Consumption Time: 2.44586
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.73796

Cumulative Model Updates: 92,030
Cumulative Timesteps: 767,630,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,422.75426
Policy Entropy: 1.86332
Value Function Loss: 0.08451

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.59592
Value Function Update Magnitude: 0.70848

Collected Steps per Second: 22,407.57681
Overall Steps per Second: 10,562.62028

Timestep Collection Time: 2.23157
Timestep Consumption Time: 2.50249
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.73405

Cumulative Model Updates: 92,036
Cumulative Timesteps: 767,680,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 767680620...
Checkpoint 767680620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,883.99062
Policy Entropy: 1.86196
Value Function Loss: 0.08173

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13473
Policy Update Magnitude: 0.58510
Value Function Update Magnitude: 0.65008

Collected Steps per Second: 21,870.49871
Overall Steps per Second: 10,585.38876

Timestep Collection Time: 2.28692
Timestep Consumption Time: 2.43809
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.72500

Cumulative Model Updates: 92,042
Cumulative Timesteps: 767,730,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,308.93646
Policy Entropy: 1.84453
Value Function Loss: 0.08735

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.57991
Value Function Update Magnitude: 0.48190

Collected Steps per Second: 22,554.68856
Overall Steps per Second: 10,560.81126

Timestep Collection Time: 2.21710
Timestep Consumption Time: 2.51795
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.73505

Cumulative Model Updates: 92,048
Cumulative Timesteps: 767,780,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 767780642...
Checkpoint 767780642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,677.21855
Policy Entropy: 1.84469
Value Function Loss: 0.08837

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.58166
Value Function Update Magnitude: 0.40026

Collected Steps per Second: 22,265.34588
Overall Steps per Second: 10,573.62753

Timestep Collection Time: 2.24744
Timestep Consumption Time: 2.48509
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.73253

Cumulative Model Updates: 92,054
Cumulative Timesteps: 767,830,682

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,148.08454
Policy Entropy: 1.85643
Value Function Loss: 0.08589

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.55782
Value Function Update Magnitude: 0.41411

Collected Steps per Second: 22,314.57285
Overall Steps per Second: 10,512.03102

Timestep Collection Time: 2.24167
Timestep Consumption Time: 2.51687
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.75855

Cumulative Model Updates: 92,060
Cumulative Timesteps: 767,880,704

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 767880704...
Checkpoint 767880704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,203.08750
Policy Entropy: 1.85038
Value Function Loss: 0.07947

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.56244
Value Function Update Magnitude: 0.52350

Collected Steps per Second: 21,979.50241
Overall Steps per Second: 10,588.57709

Timestep Collection Time: 2.27585
Timestep Consumption Time: 2.44830
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.72415

Cumulative Model Updates: 92,066
Cumulative Timesteps: 767,930,726

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,254.16803
Policy Entropy: 1.84464
Value Function Loss: 0.07794

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.55400
Value Function Update Magnitude: 0.55693

Collected Steps per Second: 22,169.76700
Overall Steps per Second: 10,812.34724

Timestep Collection Time: 2.25632
Timestep Consumption Time: 2.37006
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.62638

Cumulative Model Updates: 92,072
Cumulative Timesteps: 767,980,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 767980748...
Checkpoint 767980748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,498.78399
Policy Entropy: 1.87023
Value Function Loss: 0.08134

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.15001
Policy Update Magnitude: 0.51124
Value Function Update Magnitude: 0.58009

Collected Steps per Second: 21,435.57663
Overall Steps per Second: 10,623.58335

Timestep Collection Time: 2.33276
Timestep Consumption Time: 2.37413
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.70689

Cumulative Model Updates: 92,078
Cumulative Timesteps: 768,030,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,360.90406
Policy Entropy: 1.87437
Value Function Loss: 0.08503

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.46684
Value Function Update Magnitude: 0.57605

Collected Steps per Second: 22,027.08569
Overall Steps per Second: 10,608.23789

Timestep Collection Time: 2.27011
Timestep Consumption Time: 2.44358
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.71370

Cumulative Model Updates: 92,084
Cumulative Timesteps: 768,080,756

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 768080756...
Checkpoint 768080756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,723.88687
Policy Entropy: 1.88975
Value Function Loss: 0.08468

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.47989
Value Function Update Magnitude: 0.53885

Collected Steps per Second: 21,266.49261
Overall Steps per Second: 10,589.98710

Timestep Collection Time: 2.35149
Timestep Consumption Time: 2.37070
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.72220

Cumulative Model Updates: 92,090
Cumulative Timesteps: 768,130,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,749.51113
Policy Entropy: 1.89516
Value Function Loss: 0.09497

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.14552
Policy Update Magnitude: 0.50490
Value Function Update Magnitude: 0.51790

Collected Steps per Second: 21,861.24149
Overall Steps per Second: 10,594.44561

Timestep Collection Time: 2.28724
Timestep Consumption Time: 2.43240
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.71964

Cumulative Model Updates: 92,096
Cumulative Timesteps: 768,180,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 768180766...
Checkpoint 768180766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,960.52594
Policy Entropy: 1.88145
Value Function Loss: 0.09630

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.55571
Value Function Update Magnitude: 0.43321

Collected Steps per Second: 21,924.29998
Overall Steps per Second: 10,609.37277

Timestep Collection Time: 2.28167
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.71508

Cumulative Model Updates: 92,102
Cumulative Timesteps: 768,230,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,154.54931
Policy Entropy: 1.91302
Value Function Loss: 0.10109

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.16636
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.42065

Collected Steps per Second: 21,889.20104
Overall Steps per Second: 10,777.57399

Timestep Collection Time: 2.28478
Timestep Consumption Time: 2.35560
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.64038

Cumulative Model Updates: 92,108
Cumulative Timesteps: 768,280,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 768280802...
Checkpoint 768280802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,276.39737
Policy Entropy: 1.89552
Value Function Loss: 0.08962

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.16195
Policy Update Magnitude: 0.52894
Value Function Update Magnitude: 0.59934

Collected Steps per Second: 19,811.42497
Overall Steps per Second: 10,132.16906

Timestep Collection Time: 2.52390
Timestep Consumption Time: 2.41108
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.93497

Cumulative Model Updates: 92,114
Cumulative Timesteps: 768,330,804

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,266.26726
Policy Entropy: 1.90238
Value Function Loss: 0.08879

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.15107
Policy Update Magnitude: 0.49171
Value Function Update Magnitude: 0.55771

Collected Steps per Second: 20,579.75965
Overall Steps per Second: 10,179.25763

Timestep Collection Time: 2.43025
Timestep Consumption Time: 2.48307
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.91332

Cumulative Model Updates: 92,120
Cumulative Timesteps: 768,380,818

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 768380818...
Checkpoint 768380818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,810.66263
Policy Entropy: 1.86959
Value Function Loss: 0.08849

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.14176
Policy Update Magnitude: 0.52551
Value Function Update Magnitude: 0.45682

Collected Steps per Second: 21,561.45093
Overall Steps per Second: 10,577.78620

Timestep Collection Time: 2.32007
Timestep Consumption Time: 2.40909
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.72916

Cumulative Model Updates: 92,126
Cumulative Timesteps: 768,430,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,864.72630
Policy Entropy: 1.84298
Value Function Loss: 0.08628

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.15608
Policy Update Magnitude: 0.53251
Value Function Update Magnitude: 0.42200

Collected Steps per Second: 21,791.30219
Overall Steps per Second: 10,457.92254

Timestep Collection Time: 2.29559
Timestep Consumption Time: 2.48776
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.78336

Cumulative Model Updates: 92,132
Cumulative Timesteps: 768,480,866

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 768480866...
Checkpoint 768480866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,532.46121
Policy Entropy: 1.84198
Value Function Loss: 0.08004

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.15811
Policy Update Magnitude: 0.52367
Value Function Update Magnitude: 0.40409

Collected Steps per Second: 21,884.29666
Overall Steps per Second: 10,619.86639

Timestep Collection Time: 2.28557
Timestep Consumption Time: 2.42429
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.70985

Cumulative Model Updates: 92,138
Cumulative Timesteps: 768,530,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,061.94094
Policy Entropy: 1.85805
Value Function Loss: 0.08086

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.53287
Value Function Update Magnitude: 0.43233

Collected Steps per Second: 22,541.52671
Overall Steps per Second: 10,641.47615

Timestep Collection Time: 2.21822
Timestep Consumption Time: 2.48057
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.69878

Cumulative Model Updates: 92,144
Cumulative Timesteps: 768,580,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 768580886...
Checkpoint 768580886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,031.06188
Policy Entropy: 1.87068
Value Function Loss: 0.08457

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.16507
Policy Update Magnitude: 0.50644
Value Function Update Magnitude: 0.59804

Collected Steps per Second: 22,158.77680
Overall Steps per Second: 10,501.47295

Timestep Collection Time: 2.25653
Timestep Consumption Time: 2.50489
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.76143

Cumulative Model Updates: 92,150
Cumulative Timesteps: 768,630,888

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,082.25655
Policy Entropy: 1.87859
Value Function Loss: 0.08723

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.15750
Policy Update Magnitude: 0.54155
Value Function Update Magnitude: 0.69515

Collected Steps per Second: 22,530.34224
Overall Steps per Second: 10,788.36625

Timestep Collection Time: 2.22065
Timestep Consumption Time: 2.41694
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.63759

Cumulative Model Updates: 92,156
Cumulative Timesteps: 768,680,920

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 768680920...
Checkpoint 768680920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,718.38983
Policy Entropy: 1.86610
Value Function Loss: 0.09117

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.16450
Policy Update Magnitude: 0.52898
Value Function Update Magnitude: 0.65661

Collected Steps per Second: 21,685.11497
Overall Steps per Second: 10,471.28445

Timestep Collection Time: 2.30582
Timestep Consumption Time: 2.46933
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.77515

Cumulative Model Updates: 92,162
Cumulative Timesteps: 768,730,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,730.23046
Policy Entropy: 1.86905
Value Function Loss: 0.08949

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.16276
Policy Update Magnitude: 0.51272
Value Function Update Magnitude: 0.69756

Collected Steps per Second: 22,846.86093
Overall Steps per Second: 10,686.62620

Timestep Collection Time: 2.19059
Timestep Consumption Time: 2.49265
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.68324

Cumulative Model Updates: 92,168
Cumulative Timesteps: 768,780,970

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 768780970...
Checkpoint 768780970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,663.22972
Policy Entropy: 1.86412
Value Function Loss: 0.09201

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.16251
Policy Update Magnitude: 0.52119
Value Function Update Magnitude: 0.72153

Collected Steps per Second: 22,261.92359
Overall Steps per Second: 10,628.42553

Timestep Collection Time: 2.24689
Timestep Consumption Time: 2.45936
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.70625

Cumulative Model Updates: 92,174
Cumulative Timesteps: 768,830,990

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,042.71254
Policy Entropy: 1.85488
Value Function Loss: 0.08914

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.16219
Policy Update Magnitude: 0.52889
Value Function Update Magnitude: 0.74704

Collected Steps per Second: 22,412.85040
Overall Steps per Second: 10,512.69581

Timestep Collection Time: 2.23149
Timestep Consumption Time: 2.52600
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.75749

Cumulative Model Updates: 92,180
Cumulative Timesteps: 768,881,004

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 768881004...
Checkpoint 768881004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,548.01869
Policy Entropy: 1.85702
Value Function Loss: 0.09694

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.15615
Policy Update Magnitude: 0.53712
Value Function Update Magnitude: 0.69001

Collected Steps per Second: 20,712.15826
Overall Steps per Second: 10,157.95758

Timestep Collection Time: 2.41539
Timestep Consumption Time: 2.50961
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.92501

Cumulative Model Updates: 92,186
Cumulative Timesteps: 768,931,032

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,168.49673
Policy Entropy: 1.86818
Value Function Loss: 0.09624

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.16103
Policy Update Magnitude: 0.54302
Value Function Update Magnitude: 0.67667

Collected Steps per Second: 22,320.57306
Overall Steps per Second: 10,488.03494

Timestep Collection Time: 2.24125
Timestep Consumption Time: 2.52857
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.76982

Cumulative Model Updates: 92,192
Cumulative Timesteps: 768,981,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 768981058...
Checkpoint 768981058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,463.11923
Policy Entropy: 1.88794
Value Function Loss: 0.09067

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.16740
Policy Update Magnitude: 0.53422
Value Function Update Magnitude: 0.57357

Collected Steps per Second: 22,010.41322
Overall Steps per Second: 10,607.10938

Timestep Collection Time: 2.27202
Timestep Consumption Time: 2.44256
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.71457

Cumulative Model Updates: 92,198
Cumulative Timesteps: 769,031,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,049.46565
Policy Entropy: 1.88994
Value Function Loss: 0.09224

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.16218
Policy Update Magnitude: 0.52109
Value Function Update Magnitude: 0.63322

Collected Steps per Second: 22,308.67981
Overall Steps per Second: 10,488.18398

Timestep Collection Time: 2.24164
Timestep Consumption Time: 2.52639
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.76803

Cumulative Model Updates: 92,204
Cumulative Timesteps: 769,081,074

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 769081074...
Checkpoint 769081074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,310.71557
Policy Entropy: 1.86246
Value Function Loss: 0.09282

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.15050
Policy Update Magnitude: 0.55646
Value Function Update Magnitude: 0.62891

Collected Steps per Second: 22,116.73091
Overall Steps per Second: 10,620.71883

Timestep Collection Time: 2.26091
Timestep Consumption Time: 2.44724
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.70816

Cumulative Model Updates: 92,210
Cumulative Timesteps: 769,131,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,973.17727
Policy Entropy: 1.87715
Value Function Loss: 0.10103

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.15191
Policy Update Magnitude: 0.56708
Value Function Update Magnitude: 0.45928

Collected Steps per Second: 22,461.05151
Overall Steps per Second: 10,513.19341

Timestep Collection Time: 2.22616
Timestep Consumption Time: 2.52995
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.75612

Cumulative Model Updates: 92,216
Cumulative Timesteps: 769,181,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 769181080...
Checkpoint 769181080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,907.18392
Policy Entropy: 1.85642
Value Function Loss: 0.09843

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.58770
Value Function Update Magnitude: 0.39657

Collected Steps per Second: 22,149.41754
Overall Steps per Second: 10,610.40018

Timestep Collection Time: 2.25749
Timestep Consumption Time: 2.45506
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.71255

Cumulative Model Updates: 92,222
Cumulative Timesteps: 769,231,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,762.17229
Policy Entropy: 1.86018
Value Function Loss: 0.10063

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.59427
Value Function Update Magnitude: 0.50112

Collected Steps per Second: 22,697.19001
Overall Steps per Second: 10,625.85423

Timestep Collection Time: 2.20362
Timestep Consumption Time: 2.50339
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.70701

Cumulative Model Updates: 92,228
Cumulative Timesteps: 769,281,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 769281098...
Checkpoint 769281098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,684.88362
Policy Entropy: 1.84678
Value Function Loss: 0.08969

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.59434
Value Function Update Magnitude: 0.73167

Collected Steps per Second: 22,331.89461
Overall Steps per Second: 10,630.94547

Timestep Collection Time: 2.24002
Timestep Consumption Time: 2.46548
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.70551

Cumulative Model Updates: 92,234
Cumulative Timesteps: 769,331,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,158.84473
Policy Entropy: 1.85334
Value Function Loss: 0.08568

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.59227
Value Function Update Magnitude: 0.72475

Collected Steps per Second: 22,574.49045
Overall Steps per Second: 10,695.84208

Timestep Collection Time: 2.21524
Timestep Consumption Time: 2.46022
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.67546

Cumulative Model Updates: 92,240
Cumulative Timesteps: 769,381,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 769381130...
Checkpoint 769381130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,032.98535
Policy Entropy: 1.85840
Value Function Loss: 0.07965

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.58879
Value Function Update Magnitude: 0.67702

Collected Steps per Second: 22,000.97452
Overall Steps per Second: 10,600.69713

Timestep Collection Time: 2.27435
Timestep Consumption Time: 2.44590
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.72026

Cumulative Model Updates: 92,246
Cumulative Timesteps: 769,431,168

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,659.91875
Policy Entropy: 1.83909
Value Function Loss: 0.08396

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.57748
Value Function Update Magnitude: 0.50569

Collected Steps per Second: 22,325.47161
Overall Steps per Second: 10,499.30208

Timestep Collection Time: 2.24040
Timestep Consumption Time: 2.52354
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.76394

Cumulative Model Updates: 92,252
Cumulative Timesteps: 769,481,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 769481186...
Checkpoint 769481186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,175.44446
Policy Entropy: 1.82460
Value Function Loss: 0.08667

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.58536
Value Function Update Magnitude: 0.47221

Collected Steps per Second: 22,321.97929
Overall Steps per Second: 10,696.77614

Timestep Collection Time: 2.24138
Timestep Consumption Time: 2.43592
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.67730

Cumulative Model Updates: 92,258
Cumulative Timesteps: 769,531,218

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,378.57045
Policy Entropy: 1.81273
Value Function Loss: 0.09159

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.59837
Value Function Update Magnitude: 0.50594

Collected Steps per Second: 22,550.98121
Overall Steps per Second: 10,578.08861

Timestep Collection Time: 2.21738
Timestep Consumption Time: 2.50975
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.72713

Cumulative Model Updates: 92,264
Cumulative Timesteps: 769,581,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 769581222...
Checkpoint 769581222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,007.99954
Policy Entropy: 1.82479
Value Function Loss: 0.09202

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.16444
Policy Update Magnitude: 0.56801
Value Function Update Magnitude: 0.64693

Collected Steps per Second: 22,460.96289
Overall Steps per Second: 10,531.58143

Timestep Collection Time: 2.22662
Timestep Consumption Time: 2.52215
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.74876

Cumulative Model Updates: 92,270
Cumulative Timesteps: 769,631,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,996.19949
Policy Entropy: 1.82579
Value Function Loss: 0.09415

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.14081
Policy Update Magnitude: 0.54679
Value Function Update Magnitude: 0.64082

Collected Steps per Second: 22,521.62933
Overall Steps per Second: 10,584.36116

Timestep Collection Time: 2.22151
Timestep Consumption Time: 2.50547
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.72697

Cumulative Model Updates: 92,276
Cumulative Timesteps: 769,681,266

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 769681266...
Checkpoint 769681266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,387.39469
Policy Entropy: 1.82404
Value Function Loss: 0.08855

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.58547
Value Function Update Magnitude: 0.65860

Collected Steps per Second: 22,048.62574
Overall Steps per Second: 10,499.21174

Timestep Collection Time: 2.26844
Timestep Consumption Time: 2.49535
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.76379

Cumulative Model Updates: 92,282
Cumulative Timesteps: 769,731,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,398.72909
Policy Entropy: 1.80741
Value Function Loss: 0.08744

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.14749
Policy Update Magnitude: 0.59116
Value Function Update Magnitude: 0.59384

Collected Steps per Second: 22,399.77618
Overall Steps per Second: 10,638.40398

Timestep Collection Time: 2.23324
Timestep Consumption Time: 2.46897
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.70221

Cumulative Model Updates: 92,288
Cumulative Timesteps: 769,781,306

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 769781306...
Checkpoint 769781306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,254.44492
Policy Entropy: 1.81387
Value Function Loss: 0.08823

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.59218
Value Function Update Magnitude: 0.46731

Collected Steps per Second: 22,378.10123
Overall Steps per Second: 10,759.72329

Timestep Collection Time: 2.23495
Timestep Consumption Time: 2.41331
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.64826

Cumulative Model Updates: 92,294
Cumulative Timesteps: 769,831,320

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,300.05881
Policy Entropy: 1.83203
Value Function Loss: 0.09340

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13654
Policy Update Magnitude: 0.59124
Value Function Update Magnitude: 0.48934

Collected Steps per Second: 21,904.68632
Overall Steps per Second: 10,526.93839

Timestep Collection Time: 2.28316
Timestep Consumption Time: 2.46769
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.75086

Cumulative Model Updates: 92,300
Cumulative Timesteps: 769,881,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 769881332...
Checkpoint 769881332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,186.69488
Policy Entropy: 1.84594
Value Function Loss: 0.09830

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.60498
Value Function Update Magnitude: 0.52776

Collected Steps per Second: 22,182.10270
Overall Steps per Second: 10,741.53978

Timestep Collection Time: 2.25443
Timestep Consumption Time: 2.40114
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.65557

Cumulative Model Updates: 92,306
Cumulative Timesteps: 769,931,340

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,944.78446
Policy Entropy: 1.83664
Value Function Loss: 0.09056

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.60090
Value Function Update Magnitude: 0.60411

Collected Steps per Second: 22,651.70065
Overall Steps per Second: 10,744.32189

Timestep Collection Time: 2.20849
Timestep Consumption Time: 2.44755
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.65604

Cumulative Model Updates: 92,312
Cumulative Timesteps: 769,981,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 769981366...
Checkpoint 769981366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,943.96418
Policy Entropy: 1.81617
Value Function Loss: 0.08572

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.58013
Value Function Update Magnitude: 0.71101

Collected Steps per Second: 21,973.87872
Overall Steps per Second: 10,458.98093

Timestep Collection Time: 2.27670
Timestep Consumption Time: 2.50655
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.78326

Cumulative Model Updates: 92,318
Cumulative Timesteps: 770,031,394

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,437.77761
Policy Entropy: 1.82448
Value Function Loss: 0.07898

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.57523
Value Function Update Magnitude: 0.73095

Collected Steps per Second: 22,397.82548
Overall Steps per Second: 10,677.22995

Timestep Collection Time: 2.23343
Timestep Consumption Time: 2.45168
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.68511

Cumulative Model Updates: 92,324
Cumulative Timesteps: 770,081,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 770081418...
Checkpoint 770081418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,263.30487
Policy Entropy: 1.81195
Value Function Loss: 0.08140

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.56323
Value Function Update Magnitude: 0.71152

Collected Steps per Second: 22,046.54038
Overall Steps per Second: 10,630.82695

Timestep Collection Time: 2.26829
Timestep Consumption Time: 2.43576
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.70406

Cumulative Model Updates: 92,330
Cumulative Timesteps: 770,131,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,548.19270
Policy Entropy: 1.80022
Value Function Loss: 0.08145

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.55849
Value Function Update Magnitude: 0.67192

Collected Steps per Second: 22,406.07652
Overall Steps per Second: 10,506.48918

Timestep Collection Time: 2.23270
Timestep Consumption Time: 2.52874
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.76144

Cumulative Model Updates: 92,336
Cumulative Timesteps: 770,181,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 770181452...
Checkpoint 770181452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,848.30130
Policy Entropy: 1.79133
Value Function Loss: 0.08563

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.57999
Value Function Update Magnitude: 0.65485

Collected Steps per Second: 21,762.08016
Overall Steps per Second: 10,562.79771

Timestep Collection Time: 2.29822
Timestep Consumption Time: 2.43670
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.73492

Cumulative Model Updates: 92,342
Cumulative Timesteps: 770,231,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,141.12414
Policy Entropy: 1.81184
Value Function Loss: 0.09249

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.16459
Policy Update Magnitude: 0.54135
Value Function Update Magnitude: 0.55828

Collected Steps per Second: 22,232.31628
Overall Steps per Second: 10,513.71666

Timestep Collection Time: 2.24907
Timestep Consumption Time: 2.50681
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.75588

Cumulative Model Updates: 92,348
Cumulative Timesteps: 770,281,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 770281468...
Checkpoint 770281468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,966.83746
Policy Entropy: 1.79592
Value Function Loss: 0.09746

Mean KL Divergence: 0.03062
SB3 Clip Fraction: 0.21295
Policy Update Magnitude: 0.46622
Value Function Update Magnitude: 0.69079

Collected Steps per Second: 22,073.90371
Overall Steps per Second: 10,611.41816

Timestep Collection Time: 2.26602
Timestep Consumption Time: 2.44777
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.71379

Cumulative Model Updates: 92,354
Cumulative Timesteps: 770,331,488

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,094.74617
Policy Entropy: 1.79354
Value Function Loss: 0.09695

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.17592
Policy Update Magnitude: 0.46274
Value Function Update Magnitude: 0.76656

Collected Steps per Second: 22,551.31194
Overall Steps per Second: 10,553.74965

Timestep Collection Time: 2.21788
Timestep Consumption Time: 2.52129
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.73917

Cumulative Model Updates: 92,360
Cumulative Timesteps: 770,381,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 770381504...
Checkpoint 770381504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,215.92287
Policy Entropy: 1.79619
Value Function Loss: 0.09512

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.53650
Value Function Update Magnitude: 0.70694

Collected Steps per Second: 21,875.44228
Overall Steps per Second: 10,634.85435

Timestep Collection Time: 2.28576
Timestep Consumption Time: 2.41595
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.70171

Cumulative Model Updates: 92,366
Cumulative Timesteps: 770,431,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,050.78008
Policy Entropy: 1.82607
Value Function Loss: 0.09372

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.15579
Policy Update Magnitude: 0.57880
Value Function Update Magnitude: 0.61489

Collected Steps per Second: 22,133.46494
Overall Steps per Second: 10,474.49399

Timestep Collection Time: 2.25975
Timestep Consumption Time: 2.51528
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.77503

Cumulative Model Updates: 92,372
Cumulative Timesteps: 770,481,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 770481522...
Checkpoint 770481522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,614.84899
Policy Entropy: 1.81943
Value Function Loss: 0.09501

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14704
Policy Update Magnitude: 0.56887
Value Function Update Magnitude: 0.50514

Collected Steps per Second: 22,321.98441
Overall Steps per Second: 10,587.52801

Timestep Collection Time: 2.24084
Timestep Consumption Time: 2.48359
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.72443

Cumulative Model Updates: 92,378
Cumulative Timesteps: 770,531,542

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,389.99729
Policy Entropy: 1.80806
Value Function Loss: 0.09528

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.56887
Value Function Update Magnitude: 0.38868

Collected Steps per Second: 22,320.93267
Overall Steps per Second: 10,441.38354

Timestep Collection Time: 2.24157
Timestep Consumption Time: 2.55032
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.79189

Cumulative Model Updates: 92,384
Cumulative Timesteps: 770,581,576

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 770581576...
Checkpoint 770581576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,484.35781
Policy Entropy: 1.80202
Value Function Loss: 0.10067

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13801
Policy Update Magnitude: 0.57676
Value Function Update Magnitude: 0.35133

Collected Steps per Second: 21,957.33575
Overall Steps per Second: 10,558.16499

Timestep Collection Time: 2.27714
Timestep Consumption Time: 2.45853
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.73567

Cumulative Model Updates: 92,390
Cumulative Timesteps: 770,631,576

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,783.60800
Policy Entropy: 1.78966
Value Function Loss: 0.10215

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.15465
Policy Update Magnitude: 0.54375
Value Function Update Magnitude: 0.37508

Collected Steps per Second: 22,380.75293
Overall Steps per Second: 10,568.45441

Timestep Collection Time: 2.23540
Timestep Consumption Time: 2.49850
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.73390

Cumulative Model Updates: 92,396
Cumulative Timesteps: 770,681,606

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 770681606...
Checkpoint 770681606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,827.92371
Policy Entropy: 1.78282
Value Function Loss: 0.10256

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.52343
Value Function Update Magnitude: 0.41720

Collected Steps per Second: 22,013.02628
Overall Steps per Second: 10,587.31863

Timestep Collection Time: 2.27175
Timestep Consumption Time: 2.45164
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.72339

Cumulative Model Updates: 92,402
Cumulative Timesteps: 770,731,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,764.93535
Policy Entropy: 1.77410
Value Function Loss: 0.09535

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.58060
Value Function Update Magnitude: 0.35332

Collected Steps per Second: 22,460.47384
Overall Steps per Second: 10,519.24942

Timestep Collection Time: 2.22729
Timestep Consumption Time: 2.52837
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.75566

Cumulative Model Updates: 92,408
Cumulative Timesteps: 770,781,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 770781640...
Checkpoint 770781640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,453.93255
Policy Entropy: 1.77601
Value Function Loss: 0.09366

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.57262
Value Function Update Magnitude: 0.33013

Collected Steps per Second: 21,945.47375
Overall Steps per Second: 10,571.52729

Timestep Collection Time: 2.27956
Timestep Consumption Time: 2.45259
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.73214

Cumulative Model Updates: 92,414
Cumulative Timesteps: 770,831,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,997.29523
Policy Entropy: 1.78307
Value Function Loss: 0.09224

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.17642
Policy Update Magnitude: 0.49223
Value Function Update Magnitude: 0.38319

Collected Steps per Second: 22,379.90001
Overall Steps per Second: 10,490.09061

Timestep Collection Time: 2.23468
Timestep Consumption Time: 2.53286
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.76755

Cumulative Model Updates: 92,420
Cumulative Timesteps: 770,881,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 770881678...
Checkpoint 770881678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,575.68389
Policy Entropy: 1.78745
Value Function Loss: 0.09268

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.15128
Policy Update Magnitude: 0.51971
Value Function Update Magnitude: 0.44682

Collected Steps per Second: 22,146.03907
Overall Steps per Second: 10,640.70815

Timestep Collection Time: 2.25982
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.70326

Cumulative Model Updates: 92,426
Cumulative Timesteps: 770,931,724

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,061.88100
Policy Entropy: 1.78850
Value Function Loss: 0.09374

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.16119
Policy Update Magnitude: 0.51049
Value Function Update Magnitude: 0.38857

Collected Steps per Second: 22,543.55697
Overall Steps per Second: 10,545.21204

Timestep Collection Time: 2.21890
Timestep Consumption Time: 2.52467
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.74357

Cumulative Model Updates: 92,432
Cumulative Timesteps: 770,981,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 770981746...
Checkpoint 770981746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,366.72080
Policy Entropy: 1.79448
Value Function Loss: 0.09227

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.49605
Value Function Update Magnitude: 0.34321

Collected Steps per Second: 21,894.55219
Overall Steps per Second: 10,601.68664

Timestep Collection Time: 2.28386
Timestep Consumption Time: 2.43275
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.71661

Cumulative Model Updates: 92,438
Cumulative Timesteps: 771,031,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,597.09691
Policy Entropy: 1.78500
Value Function Loss: 0.09534

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.55382
Value Function Update Magnitude: 0.35385

Collected Steps per Second: 22,283.44093
Overall Steps per Second: 10,514.48143

Timestep Collection Time: 2.24597
Timestep Consumption Time: 2.51394
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.75991

Cumulative Model Updates: 92,444
Cumulative Timesteps: 771,081,798

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 771081798...
Checkpoint 771081798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,829.52984
Policy Entropy: 1.78249
Value Function Loss: 0.09773

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.58388
Value Function Update Magnitude: 0.30965

Collected Steps per Second: 22,227.84443
Overall Steps per Second: 10,567.36412

Timestep Collection Time: 2.25060
Timestep Consumption Time: 2.48341
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.73401

Cumulative Model Updates: 92,450
Cumulative Timesteps: 771,131,824

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,481.35470
Policy Entropy: 1.78323
Value Function Loss: 0.10096

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.15869
Policy Update Magnitude: 0.57162
Value Function Update Magnitude: 0.25295

Collected Steps per Second: 22,553.41969
Overall Steps per Second: 10,625.53683

Timestep Collection Time: 2.21696
Timestep Consumption Time: 2.48869
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.70564

Cumulative Model Updates: 92,456
Cumulative Timesteps: 771,181,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 771181824...
Checkpoint 771181824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,361.02503
Policy Entropy: 1.78320
Value Function Loss: 0.09930

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.15705
Policy Update Magnitude: 0.50495
Value Function Update Magnitude: 0.23116

Collected Steps per Second: 22,369.83509
Overall Steps per Second: 10,582.47843

Timestep Collection Time: 2.23632
Timestep Consumption Time: 2.49093
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.72725

Cumulative Model Updates: 92,462
Cumulative Timesteps: 771,231,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,089.74813
Policy Entropy: 1.80150
Value Function Loss: 0.09997

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.16279
Policy Update Magnitude: 0.52551
Value Function Update Magnitude: 0.26512

Collected Steps per Second: 22,457.05599
Overall Steps per Second: 10,748.83708

Timestep Collection Time: 2.22781
Timestep Consumption Time: 2.42665
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.65446

Cumulative Model Updates: 92,468
Cumulative Timesteps: 771,281,880

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 771281880...
Checkpoint 771281880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,273.06607
Policy Entropy: 1.80788
Value Function Loss: 0.10328

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.16086
Policy Update Magnitude: 0.57258
Value Function Update Magnitude: 0.30537

Collected Steps per Second: 22,056.53238
Overall Steps per Second: 10,616.75626

Timestep Collection Time: 2.26736
Timestep Consumption Time: 2.44312
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.71048

Cumulative Model Updates: 92,474
Cumulative Timesteps: 771,331,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,111.96618
Policy Entropy: 1.81364
Value Function Loss: 0.10091

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.16709
Policy Update Magnitude: 0.56525
Value Function Update Magnitude: 0.26834

Collected Steps per Second: 22,351.72000
Overall Steps per Second: 10,513.48318

Timestep Collection Time: 2.23786
Timestep Consumption Time: 2.51984
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.75770

Cumulative Model Updates: 92,480
Cumulative Timesteps: 771,381,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 771381910...
Checkpoint 771381910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,196.07832
Policy Entropy: 1.80048
Value Function Loss: 0.10471

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.15599
Policy Update Magnitude: 0.55778
Value Function Update Magnitude: 0.24495

Collected Steps per Second: 22,128.59350
Overall Steps per Second: 10,657.92627

Timestep Collection Time: 2.25961
Timestep Consumption Time: 2.43192
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.69153

Cumulative Model Updates: 92,486
Cumulative Timesteps: 771,431,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,379.46327
Policy Entropy: 1.79546
Value Function Loss: 0.10508

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14717
Policy Update Magnitude: 0.57833
Value Function Update Magnitude: 0.23594

Collected Steps per Second: 22,503.59106
Overall Steps per Second: 10,531.53947

Timestep Collection Time: 2.22365
Timestep Consumption Time: 2.52780
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.75144

Cumulative Model Updates: 92,492
Cumulative Timesteps: 771,481,952

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 771481952...
Checkpoint 771481952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,769.13914
Policy Entropy: 1.79866
Value Function Loss: 0.09524

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.57723
Value Function Update Magnitude: 0.28037

Collected Steps per Second: 21,990.59390
Overall Steps per Second: 10,611.87167

Timestep Collection Time: 2.27561
Timestep Consumption Time: 2.44005
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.71566

Cumulative Model Updates: 92,498
Cumulative Timesteps: 771,531,994

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,500.20251
Policy Entropy: 1.80560
Value Function Loss: 0.08894

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.56474
Value Function Update Magnitude: 0.28102

Collected Steps per Second: 22,421.20896
Overall Steps per Second: 10,569.71035

Timestep Collection Time: 2.23003
Timestep Consumption Time: 2.50047
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.73050

Cumulative Model Updates: 92,504
Cumulative Timesteps: 771,581,994

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 771581994...
Checkpoint 771581994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,874.75565
Policy Entropy: 1.82127
Value Function Loss: 0.08138

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.55960
Value Function Update Magnitude: 0.32927

Collected Steps per Second: 22,263.31280
Overall Steps per Second: 10,549.15308

Timestep Collection Time: 2.24728
Timestep Consumption Time: 2.49547
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.74275

Cumulative Model Updates: 92,510
Cumulative Timesteps: 771,632,026

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,215.62026
Policy Entropy: 1.82601
Value Function Loss: 0.08677

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.56745
Value Function Update Magnitude: 0.47658

Collected Steps per Second: 22,182.16936
Overall Steps per Second: 10,575.29262

Timestep Collection Time: 2.25424
Timestep Consumption Time: 2.47414
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.72838

Cumulative Model Updates: 92,516
Cumulative Timesteps: 771,682,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 771682030...
Checkpoint 771682030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,920.12893
Policy Entropy: 1.82376
Value Function Loss: 0.08877

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.57626
Value Function Update Magnitude: 0.55594

Collected Steps per Second: 22,039.09472
Overall Steps per Second: 10,474.67836

Timestep Collection Time: 2.26978
Timestep Consumption Time: 2.50592
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.77571

Cumulative Model Updates: 92,522
Cumulative Timesteps: 771,732,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,244.90158
Policy Entropy: 1.82288
Value Function Loss: 0.09267

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.58911
Value Function Update Magnitude: 0.52547

Collected Steps per Second: 21,372.59873
Overall Steps per Second: 10,461.53729

Timestep Collection Time: 2.33944
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.77941

Cumulative Model Updates: 92,528
Cumulative Timesteps: 771,782,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 771782054...
Checkpoint 771782054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,370.93225
Policy Entropy: 1.80991
Value Function Loss: 0.09463

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.58550
Value Function Update Magnitude: 0.51327

Collected Steps per Second: 21,678.34659
Overall Steps per Second: 10,587.61115

Timestep Collection Time: 2.30746
Timestep Consumption Time: 2.41711
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.72458

Cumulative Model Updates: 92,534
Cumulative Timesteps: 771,832,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,635.89835
Policy Entropy: 1.80370
Value Function Loss: 0.09484

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.17363
Policy Update Magnitude: 0.53894
Value Function Update Magnitude: 0.66151

Collected Steps per Second: 21,798.33995
Overall Steps per Second: 10,577.87484

Timestep Collection Time: 2.29439
Timestep Consumption Time: 2.43378
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.72817

Cumulative Model Updates: 92,540
Cumulative Timesteps: 771,882,090

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 771882090...
Checkpoint 771882090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,309.93438
Policy Entropy: 1.81002
Value Function Loss: 0.09517

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.14971
Policy Update Magnitude: 0.53351
Value Function Update Magnitude: 0.64941

Collected Steps per Second: 21,470.44066
Overall Steps per Second: 10,540.91985

Timestep Collection Time: 2.33018
Timestep Consumption Time: 2.41608
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.74627

Cumulative Model Updates: 92,546
Cumulative Timesteps: 771,932,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,693.37465
Policy Entropy: 1.81026
Value Function Loss: 0.09050

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.15486
Policy Update Magnitude: 0.54179
Value Function Update Magnitude: 0.71859

Collected Steps per Second: 21,488.02789
Overall Steps per Second: 10,494.44255

Timestep Collection Time: 2.32762
Timestep Consumption Time: 2.43833
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.76595

Cumulative Model Updates: 92,552
Cumulative Timesteps: 771,982,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 771982136...
Checkpoint 771982136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,748.89309
Policy Entropy: 1.81680
Value Function Loss: 0.08762

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.15752
Policy Update Magnitude: 0.51599
Value Function Update Magnitude: 0.78443

Collected Steps per Second: 21,675.78408
Overall Steps per Second: 10,569.90120

Timestep Collection Time: 2.30681
Timestep Consumption Time: 2.42379
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.73060

Cumulative Model Updates: 92,558
Cumulative Timesteps: 772,032,138

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,884.59504
Policy Entropy: 1.80430
Value Function Loss: 0.08134

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.18122
Policy Update Magnitude: 0.51966
Value Function Update Magnitude: 0.76128

Collected Steps per Second: 21,762.66253
Overall Steps per Second: 10,488.60539

Timestep Collection Time: 2.29806
Timestep Consumption Time: 2.47016
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.76822

Cumulative Model Updates: 92,564
Cumulative Timesteps: 772,082,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 772082150...
Checkpoint 772082150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,882.58907
Policy Entropy: 1.79962
Value Function Loss: 0.07586

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.17818
Policy Update Magnitude: 0.49221
Value Function Update Magnitude: 0.71910

Collected Steps per Second: 22,150.18292
Overall Steps per Second: 10,620.14646

Timestep Collection Time: 2.25858
Timestep Consumption Time: 2.45209
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.71067

Cumulative Model Updates: 92,570
Cumulative Timesteps: 772,132,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,855.85300
Policy Entropy: 1.79239
Value Function Loss: 0.07512

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.14644
Policy Update Magnitude: 0.49433
Value Function Update Magnitude: 0.67785

Collected Steps per Second: 22,539.62317
Overall Steps per Second: 10,828.46905

Timestep Collection Time: 2.21858
Timestep Consumption Time: 2.39943
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.61801

Cumulative Model Updates: 92,576
Cumulative Timesteps: 772,182,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 772182184...
Checkpoint 772182184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,053.01412
Policy Entropy: 1.80305
Value Function Loss: 0.07411

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.16091
Policy Update Magnitude: 0.51021
Value Function Update Magnitude: 0.60401

Collected Steps per Second: 22,142.99686
Overall Steps per Second: 10,689.18848

Timestep Collection Time: 2.25859
Timestep Consumption Time: 2.42015
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.67875

Cumulative Model Updates: 92,582
Cumulative Timesteps: 772,232,196

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,878.63526
Policy Entropy: 1.80378
Value Function Loss: 0.08263

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.15701
Policy Update Magnitude: 0.53904
Value Function Update Magnitude: 0.46058

Collected Steps per Second: 22,304.66630
Overall Steps per Second: 10,592.99086

Timestep Collection Time: 2.24276
Timestep Consumption Time: 2.47961
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.72237

Cumulative Model Updates: 92,588
Cumulative Timesteps: 772,282,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 772282220...
Checkpoint 772282220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,332.03651
Policy Entropy: 1.81151
Value Function Loss: 0.08234

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14722
Policy Update Magnitude: 0.54890
Value Function Update Magnitude: 0.42120

Collected Steps per Second: 21,931.48441
Overall Steps per Second: 10,545.21160

Timestep Collection Time: 2.28037
Timestep Consumption Time: 2.46225
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.74263

Cumulative Model Updates: 92,594
Cumulative Timesteps: 772,332,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,447.83430
Policy Entropy: 1.80667
Value Function Loss: 0.08734

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.55985
Value Function Update Magnitude: 0.38756

Collected Steps per Second: 22,613.19291
Overall Steps per Second: 10,603.18449

Timestep Collection Time: 2.21163
Timestep Consumption Time: 2.50507
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.71670

Cumulative Model Updates: 92,600
Cumulative Timesteps: 772,382,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 772382244...
Checkpoint 772382244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,120.46086
Policy Entropy: 1.80064
Value Function Loss: 0.08279

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.55349
Value Function Update Magnitude: 0.42699

Collected Steps per Second: 22,199.56496
Overall Steps per Second: 10,456.90128

Timestep Collection Time: 2.25329
Timestep Consumption Time: 2.53035
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.78364

Cumulative Model Updates: 92,606
Cumulative Timesteps: 772,432,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,924.13032
Policy Entropy: 1.81264
Value Function Loss: 0.08547

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.15917
Policy Update Magnitude: 0.52639
Value Function Update Magnitude: 0.54801

Collected Steps per Second: 22,519.24738
Overall Steps per Second: 10,540.68332

Timestep Collection Time: 2.22121
Timestep Consumption Time: 2.52421
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.74542

Cumulative Model Updates: 92,612
Cumulative Timesteps: 772,482,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 772482286...
Checkpoint 772482286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,552.67472
Policy Entropy: 1.82347
Value Function Loss: 0.08274

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.15201
Policy Update Magnitude: 0.49117
Value Function Update Magnitude: 0.63530

Collected Steps per Second: 22,075.03960
Overall Steps per Second: 10,561.80791

Timestep Collection Time: 2.26618
Timestep Consumption Time: 2.47032
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.73650

Cumulative Model Updates: 92,618
Cumulative Timesteps: 772,532,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,016.22116
Policy Entropy: 1.82911
Value Function Loss: 0.08568

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14656
Policy Update Magnitude: 0.51883
Value Function Update Magnitude: 0.66387

Collected Steps per Second: 22,661.51836
Overall Steps per Second: 10,600.51127

Timestep Collection Time: 2.20735
Timestep Consumption Time: 2.51147
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.71883

Cumulative Model Updates: 92,624
Cumulative Timesteps: 772,582,334

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 772582334...
Checkpoint 772582334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,473.66704
Policy Entropy: 1.82643
Value Function Loss: 0.08380

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.15703
Policy Update Magnitude: 0.51782
Value Function Update Magnitude: 0.71356

Collected Steps per Second: 22,287.64077
Overall Steps per Second: 10,552.95559

Timestep Collection Time: 2.24411
Timestep Consumption Time: 2.49541
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.73953

Cumulative Model Updates: 92,630
Cumulative Timesteps: 772,632,350

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,616.77558
Policy Entropy: 1.80344
Value Function Loss: 0.08033

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.15306
Policy Update Magnitude: 0.52522
Value Function Update Magnitude: 0.71258

Collected Steps per Second: 22,629.41110
Overall Steps per Second: 10,770.40054

Timestep Collection Time: 2.21075
Timestep Consumption Time: 2.43420
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.64495

Cumulative Model Updates: 92,636
Cumulative Timesteps: 772,682,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 772682378...
Checkpoint 772682378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,913.17770
Policy Entropy: 1.81380
Value Function Loss: 0.08054

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14788
Policy Update Magnitude: 0.54714
Value Function Update Magnitude: 0.70382

Collected Steps per Second: 21,878.36177
Overall Steps per Second: 10,476.02318

Timestep Collection Time: 2.28619
Timestep Consumption Time: 2.48834
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.77452

Cumulative Model Updates: 92,642
Cumulative Timesteps: 772,732,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,990.75835
Policy Entropy: 1.79393
Value Function Loss: 0.07907

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13546
Policy Update Magnitude: 0.56156
Value Function Update Magnitude: 0.63846

Collected Steps per Second: 22,501.21911
Overall Steps per Second: 10,739.91805

Timestep Collection Time: 2.22335
Timestep Consumption Time: 2.43479
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.65814

Cumulative Model Updates: 92,648
Cumulative Timesteps: 772,782,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 772782424...
Checkpoint 772782424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,525.83591
Policy Entropy: 1.80897
Value Function Loss: 0.08673

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13546
Policy Update Magnitude: 0.57699
Value Function Update Magnitude: 0.60632

Collected Steps per Second: 22,540.26396
Overall Steps per Second: 10,608.84830

Timestep Collection Time: 2.21932
Timestep Consumption Time: 2.49599
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.71531

Cumulative Model Updates: 92,654
Cumulative Timesteps: 772,832,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,569.92176
Policy Entropy: 1.80648
Value Function Loss: 0.08833

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.14120
Policy Update Magnitude: 0.58668
Value Function Update Magnitude: 0.63321

Collected Steps per Second: 22,537.83094
Overall Steps per Second: 10,526.62320

Timestep Collection Time: 2.21982
Timestep Consumption Time: 2.53289
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.75271

Cumulative Model Updates: 92,660
Cumulative Timesteps: 772,882,478

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 772882478...
Checkpoint 772882478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,499.79635
Policy Entropy: 1.81158
Value Function Loss: 0.08620

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14762
Policy Update Magnitude: 0.58273
Value Function Update Magnitude: 0.67004

Collected Steps per Second: 22,257.80168
Overall Steps per Second: 10,598.46650

Timestep Collection Time: 2.24730
Timestep Consumption Time: 2.47225
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.71955

Cumulative Model Updates: 92,666
Cumulative Timesteps: 772,932,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,366.83690
Policy Entropy: 1.81757
Value Function Loss: 0.08492

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13670
Policy Update Magnitude: 0.54557
Value Function Update Magnitude: 0.68058

Collected Steps per Second: 22,566.27568
Overall Steps per Second: 10,797.98117

Timestep Collection Time: 2.21570
Timestep Consumption Time: 2.41480
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.63050

Cumulative Model Updates: 92,672
Cumulative Timesteps: 772,982,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 772982498...
Checkpoint 772982498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,141.14753
Policy Entropy: 1.81198
Value Function Loss: 0.08243

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.54320
Value Function Update Magnitude: 0.62972

Collected Steps per Second: 21,497.91783
Overall Steps per Second: 10,325.85879

Timestep Collection Time: 2.32627
Timestep Consumption Time: 2.51691
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.84318

Cumulative Model Updates: 92,678
Cumulative Timesteps: 773,032,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,730.81565
Policy Entropy: 1.80799
Value Function Loss: 0.08943

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.56380
Value Function Update Magnitude: 0.52473

Collected Steps per Second: 22,390.66907
Overall Steps per Second: 10,774.84573

Timestep Collection Time: 2.23477
Timestep Consumption Time: 2.40919
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.64396

Cumulative Model Updates: 92,684
Cumulative Timesteps: 773,082,546

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 773082546...
Checkpoint 773082546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,510.82499
Policy Entropy: 1.80094
Value Function Loss: 0.08207

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.57724
Value Function Update Magnitude: 0.53272

Collected Steps per Second: 21,974.16426
Overall Steps per Second: 10,472.51613

Timestep Collection Time: 2.27658
Timestep Consumption Time: 2.50030
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.77688

Cumulative Model Updates: 92,690
Cumulative Timesteps: 773,132,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,649.39440
Policy Entropy: 1.79607
Value Function Loss: 0.08148

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.58656
Value Function Update Magnitude: 0.54445

Collected Steps per Second: 22,633.77632
Overall Steps per Second: 10,671.37893

Timestep Collection Time: 2.21015
Timestep Consumption Time: 2.47753
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.68768

Cumulative Model Updates: 92,696
Cumulative Timesteps: 773,182,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 773182596...
Checkpoint 773182596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,830.25355
Policy Entropy: 1.79457
Value Function Loss: 0.08667

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.15836
Policy Update Magnitude: 0.57507
Value Function Update Magnitude: 0.56692

Collected Steps per Second: 22,101.50648
Overall Steps per Second: 10,635.93675

Timestep Collection Time: 2.26365
Timestep Consumption Time: 2.44022
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.70386

Cumulative Model Updates: 92,702
Cumulative Timesteps: 773,232,626

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,760.37705
Policy Entropy: 1.79374
Value Function Loss: 0.08407

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.15584
Policy Update Magnitude: 0.52740
Value Function Update Magnitude: 0.55843

Collected Steps per Second: 22,416.29967
Overall Steps per Second: 10,512.17246

Timestep Collection Time: 2.23186
Timestep Consumption Time: 2.52739
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.75924

Cumulative Model Updates: 92,708
Cumulative Timesteps: 773,282,656

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 773282656...
Checkpoint 773282656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,336.43195
Policy Entropy: 1.79688
Value Function Loss: 0.08499

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.55870
Value Function Update Magnitude: 0.61094

Collected Steps per Second: 22,309.58471
Overall Steps per Second: 10,678.02378

Timestep Collection Time: 2.24253
Timestep Consumption Time: 2.44279
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.68532

Cumulative Model Updates: 92,714
Cumulative Timesteps: 773,332,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,301.36217
Policy Entropy: 1.78413
Value Function Loss: 0.08154

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.14646
Policy Update Magnitude: 0.57822
Value Function Update Magnitude: 0.67865

Collected Steps per Second: 22,156.15753
Overall Steps per Second: 10,485.34948

Timestep Collection Time: 2.25698
Timestep Consumption Time: 2.51215
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.76913

Cumulative Model Updates: 92,720
Cumulative Timesteps: 773,382,692

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 773382692...
Checkpoint 773382692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,788.79177
Policy Entropy: 1.77431
Value Function Loss: 0.08443

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.57082
Value Function Update Magnitude: 0.65574

Collected Steps per Second: 21,813.54434
Overall Steps per Second: 10,536.09214

Timestep Collection Time: 2.29325
Timestep Consumption Time: 2.45462
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.74787

Cumulative Model Updates: 92,726
Cumulative Timesteps: 773,432,716

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,516.88268
Policy Entropy: 1.78187
Value Function Loss: 0.08584

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.57094
Value Function Update Magnitude: 0.68072

Collected Steps per Second: 22,375.04951
Overall Steps per Second: 10,477.16103

Timestep Collection Time: 2.23722
Timestep Consumption Time: 2.54060
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.77782

Cumulative Model Updates: 92,732
Cumulative Timesteps: 773,482,774

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


Saving checkpoint 773482774...
Checkpoint 773482774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,618.86321
Policy Entropy: 1.80629
Value Function Loss: 0.08050

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 0.57009
Value Function Update Magnitude: 0.71704

Collected Steps per Second: 22,220.53577
Overall Steps per Second: 10,621.90364

Timestep Collection Time: 2.25062
Timestep Consumption Time: 2.45757
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.70820

Cumulative Model Updates: 92,738
Cumulative Timesteps: 773,532,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,469.82116
Policy Entropy: 1.81872
Value Function Loss: 0.07912

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.55372
Value Function Update Magnitude: 0.73534

Collected Steps per Second: 22,219.38813
Overall Steps per Second: 10,447.78458

Timestep Collection Time: 2.25038
Timestep Consumption Time: 2.53552
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.78589

Cumulative Model Updates: 92,744
Cumulative Timesteps: 773,582,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 773582786...
Checkpoint 773582786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,084.70071
Policy Entropy: 1.80412
Value Function Loss: 0.08066

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.54513
Value Function Update Magnitude: 0.69847

Collected Steps per Second: 21,898.53236
Overall Steps per Second: 10,585.17341

Timestep Collection Time: 2.28435
Timestep Consumption Time: 2.44150
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.72586

Cumulative Model Updates: 92,750
Cumulative Timesteps: 773,632,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,898.92969
Policy Entropy: 1.80302
Value Function Loss: 0.08363

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.56017
Value Function Update Magnitude: 0.66924

Collected Steps per Second: 22,670.25071
Overall Steps per Second: 10,574.37140

Timestep Collection Time: 2.20589
Timestep Consumption Time: 2.52328
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.72917

Cumulative Model Updates: 92,756
Cumulative Timesteps: 773,682,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 773682818...
Checkpoint 773682818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,100.57652
Policy Entropy: 1.79669
Value Function Loss: 0.09120

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.58528
Value Function Update Magnitude: 0.62445

Collected Steps per Second: 22,474.03225
Overall Steps per Second: 10,641.81037

Timestep Collection Time: 2.22693
Timestep Consumption Time: 2.47603
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.70296

Cumulative Model Updates: 92,762
Cumulative Timesteps: 773,732,866

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,738.00649
Policy Entropy: 1.81720
Value Function Loss: 0.09237

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.59771
Value Function Update Magnitude: 0.54591

Collected Steps per Second: 22,685.44474
Overall Steps per Second: 10,622.74127

Timestep Collection Time: 2.20503
Timestep Consumption Time: 2.50393
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.70895

Cumulative Model Updates: 92,768
Cumulative Timesteps: 773,782,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 773782888...
Checkpoint 773782888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,896.43146
Policy Entropy: 1.82399
Value Function Loss: 0.09087

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.59382
Value Function Update Magnitude: 0.53817

Collected Steps per Second: 22,371.48674
Overall Steps per Second: 10,594.01175

Timestep Collection Time: 2.23561
Timestep Consumption Time: 2.48536
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.72097

Cumulative Model Updates: 92,774
Cumulative Timesteps: 773,832,902

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,027.00152
Policy Entropy: 1.82433
Value Function Loss: 0.08599

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12865
Policy Update Magnitude: 0.58143
Value Function Update Magnitude: 0.55905

Collected Steps per Second: 22,602.53155
Overall Steps per Second: 10,743.39339

Timestep Collection Time: 2.21329
Timestep Consumption Time: 2.44315
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.65644

Cumulative Model Updates: 92,780
Cumulative Timesteps: 773,882,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 773882928...
Checkpoint 773882928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,091.43900
Policy Entropy: 1.82107
Value Function Loss: 0.08533

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.58389
Value Function Update Magnitude: 0.65794

Collected Steps per Second: 21,968.09041
Overall Steps per Second: 10,613.07232

Timestep Collection Time: 2.27712
Timestep Consumption Time: 2.43631
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.71343

Cumulative Model Updates: 92,786
Cumulative Timesteps: 773,932,952

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,519.11102
Policy Entropy: 1.83101
Value Function Loss: 0.08069

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.58104
Value Function Update Magnitude: 0.63732

Collected Steps per Second: 21,964.13102
Overall Steps per Second: 10,488.09023

Timestep Collection Time: 2.27708
Timestep Consumption Time: 2.49157
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.76865

Cumulative Model Updates: 92,792
Cumulative Timesteps: 773,982,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 773982966...
Checkpoint 773982966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,190.46825
Policy Entropy: 1.84239
Value Function Loss: 0.07786

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.56635
Value Function Update Magnitude: 0.61283

Collected Steps per Second: 21,935.37442
Overall Steps per Second: 10,575.76354

Timestep Collection Time: 2.27997
Timestep Consumption Time: 2.44896
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.72893

Cumulative Model Updates: 92,798
Cumulative Timesteps: 774,032,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,222.67424
Policy Entropy: 1.82906
Value Function Loss: 0.07695

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.56433
Value Function Update Magnitude: 0.66065

Collected Steps per Second: 22,366.92747
Overall Steps per Second: 10,582.71652

Timestep Collection Time: 2.23553
Timestep Consumption Time: 2.48934
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.72487

Cumulative Model Updates: 92,804
Cumulative Timesteps: 774,082,980

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 774082980...
Checkpoint 774082980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,537.33921
Policy Entropy: 1.81647
Value Function Loss: 0.07607

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.55864
Value Function Update Magnitude: 0.67604

Collected Steps per Second: 22,439.20902
Overall Steps per Second: 10,592.07112

Timestep Collection Time: 2.22994
Timestep Consumption Time: 2.49416
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.72410

Cumulative Model Updates: 92,810
Cumulative Timesteps: 774,133,018

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,626.22015
Policy Entropy: 1.81452
Value Function Loss: 0.07644

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.55793
Value Function Update Magnitude: 0.57980

Collected Steps per Second: 22,583.78131
Overall Steps per Second: 10,603.43908

Timestep Collection Time: 2.21424
Timestep Consumption Time: 2.50177
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.71602

Cumulative Model Updates: 92,816
Cumulative Timesteps: 774,183,024

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 774183024...
Checkpoint 774183024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,358.64451
Policy Entropy: 1.81920
Value Function Loss: 0.07958

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12839
Policy Update Magnitude: 0.57029
Value Function Update Magnitude: 0.59218

Collected Steps per Second: 22,017.58299
Overall Steps per Second: 10,521.34504

Timestep Collection Time: 2.27191
Timestep Consumption Time: 2.48242
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.75434

Cumulative Model Updates: 92,822
Cumulative Timesteps: 774,233,046

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,898.81082
Policy Entropy: 1.82262
Value Function Loss: 0.08344

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.57809
Value Function Update Magnitude: 0.63358

Collected Steps per Second: 22,347.22262
Overall Steps per Second: 10,778.57054

Timestep Collection Time: 2.23750
Timestep Consumption Time: 2.40152
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.63902

Cumulative Model Updates: 92,828
Cumulative Timesteps: 774,283,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 774283048...
Checkpoint 774283048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,826.13065
Policy Entropy: 1.82322
Value Function Loss: 0.08768

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.58314
Value Function Update Magnitude: 0.63895

Collected Steps per Second: 22,196.71909
Overall Steps per Second: 10,667.59723

Timestep Collection Time: 2.25367
Timestep Consumption Time: 2.43567
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.68934

Cumulative Model Updates: 92,834
Cumulative Timesteps: 774,333,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,258.25625
Policy Entropy: 1.82170
Value Function Loss: 0.08513

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.57166
Value Function Update Magnitude: 0.65809

Collected Steps per Second: 22,527.19529
Overall Steps per Second: 10,536.29959

Timestep Collection Time: 2.22007
Timestep Consumption Time: 2.52657
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.74664

Cumulative Model Updates: 92,840
Cumulative Timesteps: 774,383,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 774383084...
Checkpoint 774383084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,395.31672
Policy Entropy: 1.81812
Value Function Loss: 0.08861

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.15423
Policy Update Magnitude: 0.57602
Value Function Update Magnitude: 0.66314

Collected Steps per Second: 22,263.27180
Overall Steps per Second: 10,576.63645

Timestep Collection Time: 2.24666
Timestep Consumption Time: 2.48244
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.72910

Cumulative Model Updates: 92,846
Cumulative Timesteps: 774,433,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,231.39215
Policy Entropy: 1.80561
Value Function Loss: 0.09170

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.16934
Policy Update Magnitude: 0.58703
Value Function Update Magnitude: 0.71177

Collected Steps per Second: 22,470.19687
Overall Steps per Second: 10,544.18568

Timestep Collection Time: 2.22588
Timestep Consumption Time: 2.51759
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.74347

Cumulative Model Updates: 92,852
Cumulative Timesteps: 774,483,118

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 774483118...
Checkpoint 774483118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,173.55457
Policy Entropy: 1.79171
Value Function Loss: 0.09361

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.17589
Policy Update Magnitude: 0.59256
Value Function Update Magnitude: 0.73180

Collected Steps per Second: 21,756.40491
Overall Steps per Second: 10,529.26560

Timestep Collection Time: 2.29882
Timestep Consumption Time: 2.45118
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.75000

Cumulative Model Updates: 92,858
Cumulative Timesteps: 774,533,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,725.97804
Policy Entropy: 1.78618
Value Function Loss: 0.08858

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.16412
Policy Update Magnitude: 0.56118
Value Function Update Magnitude: 0.77725

Collected Steps per Second: 21,681.61034
Overall Steps per Second: 10,435.85465

Timestep Collection Time: 2.30721
Timestep Consumption Time: 2.48627
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.79347

Cumulative Model Updates: 92,864
Cumulative Timesteps: 774,583,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 774583156...
Checkpoint 774583156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,459.20215
Policy Entropy: 1.80651
Value Function Loss: 0.08215

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.56538
Value Function Update Magnitude: 0.77399

Collected Steps per Second: 21,920.21312
Overall Steps per Second: 10,631.20506

Timestep Collection Time: 2.28209
Timestep Consumption Time: 2.42330
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.70539

Cumulative Model Updates: 92,870
Cumulative Timesteps: 774,633,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,248.17315
Policy Entropy: 1.82662
Value Function Loss: 0.08170

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.56122
Value Function Update Magnitude: 0.77349

Collected Steps per Second: 22,263.93519
Overall Steps per Second: 10,542.84410

Timestep Collection Time: 2.24614
Timestep Consumption Time: 2.49717
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.74331

Cumulative Model Updates: 92,876
Cumulative Timesteps: 774,683,188

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 774683188...
Checkpoint 774683188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,164.43657
Policy Entropy: 1.81333
Value Function Loss: 0.07988

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.16619
Policy Update Magnitude: 0.53135
Value Function Update Magnitude: 0.77089

Collected Steps per Second: 22,302.72938
Overall Steps per Second: 10,706.61932

Timestep Collection Time: 2.24251
Timestep Consumption Time: 2.42881
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.67132

Cumulative Model Updates: 92,882
Cumulative Timesteps: 774,733,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,961.81961
Policy Entropy: 1.81429
Value Function Loss: 0.08395

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.16921
Policy Update Magnitude: 0.49635
Value Function Update Magnitude: 0.70072

Collected Steps per Second: 22,638.87100
Overall Steps per Second: 10,481.05095

Timestep Collection Time: 2.21000
Timestep Consumption Time: 2.56356
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.77357

Cumulative Model Updates: 92,888
Cumulative Timesteps: 774,783,234

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 774783234...
Checkpoint 774783234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,123.77563
Policy Entropy: 1.80514
Value Function Loss: 0.08152

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.16604
Policy Update Magnitude: 0.47412
Value Function Update Magnitude: 0.67096

Collected Steps per Second: 21,847.82336
Overall Steps per Second: 10,529.22008

Timestep Collection Time: 2.28856
Timestep Consumption Time: 2.46013
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.74869

Cumulative Model Updates: 92,894
Cumulative Timesteps: 774,833,234

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,976.73466
Policy Entropy: 1.82234
Value Function Loss: 0.08204

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.14377
Policy Update Magnitude: 0.53034
Value Function Update Magnitude: 0.70835

Collected Steps per Second: 21,990.61200
Overall Steps per Second: 10,464.50783

Timestep Collection Time: 2.27461
Timestep Consumption Time: 2.50536
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.77997

Cumulative Model Updates: 92,900
Cumulative Timesteps: 774,883,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 774883254...
Checkpoint 774883254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,179.74805
Policy Entropy: 1.80561
Value Function Loss: 0.08369

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.57317
Value Function Update Magnitude: 0.77814

Collected Steps per Second: 21,913.55198
Overall Steps per Second: 10,585.50831

Timestep Collection Time: 2.28306
Timestep Consumption Time: 2.44321
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.72627

Cumulative Model Updates: 92,906
Cumulative Timesteps: 774,933,284

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,100.43275
Policy Entropy: 1.80882
Value Function Loss: 0.08788

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.58079
Value Function Update Magnitude: 0.74408

Collected Steps per Second: 22,449.54800
Overall Steps per Second: 10,504.56113

Timestep Collection Time: 2.22748
Timestep Consumption Time: 2.53292
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.76041

Cumulative Model Updates: 92,912
Cumulative Timesteps: 774,983,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 774983290...
Checkpoint 774983290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,766.38787
Policy Entropy: 1.80594
Value Function Loss: 0.08864

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.56397
Value Function Update Magnitude: 0.69725

Collected Steps per Second: 22,535.98159
Overall Steps per Second: 10,636.91049

Timestep Collection Time: 2.21894
Timestep Consumption Time: 2.48224
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.70118

Cumulative Model Updates: 92,918
Cumulative Timesteps: 775,033,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,026.67770
Policy Entropy: 1.80640
Value Function Loss: 0.08903

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.16562
Policy Update Magnitude: 0.50374
Value Function Update Magnitude: 0.73227

Collected Steps per Second: 22,367.08229
Overall Steps per Second: 10,544.24969

Timestep Collection Time: 2.23695
Timestep Consumption Time: 2.50820
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.74515

Cumulative Model Updates: 92,924
Cumulative Timesteps: 775,083,330

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 775083330...
Checkpoint 775083330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,239.43571
Policy Entropy: 1.80572
Value Function Loss: 0.08960

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.16896
Policy Update Magnitude: 0.52226
Value Function Update Magnitude: 0.60478

Collected Steps per Second: 22,056.30684
Overall Steps per Second: 10,588.32010

Timestep Collection Time: 2.26693
Timestep Consumption Time: 2.45526
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.72218

Cumulative Model Updates: 92,930
Cumulative Timesteps: 775,133,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,145.72866
Policy Entropy: 1.82903
Value Function Loss: 0.09210

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.15975
Policy Update Magnitude: 0.51046
Value Function Update Magnitude: 0.55375

Collected Steps per Second: 22,640.78194
Overall Steps per Second: 10,796.01306

Timestep Collection Time: 2.20867
Timestep Consumption Time: 2.42323
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.63190

Cumulative Model Updates: 92,936
Cumulative Timesteps: 775,183,336

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 775183336...
Checkpoint 775183336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,460.38649
Policy Entropy: 1.82484
Value Function Loss: 0.08657

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.16367
Policy Update Magnitude: 0.48171
Value Function Update Magnitude: 0.68544

Collected Steps per Second: 22,258.48284
Overall Steps per Second: 10,653.83695

Timestep Collection Time: 2.24651
Timestep Consumption Time: 2.44701
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.69352

Cumulative Model Updates: 92,942
Cumulative Timesteps: 775,233,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,605.99059
Policy Entropy: 1.82410
Value Function Loss: 0.08042

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.16264
Policy Update Magnitude: 0.47380
Value Function Update Magnitude: 0.73407

Collected Steps per Second: 22,508.47004
Overall Steps per Second: 10,523.50005

Timestep Collection Time: 2.22236
Timestep Consumption Time: 2.53100
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.75336

Cumulative Model Updates: 92,948
Cumulative Timesteps: 775,283,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 775283362...
Checkpoint 775283362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,686.36436
Policy Entropy: 1.79869
Value Function Loss: 0.07384

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.53149
Value Function Update Magnitude: 0.69588

Collected Steps per Second: 22,034.63691
Overall Steps per Second: 10,623.42072

Timestep Collection Time: 2.26997
Timestep Consumption Time: 2.43830
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.70828

Cumulative Model Updates: 92,954
Cumulative Timesteps: 775,333,380

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,273.65930
Policy Entropy: 1.81007
Value Function Loss: 0.07478

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.13596
Policy Update Magnitude: 0.55591
Value Function Update Magnitude: 0.68685

Collected Steps per Second: 22,429.09623
Overall Steps per Second: 10,531.05353

Timestep Collection Time: 2.23014
Timestep Consumption Time: 2.51962
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.74976

Cumulative Model Updates: 92,960
Cumulative Timesteps: 775,383,400

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 775383400...
Checkpoint 775383400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,368.31010
Policy Entropy: 1.81569
Value Function Loss: 0.07878

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.57689
Value Function Update Magnitude: 0.75103

Collected Steps per Second: 22,326.41474
Overall Steps per Second: 10,616.78459

Timestep Collection Time: 2.24057
Timestep Consumption Time: 2.47121
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.71178

Cumulative Model Updates: 92,966
Cumulative Timesteps: 775,433,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,852.56461
Policy Entropy: 1.82285
Value Function Loss: 0.08060

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.14283
Policy Update Magnitude: 0.58188
Value Function Update Magnitude: 0.75235

Collected Steps per Second: 22,012.07800
Overall Steps per Second: 10,437.90981

Timestep Collection Time: 2.27266
Timestep Consumption Time: 2.52006
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.79272

Cumulative Model Updates: 92,972
Cumulative Timesteps: 775,483,450

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 775483450...
Checkpoint 775483450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,560.04110
Policy Entropy: 1.84211
Value Function Loss: 0.08347

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.58438
Value Function Update Magnitude: 0.74949

Collected Steps per Second: 21,930.61022
Overall Steps per Second: 10,593.98328

Timestep Collection Time: 2.28047
Timestep Consumption Time: 2.44033
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.72079

Cumulative Model Updates: 92,978
Cumulative Timesteps: 775,533,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,718.57796
Policy Entropy: 1.82755
Value Function Loss: 0.08370

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.59174
Value Function Update Magnitude: 0.69425

Collected Steps per Second: 22,566.76154
Overall Steps per Second: 10,535.57275

Timestep Collection Time: 2.21600
Timestep Consumption Time: 2.53058
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.74659

Cumulative Model Updates: 92,984
Cumulative Timesteps: 775,583,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 775583470...
Checkpoint 775583470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,567.96583
Policy Entropy: 1.84647
Value Function Loss: 0.08649

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.58941
Value Function Update Magnitude: 0.64970

Collected Steps per Second: 22,031.90407
Overall Steps per Second: 10,624.91577

Timestep Collection Time: 2.27053
Timestep Consumption Time: 2.43765
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.70818

Cumulative Model Updates: 92,990
Cumulative Timesteps: 775,633,494

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,156.90480
Policy Entropy: 1.82872
Value Function Loss: 0.08376

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.58715
Value Function Update Magnitude: 0.68599

Collected Steps per Second: 22,368.46137
Overall Steps per Second: 10,491.27699

Timestep Collection Time: 2.23538
Timestep Consumption Time: 2.53068
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.76605

Cumulative Model Updates: 92,996
Cumulative Timesteps: 775,683,496

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 775683496...
Checkpoint 775683496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,292.76017
Policy Entropy: 1.82835
Value Function Loss: 0.08713

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13822
Policy Update Magnitude: 0.59772
Value Function Update Magnitude: 0.74683

Collected Steps per Second: 22,160.88617
Overall Steps per Second: 10,599.05081

Timestep Collection Time: 2.25758
Timestep Consumption Time: 2.46265
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.72023

Cumulative Model Updates: 93,002
Cumulative Timesteps: 775,733,526

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,204.31539
Policy Entropy: 1.81793
Value Function Loss: 0.08252

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.14406
Policy Update Magnitude: 0.58595
Value Function Update Magnitude: 0.79606

Collected Steps per Second: 22,487.34603
Overall Steps per Second: 10,511.82165

Timestep Collection Time: 2.22347
Timestep Consumption Time: 2.53308
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.75655

Cumulative Model Updates: 93,008
Cumulative Timesteps: 775,783,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 775783526...
Checkpoint 775783526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,842.59788
Policy Entropy: 1.80814
Value Function Loss: 0.08048

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.54945
Value Function Update Magnitude: 0.81087

Collected Steps per Second: 22,376.38196
Overall Steps per Second: 10,541.85150

Timestep Collection Time: 2.23655
Timestep Consumption Time: 2.51081
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.74736

Cumulative Model Updates: 93,014
Cumulative Timesteps: 775,833,572

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,247.16571
Policy Entropy: 1.81024
Value Function Loss: 0.08184

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.15732
Policy Update Magnitude: 0.50378
Value Function Update Magnitude: 0.79611

Collected Steps per Second: 22,179.40084
Overall Steps per Second: 10,459.93277

Timestep Collection Time: 2.25516
Timestep Consumption Time: 2.52671
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.78187

Cumulative Model Updates: 93,020
Cumulative Timesteps: 775,883,590

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 775883590...
Checkpoint 775883590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,285.33129
Policy Entropy: 1.79174
Value Function Loss: 0.08329

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.15389
Policy Update Magnitude: 0.47714
Value Function Update Magnitude: 0.79922

Collected Steps per Second: 21,730.39722
Overall Steps per Second: 10,580.20240

Timestep Collection Time: 2.30230
Timestep Consumption Time: 2.42634
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.72864

Cumulative Model Updates: 93,026
Cumulative Timesteps: 775,933,620

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,584.49444
Policy Entropy: 1.80524
Value Function Loss: 0.08715

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.15360
Policy Update Magnitude: 0.50144
Value Function Update Magnitude: 0.76391

Collected Steps per Second: 22,664.78749
Overall Steps per Second: 10,586.05336

Timestep Collection Time: 2.20721
Timestep Consumption Time: 2.51844
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.72565

Cumulative Model Updates: 93,032
Cumulative Timesteps: 775,983,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 775983646...
Checkpoint 775983646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,239.77448
Policy Entropy: 1.80256
Value Function Loss: 0.09326

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.16453
Policy Update Magnitude: 0.52419
Value Function Update Magnitude: 0.71597

Collected Steps per Second: 22,362.01312
Overall Steps per Second: 10,577.02619

Timestep Collection Time: 2.23629
Timestep Consumption Time: 2.49169
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.72798

Cumulative Model Updates: 93,038
Cumulative Timesteps: 776,033,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,918.61985
Policy Entropy: 1.81370
Value Function Loss: 0.09223

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.17051
Policy Update Magnitude: 0.52132
Value Function Update Magnitude: 0.79361

Collected Steps per Second: 22,577.99811
Overall Steps per Second: 10,614.18612

Timestep Collection Time: 2.21463
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.71087

Cumulative Model Updates: 93,044
Cumulative Timesteps: 776,083,656

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 776083656...
Checkpoint 776083656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,855.18321
Policy Entropy: 1.80794
Value Function Loss: 0.09082

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.16112
Policy Update Magnitude: 0.53633
Value Function Update Magnitude: 0.71670

Collected Steps per Second: 21,769.03241
Overall Steps per Second: 10,485.36152

Timestep Collection Time: 2.29794
Timestep Consumption Time: 2.47290
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.77084

Cumulative Model Updates: 93,050
Cumulative Timesteps: 776,133,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,382.29249
Policy Entropy: 1.80683
Value Function Loss: 0.09039

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.17029
Policy Update Magnitude: 0.52401
Value Function Update Magnitude: 0.64378

Collected Steps per Second: 22,385.32143
Overall Steps per Second: 10,533.14592

Timestep Collection Time: 2.23477
Timestep Consumption Time: 2.51462
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.74939

Cumulative Model Updates: 93,056
Cumulative Timesteps: 776,183,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 776183706...
Checkpoint 776183706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,258.48090
Policy Entropy: 1.81319
Value Function Loss: 0.08491

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.15743
Policy Update Magnitude: 0.49847
Value Function Update Magnitude: 0.65639

Collected Steps per Second: 22,376.34492
Overall Steps per Second: 10,557.84409

Timestep Collection Time: 2.23522
Timestep Consumption Time: 2.50211
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.73733

Cumulative Model Updates: 93,062
Cumulative Timesteps: 776,233,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,114.84457
Policy Entropy: 1.81463
Value Function Loss: 0.08605

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.16006
Policy Update Magnitude: 0.49573
Value Function Update Magnitude: 0.63962

Collected Steps per Second: 22,364.63029
Overall Steps per Second: 10,559.38506

Timestep Collection Time: 2.23701
Timestep Consumption Time: 2.50095
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.73797

Cumulative Model Updates: 93,068
Cumulative Timesteps: 776,283,752

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 776283752...
Checkpoint 776283752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,219.15881
Policy Entropy: 1.83115
Value Function Loss: 0.08582

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.49988
Value Function Update Magnitude: 0.65221

Collected Steps per Second: 21,932.61442
Overall Steps per Second: 10,568.83130

Timestep Collection Time: 2.28035
Timestep Consumption Time: 2.45187
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.73222

Cumulative Model Updates: 93,074
Cumulative Timesteps: 776,333,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,940.70675
Policy Entropy: 1.83411
Value Function Loss: 0.08754

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.56431
Value Function Update Magnitude: 0.63818

Collected Steps per Second: 22,661.46133
Overall Steps per Second: 10,772.94072

Timestep Collection Time: 2.20648
Timestep Consumption Time: 2.43497
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.64144

Cumulative Model Updates: 93,080
Cumulative Timesteps: 776,383,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 776383768...
Checkpoint 776383768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,373.40470
Policy Entropy: 1.81581
Value Function Loss: 0.08251

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.58216
Value Function Update Magnitude: 0.60261

Collected Steps per Second: 21,968.22930
Overall Steps per Second: 10,469.53019

Timestep Collection Time: 2.27665
Timestep Consumption Time: 2.50045
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.77710

Cumulative Model Updates: 93,086
Cumulative Timesteps: 776,433,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,153.87701
Policy Entropy: 1.78706
Value Function Loss: 0.07926

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.58438
Value Function Update Magnitude: 0.56160

Collected Steps per Second: 22,460.38740
Overall Steps per Second: 10,723.60203

Timestep Collection Time: 2.22774
Timestep Consumption Time: 2.43823
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.66597

Cumulative Model Updates: 93,092
Cumulative Timesteps: 776,483,818

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 776483818...
Checkpoint 776483818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,172.80206
Policy Entropy: 1.78439
Value Function Loss: 0.07733

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13469
Policy Update Magnitude: 0.58781
Value Function Update Magnitude: 0.61157

Collected Steps per Second: 21,219.72708
Overall Steps per Second: 10,266.18129

Timestep Collection Time: 2.35743
Timestep Consumption Time: 2.51527
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.87270

Cumulative Model Updates: 93,098
Cumulative Timesteps: 776,533,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,761.24884
Policy Entropy: 1.79070
Value Function Loss: 0.08107

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.58764
Value Function Update Magnitude: 0.66612

Collected Steps per Second: 22,084.42890
Overall Steps per Second: 10,458.97268

Timestep Collection Time: 2.26503
Timestep Consumption Time: 2.51765
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.78269

Cumulative Model Updates: 93,104
Cumulative Timesteps: 776,583,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 776583864...
Checkpoint 776583864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,440.82594
Policy Entropy: 1.79130
Value Function Loss: 0.08093

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14508
Policy Update Magnitude: 0.57295
Value Function Update Magnitude: 0.74458

Collected Steps per Second: 22,160.00404
Overall Steps per Second: 10,523.64142

Timestep Collection Time: 2.25704
Timestep Consumption Time: 2.49569
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.75273

Cumulative Model Updates: 93,110
Cumulative Timesteps: 776,633,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,841.33628
Policy Entropy: 1.81159
Value Function Loss: 0.08090

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.16869
Policy Update Magnitude: 0.50412
Value Function Update Magnitude: 0.75393

Collected Steps per Second: 22,387.19864
Overall Steps per Second: 10,493.89731

Timestep Collection Time: 2.23431
Timestep Consumption Time: 2.53227
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.76658

Cumulative Model Updates: 93,116
Cumulative Timesteps: 776,683,900

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 776683900...
Checkpoint 776683900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,489.51177
Policy Entropy: 1.80362
Value Function Loss: 0.08121

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.15352
Policy Update Magnitude: 0.53799
Value Function Update Magnitude: 0.73116

Collected Steps per Second: 21,701.17836
Overall Steps per Second: 10,567.90521

Timestep Collection Time: 2.30485
Timestep Consumption Time: 2.42816
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.73301

Cumulative Model Updates: 93,122
Cumulative Timesteps: 776,733,918

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,147.86300
Policy Entropy: 1.80406
Value Function Loss: 0.08313

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.16811
Policy Update Magnitude: 0.55956
Value Function Update Magnitude: 0.75442

Collected Steps per Second: 22,335.43322
Overall Steps per Second: 10,508.94969

Timestep Collection Time: 2.23985
Timestep Consumption Time: 2.52066
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.76051

Cumulative Model Updates: 93,128
Cumulative Timesteps: 776,783,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 776783946...
Checkpoint 776783946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,231.27088
Policy Entropy: 1.78371
Value Function Loss: 0.08529

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.16408
Policy Update Magnitude: 0.54190
Value Function Update Magnitude: 0.76911

Collected Steps per Second: 22,292.75352
Overall Steps per Second: 10,688.93865

Timestep Collection Time: 2.24288
Timestep Consumption Time: 2.43485
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.67773

Cumulative Model Updates: 93,134
Cumulative Timesteps: 776,833,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,782.38644
Policy Entropy: 1.79463
Value Function Loss: 0.09063

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.17084
Policy Update Magnitude: 0.52049
Value Function Update Magnitude: 0.73755

Collected Steps per Second: 22,437.34182
Overall Steps per Second: 10,593.31861

Timestep Collection Time: 2.22923
Timestep Consumption Time: 2.49243
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.72166

Cumulative Model Updates: 93,140
Cumulative Timesteps: 776,883,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 776883964...
Checkpoint 776883964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,293.15280
Policy Entropy: 1.79137
Value Function Loss: 0.08718

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.17506
Policy Update Magnitude: 0.49426
Value Function Update Magnitude: 0.68483

Collected Steps per Second: 21,982.75389
Overall Steps per Second: 10,466.15738

Timestep Collection Time: 2.27588
Timestep Consumption Time: 2.50429
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.78017

Cumulative Model Updates: 93,146
Cumulative Timesteps: 776,933,994

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,398.47398
Policy Entropy: 1.79351
Value Function Loss: 0.07877

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.17705
Policy Update Magnitude: 0.54321
Value Function Update Magnitude: 0.71750

Collected Steps per Second: 22,386.61194
Overall Steps per Second: 10,516.40308

Timestep Collection Time: 2.23401
Timestep Consumption Time: 2.52160
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.75562

Cumulative Model Updates: 93,152
Cumulative Timesteps: 776,984,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 776984006...
Checkpoint 776984006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,409.30201
Policy Entropy: 1.77592
Value Function Loss: 0.07624

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.17384
Policy Update Magnitude: 0.57317
Value Function Update Magnitude: 0.71467

Collected Steps per Second: 22,466.38007
Overall Steps per Second: 10,544.98055

Timestep Collection Time: 2.22564
Timestep Consumption Time: 2.51615
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.74178

Cumulative Model Updates: 93,158
Cumulative Timesteps: 777,034,008

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,467.88542
Policy Entropy: 1.79321
Value Function Loss: 0.08487

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.15721
Policy Update Magnitude: 0.58723
Value Function Update Magnitude: 0.60799

Collected Steps per Second: 22,704.99078
Overall Steps per Second: 10,635.57830

Timestep Collection Time: 2.20286
Timestep Consumption Time: 2.49984
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.70271

Cumulative Model Updates: 93,164
Cumulative Timesteps: 777,084,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 777084024...
Checkpoint 777084024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,586.12925
Policy Entropy: 1.81553
Value Function Loss: 0.09498

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.15554
Policy Update Magnitude: 0.59871
Value Function Update Magnitude: 0.63355

Collected Steps per Second: 22,275.00859
Overall Steps per Second: 10,504.58705

Timestep Collection Time: 2.24566
Timestep Consumption Time: 2.51626
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.76192

Cumulative Model Updates: 93,170
Cumulative Timesteps: 777,134,046

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,388.49000
Policy Entropy: 1.83307
Value Function Loss: 0.09036

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.15496
Policy Update Magnitude: 0.59698
Value Function Update Magnitude: 0.75548

Collected Steps per Second: 22,638.83400
Overall Steps per Second: 10,774.17355

Timestep Collection Time: 2.21018
Timestep Consumption Time: 2.43388
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.64407

Cumulative Model Updates: 93,176
Cumulative Timesteps: 777,184,082

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 777184082...
Checkpoint 777184082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,381.23466
Policy Entropy: 1.83665
Value Function Loss: 0.08253

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.58684
Value Function Update Magnitude: 0.74473

Collected Steps per Second: 21,663.86916
Overall Steps per Second: 10,414.52625

Timestep Collection Time: 2.30938
Timestep Consumption Time: 2.49449
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.80387

Cumulative Model Updates: 93,182
Cumulative Timesteps: 777,234,112

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,612.72285
Policy Entropy: 1.82543
Value Function Loss: 0.07502

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.14255
Policy Update Magnitude: 0.58365
Value Function Update Magnitude: 0.73055

Collected Steps per Second: 20,403.75207
Overall Steps per Second: 10,404.78271

Timestep Collection Time: 2.45063
Timestep Consumption Time: 2.35505
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.80567

Cumulative Model Updates: 93,188
Cumulative Timesteps: 777,284,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 777284114...
Checkpoint 777284114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,790.88833
Policy Entropy: 1.80144
Value Function Loss: 0.07524

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.57003
Value Function Update Magnitude: 0.69983

Collected Steps per Second: 21,738.59380
Overall Steps per Second: 10,582.54924

Timestep Collection Time: 2.30098
Timestep Consumption Time: 2.42567
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.72665

Cumulative Model Updates: 93,194
Cumulative Timesteps: 777,334,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,570.45662
Policy Entropy: 1.80463
Value Function Loss: 0.07182

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.56662
Value Function Update Magnitude: 0.68084

Collected Steps per Second: 21,816.76231
Overall Steps per Second: 10,605.54998

Timestep Collection Time: 2.29273
Timestep Consumption Time: 2.42367
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.71640

Cumulative Model Updates: 93,200
Cumulative Timesteps: 777,384,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 777384154...
Checkpoint 777384154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,081.01000
Policy Entropy: 1.79952
Value Function Loss: 0.07804

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.57040
Value Function Update Magnitude: 0.66605

Collected Steps per Second: 21,519.66339
Overall Steps per Second: 10,503.85647

Timestep Collection Time: 2.32439
Timestep Consumption Time: 2.43767
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.76206

Cumulative Model Updates: 93,206
Cumulative Timesteps: 777,434,174

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,768.55360
Policy Entropy: 1.82141
Value Function Loss: 0.08869

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.58856
Value Function Update Magnitude: 0.65405

Collected Steps per Second: 21,937.97814
Overall Steps per Second: 10,683.00689

Timestep Collection Time: 2.27970
Timestep Consumption Time: 2.40175
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.68145

Cumulative Model Updates: 93,212
Cumulative Timesteps: 777,484,186

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 777484186...
Checkpoint 777484186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,130.05570
Policy Entropy: 1.82380
Value Function Loss: 0.09064

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14353
Policy Update Magnitude: 0.59848
Value Function Update Magnitude: 0.75295

Collected Steps per Second: 21,415.30439
Overall Steps per Second: 10,495.73272

Timestep Collection Time: 2.33543
Timestep Consumption Time: 2.42974
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.76517

Cumulative Model Updates: 93,218
Cumulative Timesteps: 777,534,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,784.28145
Policy Entropy: 1.83232
Value Function Loss: 0.08620

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.14546
Policy Update Magnitude: 0.57335
Value Function Update Magnitude: 0.69388

Collected Steps per Second: 22,069.55953
Overall Steps per Second: 10,794.27274

Timestep Collection Time: 2.26629
Timestep Consumption Time: 2.36728
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.63357

Cumulative Model Updates: 93,224
Cumulative Timesteps: 777,584,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 777584216...
Checkpoint 777584216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,302.14896
Policy Entropy: 1.84319
Value Function Loss: 0.08703

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.15157
Policy Update Magnitude: 0.54775
Value Function Update Magnitude: 0.65684

Collected Steps per Second: 21,358.24297
Overall Steps per Second: 10,629.65486

Timestep Collection Time: 2.34139
Timestep Consumption Time: 2.36318
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.70457

Cumulative Model Updates: 93,230
Cumulative Timesteps: 777,634,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,103.04776
Policy Entropy: 1.84773
Value Function Loss: 0.08129

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.15625
Policy Update Magnitude: 0.53567
Value Function Update Magnitude: 0.63971

Collected Steps per Second: 21,719.02736
Overall Steps per Second: 10,575.32630

Timestep Collection Time: 2.30259
Timestep Consumption Time: 2.42634
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.72893

Cumulative Model Updates: 93,236
Cumulative Timesteps: 777,684,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 777684234...
Checkpoint 777684234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,308.64807
Policy Entropy: 1.83127
Value Function Loss: 0.08250

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.55377
Value Function Update Magnitude: 0.66324

Collected Steps per Second: 21,275.27492
Overall Steps per Second: 10,495.08499

Timestep Collection Time: 2.35024
Timestep Consumption Time: 2.41409
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.76433

Cumulative Model Updates: 93,242
Cumulative Timesteps: 777,734,236

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,043.07954
Policy Entropy: 1.81389
Value Function Loss: 0.08084

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.58039
Value Function Update Magnitude: 0.65010

Collected Steps per Second: 22,455.89991
Overall Steps per Second: 10,615.30437

Timestep Collection Time: 2.22863
Timestep Consumption Time: 2.48588
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.71451

Cumulative Model Updates: 93,248
Cumulative Timesteps: 777,784,282

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 777784282...
Checkpoint 777784282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,321.40238
Policy Entropy: 1.80381
Value Function Loss: 0.08082

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.58701
Value Function Update Magnitude: 0.70482

Collected Steps per Second: 22,032.66870
Overall Steps per Second: 10,488.57731

Timestep Collection Time: 2.27081
Timestep Consumption Time: 2.49933
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.77014

Cumulative Model Updates: 93,254
Cumulative Timesteps: 777,834,314

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,606.00279
Policy Entropy: 1.80830
Value Function Loss: 0.07988

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.58104
Value Function Update Magnitude: 0.71974

Collected Steps per Second: 22,426.79626
Overall Steps per Second: 10,610.38802

Timestep Collection Time: 2.22956
Timestep Consumption Time: 2.48299
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.71255

Cumulative Model Updates: 93,260
Cumulative Timesteps: 777,884,316

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 777884316...
Checkpoint 777884316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,369.16512
Policy Entropy: 1.79534
Value Function Loss: 0.08036

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.58147
Value Function Update Magnitude: 0.66380

Collected Steps per Second: 22,476.80049
Overall Steps per Second: 10,627.98920

Timestep Collection Time: 2.22496
Timestep Consumption Time: 2.48054
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.70550

Cumulative Model Updates: 93,266
Cumulative Timesteps: 777,934,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,719.33385
Policy Entropy: 1.80668
Value Function Loss: 0.08617

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.58087
Value Function Update Magnitude: 0.57122

Collected Steps per Second: 22,801.06867
Overall Steps per Second: 10,765.63019

Timestep Collection Time: 2.19420
Timestep Consumption Time: 2.45300
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.64720

Cumulative Model Updates: 93,272
Cumulative Timesteps: 777,984,356

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 777984356...
Checkpoint 777984356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,378.30996
Policy Entropy: 1.81067
Value Function Loss: 0.09081

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.59375
Value Function Update Magnitude: 0.54114

Collected Steps per Second: 22,268.84272
Overall Steps per Second: 10,632.24371

Timestep Collection Time: 2.24718
Timestep Consumption Time: 2.45945
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.70663

Cumulative Model Updates: 93,278
Cumulative Timesteps: 778,034,398

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,698.01011
Policy Entropy: 1.81097
Value Function Loss: 0.09210

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.59659
Value Function Update Magnitude: 0.51845

Collected Steps per Second: 22,472.68454
Overall Steps per Second: 10,512.41530

Timestep Collection Time: 2.22564
Timestep Consumption Time: 2.53217
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.75780

Cumulative Model Updates: 93,284
Cumulative Timesteps: 778,084,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 778084414...
Checkpoint 778084414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,670.03608
Policy Entropy: 1.80099
Value Function Loss: 0.08611

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.59138
Value Function Update Magnitude: 0.46029

Collected Steps per Second: 22,014.39941
Overall Steps per Second: 10,619.81188

Timestep Collection Time: 2.27215
Timestep Consumption Time: 2.43792
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.71006

Cumulative Model Updates: 93,290
Cumulative Timesteps: 778,134,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,732.38118
Policy Entropy: 1.80157
Value Function Loss: 0.08015

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.58127
Value Function Update Magnitude: 0.45228

Collected Steps per Second: 22,693.95525
Overall Steps per Second: 10,625.12738

Timestep Collection Time: 2.20393
Timestep Consumption Time: 2.50340
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.70733

Cumulative Model Updates: 93,296
Cumulative Timesteps: 778,184,450

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 778184450...
Checkpoint 778184450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,462.74043
Policy Entropy: 1.80731
Value Function Loss: 0.07867

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.57635
Value Function Update Magnitude: 0.43029

Collected Steps per Second: 21,933.27726
Overall Steps per Second: 10,469.35575

Timestep Collection Time: 2.28083
Timestep Consumption Time: 2.49750
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.77833

Cumulative Model Updates: 93,302
Cumulative Timesteps: 778,234,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,253.96197
Policy Entropy: 1.81341
Value Function Loss: 0.07953

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.56489
Value Function Update Magnitude: 0.42119

Collected Steps per Second: 22,531.61533
Overall Steps per Second: 10,576.89334

Timestep Collection Time: 2.22035
Timestep Consumption Time: 2.50959
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.72993

Cumulative Model Updates: 93,308
Cumulative Timesteps: 778,284,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 778284504...
Checkpoint 778284504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,257.21159
Policy Entropy: 1.80140
Value Function Loss: 0.07902

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.55337
Value Function Update Magnitude: 0.57046

Collected Steps per Second: 22,015.31580
Overall Steps per Second: 10,595.94308

Timestep Collection Time: 2.27142
Timestep Consumption Time: 2.44793
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.71935

Cumulative Model Updates: 93,314
Cumulative Timesteps: 778,334,510

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,836.15909
Policy Entropy: 1.80842
Value Function Loss: 0.08033

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.16884
Policy Update Magnitude: 0.50399
Value Function Update Magnitude: 0.59580

Collected Steps per Second: 22,602.93768
Overall Steps per Second: 10,628.69642

Timestep Collection Time: 2.21343
Timestep Consumption Time: 2.49364
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.70707

Cumulative Model Updates: 93,320
Cumulative Timesteps: 778,384,540

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 778384540...
Checkpoint 778384540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,441.97410
Policy Entropy: 1.79980
Value Function Loss: 0.08055

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.17255
Policy Update Magnitude: 0.45193
Value Function Update Magnitude: 0.52211

Collected Steps per Second: 21,878.34646
Overall Steps per Second: 10,420.13055

Timestep Collection Time: 2.28619
Timestep Consumption Time: 2.51394
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.80013

Cumulative Model Updates: 93,326
Cumulative Timesteps: 778,434,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,088.03273
Policy Entropy: 1.81421
Value Function Loss: 0.08392

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.14364
Policy Update Magnitude: 0.51641
Value Function Update Magnitude: 0.43488

Collected Steps per Second: 22,391.37925
Overall Steps per Second: 10,546.04351

Timestep Collection Time: 2.23416
Timestep Consumption Time: 2.50942
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.74358

Cumulative Model Updates: 93,332
Cumulative Timesteps: 778,484,584

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 778484584...
Checkpoint 778484584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,211.00840
Policy Entropy: 1.80820
Value Function Loss: 0.08011

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.14467
Policy Update Magnitude: 0.55113
Value Function Update Magnitude: 0.42434

Collected Steps per Second: 22,533.83870
Overall Steps per Second: 10,557.10447

Timestep Collection Time: 2.22057
Timestep Consumption Time: 2.51918
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.73975

Cumulative Model Updates: 93,338
Cumulative Timesteps: 778,534,622

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,481.99595
Policy Entropy: 1.80960
Value Function Loss: 0.07607

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.14300
Policy Update Magnitude: 0.55463
Value Function Update Magnitude: 0.51918

Collected Steps per Second: 22,576.39126
Overall Steps per Second: 10,593.71563

Timestep Collection Time: 2.21497
Timestep Consumption Time: 2.50538
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.72035

Cumulative Model Updates: 93,344
Cumulative Timesteps: 778,584,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 778584628...
Checkpoint 778584628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,141.07396
Policy Entropy: 1.80114
Value Function Loss: 0.07339

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.56186
Value Function Update Magnitude: 0.53654

Collected Steps per Second: 21,751.91292
Overall Steps per Second: 10,499.68034

Timestep Collection Time: 2.29883
Timestep Consumption Time: 2.46360
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.76243

Cumulative Model Updates: 93,350
Cumulative Timesteps: 778,634,632

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,412.16569
Policy Entropy: 1.79234
Value Function Loss: 0.08346

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.57434
Value Function Update Magnitude: 0.53199

Collected Steps per Second: 22,322.39820
Overall Steps per Second: 10,540.33332

Timestep Collection Time: 2.23990
Timestep Consumption Time: 2.50378
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.74368

Cumulative Model Updates: 93,356
Cumulative Timesteps: 778,684,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 778684632...
Checkpoint 778684632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,444.52887
Policy Entropy: 1.78384
Value Function Loss: 0.08848

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.58331
Value Function Update Magnitude: 0.50443

Collected Steps per Second: 21,649.62227
Overall Steps per Second: 10,517.50843

Timestep Collection Time: 2.31053
Timestep Consumption Time: 2.44554
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.75607

Cumulative Model Updates: 93,362
Cumulative Timesteps: 778,734,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,271.99280
Policy Entropy: 1.78971
Value Function Loss: 0.09126

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.58671
Value Function Update Magnitude: 0.66135

Collected Steps per Second: 21,981.18176
Overall Steps per Second: 10,632.78278

Timestep Collection Time: 2.27586
Timestep Consumption Time: 2.42903
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.70488

Cumulative Model Updates: 93,368
Cumulative Timesteps: 778,784,680

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 778784680...
Checkpoint 778784680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,010.85236
Policy Entropy: 1.79168
Value Function Loss: 0.08459

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.58223
Value Function Update Magnitude: 0.65001

Collected Steps per Second: 21,355.62039
Overall Steps per Second: 10,500.97427

Timestep Collection Time: 2.34233
Timestep Consumption Time: 2.42122
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.76356

Cumulative Model Updates: 93,374
Cumulative Timesteps: 778,834,702

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,563.14658
Policy Entropy: 1.79323
Value Function Loss: 0.08126

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.57534
Value Function Update Magnitude: 0.66700

Collected Steps per Second: 22,001.89533
Overall Steps per Second: 10,653.13716

Timestep Collection Time: 2.27317
Timestep Consumption Time: 2.42160
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.69477

Cumulative Model Updates: 93,380
Cumulative Timesteps: 778,884,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 778884716...
Checkpoint 778884716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,066.67851
Policy Entropy: 1.77794
Value Function Loss: 0.07467

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13899
Policy Update Magnitude: 0.56377
Value Function Update Magnitude: 0.64623

Collected Steps per Second: 21,961.85774
Overall Steps per Second: 10,800.69411

Timestep Collection Time: 2.27704
Timestep Consumption Time: 2.35303
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.63007

Cumulative Model Updates: 93,386
Cumulative Timesteps: 778,934,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,192.95793
Policy Entropy: 1.79467
Value Function Loss: 0.07543

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.15206
Policy Update Magnitude: 0.55768
Value Function Update Magnitude: 0.65252

Collected Steps per Second: 21,887.31960
Overall Steps per Second: 10,484.32478

Timestep Collection Time: 2.28498
Timestep Consumption Time: 2.48519
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.77017

Cumulative Model Updates: 93,392
Cumulative Timesteps: 778,984,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 778984736...
Checkpoint 778984736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,777.73596
Policy Entropy: 1.80302
Value Function Loss: 0.07872

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.15868
Policy Update Magnitude: 0.56908
Value Function Update Magnitude: 0.69567

Collected Steps per Second: 21,864.44325
Overall Steps per Second: 10,607.78826

Timestep Collection Time: 2.28746
Timestep Consumption Time: 2.42738
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.71484

Cumulative Model Updates: 93,398
Cumulative Timesteps: 779,034,750

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,923.11363
Policy Entropy: 1.80546
Value Function Loss: 0.07616

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.15759
Policy Update Magnitude: 0.56498
Value Function Update Magnitude: 0.72901

Collected Steps per Second: 22,372.84475
Overall Steps per Second: 10,575.21771

Timestep Collection Time: 2.23548
Timestep Consumption Time: 2.49388
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.72936

Cumulative Model Updates: 93,404
Cumulative Timesteps: 779,084,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 779084764...
Checkpoint 779084764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,822.54797
Policy Entropy: 1.80799
Value Function Loss: 0.07503

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.17634
Policy Update Magnitude: 0.50550
Value Function Update Magnitude: 0.72838

Collected Steps per Second: 22,505.17897
Overall Steps per Second: 10,620.24083

Timestep Collection Time: 2.22322
Timestep Consumption Time: 2.48797
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.71119

Cumulative Model Updates: 93,410
Cumulative Timesteps: 779,134,798

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,724.02109
Policy Entropy: 1.81557
Value Function Loss: 0.07560

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.15225
Policy Update Magnitude: 0.46848
Value Function Update Magnitude: 0.73671

Collected Steps per Second: 22,450.12753
Overall Steps per Second: 10,771.82660

Timestep Collection Time: 2.22743
Timestep Consumption Time: 2.41487
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.64230

Cumulative Model Updates: 93,416
Cumulative Timesteps: 779,184,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 779184804...
Checkpoint 779184804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,105.31523
Policy Entropy: 1.82293
Value Function Loss: 0.07454

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.49771
Value Function Update Magnitude: 0.68682

Collected Steps per Second: 21,894.51474
Overall Steps per Second: 10,626.88823

Timestep Collection Time: 2.28404
Timestep Consumption Time: 2.42176
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.70580

Cumulative Model Updates: 93,422
Cumulative Timesteps: 779,234,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,713.03443
Policy Entropy: 1.81696
Value Function Loss: 0.07504

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.52615
Value Function Update Magnitude: 0.63153

Collected Steps per Second: 22,191.08380
Overall Steps per Second: 10,548.13367

Timestep Collection Time: 2.25388
Timestep Consumption Time: 2.48781
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.74169

Cumulative Model Updates: 93,428
Cumulative Timesteps: 779,284,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 779284828...
Checkpoint 779284828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,719.31617
Policy Entropy: 1.79976
Value Function Loss: 0.07070

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.53032
Value Function Update Magnitude: 0.64682

Collected Steps per Second: 22,187.06380
Overall Steps per Second: 10,640.02532

Timestep Collection Time: 2.25456
Timestep Consumption Time: 2.44675
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.70130

Cumulative Model Updates: 93,434
Cumulative Timesteps: 779,334,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,686.48895
Policy Entropy: 1.79983
Value Function Loss: 0.07349

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.16130
Policy Update Magnitude: 0.50153
Value Function Update Magnitude: 0.65234

Collected Steps per Second: 22,254.61109
Overall Steps per Second: 10,477.94496

Timestep Collection Time: 2.24673
Timestep Consumption Time: 2.52520
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.77193

Cumulative Model Updates: 93,440
Cumulative Timesteps: 779,384,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 779384850...
Checkpoint 779384850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,101.79773
Policy Entropy: 1.79399
Value Function Loss: 0.07385

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.16497
Policy Update Magnitude: 0.51537
Value Function Update Magnitude: 0.65217

Collected Steps per Second: 21,943.49471
Overall Steps per Second: 10,593.37764

Timestep Collection Time: 2.27894
Timestep Consumption Time: 2.44174
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.72069

Cumulative Model Updates: 93,446
Cumulative Timesteps: 779,434,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,728.82136
Policy Entropy: 1.79250
Value Function Loss: 0.08116

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.17187
Policy Update Magnitude: 0.52084
Value Function Update Magnitude: 0.58900

Collected Steps per Second: 22,131.89856
Overall Steps per Second: 10,503.67647

Timestep Collection Time: 2.26000
Timestep Consumption Time: 2.50196
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.76195

Cumulative Model Updates: 93,452
Cumulative Timesteps: 779,484,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 779484876...
Checkpoint 779484876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,436.73301
Policy Entropy: 1.79091
Value Function Loss: 0.08323

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.16247
Policy Update Magnitude: 0.53204
Value Function Update Magnitude: 0.60550

Collected Steps per Second: 22,373.14850
Overall Steps per Second: 10,639.00305

Timestep Collection Time: 2.23607
Timestep Consumption Time: 2.46625
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.70232

Cumulative Model Updates: 93,458
Cumulative Timesteps: 779,534,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,313.57735
Policy Entropy: 1.77971
Value Function Loss: 0.08222

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.16921
Policy Update Magnitude: 0.52026
Value Function Update Magnitude: 0.65465

Collected Steps per Second: 22,400.20363
Overall Steps per Second: 10,498.29193

Timestep Collection Time: 2.23310
Timestep Consumption Time: 2.53167
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.76478

Cumulative Model Updates: 93,464
Cumulative Timesteps: 779,584,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 779584926...
Checkpoint 779584926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,955.17583
Policy Entropy: 1.78198
Value Function Loss: 0.07717

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.15917
Policy Update Magnitude: 0.46872
Value Function Update Magnitude: 0.71197

Collected Steps per Second: 21,961.81376
Overall Steps per Second: 10,560.52594

Timestep Collection Time: 2.27832
Timestep Consumption Time: 2.45970
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.73802

Cumulative Model Updates: 93,470
Cumulative Timesteps: 779,634,962

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,030.08443
Policy Entropy: 1.78088
Value Function Loss: 0.08017

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.51850
Value Function Update Magnitude: 0.64022

Collected Steps per Second: 22,252.65876
Overall Steps per Second: 10,509.06623

Timestep Collection Time: 2.24737
Timestep Consumption Time: 2.51138
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.75875

Cumulative Model Updates: 93,476
Cumulative Timesteps: 779,684,972

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 779684972...
Checkpoint 779684972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,311.71771
Policy Entropy: 1.78392
Value Function Loss: 0.08422

Mean KL Divergence: 0.02255
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.57511
Value Function Update Magnitude: 0.62435

Collected Steps per Second: 22,282.06508
Overall Steps per Second: 10,619.23707

Timestep Collection Time: 2.24521
Timestep Consumption Time: 2.46586
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.71107

Cumulative Model Updates: 93,482
Cumulative Timesteps: 779,735,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,830.04542
Policy Entropy: 1.77657
Value Function Loss: 0.08181

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.58727
Value Function Update Magnitude: 0.70630

Collected Steps per Second: 22,460.35325
Overall Steps per Second: 10,608.66983

Timestep Collection Time: 2.22641
Timestep Consumption Time: 2.48728
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.71369

Cumulative Model Updates: 93,488
Cumulative Timesteps: 779,785,006

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 779785006...
Checkpoint 779785006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,964.58684
Policy Entropy: 1.78231
Value Function Loss: 0.07798

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.56970
Value Function Update Magnitude: 0.75231

Collected Steps per Second: 21,469.68529
Overall Steps per Second: 10,481.76138

Timestep Collection Time: 2.32961
Timestep Consumption Time: 2.44211
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.77172

Cumulative Model Updates: 93,494
Cumulative Timesteps: 779,835,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,713.91940
Policy Entropy: 1.78744
Value Function Loss: 0.07675

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.16073
Policy Update Magnitude: 0.50987
Value Function Update Magnitude: 0.67427

Collected Steps per Second: 21,923.97928
Overall Steps per Second: 10,645.40961

Timestep Collection Time: 2.28179
Timestep Consumption Time: 2.41751
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.69930

Cumulative Model Updates: 93,500
Cumulative Timesteps: 779,885,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 779885048...
Checkpoint 779885048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,710.22191
Policy Entropy: 1.78870
Value Function Loss: 0.08103

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.50796
Value Function Update Magnitude: 0.54164

Collected Steps per Second: 21,386.82920
Overall Steps per Second: 10,485.07939

Timestep Collection Time: 2.33807
Timestep Consumption Time: 2.43099
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.76906

Cumulative Model Updates: 93,506
Cumulative Timesteps: 779,935,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,094.84762
Policy Entropy: 1.80214
Value Function Loss: 0.08746

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.15787
Policy Update Magnitude: 0.54508
Value Function Update Magnitude: 0.56425

Collected Steps per Second: 22,092.07791
Overall Steps per Second: 10,795.23068

Timestep Collection Time: 2.26434
Timestep Consumption Time: 2.36956
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.63390

Cumulative Model Updates: 93,512
Cumulative Timesteps: 779,985,076

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 779985076...
Checkpoint 779985076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,653.41585
Policy Entropy: 1.81589
Value Function Loss: 0.08792

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.17672
Policy Update Magnitude: 0.51653
Value Function Update Magnitude: 0.62735

Collected Steps per Second: 21,385.94043
Overall Steps per Second: 10,633.02368

Timestep Collection Time: 2.33929
Timestep Consumption Time: 2.36567
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.70496

Cumulative Model Updates: 93,518
Cumulative Timesteps: 780,035,104

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,379.10394
Policy Entropy: 1.80819
Value Function Loss: 0.08680

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.17251
Policy Update Magnitude: 0.52534
Value Function Update Magnitude: 0.55046

Collected Steps per Second: 21,795.82293
Overall Steps per Second: 10,565.37450

Timestep Collection Time: 2.29457
Timestep Consumption Time: 2.43901
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.73358

Cumulative Model Updates: 93,524
Cumulative Timesteps: 780,085,116

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 780085116...
Checkpoint 780085116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,109.35835
Policy Entropy: 1.80612
Value Function Loss: 0.08157

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.44490

Collected Steps per Second: 21,850.82814
Overall Steps per Second: 10,554.53226

Timestep Collection Time: 2.28888
Timestep Consumption Time: 2.44974
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.73863

Cumulative Model Updates: 93,530
Cumulative Timesteps: 780,135,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,545.87125
Policy Entropy: 1.79485
Value Function Loss: 0.08050

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13696
Policy Update Magnitude: 0.56736
Value Function Update Magnitude: 0.44056

Collected Steps per Second: 21,989.44633
Overall Steps per Second: 10,475.81067

Timestep Collection Time: 2.27546
Timestep Consumption Time: 2.50088
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.77634

Cumulative Model Updates: 93,536
Cumulative Timesteps: 780,185,166

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 780185166...
Checkpoint 780185166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,713.97379
Policy Entropy: 1.80224
Value Function Loss: 0.08308

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.57852
Value Function Update Magnitude: 0.56944

Collected Steps per Second: 21,846.50875
Overall Steps per Second: 10,636.49282

Timestep Collection Time: 2.28924
Timestep Consumption Time: 2.41268
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.70193

Cumulative Model Updates: 93,542
Cumulative Timesteps: 780,235,178

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,499.95033
Policy Entropy: 1.79869
Value Function Loss: 0.08612

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14671
Policy Update Magnitude: 0.56142
Value Function Update Magnitude: 0.58957

Collected Steps per Second: 22,629.73093
Overall Steps per Second: 10,696.26427

Timestep Collection Time: 2.21010
Timestep Consumption Time: 2.46574
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.67584

Cumulative Model Updates: 93,548
Cumulative Timesteps: 780,285,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 780285192...
Checkpoint 780285192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,237.00804
Policy Entropy: 1.80521
Value Function Loss: 0.08802

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.16262
Policy Update Magnitude: 0.48418
Value Function Update Magnitude: 0.57902

Collected Steps per Second: 22,044.59863
Overall Steps per Second: 10,568.43687

Timestep Collection Time: 2.26958
Timestep Consumption Time: 2.46452
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.73410

Cumulative Model Updates: 93,554
Cumulative Timesteps: 780,335,224

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,550.29625
Policy Entropy: 1.81438
Value Function Loss: 0.08672

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.15024
Policy Update Magnitude: 0.50873
Value Function Update Magnitude: 0.60018

Collected Steps per Second: 22,769.60293
Overall Steps per Second: 10,748.39297

Timestep Collection Time: 2.19626
Timestep Consumption Time: 2.45634
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.65260

Cumulative Model Updates: 93,560
Cumulative Timesteps: 780,385,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 780385232...
Checkpoint 780385232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,141.84386
Policy Entropy: 1.81215
Value Function Loss: 0.08179

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.16804
Policy Update Magnitude: 0.50083
Value Function Update Magnitude: 0.68100

Collected Steps per Second: 21,971.38667
Overall Steps per Second: 10,669.75410

Timestep Collection Time: 2.27587
Timestep Consumption Time: 2.41065
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.68652

Cumulative Model Updates: 93,566
Cumulative Timesteps: 780,435,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,270.14408
Policy Entropy: 1.80609
Value Function Loss: 0.08541

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.15509
Policy Update Magnitude: 0.50040
Value Function Update Magnitude: 0.54537

Collected Steps per Second: 22,809.90647
Overall Steps per Second: 10,809.37830

Timestep Collection Time: 2.19264
Timestep Consumption Time: 2.43426
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.62691

Cumulative Model Updates: 93,572
Cumulative Timesteps: 780,485,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 780485250...
Checkpoint 780485250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,699.69230
Policy Entropy: 1.79439
Value Function Loss: 0.08709

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.16005
Policy Update Magnitude: 0.52221
Value Function Update Magnitude: 0.39498

Collected Steps per Second: 22,097.92306
Overall Steps per Second: 10,606.25526

Timestep Collection Time: 2.26293
Timestep Consumption Time: 2.45184
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.71476

Cumulative Model Updates: 93,578
Cumulative Timesteps: 780,535,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,690.82200
Policy Entropy: 1.79943
Value Function Loss: 0.09219

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.14940
Policy Update Magnitude: 0.51663
Value Function Update Magnitude: 0.38516

Collected Steps per Second: 22,383.84804
Overall Steps per Second: 10,535.91553

Timestep Collection Time: 2.23420
Timestep Consumption Time: 2.51242
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.74662

Cumulative Model Updates: 93,584
Cumulative Timesteps: 780,585,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 780585266...
Checkpoint 780585266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,742.40371
Policy Entropy: 1.79099
Value Function Loss: 0.08366

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.15518
Policy Update Magnitude: 0.50982
Value Function Update Magnitude: 0.47351

Collected Steps per Second: 21,802.49440
Overall Steps per Second: 10,541.28173

Timestep Collection Time: 2.29451
Timestep Consumption Time: 2.45121
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.74572

Cumulative Model Updates: 93,590
Cumulative Timesteps: 780,635,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,555.53598
Policy Entropy: 1.79118
Value Function Loss: 0.08684

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.15714
Policy Update Magnitude: 0.45336
Value Function Update Magnitude: 0.45034

Collected Steps per Second: 22,517.67548
Overall Steps per Second: 10,549.07120

Timestep Collection Time: 2.22110
Timestep Consumption Time: 2.51998
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.74108

Cumulative Model Updates: 93,596
Cumulative Timesteps: 780,685,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 780685306...
Checkpoint 780685306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,209.40796
Policy Entropy: 1.77599
Value Function Loss: 0.07993

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.15259
Policy Update Magnitude: 0.47144
Value Function Update Magnitude: 0.52662

Collected Steps per Second: 22,040.13992
Overall Steps per Second: 10,629.57015

Timestep Collection Time: 2.26913
Timestep Consumption Time: 2.43586
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.70499

Cumulative Model Updates: 93,602
Cumulative Timesteps: 780,735,318

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,481.82804
Policy Entropy: 1.77868
Value Function Loss: 0.08189

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.52656
Value Function Update Magnitude: 0.60638

Collected Steps per Second: 22,382.17016
Overall Steps per Second: 10,536.77111

Timestep Collection Time: 2.23455
Timestep Consumption Time: 2.51207
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.74662

Cumulative Model Updates: 93,608
Cumulative Timesteps: 780,785,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 780785332...
Checkpoint 780785332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,492.89810
Policy Entropy: 1.78731
Value Function Loss: 0.07532

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.55355
Value Function Update Magnitude: 0.64476

Collected Steps per Second: 21,544.80443
Overall Steps per Second: 10,503.17645

Timestep Collection Time: 2.32158
Timestep Consumption Time: 2.44060
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.76218

Cumulative Model Updates: 93,614
Cumulative Timesteps: 780,835,350

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,775.75426
Policy Entropy: 1.78541
Value Function Loss: 0.07352

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.53973
Value Function Update Magnitude: 0.70193

Collected Steps per Second: 22,512.61331
Overall Steps per Second: 10,541.07181

Timestep Collection Time: 2.22107
Timestep Consumption Time: 2.52247
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.74354

Cumulative Model Updates: 93,620
Cumulative Timesteps: 780,885,352

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 780885352...
Checkpoint 780885352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,711.71953
Policy Entropy: 1.79447
Value Function Loss: 0.07271

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.65601

Collected Steps per Second: 21,754.06826
Overall Steps per Second: 10,554.66783

Timestep Collection Time: 2.29851
Timestep Consumption Time: 2.43892
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.73743

Cumulative Model Updates: 93,626
Cumulative Timesteps: 780,935,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,695.77818
Policy Entropy: 1.77763
Value Function Loss: 0.07880

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13659
Policy Update Magnitude: 0.56351
Value Function Update Magnitude: 0.51947

Collected Steps per Second: 22,299.05973
Overall Steps per Second: 10,521.79094

Timestep Collection Time: 2.24234
Timestep Consumption Time: 2.50990
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.75223

Cumulative Model Updates: 93,632
Cumulative Timesteps: 780,985,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 780985356...
Checkpoint 780985356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,596.81024
Policy Entropy: 1.78319
Value Function Loss: 0.08250

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.56681
Value Function Update Magnitude: 0.58197

Collected Steps per Second: 21,860.90327
Overall Steps per Second: 10,569.74409

Timestep Collection Time: 2.28719
Timestep Consumption Time: 2.44330
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.73048

Cumulative Model Updates: 93,638
Cumulative Timesteps: 781,035,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,307.99784
Policy Entropy: 1.76334
Value Function Loss: 0.08293

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.56457
Value Function Update Magnitude: 0.67684

Collected Steps per Second: 22,280.20315
Overall Steps per Second: 10,517.82775

Timestep Collection Time: 2.24495
Timestep Consumption Time: 2.51059
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.75554

Cumulative Model Updates: 93,644
Cumulative Timesteps: 781,085,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 781085374...
Checkpoint 781085374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,370.95061
Policy Entropy: 1.76794
Value Function Loss: 0.07591

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.15427
Policy Update Magnitude: 0.57041
Value Function Update Magnitude: 0.75526

Collected Steps per Second: 21,977.35190
Overall Steps per Second: 10,601.08598

Timestep Collection Time: 2.27625
Timestep Consumption Time: 2.44270
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.71895

Cumulative Model Updates: 93,650
Cumulative Timesteps: 781,135,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,023.51479
Policy Entropy: 1.74168
Value Function Loss: 0.07442

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.17620
Policy Update Magnitude: 0.52061
Value Function Update Magnitude: 0.73020

Collected Steps per Second: 21,658.27677
Overall Steps per Second: 10,494.56586

Timestep Collection Time: 2.30933
Timestep Consumption Time: 2.45657
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.76590

Cumulative Model Updates: 93,656
Cumulative Timesteps: 781,185,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 781185416...
Checkpoint 781185416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,404.04134
Policy Entropy: 1.76719
Value Function Loss: 0.07934

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.18736
Policy Update Magnitude: 0.46817
Value Function Update Magnitude: 0.64043

Collected Steps per Second: 21,248.51865
Overall Steps per Second: 10,598.54697

Timestep Collection Time: 2.35461
Timestep Consumption Time: 2.36604
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.72065

Cumulative Model Updates: 93,662
Cumulative Timesteps: 781,235,448

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,121.66961
Policy Entropy: 1.76277
Value Function Loss: 0.08655

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.16301
Policy Update Magnitude: 0.52809
Value Function Update Magnitude: 0.61764

Collected Steps per Second: 21,984.03232
Overall Steps per Second: 10,633.71832

Timestep Collection Time: 2.27447
Timestep Consumption Time: 2.42774
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.70221

Cumulative Model Updates: 93,668
Cumulative Timesteps: 781,285,450

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 781285450...
Checkpoint 781285450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,689.95702
Policy Entropy: 1.79077
Value Function Loss: 0.09022

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.16879
Policy Update Magnitude: 0.52888
Value Function Update Magnitude: 0.60356

Collected Steps per Second: 21,532.45859
Overall Steps per Second: 10,513.73372

Timestep Collection Time: 2.32291
Timestep Consumption Time: 2.43448
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.75740

Cumulative Model Updates: 93,674
Cumulative Timesteps: 781,335,468

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,327.88454
Policy Entropy: 1.80009
Value Function Loss: 0.08916

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.16062
Policy Update Magnitude: 0.55909
Value Function Update Magnitude: 0.62889

Collected Steps per Second: 21,729.02198
Overall Steps per Second: 10,553.19410

Timestep Collection Time: 2.30135
Timestep Consumption Time: 2.43712
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.73847

Cumulative Model Updates: 93,680
Cumulative Timesteps: 781,385,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 781385474...
Checkpoint 781385474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,686.73937
Policy Entropy: 1.80184
Value Function Loss: 0.07965

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.15745
Policy Update Magnitude: 0.58595
Value Function Update Magnitude: 0.62968

Collected Steps per Second: 21,122.47029
Overall Steps per Second: 10,571.76261

Timestep Collection Time: 2.36762
Timestep Consumption Time: 2.36291
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.73053

Cumulative Model Updates: 93,686
Cumulative Timesteps: 781,435,484

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,259.08318
Policy Entropy: 1.79668
Value Function Loss: 0.08458

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.15626
Policy Update Magnitude: 0.59542
Value Function Update Magnitude: 0.63981

Collected Steps per Second: 21,602.40697
Overall Steps per Second: 10,504.99164

Timestep Collection Time: 2.31558
Timestep Consumption Time: 2.44616
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.76174

Cumulative Model Updates: 93,692
Cumulative Timesteps: 781,485,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 781485506...
Checkpoint 781485506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,922.28233
Policy Entropy: 1.79303
Value Function Loss: 0.08394

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.14847
Policy Update Magnitude: 0.61820
Value Function Update Magnitude: 0.66994

Collected Steps per Second: 21,559.50136
Overall Steps per Second: 10,556.35206

Timestep Collection Time: 2.31916
Timestep Consumption Time: 2.41732
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.73648

Cumulative Model Updates: 93,698
Cumulative Timesteps: 781,535,506

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,171.31937
Policy Entropy: 1.80484
Value Function Loss: 0.08957

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.15579
Policy Update Magnitude: 0.60358
Value Function Update Magnitude: 0.61806

Collected Steps per Second: 21,935.70686
Overall Steps per Second: 10,445.17942

Timestep Collection Time: 2.28048
Timestep Consumption Time: 2.50871
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.78919

Cumulative Model Updates: 93,704
Cumulative Timesteps: 781,585,530

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 781585530...
Checkpoint 781585530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,606.06034
Policy Entropy: 1.79309
Value Function Loss: 0.08409

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.15396
Policy Update Magnitude: 0.58390
Value Function Update Magnitude: 0.56860

Collected Steps per Second: 21,600.20519
Overall Steps per Second: 10,555.26597

Timestep Collection Time: 2.31507
Timestep Consumption Time: 2.42247
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.73754

Cumulative Model Updates: 93,710
Cumulative Timesteps: 781,635,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,537.28189
Policy Entropy: 1.79006
Value Function Loss: 0.08639

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.14723
Policy Update Magnitude: 0.57948
Value Function Update Magnitude: 0.55067

Collected Steps per Second: 22,368.22322
Overall Steps per Second: 10,548.38306

Timestep Collection Time: 2.23612
Timestep Consumption Time: 2.50565
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.74177

Cumulative Model Updates: 93,716
Cumulative Timesteps: 781,685,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 781685554...
Checkpoint 781685554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,589.01020
Policy Entropy: 1.77982
Value Function Loss: 0.08245

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.58537
Value Function Update Magnitude: 0.60485

Collected Steps per Second: 22,168.38560
Overall Steps per Second: 10,674.72581

Timestep Collection Time: 2.25646
Timestep Consumption Time: 2.42957
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.68602

Cumulative Model Updates: 93,722
Cumulative Timesteps: 781,735,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,189.94765
Policy Entropy: 1.78594
Value Function Loss: 0.08631

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13895
Policy Update Magnitude: 0.58958
Value Function Update Magnitude: 0.59962

Collected Steps per Second: 22,642.45254
Overall Steps per Second: 10,608.88622

Timestep Collection Time: 2.20868
Timestep Consumption Time: 2.50529
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.71397

Cumulative Model Updates: 93,728
Cumulative Timesteps: 781,785,586

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 781785586...
Checkpoint 781785586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,731.89314
Policy Entropy: 1.79361
Value Function Loss: 0.09193

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.60098
Value Function Update Magnitude: 0.53373

Collected Steps per Second: 22,279.87530
Overall Steps per Second: 10,515.78376

Timestep Collection Time: 2.24454
Timestep Consumption Time: 2.51098
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.75552

Cumulative Model Updates: 93,734
Cumulative Timesteps: 781,835,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,953.62396
Policy Entropy: 1.77835
Value Function Loss: 0.09455

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14492
Policy Update Magnitude: 0.60427
Value Function Update Magnitude: 0.44627

Collected Steps per Second: 22,219.20224
Overall Steps per Second: 10,581.43274

Timestep Collection Time: 2.25094
Timestep Consumption Time: 2.47565
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.72658

Cumulative Model Updates: 93,740
Cumulative Timesteps: 781,885,608

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 781885608...
Checkpoint 781885608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,978.62038
Policy Entropy: 1.78443
Value Function Loss: 0.09384

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.17002
Policy Update Magnitude: 0.51237
Value Function Update Magnitude: 0.45122

Collected Steps per Second: 21,984.43372
Overall Steps per Second: 10,419.92181

Timestep Collection Time: 2.27570
Timestep Consumption Time: 2.52568
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.80138

Cumulative Model Updates: 93,746
Cumulative Timesteps: 781,935,638

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,124.41620
Policy Entropy: 1.77134
Value Function Loss: 0.09165

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.15743
Policy Update Magnitude: 0.50186
Value Function Update Magnitude: 0.44745

Collected Steps per Second: 22,415.79595
Overall Steps per Second: 10,496.66883

Timestep Collection Time: 2.23209
Timestep Consumption Time: 2.53457
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.76666

Cumulative Model Updates: 93,752
Cumulative Timesteps: 781,985,672

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 781985672...
Checkpoint 781985672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,970.35118
Policy Entropy: 1.77455
Value Function Loss: 0.09360

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.15523
Policy Update Magnitude: 0.50220
Value Function Update Magnitude: 0.42250

Collected Steps per Second: 22,352.07495
Overall Steps per Second: 10,597.20376

Timestep Collection Time: 2.23729
Timestep Consumption Time: 2.48169
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.71898

Cumulative Model Updates: 93,758
Cumulative Timesteps: 782,035,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,032.61078
Policy Entropy: 1.76558
Value Function Loss: 0.09672

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.16234
Policy Update Magnitude: 0.46929
Value Function Update Magnitude: 0.36024

Collected Steps per Second: 22,438.75383
Overall Steps per Second: 10,519.19719

Timestep Collection Time: 2.22847
Timestep Consumption Time: 2.52513
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.75359

Cumulative Model Updates: 93,764
Cumulative Timesteps: 782,085,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 782085684...
Checkpoint 782085684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,226.05911
Policy Entropy: 1.76915
Value Function Loss: 0.08684

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.14648
Policy Update Magnitude: 0.46383
Value Function Update Magnitude: 0.42654

Collected Steps per Second: 22,171.21013
Overall Steps per Second: 10,668.91144

Timestep Collection Time: 2.25572
Timestep Consumption Time: 2.43192
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.68764

Cumulative Model Updates: 93,770
Cumulative Timesteps: 782,135,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,906.44132
Policy Entropy: 1.77845
Value Function Loss: 0.09322

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.15291
Policy Update Magnitude: 0.48497
Value Function Update Magnitude: 0.45822

Collected Steps per Second: 22,645.40956
Overall Steps per Second: 10,769.40907

Timestep Collection Time: 2.20892
Timestep Consumption Time: 2.43590
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.64482

Cumulative Model Updates: 93,776
Cumulative Timesteps: 782,185,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 782185718...
Checkpoint 782185718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,295.45398
Policy Entropy: 1.77208
Value Function Loss: 0.09195

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.56725
Value Function Update Magnitude: 0.44569

Collected Steps per Second: 21,782.08309
Overall Steps per Second: 10,450.67059

Timestep Collection Time: 2.29611
Timestep Consumption Time: 2.48961
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.78572

Cumulative Model Updates: 93,782
Cumulative Timesteps: 782,235,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,233.68096
Policy Entropy: 1.76604
Value Function Loss: 0.09433

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.60629
Value Function Update Magnitude: 0.54402

Collected Steps per Second: 22,531.40091
Overall Steps per Second: 10,736.37325

Timestep Collection Time: 2.22019
Timestep Consumption Time: 2.43911
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.65930

Cumulative Model Updates: 93,788
Cumulative Timesteps: 782,285,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 782285756...
Checkpoint 782285756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,027.84005
Policy Entropy: 1.75899
Value Function Loss: 0.08297

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.58942
Value Function Update Magnitude: 0.69018

Collected Steps per Second: 21,719.91156
Overall Steps per Second: 10,544.89522

Timestep Collection Time: 2.30231
Timestep Consumption Time: 2.43989
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.74220

Cumulative Model Updates: 93,794
Cumulative Timesteps: 782,335,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,428.28315
Policy Entropy: 1.76638
Value Function Loss: 0.08049

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.56715
Value Function Update Magnitude: 0.72153

Collected Steps per Second: 22,490.77765
Overall Steps per Second: 10,547.70477

Timestep Collection Time: 2.22438
Timestep Consumption Time: 2.51864
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.74302

Cumulative Model Updates: 93,800
Cumulative Timesteps: 782,385,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 782385790...
Checkpoint 782385790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,367.12291
Policy Entropy: 1.77254
Value Function Loss: 0.08029

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.14633
Policy Update Magnitude: 0.58210
Value Function Update Magnitude: 0.59789

Collected Steps per Second: 21,500.20943
Overall Steps per Second: 10,372.97943

Timestep Collection Time: 2.32705
Timestep Consumption Time: 2.49625
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.82330

Cumulative Model Updates: 93,806
Cumulative Timesteps: 782,435,822

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,137.41223
Policy Entropy: 1.78949
Value Function Loss: 0.08418

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.14305
Policy Update Magnitude: 0.58537
Value Function Update Magnitude: 0.51694

Collected Steps per Second: 22,622.93304
Overall Steps per Second: 10,725.26736

Timestep Collection Time: 2.21068
Timestep Consumption Time: 2.45233
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.66301

Cumulative Model Updates: 93,812
Cumulative Timesteps: 782,485,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 782485834...
Checkpoint 782485834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,942.51652
Policy Entropy: 1.78954
Value Function Loss: 0.08321

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.58563
Value Function Update Magnitude: 0.51521

Collected Steps per Second: 21,919.81355
Overall Steps per Second: 10,593.53687

Timestep Collection Time: 2.28214
Timestep Consumption Time: 2.43999
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.72212

Cumulative Model Updates: 93,818
Cumulative Timesteps: 782,535,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,094.81744
Policy Entropy: 1.78058
Value Function Loss: 0.08675

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.14283
Policy Update Magnitude: 0.58129
Value Function Update Magnitude: 0.42149

Collected Steps per Second: 22,391.52658
Overall Steps per Second: 10,526.96258

Timestep Collection Time: 2.23415
Timestep Consumption Time: 2.51803
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.75218

Cumulative Model Updates: 93,824
Cumulative Timesteps: 782,585,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 782585884...
Checkpoint 782585884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,998.99076
Policy Entropy: 1.78174
Value Function Loss: 0.08722

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.56903
Value Function Update Magnitude: 0.40444

Collected Steps per Second: 22,246.95490
Overall Steps per Second: 10,559.37686

Timestep Collection Time: 2.24750
Timestep Consumption Time: 2.48763
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.73513

Cumulative Model Updates: 93,830
Cumulative Timesteps: 782,635,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,493.70990
Policy Entropy: 1.77531
Value Function Loss: 0.08701

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.57546
Value Function Update Magnitude: 0.40511

Collected Steps per Second: 22,691.64121
Overall Steps per Second: 10,632.99195

Timestep Collection Time: 2.20381
Timestep Consumption Time: 2.49929
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.70310

Cumulative Model Updates: 93,836
Cumulative Timesteps: 782,685,892

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 782685892...
Checkpoint 782685892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,529.94252
Policy Entropy: 1.78690
Value Function Loss: 0.08331

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.58396
Value Function Update Magnitude: 0.41519

Collected Steps per Second: 22,166.22854
Overall Steps per Second: 10,502.37251

Timestep Collection Time: 2.25641
Timestep Consumption Time: 2.50595
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.76235

Cumulative Model Updates: 93,842
Cumulative Timesteps: 782,735,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,533.90658
Policy Entropy: 1.78065
Value Function Loss: 0.08713

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.16517
Policy Update Magnitude: 0.53509
Value Function Update Magnitude: 0.41575

Collected Steps per Second: 21,871.89864
Overall Steps per Second: 10,620.82063

Timestep Collection Time: 2.28650
Timestep Consumption Time: 2.42218
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.70868

Cumulative Model Updates: 93,848
Cumulative Timesteps: 782,785,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 782785918...
Checkpoint 782785918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,853.20712
Policy Entropy: 1.79315
Value Function Loss: 0.08769

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.16095
Policy Update Magnitude: 0.52641
Value Function Update Magnitude: 0.47049

Collected Steps per Second: 21,521.83213
Overall Steps per Second: 10,518.10833

Timestep Collection Time: 2.32359
Timestep Consumption Time: 2.43087
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.75447

Cumulative Model Updates: 93,854
Cumulative Timesteps: 782,835,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,170.33867
Policy Entropy: 1.77781
Value Function Loss: 0.09136

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.15472
Policy Update Magnitude: 0.56266
Value Function Update Magnitude: 0.48318

Collected Steps per Second: 21,955.96939
Overall Steps per Second: 10,792.65918

Timestep Collection Time: 2.27847
Timestep Consumption Time: 2.35672
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.63519

Cumulative Model Updates: 93,860
Cumulative Timesteps: 782,885,952

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 782885952...
Checkpoint 782885952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,605.92312
Policy Entropy: 1.76049
Value Function Loss: 0.08276

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.14986
Policy Update Magnitude: 0.58913
Value Function Update Magnitude: 0.56156

Collected Steps per Second: 21,299.97110
Overall Steps per Second: 10,610.93178

Timestep Collection Time: 2.34817
Timestep Consumption Time: 2.36546
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.71363

Cumulative Model Updates: 93,866
Cumulative Timesteps: 782,935,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,474.66494
Policy Entropy: 1.74805
Value Function Loss: 0.07636

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14233
Policy Update Magnitude: 0.58455
Value Function Update Magnitude: 0.64082

Collected Steps per Second: 21,814.38656
Overall Steps per Second: 10,473.45228

Timestep Collection Time: 2.29243
Timestep Consumption Time: 2.48231
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.77474

Cumulative Model Updates: 93,872
Cumulative Timesteps: 782,985,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 782985976...
Checkpoint 782985976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,343.20796
Policy Entropy: 1.76000
Value Function Loss: 0.07440

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.57289
Value Function Update Magnitude: 0.62657

Collected Steps per Second: 22,066.80656
Overall Steps per Second: 10,699.74387

Timestep Collection Time: 2.26648
Timestep Consumption Time: 2.40784
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.67432

Cumulative Model Updates: 93,878
Cumulative Timesteps: 783,035,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,660.04929
Policy Entropy: 1.76654
Value Function Loss: 0.07907

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.13932
Policy Update Magnitude: 0.56631
Value Function Update Magnitude: 0.49894

Collected Steps per Second: 22,483.83365
Overall Steps per Second: 10,649.91261

Timestep Collection Time: 2.22391
Timestep Consumption Time: 2.47115
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.69506

Cumulative Model Updates: 93,884
Cumulative Timesteps: 783,085,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 783085992...
Checkpoint 783085992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,424.26070
Policy Entropy: 1.77359
Value Function Loss: 0.08150

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14870
Policy Update Magnitude: 0.55203
Value Function Update Magnitude: 0.50412

Collected Steps per Second: 21,896.33409
Overall Steps per Second: 10,493.38727

Timestep Collection Time: 2.28404
Timestep Consumption Time: 2.48201
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.76605

Cumulative Model Updates: 93,890
Cumulative Timesteps: 783,136,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,545.52646
Policy Entropy: 1.77144
Value Function Loss: 0.08581

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.15996
Policy Update Magnitude: 0.52110
Value Function Update Magnitude: 0.43550

Collected Steps per Second: 22,372.99988
Overall Steps per Second: 10,552.29738

Timestep Collection Time: 2.23546
Timestep Consumption Time: 2.50417
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.73963

Cumulative Model Updates: 93,896
Cumulative Timesteps: 783,186,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 783186018...
Checkpoint 783186018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,973.57069
Policy Entropy: 1.77632
Value Function Loss: 0.08674

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.16512
Policy Update Magnitude: 0.47867
Value Function Update Magnitude: 0.39940

Collected Steps per Second: 22,405.00012
Overall Steps per Second: 10,652.11769

Timestep Collection Time: 2.23272
Timestep Consumption Time: 2.46344
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.69616

Cumulative Model Updates: 93,902
Cumulative Timesteps: 783,236,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,080.00135
Policy Entropy: 1.78580
Value Function Loss: 0.08917

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.15274
Policy Update Magnitude: 0.47021
Value Function Update Magnitude: 0.44017

Collected Steps per Second: 22,690.06124
Overall Steps per Second: 10,721.45137

Timestep Collection Time: 2.20484
Timestep Consumption Time: 2.46132
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.66616

Cumulative Model Updates: 93,908
Cumulative Timesteps: 783,286,070

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 783286070...
Checkpoint 783286070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,136.94564
Policy Entropy: 1.78529
Value Function Loss: 0.08486

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.52505
Value Function Update Magnitude: 0.42674

Collected Steps per Second: 21,626.64274
Overall Steps per Second: 10,551.00375

Timestep Collection Time: 2.31326
Timestep Consumption Time: 2.42828
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.74154

Cumulative Model Updates: 93,914
Cumulative Timesteps: 783,336,098

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,314.09118
Policy Entropy: 1.77929
Value Function Loss: 0.08871

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.14957
Policy Update Magnitude: 0.54961
Value Function Update Magnitude: 0.42218

Collected Steps per Second: 22,503.44505
Overall Steps per Second: 10,521.69677

Timestep Collection Time: 2.22268
Timestep Consumption Time: 2.53111
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.75380

Cumulative Model Updates: 93,920
Cumulative Timesteps: 783,386,116

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 783386116...
Checkpoint 783386116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,900.58291
Policy Entropy: 1.78446
Value Function Loss: 0.08821

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.56590
Value Function Update Magnitude: 0.43038

Collected Steps per Second: 22,389.54176
Overall Steps per Second: 10,685.48749

Timestep Collection Time: 2.23319
Timestep Consumption Time: 2.44606
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.67924

Cumulative Model Updates: 93,926
Cumulative Timesteps: 783,436,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,344.81380
Policy Entropy: 1.79562
Value Function Loss: 0.08719

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.57584
Value Function Update Magnitude: 0.44078

Collected Steps per Second: 22,499.85719
Overall Steps per Second: 10,594.42847

Timestep Collection Time: 2.22330
Timestep Consumption Time: 2.49842
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.72173

Cumulative Model Updates: 93,932
Cumulative Timesteps: 783,486,140

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 783486140...
Checkpoint 783486140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,812.36155
Policy Entropy: 1.81052
Value Function Loss: 0.08789

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.57432
Value Function Update Magnitude: 0.44137

Collected Steps per Second: 22,097.65488
Overall Steps per Second: 10,469.28941

Timestep Collection Time: 2.26341
Timestep Consumption Time: 2.51399
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.77740

Cumulative Model Updates: 93,938
Cumulative Timesteps: 783,536,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,470.11757
Policy Entropy: 1.83035
Value Function Loss: 0.08288

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.57308
Value Function Update Magnitude: 0.64761

Collected Steps per Second: 22,595.67870
Overall Steps per Second: 10,611.74480

Timestep Collection Time: 2.21432
Timestep Consumption Time: 2.50065
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.71496

Cumulative Model Updates: 93,944
Cumulative Timesteps: 783,586,190

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 783586190...
Checkpoint 783586190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,914.06195
Policy Entropy: 1.81787
Value Function Loss: 0.08061

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.14079
Policy Update Magnitude: 0.56271
Value Function Update Magnitude: 0.69498

Collected Steps per Second: 22,103.40977
Overall Steps per Second: 10,483.10304

Timestep Collection Time: 2.26390
Timestep Consumption Time: 2.50949
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.77340

Cumulative Model Updates: 93,950
Cumulative Timesteps: 783,636,230

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,055.48729
Policy Entropy: 1.82614
Value Function Loss: 0.07451

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.54041
Value Function Update Magnitude: 0.68527

Collected Steps per Second: 22,393.16506
Overall Steps per Second: 10,514.66672

Timestep Collection Time: 2.23309
Timestep Consumption Time: 2.52274
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.75583

Cumulative Model Updates: 93,956
Cumulative Timesteps: 783,686,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 783686236...
Checkpoint 783686236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,063.51136
Policy Entropy: 1.82063
Value Function Loss: 0.07873

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13530
Policy Update Magnitude: 0.56164
Value Function Update Magnitude: 0.69953

Collected Steps per Second: 21,922.94850
Overall Steps per Second: 10,660.98672

Timestep Collection Time: 2.28099
Timestep Consumption Time: 2.40957
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.69056

Cumulative Model Updates: 93,962
Cumulative Timesteps: 783,736,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,169.27342
Policy Entropy: 1.84022
Value Function Loss: 0.07540

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.14982
Policy Update Magnitude: 0.56300
Value Function Update Magnitude: 0.70539

Collected Steps per Second: 22,595.29095
Overall Steps per Second: 10,733.35911

Timestep Collection Time: 2.21436
Timestep Consumption Time: 2.44719
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.66154

Cumulative Model Updates: 93,968
Cumulative Timesteps: 783,786,276

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 783786276...
Checkpoint 783786276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,510.14204
Policy Entropy: 1.82512
Value Function Loss: 0.07330

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.15298
Policy Update Magnitude: 0.55086
Value Function Update Magnitude: 0.64496

Collected Steps per Second: 22,096.18766
Overall Steps per Second: 10,633.28685

Timestep Collection Time: 2.26292
Timestep Consumption Time: 2.43948
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.70240

Cumulative Model Updates: 93,974
Cumulative Timesteps: 783,836,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,863.00737
Policy Entropy: 1.82790
Value Function Loss: 0.07278

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.14854
Policy Update Magnitude: 0.54724
Value Function Update Magnitude: 0.65103

Collected Steps per Second: 22,647.62310
Overall Steps per Second: 10,546.62415

Timestep Collection Time: 2.20774
Timestep Consumption Time: 2.53312
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.74085

Cumulative Model Updates: 93,980
Cumulative Timesteps: 783,886,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 783886278...
Checkpoint 783886278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,439.39666
Policy Entropy: 1.82191
Value Function Loss: 0.07428

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.15123
Policy Update Magnitude: 0.53714
Value Function Update Magnitude: 0.69756

Collected Steps per Second: 21,901.35351
Overall Steps per Second: 10,578.06744

Timestep Collection Time: 2.28333
Timestep Consumption Time: 2.44419
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.72752

Cumulative Model Updates: 93,986
Cumulative Timesteps: 783,936,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,175.26315
Policy Entropy: 1.84143
Value Function Loss: 0.07775

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14858
Policy Update Magnitude: 0.54597
Value Function Update Magnitude: 0.66337

Collected Steps per Second: 22,708.71124
Overall Steps per Second: 10,593.30019

Timestep Collection Time: 2.20312
Timestep Consumption Time: 2.51968
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.72280

Cumulative Model Updates: 93,992
Cumulative Timesteps: 783,986,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 783986316...
Checkpoint 783986316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,775.39204
Policy Entropy: 1.83751
Value Function Loss: 0.07581

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.55383
Value Function Update Magnitude: 0.62348

Collected Steps per Second: 22,095.33153
Overall Steps per Second: 10,628.44890

Timestep Collection Time: 2.26365
Timestep Consumption Time: 2.44222
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.70586

Cumulative Model Updates: 93,998
Cumulative Timesteps: 784,036,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,799.49239
Policy Entropy: 1.83724
Value Function Loss: 0.07982

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.14229
Policy Update Magnitude: 0.56282
Value Function Update Magnitude: 0.57863

Collected Steps per Second: 22,646.33679
Overall Steps per Second: 10,767.36542

Timestep Collection Time: 2.20848
Timestep Consumption Time: 2.43648
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.64496

Cumulative Model Updates: 94,004
Cumulative Timesteps: 784,086,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 784086346...
Checkpoint 784086346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,049.17152
Policy Entropy: 1.84277
Value Function Loss: 0.08127

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.57672
Value Function Update Magnitude: 0.50183

Collected Steps per Second: 21,849.89166
Overall Steps per Second: 10,446.57379

Timestep Collection Time: 2.28843
Timestep Consumption Time: 2.49802
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.78645

Cumulative Model Updates: 94,010
Cumulative Timesteps: 784,136,348

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,150.76331
Policy Entropy: 1.85322
Value Function Loss: 0.08521

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.57582
Value Function Update Magnitude: 0.51877

Collected Steps per Second: 22,771.18181
Overall Steps per Second: 10,725.18044

Timestep Collection Time: 2.19664
Timestep Consumption Time: 2.46715
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.66379

Cumulative Model Updates: 94,016
Cumulative Timesteps: 784,186,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 784186368...
Checkpoint 784186368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,558.03931
Policy Entropy: 1.85494
Value Function Loss: 0.08370

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.57563
Value Function Update Magnitude: 0.63818

Collected Steps per Second: 22,166.04527
Overall Steps per Second: 10,649.77149

Timestep Collection Time: 2.25624
Timestep Consumption Time: 2.43982
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.69606

Cumulative Model Updates: 94,022
Cumulative Timesteps: 784,236,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,328.23167
Policy Entropy: 1.85928
Value Function Loss: 0.08174

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.57307
Value Function Update Magnitude: 0.66771

Collected Steps per Second: 22,358.71175
Overall Steps per Second: 10,517.02311

Timestep Collection Time: 2.23662
Timestep Consumption Time: 2.51834
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.75496

Cumulative Model Updates: 94,028
Cumulative Timesteps: 784,286,388

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 784286388...
Checkpoint 784286388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,140.96379
Policy Entropy: 1.85759
Value Function Loss: 0.07892

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.57119
Value Function Update Magnitude: 0.69815

Collected Steps per Second: 21,591.30593
Overall Steps per Second: 10,497.98083

Timestep Collection Time: 2.31602
Timestep Consumption Time: 2.44737
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.76339

Cumulative Model Updates: 94,034
Cumulative Timesteps: 784,336,394

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,077.37706
Policy Entropy: 1.86882
Value Function Loss: 0.07785

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.57202
Value Function Update Magnitude: 0.76724

Collected Steps per Second: 22,442.61114
Overall Steps per Second: 10,514.58314

Timestep Collection Time: 2.22817
Timestep Consumption Time: 2.52770
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.75587

Cumulative Model Updates: 94,040
Cumulative Timesteps: 784,386,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 784386400...
Checkpoint 784386400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,672.68829
Policy Entropy: 1.86998
Value Function Loss: 0.07481

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.57408
Value Function Update Magnitude: 0.75215

Collected Steps per Second: 22,079.40196
Overall Steps per Second: 10,586.20659

Timestep Collection Time: 2.26501
Timestep Consumption Time: 2.45906
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.72407

Cumulative Model Updates: 94,046
Cumulative Timesteps: 784,436,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,592.43313
Policy Entropy: 1.87124
Value Function Loss: 0.07579

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.57162
Value Function Update Magnitude: 0.74513

Collected Steps per Second: 22,569.56694
Overall Steps per Second: 10,524.87214

Timestep Collection Time: 2.21661
Timestep Consumption Time: 2.53670
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.75331

Cumulative Model Updates: 94,052
Cumulative Timesteps: 784,486,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 784486438...
Checkpoint 784486438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,551.90355
Policy Entropy: 1.88711
Value Function Loss: 0.08252

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13364
Policy Update Magnitude: 0.57356
Value Function Update Magnitude: 0.66424

Collected Steps per Second: 21,820.35029
Overall Steps per Second: 10,547.43330

Timestep Collection Time: 2.29236
Timestep Consumption Time: 2.45003
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.74239

Cumulative Model Updates: 94,058
Cumulative Timesteps: 784,536,458

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,233.84872
Policy Entropy: 1.89881
Value Function Loss: 0.08437

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13739
Policy Update Magnitude: 0.56914
Value Function Update Magnitude: 0.71605

Collected Steps per Second: 22,567.13294
Overall Steps per Second: 10,567.02603

Timestep Collection Time: 2.21694
Timestep Consumption Time: 2.51760
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.73454

Cumulative Model Updates: 94,064
Cumulative Timesteps: 784,586,488

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 784586488...
Checkpoint 784586488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,051.89420
Policy Entropy: 1.90435
Value Function Loss: 0.08197

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13596
Policy Update Magnitude: 0.53371
Value Function Update Magnitude: 0.69740

Collected Steps per Second: 22,024.81915
Overall Steps per Second: 10,627.02936

Timestep Collection Time: 2.27153
Timestep Consumption Time: 2.43628
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.70781

Cumulative Model Updates: 94,070
Cumulative Timesteps: 784,636,518

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,933.63657
Policy Entropy: 1.88027
Value Function Loss: 0.07845

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13916
Policy Update Magnitude: 0.53199
Value Function Update Magnitude: 0.63145

Collected Steps per Second: 22,832.19759
Overall Steps per Second: 10,810.77950

Timestep Collection Time: 2.19085
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.62705

Cumulative Model Updates: 94,076
Cumulative Timesteps: 784,686,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 784686540...
Checkpoint 784686540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,173.56185
Policy Entropy: 1.86382
Value Function Loss: 0.07437

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.14472
Policy Update Magnitude: 0.52602
Value Function Update Magnitude: 0.57498

Collected Steps per Second: 21,678.21802
Overall Steps per Second: 10,410.00041

Timestep Collection Time: 2.30655
Timestep Consumption Time: 2.49671
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.80327

Cumulative Model Updates: 94,082
Cumulative Timesteps: 784,736,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,694.20402
Policy Entropy: 1.86619
Value Function Loss: 0.07481

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13628
Policy Update Magnitude: 0.52865
Value Function Update Magnitude: 0.60165

Collected Steps per Second: 22,550.73871
Overall Steps per Second: 10,728.19869

Timestep Collection Time: 2.21775
Timestep Consumption Time: 2.44398
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.66173

Cumulative Model Updates: 94,088
Cumulative Timesteps: 784,786,554

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 784786554...
Checkpoint 784786554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,498.77023
Policy Entropy: 1.88404
Value Function Loss: 0.06549

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.54259
Value Function Update Magnitude: 0.67324

Collected Steps per Second: 22,281.83781
Overall Steps per Second: 10,641.36879

Timestep Collection Time: 2.24524
Timestep Consumption Time: 2.45604
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.70127

Cumulative Model Updates: 94,094
Cumulative Timesteps: 784,836,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,388.43478
Policy Entropy: 1.88198
Value Function Loss: 0.06791

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12319
Policy Update Magnitude: 0.54002
Value Function Update Magnitude: 0.66896

Collected Steps per Second: 22,547.65711
Overall Steps per Second: 10,566.97121

Timestep Collection Time: 2.21788
Timestep Consumption Time: 2.51460
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.73248

Cumulative Model Updates: 94,100
Cumulative Timesteps: 784,886,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 784886590...
Checkpoint 784886590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,119.82542
Policy Entropy: 1.88352
Value Function Loss: 0.06939

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.54168
Value Function Update Magnitude: 0.67935

Collected Steps per Second: 22,161.74869
Overall Steps per Second: 10,540.64552

Timestep Collection Time: 2.25722
Timestep Consumption Time: 2.48860
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.74582

Cumulative Model Updates: 94,106
Cumulative Timesteps: 784,936,614

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,577.38557
Policy Entropy: 1.87115
Value Function Loss: 0.07352

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13442
Policy Update Magnitude: 0.52882
Value Function Update Magnitude: 0.72782

Collected Steps per Second: 22,549.71925
Overall Steps per Second: 10,548.70292

Timestep Collection Time: 2.21865
Timestep Consumption Time: 2.52411
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.74276

Cumulative Model Updates: 94,112
Cumulative Timesteps: 784,986,644

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 784986644...
Checkpoint 784986644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,538.52853
Policy Entropy: 1.87028
Value Function Loss: 0.07698

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.15120
Policy Update Magnitude: 0.49162
Value Function Update Magnitude: 0.71591

Collected Steps per Second: 21,955.86547
Overall Steps per Second: 10,614.68832

Timestep Collection Time: 2.27830
Timestep Consumption Time: 2.43423
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.71253

Cumulative Model Updates: 94,118
Cumulative Timesteps: 785,036,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,898.75635
Policy Entropy: 1.88030
Value Function Loss: 0.07491

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.14655
Policy Update Magnitude: 0.48994
Value Function Update Magnitude: 0.68144

Collected Steps per Second: 22,569.64619
Overall Steps per Second: 10,765.81839

Timestep Collection Time: 2.21590
Timestep Consumption Time: 2.42955
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.64544

Cumulative Model Updates: 94,124
Cumulative Timesteps: 785,086,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 785086678...
Checkpoint 785086678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,966.73128
Policy Entropy: 1.89243
Value Function Loss: 0.07572

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14524
Policy Update Magnitude: 0.51867
Value Function Update Magnitude: 0.66875

Collected Steps per Second: 21,994.37837
Overall Steps per Second: 10,610.04716

Timestep Collection Time: 2.27340
Timestep Consumption Time: 2.43930
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.71270

Cumulative Model Updates: 94,130
Cumulative Timesteps: 785,136,680

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,830.15581
Policy Entropy: 1.89025
Value Function Loss: 0.07557

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.53949
Value Function Update Magnitude: 0.69065

Collected Steps per Second: 22,428.89443
Overall Steps per Second: 10,587.73736

Timestep Collection Time: 2.22945
Timestep Consumption Time: 2.49338
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.72282

Cumulative Model Updates: 94,136
Cumulative Timesteps: 785,186,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 785186684...
Checkpoint 785186684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,323.09220
Policy Entropy: 1.90045
Value Function Loss: 0.08032

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.55858
Value Function Update Magnitude: 0.70023

Collected Steps per Second: 21,898.19855
Overall Steps per Second: 10,583.81742

Timestep Collection Time: 2.28375
Timestep Consumption Time: 2.44139
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.72514

Cumulative Model Updates: 94,142
Cumulative Timesteps: 785,236,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,706.73877
Policy Entropy: 1.89905
Value Function Loss: 0.07711

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.55746
Value Function Update Magnitude: 0.71057

Collected Steps per Second: 22,632.88810
Overall Steps per Second: 10,624.65975

Timestep Collection Time: 2.20926
Timestep Consumption Time: 2.49696
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.70622

Cumulative Model Updates: 94,148
Cumulative Timesteps: 785,286,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 785286696...
Checkpoint 785286696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,012.02176
Policy Entropy: 1.89874
Value Function Loss: 0.07628

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.53285
Value Function Update Magnitude: 0.69763

Collected Steps per Second: 22,422.42228
Overall Steps per Second: 10,547.17809

Timestep Collection Time: 2.23062
Timestep Consumption Time: 2.51150
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.74212

Cumulative Model Updates: 94,154
Cumulative Timesteps: 785,336,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,858.44572
Policy Entropy: 1.89249
Value Function Loss: 0.07194

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.14944
Policy Update Magnitude: 0.49242
Value Function Update Magnitude: 0.71733

Collected Steps per Second: 22,574.30257
Overall Steps per Second: 10,736.64691

Timestep Collection Time: 2.21615
Timestep Consumption Time: 2.44341
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.65956

Cumulative Model Updates: 94,160
Cumulative Timesteps: 785,386,740

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 785386740...
Checkpoint 785386740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,343.68010
Policy Entropy: 1.88753
Value Function Loss: 0.07365

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.14579
Policy Update Magnitude: 0.52570
Value Function Update Magnitude: 0.73004

Collected Steps per Second: 21,826.52615
Overall Steps per Second: 10,445.35378

Timestep Collection Time: 2.29207
Timestep Consumption Time: 2.49742
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.78950

Cumulative Model Updates: 94,166
Cumulative Timesteps: 785,436,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,391.68946
Policy Entropy: 1.88408
Value Function Loss: 0.07622

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.15704
Policy Update Magnitude: 0.52373
Value Function Update Magnitude: 0.68553

Collected Steps per Second: 22,641.50192
Overall Steps per Second: 10,753.45888

Timestep Collection Time: 2.20922
Timestep Consumption Time: 2.44231
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.65153

Cumulative Model Updates: 94,172
Cumulative Timesteps: 785,486,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 785486788...
Checkpoint 785486788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,279.88508
Policy Entropy: 1.88050
Value Function Loss: 0.07847

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.15320
Policy Update Magnitude: 0.49289
Value Function Update Magnitude: 0.67579

Collected Steps per Second: 22,201.46040
Overall Steps per Second: 10,667.36280

Timestep Collection Time: 2.25210
Timestep Consumption Time: 2.43509
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.68719

Cumulative Model Updates: 94,178
Cumulative Timesteps: 785,536,788

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,204.23855
Policy Entropy: 1.89320
Value Function Loss: 0.07546

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.15563
Policy Update Magnitude: 0.49928
Value Function Update Magnitude: 0.71094

Collected Steps per Second: 22,061.15325
Overall Steps per Second: 10,436.34076

Timestep Collection Time: 2.26770
Timestep Consumption Time: 2.52594
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.79363

Cumulative Model Updates: 94,184
Cumulative Timesteps: 785,586,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 785586816...
Checkpoint 785586816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,369.02513
Policy Entropy: 1.89735
Value Function Loss: 0.07226

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.15575
Policy Update Magnitude: 0.51161
Value Function Update Magnitude: 0.67953

Collected Steps per Second: 21,965.20284
Overall Steps per Second: 10,566.65197

Timestep Collection Time: 2.27733
Timestep Consumption Time: 2.45662
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.73395

Cumulative Model Updates: 94,190
Cumulative Timesteps: 785,636,838

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,209.13412
Policy Entropy: 1.88622
Value Function Loss: 0.07125

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.51565
Value Function Update Magnitude: 0.67873

Collected Steps per Second: 22,313.65054
Overall Steps per Second: 10,510.59682

Timestep Collection Time: 2.24132
Timestep Consumption Time: 2.51693
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.75825

Cumulative Model Updates: 94,196
Cumulative Timesteps: 785,686,850

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 785686850...
Checkpoint 785686850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,342.60145
Policy Entropy: 1.87554
Value Function Loss: 0.07291

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.53813
Value Function Update Magnitude: 0.67773

Collected Steps per Second: 22,066.44415
Overall Steps per Second: 10,651.91650

Timestep Collection Time: 2.26697
Timestep Consumption Time: 2.42927
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.69624

Cumulative Model Updates: 94,202
Cumulative Timesteps: 785,736,874

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,825.87216
Policy Entropy: 1.88018
Value Function Loss: 0.07794

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.54835
Value Function Update Magnitude: 0.65081

Collected Steps per Second: 22,366.44920
Overall Steps per Second: 10,608.72406

Timestep Collection Time: 2.23647
Timestep Consumption Time: 2.47870
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.71518

Cumulative Model Updates: 94,208
Cumulative Timesteps: 785,786,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 785786896...
Checkpoint 785786896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,346.80530
Policy Entropy: 1.89418
Value Function Loss: 0.07967

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.16259
Policy Update Magnitude: 0.51110
Value Function Update Magnitude: 0.57312

Collected Steps per Second: 22,058.36476
Overall Steps per Second: 10,513.00705

Timestep Collection Time: 2.26789
Timestep Consumption Time: 2.49059
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.75849

Cumulative Model Updates: 94,214
Cumulative Timesteps: 785,836,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,347.36679
Policy Entropy: 1.90791
Value Function Loss: 0.08050

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.51446
Value Function Update Magnitude: 0.63999

Collected Steps per Second: 22,746.81403
Overall Steps per Second: 10,801.23471

Timestep Collection Time: 2.19837
Timestep Consumption Time: 2.43128
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.62966

Cumulative Model Updates: 94,220
Cumulative Timesteps: 785,886,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 785886928...
Checkpoint 785886928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,537.18280
Policy Entropy: 1.90482
Value Function Loss: 0.08155

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.69050

Collected Steps per Second: 21,873.72233
Overall Steps per Second: 10,652.54438

Timestep Collection Time: 2.28640
Timestep Consumption Time: 2.40844
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.69484

Cumulative Model Updates: 94,226
Cumulative Timesteps: 785,936,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,436.95967
Policy Entropy: 1.89644
Value Function Loss: 0.08007

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.54459
Value Function Update Magnitude: 0.66861

Collected Steps per Second: 22,726.49389
Overall Steps per Second: 10,577.81203

Timestep Collection Time: 2.20025
Timestep Consumption Time: 2.52700
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.72725

Cumulative Model Updates: 94,232
Cumulative Timesteps: 785,986,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 785986944...
Checkpoint 785986944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,342.19578
Policy Entropy: 1.89178
Value Function Loss: 0.07572

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.54733
Value Function Update Magnitude: 0.66625

Collected Steps per Second: 22,314.68263
Overall Steps per Second: 10,566.84101

Timestep Collection Time: 2.24077
Timestep Consumption Time: 2.49121
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.73197

Cumulative Model Updates: 94,238
Cumulative Timesteps: 786,036,946

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,625.52646
Policy Entropy: 1.88816
Value Function Loss: 0.07373

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12675
Policy Update Magnitude: 0.55082
Value Function Update Magnitude: 0.71261

Collected Steps per Second: 22,466.20769
Overall Steps per Second: 10,546.93173

Timestep Collection Time: 2.22574
Timestep Consumption Time: 2.51535
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.74109

Cumulative Model Updates: 94,244
Cumulative Timesteps: 786,086,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 786086950...
Checkpoint 786086950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,259.05332
Policy Entropy: 1.88328
Value Function Loss: 0.07549

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.55359
Value Function Update Magnitude: 0.70782

Collected Steps per Second: 22,297.46602
Overall Steps per Second: 10,537.66920

Timestep Collection Time: 2.24420
Timestep Consumption Time: 2.50448
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.74868

Cumulative Model Updates: 94,250
Cumulative Timesteps: 786,136,990

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,529.27195
Policy Entropy: 1.89048
Value Function Loss: 0.07585

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.55465
Value Function Update Magnitude: 0.70617

Collected Steps per Second: 22,554.81481
Overall Steps per Second: 10,511.57097

Timestep Collection Time: 2.21771
Timestep Consumption Time: 2.54086
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.75857

Cumulative Model Updates: 94,256
Cumulative Timesteps: 786,187,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 786187010...
Checkpoint 786187010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,622.61531
Policy Entropy: 1.87068
Value Function Loss: 0.07351

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.55829
Value Function Update Magnitude: 0.71262

Collected Steps per Second: 21,631.24837
Overall Steps per Second: 10,485.61027

Timestep Collection Time: 2.31203
Timestep Consumption Time: 2.45756
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.76958

Cumulative Model Updates: 94,262
Cumulative Timesteps: 786,237,022

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,042.97895
Policy Entropy: 1.86618
Value Function Loss: 0.07272

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.12012
Policy Update Magnitude: 0.56191
Value Function Update Magnitude: 0.72411

Collected Steps per Second: 22,520.52309
Overall Steps per Second: 10,559.90104

Timestep Collection Time: 2.22135
Timestep Consumption Time: 2.51600
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.73736

Cumulative Model Updates: 94,268
Cumulative Timesteps: 786,287,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 786287048...
Checkpoint 786287048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,880.93597
Policy Entropy: 1.86116
Value Function Loss: 0.07265

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.56491
Value Function Update Magnitude: 0.69719

Collected Steps per Second: 22,175.61063
Overall Steps per Second: 10,687.48015

Timestep Collection Time: 2.25509
Timestep Consumption Time: 2.42403
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.67912

Cumulative Model Updates: 94,274
Cumulative Timesteps: 786,337,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,483.73474
Policy Entropy: 1.87771
Value Function Loss: 0.07415

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.55950
Value Function Update Magnitude: 0.66087

Collected Steps per Second: 22,596.77437
Overall Steps per Second: 10,750.26265

Timestep Collection Time: 2.21386
Timestep Consumption Time: 2.43961
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.65347

Cumulative Model Updates: 94,280
Cumulative Timesteps: 786,387,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 786387082...
Checkpoint 786387082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,818.70626
Policy Entropy: 1.87231
Value Function Loss: 0.07640

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.55796
Value Function Update Magnitude: 0.60411

Collected Steps per Second: 21,795.87921
Overall Steps per Second: 10,436.18154

Timestep Collection Time: 2.29566
Timestep Consumption Time: 2.49881
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.79447

Cumulative Model Updates: 94,286
Cumulative Timesteps: 786,437,118

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,480.96300
Policy Entropy: 1.87132
Value Function Loss: 0.07366

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.56296
Value Function Update Magnitude: 0.54366

Collected Steps per Second: 22,303.49433
Overall Steps per Second: 10,687.72060

Timestep Collection Time: 2.24207
Timestep Consumption Time: 2.43676
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.67883

Cumulative Model Updates: 94,292
Cumulative Timesteps: 786,487,124

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 786487124...
Checkpoint 786487124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,775.32794
Policy Entropy: 1.87200
Value Function Loss: 0.07839

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.57180
Value Function Update Magnitude: 0.61721

Collected Steps per Second: 22,120.02728
Overall Steps per Second: 10,648.41911

Timestep Collection Time: 2.26130
Timestep Consumption Time: 2.43611
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.69741

Cumulative Model Updates: 94,298
Cumulative Timesteps: 786,537,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,557.58313
Policy Entropy: 1.87895
Value Function Loss: 0.08053

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.57044
Value Function Update Magnitude: 0.61020

Collected Steps per Second: 22,216.78650
Overall Steps per Second: 10,499.96947

Timestep Collection Time: 2.25136
Timestep Consumption Time: 2.51227
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.76363

Cumulative Model Updates: 94,304
Cumulative Timesteps: 786,587,162

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 786587162...
Checkpoint 786587162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,701.96508
Policy Entropy: 1.88498
Value Function Loss: 0.08783

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.58713
Value Function Update Magnitude: 0.64347

Collected Steps per Second: 22,142.18807
Overall Steps per Second: 10,656.76320

Timestep Collection Time: 2.25867
Timestep Consumption Time: 2.43431
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.69298

Cumulative Model Updates: 94,310
Cumulative Timesteps: 786,637,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,993.21895
Policy Entropy: 1.87573
Value Function Loss: 0.08263

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.58531
Value Function Update Magnitude: 0.71997

Collected Steps per Second: 22,136.39051
Overall Steps per Second: 10,823.69805

Timestep Collection Time: 2.25936
Timestep Consumption Time: 2.36143
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.62079

Cumulative Model Updates: 94,316
Cumulative Timesteps: 786,687,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 786687188...
Checkpoint 786687188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,739.61061
Policy Entropy: 1.88066
Value Function Loss: 0.07934

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.55685
Value Function Update Magnitude: 0.73286

Collected Steps per Second: 21,299.38148
Overall Steps per Second: 10,644.69560

Timestep Collection Time: 2.34880
Timestep Consumption Time: 2.35101
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.69981

Cumulative Model Updates: 94,322
Cumulative Timesteps: 786,737,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,309.55916
Policy Entropy: 1.86439
Value Function Loss: 0.07655

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.16389
Policy Update Magnitude: 0.50720
Value Function Update Magnitude: 0.72545

Collected Steps per Second: 22,035.19799
Overall Steps per Second: 10,610.15565

Timestep Collection Time: 2.26991
Timestep Consumption Time: 2.44425
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.71416

Cumulative Model Updates: 94,328
Cumulative Timesteps: 786,787,234

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 786787234...
Checkpoint 786787234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,866.92406
Policy Entropy: 1.87359
Value Function Loss: 0.07445

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.15992
Policy Update Magnitude: 0.50545
Value Function Update Magnitude: 0.71412

Collected Steps per Second: 20,895.95786
Overall Steps per Second: 10,506.54406

Timestep Collection Time: 2.39300
Timestep Consumption Time: 2.36632
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.75932

Cumulative Model Updates: 94,334
Cumulative Timesteps: 786,837,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,458.60673
Policy Entropy: 1.86274
Value Function Loss: 0.06982

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.54775
Value Function Update Magnitude: 0.69649

Collected Steps per Second: 21,853.06725
Overall Steps per Second: 10,561.77315

Timestep Collection Time: 2.28966
Timestep Consumption Time: 2.44781
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.73746

Cumulative Model Updates: 94,340
Cumulative Timesteps: 786,887,274

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 786887274...
Checkpoint 786887274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,056.22683
Policy Entropy: 1.84424
Value Function Loss: 0.06906

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13780
Policy Update Magnitude: 0.55075
Value Function Update Magnitude: 0.69321

Collected Steps per Second: 21,465.70711
Overall Steps per Second: 10,536.94148

Timestep Collection Time: 2.33051
Timestep Consumption Time: 2.41717
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.74768

Cumulative Model Updates: 94,346
Cumulative Timesteps: 786,937,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,896.16512
Policy Entropy: 1.84684
Value Function Loss: 0.07516

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13646
Policy Update Magnitude: 0.56336
Value Function Update Magnitude: 0.68004

Collected Steps per Second: 22,616.57377
Overall Steps per Second: 10,672.37454

Timestep Collection Time: 2.21103
Timestep Consumption Time: 2.47452
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.68556

Cumulative Model Updates: 94,352
Cumulative Timesteps: 786,987,306

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 786987306...
Checkpoint 786987306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,848.86788
Policy Entropy: 1.84800
Value Function Loss: 0.07990

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.57749
Value Function Update Magnitude: 0.62466

Collected Steps per Second: 22,255.67981
Overall Steps per Second: 10,588.44513

Timestep Collection Time: 2.24868
Timestep Consumption Time: 2.47779
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.72647

Cumulative Model Updates: 94,358
Cumulative Timesteps: 787,037,352

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,096.66316
Policy Entropy: 1.86522
Value Function Loss: 0.08417

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.58814
Value Function Update Magnitude: 0.63104

Collected Steps per Second: 22,690.02511
Overall Steps per Second: 10,833.81015

Timestep Collection Time: 2.20502
Timestep Consumption Time: 2.41311
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.61814

Cumulative Model Updates: 94,364
Cumulative Timesteps: 787,087,384

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 787087384...
Checkpoint 787087384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,340.52404
Policy Entropy: 1.84347
Value Function Loss: 0.07583

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.14616
Policy Update Magnitude: 0.58273
Value Function Update Magnitude: 0.70555

Collected Steps per Second: 21,619.28319
Overall Steps per Second: 10,552.47970

Timestep Collection Time: 2.31432
Timestep Consumption Time: 2.42712
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.74144

Cumulative Model Updates: 94,370
Cumulative Timesteps: 787,137,418

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,131.87350
Policy Entropy: 1.84738
Value Function Loss: 0.07682

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.15426
Policy Update Magnitude: 0.56383
Value Function Update Magnitude: 0.72617

Collected Steps per Second: 22,430.81182
Overall Steps per Second: 10,594.65870

Timestep Collection Time: 2.22908
Timestep Consumption Time: 2.49028
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.71936

Cumulative Model Updates: 94,376
Cumulative Timesteps: 787,187,418

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 787187418...
Checkpoint 787187418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,330.07425
Policy Entropy: 1.84475
Value Function Loss: 0.07217

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.16427
Policy Update Magnitude: 0.50749
Value Function Update Magnitude: 0.64672

Collected Steps per Second: 22,351.55624
Overall Steps per Second: 10,534.96493

Timestep Collection Time: 2.23743
Timestep Consumption Time: 2.50962
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.74705

Cumulative Model Updates: 94,382
Cumulative Timesteps: 787,237,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,984.64874
Policy Entropy: 1.86599
Value Function Loss: 0.07136

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.48715
Value Function Update Magnitude: 0.57416

Collected Steps per Second: 22,667.18476
Overall Steps per Second: 10,611.54152

Timestep Collection Time: 2.20707
Timestep Consumption Time: 2.50742
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.71449

Cumulative Model Updates: 94,388
Cumulative Timesteps: 787,287,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 787287456...
Checkpoint 787287456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,997.23565
Policy Entropy: 1.86461
Value Function Loss: 0.07060

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.50696
Value Function Update Magnitude: 0.56795

Collected Steps per Second: 21,787.65126
Overall Steps per Second: 10,474.11584

Timestep Collection Time: 2.29543
Timestep Consumption Time: 2.47939
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.77482

Cumulative Model Updates: 94,394
Cumulative Timesteps: 787,337,468

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,909.07237
Policy Entropy: 1.88430
Value Function Loss: 0.07597

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.54536
Value Function Update Magnitude: 0.56768

Collected Steps per Second: 22,274.18572
Overall Steps per Second: 10,478.73536

Timestep Collection Time: 2.24538
Timestep Consumption Time: 2.52752
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.77290

Cumulative Model Updates: 94,400
Cumulative Timesteps: 787,387,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 787387482...
Checkpoint 787387482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,794.32163
Policy Entropy: 1.87812
Value Function Loss: 0.07859

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14298
Policy Update Magnitude: 0.54637
Value Function Update Magnitude: 0.63162

Collected Steps per Second: 22,036.88876
Overall Steps per Second: 10,511.86073

Timestep Collection Time: 2.26920
Timestep Consumption Time: 2.48791
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.75710

Cumulative Model Updates: 94,406
Cumulative Timesteps: 787,437,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,904.49172
Policy Entropy: 1.88569
Value Function Loss: 0.08128

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.15976
Policy Update Magnitude: 0.51968
Value Function Update Magnitude: 0.60536

Collected Steps per Second: 21,410.28151
Overall Steps per Second: 10,314.24599

Timestep Collection Time: 2.33673
Timestep Consumption Time: 2.51384
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.85057

Cumulative Model Updates: 94,412
Cumulative Timesteps: 787,487,518

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 787487518...
Checkpoint 787487518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,877.23686
Policy Entropy: 1.87207
Value Function Loss: 0.07895

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.49579
Value Function Update Magnitude: 0.65482

Collected Steps per Second: 21,699.15595
Overall Steps per Second: 10,451.52136

Timestep Collection Time: 2.30451
Timestep Consumption Time: 2.48005
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.78457

Cumulative Model Updates: 94,418
Cumulative Timesteps: 787,537,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,779.84383
Policy Entropy: 1.87966
Value Function Loss: 0.07461

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.66134

Collected Steps per Second: 22,492.77920
Overall Steps per Second: 10,578.75743

Timestep Collection Time: 2.22489
Timestep Consumption Time: 2.50572
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.73061

Cumulative Model Updates: 94,424
Cumulative Timesteps: 787,587,568

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 787587568...
Checkpoint 787587568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,711.73553
Policy Entropy: 1.87647
Value Function Loss: 0.08132

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12491
Policy Update Magnitude: 0.57050
Value Function Update Magnitude: 0.57809

Collected Steps per Second: 22,124.73670
Overall Steps per Second: 10,499.56687

Timestep Collection Time: 2.25991
Timestep Consumption Time: 2.50219
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.76210

Cumulative Model Updates: 94,430
Cumulative Timesteps: 787,637,568

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,920.25311
Policy Entropy: 1.88000
Value Function Loss: 0.08159

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13646
Policy Update Magnitude: 0.56985
Value Function Update Magnitude: 0.53702

Collected Steps per Second: 22,662.45760
Overall Steps per Second: 10,575.96965

Timestep Collection Time: 2.20638
Timestep Consumption Time: 2.52151
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.72789

Cumulative Model Updates: 94,436
Cumulative Timesteps: 787,687,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 787687570...
Checkpoint 787687570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,810.77183
Policy Entropy: 1.84953
Value Function Loss: 0.07946

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.53179
Value Function Update Magnitude: 0.47259

Collected Steps per Second: 22,262.70445
Overall Steps per Second: 10,524.87167

Timestep Collection Time: 2.24609
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.75103

Cumulative Model Updates: 94,442
Cumulative Timesteps: 787,737,574

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,105.41195
Policy Entropy: 1.86106
Value Function Loss: 0.08220

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.15117
Policy Update Magnitude: 0.49073
Value Function Update Magnitude: 0.50349

Collected Steps per Second: 22,270.23132
Overall Steps per Second: 10,456.61259

Timestep Collection Time: 2.24578
Timestep Consumption Time: 2.53722
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.78300

Cumulative Model Updates: 94,448
Cumulative Timesteps: 787,787,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 787787588...
Checkpoint 787787588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,368.18273
Policy Entropy: 1.85277
Value Function Loss: 0.08786

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.15845
Policy Update Magnitude: 0.53352
Value Function Update Magnitude: 0.58548

Collected Steps per Second: 21,761.76575
Overall Steps per Second: 10,534.25338

Timestep Collection Time: 2.29816
Timestep Consumption Time: 2.44940
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.74756

Cumulative Model Updates: 94,454
Cumulative Timesteps: 787,837,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,911.48427
Policy Entropy: 1.85680
Value Function Loss: 0.09480

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.15947
Policy Update Magnitude: 0.56055
Value Function Update Magnitude: 0.57223

Collected Steps per Second: 22,455.01152
Overall Steps per Second: 10,585.92169

Timestep Collection Time: 2.22730
Timestep Consumption Time: 2.49728
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.72458

Cumulative Model Updates: 94,460
Cumulative Timesteps: 787,887,614

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 787887614...
Checkpoint 787887614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,477.76872
Policy Entropy: 1.84910
Value Function Loss: 0.08731

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.15832
Policy Update Magnitude: 0.55220
Value Function Update Magnitude: 0.55849

Collected Steps per Second: 22,189.26083
Overall Steps per Second: 10,657.06225

Timestep Collection Time: 2.25361
Timestep Consumption Time: 2.43867
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.69229

Cumulative Model Updates: 94,466
Cumulative Timesteps: 787,937,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,708.99994
Policy Entropy: 1.84228
Value Function Loss: 0.07583

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.14833
Policy Update Magnitude: 0.56442
Value Function Update Magnitude: 0.61939

Collected Steps per Second: 22,506.38493
Overall Steps per Second: 10,589.81631

Timestep Collection Time: 2.22230
Timestep Consumption Time: 2.50073
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.72303

Cumulative Model Updates: 94,472
Cumulative Timesteps: 787,987,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 787987636...
Checkpoint 787987636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,555.05590
Policy Entropy: 1.85815
Value Function Loss: 0.07844

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.15086
Policy Update Magnitude: 0.56004
Value Function Update Magnitude: 0.56960

Collected Steps per Second: 22,064.70611
Overall Steps per Second: 10,488.41198

Timestep Collection Time: 2.26679
Timestep Consumption Time: 2.50190
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.76869

Cumulative Model Updates: 94,478
Cumulative Timesteps: 788,037,652

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,716.56732
Policy Entropy: 1.85438
Value Function Loss: 0.07971

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.15414
Policy Update Magnitude: 0.56494
Value Function Update Magnitude: 0.46754

Collected Steps per Second: 22,435.97090
Overall Steps per Second: 10,544.41492

Timestep Collection Time: 2.22954
Timestep Consumption Time: 2.51439
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.74393

Cumulative Model Updates: 94,484
Cumulative Timesteps: 788,087,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 788087674...
Checkpoint 788087674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,299.13500
Policy Entropy: 1.85014
Value Function Loss: 0.08100

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.15301
Policy Update Magnitude: 0.57965
Value Function Update Magnitude: 0.59566

Collected Steps per Second: 22,342.10770
Overall Steps per Second: 10,547.45153

Timestep Collection Time: 2.23882
Timestep Consumption Time: 2.50356
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.74238

Cumulative Model Updates: 94,490
Cumulative Timesteps: 788,137,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,711.47909
Policy Entropy: 1.84191
Value Function Loss: 0.07300

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.58077
Value Function Update Magnitude: 0.70214

Collected Steps per Second: 22,772.80799
Overall Steps per Second: 10,799.50461

Timestep Collection Time: 2.19560
Timestep Consumption Time: 2.43424
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.62984

Cumulative Model Updates: 94,496
Cumulative Timesteps: 788,187,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 788187694...
Checkpoint 788187694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,683.28231
Policy Entropy: 1.83713
Value Function Loss: 0.07364

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.13665
Policy Update Magnitude: 0.58213
Value Function Update Magnitude: 0.69543

Collected Steps per Second: 21,921.99192
Overall Steps per Second: 10,456.76078

Timestep Collection Time: 2.28100
Timestep Consumption Time: 2.50098
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.78198

Cumulative Model Updates: 94,502
Cumulative Timesteps: 788,237,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,478.62829
Policy Entropy: 1.85016
Value Function Loss: 0.07805

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.58940
Value Function Update Magnitude: 0.68283

Collected Steps per Second: 22,664.16436
Overall Steps per Second: 10,746.67396

Timestep Collection Time: 2.20613
Timestep Consumption Time: 2.44648
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.65260

Cumulative Model Updates: 94,508
Cumulative Timesteps: 788,287,698

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 788287698...
Checkpoint 788287698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,815.29524
Policy Entropy: 1.85837
Value Function Loss: 0.07387

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.58715
Value Function Update Magnitude: 0.73691

Collected Steps per Second: 21,449.75248
Overall Steps per Second: 10,669.43249

Timestep Collection Time: 2.33345
Timestep Consumption Time: 2.35771
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.69116

Cumulative Model Updates: 94,514
Cumulative Timesteps: 788,337,750

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,977.31806
Policy Entropy: 1.87444
Value Function Loss: 0.06923

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.56969
Value Function Update Magnitude: 0.65635

Collected Steps per Second: 21,857.52516
Overall Steps per Second: 10,605.21975

Timestep Collection Time: 2.28818
Timestep Consumption Time: 2.42780
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.71598

Cumulative Model Updates: 94,520
Cumulative Timesteps: 788,387,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 788387764...
Checkpoint 788387764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,434.35539
Policy Entropy: 1.86241
Value Function Loss: 0.07724

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12598
Policy Update Magnitude: 0.57509
Value Function Update Magnitude: 0.56162

Collected Steps per Second: 21,271.33919
Overall Steps per Second: 10,449.35136

Timestep Collection Time: 2.35086
Timestep Consumption Time: 2.43470
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.78556

Cumulative Model Updates: 94,526
Cumulative Timesteps: 788,437,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,735.29423
Policy Entropy: 1.87426
Value Function Loss: 0.08486

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.58110
Value Function Update Magnitude: 0.55457

Collected Steps per Second: 21,872.09417
Overall Steps per Second: 10,623.40901

Timestep Collection Time: 2.28657
Timestep Consumption Time: 2.42115
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.70772

Cumulative Model Updates: 94,532
Cumulative Timesteps: 788,487,782

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 788487782...
Checkpoint 788487782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,374.06611
Policy Entropy: 1.85714
Value Function Loss: 0.08132

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.57981
Value Function Update Magnitude: 0.56363

Collected Steps per Second: 21,643.22554
Overall Steps per Second: 10,573.69604

Timestep Collection Time: 2.31139
Timestep Consumption Time: 2.41978
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.73117

Cumulative Model Updates: 94,538
Cumulative Timesteps: 788,537,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,523.83506
Policy Entropy: 1.86270
Value Function Loss: 0.07485

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.56739
Value Function Update Magnitude: 0.52546

Collected Steps per Second: 22,067.63556
Overall Steps per Second: 10,554.78752

Timestep Collection Time: 2.26712
Timestep Consumption Time: 2.47291
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.74003

Cumulative Model Updates: 94,544
Cumulative Timesteps: 788,587,838

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 788587838...
Checkpoint 788587838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,423.21563
Policy Entropy: 1.84683
Value Function Loss: 0.06963

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.56373
Value Function Update Magnitude: 0.57683

Collected Steps per Second: 21,982.38421
Overall Steps per Second: 10,480.67569

Timestep Collection Time: 2.27528
Timestep Consumption Time: 2.49694
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.77221

Cumulative Model Updates: 94,550
Cumulative Timesteps: 788,637,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,722.12366
Policy Entropy: 1.86338
Value Function Loss: 0.07426

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.56644
Value Function Update Magnitude: 0.64326

Collected Steps per Second: 22,640.02478
Overall Steps per Second: 10,807.33549

Timestep Collection Time: 2.20927
Timestep Consumption Time: 2.41888
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.62815

Cumulative Model Updates: 94,556
Cumulative Timesteps: 788,687,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 788687872...
Checkpoint 788687872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,225.64281
Policy Entropy: 1.86763
Value Function Loss: 0.07896

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14709
Policy Update Magnitude: 0.56891
Value Function Update Magnitude: 0.67593

Collected Steps per Second: 21,972.39743
Overall Steps per Second: 10,652.17909

Timestep Collection Time: 2.27613
Timestep Consumption Time: 2.41887
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.69500

Cumulative Model Updates: 94,562
Cumulative Timesteps: 788,737,884

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,265.28516
Policy Entropy: 1.87664
Value Function Loss: 0.07904

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.16143
Policy Update Magnitude: 0.52214
Value Function Update Magnitude: 0.68475

Collected Steps per Second: 22,514.57403
Overall Steps per Second: 10,602.42666

Timestep Collection Time: 2.22123
Timestep Consumption Time: 2.49562
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.71684

Cumulative Model Updates: 94,568
Cumulative Timesteps: 788,787,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 788787894...
Checkpoint 788787894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,249.48691
Policy Entropy: 1.86669
Value Function Loss: 0.07690

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.16619
Policy Update Magnitude: 0.50810
Value Function Update Magnitude: 0.61699

Collected Steps per Second: 21,974.81079
Overall Steps per Second: 10,558.55535

Timestep Collection Time: 2.27570
Timestep Consumption Time: 2.46056
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.73625

Cumulative Model Updates: 94,574
Cumulative Timesteps: 788,837,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,009.63196
Policy Entropy: 1.86005
Value Function Loss: 0.07606

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.15179
Policy Update Magnitude: 0.54267
Value Function Update Magnitude: 0.61853

Collected Steps per Second: 22,744.86269
Overall Steps per Second: 10,631.15455

Timestep Collection Time: 2.19883
Timestep Consumption Time: 2.50546
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.70429

Cumulative Model Updates: 94,580
Cumulative Timesteps: 788,887,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 788887914...
Checkpoint 788887914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,283.03208
Policy Entropy: 1.84882
Value Function Loss: 0.07729

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.57415
Value Function Update Magnitude: 0.70554

Collected Steps per Second: 22,401.67917
Overall Steps per Second: 10,531.83070

Timestep Collection Time: 2.23215
Timestep Consumption Time: 2.51574
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.74789

Cumulative Model Updates: 94,586
Cumulative Timesteps: 788,937,918

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,072.20772
Policy Entropy: 1.85415
Value Function Loss: 0.07975

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.58629
Value Function Update Magnitude: 0.66821

Collected Steps per Second: 22,885.45056
Overall Steps per Second: 10,808.17813

Timestep Collection Time: 2.18602
Timestep Consumption Time: 2.44270
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.62872

Cumulative Model Updates: 94,592
Cumulative Timesteps: 788,987,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 788987946...
Checkpoint 788987946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,317.45815
Policy Entropy: 1.84844
Value Function Loss: 0.08137

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.58538
Value Function Update Magnitude: 0.58641

Collected Steps per Second: 21,863.14060
Overall Steps per Second: 10,579.89723

Timestep Collection Time: 2.28714
Timestep Consumption Time: 2.43918
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.72632

Cumulative Model Updates: 94,598
Cumulative Timesteps: 789,037,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,321.23842
Policy Entropy: 1.85296
Value Function Loss: 0.07625

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.58715
Value Function Update Magnitude: 0.54985

Collected Steps per Second: 22,712.12856
Overall Steps per Second: 10,602.11250

Timestep Collection Time: 2.20367
Timestep Consumption Time: 2.51709
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.72076

Cumulative Model Updates: 94,604
Cumulative Timesteps: 789,088,000

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 789088000...
Checkpoint 789088000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,527.32063
Policy Entropy: 1.86008
Value Function Loss: 0.07354

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.55732
Value Function Update Magnitude: 0.56088

Collected Steps per Second: 22,158.88735
Overall Steps per Second: 10,587.90086

Timestep Collection Time: 2.25788
Timestep Consumption Time: 2.46752
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.72539

Cumulative Model Updates: 94,610
Cumulative Timesteps: 789,138,032

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,755.56328
Policy Entropy: 1.85770
Value Function Loss: 0.06948

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.54764
Value Function Update Magnitude: 0.59993

Collected Steps per Second: 22,312.79651
Overall Steps per Second: 10,519.66051

Timestep Collection Time: 2.24221
Timestep Consumption Time: 2.51365
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.75586

Cumulative Model Updates: 94,616
Cumulative Timesteps: 789,188,062

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 789188062...
Checkpoint 789188062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,386.04833
Policy Entropy: 1.86384
Value Function Loss: 0.06525

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13933
Policy Update Magnitude: 0.52692
Value Function Update Magnitude: 0.61354

Collected Steps per Second: 21,893.13767
Overall Steps per Second: 10,602.42418

Timestep Collection Time: 2.28528
Timestep Consumption Time: 2.43364
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.71892

Cumulative Model Updates: 94,622
Cumulative Timesteps: 789,238,094

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,233.42300
Policy Entropy: 1.85473
Value Function Loss: 0.06620

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.15782
Policy Update Magnitude: 0.51346
Value Function Update Magnitude: 0.62226

Collected Steps per Second: 22,480.55238
Overall Steps per Second: 10,620.87858

Timestep Collection Time: 2.22450
Timestep Consumption Time: 2.48396
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.70846

Cumulative Model Updates: 94,628
Cumulative Timesteps: 789,288,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 789288102...
Checkpoint 789288102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,247.16440
Policy Entropy: 1.85199
Value Function Loss: 0.06818

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.15205
Policy Update Magnitude: 0.54483
Value Function Update Magnitude: 0.63040

Collected Steps per Second: 21,842.38466
Overall Steps per Second: 10,457.65880

Timestep Collection Time: 2.28977
Timestep Consumption Time: 2.49276
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.78252

Cumulative Model Updates: 94,634
Cumulative Timesteps: 789,338,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,319.77922
Policy Entropy: 1.84974
Value Function Loss: 0.07283

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.14820
Policy Update Magnitude: 0.55972
Value Function Update Magnitude: 0.65909

Collected Steps per Second: 22,519.88318
Overall Steps per Second: 10,550.84649

Timestep Collection Time: 2.22124
Timestep Consumption Time: 2.51980
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.74104

Cumulative Model Updates: 94,640
Cumulative Timesteps: 789,388,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 789388138...
Checkpoint 789388138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,874.93475
Policy Entropy: 1.85868
Value Function Loss: 0.07668

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.56612
Value Function Update Magnitude: 0.67939

Collected Steps per Second: 21,808.07170
Overall Steps per Second: 10,580.91030

Timestep Collection Time: 2.29300
Timestep Consumption Time: 2.43305
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.72606

Cumulative Model Updates: 94,646
Cumulative Timesteps: 789,438,144

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,153.09935
Policy Entropy: 1.86869
Value Function Loss: 0.07646

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.55948
Value Function Update Magnitude: 0.70207

Collected Steps per Second: 22,755.35041
Overall Steps per Second: 10,788.77747

Timestep Collection Time: 2.19764
Timestep Consumption Time: 2.43755
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.63519

Cumulative Model Updates: 94,652
Cumulative Timesteps: 789,488,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 789488152...
Checkpoint 789488152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,252.21413
Policy Entropy: 1.85269
Value Function Loss: 0.07628

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.54930
Value Function Update Magnitude: 0.72087

Collected Steps per Second: 22,132.03729
Overall Steps per Second: 10,637.74335

Timestep Collection Time: 2.26007
Timestep Consumption Time: 2.44205
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.70213

Cumulative Model Updates: 94,658
Cumulative Timesteps: 789,538,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,224.84491
Policy Entropy: 1.85917
Value Function Loss: 0.07337

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.14016
Policy Update Magnitude: 0.54878
Value Function Update Magnitude: 0.68734

Collected Steps per Second: 22,573.56308
Overall Steps per Second: 10,574.31782

Timestep Collection Time: 2.21613
Timestep Consumption Time: 2.51476
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.73090

Cumulative Model Updates: 94,664
Cumulative Timesteps: 789,588,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 789588198...
Checkpoint 789588198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,875.96100
Policy Entropy: 1.86166
Value Function Loss: 0.07797

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.56824
Value Function Update Magnitude: 0.64386

Collected Steps per Second: 22,015.28723
Overall Steps per Second: 10,649.66353

Timestep Collection Time: 2.27251
Timestep Consumption Time: 2.42529
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.69780

Cumulative Model Updates: 94,670
Cumulative Timesteps: 789,638,228

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,353.30906
Policy Entropy: 1.86755
Value Function Loss: 0.08704

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.58558
Value Function Update Magnitude: 0.51828

Collected Steps per Second: 22,476.39558
Overall Steps per Second: 10,625.59734

Timestep Collection Time: 2.22491
Timestep Consumption Time: 2.48146
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.70637

Cumulative Model Updates: 94,676
Cumulative Timesteps: 789,688,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 789688236...
Checkpoint 789688236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,492.11110
Policy Entropy: 1.87218
Value Function Loss: 0.09091

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.59045
Value Function Update Magnitude: 0.40497

Collected Steps per Second: 22,117.10068
Overall Steps per Second: 10,536.95149

Timestep Collection Time: 2.26087
Timestep Consumption Time: 2.48471
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.74559

Cumulative Model Updates: 94,682
Cumulative Timesteps: 789,738,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,382.82561
Policy Entropy: 1.86330
Value Function Loss: 0.08711

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.58387
Value Function Update Magnitude: 0.41197

Collected Steps per Second: 21,846.81338
Overall Steps per Second: 10,730.07679

Timestep Collection Time: 2.28866
Timestep Consumption Time: 2.37114
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.65980

Cumulative Model Updates: 94,688
Cumulative Timesteps: 789,788,240

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 789788240...
Checkpoint 789788240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,973.15440
Policy Entropy: 1.86941
Value Function Loss: 0.08048

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.57567
Value Function Update Magnitude: 0.57133

Collected Steps per Second: 21,498.55371
Overall Steps per Second: 10,640.70695

Timestep Collection Time: 2.32685
Timestep Consumption Time: 2.37434
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.70119

Cumulative Model Updates: 94,694
Cumulative Timesteps: 789,838,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,898.59220
Policy Entropy: 1.85924
Value Function Loss: 0.07992

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.58217
Value Function Update Magnitude: 0.66452

Collected Steps per Second: 21,948.48026
Overall Steps per Second: 10,618.36648

Timestep Collection Time: 2.27906
Timestep Consumption Time: 2.43183
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.71089

Cumulative Model Updates: 94,700
Cumulative Timesteps: 789,888,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 789888286...
Checkpoint 789888286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,329.20777
Policy Entropy: 1.87345
Value Function Loss: 0.07895

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.58174
Value Function Update Magnitude: 0.73283

Collected Steps per Second: 21,625.81021
Overall Steps per Second: 10,536.78823

Timestep Collection Time: 2.31362
Timestep Consumption Time: 2.43488
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.74851

Cumulative Model Updates: 94,706
Cumulative Timesteps: 789,938,320

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,377.03160
Policy Entropy: 1.88766
Value Function Loss: 0.07626

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.56931
Value Function Update Magnitude: 0.72414

Collected Steps per Second: 21,619.90549
Overall Steps per Second: 10,539.06258

Timestep Collection Time: 2.31444
Timestep Consumption Time: 2.43342
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.74786

Cumulative Model Updates: 94,712
Cumulative Timesteps: 789,988,358

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 789988358...
Checkpoint 789988358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,215.05853
Policy Entropy: 1.89133
Value Function Loss: 0.07821

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.57051
Value Function Update Magnitude: 0.69681

Collected Steps per Second: 21,553.46224
Overall Steps per Second: 10,512.29681

Timestep Collection Time: 2.32120
Timestep Consumption Time: 2.43798
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.75919

Cumulative Model Updates: 94,718
Cumulative Timesteps: 790,038,388

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,403.03333
Policy Entropy: 1.89979
Value Function Loss: 0.07942

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.58388
Value Function Update Magnitude: 0.72869

Collected Steps per Second: 21,964.77475
Overall Steps per Second: 10,677.63024

Timestep Collection Time: 2.27674
Timestep Consumption Time: 2.40670
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.68344

Cumulative Model Updates: 94,724
Cumulative Timesteps: 790,088,396

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 790088396...
Checkpoint 790088396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,356.54518
Policy Entropy: 1.89926
Value Function Loss: 0.08478

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.57330
Value Function Update Magnitude: 0.70983

Collected Steps per Second: 21,700.50380
Overall Steps per Second: 10,583.24441

Timestep Collection Time: 2.30428
Timestep Consumption Time: 2.42055
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.72483

Cumulative Model Updates: 94,730
Cumulative Timesteps: 790,138,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,681.08905
Policy Entropy: 1.89838
Value Function Loss: 0.07899

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.58347
Value Function Update Magnitude: 0.72399

Collected Steps per Second: 21,744.18077
Overall Steps per Second: 10,707.70622

Timestep Collection Time: 2.30075
Timestep Consumption Time: 2.37140
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.67215

Cumulative Model Updates: 94,736
Cumulative Timesteps: 790,188,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 790188428...
Checkpoint 790188428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,658.72671
Policy Entropy: 1.90555
Value Function Loss: 0.07270

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.57530
Value Function Update Magnitude: 0.78756

Collected Steps per Second: 21,376.76993
Overall Steps per Second: 10,384.92867

Timestep Collection Time: 2.34086
Timestep Consumption Time: 2.47766
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.81852

Cumulative Model Updates: 94,742
Cumulative Timesteps: 790,238,468

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,609.20164
Policy Entropy: 1.88817
Value Function Loss: 0.07121

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.55899
Value Function Update Magnitude: 0.74966

Collected Steps per Second: 22,406.73882
Overall Steps per Second: 10,734.68233

Timestep Collection Time: 2.23156
Timestep Consumption Time: 2.42643
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.65799

Cumulative Model Updates: 94,748
Cumulative Timesteps: 790,288,470

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 790288470...
Checkpoint 790288470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,841.59516
Policy Entropy: 1.89101
Value Function Loss: 0.07304

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.50980
Value Function Update Magnitude: 0.74277

Collected Steps per Second: 22,046.92492
Overall Steps per Second: 10,695.58421

Timestep Collection Time: 2.26862
Timestep Consumption Time: 2.40771
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.67632

Cumulative Model Updates: 94,754
Cumulative Timesteps: 790,338,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,229.22386
Policy Entropy: 1.88305
Value Function Loss: 0.07678

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.54209
Value Function Update Magnitude: 0.67015

Collected Steps per Second: 22,279.34883
Overall Steps per Second: 10,617.62385

Timestep Collection Time: 2.24441
Timestep Consumption Time: 2.46512
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.70953

Cumulative Model Updates: 94,760
Cumulative Timesteps: 790,388,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 790388490...
Checkpoint 790388490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,682.47656
Policy Entropy: 1.88489
Value Function Loss: 0.07773

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.15816
Policy Update Magnitude: 0.50331
Value Function Update Magnitude: 0.51588

Collected Steps per Second: 22,045.22197
Overall Steps per Second: 10,533.12898

Timestep Collection Time: 2.26861
Timestep Consumption Time: 2.47946
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.74807

Cumulative Model Updates: 94,766
Cumulative Timesteps: 790,438,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,127.48391
Policy Entropy: 1.87365
Value Function Loss: 0.07580

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.14040
Policy Update Magnitude: 0.49884
Value Function Update Magnitude: 0.47875

Collected Steps per Second: 22,524.02746
Overall Steps per Second: 10,770.72384

Timestep Collection Time: 2.22092
Timestep Consumption Time: 2.42352
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.64444

Cumulative Model Updates: 94,772
Cumulative Timesteps: 790,488,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 790488526...
Checkpoint 790488526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,639.56002
Policy Entropy: 1.87911
Value Function Loss: 0.07527

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.55055
Value Function Update Magnitude: 0.63511

Collected Steps per Second: 22,341.11379
Overall Steps per Second: 10,640.76396

Timestep Collection Time: 2.23892
Timestep Consumption Time: 2.46187
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.70079

Cumulative Model Updates: 94,778
Cumulative Timesteps: 790,538,546

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,430.93404
Policy Entropy: 1.87690
Value Function Loss: 0.07414

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.15961
Policy Update Magnitude: 0.52207
Value Function Update Magnitude: 0.68855

Collected Steps per Second: 22,185.64038
Overall Steps per Second: 10,474.04562

Timestep Collection Time: 2.25479
Timestep Consumption Time: 2.52120
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.77600

Cumulative Model Updates: 94,784
Cumulative Timesteps: 790,588,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 790588570...
Checkpoint 790588570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,440.49958
Policy Entropy: 1.87831
Value Function Loss: 0.07592

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.16152
Policy Update Magnitude: 0.51253
Value Function Update Magnitude: 0.64420

Collected Steps per Second: 21,796.42966
Overall Steps per Second: 10,595.71228

Timestep Collection Time: 2.29588
Timestep Consumption Time: 2.42697
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.72285

Cumulative Model Updates: 94,790
Cumulative Timesteps: 790,638,612

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,355.75439
Policy Entropy: 1.87926
Value Function Loss: 0.07488

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.16801
Policy Update Magnitude: 0.50157
Value Function Update Magnitude: 0.64723

Collected Steps per Second: 22,136.13724
Overall Steps per Second: 10,510.16016

Timestep Collection Time: 2.25911
Timestep Consumption Time: 2.49895
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.75806

Cumulative Model Updates: 94,796
Cumulative Timesteps: 790,688,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 790688620...
Checkpoint 790688620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,945.08087
Policy Entropy: 1.88943
Value Function Loss: 0.07278

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.16188
Policy Update Magnitude: 0.53401
Value Function Update Magnitude: 0.68807

Collected Steps per Second: 21,191.49070
Overall Steps per Second: 10,260.66327

Timestep Collection Time: 2.36029
Timestep Consumption Time: 2.51445
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.87473

Cumulative Model Updates: 94,802
Cumulative Timesteps: 790,738,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,169.72866
Policy Entropy: 1.87636
Value Function Loss: 0.07130

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.15186
Policy Update Magnitude: 0.52566
Value Function Update Magnitude: 0.69885

Collected Steps per Second: 22,412.74294
Overall Steps per Second: 10,561.77608

Timestep Collection Time: 2.23150
Timestep Consumption Time: 2.50388
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.73538

Cumulative Model Updates: 94,808
Cumulative Timesteps: 790,788,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 790788652...
Checkpoint 790788652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,757.36357
Policy Entropy: 1.88840
Value Function Loss: 0.06786

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.53734
Value Function Update Magnitude: 0.69670

Collected Steps per Second: 21,943.47590
Overall Steps per Second: 10,459.64389

Timestep Collection Time: 2.27968
Timestep Consumption Time: 2.50290
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.78257

Cumulative Model Updates: 94,814
Cumulative Timesteps: 790,838,676

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,833.01885
Policy Entropy: 1.88452
Value Function Loss: 0.07160

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.54222
Value Function Update Magnitude: 0.68865

Collected Steps per Second: 22,459.40094
Overall Steps per Second: 10,625.87243

Timestep Collection Time: 2.22722
Timestep Consumption Time: 2.48035
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.70757

Cumulative Model Updates: 94,820
Cumulative Timesteps: 790,888,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 790888698...
Checkpoint 790888698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,539.38633
Policy Entropy: 1.91109
Value Function Loss: 0.07076

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.14239
Policy Update Magnitude: 0.53400
Value Function Update Magnitude: 0.68116

Collected Steps per Second: 22,453.81287
Overall Steps per Second: 10,529.85438

Timestep Collection Time: 2.22742
Timestep Consumption Time: 2.52232
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.74973

Cumulative Model Updates: 94,826
Cumulative Timesteps: 790,938,712

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,928.14818
Policy Entropy: 1.89204
Value Function Loss: 0.07068

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.15516
Policy Update Magnitude: 0.48379
Value Function Update Magnitude: 0.69569

Collected Steps per Second: 22,453.47757
Overall Steps per Second: 10,553.94654

Timestep Collection Time: 2.22798
Timestep Consumption Time: 2.51204
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.74003

Cumulative Model Updates: 94,832
Cumulative Timesteps: 790,988,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 790988738...
Checkpoint 790988738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,078.50653
Policy Entropy: 1.88900
Value Function Loss: 0.07012

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.46575
Value Function Update Magnitude: 0.68386

Collected Steps per Second: 21,950.32134
Overall Steps per Second: 10,494.68895

Timestep Collection Time: 2.27860
Timestep Consumption Time: 2.48724
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.76584

Cumulative Model Updates: 94,838
Cumulative Timesteps: 791,038,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,625.50533
Policy Entropy: 1.89257
Value Function Loss: 0.07746

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.49260
Value Function Update Magnitude: 0.68806

Collected Steps per Second: 22,353.81646
Overall Steps per Second: 10,525.83190

Timestep Collection Time: 2.23711
Timestep Consumption Time: 2.51387
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.75098

Cumulative Model Updates: 94,844
Cumulative Timesteps: 791,088,762

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 791088762...
Checkpoint 791088762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,641.21387
Policy Entropy: 1.91780
Value Function Loss: 0.07818

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.55548
Value Function Update Magnitude: 0.66775

Collected Steps per Second: 22,433.94184
Overall Steps per Second: 10,566.93758

Timestep Collection Time: 2.22930
Timestep Consumption Time: 2.50357
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.73288

Cumulative Model Updates: 94,850
Cumulative Timesteps: 791,138,774

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,611.32143
Policy Entropy: 1.90308
Value Function Loss: 0.08381

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.14133
Policy Update Magnitude: 0.57582
Value Function Update Magnitude: 0.71231

Collected Steps per Second: 22,264.53906
Overall Steps per Second: 10,487.26885

Timestep Collection Time: 2.24770
Timestep Consumption Time: 2.52418
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.77188

Cumulative Model Updates: 94,856
Cumulative Timesteps: 791,188,818

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 791188818...
Checkpoint 791188818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,444.14570
Policy Entropy: 1.87453
Value Function Loss: 0.08028

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.57938
Value Function Update Magnitude: 0.68998

Collected Steps per Second: 21,642.10172
Overall Steps per Second: 10,529.50041

Timestep Collection Time: 2.31059
Timestep Consumption Time: 2.43854
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.74913

Cumulative Model Updates: 94,862
Cumulative Timesteps: 791,238,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,378.64458
Policy Entropy: 1.85839
Value Function Loss: 0.07873

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14353
Policy Update Magnitude: 0.58457
Value Function Update Magnitude: 0.58997

Collected Steps per Second: 22,309.63806
Overall Steps per Second: 10,556.12102

Timestep Collection Time: 2.24208
Timestep Consumption Time: 2.49640
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.73848

Cumulative Model Updates: 94,868
Cumulative Timesteps: 791,288,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 791288844...
Checkpoint 791288844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,142.48020
Policy Entropy: 1.86654
Value Function Loss: 0.08127

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.57996
Value Function Update Magnitude: 0.63290

Collected Steps per Second: 22,084.63456
Overall Steps per Second: 10,591.45330

Timestep Collection Time: 2.26411
Timestep Consumption Time: 2.45687
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.72098

Cumulative Model Updates: 94,874
Cumulative Timesteps: 791,338,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,090.97949
Policy Entropy: 1.88312
Value Function Loss: 0.07955

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.58045
Value Function Update Magnitude: 0.60156

Collected Steps per Second: 22,423.90123
Overall Steps per Second: 10,517.79156

Timestep Collection Time: 2.23030
Timestep Consumption Time: 2.52469
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.75499

Cumulative Model Updates: 94,880
Cumulative Timesteps: 791,388,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 791388858...
Checkpoint 791388858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,429.69374
Policy Entropy: 1.88470
Value Function Loss: 0.07977

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.57580
Value Function Update Magnitude: 0.56920

Collected Steps per Second: 21,843.72520
Overall Steps per Second: 10,578.56510

Timestep Collection Time: 2.28935
Timestep Consumption Time: 2.43794
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.72730

Cumulative Model Updates: 94,886
Cumulative Timesteps: 791,438,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,145.22387
Policy Entropy: 1.88749
Value Function Loss: 0.08389

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.16228
Policy Update Magnitude: 0.51728
Value Function Update Magnitude: 0.56988

Collected Steps per Second: 22,330.23905
Overall Steps per Second: 10,543.61286

Timestep Collection Time: 2.23912
Timestep Consumption Time: 2.50309
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.74221

Cumulative Model Updates: 94,892
Cumulative Timesteps: 791,488,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 791488866...
Checkpoint 791488866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,649.16415
Policy Entropy: 1.88462
Value Function Loss: 0.07995

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.14832
Policy Update Magnitude: 0.52165
Value Function Update Magnitude: 0.55173

Collected Steps per Second: 22,149.44113
Overall Steps per Second: 10,557.46520

Timestep Collection Time: 2.25739
Timestep Consumption Time: 2.47859
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.73599

Cumulative Model Updates: 94,898
Cumulative Timesteps: 791,538,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,309.75024
Policy Entropy: 1.88440
Value Function Loss: 0.07273

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.16326
Policy Update Magnitude: 0.53718
Value Function Update Magnitude: 0.62354

Collected Steps per Second: 22,225.22667
Overall Steps per Second: 10,486.29678

Timestep Collection Time: 2.25222
Timestep Consumption Time: 2.52125
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.77347

Cumulative Model Updates: 94,904
Cumulative Timesteps: 791,588,922

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 791588922...
Checkpoint 791588922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,632.49034
Policy Entropy: 1.89321
Value Function Loss: 0.06561

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.16846
Policy Update Magnitude: 0.48415
Value Function Update Magnitude: 0.63402

Collected Steps per Second: 21,860.56981
Overall Steps per Second: 10,588.70526

Timestep Collection Time: 2.28878
Timestep Consumption Time: 2.43645
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.72522

Cumulative Model Updates: 94,910
Cumulative Timesteps: 791,638,956

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,492.74434
Policy Entropy: 1.88866
Value Function Loss: 0.06749

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.17101
Policy Update Magnitude: 0.49479
Value Function Update Magnitude: 0.59741

Collected Steps per Second: 22,182.22433
Overall Steps per Second: 10,471.03340

Timestep Collection Time: 2.25451
Timestep Consumption Time: 2.52153
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.77603

Cumulative Model Updates: 94,916
Cumulative Timesteps: 791,688,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 791688966...
Checkpoint 791688966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,012.75701
Policy Entropy: 1.90893
Value Function Loss: 0.07411

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.16863
Policy Update Magnitude: 0.49152
Value Function Update Magnitude: 0.60326

Collected Steps per Second: 22,300.97760
Overall Steps per Second: 10,686.34743

Timestep Collection Time: 2.24295
Timestep Consumption Time: 2.43779
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.68074

Cumulative Model Updates: 94,922
Cumulative Timesteps: 791,738,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,672.75637
Policy Entropy: 1.90633
Value Function Loss: 0.07761

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.16139
Policy Update Magnitude: 0.49302
Value Function Update Magnitude: 0.67068

Collected Steps per Second: 22,514.09393
Overall Steps per Second: 10,582.53550

Timestep Collection Time: 2.22110
Timestep Consumption Time: 2.50423
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.72533

Cumulative Model Updates: 94,928
Cumulative Timesteps: 791,788,992

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 791788992...
Checkpoint 791788992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,010.13171
Policy Entropy: 1.89975
Value Function Loss: 0.07661

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.14717
Policy Update Magnitude: 0.53776
Value Function Update Magnitude: 0.67155

Collected Steps per Second: 22,321.43853
Overall Steps per Second: 10,538.63732

Timestep Collection Time: 2.24045
Timestep Consumption Time: 2.50495
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.74540

Cumulative Model Updates: 94,934
Cumulative Timesteps: 791,839,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,898.53754
Policy Entropy: 1.89478
Value Function Loss: 0.08539

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.16246
Policy Update Magnitude: 0.57767
Value Function Update Magnitude: 0.59915

Collected Steps per Second: 22,439.89938
Overall Steps per Second: 10,750.68110

Timestep Collection Time: 2.22889
Timestep Consumption Time: 2.42347
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.65236

Cumulative Model Updates: 94,940
Cumulative Timesteps: 791,889,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 791889018...
Checkpoint 791889018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,906.98025
Policy Entropy: 1.90190
Value Function Loss: 0.08566

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.16500
Policy Update Magnitude: 0.59872
Value Function Update Magnitude: 0.58620

Collected Steps per Second: 22,004.13527
Overall Steps per Second: 10,659.98123

Timestep Collection Time: 2.27294
Timestep Consumption Time: 2.41882
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.69175

Cumulative Model Updates: 94,946
Cumulative Timesteps: 791,939,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,669.57926
Policy Entropy: 1.92005
Value Function Loss: 0.08408

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.15195
Policy Update Magnitude: 0.59891
Value Function Update Magnitude: 0.61441

Collected Steps per Second: 21,746.86322
Overall Steps per Second: 10,500.57220

Timestep Collection Time: 2.29992
Timestep Consumption Time: 2.46325
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.76317

Cumulative Model Updates: 94,952
Cumulative Timesteps: 791,989,048

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 791989048...
Checkpoint 791989048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,213.41569
Policy Entropy: 1.92091
Value Function Loss: 0.08859

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.59797
Value Function Update Magnitude: 0.62736

Collected Steps per Second: 21,772.30478
Overall Steps per Second: 10,647.79091

Timestep Collection Time: 2.29787
Timestep Consumption Time: 2.40075
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.69863

Cumulative Model Updates: 94,958
Cumulative Timesteps: 792,039,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,720.23382
Policy Entropy: 1.92443
Value Function Loss: 0.08589

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.14745
Policy Update Magnitude: 0.59533
Value Function Update Magnitude: 0.64044

Collected Steps per Second: 22,036.77250
Overall Steps per Second: 10,693.64019

Timestep Collection Time: 2.26893
Timestep Consumption Time: 2.40674
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.67568

Cumulative Model Updates: 94,964
Cumulative Timesteps: 792,089,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 792089078...
Checkpoint 792089078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,856.69685
Policy Entropy: 1.94612
Value Function Loss: 0.08727

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.58844
Value Function Update Magnitude: 0.60981

Collected Steps per Second: 21,744.60767
Overall Steps per Second: 10,640.15931

Timestep Collection Time: 2.30043
Timestep Consumption Time: 2.40081
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.70125

Cumulative Model Updates: 94,970
Cumulative Timesteps: 792,139,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,240.42732
Policy Entropy: 1.94217
Value Function Loss: 0.08352

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.58632
Value Function Update Magnitude: 0.59556

Collected Steps per Second: 22,112.81692
Overall Steps per Second: 10,692.49546

Timestep Collection Time: 2.26195
Timestep Consumption Time: 2.41591
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.67786

Cumulative Model Updates: 94,976
Cumulative Timesteps: 792,189,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 792189118...
Checkpoint 792189118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,381.72799
Policy Entropy: 1.93480
Value Function Loss: 0.07893

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.57786
Value Function Update Magnitude: 0.68307

Collected Steps per Second: 21,353.86656
Overall Steps per Second: 10,628.51869

Timestep Collection Time: 2.34225
Timestep Consumption Time: 2.36358
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.70583

Cumulative Model Updates: 94,982
Cumulative Timesteps: 792,239,134

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,346.68913
Policy Entropy: 1.91754
Value Function Loss: 0.07961

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.14353
Policy Update Magnitude: 0.54950
Value Function Update Magnitude: 0.67759

Collected Steps per Second: 21,801.44747
Overall Steps per Second: 10,553.36240

Timestep Collection Time: 2.29416
Timestep Consumption Time: 2.44518
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.73934

Cumulative Model Updates: 94,988
Cumulative Timesteps: 792,289,150

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 792289150...
Checkpoint 792289150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,206.79291
Policy Entropy: 1.90767
Value Function Loss: 0.08253

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.55805
Value Function Update Magnitude: 0.65626

Collected Steps per Second: 21,673.51011
Overall Steps per Second: 10,541.85990

Timestep Collection Time: 2.30761
Timestep Consumption Time: 2.43671
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.74432

Cumulative Model Updates: 94,994
Cumulative Timesteps: 792,339,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,258.58002
Policy Entropy: 1.90275
Value Function Loss: 0.08718

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.58202
Value Function Update Magnitude: 0.59232

Collected Steps per Second: 21,736.34374
Overall Steps per Second: 10,590.87859

Timestep Collection Time: 2.30131
Timestep Consumption Time: 2.42181
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.72312

Cumulative Model Updates: 95,000
Cumulative Timesteps: 792,389,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 792389186...
Checkpoint 792389186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,750.54230
Policy Entropy: 1.90594
Value Function Loss: 0.09462

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.13854
Policy Update Magnitude: 0.60292
Value Function Update Magnitude: 0.52921

Collected Steps per Second: 21,298.56510
Overall Steps per Second: 10,474.10708

Timestep Collection Time: 2.34795
Timestep Consumption Time: 2.42649
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.77444

Cumulative Model Updates: 95,006
Cumulative Timesteps: 792,439,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,774.37294
Policy Entropy: 1.91793
Value Function Loss: 0.09348

Mean KL Divergence: 0.02356
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.59688
Value Function Update Magnitude: 0.50320

Collected Steps per Second: 22,472.69584
Overall Steps per Second: 10,615.88952

Timestep Collection Time: 2.22510
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.71030

Cumulative Model Updates: 95,012
Cumulative Timesteps: 792,489,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 792489198...
Checkpoint 792489198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,022.62820
Policy Entropy: 1.93072
Value Function Loss: 0.08971

Mean KL Divergence: 0.02663
SB3 Clip Fraction: 0.14453
Policy Update Magnitude: 0.58874
Value Function Update Magnitude: 0.43525

Collected Steps per Second: 22,617.21247
Overall Steps per Second: 10,762.71277

Timestep Collection Time: 2.21203
Timestep Consumption Time: 2.43642
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.64846

Cumulative Model Updates: 95,018
Cumulative Timesteps: 792,539,228

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,132.68390
Policy Entropy: 1.94118
Value Function Loss: 0.08401

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.58379
Value Function Update Magnitude: 0.41728

Collected Steps per Second: 22,557.20602
Overall Steps per Second: 10,628.76712

Timestep Collection Time: 2.21676
Timestep Consumption Time: 2.48783
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.70459

Cumulative Model Updates: 95,024
Cumulative Timesteps: 792,589,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 792589232...
Checkpoint 792589232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,792.33160
Policy Entropy: 1.94885
Value Function Loss: 0.08786

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.59015
Value Function Update Magnitude: 0.42622

Collected Steps per Second: 21,982.02240
Overall Steps per Second: 10,704.18961

Timestep Collection Time: 2.27559
Timestep Consumption Time: 2.39754
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.67312

Cumulative Model Updates: 95,030
Cumulative Timesteps: 792,639,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,044.44822
Policy Entropy: 1.95193
Value Function Loss: 0.09439

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13571
Policy Update Magnitude: 0.59778
Value Function Update Magnitude: 0.40815

Collected Steps per Second: 22,706.95694
Overall Steps per Second: 10,832.01844

Timestep Collection Time: 2.20250
Timestep Consumption Time: 2.41456
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.61705

Cumulative Model Updates: 95,036
Cumulative Timesteps: 792,689,266

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 792689266...
Checkpoint 792689266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,684.27890
Policy Entropy: 1.95216
Value Function Loss: 0.09337

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.14849
Policy Update Magnitude: 0.58198
Value Function Update Magnitude: 0.38445

Collected Steps per Second: 22,362.62191
Overall Steps per Second: 10,682.28778

Timestep Collection Time: 2.23695
Timestep Consumption Time: 2.44594
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.68289

Cumulative Model Updates: 95,042
Cumulative Timesteps: 792,739,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,542.93877
Policy Entropy: 1.93846
Value Function Loss: 0.09059

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.16579
Policy Update Magnitude: 0.50266
Value Function Update Magnitude: 0.37613

Collected Steps per Second: 22,635.08006
Overall Steps per Second: 10,616.97679

Timestep Collection Time: 2.21002
Timestep Consumption Time: 2.50168
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.71170

Cumulative Model Updates: 95,048
Cumulative Timesteps: 792,789,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 792789314...
Checkpoint 792789314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,861.41638
Policy Entropy: 1.94129
Value Function Loss: 0.08866

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.16181
Policy Update Magnitude: 0.46033
Value Function Update Magnitude: 0.41169

Collected Steps per Second: 22,392.17838
Overall Steps per Second: 10,515.62779

Timestep Collection Time: 2.23373
Timestep Consumption Time: 2.52281
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.75654

Cumulative Model Updates: 95,054
Cumulative Timesteps: 792,839,332

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,742.98684
Policy Entropy: 1.94402
Value Function Loss: 0.09048

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.15143
Policy Update Magnitude: 0.49891
Value Function Update Magnitude: 0.43687

Collected Steps per Second: 22,551.77734
Overall Steps per Second: 10,780.48026

Timestep Collection Time: 2.21801
Timestep Consumption Time: 2.42186
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.63987

Cumulative Model Updates: 95,060
Cumulative Timesteps: 792,889,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 792889352...
Checkpoint 792889352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,212.23984
Policy Entropy: 1.95936
Value Function Loss: 0.09245

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.15513
Policy Update Magnitude: 0.51211
Value Function Update Magnitude: 0.44775

Collected Steps per Second: 22,502.16577
Overall Steps per Second: 10,726.65677

Timestep Collection Time: 2.22219
Timestep Consumption Time: 2.43947
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.66166

Cumulative Model Updates: 95,066
Cumulative Timesteps: 792,939,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,202.12555
Policy Entropy: 1.94767
Value Function Loss: 0.08657

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.15762
Policy Update Magnitude: 0.49712
Value Function Update Magnitude: 0.51570

Collected Steps per Second: 22,400.89159
Overall Steps per Second: 10,532.58821

Timestep Collection Time: 2.23313
Timestep Consumption Time: 2.51632
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.74945

Cumulative Model Updates: 95,072
Cumulative Timesteps: 792,989,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 792989380...
Checkpoint 792989380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,970.69698
Policy Entropy: 1.95204
Value Function Loss: 0.08238

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.15324
Policy Update Magnitude: 0.48235
Value Function Update Magnitude: 0.45994

Collected Steps per Second: 22,084.00770
Overall Steps per Second: 10,550.60392

Timestep Collection Time: 2.26508
Timestep Consumption Time: 2.47607
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.74115

Cumulative Model Updates: 95,078
Cumulative Timesteps: 793,039,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,134.81422
Policy Entropy: 1.95469
Value Function Loss: 0.07971

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.52866
Value Function Update Magnitude: 0.35478

Collected Steps per Second: 22,719.06035
Overall Steps per Second: 10,625.72398

Timestep Collection Time: 2.20150
Timestep Consumption Time: 2.50557
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.70707

Cumulative Model Updates: 95,084
Cumulative Timesteps: 793,089,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 793089418...
Checkpoint 793089418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,635.41425
Policy Entropy: 1.95942
Value Function Loss: 0.08134

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13941
Policy Update Magnitude: 0.55678
Value Function Update Magnitude: 0.35661

Collected Steps per Second: 21,965.30609
Overall Steps per Second: 10,483.78038

Timestep Collection Time: 2.27750
Timestep Consumption Time: 2.49425
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.77175

Cumulative Model Updates: 95,090
Cumulative Timesteps: 793,139,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,128.89705
Policy Entropy: 1.96103
Value Function Loss: 0.08692

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.56446
Value Function Update Magnitude: 0.40472

Collected Steps per Second: 22,257.27354
Overall Steps per Second: 10,486.80945

Timestep Collection Time: 2.24762
Timestep Consumption Time: 2.52275
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.77037

Cumulative Model Updates: 95,096
Cumulative Timesteps: 793,189,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 793189470...
Checkpoint 793189470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,148.14570
Policy Entropy: 1.95675
Value Function Loss: 0.08524

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.56965
Value Function Update Magnitude: 0.41225

Collected Steps per Second: 22,056.51070
Overall Steps per Second: 10,590.52805

Timestep Collection Time: 2.26709
Timestep Consumption Time: 2.45449
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.72158

Cumulative Model Updates: 95,102
Cumulative Timesteps: 793,239,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,932.71108
Policy Entropy: 1.96823
Value Function Loss: 0.09236

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.57613
Value Function Update Magnitude: 0.36211

Collected Steps per Second: 22,307.27138
Overall Steps per Second: 10,504.36952

Timestep Collection Time: 2.24268
Timestep Consumption Time: 2.51991
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.76259

Cumulative Model Updates: 95,108
Cumulative Timesteps: 793,289,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 793289502...
Checkpoint 793289502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,745.15223
Policy Entropy: 1.99399
Value Function Loss: 0.08938

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.56702
Value Function Update Magnitude: 0.35750

Collected Steps per Second: 22,219.63668
Overall Steps per Second: 10,616.37304

Timestep Collection Time: 2.25098
Timestep Consumption Time: 2.46023
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.71121

Cumulative Model Updates: 95,114
Cumulative Timesteps: 793,339,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,875.81313
Policy Entropy: 1.99841
Value Function Loss: 0.09477

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.55566
Value Function Update Magnitude: 0.34187

Collected Steps per Second: 22,273.05728
Overall Steps per Second: 10,499.55963

Timestep Collection Time: 2.24648
Timestep Consumption Time: 2.51905
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.76553

Cumulative Model Updates: 95,120
Cumulative Timesteps: 793,389,554

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 793389554...
Checkpoint 793389554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,895.99809
Policy Entropy: 1.99135
Value Function Loss: 0.09579

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.14886
Policy Update Magnitude: 0.56213
Value Function Update Magnitude: 0.36929

Collected Steps per Second: 22,306.60021
Overall Steps per Second: 10,570.48767

Timestep Collection Time: 2.24248
Timestep Consumption Time: 2.48976
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.73223

Cumulative Model Updates: 95,126
Cumulative Timesteps: 793,439,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,829.14048
Policy Entropy: 1.99254
Value Function Loss: 0.10207

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.14675
Policy Update Magnitude: 0.58135
Value Function Update Magnitude: 0.40968

Collected Steps per Second: 22,490.74119
Overall Steps per Second: 10,678.77651

Timestep Collection Time: 2.22331
Timestep Consumption Time: 2.45924
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.68256

Cumulative Model Updates: 95,132
Cumulative Timesteps: 793,489,580

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 793489580...
Checkpoint 793489580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,840.59582
Policy Entropy: 2.01182
Value Function Loss: 0.10541

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.15093
Policy Update Magnitude: 0.58874
Value Function Update Magnitude: 0.38238

Collected Steps per Second: 22,220.17105
Overall Steps per Second: 10,579.64164

Timestep Collection Time: 2.25021
Timestep Consumption Time: 2.47585
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.72606

Cumulative Model Updates: 95,138
Cumulative Timesteps: 793,539,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,819.34347
Policy Entropy: 2.03508
Value Function Loss: 0.10302

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.15322
Policy Update Magnitude: 0.59672
Value Function Update Magnitude: 0.38449

Collected Steps per Second: 22,416.49392
Overall Steps per Second: 10,672.04751

Timestep Collection Time: 2.23113
Timestep Consumption Time: 2.45532
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.68645

Cumulative Model Updates: 95,144
Cumulative Timesteps: 793,589,594

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 793589594...
Checkpoint 793589594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,294.91708
Policy Entropy: 2.00566
Value Function Loss: 0.09323

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.14055
Policy Update Magnitude: 0.59357
Value Function Update Magnitude: 0.42605

Collected Steps per Second: 22,183.11576
Overall Steps per Second: 10,642.65051

Timestep Collection Time: 2.25595
Timestep Consumption Time: 2.44626
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.70221

Cumulative Model Updates: 95,150
Cumulative Timesteps: 793,639,638

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,432.99234
Policy Entropy: 1.99606
Value Function Loss: 0.08425

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.57719
Value Function Update Magnitude: 0.48279

Collected Steps per Second: 22,284.45761
Overall Steps per Second: 10,500.57594

Timestep Collection Time: 2.24470
Timestep Consumption Time: 2.51904
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.76374

Cumulative Model Updates: 95,156
Cumulative Timesteps: 793,689,660

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 793689660...
Checkpoint 793689660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,257.89769
Policy Entropy: 1.98769
Value Function Loss: 0.08351

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.57965
Value Function Update Magnitude: 0.57254

Collected Steps per Second: 21,758.35080
Overall Steps per Second: 10,614.35259

Timestep Collection Time: 2.29953
Timestep Consumption Time: 2.41428
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.71381

Cumulative Model Updates: 95,162
Cumulative Timesteps: 793,739,694

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,381.37525
Policy Entropy: 1.98376
Value Function Loss: 0.08393

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.57730
Value Function Update Magnitude: 0.58065

Collected Steps per Second: 22,355.41410
Overall Steps per Second: 10,488.47437

Timestep Collection Time: 2.23874
Timestep Consumption Time: 2.53297
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.77171

Cumulative Model Updates: 95,168
Cumulative Timesteps: 793,789,742

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 793789742...
Checkpoint 793789742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,885.03204
Policy Entropy: 1.96716
Value Function Loss: 0.08045

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.56846
Value Function Update Magnitude: 0.57857

Collected Steps per Second: 21,976.97489
Overall Steps per Second: 10,602.54193

Timestep Collection Time: 2.27738
Timestep Consumption Time: 2.44318
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.72057

Cumulative Model Updates: 95,174
Cumulative Timesteps: 793,839,792

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,823.13386
Policy Entropy: 1.94088
Value Function Loss: 0.07429

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13526
Policy Update Magnitude: 0.53656
Value Function Update Magnitude: 0.60415

Collected Steps per Second: 22,564.80445
Overall Steps per Second: 10,585.92639

Timestep Collection Time: 2.21646
Timestep Consumption Time: 2.50811
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.72457

Cumulative Model Updates: 95,180
Cumulative Timesteps: 793,889,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 793889806...
Checkpoint 793889806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,360.39164
Policy Entropy: 1.95084
Value Function Loss: 0.07467

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.51473
Value Function Update Magnitude: 0.59802

Collected Steps per Second: 22,550.95672
Overall Steps per Second: 10,562.77713

Timestep Collection Time: 2.21818
Timestep Consumption Time: 2.51751
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.73569

Cumulative Model Updates: 95,186
Cumulative Timesteps: 793,939,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,884.64567
Policy Entropy: 1.95166
Value Function Loss: 0.07523

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.54373
Value Function Update Magnitude: 0.61856

Collected Steps per Second: 22,242.28267
Overall Steps per Second: 10,462.23786

Timestep Collection Time: 2.24887
Timestep Consumption Time: 2.53213
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.78100

Cumulative Model Updates: 95,192
Cumulative Timesteps: 793,989,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 793989848...
Checkpoint 793989848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,457.53264
Policy Entropy: 1.96226
Value Function Loss: 0.08390

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11832
Policy Update Magnitude: 0.56840
Value Function Update Magnitude: 0.63918

Collected Steps per Second: 22,326.27817
Overall Steps per Second: 10,681.91866

Timestep Collection Time: 2.23969
Timestep Consumption Time: 2.44149
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.68118

Cumulative Model Updates: 95,198
Cumulative Timesteps: 794,039,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,991.49139
Policy Entropy: 1.96254
Value Function Loss: 0.09232

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.59201
Value Function Update Magnitude: 0.70356

Collected Steps per Second: 22,851.84668
Overall Steps per Second: 10,861.42630

Timestep Collection Time: 2.18853
Timestep Consumption Time: 2.41602
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.60455

Cumulative Model Updates: 95,204
Cumulative Timesteps: 794,089,864

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 794089864...
Checkpoint 794089864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,574.96113
Policy Entropy: 1.98925
Value Function Loss: 0.09861

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.59803
Value Function Update Magnitude: 0.67841

Collected Steps per Second: 22,403.63588
Overall Steps per Second: 10,668.23774

Timestep Collection Time: 2.23303
Timestep Consumption Time: 2.45640
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.68943

Cumulative Model Updates: 95,210
Cumulative Timesteps: 794,139,892

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,560.74533
Policy Entropy: 2.01092
Value Function Loss: 0.09549

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14458
Policy Update Magnitude: 0.58197
Value Function Update Magnitude: 0.59223

Collected Steps per Second: 22,292.59016
Overall Steps per Second: 10,478.98351

Timestep Collection Time: 2.24326
Timestep Consumption Time: 2.52896
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.77222

Cumulative Model Updates: 95,216
Cumulative Timesteps: 794,189,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 794189900...
Checkpoint 794189900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,707.26692
Policy Entropy: 2.00973
Value Function Loss: 0.09290

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.56960
Value Function Update Magnitude: 0.47209

Collected Steps per Second: 21,747.78725
Overall Steps per Second: 10,526.00890

Timestep Collection Time: 2.29927
Timestep Consumption Time: 2.45125
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.75052

Cumulative Model Updates: 95,222
Cumulative Timesteps: 794,239,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,249.95360
Policy Entropy: 2.02264
Value Function Loss: 0.09780

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.57401
Value Function Update Magnitude: 0.44732

Collected Steps per Second: 22,324.08170
Overall Steps per Second: 10,561.71712

Timestep Collection Time: 2.24045
Timestep Consumption Time: 2.49514
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.73559

Cumulative Model Updates: 95,228
Cumulative Timesteps: 794,289,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 794289920...
Checkpoint 794289920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,657.26492
Policy Entropy: 2.01042
Value Function Loss: 0.09020

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.14304
Policy Update Magnitude: 0.56545
Value Function Update Magnitude: 0.59401

Collected Steps per Second: 22,179.69215
Overall Steps per Second: 10,651.61866

Timestep Collection Time: 2.25440
Timestep Consumption Time: 2.43991
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.69431

Cumulative Model Updates: 95,234
Cumulative Timesteps: 794,339,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,377.45154
Policy Entropy: 2.01192
Value Function Loss: 0.08359

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.56027
Value Function Update Magnitude: 0.61767

Collected Steps per Second: 22,330.81847
Overall Steps per Second: 10,525.24654

Timestep Collection Time: 2.23977
Timestep Consumption Time: 2.51223
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.75200

Cumulative Model Updates: 95,240
Cumulative Timesteps: 794,389,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 794389938...
Checkpoint 794389938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,440.26979
Policy Entropy: 1.99170
Value Function Loss: 0.07298

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.56744
Value Function Update Magnitude: 0.65649

Collected Steps per Second: 22,417.81706
Overall Steps per Second: 10,544.56661

Timestep Collection Time: 2.23090
Timestep Consumption Time: 2.51201
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.74292

Cumulative Model Updates: 95,246
Cumulative Timesteps: 794,439,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,241.35847
Policy Entropy: 2.00659
Value Function Loss: 0.08063

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.58426
Value Function Update Magnitude: 0.60779

Collected Steps per Second: 22,407.16441
Overall Steps per Second: 10,543.51691

Timestep Collection Time: 2.23196
Timestep Consumption Time: 2.51142
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.74339

Cumulative Model Updates: 95,252
Cumulative Timesteps: 794,489,962

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 794489962...
Checkpoint 794489962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,153.85080
Policy Entropy: 2.00644
Value Function Loss: 0.09307

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12901
Policy Update Magnitude: 0.60038
Value Function Update Magnitude: 0.68832

Collected Steps per Second: 21,788.10098
Overall Steps per Second: 10,581.21767

Timestep Collection Time: 2.29566
Timestep Consumption Time: 2.43140
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.72706

Cumulative Model Updates: 95,258
Cumulative Timesteps: 794,539,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,922.77281
Policy Entropy: 2.02394
Value Function Loss: 0.09914

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.60451
Value Function Update Magnitude: 0.71229

Collected Steps per Second: 22,344.71003
Overall Steps per Second: 10,567.86497

Timestep Collection Time: 2.23776
Timestep Consumption Time: 2.49376
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.73151

Cumulative Model Updates: 95,264
Cumulative Timesteps: 794,589,982

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 794589982...
Checkpoint 794589982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,600.03499
Policy Entropy: 2.01500
Value Function Loss: 0.10404

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.60307
Value Function Update Magnitude: 0.70719

Collected Steps per Second: 22,040.94767
Overall Steps per Second: 10,509.72591

Timestep Collection Time: 2.26851
Timestep Consumption Time: 2.48899
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.75750

Cumulative Model Updates: 95,270
Cumulative Timesteps: 794,639,982

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,230.36817
Policy Entropy: 2.03228
Value Function Loss: 0.09618

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.16016
Policy Update Magnitude: 0.55202
Value Function Update Magnitude: 0.75283

Collected Steps per Second: 22,569.54032
Overall Steps per Second: 10,602.74146

Timestep Collection Time: 2.21653
Timestep Consumption Time: 2.50169
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.71821

Cumulative Model Updates: 95,276
Cumulative Timesteps: 794,690,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 794690008...
Checkpoint 794690008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,551.69516
Policy Entropy: 2.01281
Value Function Loss: 0.09444

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.15838
Policy Update Magnitude: 0.49284
Value Function Update Magnitude: 0.79259

Collected Steps per Second: 22,017.42807
Overall Steps per Second: 10,475.45214

Timestep Collection Time: 2.27147
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.77421

Cumulative Model Updates: 95,282
Cumulative Timesteps: 794,740,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,828.56939
Policy Entropy: 2.00137
Value Function Loss: 0.08738

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.15473
Policy Update Magnitude: 0.49647
Value Function Update Magnitude: 0.83303

Collected Steps per Second: 22,560.32378
Overall Steps per Second: 10,589.41548

Timestep Collection Time: 2.21637
Timestep Consumption Time: 2.50552
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.72188

Cumulative Model Updates: 95,288
Cumulative Timesteps: 794,790,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 794790022...
Checkpoint 794790022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,817.25363
Policy Entropy: 1.99460
Value Function Loss: 0.08486

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.16832
Policy Update Magnitude: 0.48853
Value Function Update Magnitude: 0.80023

Collected Steps per Second: 21,992.33742
Overall Steps per Second: 10,480.95002

Timestep Collection Time: 2.27388
Timestep Consumption Time: 2.49744
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.77132

Cumulative Model Updates: 95,294
Cumulative Timesteps: 794,840,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,373.94486
Policy Entropy: 1.97570
Value Function Loss: 0.08005

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.17026
Policy Update Magnitude: 0.53909
Value Function Update Magnitude: 0.70309

Collected Steps per Second: 22,797.66703
Overall Steps per Second: 10,657.96239

Timestep Collection Time: 2.19329
Timestep Consumption Time: 2.49822
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.69152

Cumulative Model Updates: 95,300
Cumulative Timesteps: 794,890,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 794890032...
Checkpoint 794890032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,064.28302
Policy Entropy: 1.97920
Value Function Loss: 0.08352

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.16393
Policy Update Magnitude: 0.55495
Value Function Update Magnitude: 0.66817

Collected Steps per Second: 22,530.45385
Overall Steps per Second: 10,541.52599

Timestep Collection Time: 2.21922
Timestep Consumption Time: 2.52393
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.74315

Cumulative Model Updates: 95,306
Cumulative Timesteps: 794,940,032

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,839.15502
Policy Entropy: 1.98422
Value Function Loss: 0.08532

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.16270
Policy Update Magnitude: 0.56563
Value Function Update Magnitude: 0.71561

Collected Steps per Second: 22,390.02833
Overall Steps per Second: 10,768.01270

Timestep Collection Time: 2.23430
Timestep Consumption Time: 2.41150
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.64580

Cumulative Model Updates: 95,312
Cumulative Timesteps: 794,990,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 794990058...
Checkpoint 794990058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,492.65536
Policy Entropy: 1.98899
Value Function Loss: 0.08611

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.17137
Policy Update Magnitude: 0.53110
Value Function Update Magnitude: 0.72011

Collected Steps per Second: 22,140.19820
Overall Steps per Second: 10,634.37447

Timestep Collection Time: 2.25834
Timestep Consumption Time: 2.44340
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.70173

Cumulative Model Updates: 95,318
Cumulative Timesteps: 795,040,058

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,732.03861
Policy Entropy: 1.97515
Value Function Loss: 0.08273

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.15168
Policy Update Magnitude: 0.53306
Value Function Update Magnitude: 0.71961

Collected Steps per Second: 22,448.36680
Overall Steps per Second: 10,545.29873

Timestep Collection Time: 2.22769
Timestep Consumption Time: 2.51452
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.74221

Cumulative Model Updates: 95,324
Cumulative Timesteps: 795,090,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 795090066...
Checkpoint 795090066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,209.81495
Policy Entropy: 1.96470
Value Function Loss: 0.08167

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.16396
Policy Update Magnitude: 0.51468
Value Function Update Magnitude: 0.67449

Collected Steps per Second: 22,183.04408
Overall Steps per Second: 10,607.97115

Timestep Collection Time: 2.25506
Timestep Consumption Time: 2.46064
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.71570

Cumulative Model Updates: 95,330
Cumulative Timesteps: 795,140,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,674.86067
Policy Entropy: 1.95140
Value Function Loss: 0.08595

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.15599
Policy Update Magnitude: 0.50670
Value Function Update Magnitude: 0.61041

Collected Steps per Second: 22,530.45372
Overall Steps per Second: 10,791.14566

Timestep Collection Time: 2.22011
Timestep Consumption Time: 2.41518
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.63528

Cumulative Model Updates: 95,336
Cumulative Timesteps: 795,190,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 795190110...
Checkpoint 795190110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,926.15818
Policy Entropy: 1.95241
Value Function Loss: 0.08552

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.16586
Policy Update Magnitude: 0.48988
Value Function Update Magnitude: 0.57385

Collected Steps per Second: 22,089.18338
Overall Steps per Second: 10,665.89733

Timestep Collection Time: 2.26482
Timestep Consumption Time: 2.42564
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.69046

Cumulative Model Updates: 95,342
Cumulative Timesteps: 795,240,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,964.39239
Policy Entropy: 1.94631
Value Function Loss: 0.08808

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.14936
Policy Update Magnitude: 0.47715
Value Function Update Magnitude: 0.50429

Collected Steps per Second: 22,535.68266
Overall Steps per Second: 10,543.81892

Timestep Collection Time: 2.22057
Timestep Consumption Time: 2.52553
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.74610

Cumulative Model Updates: 95,348
Cumulative Timesteps: 795,290,180

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 795290180...
Checkpoint 795290180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,112.63680
Policy Entropy: 1.93553
Value Function Loss: 0.07967

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14474
Policy Update Magnitude: 0.49229
Value Function Update Magnitude: 0.53414

Collected Steps per Second: 22,059.16759
Overall Steps per Second: 10,703.00201

Timestep Collection Time: 2.26745
Timestep Consumption Time: 2.40582
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.67327

Cumulative Model Updates: 95,354
Cumulative Timesteps: 795,340,198

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,647.91905
Policy Entropy: 1.94937
Value Function Loss: 0.08105

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.14985
Policy Update Magnitude: 0.47569
Value Function Update Magnitude: 0.55491

Collected Steps per Second: 22,038.59760
Overall Steps per Second: 10,463.90305

Timestep Collection Time: 2.26947
Timestep Consumption Time: 2.51039
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.77986

Cumulative Model Updates: 95,360
Cumulative Timesteps: 795,390,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 795390214...
Checkpoint 795390214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,276.14751
Policy Entropy: 1.95304
Value Function Loss: 0.07636

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.52234
Value Function Update Magnitude: 0.55807

Collected Steps per Second: 21,995.68978
Overall Steps per Second: 10,517.09985

Timestep Collection Time: 2.27408
Timestep Consumption Time: 2.48198
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.75606

Cumulative Model Updates: 95,366
Cumulative Timesteps: 795,440,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,664.51467
Policy Entropy: 1.98196
Value Function Loss: 0.07903

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.55356
Value Function Update Magnitude: 0.61806

Collected Steps per Second: 22,307.75287
Overall Steps per Second: 10,502.50662

Timestep Collection Time: 2.24182
Timestep Consumption Time: 2.51990
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.76172

Cumulative Model Updates: 95,372
Cumulative Timesteps: 795,490,244

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 795490244...
Checkpoint 795490244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,140.13486
Policy Entropy: 1.99283
Value Function Loss: 0.07566

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.56709
Value Function Update Magnitude: 0.66367

Collected Steps per Second: 22,267.12660
Overall Steps per Second: 10,697.11974

Timestep Collection Time: 2.24546
Timestep Consumption Time: 2.42869
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.67416

Cumulative Model Updates: 95,378
Cumulative Timesteps: 795,540,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,367.40577
Policy Entropy: 1.99641
Value Function Loss: 0.07654

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.55396
Value Function Update Magnitude: 0.64977

Collected Steps per Second: 22,597.26859
Overall Steps per Second: 10,741.84031

Timestep Collection Time: 2.21407
Timestep Consumption Time: 2.44360
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.65767

Cumulative Model Updates: 95,384
Cumulative Timesteps: 795,590,276

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 795590276...
Checkpoint 795590276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,094.25537
Policy Entropy: 1.99182
Value Function Loss: 0.07536

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.56876
Value Function Update Magnitude: 0.53210

Collected Steps per Second: 21,945.07273
Overall Steps per Second: 10,621.13665

Timestep Collection Time: 2.27896
Timestep Consumption Time: 2.42976
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.70872

Cumulative Model Updates: 95,390
Cumulative Timesteps: 795,640,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,929.22903
Policy Entropy: 1.98399
Value Function Loss: 0.07390

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12222
Policy Update Magnitude: 0.56246
Value Function Update Magnitude: 0.43703

Collected Steps per Second: 22,279.37364
Overall Steps per Second: 10,590.02685

Timestep Collection Time: 2.24557
Timestep Consumption Time: 2.47868
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.72426

Cumulative Model Updates: 95,396
Cumulative Timesteps: 795,690,318

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 795690318...
Checkpoint 795690318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,109.39473
Policy Entropy: 1.97891
Value Function Loss: 0.07633

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.53681
Value Function Update Magnitude: 0.41630

Collected Steps per Second: 22,415.44654
Overall Steps per Second: 10,636.72647

Timestep Collection Time: 2.23141
Timestep Consumption Time: 2.47098
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.70239

Cumulative Model Updates: 95,402
Cumulative Timesteps: 795,740,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,277.13516
Policy Entropy: 1.97108
Value Function Loss: 0.07831

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.15412
Policy Update Magnitude: 0.48907
Value Function Update Magnitude: 0.37007

Collected Steps per Second: 22,564.22774
Overall Steps per Second: 10,578.92080

Timestep Collection Time: 2.21714
Timestep Consumption Time: 2.51189
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.72903

Cumulative Model Updates: 95,408
Cumulative Timesteps: 795,790,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 795790364...
Checkpoint 795790364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,646.58841
Policy Entropy: 1.97988
Value Function Loss: 0.08728

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13054
Policy Update Magnitude: 0.49898
Value Function Update Magnitude: 0.42673

Collected Steps per Second: 22,051.84669
Overall Steps per Second: 10,482.37461

Timestep Collection Time: 2.26938
Timestep Consumption Time: 2.50473
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.77411

Cumulative Model Updates: 95,414
Cumulative Timesteps: 795,840,408

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,951.22109
Policy Entropy: 1.99848
Value Function Loss: 0.08559

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.54296
Value Function Update Magnitude: 0.56668

Collected Steps per Second: 22,334.85817
Overall Steps per Second: 10,465.26200

Timestep Collection Time: 2.23919
Timestep Consumption Time: 2.53967
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.77886

Cumulative Model Updates: 95,420
Cumulative Timesteps: 795,890,420

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 795890420...
Checkpoint 795890420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,053.94051
Policy Entropy: 2.00005
Value Function Loss: 0.08714

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.56020
Value Function Update Magnitude: 0.60040

Collected Steps per Second: 22,259.98103
Overall Steps per Second: 10,656.64579

Timestep Collection Time: 2.24636
Timestep Consumption Time: 2.44592
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.69228

Cumulative Model Updates: 95,426
Cumulative Timesteps: 795,940,424

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,889.42784
Policy Entropy: 1.99673
Value Function Loss: 0.08275

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.55298
Value Function Update Magnitude: 0.64785

Collected Steps per Second: 22,467.77518
Overall Steps per Second: 10,570.47153

Timestep Collection Time: 2.22603
Timestep Consumption Time: 2.50545
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.73148

Cumulative Model Updates: 95,432
Cumulative Timesteps: 795,990,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 795990438...
Checkpoint 795990438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,672.96812
Policy Entropy: 1.99894
Value Function Loss: 0.08375

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.57188
Value Function Update Magnitude: 0.63197

Collected Steps per Second: 22,144.53695
Overall Steps per Second: 10,482.19874

Timestep Collection Time: 2.25889
Timestep Consumption Time: 2.51320
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.77209

Cumulative Model Updates: 95,438
Cumulative Timesteps: 796,040,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,864.87320
Policy Entropy: 1.99854
Value Function Loss: 0.07807

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12988
Policy Update Magnitude: 0.57623
Value Function Update Magnitude: 0.61247

Collected Steps per Second: 22,519.41835
Overall Steps per Second: 10,537.15027

Timestep Collection Time: 2.22093
Timestep Consumption Time: 2.52552
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.74644

Cumulative Model Updates: 95,444
Cumulative Timesteps: 796,090,474

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 796090474...
Checkpoint 796090474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,017.97397
Policy Entropy: 2.00789
Value Function Loss: 0.08361

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.57428
Value Function Update Magnitude: 0.57310

Collected Steps per Second: 22,304.90197
Overall Steps per Second: 10,575.32444

Timestep Collection Time: 2.24381
Timestep Consumption Time: 2.48871
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.73253

Cumulative Model Updates: 95,450
Cumulative Timesteps: 796,140,522

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,845.56878
Policy Entropy: 1.98490
Value Function Loss: 0.08237

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.58289
Value Function Update Magnitude: 0.63221

Collected Steps per Second: 22,443.11030
Overall Steps per Second: 10,538.80271

Timestep Collection Time: 2.22910
Timestep Consumption Time: 2.51793
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.74703

Cumulative Model Updates: 95,456
Cumulative Timesteps: 796,190,550

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 796190550...
Checkpoint 796190550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,814.55042
Policy Entropy: 1.98278
Value Function Loss: 0.08940

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.59462
Value Function Update Magnitude: 0.69258

Collected Steps per Second: 21,915.62419
Overall Steps per Second: 10,570.23086

Timestep Collection Time: 2.28358
Timestep Consumption Time: 2.45104
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.73462

Cumulative Model Updates: 95,462
Cumulative Timesteps: 796,240,596

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,519.65147
Policy Entropy: 1.98436
Value Function Loss: 0.08283

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13902
Policy Update Magnitude: 0.58004
Value Function Update Magnitude: 0.66776

Collected Steps per Second: 22,581.12252
Overall Steps per Second: 10,599.55733

Timestep Collection Time: 2.21512
Timestep Consumption Time: 2.50394
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.71906

Cumulative Model Updates: 95,468
Cumulative Timesteps: 796,290,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 796290616...
Checkpoint 796290616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,705.54845
Policy Entropy: 1.98830
Value Function Loss: 0.08051

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.57049
Value Function Update Magnitude: 0.64208

Collected Steps per Second: 22,321.53112
Overall Steps per Second: 10,507.97313

Timestep Collection Time: 2.24205
Timestep Consumption Time: 2.52062
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.76267

Cumulative Model Updates: 95,474
Cumulative Timesteps: 796,340,662

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,933.44039
Policy Entropy: 1.98739
Value Function Loss: 0.07869

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.56785
Value Function Update Magnitude: 0.63822

Collected Steps per Second: 22,689.39877
Overall Steps per Second: 10,613.36854

Timestep Collection Time: 2.20420
Timestep Consumption Time: 2.50797
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.71217

Cumulative Model Updates: 95,480
Cumulative Timesteps: 796,390,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 796390674...
Checkpoint 796390674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,972.83107
Policy Entropy: 1.98138
Value Function Loss: 0.07953

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.57381
Value Function Update Magnitude: 0.68546

Collected Steps per Second: 22,062.42086
Overall Steps per Second: 10,444.77297

Timestep Collection Time: 2.26720
Timestep Consumption Time: 2.52179
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.78900

Cumulative Model Updates: 95,486
Cumulative Timesteps: 796,440,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,338.07414
Policy Entropy: 1.97649
Value Function Loss: 0.07619

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.54324
Value Function Update Magnitude: 0.70040

Collected Steps per Second: 22,390.51548
Overall Steps per Second: 10,559.77358

Timestep Collection Time: 2.23353
Timestep Consumption Time: 2.50236
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.73590

Cumulative Model Updates: 95,492
Cumulative Timesteps: 796,490,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 796490704...
Checkpoint 796490704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,230.18661
Policy Entropy: 1.97642
Value Function Loss: 0.07566

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.15346
Policy Update Magnitude: 0.49816
Value Function Update Magnitude: 0.61797

Collected Steps per Second: 22,119.53254
Overall Steps per Second: 10,532.06053

Timestep Collection Time: 2.26045
Timestep Consumption Time: 2.48696
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.74741

Cumulative Model Updates: 95,498
Cumulative Timesteps: 796,540,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,463.53605
Policy Entropy: 1.97495
Value Function Loss: 0.08032

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.14426
Policy Update Magnitude: 0.55069
Value Function Update Magnitude: 0.56621

Collected Steps per Second: 22,354.78276
Overall Steps per Second: 10,577.28547

Timestep Collection Time: 2.23702
Timestep Consumption Time: 2.49085
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.72787

Cumulative Model Updates: 95,504
Cumulative Timesteps: 796,590,712

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 796590712...
Checkpoint 796590712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,141.38667
Policy Entropy: 1.96636
Value Function Loss: 0.08416

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.55430
Value Function Update Magnitude: 0.60579

Collected Steps per Second: 21,972.81812
Overall Steps per Second: 10,470.70608

Timestep Collection Time: 2.27599
Timestep Consumption Time: 2.50019
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.77618

Cumulative Model Updates: 95,510
Cumulative Timesteps: 796,640,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,492.09522
Policy Entropy: 1.98089
Value Function Loss: 0.07695

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.16376
Policy Update Magnitude: 0.52297
Value Function Update Magnitude: 0.70325

Collected Steps per Second: 22,643.51264
Overall Steps per Second: 10,588.98627

Timestep Collection Time: 2.20929
Timestep Consumption Time: 2.51506
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.72434

Cumulative Model Updates: 95,516
Cumulative Timesteps: 796,690,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 796690748...
Checkpoint 796690748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,938.63104
Policy Entropy: 1.97773
Value Function Loss: 0.07611

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.14028
Policy Update Magnitude: 0.49305
Value Function Update Magnitude: 0.70924

Collected Steps per Second: 22,360.52455
Overall Steps per Second: 10,540.49709

Timestep Collection Time: 2.23608
Timestep Consumption Time: 2.50753
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.74361

Cumulative Model Updates: 95,522
Cumulative Timesteps: 796,740,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,945.99561
Policy Entropy: 1.99761
Value Function Loss: 0.07418

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.49153
Value Function Update Magnitude: 0.67828

Collected Steps per Second: 22,337.54534
Overall Steps per Second: 10,475.09178

Timestep Collection Time: 2.23910
Timestep Consumption Time: 2.53566
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.77476

Cumulative Model Updates: 95,528
Cumulative Timesteps: 796,790,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 796790764...
Checkpoint 796790764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,696.11571
Policy Entropy: 2.00432
Value Function Loss: 0.07819

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.48554
Value Function Update Magnitude: 0.69106

Collected Steps per Second: 21,697.57648
Overall Steps per Second: 10,518.54033

Timestep Collection Time: 2.30606
Timestep Consumption Time: 2.45087
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.75693

Cumulative Model Updates: 95,534
Cumulative Timesteps: 796,840,800

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,038.47250
Policy Entropy: 2.00631
Value Function Loss: 0.07841

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.52526
Value Function Update Magnitude: 0.63932

Collected Steps per Second: 22,259.92879
Overall Steps per Second: 10,653.48578

Timestep Collection Time: 2.24718
Timestep Consumption Time: 2.44819
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.69536

Cumulative Model Updates: 95,540
Cumulative Timesteps: 796,890,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 796890822...
Checkpoint 796890822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,165.44281
Policy Entropy: 1.99279
Value Function Loss: 0.08359

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.14496
Policy Update Magnitude: 0.56247
Value Function Update Magnitude: 0.60566

Collected Steps per Second: 22,429.55006
Overall Steps per Second: 10,545.81277

Timestep Collection Time: 2.22947
Timestep Consumption Time: 2.51232
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.74179

Cumulative Model Updates: 95,546
Cumulative Timesteps: 796,940,828

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,264.00517
Policy Entropy: 1.97666
Value Function Loss: 0.08480

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.14429
Policy Update Magnitude: 0.58418
Value Function Update Magnitude: 0.61903

Collected Steps per Second: 22,234.59997
Overall Steps per Second: 10,453.58633

Timestep Collection Time: 2.24956
Timestep Consumption Time: 2.53521
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.78477

Cumulative Model Updates: 95,552
Cumulative Timesteps: 796,990,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 796990846...
Checkpoint 796990846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,472.62217
Policy Entropy: 1.96660
Value Function Loss: 0.08471

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.59275
Value Function Update Magnitude: 0.63378

Collected Steps per Second: 22,394.58385
Overall Steps per Second: 10,629.95062

Timestep Collection Time: 2.23509
Timestep Consumption Time: 2.47368
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.70877

Cumulative Model Updates: 95,558
Cumulative Timesteps: 797,040,900

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,277.70568
Policy Entropy: 1.96947
Value Function Loss: 0.08367

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.59892
Value Function Update Magnitude: 0.64770

Collected Steps per Second: 22,454.97288
Overall Steps per Second: 10,540.82064

Timestep Collection Time: 2.22739
Timestep Consumption Time: 2.51759
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.74498

Cumulative Model Updates: 95,564
Cumulative Timesteps: 797,090,916

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 797090916...
Checkpoint 797090916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,268.49211
Policy Entropy: 1.96712
Value Function Loss: 0.07689

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.58243
Value Function Update Magnitude: 0.70975

Collected Steps per Second: 21,878.08924
Overall Steps per Second: 10,641.85734

Timestep Collection Time: 2.28576
Timestep Consumption Time: 2.41342
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.69918

Cumulative Model Updates: 95,570
Cumulative Timesteps: 797,140,924

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,440.70361
Policy Entropy: 1.97940
Value Function Loss: 0.07323

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.56613
Value Function Update Magnitude: 0.70610

Collected Steps per Second: 22,442.62047
Overall Steps per Second: 10,542.86105

Timestep Collection Time: 2.22942
Timestep Consumption Time: 2.51635
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.74577

Cumulative Model Updates: 95,576
Cumulative Timesteps: 797,190,958

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 797190958...
Checkpoint 797190958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,463.06610
Policy Entropy: 1.97659
Value Function Loss: 0.07116

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.55320
Value Function Update Magnitude: 0.67565

Collected Steps per Second: 22,287.15775
Overall Steps per Second: 10,509.51772

Timestep Collection Time: 2.24479
Timestep Consumption Time: 2.51566
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.76045

Cumulative Model Updates: 95,582
Cumulative Timesteps: 797,240,988

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,435.77062
Policy Entropy: 1.98774
Value Function Loss: 0.07860

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.14955
Policy Update Magnitude: 0.51745
Value Function Update Magnitude: 0.69057

Collected Steps per Second: 22,042.94664
Overall Steps per Second: 10,452.85391

Timestep Collection Time: 2.26921
Timestep Consumption Time: 2.51609
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.78530

Cumulative Model Updates: 95,588
Cumulative Timesteps: 797,291,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 797291008...
Checkpoint 797291008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,013.49259
Policy Entropy: 1.98042
Value Function Loss: 0.07779

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.15138
Policy Update Magnitude: 0.48458
Value Function Update Magnitude: 0.68766

Collected Steps per Second: 22,106.24277
Overall Steps per Second: 10,656.44030

Timestep Collection Time: 2.26189
Timestep Consumption Time: 2.43029
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.69219

Cumulative Model Updates: 95,594
Cumulative Timesteps: 797,341,010

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,264.22523
Policy Entropy: 1.96967
Value Function Loss: 0.07404

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12706
Policy Update Magnitude: 0.52590
Value Function Update Magnitude: 0.68554

Collected Steps per Second: 22,435.41678
Overall Steps per Second: 10,558.59523

Timestep Collection Time: 2.22987
Timestep Consumption Time: 2.50826
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.73813

Cumulative Model Updates: 95,600
Cumulative Timesteps: 797,391,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 797391038...
Checkpoint 797391038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,917.33412
Policy Entropy: 1.95152
Value Function Loss: 0.07043

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.56814
Value Function Update Magnitude: 0.70689

Collected Steps per Second: 22,392.74635
Overall Steps per Second: 10,512.15389

Timestep Collection Time: 2.23340
Timestep Consumption Time: 2.52414
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.75754

Cumulative Model Updates: 95,606
Cumulative Timesteps: 797,441,050

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,166.01572
Policy Entropy: 1.95570
Value Function Loss: 0.06978

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.57046
Value Function Update Magnitude: 0.68419

Collected Steps per Second: 22,254.09941
Overall Steps per Second: 10,488.26080

Timestep Collection Time: 2.24696
Timestep Consumption Time: 2.52066
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.76762

Cumulative Model Updates: 95,612
Cumulative Timesteps: 797,491,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 797491054...
Checkpoint 797491054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,738.08639
Policy Entropy: 1.96006
Value Function Loss: 0.07303

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.55415
Value Function Update Magnitude: 0.70040

Collected Steps per Second: 21,800.62949
Overall Steps per Second: 10,564.25569

Timestep Collection Time: 2.29452
Timestep Consumption Time: 2.44050
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.73502

Cumulative Model Updates: 95,618
Cumulative Timesteps: 797,541,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,228.42138
Policy Entropy: 1.96666
Value Function Loss: 0.07009

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.14844
Policy Update Magnitude: 0.54834
Value Function Update Magnitude: 0.69078

Collected Steps per Second: 22,676.38774
Overall Steps per Second: 10,610.20742

Timestep Collection Time: 2.20564
Timestep Consumption Time: 2.50831
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.71395

Cumulative Model Updates: 95,624
Cumulative Timesteps: 797,591,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 797591092...
Checkpoint 797591092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,235.13005
Policy Entropy: 1.97804
Value Function Loss: 0.07046

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.56695
Value Function Update Magnitude: 0.64764

Collected Steps per Second: 22,467.99647
Overall Steps per Second: 10,539.23069

Timestep Collection Time: 2.22672
Timestep Consumption Time: 2.52030
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.74703

Cumulative Model Updates: 95,630
Cumulative Timesteps: 797,641,122

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,443.46988
Policy Entropy: 1.97065
Value Function Loss: 0.06764

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.56735
Value Function Update Magnitude: 0.64155

Collected Steps per Second: 22,614.94097
Overall Steps per Second: 10,650.07070

Timestep Collection Time: 2.21110
Timestep Consumption Time: 2.48408
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.69518

Cumulative Model Updates: 95,636
Cumulative Timesteps: 797,691,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 797691126...
Checkpoint 797691126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,238.78971
Policy Entropy: 1.97369
Value Function Loss: 0.06969

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.56626
Value Function Update Magnitude: 0.65736

Collected Steps per Second: 22,137.83184
Overall Steps per Second: 10,484.81329

Timestep Collection Time: 2.25921
Timestep Consumption Time: 2.51093
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.77014

Cumulative Model Updates: 95,642
Cumulative Timesteps: 797,741,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,783.40139
Policy Entropy: 1.97151
Value Function Loss: 0.07299

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.56186
Value Function Update Magnitude: 0.64627

Collected Steps per Second: 22,449.48272
Overall Steps per Second: 10,570.73960

Timestep Collection Time: 2.22731
Timestep Consumption Time: 2.50292
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.73023

Cumulative Model Updates: 95,648
Cumulative Timesteps: 797,791,142

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 797791142...
Checkpoint 797791142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,686.52238
Policy Entropy: 1.96526
Value Function Loss: 0.07840

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.57364
Value Function Update Magnitude: 0.60493

Collected Steps per Second: 22,425.58978
Overall Steps per Second: 10,557.07240

Timestep Collection Time: 2.22995
Timestep Consumption Time: 2.50697
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.73692

Cumulative Model Updates: 95,654
Cumulative Timesteps: 797,841,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,148.70347
Policy Entropy: 1.98308
Value Function Loss: 0.08009

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.57375
Value Function Update Magnitude: 0.65984

Collected Steps per Second: 21,890.68969
Overall Steps per Second: 10,746.88694

Timestep Collection Time: 2.28444
Timestep Consumption Time: 2.36881
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.65325

Cumulative Model Updates: 95,660
Cumulative Timesteps: 797,891,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 797891158...
Checkpoint 797891158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,476.20439
Policy Entropy: 1.99386
Value Function Loss: 0.07546

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13354
Policy Update Magnitude: 0.57387
Value Function Update Magnitude: 0.66091

Collected Steps per Second: 21,383.52483
Overall Steps per Second: 10,667.45574

Timestep Collection Time: 2.33937
Timestep Consumption Time: 2.35003
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.68940

Cumulative Model Updates: 95,666
Cumulative Timesteps: 797,941,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,213.48524
Policy Entropy: 2.00476
Value Function Loss: 0.07275

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.56682
Value Function Update Magnitude: 0.67324

Collected Steps per Second: 21,680.41780
Overall Steps per Second: 10,496.26722

Timestep Collection Time: 2.30826
Timestep Consumption Time: 2.45953
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.76779

Cumulative Model Updates: 95,672
Cumulative Timesteps: 797,991,226

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 797991226...
Checkpoint 797991226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,775.36558
Policy Entropy: 2.00360
Value Function Loss: 0.07362

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.57052
Value Function Update Magnitude: 0.65840

Collected Steps per Second: 21,472.35391
Overall Steps per Second: 10,618.49574

Timestep Collection Time: 2.32895
Timestep Consumption Time: 2.38057
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.70952

Cumulative Model Updates: 95,678
Cumulative Timesteps: 798,041,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,881.20662
Policy Entropy: 2.00621
Value Function Loss: 0.08214

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.58310
Value Function Update Magnitude: 0.59970

Collected Steps per Second: 21,980.53277
Overall Steps per Second: 10,620.93428

Timestep Collection Time: 2.27501
Timestep Consumption Time: 2.43324
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.70825

Cumulative Model Updates: 95,684
Cumulative Timesteps: 798,091,240

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 798091240...
Checkpoint 798091240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,187.10165
Policy Entropy: 2.00373
Value Function Loss: 0.08168

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13571
Policy Update Magnitude: 0.58431
Value Function Update Magnitude: 0.50718

Collected Steps per Second: 21,632.38980
Overall Steps per Second: 10,536.92469

Timestep Collection Time: 2.31292
Timestep Consumption Time: 2.43552
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.74844

Cumulative Model Updates: 95,690
Cumulative Timesteps: 798,141,274

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,881.00365
Policy Entropy: 1.99606
Value Function Loss: 0.08359

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.57986
Value Function Update Magnitude: 0.53482

Collected Steps per Second: 21,761.40041
Overall Steps per Second: 10,566.29516

Timestep Collection Time: 2.29847
Timestep Consumption Time: 2.43526
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.73373

Cumulative Model Updates: 95,696
Cumulative Timesteps: 798,191,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 798191292...
Checkpoint 798191292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,636.50809
Policy Entropy: 1.97713
Value Function Loss: 0.07868

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.57463
Value Function Update Magnitude: 0.51464

Collected Steps per Second: 21,387.06051
Overall Steps per Second: 10,505.64641

Timestep Collection Time: 2.33861
Timestep Consumption Time: 2.42226
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.76087

Cumulative Model Updates: 95,702
Cumulative Timesteps: 798,241,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,573.45470
Policy Entropy: 1.96975
Value Function Loss: 0.08303

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13216
Policy Update Magnitude: 0.57802
Value Function Update Magnitude: 0.50236

Collected Steps per Second: 22,682.16589
Overall Steps per Second: 10,816.88526

Timestep Collection Time: 2.20517
Timestep Consumption Time: 2.41890
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.62407

Cumulative Model Updates: 95,708
Cumulative Timesteps: 798,291,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 798291326...
Checkpoint 798291326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,006.50167
Policy Entropy: 1.96317
Value Function Loss: 0.07880

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13304
Policy Update Magnitude: 0.58333
Value Function Update Magnitude: 0.59120

Collected Steps per Second: 22,324.33122
Overall Steps per Second: 10,712.81714

Timestep Collection Time: 2.24087
Timestep Consumption Time: 2.42886
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.66973

Cumulative Model Updates: 95,714
Cumulative Timesteps: 798,341,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,336.99343
Policy Entropy: 1.96190
Value Function Loss: 0.07816

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.58141
Value Function Update Magnitude: 0.66586

Collected Steps per Second: 21,757.67380
Overall Steps per Second: 10,456.58855

Timestep Collection Time: 2.29896
Timestep Consumption Time: 2.48463
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.78359

Cumulative Model Updates: 95,720
Cumulative Timesteps: 798,391,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 798391372...
Checkpoint 798391372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,524.56059
Policy Entropy: 1.96164
Value Function Loss: 0.07546

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.55919
Value Function Update Magnitude: 0.70686

Collected Steps per Second: 21,642.52131
Overall Steps per Second: 10,582.84068

Timestep Collection Time: 2.31138
Timestep Consumption Time: 2.41552
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.72690

Cumulative Model Updates: 95,726
Cumulative Timesteps: 798,441,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,383.28588
Policy Entropy: 1.96624
Value Function Loss: 0.08162

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.15488
Policy Update Magnitude: 0.50271
Value Function Update Magnitude: 0.70703

Collected Steps per Second: 22,388.52934
Overall Steps per Second: 10,612.46234

Timestep Collection Time: 2.23418
Timestep Consumption Time: 2.47915
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.71333

Cumulative Model Updates: 95,732
Cumulative Timesteps: 798,491,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 798491416...
Checkpoint 798491416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,976.32232
Policy Entropy: 1.96841
Value Function Loss: 0.08035

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.15242
Policy Update Magnitude: 0.50602
Value Function Update Magnitude: 0.66746

Collected Steps per Second: 22,305.72739
Overall Steps per Second: 10,553.70744

Timestep Collection Time: 2.24292
Timestep Consumption Time: 2.49759
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.74051

Cumulative Model Updates: 95,738
Cumulative Timesteps: 798,541,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,863.10383
Policy Entropy: 1.96008
Value Function Loss: 0.08541

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.14944
Policy Update Magnitude: 0.46664
Value Function Update Magnitude: 0.65540

Collected Steps per Second: 22,253.24567
Overall Steps per Second: 10,481.91780

Timestep Collection Time: 2.24776
Timestep Consumption Time: 2.52427
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.77203

Cumulative Model Updates: 95,744
Cumulative Timesteps: 798,591,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 798591466...
Checkpoint 798591466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,048.23648
Policy Entropy: 1.95584
Value Function Loss: 0.08604

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 0.49220
Value Function Update Magnitude: 0.55010

Collected Steps per Second: 22,283.87799
Overall Steps per Second: 10,622.51977

Timestep Collection Time: 2.24602
Timestep Consumption Time: 2.46567
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.71169

Cumulative Model Updates: 95,750
Cumulative Timesteps: 798,641,516

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,023.31094
Policy Entropy: 1.95076
Value Function Loss: 0.08580

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.15119
Policy Update Magnitude: 0.48107
Value Function Update Magnitude: 0.49492

Collected Steps per Second: 22,693.52215
Overall Steps per Second: 10,638.17454

Timestep Collection Time: 2.20380
Timestep Consumption Time: 2.49738
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.70118

Cumulative Model Updates: 95,756
Cumulative Timesteps: 798,691,528

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 798691528...
Checkpoint 798691528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,595.05714
Policy Entropy: 1.94455
Value Function Loss: 0.08040

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.49799
Value Function Update Magnitude: 0.52263

Collected Steps per Second: 22,205.37812
Overall Steps per Second: 10,506.65569

Timestep Collection Time: 2.25216
Timestep Consumption Time: 2.50768
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.75984

Cumulative Model Updates: 95,762
Cumulative Timesteps: 798,741,538

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,474.65778
Policy Entropy: 1.93534
Value Function Loss: 0.07792

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.51914
Value Function Update Magnitude: 0.58847

Collected Steps per Second: 21,724.27902
Overall Steps per Second: 10,378.33087

Timestep Collection Time: 2.30369
Timestep Consumption Time: 2.51847
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.82216

Cumulative Model Updates: 95,768
Cumulative Timesteps: 798,791,584

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 798791584...
Checkpoint 798791584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,063.00331
Policy Entropy: 1.95464
Value Function Loss: 0.07922

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12839
Policy Update Magnitude: 0.56036
Value Function Update Magnitude: 0.50964

Collected Steps per Second: 21,096.46161
Overall Steps per Second: 10,201.99426

Timestep Collection Time: 2.37016
Timestep Consumption Time: 2.53104
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.90120

Cumulative Model Updates: 95,774
Cumulative Timesteps: 798,841,586

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,940.21544
Policy Entropy: 1.94528
Value Function Loss: 0.08609

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.59145
Value Function Update Magnitude: 0.43343

Collected Steps per Second: 22,596.09028
Overall Steps per Second: 10,573.22628

Timestep Collection Time: 2.21454
Timestep Consumption Time: 2.51817
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.73271

Cumulative Model Updates: 95,780
Cumulative Timesteps: 798,891,626

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 798891626...
Checkpoint 798891626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,759.37076
Policy Entropy: 1.95572
Value Function Loss: 0.08351

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.58329
Value Function Update Magnitude: 0.38011

Collected Steps per Second: 21,795.86567
Overall Steps per Second: 10,569.10952

Timestep Collection Time: 2.29456
Timestep Consumption Time: 2.43734
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.73190

Cumulative Model Updates: 95,786
Cumulative Timesteps: 798,941,638

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,663.46521
Policy Entropy: 1.93960
Value Function Loss: 0.08021

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.57758
Value Function Update Magnitude: 0.35951

Collected Steps per Second: 22,296.56590
Overall Steps per Second: 10,521.66139

Timestep Collection Time: 2.24322
Timestep Consumption Time: 2.51041
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.75362

Cumulative Model Updates: 95,792
Cumulative Timesteps: 798,991,654

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 798991654...
Checkpoint 798991654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,057.48594
Policy Entropy: 1.93832
Value Function Loss: 0.07305

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.57452
Value Function Update Magnitude: 0.46588

Collected Steps per Second: 22,293.70689
Overall Steps per Second: 10,539.07894

Timestep Collection Time: 2.24368
Timestep Consumption Time: 2.50246
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.74615

Cumulative Model Updates: 95,798
Cumulative Timesteps: 799,041,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,397.04560
Policy Entropy: 1.93722
Value Function Loss: 0.07325

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.56511
Value Function Update Magnitude: 0.57990

Collected Steps per Second: 22,510.97123
Overall Steps per Second: 10,586.37376

Timestep Collection Time: 2.22158
Timestep Consumption Time: 2.50241
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.72400

Cumulative Model Updates: 95,804
Cumulative Timesteps: 799,091,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 799091684...
Checkpoint 799091684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,213.93790
Policy Entropy: 1.95251
Value Function Loss: 0.07054

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.56983
Value Function Update Magnitude: 0.59436

Collected Steps per Second: 22,059.91041
Overall Steps per Second: 10,499.96019

Timestep Collection Time: 2.26701
Timestep Consumption Time: 2.49587
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.76288

Cumulative Model Updates: 95,810
Cumulative Timesteps: 799,141,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,408.14293
Policy Entropy: 1.95640
Value Function Loss: 0.07465

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.57947
Value Function Update Magnitude: 0.57102

Collected Steps per Second: 22,520.42534
Overall Steps per Second: 10,617.31474

Timestep Collection Time: 2.22198
Timestep Consumption Time: 2.49107
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.71306

Cumulative Model Updates: 95,816
Cumulative Timesteps: 799,191,734

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 799191734...
Checkpoint 799191734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,128.63203
Policy Entropy: 1.94524
Value Function Loss: 0.08083

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.14863
Policy Update Magnitude: 0.58250
Value Function Update Magnitude: 0.56051

Collected Steps per Second: 22,359.88492
Overall Steps per Second: 10,520.47701

Timestep Collection Time: 2.23758
Timestep Consumption Time: 2.51810
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.75568

Cumulative Model Updates: 95,822
Cumulative Timesteps: 799,241,766

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,660.36295
Policy Entropy: 1.93808
Value Function Loss: 0.08380

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.15349
Policy Update Magnitude: 0.57585
Value Function Update Magnitude: 0.57502

Collected Steps per Second: 22,224.13745
Overall Steps per Second: 10,540.80085

Timestep Collection Time: 2.24981
Timestep Consumption Time: 2.49367
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.74347

Cumulative Model Updates: 95,828
Cumulative Timesteps: 799,291,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 799291766...
Checkpoint 799291766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,999.30370
Policy Entropy: 1.95001
Value Function Loss: 0.08442

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.15777
Policy Update Magnitude: 0.59064
Value Function Update Magnitude: 0.72665

Collected Steps per Second: 22,422.76038
Overall Steps per Second: 10,560.01489

Timestep Collection Time: 2.22997
Timestep Consumption Time: 2.50506
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.73503

Cumulative Model Updates: 95,834
Cumulative Timesteps: 799,341,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,119.83307
Policy Entropy: 1.96004
Value Function Loss: 0.09183

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.17789
Policy Update Magnitude: 0.57169
Value Function Update Magnitude: 0.70109

Collected Steps per Second: 22,528.47203
Overall Steps per Second: 10,765.37460

Timestep Collection Time: 2.21950
Timestep Consumption Time: 2.42520
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.64471

Cumulative Model Updates: 95,840
Cumulative Timesteps: 799,391,770

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 799391770...
Checkpoint 799391770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,309.50889
Policy Entropy: 1.95893
Value Function Loss: 0.09347

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.17895
Policy Update Magnitude: 0.49267
Value Function Update Magnitude: 0.55330

Collected Steps per Second: 21,550.73609
Overall Steps per Second: 10,683.34398

Timestep Collection Time: 2.32085
Timestep Consumption Time: 2.36083
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.68168

Cumulative Model Updates: 95,846
Cumulative Timesteps: 799,441,786

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,237.55221
Policy Entropy: 1.95686
Value Function Loss: 0.09399

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.16272
Policy Update Magnitude: 0.47738
Value Function Update Magnitude: 0.45017

Collected Steps per Second: 21,523.00379
Overall Steps per Second: 10,501.02466

Timestep Collection Time: 2.32421
Timestep Consumption Time: 2.43951
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.76373

Cumulative Model Updates: 95,852
Cumulative Timesteps: 799,491,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 799491810...
Checkpoint 799491810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,705.05210
Policy Entropy: 1.96802
Value Function Loss: 0.08581

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.15128
Policy Update Magnitude: 0.51658
Value Function Update Magnitude: 0.42087

Collected Steps per Second: 21,626.78110
Overall Steps per Second: 10,626.36730

Timestep Collection Time: 2.31324
Timestep Consumption Time: 2.39467
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.70791

Cumulative Model Updates: 95,858
Cumulative Timesteps: 799,541,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,474.20199
Policy Entropy: 1.97415
Value Function Loss: 0.07729

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.17543
Policy Update Magnitude: 0.53238
Value Function Update Magnitude: 0.44577

Collected Steps per Second: 21,870.30494
Overall Steps per Second: 10,587.21144

Timestep Collection Time: 2.28758
Timestep Consumption Time: 2.43794
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.72551

Cumulative Model Updates: 95,864
Cumulative Timesteps: 799,591,868

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 799591868...
Checkpoint 799591868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,003.57302
Policy Entropy: 1.98434
Value Function Loss: 0.07339

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.15805
Policy Update Magnitude: 0.52035
Value Function Update Magnitude: 0.48977

Collected Steps per Second: 21,411.46882
Overall Steps per Second: 10,511.00319

Timestep Collection Time: 2.33632
Timestep Consumption Time: 2.42289
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.75920

Cumulative Model Updates: 95,870
Cumulative Timesteps: 799,641,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,376.16810
Policy Entropy: 1.96469
Value Function Loss: 0.07168

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.15059
Policy Update Magnitude: 0.53847
Value Function Update Magnitude: 0.57261

Collected Steps per Second: 22,212.09616
Overall Steps per Second: 10,529.81708

Timestep Collection Time: 2.25184
Timestep Consumption Time: 2.49829
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.75013

Cumulative Model Updates: 95,876
Cumulative Timesteps: 799,691,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 799691910...
Checkpoint 799691910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,968.67492
Policy Entropy: 1.95930
Value Function Loss: 0.07457

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.57666
Value Function Update Magnitude: 0.61392

Collected Steps per Second: 21,971.68066
Overall Steps per Second: 10,569.49115

Timestep Collection Time: 2.27602
Timestep Consumption Time: 2.45533
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.73135

Cumulative Model Updates: 95,882
Cumulative Timesteps: 799,741,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,490.93085
Policy Entropy: 1.96158
Value Function Loss: 0.07623

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.57524
Value Function Update Magnitude: 0.58608

Collected Steps per Second: 22,649.25351
Overall Steps per Second: 10,809.17348

Timestep Collection Time: 2.20828
Timestep Consumption Time: 2.41890
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.62718

Cumulative Model Updates: 95,888
Cumulative Timesteps: 799,791,934

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 799791934...
Checkpoint 799791934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,963.44972
Policy Entropy: 1.95270
Value Function Loss: 0.07268

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.56696
Value Function Update Magnitude: 0.66797

Collected Steps per Second: 22,099.34207
Overall Steps per Second: 10,685.62825

Timestep Collection Time: 2.26351
Timestep Consumption Time: 2.41773
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.68124

Cumulative Model Updates: 95,894
Cumulative Timesteps: 799,841,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,625.76205
Policy Entropy: 1.96674
Value Function Loss: 0.07812

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.57454
Value Function Update Magnitude: 0.61441

Collected Steps per Second: 22,153.12873
Overall Steps per Second: 10,490.85998

Timestep Collection Time: 2.25765
Timestep Consumption Time: 2.50974
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.76739

Cumulative Model Updates: 95,900
Cumulative Timesteps: 799,891,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 799891970...
Checkpoint 799891970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,357.04951
Policy Entropy: 1.95575
Value Function Loss: 0.08035

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.14040
Policy Update Magnitude: 0.55896
Value Function Update Magnitude: 0.52173

Collected Steps per Second: 22,129.34867
Overall Steps per Second: 10,666.82058

Timestep Collection Time: 2.26152
Timestep Consumption Time: 2.43022
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.69174

Cumulative Model Updates: 95,906
Cumulative Timesteps: 799,942,016

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,587.04318
Policy Entropy: 1.95631
Value Function Loss: 0.08405

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.15808
Policy Update Magnitude: 0.51090
Value Function Update Magnitude: 0.42646

Collected Steps per Second: 22,448.13665
Overall Steps per Second: 10,475.86768

Timestep Collection Time: 2.22834
Timestep Consumption Time: 2.54664
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.77497

Cumulative Model Updates: 95,912
Cumulative Timesteps: 799,992,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 799992038...
Checkpoint 799992038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,357.58636
Policy Entropy: 1.94305
Value Function Loss: 0.08169

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.15728
Policy Update Magnitude: 0.55457
Value Function Update Magnitude: 0.40283

Collected Steps per Second: 21,877.07737
Overall Steps per Second: 10,568.51675

Timestep Collection Time: 2.28714
Timestep Consumption Time: 2.44730
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.73444

Cumulative Model Updates: 95,918
Cumulative Timesteps: 800,042,074

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,776.63812
Policy Entropy: 1.94165
Value Function Loss: 0.07744

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.16000
Policy Update Magnitude: 0.57024
Value Function Update Magnitude: 0.56788

Collected Steps per Second: 22,516.95399
Overall Steps per Second: 10,563.68335

Timestep Collection Time: 2.22170
Timestep Consumption Time: 2.51396
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.73566

Cumulative Model Updates: 95,924
Cumulative Timesteps: 800,092,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 800092100...
Checkpoint 800092100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,731.09164
Policy Entropy: 1.94132
Value Function Loss: 0.07287

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.14827
Policy Update Magnitude: 0.56802
Value Function Update Magnitude: 0.68063

Collected Steps per Second: 22,097.77705
Overall Steps per Second: 10,636.83397

Timestep Collection Time: 2.26358
Timestep Consumption Time: 2.43895
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.70253

Cumulative Model Updates: 95,930
Cumulative Timesteps: 800,142,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,125.91411
Policy Entropy: 1.95474
Value Function Loss: 0.07589

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.15528
Policy Update Magnitude: 0.51834
Value Function Update Magnitude: 0.69493

Collected Steps per Second: 22,354.61754
Overall Steps per Second: 10,572.60810

Timestep Collection Time: 2.23712
Timestep Consumption Time: 2.49303
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.73015

Cumulative Model Updates: 95,936
Cumulative Timesteps: 800,192,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 800192130...
Checkpoint 800192130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,876.82653
Policy Entropy: 1.97513
Value Function Loss: 0.07518

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.14505
Policy Update Magnitude: 0.51956
Value Function Update Magnitude: 0.62802

Collected Steps per Second: 22,079.30253
Overall Steps per Second: 10,465.00051

Timestep Collection Time: 2.26502
Timestep Consumption Time: 2.51377
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.77879

Cumulative Model Updates: 95,942
Cumulative Timesteps: 800,242,140

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,158.50110
Policy Entropy: 1.99024
Value Function Loss: 0.07588

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.56034
Value Function Update Magnitude: 0.62259

Collected Steps per Second: 22,357.18903
Overall Steps per Second: 10,542.13767

Timestep Collection Time: 2.23767
Timestep Consumption Time: 2.50786
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.74553

Cumulative Model Updates: 95,948
Cumulative Timesteps: 800,292,168

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 800292168...
Checkpoint 800292168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,200.75275
Policy Entropy: 1.98626
Value Function Loss: 0.07246

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.57897
Value Function Update Magnitude: 0.64289

Collected Steps per Second: 22,289.96343
Overall Steps per Second: 10,548.78646

Timestep Collection Time: 2.24334
Timestep Consumption Time: 2.49692
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.74026

Cumulative Model Updates: 95,954
Cumulative Timesteps: 800,342,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,824.31508
Policy Entropy: 1.98920
Value Function Loss: 0.07898

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13691
Policy Update Magnitude: 0.59095
Value Function Update Magnitude: 0.66895

Collected Steps per Second: 22,731.69177
Overall Steps per Second: 10,840.17513

Timestep Collection Time: 2.20019
Timestep Consumption Time: 2.41357
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.61376

Cumulative Model Updates: 95,960
Cumulative Timesteps: 800,392,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 800392186...
Checkpoint 800392186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,737.45802
Policy Entropy: 1.96729
Value Function Loss: 0.08094

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.59388
Value Function Update Magnitude: 0.70268

Collected Steps per Second: 21,924.55089
Overall Steps per Second: 10,479.33399

Timestep Collection Time: 2.28128
Timestep Consumption Time: 2.49154
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.77282

Cumulative Model Updates: 95,966
Cumulative Timesteps: 800,442,202

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,727.32293
Policy Entropy: 1.97038
Value Function Loss: 0.07944

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.58457
Value Function Update Magnitude: 0.66986

Collected Steps per Second: 22,607.39360
Overall Steps per Second: 10,751.38943

Timestep Collection Time: 2.21202
Timestep Consumption Time: 2.43929
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.65131

Cumulative Model Updates: 95,972
Cumulative Timesteps: 800,492,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 800492210...
Checkpoint 800492210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,996.94799
Policy Entropy: 1.95893
Value Function Loss: 0.07541

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.57335
Value Function Update Magnitude: 0.62651

Collected Steps per Second: 22,369.14293
Overall Steps per Second: 10,602.49836

Timestep Collection Time: 2.23540
Timestep Consumption Time: 2.48085
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.71625

Cumulative Model Updates: 95,978
Cumulative Timesteps: 800,542,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,185.88834
Policy Entropy: 1.97649
Value Function Loss: 0.07703

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.12965
Policy Update Magnitude: 0.57515
Value Function Update Magnitude: 0.62380

Collected Steps per Second: 22,325.18865
Overall Steps per Second: 10,476.93327

Timestep Collection Time: 2.24159
Timestep Consumption Time: 2.53500
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.77659

Cumulative Model Updates: 95,984
Cumulative Timesteps: 800,592,258

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 800592258...
Checkpoint 800592258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,395.80714
Policy Entropy: 1.97450
Value Function Loss: 0.07742

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.58156
Value Function Update Magnitude: 0.69617

Collected Steps per Second: 21,749.99933
Overall Steps per Second: 10,531.17058

Timestep Collection Time: 2.29894
Timestep Consumption Time: 2.44906
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.74800

Cumulative Model Updates: 95,990
Cumulative Timesteps: 800,642,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,381.54877
Policy Entropy: 1.98817
Value Function Loss: 0.07701

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.58633
Value Function Update Magnitude: 0.74028

Collected Steps per Second: 14,110.73271
Overall Steps per Second: 6,926.50826

Timestep Collection Time: 3.54652
Timestep Consumption Time: 3.67848
PPO Batch Consumption Time: 0.45909
Total Iteration Time: 7.22500

Cumulative Model Updates: 95,996
Cumulative Timesteps: 800,692,304

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 800692304...
Checkpoint 800692304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,128.96627
Policy Entropy: 1.99803
Value Function Loss: 0.08520

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.14136
Policy Update Magnitude: 0.59103
Value Function Update Magnitude: 0.79012

Collected Steps per Second: 13,862.28566
Overall Steps per Second: 7,835.48919

Timestep Collection Time: 3.60806
Timestep Consumption Time: 2.77520
PPO Batch Consumption Time: 0.31150
Total Iteration Time: 6.38326

Cumulative Model Updates: 96,002
Cumulative Timesteps: 800,742,320

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,318.49299
Policy Entropy: 2.01010
Value Function Loss: 0.08219

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.16325
Policy Update Magnitude: 0.55168
Value Function Update Magnitude: 0.81897

Collected Steps per Second: 19,945.87350
Overall Steps per Second: 9,757.88834

Timestep Collection Time: 2.50879
Timestep Consumption Time: 2.61937
PPO Batch Consumption Time: 0.31331
Total Iteration Time: 5.12816

Cumulative Model Updates: 96,008
Cumulative Timesteps: 800,792,360

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 800792360...
Checkpoint 800792360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,094.76382
Policy Entropy: 1.98991
Value Function Loss: 0.07617

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.15631
Policy Update Magnitude: 0.56328
Value Function Update Magnitude: 0.80469

Collected Steps per Second: 18,924.05092
Overall Steps per Second: 9,737.74646

Timestep Collection Time: 2.64235
Timestep Consumption Time: 2.49272
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 5.13507

Cumulative Model Updates: 96,014
Cumulative Timesteps: 800,842,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,961.29434
Policy Entropy: 1.98112
Value Function Loss: 0.06820

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.15708
Policy Update Magnitude: 0.54307
Value Function Update Magnitude: 0.76593

Collected Steps per Second: 19,622.60279
Overall Steps per Second: 9,556.24325

Timestep Collection Time: 2.54961
Timestep Consumption Time: 2.68571
PPO Batch Consumption Time: 0.31418
Total Iteration Time: 5.23532

Cumulative Model Updates: 96,020
Cumulative Timesteps: 800,892,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 800892394...
Checkpoint 800892394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,542.69172
Policy Entropy: 1.97675
Value Function Loss: 0.07499

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.14798
Policy Update Magnitude: 0.56770
Value Function Update Magnitude: 0.75852

Collected Steps per Second: 20,431.07109
Overall Steps per Second: 9,835.96300

Timestep Collection Time: 2.44823
Timestep Consumption Time: 2.63719
PPO Batch Consumption Time: 0.30940
Total Iteration Time: 5.08542

Cumulative Model Updates: 96,026
Cumulative Timesteps: 800,942,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,232.91287
Policy Entropy: 1.99465
Value Function Loss: 0.07761

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13680
Policy Update Magnitude: 0.58252
Value Function Update Magnitude: 0.75112

Collected Steps per Second: 20,104.95791
Overall Steps per Second: 9,780.31166

Timestep Collection Time: 2.48854
Timestep Consumption Time: 2.62704
PPO Batch Consumption Time: 0.30613
Total Iteration Time: 5.11558

Cumulative Model Updates: 96,032
Cumulative Timesteps: 800,992,446

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 800992446...
Checkpoint 800992446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,555.69739
Policy Entropy: 1.99004
Value Function Loss: 0.07892

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.58284
Value Function Update Magnitude: 0.56818

Collected Steps per Second: 19,869.36733
Overall Steps per Second: 9,960.78161

Timestep Collection Time: 2.51724
Timestep Consumption Time: 2.50405
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 5.02129

Cumulative Model Updates: 96,038
Cumulative Timesteps: 801,042,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,114.27954
Policy Entropy: 1.97532
Value Function Loss: 0.08039

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12334
Policy Update Magnitude: 0.57623
Value Function Update Magnitude: 0.44391

Collected Steps per Second: 20,235.80693
Overall Steps per Second: 9,906.67158

Timestep Collection Time: 2.47225
Timestep Consumption Time: 2.57768
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 5.04993

Cumulative Model Updates: 96,044
Cumulative Timesteps: 801,092,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 801092490...
Checkpoint 801092490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,079.32366
Policy Entropy: 1.96494
Value Function Loss: 0.08664

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.58003
Value Function Update Magnitude: 0.40442

Collected Steps per Second: 19,168.03068
Overall Steps per Second: 9,800.89858

Timestep Collection Time: 2.60976
Timestep Consumption Time: 2.49426
PPO Batch Consumption Time: 0.30182
Total Iteration Time: 5.10402

Cumulative Model Updates: 96,050
Cumulative Timesteps: 801,142,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,455.55187
Policy Entropy: 1.97700
Value Function Loss: 0.08935

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.54834
Value Function Update Magnitude: 0.45212

Collected Steps per Second: 21,858.00278
Overall Steps per Second: 10,279.49393

Timestep Collection Time: 2.28841
Timestep Consumption Time: 2.57759
PPO Batch Consumption Time: 0.30120
Total Iteration Time: 4.86600

Cumulative Model Updates: 96,056
Cumulative Timesteps: 801,192,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 801192534...
Checkpoint 801192534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,811.87370
Policy Entropy: 1.99987
Value Function Loss: 0.09135

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14616
Policy Update Magnitude: 0.53786
Value Function Update Magnitude: 0.44362

Collected Steps per Second: 19,164.05506
Overall Steps per Second: 9,607.86010

Timestep Collection Time: 2.61030
Timestep Consumption Time: 2.59627
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 5.20657

Cumulative Model Updates: 96,062
Cumulative Timesteps: 801,242,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,908.67120
Policy Entropy: 2.00274
Value Function Loss: 0.09378

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.15713
Policy Update Magnitude: 0.50079
Value Function Update Magnitude: 0.44218

Collected Steps per Second: 18,650.08689
Overall Steps per Second: 9,550.49072

Timestep Collection Time: 2.68192
Timestep Consumption Time: 2.55530
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 5.23722

Cumulative Model Updates: 96,068
Cumulative Timesteps: 801,292,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 801292576...
Checkpoint 801292576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,046.94555
Policy Entropy: 1.99872
Value Function Loss: 0.08782

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.15647
Policy Update Magnitude: 0.47694
Value Function Update Magnitude: 0.39301

Collected Steps per Second: 18,571.07656
Overall Steps per Second: 9,253.86934

Timestep Collection Time: 2.69473
Timestep Consumption Time: 2.71317
PPO Batch Consumption Time: 0.31104
Total Iteration Time: 5.40790

Cumulative Model Updates: 96,074
Cumulative Timesteps: 801,342,620

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,347.99381
Policy Entropy: 1.97667
Value Function Loss: 0.08297

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.52711
Value Function Update Magnitude: 0.40116

Collected Steps per Second: 20,966.27665
Overall Steps per Second: 10,171.10952

Timestep Collection Time: 2.38631
Timestep Consumption Time: 2.53272
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.91903

Cumulative Model Updates: 96,080
Cumulative Timesteps: 801,392,652

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 801392652...
Checkpoint 801392652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,320.82045
Policy Entropy: 1.97818
Value Function Loss: 0.07660

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.57281
Value Function Update Magnitude: 0.45654

Collected Steps per Second: 16,554.47503
Overall Steps per Second: 8,496.81864

Timestep Collection Time: 3.02166
Timestep Consumption Time: 2.86548
PPO Batch Consumption Time: 0.32587
Total Iteration Time: 5.88714

Cumulative Model Updates: 96,086
Cumulative Timesteps: 801,442,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,115.59576
Policy Entropy: 1.97198
Value Function Loss: 0.07642

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.57196
Value Function Update Magnitude: 0.41779

Collected Steps per Second: 18,562.26522
Overall Steps per Second: 8,655.94557

Timestep Collection Time: 2.69396
Timestep Consumption Time: 3.08311
PPO Batch Consumption Time: 0.36970
Total Iteration Time: 5.77707

Cumulative Model Updates: 96,092
Cumulative Timesteps: 801,492,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 801492680...
Checkpoint 801492680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,297.67982
Policy Entropy: 1.97387
Value Function Loss: 0.07383

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.56778
Value Function Update Magnitude: 0.41787

Collected Steps per Second: 14,015.55875
Overall Steps per Second: 6,261.87601

Timestep Collection Time: 3.56832
Timestep Consumption Time: 4.41842
PPO Batch Consumption Time: 0.58210
Total Iteration Time: 7.98674

Cumulative Model Updates: 96,098
Cumulative Timesteps: 801,542,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,348.58488
Policy Entropy: 1.93701
Value Function Loss: 0.06850

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.56499
Value Function Update Magnitude: 0.51233

Collected Steps per Second: 14,528.07449
Overall Steps per Second: 7,048.28610

Timestep Collection Time: 3.44437
Timestep Consumption Time: 3.65523
PPO Batch Consumption Time: 0.47624
Total Iteration Time: 7.09960

Cumulative Model Updates: 96,104
Cumulative Timesteps: 801,592,732

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 801592732...
Checkpoint 801592732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,776.75168
Policy Entropy: 1.91845
Value Function Loss: 0.07078

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.56572
Value Function Update Magnitude: 0.63680

Collected Steps per Second: 15,489.08735
Overall Steps per Second: 7,331.99599

Timestep Collection Time: 3.22834
Timestep Consumption Time: 3.59163
PPO Batch Consumption Time: 0.46762
Total Iteration Time: 6.81997

Cumulative Model Updates: 96,110
Cumulative Timesteps: 801,642,736

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,792.89358
Policy Entropy: 1.92000
Value Function Loss: 0.06801

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.54672
Value Function Update Magnitude: 0.66750

Collected Steps per Second: 15,520.77170
Overall Steps per Second: 7,386.44002

Timestep Collection Time: 3.22213
Timestep Consumption Time: 3.54838
PPO Batch Consumption Time: 0.45780
Total Iteration Time: 6.77051

Cumulative Model Updates: 96,116
Cumulative Timesteps: 801,692,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 801692746...
Checkpoint 801692746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,221.37075
Policy Entropy: 1.93698
Value Function Loss: 0.07313

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.56109
Value Function Update Magnitude: 0.66370

Collected Steps per Second: 15,491.06103
Overall Steps per Second: 7,456.02551

Timestep Collection Time: 3.22818
Timestep Consumption Time: 3.47887
PPO Batch Consumption Time: 0.45099
Total Iteration Time: 6.70706

Cumulative Model Updates: 96,122
Cumulative Timesteps: 801,742,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,639.65400
Policy Entropy: 1.92739
Value Function Loss: 0.07115

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12680
Policy Update Magnitude: 0.57298
Value Function Update Magnitude: 0.67942

Collected Steps per Second: 15,695.50408
Overall Steps per Second: 7,367.11340

Timestep Collection Time: 3.18805
Timestep Consumption Time: 3.60403
PPO Batch Consumption Time: 0.47050
Total Iteration Time: 6.79208

Cumulative Model Updates: 96,128
Cumulative Timesteps: 801,792,792

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 801792792...
Checkpoint 801792792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,377.63593
Policy Entropy: 1.93578
Value Function Loss: 0.07400

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12364
Policy Update Magnitude: 0.57095
Value Function Update Magnitude: 0.68564

Collected Steps per Second: 14,801.82415
Overall Steps per Second: 6,889.19586

Timestep Collection Time: 3.37918
Timestep Consumption Time: 3.88118
PPO Batch Consumption Time: 0.51200
Total Iteration Time: 7.26035

Cumulative Model Updates: 96,134
Cumulative Timesteps: 801,842,810

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,135.85248
Policy Entropy: 1.93057
Value Function Loss: 0.07128

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12301
Policy Update Magnitude: 0.57669
Value Function Update Magnitude: 0.71627

Collected Steps per Second: 14,741.64198
Overall Steps per Second: 6,897.20425

Timestep Collection Time: 3.39324
Timestep Consumption Time: 3.85926
PPO Batch Consumption Time: 0.50579
Total Iteration Time: 7.25250

Cumulative Model Updates: 96,140
Cumulative Timesteps: 801,892,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 801892832...
Checkpoint 801892832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,961.69201
Policy Entropy: 1.95834
Value Function Loss: 0.07539

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.57754
Value Function Update Magnitude: 0.74069

Collected Steps per Second: 15,014.43735
Overall Steps per Second: 7,383.74970

Timestep Collection Time: 3.33226
Timestep Consumption Time: 3.44370
PPO Batch Consumption Time: 0.44592
Total Iteration Time: 6.77596

Cumulative Model Updates: 96,146
Cumulative Timesteps: 801,942,864

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,298.12077
Policy Entropy: 1.94260
Value Function Loss: 0.07766

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.14399
Policy Update Magnitude: 0.56264
Value Function Update Magnitude: 0.76270

Collected Steps per Second: 15,959.71630
Overall Steps per Second: 7,590.35761

Timestep Collection Time: 3.13314
Timestep Consumption Time: 3.45469
PPO Batch Consumption Time: 0.44466
Total Iteration Time: 6.58783

Cumulative Model Updates: 96,152
Cumulative Timesteps: 801,992,868

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 801992868...
Checkpoint 801992868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,125.12180
Policy Entropy: 1.95150
Value Function Loss: 0.08164

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.15958
Policy Update Magnitude: 0.53032
Value Function Update Magnitude: 0.78477

Collected Steps per Second: 15,125.59022
Overall Steps per Second: 6,937.74952

Timestep Collection Time: 3.30804
Timestep Consumption Time: 3.90410
PPO Batch Consumption Time: 0.51393
Total Iteration Time: 7.21214

Cumulative Model Updates: 96,158
Cumulative Timesteps: 802,042,904

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,848.94627
Policy Entropy: 1.94814
Value Function Loss: 0.07457

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.16344
Policy Update Magnitude: 0.52685
Value Function Update Magnitude: 0.77674

Collected Steps per Second: 14,859.19339
Overall Steps per Second: 6,939.81154

Timestep Collection Time: 3.36492
Timestep Consumption Time: 3.83989
PPO Batch Consumption Time: 0.50199
Total Iteration Time: 7.20481

Cumulative Model Updates: 96,164
Cumulative Timesteps: 802,092,904

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 802092904...
Checkpoint 802092904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,692.34760
Policy Entropy: 1.95964
Value Function Loss: 0.07528

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.15016
Policy Update Magnitude: 0.52730
Value Function Update Magnitude: 0.74421

Collected Steps per Second: 14,906.67234
Overall Steps per Second: 7,010.50239

Timestep Collection Time: 3.35487
Timestep Consumption Time: 3.77871
PPO Batch Consumption Time: 0.49628
Total Iteration Time: 7.13358

Cumulative Model Updates: 96,170
Cumulative Timesteps: 802,142,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,952.40645
Policy Entropy: 1.95008
Value Function Loss: 0.07645

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.15424
Policy Update Magnitude: 0.52239
Value Function Update Magnitude: 0.74916

Collected Steps per Second: 15,122.15246
Overall Steps per Second: 7,155.59126

Timestep Collection Time: 3.30826
Timestep Consumption Time: 3.68320
PPO Batch Consumption Time: 0.48359
Total Iteration Time: 6.99146

Cumulative Model Updates: 96,176
Cumulative Timesteps: 802,192,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 802192942...
Checkpoint 802192942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,968.39296
Policy Entropy: 1.95938
Value Function Loss: 0.07538

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.16081
Policy Update Magnitude: 0.50655
Value Function Update Magnitude: 0.75756

Collected Steps per Second: 15,028.25251
Overall Steps per Second: 7,105.63408

Timestep Collection Time: 3.32707
Timestep Consumption Time: 3.70960
PPO Batch Consumption Time: 0.48694
Total Iteration Time: 7.03667

Cumulative Model Updates: 96,182
Cumulative Timesteps: 802,242,942

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,717.24247
Policy Entropy: 1.94901
Value Function Loss: 0.07355

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.14785
Policy Update Magnitude: 0.52650
Value Function Update Magnitude: 0.72231

Collected Steps per Second: 15,571.99415
Overall Steps per Second: 7,344.37107

Timestep Collection Time: 3.21179
Timestep Consumption Time: 3.59805
PPO Batch Consumption Time: 0.46664
Total Iteration Time: 6.80984

Cumulative Model Updates: 96,188
Cumulative Timesteps: 802,292,956

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 802292956...
Checkpoint 802292956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,658.48124
Policy Entropy: 1.95123
Value Function Loss: 0.07726

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14498
Policy Update Magnitude: 0.56009
Value Function Update Magnitude: 0.68191

Collected Steps per Second: 15,631.25438
Overall Steps per Second: 7,427.13508

Timestep Collection Time: 3.20025
Timestep Consumption Time: 3.53505
PPO Batch Consumption Time: 0.45954
Total Iteration Time: 6.73530

Cumulative Model Updates: 96,194
Cumulative Timesteps: 802,342,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,130.33548
Policy Entropy: 1.92450
Value Function Loss: 0.07907

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.16892
Policy Update Magnitude: 0.53898
Value Function Update Magnitude: 0.72562

Collected Steps per Second: 14,629.14089
Overall Steps per Second: 6,786.60618

Timestep Collection Time: 3.41784
Timestep Consumption Time: 3.94962
PPO Batch Consumption Time: 0.54079
Total Iteration Time: 7.36745

Cumulative Model Updates: 96,200
Cumulative Timesteps: 802,392,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 802392980...
Checkpoint 802392980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,022.58900
Policy Entropy: 1.90943
Value Function Loss: 0.07426

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.54341
Value Function Update Magnitude: 0.74209

Collected Steps per Second: 13,445.48982
Overall Steps per Second: 7,086.11307

Timestep Collection Time: 3.72050
Timestep Consumption Time: 3.33894
PPO Batch Consumption Time: 0.43859
Total Iteration Time: 7.05944

Cumulative Model Updates: 96,206
Cumulative Timesteps: 802,443,004

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,324.38283
Policy Entropy: 1.90893
Value Function Loss: 0.07598

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13930
Policy Update Magnitude: 0.56308
Value Function Update Magnitude: 0.67992

Collected Steps per Second: 13,982.59515
Overall Steps per Second: 6,754.68715

Timestep Collection Time: 3.57788
Timestep Consumption Time: 3.82854
PPO Batch Consumption Time: 0.51053
Total Iteration Time: 7.40641

Cumulative Model Updates: 96,212
Cumulative Timesteps: 802,493,032

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 802493032...
Checkpoint 802493032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,316.63989
Policy Entropy: 1.91239
Value Function Loss: 0.08067

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.58438
Value Function Update Magnitude: 0.58540

Collected Steps per Second: 13,626.71715
Overall Steps per Second: 6,752.74955

Timestep Collection Time: 3.67044
Timestep Consumption Time: 3.73632
PPO Batch Consumption Time: 0.49438
Total Iteration Time: 7.40676

Cumulative Model Updates: 96,218
Cumulative Timesteps: 802,543,048

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,616.58242
Policy Entropy: 1.93045
Value Function Loss: 0.08240

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.59283
Value Function Update Magnitude: 0.56070

Collected Steps per Second: 14,007.43052
Overall Steps per Second: 6,303.25136

Timestep Collection Time: 3.56982
Timestep Consumption Time: 4.36323
PPO Batch Consumption Time: 0.60685
Total Iteration Time: 7.93305

Cumulative Model Updates: 96,224
Cumulative Timesteps: 802,593,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 802593052...
Checkpoint 802593052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,888.30467
Policy Entropy: 1.93379
Value Function Loss: 0.08539

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.59344
Value Function Update Magnitude: 0.60480

Collected Steps per Second: 14,301.79520
Overall Steps per Second: 6,429.41093

Timestep Collection Time: 3.49900
Timestep Consumption Time: 4.28429
PPO Batch Consumption Time: 0.58079
Total Iteration Time: 7.78329

Cumulative Model Updates: 96,230
Cumulative Timesteps: 802,643,094

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,307.47822
Policy Entropy: 1.95024
Value Function Loss: 0.08349

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.59794
Value Function Update Magnitude: 0.61760

Collected Steps per Second: 14,296.65966
Overall Steps per Second: 6,340.44163

Timestep Collection Time: 3.49802
Timestep Consumption Time: 4.38944
PPO Batch Consumption Time: 0.59262
Total Iteration Time: 7.88746

Cumulative Model Updates: 96,236
Cumulative Timesteps: 802,693,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 802693104...
Checkpoint 802693104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,900.09648
Policy Entropy: 1.95088
Value Function Loss: 0.08034

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.14598
Policy Update Magnitude: 0.56529
Value Function Update Magnitude: 0.62744

Collected Steps per Second: 13,999.00652
Overall Steps per Second: 6,436.82426

Timestep Collection Time: 3.57311
Timestep Consumption Time: 4.19780
PPO Batch Consumption Time: 0.56812
Total Iteration Time: 7.77091

Cumulative Model Updates: 96,242
Cumulative Timesteps: 802,743,124

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,465.44335
Policy Entropy: 1.95927
Value Function Loss: 0.07826

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.15271
Policy Update Magnitude: 0.49564
Value Function Update Magnitude: 0.61741

Collected Steps per Second: 14,831.10715
Overall Steps per Second: 6,597.98923

Timestep Collection Time: 3.37291
Timestep Consumption Time: 4.20879
PPO Batch Consumption Time: 0.56803
Total Iteration Time: 7.58170

Cumulative Model Updates: 96,248
Cumulative Timesteps: 802,793,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 802793148...
Checkpoint 802793148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,675.91899
Policy Entropy: 1.93620
Value Function Loss: 0.07786

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.50272
Value Function Update Magnitude: 0.59567

Collected Steps per Second: 13,749.08370
Overall Steps per Second: 6,761.06607

Timestep Collection Time: 3.63733
Timestep Consumption Time: 3.75943
PPO Batch Consumption Time: 0.49068
Total Iteration Time: 7.39676

Cumulative Model Updates: 96,254
Cumulative Timesteps: 802,843,158

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,800.90534
Policy Entropy: 1.93864
Value Function Loss: 0.08173

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.15303
Policy Update Magnitude: 0.52682
Value Function Update Magnitude: 0.61185

Collected Steps per Second: 15,117.43949
Overall Steps per Second: 6,989.95495

Timestep Collection Time: 3.30784
Timestep Consumption Time: 3.84615
PPO Batch Consumption Time: 0.49833
Total Iteration Time: 7.15398

Cumulative Model Updates: 96,260
Cumulative Timesteps: 802,893,164

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 802893164...
Checkpoint 802893164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,026.80628
Policy Entropy: 1.93075
Value Function Loss: 0.07580

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.15127
Policy Update Magnitude: 0.52891
Value Function Update Magnitude: 0.67388

Collected Steps per Second: 15,130.84854
Overall Steps per Second: 7,101.40702

Timestep Collection Time: 3.30675
Timestep Consumption Time: 3.73889
PPO Batch Consumption Time: 0.48050
Total Iteration Time: 7.04565

Cumulative Model Updates: 96,266
Cumulative Timesteps: 802,943,198

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,273.29712
Policy Entropy: 1.93295
Value Function Loss: 0.07288

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.15332
Policy Update Magnitude: 0.51701
Value Function Update Magnitude: 0.70743

Collected Steps per Second: 14,632.85804
Overall Steps per Second: 6,909.07360

Timestep Collection Time: 3.41874
Timestep Consumption Time: 3.82188
PPO Batch Consumption Time: 0.49885
Total Iteration Time: 7.24062

Cumulative Model Updates: 96,272
Cumulative Timesteps: 802,993,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 802993224...
Checkpoint 802993224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,154.58086
Policy Entropy: 1.92839
Value Function Loss: 0.06885

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14176
Policy Update Magnitude: 0.53326
Value Function Update Magnitude: 0.64455

Collected Steps per Second: 14,960.72764
Overall Steps per Second: 6,634.13001

Timestep Collection Time: 3.34235
Timestep Consumption Time: 4.19504
PPO Batch Consumption Time: 0.55564
Total Iteration Time: 7.53739

Cumulative Model Updates: 96,278
Cumulative Timesteps: 803,043,228

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,511.48261
Policy Entropy: 1.93193
Value Function Loss: 0.07691

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.14164
Policy Update Magnitude: 0.56329
Value Function Update Magnitude: 0.53836

Collected Steps per Second: 14,459.47737
Overall Steps per Second: 6,538.17254

Timestep Collection Time: 3.45918
Timestep Consumption Time: 4.19097
PPO Batch Consumption Time: 0.55588
Total Iteration Time: 7.65015

Cumulative Model Updates: 96,284
Cumulative Timesteps: 803,093,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 803093246...
Checkpoint 803093246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,819.49374
Policy Entropy: 1.94142
Value Function Loss: 0.07787

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.57089
Value Function Update Magnitude: 0.42886

Collected Steps per Second: 14,271.27230
Overall Steps per Second: 6,542.06765

Timestep Collection Time: 3.50634
Timestep Consumption Time: 4.14261
PPO Batch Consumption Time: 0.55263
Total Iteration Time: 7.64896

Cumulative Model Updates: 96,290
Cumulative Timesteps: 803,143,286

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,218.88607
Policy Entropy: 1.94834
Value Function Loss: 0.08174

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.14076
Policy Update Magnitude: 0.57293
Value Function Update Magnitude: 0.41769

Collected Steps per Second: 13,557.12510
Overall Steps per Second: 6,805.12960

Timestep Collection Time: 3.68957
Timestep Consumption Time: 3.66076
PPO Batch Consumption Time: 0.47362
Total Iteration Time: 7.35034

Cumulative Model Updates: 96,296
Cumulative Timesteps: 803,193,306

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 803193306...
Checkpoint 803193306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,500.81822
Policy Entropy: 1.94604
Value Function Loss: 0.07590

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.56836
Value Function Update Magnitude: 0.54996

Collected Steps per Second: 15,476.53468
Overall Steps per Second: 7,289.59163

Timestep Collection Time: 3.23173
Timestep Consumption Time: 3.62956
PPO Batch Consumption Time: 0.47200
Total Iteration Time: 6.86129

Cumulative Model Updates: 96,302
Cumulative Timesteps: 803,243,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,894.74055
Policy Entropy: 1.95363
Value Function Loss: 0.08005

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.55499
Value Function Update Magnitude: 0.60093

Collected Steps per Second: 15,329.05821
Overall Steps per Second: 7,187.49068

Timestep Collection Time: 3.26400
Timestep Consumption Time: 3.69726
PPO Batch Consumption Time: 0.48253
Total Iteration Time: 6.96126

Cumulative Model Updates: 96,308
Cumulative Timesteps: 803,293,356

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 803293356...
Checkpoint 803293356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,092.21084
Policy Entropy: 1.94422
Value Function Loss: 0.08023

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.55080
Value Function Update Magnitude: 0.64355

Collected Steps per Second: 15,023.15732
Overall Steps per Second: 6,997.97278

Timestep Collection Time: 3.32966
Timestep Consumption Time: 3.81841
PPO Batch Consumption Time: 0.50435
Total Iteration Time: 7.14807

Cumulative Model Updates: 96,314
Cumulative Timesteps: 803,343,378

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,801.03559
Policy Entropy: 1.93910
Value Function Loss: 0.07725

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.14567
Policy Update Magnitude: 0.55200
Value Function Update Magnitude: 0.67449

Collected Steps per Second: 14,818.18975
Overall Steps per Second: 6,581.57585

Timestep Collection Time: 3.37477
Timestep Consumption Time: 4.22341
PPO Batch Consumption Time: 0.56742
Total Iteration Time: 7.59818

Cumulative Model Updates: 96,320
Cumulative Timesteps: 803,393,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 803393386...
Checkpoint 803393386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,701.43373
Policy Entropy: 1.92867
Value Function Loss: 0.07092

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.55339
Value Function Update Magnitude: 0.67653

Collected Steps per Second: 14,621.90992
Overall Steps per Second: 6,646.50796

Timestep Collection Time: 3.42185
Timestep Consumption Time: 4.10601
PPO Batch Consumption Time: 0.54979
Total Iteration Time: 7.52786

Cumulative Model Updates: 96,326
Cumulative Timesteps: 803,443,420

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,727.03142
Policy Entropy: 1.93288
Value Function Loss: 0.07051

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.56012
Value Function Update Magnitude: 0.65726

Collected Steps per Second: 14,602.71848
Overall Steps per Second: 6,599.12280

Timestep Collection Time: 3.42539
Timestep Consumption Time: 4.15441
PPO Batch Consumption Time: 0.55551
Total Iteration Time: 7.57980

Cumulative Model Updates: 96,332
Cumulative Timesteps: 803,493,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 803493440...
Checkpoint 803493440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,406.66749
Policy Entropy: 1.93497
Value Function Loss: 0.07320

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12771
Policy Update Magnitude: 0.56796
Value Function Update Magnitude: 0.65849

Collected Steps per Second: 14,207.87436
Overall Steps per Second: 6,608.00773

Timestep Collection Time: 3.52072
Timestep Consumption Time: 4.04918
PPO Batch Consumption Time: 0.54213
Total Iteration Time: 7.56991

Cumulative Model Updates: 96,338
Cumulative Timesteps: 803,543,462

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,330.93267
Policy Entropy: 1.94123
Value Function Loss: 0.07242

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.57597
Value Function Update Magnitude: 0.69423

Collected Steps per Second: 14,767.43490
Overall Steps per Second: 6,552.26066

Timestep Collection Time: 3.38637
Timestep Consumption Time: 4.24580
PPO Batch Consumption Time: 0.57322
Total Iteration Time: 7.63218

Cumulative Model Updates: 96,344
Cumulative Timesteps: 803,593,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 803593470...
Checkpoint 803593470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,754.53501
Policy Entropy: 1.96610
Value Function Loss: 0.07746

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.58681
Value Function Update Magnitude: 0.71206

Collected Steps per Second: 15,086.48524
Overall Steps per Second: 6,921.65080

Timestep Collection Time: 3.31621
Timestep Consumption Time: 3.91183
PPO Batch Consumption Time: 0.51793
Total Iteration Time: 7.22804

Cumulative Model Updates: 96,350
Cumulative Timesteps: 803,643,500

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,433.73966
Policy Entropy: 1.96913
Value Function Loss: 0.07983

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.58791
Value Function Update Magnitude: 0.74658

Collected Steps per Second: 15,151.82498
Overall Steps per Second: 7,003.84224

Timestep Collection Time: 3.30099
Timestep Consumption Time: 3.84023
PPO Batch Consumption Time: 0.52098
Total Iteration Time: 7.14122

Cumulative Model Updates: 96,356
Cumulative Timesteps: 803,693,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 803693516...
Checkpoint 803693516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,888.00768
Policy Entropy: 1.95392
Value Function Loss: 0.08280

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.58142
Value Function Update Magnitude: 0.76486

Collected Steps per Second: 14,289.74361
Overall Steps per Second: 6,818.50504

Timestep Collection Time: 3.50041
Timestep Consumption Time: 3.83551
PPO Batch Consumption Time: 0.51823
Total Iteration Time: 7.33592

Cumulative Model Updates: 96,362
Cumulative Timesteps: 803,743,536

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,596.78834
Policy Entropy: 1.93445
Value Function Loss: 0.07879

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.57561
Value Function Update Magnitude: 0.68827

Collected Steps per Second: 14,486.10317
Overall Steps per Second: 6,751.03827

Timestep Collection Time: 3.45296
Timestep Consumption Time: 3.95627
PPO Batch Consumption Time: 0.53968
Total Iteration Time: 7.40923

Cumulative Model Updates: 96,368
Cumulative Timesteps: 803,793,556

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 803793556...
Checkpoint 803793556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,364.53830
Policy Entropy: 1.94280
Value Function Loss: 0.07740

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.56929
Value Function Update Magnitude: 0.71662

Collected Steps per Second: 14,466.16249
Overall Steps per Second: 6,635.69619

Timestep Collection Time: 3.45800
Timestep Consumption Time: 4.08062
PPO Batch Consumption Time: 0.55961
Total Iteration Time: 7.53862

Cumulative Model Updates: 96,374
Cumulative Timesteps: 803,843,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,162.71733
Policy Entropy: 1.95236
Value Function Loss: 0.07158

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.15578
Policy Update Magnitude: 0.53722
Value Function Update Magnitude: 0.79986

Collected Steps per Second: 14,583.55707
Overall Steps per Second: 6,730.81607

Timestep Collection Time: 3.43044
Timestep Consumption Time: 4.00224
PPO Batch Consumption Time: 0.53564
Total Iteration Time: 7.43268

Cumulative Model Updates: 96,380
Cumulative Timesteps: 803,893,608

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 803893608...
Checkpoint 803893608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,505.76017
Policy Entropy: 1.97144
Value Function Loss: 0.07248

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.15213
Policy Update Magnitude: 0.50332
Value Function Update Magnitude: 0.76353

Collected Steps per Second: 14,585.65105
Overall Steps per Second: 6,691.74035

Timestep Collection Time: 3.42858
Timestep Consumption Time: 4.04452
PPO Batch Consumption Time: 0.54260
Total Iteration Time: 7.47309

Cumulative Model Updates: 96,386
Cumulative Timesteps: 803,943,616

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,260.76913
Policy Entropy: 1.97404
Value Function Loss: 0.07040

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.50940
Value Function Update Magnitude: 0.67019

Collected Steps per Second: 15,299.11541
Overall Steps per Second: 7,196.45010

Timestep Collection Time: 3.26960
Timestep Consumption Time: 3.68133
PPO Batch Consumption Time: 0.48555
Total Iteration Time: 6.95093

Cumulative Model Updates: 96,392
Cumulative Timesteps: 803,993,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 803993638...
Checkpoint 803993638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,006.17614
Policy Entropy: 1.97409
Value Function Loss: 0.06965

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.54513
Value Function Update Magnitude: 0.71083

Collected Steps per Second: 14,781.82969
Overall Steps per Second: 7,210.39905

Timestep Collection Time: 3.38348
Timestep Consumption Time: 3.55289
PPO Batch Consumption Time: 0.46535
Total Iteration Time: 6.93637

Cumulative Model Updates: 96,398
Cumulative Timesteps: 804,043,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,157.52040
Policy Entropy: 1.95226
Value Function Loss: 0.07111

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.54879
Value Function Update Magnitude: 0.69074

Collected Steps per Second: 15,186.59467
Overall Steps per Second: 6,871.39075

Timestep Collection Time: 3.29317
Timestep Consumption Time: 3.98513
PPO Batch Consumption Time: 0.53485
Total Iteration Time: 7.27829

Cumulative Model Updates: 96,404
Cumulative Timesteps: 804,093,664

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 804093664...
Checkpoint 804093664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,406.32865
Policy Entropy: 1.95800
Value Function Loss: 0.07465

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.55868
Value Function Update Magnitude: 0.70902

Collected Steps per Second: 14,390.10013
Overall Steps per Second: 6,539.07574

Timestep Collection Time: 3.47628
Timestep Consumption Time: 4.17373
PPO Batch Consumption Time: 0.56091
Total Iteration Time: 7.65001

Cumulative Model Updates: 96,410
Cumulative Timesteps: 804,143,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,458.70008
Policy Entropy: 1.96076
Value Function Loss: 0.07791

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12965
Policy Update Magnitude: 0.56760
Value Function Update Magnitude: 0.61517

Collected Steps per Second: 15,020.73414
Overall Steps per Second: 6,731.54881

Timestep Collection Time: 3.32980
Timestep Consumption Time: 4.10029
PPO Batch Consumption Time: 0.54451
Total Iteration Time: 7.43009

Cumulative Model Updates: 96,416
Cumulative Timesteps: 804,193,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 804193704...
Checkpoint 804193704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,992.53765
Policy Entropy: 1.97161
Value Function Loss: 0.07526

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.56520
Value Function Update Magnitude: 0.49482

Collected Steps per Second: 15,148.15139
Overall Steps per Second: 6,933.76645

Timestep Collection Time: 3.30258
Timestep Consumption Time: 3.91255
PPO Batch Consumption Time: 0.51964
Total Iteration Time: 7.21513

Cumulative Model Updates: 96,422
Cumulative Timesteps: 804,243,732

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,141.89772
Policy Entropy: 1.96442
Value Function Loss: 0.06981

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.14484
Policy Update Magnitude: 0.54446
Value Function Update Magnitude: 0.62537

Collected Steps per Second: 15,105.93769
Overall Steps per Second: 6,765.88669

Timestep Collection Time: 3.31168
Timestep Consumption Time: 4.08218
PPO Batch Consumption Time: 0.54606
Total Iteration Time: 7.39386

Cumulative Model Updates: 96,428
Cumulative Timesteps: 804,293,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 804293758...
Checkpoint 804293758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,472.04851
Policy Entropy: 1.95759
Value Function Loss: 0.06236

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.52725
Value Function Update Magnitude: 0.68019

Collected Steps per Second: 14,082.08549
Overall Steps per Second: 6,591.48603

Timestep Collection Time: 3.55260
Timestep Consumption Time: 4.03719
PPO Batch Consumption Time: 0.53894
Total Iteration Time: 7.58979

Cumulative Model Updates: 96,434
Cumulative Timesteps: 804,343,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,598.96010
Policy Entropy: 1.96049
Value Function Loss: 0.06521

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.53521
Value Function Update Magnitude: 0.67073

Collected Steps per Second: 14,450.36392
Overall Steps per Second: 6,701.32592

Timestep Collection Time: 3.46095
Timestep Consumption Time: 4.00205
PPO Batch Consumption Time: 0.53056
Total Iteration Time: 7.46300

Cumulative Model Updates: 96,440
Cumulative Timesteps: 804,393,798

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 804393798...
Checkpoint 804393798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,400.52107
Policy Entropy: 1.96302
Value Function Loss: 0.06601

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.54264
Value Function Update Magnitude: 0.68335

Collected Steps per Second: 15,074.72729
Overall Steps per Second: 7,198.67858

Timestep Collection Time: 3.31867
Timestep Consumption Time: 3.63094
PPO Batch Consumption Time: 0.47521
Total Iteration Time: 6.94961

Cumulative Model Updates: 96,446
Cumulative Timesteps: 804,443,826

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,503.96863
Policy Entropy: 1.95701
Value Function Loss: 0.07077

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.54808
Value Function Update Magnitude: 0.65335

Collected Steps per Second: 15,212.15452
Overall Steps per Second: 7,022.99467

Timestep Collection Time: 3.28882
Timestep Consumption Time: 3.83492
PPO Batch Consumption Time: 0.50696
Total Iteration Time: 7.12374

Cumulative Model Updates: 96,452
Cumulative Timesteps: 804,493,856

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 804493856...
Checkpoint 804493856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,630.92286
Policy Entropy: 1.94304
Value Function Loss: 0.07248

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.56863
Value Function Update Magnitude: 0.67186

Collected Steps per Second: 14,673.69170
Overall Steps per Second: 6,671.61621

Timestep Collection Time: 3.40800
Timestep Consumption Time: 4.08763
PPO Batch Consumption Time: 0.54965
Total Iteration Time: 7.49564

Cumulative Model Updates: 96,458
Cumulative Timesteps: 804,543,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,253.45230
Policy Entropy: 1.94405
Value Function Loss: 0.07193

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.57498
Value Function Update Magnitude: 0.74484

Collected Steps per Second: 15,076.01891
Overall Steps per Second: 7,253.22420

Timestep Collection Time: 3.31865
Timestep Consumption Time: 3.57925
PPO Batch Consumption Time: 0.46381
Total Iteration Time: 6.89790

Cumulative Model Updates: 96,464
Cumulative Timesteps: 804,593,896

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 804593896...
Checkpoint 804593896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,954.15311
Policy Entropy: 1.95519
Value Function Loss: 0.06833

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12734
Policy Update Magnitude: 0.56995
Value Function Update Magnitude: 0.75835

Collected Steps per Second: 15,065.69231
Overall Steps per Second: 7,032.46590

Timestep Collection Time: 3.31906
Timestep Consumption Time: 3.79139
PPO Batch Consumption Time: 0.49955
Total Iteration Time: 7.11045

Cumulative Model Updates: 96,470
Cumulative Timesteps: 804,643,900

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,851.91432
Policy Entropy: 1.96037
Value Function Loss: 0.06753

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.56241
Value Function Update Magnitude: 0.73680

Collected Steps per Second: 15,748.89396
Overall Steps per Second: 7,389.21523

Timestep Collection Time: 3.17711
Timestep Consumption Time: 3.59438
PPO Batch Consumption Time: 0.46786
Total Iteration Time: 6.77149

Cumulative Model Updates: 96,476
Cumulative Timesteps: 804,693,936

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 804693936...
Checkpoint 804693936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,379.35749
Policy Entropy: 1.95891
Value Function Loss: 0.06924

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.54861
Value Function Update Magnitude: 0.70778

Collected Steps per Second: 15,180.06873
Overall Steps per Second: 7,199.88358

Timestep Collection Time: 3.29551
Timestep Consumption Time: 3.65266
PPO Batch Consumption Time: 0.47755
Total Iteration Time: 6.94817

Cumulative Model Updates: 96,482
Cumulative Timesteps: 804,743,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,697.36413
Policy Entropy: 1.95736
Value Function Loss: 0.07659

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13396
Policy Update Magnitude: 0.54676
Value Function Update Magnitude: 0.71563

Collected Steps per Second: 15,374.00201
Overall Steps per Second: 6,930.12242

Timestep Collection Time: 3.25380
Timestep Consumption Time: 3.96454
PPO Batch Consumption Time: 0.52829
Total Iteration Time: 7.21834

Cumulative Model Updates: 96,488
Cumulative Timesteps: 804,793,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 804793986...
Checkpoint 804793986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,402.36640
Policy Entropy: 1.94905
Value Function Loss: 0.07324

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.54747
Value Function Update Magnitude: 0.73906

Collected Steps per Second: 15,059.98027
Overall Steps per Second: 7,671.02917

Timestep Collection Time: 3.32178
Timestep Consumption Time: 3.19964
PPO Batch Consumption Time: 0.40355
Total Iteration Time: 6.52142

Cumulative Model Updates: 96,494
Cumulative Timesteps: 804,844,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,803.95968
Policy Entropy: 1.94860
Value Function Loss: 0.08476

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.14931
Policy Update Magnitude: 0.55540
Value Function Update Magnitude: 0.73771

Collected Steps per Second: 15,497.41636
Overall Steps per Second: 6,958.58026

Timestep Collection Time: 3.22673
Timestep Consumption Time: 3.95950
PPO Batch Consumption Time: 0.53033
Total Iteration Time: 7.18624

Cumulative Model Updates: 96,500
Cumulative Timesteps: 804,894,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 804894018...
Checkpoint 804894018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,541.34783
Policy Entropy: 1.95815
Value Function Loss: 0.08029

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.15039
Policy Update Magnitude: 0.56618
Value Function Update Magnitude: 0.76108

Collected Steps per Second: 15,431.49130
Overall Steps per Second: 6,914.68741

Timestep Collection Time: 3.24155
Timestep Consumption Time: 3.99261
PPO Batch Consumption Time: 0.53624
Total Iteration Time: 7.23417

Cumulative Model Updates: 96,506
Cumulative Timesteps: 804,944,040

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,327.84189
Policy Entropy: 1.97801
Value Function Loss: 0.08323

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.57785
Value Function Update Magnitude: 0.74507

Collected Steps per Second: 15,411.29898
Overall Steps per Second: 7,086.73925

Timestep Collection Time: 3.24567
Timestep Consumption Time: 3.81258
PPO Batch Consumption Time: 0.51664
Total Iteration Time: 7.05825

Cumulative Model Updates: 96,512
Cumulative Timesteps: 804,994,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 804994060...
Checkpoint 804994060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,189.61539
Policy Entropy: 1.99127
Value Function Loss: 0.07816

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.57483
Value Function Update Magnitude: 0.77668

Collected Steps per Second: 15,143.53483
Overall Steps per Second: 7,141.87905

Timestep Collection Time: 3.30187
Timestep Consumption Time: 3.69937
PPO Batch Consumption Time: 0.50027
Total Iteration Time: 7.00124

Cumulative Model Updates: 96,518
Cumulative Timesteps: 805,044,062

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,310.77164
Policy Entropy: 2.00200
Value Function Loss: 0.08126

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.16163
Policy Update Magnitude: 0.55371
Value Function Update Magnitude: 0.78800

Collected Steps per Second: 15,069.29008
Overall Steps per Second: 7,085.49731

Timestep Collection Time: 3.31840
Timestep Consumption Time: 3.73911
PPO Batch Consumption Time: 0.50903
Total Iteration Time: 7.05751

Cumulative Model Updates: 96,524
Cumulative Timesteps: 805,094,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 805094068...
Checkpoint 805094068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,999.14892
Policy Entropy: 1.97823
Value Function Loss: 0.08190

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.16815
Policy Update Magnitude: 0.48307
Value Function Update Magnitude: 0.78692

Collected Steps per Second: 15,131.58891
Overall Steps per Second: 7,126.37861

Timestep Collection Time: 3.30712
Timestep Consumption Time: 3.71496
PPO Batch Consumption Time: 0.50254
Total Iteration Time: 7.02208

Cumulative Model Updates: 96,530
Cumulative Timesteps: 805,144,110

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,047.96468
Policy Entropy: 1.97065
Value Function Loss: 0.08269

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.15926
Policy Update Magnitude: 0.50090
Value Function Update Magnitude: 0.72605

Collected Steps per Second: 15,193.18450
Overall Steps per Second: 6,929.88645

Timestep Collection Time: 3.29266
Timestep Consumption Time: 3.92622
PPO Batch Consumption Time: 0.53682
Total Iteration Time: 7.21888

Cumulative Model Updates: 96,536
Cumulative Timesteps: 805,194,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 805194136...
Checkpoint 805194136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,917.74485
Policy Entropy: 1.95297
Value Function Loss: 0.08236

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.14859
Policy Update Magnitude: 0.56853
Value Function Update Magnitude: 0.59528

Collected Steps per Second: 14,871.80676
Overall Steps per Second: 7,015.72251

Timestep Collection Time: 3.36422
Timestep Consumption Time: 3.76719
PPO Batch Consumption Time: 0.51089
Total Iteration Time: 7.13141

Cumulative Model Updates: 96,542
Cumulative Timesteps: 805,244,168

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,158.64277
Policy Entropy: 1.96176
Value Function Loss: 0.08735

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.16004
Policy Update Magnitude: 0.56882
Value Function Update Magnitude: 0.52124

Collected Steps per Second: 15,097.59693
Overall Steps per Second: 7,078.10191

Timestep Collection Time: 3.31285
Timestep Consumption Time: 3.75346
PPO Batch Consumption Time: 0.50997
Total Iteration Time: 7.06630

Cumulative Model Updates: 96,548
Cumulative Timesteps: 805,294,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 805294184...
Checkpoint 805294184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,562.63390
Policy Entropy: 1.96951
Value Function Loss: 0.08382

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.14692
Policy Update Magnitude: 0.57837
Value Function Update Magnitude: 0.52540

Collected Steps per Second: 14,749.12903
Overall Steps per Second: 6,813.12706

Timestep Collection Time: 3.39152
Timestep Consumption Time: 3.95048
PPO Batch Consumption Time: 0.52717
Total Iteration Time: 7.34200

Cumulative Model Updates: 96,554
Cumulative Timesteps: 805,344,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,934.62214
Policy Entropy: 1.97264
Value Function Loss: 0.07908

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.57835
Value Function Update Magnitude: 0.63456

Collected Steps per Second: 15,484.30837
Overall Steps per Second: 7,108.93386

Timestep Collection Time: 3.22959
Timestep Consumption Time: 3.80494
PPO Batch Consumption Time: 0.50754
Total Iteration Time: 7.03453

Cumulative Model Updates: 96,560
Cumulative Timesteps: 805,394,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 805394214...
Checkpoint 805394214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,163.96299
Policy Entropy: 1.97473
Value Function Loss: 0.07659

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13039
Policy Update Magnitude: 0.57907
Value Function Update Magnitude: 0.60569

Collected Steps per Second: 15,503.71352
Overall Steps per Second: 6,881.99576

Timestep Collection Time: 3.22581
Timestep Consumption Time: 4.04127
PPO Batch Consumption Time: 0.54602
Total Iteration Time: 7.26708

Cumulative Model Updates: 96,566
Cumulative Timesteps: 805,444,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,505.78620
Policy Entropy: 1.95539
Value Function Loss: 0.08175

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.57889
Value Function Update Magnitude: 0.62225

Collected Steps per Second: 15,416.10177
Overall Steps per Second: 6,995.47272

Timestep Collection Time: 3.24492
Timestep Consumption Time: 3.90599
PPO Batch Consumption Time: 0.52436
Total Iteration Time: 7.15091

Cumulative Model Updates: 96,572
Cumulative Timesteps: 805,494,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 805494250...
Checkpoint 805494250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,473.21392
Policy Entropy: 1.95238
Value Function Loss: 0.07802

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.57448
Value Function Update Magnitude: 0.64214

Collected Steps per Second: 13,887.32778
Overall Steps per Second: 6,737.16459

Timestep Collection Time: 3.60055
Timestep Consumption Time: 3.82127
PPO Batch Consumption Time: 0.50358
Total Iteration Time: 7.42182

Cumulative Model Updates: 96,578
Cumulative Timesteps: 805,544,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,658.67564
Policy Entropy: 1.97045
Value Function Loss: 0.07841

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 0.56833
Value Function Update Magnitude: 0.61833

Collected Steps per Second: 15,553.16146
Overall Steps per Second: 6,989.38852

Timestep Collection Time: 3.21607
Timestep Consumption Time: 3.94050
PPO Batch Consumption Time: 0.52423
Total Iteration Time: 7.15656

Cumulative Model Updates: 96,584
Cumulative Timesteps: 805,594,272

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 805594272...
Checkpoint 805594272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,717.57638
Policy Entropy: 1.99323
Value Function Loss: 0.07475

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.56418
Value Function Update Magnitude: 0.57797

Collected Steps per Second: 15,216.55578
Overall Steps per Second: 7,022.78172

Timestep Collection Time: 3.28589
Timestep Consumption Time: 3.83379
PPO Batch Consumption Time: 0.50862
Total Iteration Time: 7.11969

Cumulative Model Updates: 96,590
Cumulative Timesteps: 805,644,272

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,956.04686
Policy Entropy: 1.97530
Value Function Loss: 0.07742

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13711
Policy Update Magnitude: 0.53770
Value Function Update Magnitude: 0.54432

Collected Steps per Second: 14,769.86899
Overall Steps per Second: 6,801.79834

Timestep Collection Time: 3.38554
Timestep Consumption Time: 3.96604
PPO Batch Consumption Time: 0.52945
Total Iteration Time: 7.35159

Cumulative Model Updates: 96,596
Cumulative Timesteps: 805,694,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 805694276...
Checkpoint 805694276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,979.75726
Policy Entropy: 1.97459
Value Function Loss: 0.08126

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.15209
Policy Update Magnitude: 0.51594
Value Function Update Magnitude: 0.44030

Collected Steps per Second: 15,595.77362
Overall Steps per Second: 6,992.64919

Timestep Collection Time: 3.20638
Timestep Consumption Time: 3.94484
PPO Batch Consumption Time: 0.52526
Total Iteration Time: 7.15122

Cumulative Model Updates: 96,602
Cumulative Timesteps: 805,744,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,237.73255
Policy Entropy: 1.96482
Value Function Loss: 0.08026

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.15314
Policy Update Magnitude: 0.48886
Value Function Update Magnitude: 0.55924

Collected Steps per Second: 15,591.92396
Overall Steps per Second: 6,952.42162

Timestep Collection Time: 3.20743
Timestep Consumption Time: 3.98575
PPO Batch Consumption Time: 0.53104
Total Iteration Time: 7.19318

Cumulative Model Updates: 96,608
Cumulative Timesteps: 805,794,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 805794292...
Checkpoint 805794292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,905.29331
Policy Entropy: 1.99474
Value Function Loss: 0.07795

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.48468
Value Function Update Magnitude: 0.68239

Collected Steps per Second: 15,473.37625
Overall Steps per Second: 6,915.27454

Timestep Collection Time: 3.23200
Timestep Consumption Time: 3.99981
PPO Batch Consumption Time: 0.54117
Total Iteration Time: 7.23182

Cumulative Model Updates: 96,614
Cumulative Timesteps: 805,844,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,623.50175
Policy Entropy: 1.99146
Value Function Loss: 0.07972

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.54031
Value Function Update Magnitude: 0.64554

Collected Steps per Second: 15,653.01256
Overall Steps per Second: 6,946.76810

Timestep Collection Time: 3.19645
Timestep Consumption Time: 4.00604
PPO Batch Consumption Time: 0.53605
Total Iteration Time: 7.20249

Cumulative Model Updates: 96,620
Cumulative Timesteps: 805,894,336

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 805894336...
Checkpoint 805894336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,842.05313
Policy Entropy: 2.00126
Value Function Loss: 0.07796

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.51575

Collected Steps per Second: 15,387.77690
Overall Steps per Second: 6,849.83986

Timestep Collection Time: 3.25063
Timestep Consumption Time: 4.05173
PPO Batch Consumption Time: 0.54324
Total Iteration Time: 7.30236

Cumulative Model Updates: 96,626
Cumulative Timesteps: 805,944,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,542.79810
Policy Entropy: 1.99080
Value Function Loss: 0.07584

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.14812
Policy Update Magnitude: 0.53742
Value Function Update Magnitude: 0.53048

Collected Steps per Second: 15,575.75121
Overall Steps per Second: 7,034.76489

Timestep Collection Time: 3.21166
Timestep Consumption Time: 3.89931
PPO Batch Consumption Time: 0.52078
Total Iteration Time: 7.11097

Cumulative Model Updates: 96,632
Cumulative Timesteps: 805,994,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 805994380...
Checkpoint 805994380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,023.93282
Policy Entropy: 1.98040
Value Function Loss: 0.07578

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.50221
Value Function Update Magnitude: 0.47949

Collected Steps per Second: 15,161.48800
Overall Steps per Second: 6,953.11632

Timestep Collection Time: 3.29941
Timestep Consumption Time: 3.89506
PPO Batch Consumption Time: 0.51517
Total Iteration Time: 7.19447

Cumulative Model Updates: 96,638
Cumulative Timesteps: 806,044,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,540.40955
Policy Entropy: 1.98083
Value Function Loss: 0.07422

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.14274
Policy Update Magnitude: 0.50702
Value Function Update Magnitude: 0.55183

Collected Steps per Second: 15,438.09079
Overall Steps per Second: 7,097.29061

Timestep Collection Time: 3.23887
Timestep Consumption Time: 3.80635
PPO Batch Consumption Time: 0.50127
Total Iteration Time: 7.04522

Cumulative Model Updates: 96,644
Cumulative Timesteps: 806,094,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 806094406...
Checkpoint 806094406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,621.94443
Policy Entropy: 1.99533
Value Function Loss: 0.07556

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.14417
Policy Update Magnitude: 0.51350
Value Function Update Magnitude: 0.52525

Collected Steps per Second: 15,471.60333
Overall Steps per Second: 7,012.98173

Timestep Collection Time: 3.23263
Timestep Consumption Time: 3.89900
PPO Batch Consumption Time: 0.51698
Total Iteration Time: 7.13163

Cumulative Model Updates: 96,650
Cumulative Timesteps: 806,144,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,276.58955
Policy Entropy: 1.98207
Value Function Loss: 0.07168

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.16222
Policy Update Magnitude: 0.50838
Value Function Update Magnitude: 0.42362

Collected Steps per Second: 15,774.56379
Overall Steps per Second: 7,018.77266

Timestep Collection Time: 3.17017
Timestep Consumption Time: 3.95473
PPO Batch Consumption Time: 0.52576
Total Iteration Time: 7.12489

Cumulative Model Updates: 96,656
Cumulative Timesteps: 806,194,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 806194428...
Checkpoint 806194428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,338.12151
Policy Entropy: 1.97897
Value Function Loss: 0.07942

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.15243
Policy Update Magnitude: 0.54067
Value Function Update Magnitude: 0.32460

Collected Steps per Second: 15,360.68750
Overall Steps per Second: 7,046.42834

Timestep Collection Time: 3.25819
Timestep Consumption Time: 3.84442
PPO Batch Consumption Time: 0.50929
Total Iteration Time: 7.10261

Cumulative Model Updates: 96,662
Cumulative Timesteps: 806,244,476

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,185.68930
Policy Entropy: 1.97231
Value Function Loss: 0.08705

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.14345
Policy Update Magnitude: 0.55939
Value Function Update Magnitude: 0.30990

Collected Steps per Second: 15,382.35476
Overall Steps per Second: 7,006.68392

Timestep Collection Time: 3.25165
Timestep Consumption Time: 3.88696
PPO Batch Consumption Time: 0.51381
Total Iteration Time: 7.13861

Cumulative Model Updates: 96,668
Cumulative Timesteps: 806,294,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 806294494...
Checkpoint 806294494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,405.78659
Policy Entropy: 1.97151
Value Function Loss: 0.08535

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.16740
Policy Update Magnitude: 0.51417
Value Function Update Magnitude: 0.39284

Collected Steps per Second: 15,535.38068
Overall Steps per Second: 7,105.39633

Timestep Collection Time: 3.22142
Timestep Consumption Time: 3.82196
PPO Batch Consumption Time: 0.50732
Total Iteration Time: 7.04338

Cumulative Model Updates: 96,674
Cumulative Timesteps: 806,344,540

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,748.61062
Policy Entropy: 1.97631
Value Function Loss: 0.08051

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.15282
Policy Update Magnitude: 0.47965
Value Function Update Magnitude: 0.55499

Collected Steps per Second: 15,567.62007
Overall Steps per Second: 7,125.40934

Timestep Collection Time: 3.21372
Timestep Consumption Time: 3.80763
PPO Batch Consumption Time: 0.50371
Total Iteration Time: 7.02135

Cumulative Model Updates: 96,680
Cumulative Timesteps: 806,394,570

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 806394570...
Checkpoint 806394570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,409.45016
Policy Entropy: 1.97217
Value Function Loss: 0.07370

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.14953
Policy Update Magnitude: 0.46619
Value Function Update Magnitude: 0.60855

Collected Steps per Second: 15,398.50072
Overall Steps per Second: 7,119.74790

Timestep Collection Time: 3.24759
Timestep Consumption Time: 3.77626
PPO Batch Consumption Time: 0.50112
Total Iteration Time: 7.02384

Cumulative Model Updates: 96,686
Cumulative Timesteps: 806,444,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,998.12861
Policy Entropy: 1.97050
Value Function Loss: 0.07064

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.14313
Policy Update Magnitude: 0.50966
Value Function Update Magnitude: 0.56539

Collected Steps per Second: 15,522.05909
Overall Steps per Second: 6,924.12458

Timestep Collection Time: 3.22277
Timestep Consumption Time: 4.00183
PPO Batch Consumption Time: 0.53378
Total Iteration Time: 7.22460

Cumulative Model Updates: 96,692
Cumulative Timesteps: 806,494,602

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 806494602...
Checkpoint 806494602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,727.34186
Policy Entropy: 1.96525
Value Function Loss: 0.08016

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.15209
Policy Update Magnitude: 0.54866
Value Function Update Magnitude: 0.53396

Collected Steps per Second: 15,428.33747
Overall Steps per Second: 6,998.60893

Timestep Collection Time: 3.24209
Timestep Consumption Time: 3.90505
PPO Batch Consumption Time: 0.51777
Total Iteration Time: 7.14713

Cumulative Model Updates: 96,698
Cumulative Timesteps: 806,544,622

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,702.37204
Policy Entropy: 1.96100
Value Function Loss: 0.07997

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.14706
Policy Update Magnitude: 0.56292
Value Function Update Magnitude: 0.49807

Collected Steps per Second: 15,668.90803
Overall Steps per Second: 7,019.39599

Timestep Collection Time: 3.19154
Timestep Consumption Time: 3.93272
PPO Batch Consumption Time: 0.52473
Total Iteration Time: 7.12426

Cumulative Model Updates: 96,704
Cumulative Timesteps: 806,594,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 806594630...
Checkpoint 806594630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,996.55751
Policy Entropy: 1.96474
Value Function Loss: 0.07918

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.13758
Policy Update Magnitude: 0.56710
Value Function Update Magnitude: 0.43332

Collected Steps per Second: 15,193.06861
Overall Steps per Second: 6,967.98546

Timestep Collection Time: 3.29229
Timestep Consumption Time: 3.88625
PPO Batch Consumption Time: 0.51639
Total Iteration Time: 7.17855

Cumulative Model Updates: 96,710
Cumulative Timesteps: 806,644,650

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,585.54742
Policy Entropy: 1.96727
Value Function Loss: 0.07139

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.55813
Value Function Update Magnitude: 0.43914

Collected Steps per Second: 15,581.58560
Overall Steps per Second: 7,032.15486

Timestep Collection Time: 3.20904
Timestep Consumption Time: 3.90144
PPO Batch Consumption Time: 0.51680
Total Iteration Time: 7.11048

Cumulative Model Updates: 96,716
Cumulative Timesteps: 806,694,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 806694652...
Checkpoint 806694652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,754.12722
Policy Entropy: 1.96557
Value Function Loss: 0.07408

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12903
Policy Update Magnitude: 0.55918
Value Function Update Magnitude: 0.53126

Collected Steps per Second: 15,315.39041
Overall Steps per Second: 7,067.34384

Timestep Collection Time: 3.26547
Timestep Consumption Time: 3.81102
PPO Batch Consumption Time: 0.50472
Total Iteration Time: 7.07649

Cumulative Model Updates: 96,722
Cumulative Timesteps: 806,744,664

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,139.19244
Policy Entropy: 1.97698
Value Function Loss: 0.07426

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.55446
Value Function Update Magnitude: 0.63703

Collected Steps per Second: 15,611.71233
Overall Steps per Second: 7,124.52481

Timestep Collection Time: 3.20516
Timestep Consumption Time: 3.81819
PPO Batch Consumption Time: 0.50508
Total Iteration Time: 7.02335

Cumulative Model Updates: 96,728
Cumulative Timesteps: 806,794,702

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 806794702...
Checkpoint 806794702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,497.80976
Policy Entropy: 1.97048
Value Function Loss: 0.07155

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12874
Policy Update Magnitude: 0.55241
Value Function Update Magnitude: 0.65490

Collected Steps per Second: 15,444.35032
Overall Steps per Second: 7,018.21926

Timestep Collection Time: 3.23756
Timestep Consumption Time: 3.88704
PPO Batch Consumption Time: 0.51540
Total Iteration Time: 7.12460

Cumulative Model Updates: 96,734
Cumulative Timesteps: 806,844,704

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,134.13340
Policy Entropy: 1.98568
Value Function Loss: 0.07420

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.55426
Value Function Update Magnitude: 0.65363

Collected Steps per Second: 15,525.09842
Overall Steps per Second: 7,146.59869

Timestep Collection Time: 3.22059
Timestep Consumption Time: 3.77574
PPO Batch Consumption Time: 0.50144
Total Iteration Time: 6.99634

Cumulative Model Updates: 96,740
Cumulative Timesteps: 806,894,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 806894704...
Checkpoint 806894704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,959.05936
Policy Entropy: 1.97257
Value Function Loss: 0.07744

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.14859
Policy Update Magnitude: 0.53371
Value Function Update Magnitude: 0.67814

Collected Steps per Second: 14,704.11309
Overall Steps per Second: 6,916.93268

Timestep Collection Time: 3.40204
Timestep Consumption Time: 3.83007
PPO Batch Consumption Time: 0.50906
Total Iteration Time: 7.23211

Cumulative Model Updates: 96,746
Cumulative Timesteps: 806,944,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,573.77062
Policy Entropy: 1.97507
Value Function Loss: 0.08082

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.16487
Policy Update Magnitude: 0.47072
Value Function Update Magnitude: 0.66939

Collected Steps per Second: 15,602.89238
Overall Steps per Second: 7,099.58862

Timestep Collection Time: 3.20492
Timestep Consumption Time: 3.83859
PPO Batch Consumption Time: 0.50698
Total Iteration Time: 7.04351

Cumulative Model Updates: 96,752
Cumulative Timesteps: 806,994,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 806994734...
Checkpoint 806994734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,332.92893
Policy Entropy: 1.97772
Value Function Loss: 0.08849

Mean KL Divergence: 0.02831
SB3 Clip Fraction: 0.20314
Policy Update Magnitude: 0.43872
Value Function Update Magnitude: 0.65754

Collected Steps per Second: 15,216.74924
Overall Steps per Second: 6,840.41847

Timestep Collection Time: 3.28730
Timestep Consumption Time: 4.02541
PPO Batch Consumption Time: 0.53741
Total Iteration Time: 7.31271

Cumulative Model Updates: 96,758
Cumulative Timesteps: 807,044,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,445.44355
Policy Entropy: 1.96979
Value Function Loss: 0.08801

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.16256
Policy Update Magnitude: 0.49981
Value Function Update Magnitude: 0.57493

Collected Steps per Second: 15,575.06987
Overall Steps per Second: 7,015.27232

Timestep Collection Time: 3.21308
Timestep Consumption Time: 3.92050
PPO Batch Consumption Time: 0.51922
Total Iteration Time: 7.13358

Cumulative Model Updates: 96,764
Cumulative Timesteps: 807,094,800

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 807094800...
Checkpoint 807094800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,258.10398
Policy Entropy: 1.97518
Value Function Loss: 0.09368

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.15020
Policy Update Magnitude: 0.56420
Value Function Update Magnitude: 0.53303

Collected Steps per Second: 15,593.39281
Overall Steps per Second: 7,052.32669

Timestep Collection Time: 3.20956
Timestep Consumption Time: 3.88710
PPO Batch Consumption Time: 0.51604
Total Iteration Time: 7.09666

Cumulative Model Updates: 96,770
Cumulative Timesteps: 807,144,848

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,993.98716
Policy Entropy: 1.95011
Value Function Loss: 0.08241

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.16866
Policy Update Magnitude: 0.57275
Value Function Update Magnitude: 0.72391

Collected Steps per Second: 15,598.60010
Overall Steps per Second: 7,029.44563

Timestep Collection Time: 3.20657
Timestep Consumption Time: 3.90893
PPO Batch Consumption Time: 0.51863
Total Iteration Time: 7.11550

Cumulative Model Updates: 96,776
Cumulative Timesteps: 807,194,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 807194866...
Checkpoint 807194866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,916.67776
Policy Entropy: 1.95534
Value Function Loss: 0.08363

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.17515
Policy Update Magnitude: 0.57161
Value Function Update Magnitude: 0.65777

Collected Steps per Second: 15,321.45845
Overall Steps per Second: 7,049.29378

Timestep Collection Time: 3.26340
Timestep Consumption Time: 3.82951
PPO Batch Consumption Time: 0.50420
Total Iteration Time: 7.09291

Cumulative Model Updates: 96,782
Cumulative Timesteps: 807,244,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,514.71690
Policy Entropy: 1.94591
Value Function Loss: 0.07919

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.15382
Policy Update Magnitude: 0.56264
Value Function Update Magnitude: 0.72370

Collected Steps per Second: 15,584.13117
Overall Steps per Second: 7,086.75605

Timestep Collection Time: 3.20916
Timestep Consumption Time: 3.84795
PPO Batch Consumption Time: 0.51012
Total Iteration Time: 7.05711

Cumulative Model Updates: 96,788
Cumulative Timesteps: 807,294,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 807294878...
Checkpoint 807294878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,222.47099
Policy Entropy: 1.96049
Value Function Loss: 0.07803

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.15156
Policy Update Magnitude: 0.57368
Value Function Update Magnitude: 0.74925

Collected Steps per Second: 15,399.29735
Overall Steps per Second: 6,956.97187

Timestep Collection Time: 3.24794
Timestep Consumption Time: 3.94139
PPO Batch Consumption Time: 0.52870
Total Iteration Time: 7.18933

Cumulative Model Updates: 96,794
Cumulative Timesteps: 807,344,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,233.45276
Policy Entropy: 1.96558
Value Function Loss: 0.07449

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.56432
Value Function Update Magnitude: 0.74310

Collected Steps per Second: 15,734.33802
Overall Steps per Second: 7,126.84715

Timestep Collection Time: 3.17802
Timestep Consumption Time: 3.83827
PPO Batch Consumption Time: 0.50804
Total Iteration Time: 7.01629

Cumulative Model Updates: 96,800
Cumulative Timesteps: 807,394,898

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 807394898...
Checkpoint 807394898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,043.76805
Policy Entropy: 1.97100
Value Function Loss: 0.07787

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.57667
Value Function Update Magnitude: 0.72850

Collected Steps per Second: 15,186.09065
Overall Steps per Second: 6,906.74385

Timestep Collection Time: 3.29315
Timestep Consumption Time: 3.94760
PPO Batch Consumption Time: 0.52502
Total Iteration Time: 7.24075

Cumulative Model Updates: 96,806
Cumulative Timesteps: 807,444,908

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,180.82320
Policy Entropy: 1.96380
Value Function Loss: 0.07508

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.58074
Value Function Update Magnitude: 0.74703

Collected Steps per Second: 15,728.32635
Overall Steps per Second: 7,158.79984

Timestep Collection Time: 3.17923
Timestep Consumption Time: 3.80574
PPO Batch Consumption Time: 0.50255
Total Iteration Time: 6.98497

Cumulative Model Updates: 96,812
Cumulative Timesteps: 807,494,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 807494912...
Checkpoint 807494912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,200.04679
Policy Entropy: 1.96497
Value Function Loss: 0.07344

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.58204
Value Function Update Magnitude: 0.72122

Collected Steps per Second: 15,409.14649
Overall Steps per Second: 7,085.50610

Timestep Collection Time: 3.24768
Timestep Consumption Time: 3.81519
PPO Batch Consumption Time: 0.50966
Total Iteration Time: 7.06287

Cumulative Model Updates: 96,818
Cumulative Timesteps: 807,544,956

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,058.72406
Policy Entropy: 1.96167
Value Function Loss: 0.07546

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.58260
Value Function Update Magnitude: 0.64522

Collected Steps per Second: 15,531.95534
Overall Steps per Second: 6,915.06040

Timestep Collection Time: 3.21956
Timestep Consumption Time: 4.01191
PPO Batch Consumption Time: 0.53624
Total Iteration Time: 7.23146

Cumulative Model Updates: 96,824
Cumulative Timesteps: 807,594,962

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 807594962...
Checkpoint 807594962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,742.15725
Policy Entropy: 1.96423
Value Function Loss: 0.07568

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.58316
Value Function Update Magnitude: 0.63557

Collected Steps per Second: 15,622.40082
Overall Steps per Second: 7,110.09686

Timestep Collection Time: 3.20053
Timestep Consumption Time: 3.83172
PPO Batch Consumption Time: 0.50670
Total Iteration Time: 7.03225

Cumulative Model Updates: 96,830
Cumulative Timesteps: 807,644,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,567.81979
Policy Entropy: 1.96960
Value Function Loss: 0.08147

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.57587
Value Function Update Magnitude: 0.73724

Collected Steps per Second: 15,510.03834
Overall Steps per Second: 7,083.99921

Timestep Collection Time: 3.22462
Timestep Consumption Time: 3.83552
PPO Batch Consumption Time: 0.51267
Total Iteration Time: 7.06014

Cumulative Model Updates: 96,836
Cumulative Timesteps: 807,694,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 807694976...
Checkpoint 807694976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,849.16324
Policy Entropy: 1.95735
Value Function Loss: 0.08304

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.56149
Value Function Update Magnitude: 0.73468

Collected Steps per Second: 15,231.17603
Overall Steps per Second: 6,937.66636

Timestep Collection Time: 3.28405
Timestep Consumption Time: 3.92586
PPO Batch Consumption Time: 0.52144
Total Iteration Time: 7.20992

Cumulative Model Updates: 96,842
Cumulative Timesteps: 807,744,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,625.36558
Policy Entropy: 1.96645
Value Function Loss: 0.08299

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.16708
Policy Update Magnitude: 0.50667
Value Function Update Magnitude: 0.72148

Collected Steps per Second: 15,573.69441
Overall Steps per Second: 7,060.09328

Timestep Collection Time: 3.21054
Timestep Consumption Time: 3.87152
PPO Batch Consumption Time: 0.51043
Total Iteration Time: 7.08206

Cumulative Model Updates: 96,848
Cumulative Timesteps: 807,794,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 807794996...
Checkpoint 807794996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,169.50158
Policy Entropy: 1.96932
Value Function Loss: 0.07542

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.16261
Policy Update Magnitude: 0.47405
Value Function Update Magnitude: 0.69821

Collected Steps per Second: 15,517.20335
Overall Steps per Second: 7,122.06559

Timestep Collection Time: 3.22365
Timestep Consumption Time: 3.79988
PPO Batch Consumption Time: 0.50092
Total Iteration Time: 7.02352

Cumulative Model Updates: 96,854
Cumulative Timesteps: 807,845,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,588.29194
Policy Entropy: 1.97679
Value Function Loss: 0.07636

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.50044
Value Function Update Magnitude: 0.65644

Collected Steps per Second: 15,692.97037
Overall Steps per Second: 7,012.07298

Timestep Collection Time: 3.18792
Timestep Consumption Time: 3.94663
PPO Batch Consumption Time: 0.52506
Total Iteration Time: 7.13455

Cumulative Model Updates: 96,860
Cumulative Timesteps: 807,895,046

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 807895046...
Checkpoint 807895046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,131.15574
Policy Entropy: 1.97493
Value Function Loss: 0.07511

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.15094
Policy Update Magnitude: 0.50272
Value Function Update Magnitude: 0.68874

Collected Steps per Second: 15,415.51098
Overall Steps per Second: 7,021.72072

Timestep Collection Time: 3.24517
Timestep Consumption Time: 3.87929
PPO Batch Consumption Time: 0.51359
Total Iteration Time: 7.12446

Cumulative Model Updates: 96,866
Cumulative Timesteps: 807,945,072

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,173.85228
Policy Entropy: 1.97178
Value Function Loss: 0.07608

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.14890
Policy Update Magnitude: 0.52176
Value Function Update Magnitude: 0.70155

Collected Steps per Second: 15,516.69804
Overall Steps per Second: 6,977.52195

Timestep Collection Time: 3.22337
Timestep Consumption Time: 3.94479
PPO Batch Consumption Time: 0.52432
Total Iteration Time: 7.16816

Cumulative Model Updates: 96,872
Cumulative Timesteps: 807,995,088

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 807995088...
Checkpoint 807995088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,148.30305
Policy Entropy: 1.95868
Value Function Loss: 0.07387

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.55984
Value Function Update Magnitude: 0.62730

Collected Steps per Second: 15,077.54532
Overall Steps per Second: 7,022.49242

Timestep Collection Time: 3.31712
Timestep Consumption Time: 3.80485
PPO Batch Consumption Time: 0.50149
Total Iteration Time: 7.12197

Cumulative Model Updates: 96,878
Cumulative Timesteps: 808,045,102

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,014.33169
Policy Entropy: 1.96647
Value Function Loss: 0.08210

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.57535
Value Function Update Magnitude: 0.51654

Collected Steps per Second: 15,769.40234
Overall Steps per Second: 7,081.72199

Timestep Collection Time: 3.17247
Timestep Consumption Time: 3.89191
PPO Batch Consumption Time: 0.51603
Total Iteration Time: 7.06438

Cumulative Model Updates: 96,884
Cumulative Timesteps: 808,095,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 808095130...
Checkpoint 808095130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,195.81483
Policy Entropy: 1.97137
Value Function Loss: 0.07842

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13744
Policy Update Magnitude: 0.56358
Value Function Update Magnitude: 0.51310

Collected Steps per Second: 15,280.22096
Overall Steps per Second: 6,964.24495

Timestep Collection Time: 3.27430
Timestep Consumption Time: 3.90983
PPO Batch Consumption Time: 0.51935
Total Iteration Time: 7.18412

Cumulative Model Updates: 96,890
Cumulative Timesteps: 808,145,162

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,413.71112
Policy Entropy: 1.98596
Value Function Loss: 0.07780

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.56343
Value Function Update Magnitude: 0.52558

Collected Steps per Second: 15,589.78821
Overall Steps per Second: 6,968.27151

Timestep Collection Time: 3.20915
Timestep Consumption Time: 3.97053
PPO Batch Consumption Time: 0.52460
Total Iteration Time: 7.17969

Cumulative Model Updates: 96,896
Cumulative Timesteps: 808,195,192

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 808195192...
Checkpoint 808195192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,100.33144
Policy Entropy: 1.98187
Value Function Loss: 0.07787

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.57213
Value Function Update Magnitude: 0.57079

Collected Steps per Second: 15,324.95429
Overall Steps per Second: 6,926.97927

Timestep Collection Time: 3.26539
Timestep Consumption Time: 3.95882
PPO Batch Consumption Time: 0.52499
Total Iteration Time: 7.22422

Cumulative Model Updates: 96,902
Cumulative Timesteps: 808,245,234

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,083.40086
Policy Entropy: 2.00261
Value Function Loss: 0.08363

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.14432
Policy Update Magnitude: 0.57289
Value Function Update Magnitude: 0.62716

Collected Steps per Second: 15,332.50755
Overall Steps per Second: 7,008.78694

Timestep Collection Time: 3.26170
Timestep Consumption Time: 3.87363
PPO Batch Consumption Time: 0.51664
Total Iteration Time: 7.13533

Cumulative Model Updates: 96,908
Cumulative Timesteps: 808,295,244

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 808295244...
Checkpoint 808295244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,345.00058
Policy Entropy: 1.98326
Value Function Loss: 0.08737

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.53798
Value Function Update Magnitude: 0.70211

Collected Steps per Second: 15,416.35831
Overall Steps per Second: 7,019.67449

Timestep Collection Time: 3.24525
Timestep Consumption Time: 3.88186
PPO Batch Consumption Time: 0.51540
Total Iteration Time: 7.12711

Cumulative Model Updates: 96,914
Cumulative Timesteps: 808,345,274

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,534.79102
Policy Entropy: 1.99740
Value Function Loss: 0.09128

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.16145
Policy Update Magnitude: 0.48333
Value Function Update Magnitude: 0.73256

Collected Steps per Second: 15,499.57441
Overall Steps per Second: 6,910.38728

Timestep Collection Time: 3.22796
Timestep Consumption Time: 4.01216
PPO Batch Consumption Time: 0.53564
Total Iteration Time: 7.24012

Cumulative Model Updates: 96,920
Cumulative Timesteps: 808,395,306

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 808395306...
Checkpoint 808395306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,087.28367
Policy Entropy: 1.98977
Value Function Loss: 0.08991

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14732
Policy Update Magnitude: 0.45150
Value Function Update Magnitude: 0.76479

Collected Steps per Second: 15,408.83833
Overall Steps per Second: 7,067.52093

Timestep Collection Time: 3.24632
Timestep Consumption Time: 3.83141
PPO Batch Consumption Time: 0.50645
Total Iteration Time: 7.07773

Cumulative Model Updates: 96,926
Cumulative Timesteps: 808,445,328

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,507.11950
Policy Entropy: 2.00404
Value Function Loss: 0.08544

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.46084
Value Function Update Magnitude: 0.78165

Collected Steps per Second: 15,404.15297
Overall Steps per Second: 6,897.80368

Timestep Collection Time: 3.24692
Timestep Consumption Time: 4.00409
PPO Batch Consumption Time: 0.53043
Total Iteration Time: 7.25100

Cumulative Model Updates: 96,932
Cumulative Timesteps: 808,495,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 808495344...
Checkpoint 808495344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,757.17495
Policy Entropy: 2.00903
Value Function Loss: 0.08472

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13838
Policy Update Magnitude: 0.50386
Value Function Update Magnitude: 0.75049

Collected Steps per Second: 15,431.69827
Overall Steps per Second: 6,974.51335

Timestep Collection Time: 3.24060
Timestep Consumption Time: 3.92950
PPO Batch Consumption Time: 0.52199
Total Iteration Time: 7.17011

Cumulative Model Updates: 96,938
Cumulative Timesteps: 808,545,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,993.99481
Policy Entropy: 1.98956
Value Function Loss: 0.08708

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.16204
Policy Update Magnitude: 0.47386
Value Function Update Magnitude: 0.64194

Collected Steps per Second: 15,530.08682
Overall Steps per Second: 7,036.76051

Timestep Collection Time: 3.21969
Timestep Consumption Time: 3.88614
PPO Batch Consumption Time: 0.52061
Total Iteration Time: 7.10583

Cumulative Model Updates: 96,944
Cumulative Timesteps: 808,595,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 808595354...
Checkpoint 808595354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,373.67949
Policy Entropy: 1.97770
Value Function Loss: 0.08836

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.15319
Policy Update Magnitude: 0.47971
Value Function Update Magnitude: 0.50558

Collected Steps per Second: 15,150.34069
Overall Steps per Second: 7,036.50188

Timestep Collection Time: 3.30131
Timestep Consumption Time: 3.80677
PPO Batch Consumption Time: 0.50331
Total Iteration Time: 7.10808

Cumulative Model Updates: 96,950
Cumulative Timesteps: 808,645,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,797.96723
Policy Entropy: 1.96243
Value Function Loss: 0.08423

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.51488
Value Function Update Magnitude: 0.60812

Collected Steps per Second: 15,578.92093
Overall Steps per Second: 7,134.47683

Timestep Collection Time: 3.21011
Timestep Consumption Time: 3.79952
PPO Batch Consumption Time: 0.50623
Total Iteration Time: 7.00962

Cumulative Model Updates: 96,956
Cumulative Timesteps: 808,695,380

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 808695380...
Checkpoint 808695380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,839.42664
Policy Entropy: 1.95394
Value Function Loss: 0.07990

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.15796
Policy Update Magnitude: 0.51695
Value Function Update Magnitude: 0.60154

Collected Steps per Second: 15,428.38765
Overall Steps per Second: 6,898.81323

Timestep Collection Time: 3.24143
Timestep Consumption Time: 4.00765
PPO Batch Consumption Time: 0.53424
Total Iteration Time: 7.24907

Cumulative Model Updates: 96,962
Cumulative Timesteps: 808,745,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,596.48215
Policy Entropy: 1.97257
Value Function Loss: 0.07864

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.15121
Policy Update Magnitude: 0.50384
Value Function Update Magnitude: 0.58667

Collected Steps per Second: 15,392.77008
Overall Steps per Second: 7,034.41683

Timestep Collection Time: 3.25023
Timestep Consumption Time: 3.86195
PPO Batch Consumption Time: 0.50990
Total Iteration Time: 7.11217

Cumulative Model Updates: 96,968
Cumulative Timesteps: 808,795,420

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 808795420...
Checkpoint 808795420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,560.29753
Policy Entropy: 1.97911
Value Function Loss: 0.07707

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.53681
Value Function Update Magnitude: 0.56876

Collected Steps per Second: 15,287.68004
Overall Steps per Second: 6,976.27621

Timestep Collection Time: 3.27257
Timestep Consumption Time: 3.89888
PPO Batch Consumption Time: 0.51850
Total Iteration Time: 7.17145

Cumulative Model Updates: 96,974
Cumulative Timesteps: 808,845,450

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,232.65167
Policy Entropy: 2.00415
Value Function Loss: 0.07953

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.56993
Value Function Update Magnitude: 0.59319

Collected Steps per Second: 15,555.81425
Overall Steps per Second: 7,035.00102

Timestep Collection Time: 3.21616
Timestep Consumption Time: 3.89542
PPO Batch Consumption Time: 0.51807
Total Iteration Time: 7.11158

Cumulative Model Updates: 96,980
Cumulative Timesteps: 808,895,480

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 808895480...
Checkpoint 808895480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,419.73379
Policy Entropy: 2.01376
Value Function Loss: 0.08500

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.57337
Value Function Update Magnitude: 0.68267

Collected Steps per Second: 15,338.76437
Overall Steps per Second: 6,949.39914

Timestep Collection Time: 3.26063
Timestep Consumption Time: 3.93625
PPO Batch Consumption Time: 0.52537
Total Iteration Time: 7.19688

Cumulative Model Updates: 96,986
Cumulative Timesteps: 808,945,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,111.49657
Policy Entropy: 2.02230
Value Function Loss: 0.09227

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.15511
Policy Update Magnitude: 0.54974
Value Function Update Magnitude: 0.70208

Collected Steps per Second: 15,311.05903
Overall Steps per Second: 6,894.23153

Timestep Collection Time: 3.26705
Timestep Consumption Time: 3.98858
PPO Batch Consumption Time: 0.53448
Total Iteration Time: 7.25563

Cumulative Model Updates: 96,992
Cumulative Timesteps: 808,995,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 808995516...
Checkpoint 808995516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,940.56827
Policy Entropy: 2.02774
Value Function Loss: 0.10195

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.16073
Policy Update Magnitude: 0.49909
Value Function Update Magnitude: 0.69669

Collected Steps per Second: 15,142.82684
Overall Steps per Second: 7,051.53513

Timestep Collection Time: 3.30189
Timestep Consumption Time: 3.78876
PPO Batch Consumption Time: 0.50516
Total Iteration Time: 7.09065

Cumulative Model Updates: 96,998
Cumulative Timesteps: 809,045,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,676.10374
Policy Entropy: 2.01253
Value Function Loss: 0.10222

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.16106
Policy Update Magnitude: 0.50530
Value Function Update Magnitude: 0.74593

Collected Steps per Second: 15,797.26783
Overall Steps per Second: 7,202.94796

Timestep Collection Time: 3.16574
Timestep Consumption Time: 3.77725
PPO Batch Consumption Time: 0.49974
Total Iteration Time: 6.94299

Cumulative Model Updates: 97,004
Cumulative Timesteps: 809,095,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 809095526...
Checkpoint 809095526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,699.39914
Policy Entropy: 1.99704
Value Function Loss: 0.08954

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.15575
Policy Update Magnitude: 0.51302
Value Function Update Magnitude: 0.75727

Collected Steps per Second: 15,132.45130
Overall Steps per Second: 6,841.49677

Timestep Collection Time: 3.30588
Timestep Consumption Time: 4.00627
PPO Batch Consumption Time: 0.53791
Total Iteration Time: 7.31214

Cumulative Model Updates: 97,010
Cumulative Timesteps: 809,145,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,200.34262
Policy Entropy: 1.98451
Value Function Loss: 0.08323

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.13404
Policy Update Magnitude: 0.54840
Value Function Update Magnitude: 0.71400

Collected Steps per Second: 15,457.95887
Overall Steps per Second: 6,930.01605

Timestep Collection Time: 3.23613
Timestep Consumption Time: 3.98232
PPO Batch Consumption Time: 0.53052
Total Iteration Time: 7.21845

Cumulative Model Updates: 97,016
Cumulative Timesteps: 809,195,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 809195576...
Checkpoint 809195576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,014.71242
Policy Entropy: 1.98685
Value Function Loss: 0.08049

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.57892
Value Function Update Magnitude: 0.63832

Collected Steps per Second: 15,340.72313
Overall Steps per Second: 7,067.76222

Timestep Collection Time: 3.26008
Timestep Consumption Time: 3.81599
PPO Batch Consumption Time: 0.50386
Total Iteration Time: 7.07607

Cumulative Model Updates: 97,022
Cumulative Timesteps: 809,245,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,885.84618
Policy Entropy: 2.00506
Value Function Loss: 0.08253

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.58245
Value Function Update Magnitude: 0.65592

Collected Steps per Second: 15,589.73385
Overall Steps per Second: 6,989.46664

Timestep Collection Time: 3.20903
Timestep Consumption Time: 3.94859
PPO Batch Consumption Time: 0.52433
Total Iteration Time: 7.15763

Cumulative Model Updates: 97,028
Cumulative Timesteps: 809,295,616

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 809295616...
Checkpoint 809295616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,302.15653
Policy Entropy: 2.01108
Value Function Loss: 0.08069

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.14925
Policy Update Magnitude: 0.56990
Value Function Update Magnitude: 0.68434

Collected Steps per Second: 15,391.11370
Overall Steps per Second: 6,887.82275

Timestep Collection Time: 3.24889
Timestep Consumption Time: 4.01088
PPO Batch Consumption Time: 0.53896
Total Iteration Time: 7.25977

Cumulative Model Updates: 97,034
Cumulative Timesteps: 809,345,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,259.13020
Policy Entropy: 2.00014
Value Function Loss: 0.07688

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.54869
Value Function Update Magnitude: 0.69009

Collected Steps per Second: 15,666.94441
Overall Steps per Second: 6,982.49496

Timestep Collection Time: 3.19348
Timestep Consumption Time: 3.97187
PPO Batch Consumption Time: 0.52656
Total Iteration Time: 7.16535

Cumulative Model Updates: 97,040
Cumulative Timesteps: 809,395,652

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 809395652...
Checkpoint 809395652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,094.40550
Policy Entropy: 1.99978
Value Function Loss: 0.07619

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.14891
Policy Update Magnitude: 0.54860
Value Function Update Magnitude: 0.69876

Collected Steps per Second: 15,486.02114
Overall Steps per Second: 7,035.59621

Timestep Collection Time: 3.22975
Timestep Consumption Time: 3.87924
PPO Batch Consumption Time: 0.51697
Total Iteration Time: 7.10899

Cumulative Model Updates: 97,046
Cumulative Timesteps: 809,445,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,651.58779
Policy Entropy: 2.00340
Value Function Loss: 0.07033

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.15197
Policy Update Magnitude: 0.55433
Value Function Update Magnitude: 0.68017

Collected Steps per Second: 15,566.76509
Overall Steps per Second: 7,109.38950

Timestep Collection Time: 3.21274
Timestep Consumption Time: 3.82190
PPO Batch Consumption Time: 0.50546
Total Iteration Time: 7.03464

Cumulative Model Updates: 97,052
Cumulative Timesteps: 809,495,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 809495680...
Checkpoint 809495680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,174.51213
Policy Entropy: 2.00968
Value Function Loss: 0.07127

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.15138
Policy Update Magnitude: 0.53888
Value Function Update Magnitude: 0.66261

Collected Steps per Second: 15,512.97232
Overall Steps per Second: 7,109.63832

Timestep Collection Time: 3.22388
Timestep Consumption Time: 3.81051
PPO Batch Consumption Time: 0.50571
Total Iteration Time: 7.03439

Cumulative Model Updates: 97,058
Cumulative Timesteps: 809,545,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,550.64438
Policy Entropy: 2.00175
Value Function Loss: 0.06960

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.54688
Value Function Update Magnitude: 0.68019

Collected Steps per Second: 15,617.47644
Overall Steps per Second: 7,141.93963

Timestep Collection Time: 3.20410
Timestep Consumption Time: 3.80240
PPO Batch Consumption Time: 0.50316
Total Iteration Time: 7.00650

Cumulative Model Updates: 97,064
Cumulative Timesteps: 809,595,732

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 809595732...
Checkpoint 809595732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,329.38094
Policy Entropy: 1.98851
Value Function Loss: 0.07523

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.14846
Policy Update Magnitude: 0.56951
Value Function Update Magnitude: 0.68932

Collected Steps per Second: 15,472.03606
Overall Steps per Second: 6,955.19333

Timestep Collection Time: 3.23474
Timestep Consumption Time: 3.96104
PPO Batch Consumption Time: 0.52917
Total Iteration Time: 7.19577

Cumulative Model Updates: 97,070
Cumulative Timesteps: 809,645,780

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,764.83845
Policy Entropy: 1.97858
Value Function Loss: 0.07236

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13945
Policy Update Magnitude: 0.57172
Value Function Update Magnitude: 0.69528

Collected Steps per Second: 15,652.47328
Overall Steps per Second: 7,072.30430

Timestep Collection Time: 3.19515
Timestep Consumption Time: 3.87638
PPO Batch Consumption Time: 0.51410
Total Iteration Time: 7.07153

Cumulative Model Updates: 97,076
Cumulative Timesteps: 809,695,792

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 809695792...
Checkpoint 809695792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,776.15009
Policy Entropy: 2.00471
Value Function Loss: 0.07336

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.57029
Value Function Update Magnitude: 0.66325

Collected Steps per Second: 15,472.99845
Overall Steps per Second: 7,019.13162

Timestep Collection Time: 3.23182
Timestep Consumption Time: 3.89242
PPO Batch Consumption Time: 0.52017
Total Iteration Time: 7.12424

Cumulative Model Updates: 97,082
Cumulative Timesteps: 809,745,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,356.94660
Policy Entropy: 2.00037
Value Function Loss: 0.07143

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 0.56955
Value Function Update Magnitude: 0.54490

Collected Steps per Second: 15,607.52294
Overall Steps per Second: 7,007.70102

Timestep Collection Time: 3.20474
Timestep Consumption Time: 3.93284
PPO Batch Consumption Time: 0.52399
Total Iteration Time: 7.13758

Cumulative Model Updates: 97,088
Cumulative Timesteps: 809,795,816

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 809795816...
Checkpoint 809795816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,708.10795
Policy Entropy: 2.01292
Value Function Loss: 0.07446

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.57291
Value Function Update Magnitude: 0.43377

Collected Steps per Second: 15,155.36721
Overall Steps per Second: 6,945.11284

Timestep Collection Time: 3.30048
Timestep Consumption Time: 3.90171
PPO Batch Consumption Time: 0.51858
Total Iteration Time: 7.20219

Cumulative Model Updates: 97,094
Cumulative Timesteps: 809,845,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,402.19371
Policy Entropy: 1.99180
Value Function Loss: 0.07776

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.57484
Value Function Update Magnitude: 0.44844

Collected Steps per Second: 15,699.98635
Overall Steps per Second: 7,137.71728

Timestep Collection Time: 3.18523
Timestep Consumption Time: 3.82094
PPO Batch Consumption Time: 0.50498
Total Iteration Time: 7.00616

Cumulative Model Updates: 97,100
Cumulative Timesteps: 809,895,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 809895844...
Checkpoint 809895844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,843.35843
Policy Entropy: 2.00495
Value Function Loss: 0.08284

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.57676
Value Function Update Magnitude: 0.40690

Collected Steps per Second: 15,402.84010
Overall Steps per Second: 7,072.87314

Timestep Collection Time: 3.24901
Timestep Consumption Time: 3.82647
PPO Batch Consumption Time: 0.50947
Total Iteration Time: 7.07548

Cumulative Model Updates: 97,106
Cumulative Timesteps: 809,945,888

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,740.39113
Policy Entropy: 1.97792
Value Function Loss: 0.07951

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13283
Policy Update Magnitude: 0.57069
Value Function Update Magnitude: 0.52247

Collected Steps per Second: 15,215.35370
Overall Steps per Second: 6,984.01402

Timestep Collection Time: 3.28615
Timestep Consumption Time: 3.87305
PPO Batch Consumption Time: 0.51101
Total Iteration Time: 7.15921

Cumulative Model Updates: 97,112
Cumulative Timesteps: 809,995,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 809995888...
Checkpoint 809995888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,461.39137
Policy Entropy: 1.96263
Value Function Loss: 0.07293

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.57488
Value Function Update Magnitude: 0.64464

Collected Steps per Second: 15,434.24947
Overall Steps per Second: 7,045.48409

Timestep Collection Time: 3.23968
Timestep Consumption Time: 3.85735
PPO Batch Consumption Time: 0.51336
Total Iteration Time: 7.09703

Cumulative Model Updates: 97,118
Cumulative Timesteps: 810,045,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,995.73754
Policy Entropy: 1.95543
Value Function Loss: 0.06775

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12573
Policy Update Magnitude: 0.57927
Value Function Update Magnitude: 0.66865

Collected Steps per Second: 15,191.21535
Overall Steps per Second: 6,920.19570

Timestep Collection Time: 3.29282
Timestep Consumption Time: 3.93558
PPO Batch Consumption Time: 0.53705
Total Iteration Time: 7.22841

Cumulative Model Updates: 97,124
Cumulative Timesteps: 810,095,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 810095912...
Checkpoint 810095912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,463.14781
Policy Entropy: 1.96362
Value Function Loss: 0.06884

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.57799
Value Function Update Magnitude: 0.63371

Collected Steps per Second: 15,003.62001
Overall Steps per Second: 6,958.83422

Timestep Collection Time: 3.33466
Timestep Consumption Time: 3.85505
PPO Batch Consumption Time: 0.52727
Total Iteration Time: 7.18971

Cumulative Model Updates: 97,130
Cumulative Timesteps: 810,145,944

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,015.52434
Policy Entropy: 1.97797
Value Function Loss: 0.06665

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.54697
Value Function Update Magnitude: 0.62068

Collected Steps per Second: 15,157.13642
Overall Steps per Second: 7,127.86746

Timestep Collection Time: 3.29970
Timestep Consumption Time: 3.71699
PPO Batch Consumption Time: 0.50124
Total Iteration Time: 7.01668

Cumulative Model Updates: 97,136
Cumulative Timesteps: 810,195,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 810195958...
Checkpoint 810195958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,709.24394
Policy Entropy: 1.98649
Value Function Loss: 0.07166

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.14210
Policy Update Magnitude: 0.49726
Value Function Update Magnitude: 0.59244

Collected Steps per Second: 14,947.68713
Overall Steps per Second: 7,027.74616

Timestep Collection Time: 3.34513
Timestep Consumption Time: 3.76981
PPO Batch Consumption Time: 0.51176
Total Iteration Time: 7.11494

Cumulative Model Updates: 97,142
Cumulative Timesteps: 810,245,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,878.51186
Policy Entropy: 1.98632
Value Function Loss: 0.07292

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.53615
Value Function Update Magnitude: 0.60965

Collected Steps per Second: 15,342.94933
Overall Steps per Second: 7,094.00307

Timestep Collection Time: 3.26065
Timestep Consumption Time: 3.79150
PPO Batch Consumption Time: 0.51530
Total Iteration Time: 7.05215

Cumulative Model Updates: 97,148
Cumulative Timesteps: 810,295,988

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 810295988...
Checkpoint 810295988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,243.50472
Policy Entropy: 1.98232
Value Function Loss: 0.07369

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.15182
Policy Update Magnitude: 0.52100
Value Function Update Magnitude: 0.60674

Collected Steps per Second: 15,208.70456
Overall Steps per Second: 7,094.16501

Timestep Collection Time: 3.28812
Timestep Consumption Time: 3.76106
PPO Batch Consumption Time: 0.51336
Total Iteration Time: 7.04917

Cumulative Model Updates: 97,154
Cumulative Timesteps: 810,345,996

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,418.84150
Policy Entropy: 1.98453
Value Function Loss: 0.07648

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.15944
Policy Update Magnitude: 0.54160
Value Function Update Magnitude: 0.68147

Collected Steps per Second: 15,308.81798
Overall Steps per Second: 6,864.25915

Timestep Collection Time: 3.26674
Timestep Consumption Time: 4.01882
PPO Batch Consumption Time: 0.54259
Total Iteration Time: 7.28556

Cumulative Model Updates: 97,160
Cumulative Timesteps: 810,396,006

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 810396006...
Checkpoint 810396006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,356.67654
Policy Entropy: 1.97562
Value Function Loss: 0.08091

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.55795
Value Function Update Magnitude: 0.71291

Collected Steps per Second: 15,364.60271
Overall Steps per Second: 7,070.40780

Timestep Collection Time: 3.25501
Timestep Consumption Time: 3.81841
PPO Batch Consumption Time: 0.51192
Total Iteration Time: 7.07343

Cumulative Model Updates: 97,166
Cumulative Timesteps: 810,446,018

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,481.65352
Policy Entropy: 1.98075
Value Function Loss: 0.08443

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.59204
Value Function Update Magnitude: 0.65351

Collected Steps per Second: 15,474.56025
Overall Steps per Second: 7,034.32113

Timestep Collection Time: 3.23201
Timestep Consumption Time: 3.87798
PPO Batch Consumption Time: 0.52186
Total Iteration Time: 7.11000

Cumulative Model Updates: 97,172
Cumulative Timesteps: 810,496,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 810496032...
Checkpoint 810496032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,775.94275
Policy Entropy: 1.98954
Value Function Loss: 0.08217

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14236
Policy Update Magnitude: 0.59620
Value Function Update Magnitude: 0.68831

Collected Steps per Second: 15,396.25740
Overall Steps per Second: 6,945.61007

Timestep Collection Time: 3.24884
Timestep Consumption Time: 3.95283
PPO Batch Consumption Time: 0.53106
Total Iteration Time: 7.20167

Cumulative Model Updates: 97,178
Cumulative Timesteps: 810,546,052

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,544.39993
Policy Entropy: 2.00198
Value Function Loss: 0.07300

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.58870
Value Function Update Magnitude: 0.68473

Collected Steps per Second: 15,432.58765
Overall Steps per Second: 7,000.88722

Timestep Collection Time: 3.24184
Timestep Consumption Time: 3.90440
PPO Batch Consumption Time: 0.52207
Total Iteration Time: 7.14624

Cumulative Model Updates: 97,184
Cumulative Timesteps: 810,596,082

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 810596082...
Checkpoint 810596082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,227.45945
Policy Entropy: 1.98060
Value Function Loss: 0.07393

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.58561
Value Function Update Magnitude: 0.64467

Collected Steps per Second: 15,500.35031
Overall Steps per Second: 6,983.63116

Timestep Collection Time: 3.22728
Timestep Consumption Time: 3.93575
PPO Batch Consumption Time: 0.52305
Total Iteration Time: 7.16304

Cumulative Model Updates: 97,190
Cumulative Timesteps: 810,646,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,503.40346
Policy Entropy: 1.97325
Value Function Loss: 0.07049

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.58084
Value Function Update Magnitude: 0.55382

Collected Steps per Second: 15,527.06844
Overall Steps per Second: 7,035.93088

Timestep Collection Time: 3.22224
Timestep Consumption Time: 3.88868
PPO Batch Consumption Time: 0.51585
Total Iteration Time: 7.11093

Cumulative Model Updates: 97,196
Cumulative Timesteps: 810,696,138

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 810696138...
Checkpoint 810696138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,406.00366
Policy Entropy: 1.96138
Value Function Loss: 0.07673

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.57509
Value Function Update Magnitude: 0.50364

Collected Steps per Second: 15,205.60015
Overall Steps per Second: 7,007.99618

Timestep Collection Time: 3.28918
Timestep Consumption Time: 3.84752
PPO Batch Consumption Time: 0.51272
Total Iteration Time: 7.13670

Cumulative Model Updates: 97,202
Cumulative Timesteps: 810,746,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,958.90302
Policy Entropy: 1.96875
Value Function Loss: 0.07631

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.57796
Value Function Update Magnitude: 0.49507

Collected Steps per Second: 15,525.27025
Overall Steps per Second: 7,096.69269

Timestep Collection Time: 3.22197
Timestep Consumption Time: 3.82666
PPO Batch Consumption Time: 0.50470
Total Iteration Time: 7.04864

Cumulative Model Updates: 97,208
Cumulative Timesteps: 810,796,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 810796174...
Checkpoint 810796174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,584.46672
Policy Entropy: 1.95466
Value Function Loss: 0.07797

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.57997
Value Function Update Magnitude: 0.54663

Collected Steps per Second: 15,145.41777
Overall Steps per Second: 6,890.14053

Timestep Collection Time: 3.30371
Timestep Consumption Time: 3.95827
PPO Batch Consumption Time: 0.52823
Total Iteration Time: 7.26197

Cumulative Model Updates: 97,214
Cumulative Timesteps: 810,846,210

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,410.10029
Policy Entropy: 1.95317
Value Function Loss: 0.07799

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13528
Policy Update Magnitude: 0.58348
Value Function Update Magnitude: 0.58372

Collected Steps per Second: 15,724.80194
Overall Steps per Second: 7,054.41053

Timestep Collection Time: 3.18058
Timestep Consumption Time: 3.90917
PPO Batch Consumption Time: 0.51828
Total Iteration Time: 7.08975

Cumulative Model Updates: 97,220
Cumulative Timesteps: 810,896,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 810896224...
Checkpoint 810896224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,187.14811
Policy Entropy: 1.95566
Value Function Loss: 0.08048

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.59199
Value Function Update Magnitude: 0.54801

Collected Steps per Second: 15,226.13412
Overall Steps per Second: 7,112.14036

Timestep Collection Time: 3.28448
Timestep Consumption Time: 3.74715
PPO Batch Consumption Time: 0.50042
Total Iteration Time: 7.03164

Cumulative Model Updates: 97,226
Cumulative Timesteps: 810,946,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,069.51550
Policy Entropy: 1.96111
Value Function Loss: 0.07689

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.59160
Value Function Update Magnitude: 0.57315

Collected Steps per Second: 15,550.69119
Overall Steps per Second: 6,926.78614

Timestep Collection Time: 3.21568
Timestep Consumption Time: 4.00354
PPO Batch Consumption Time: 0.53543
Total Iteration Time: 7.21922

Cumulative Model Updates: 97,232
Cumulative Timesteps: 810,996,240

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 810996240...
Checkpoint 810996240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,604.85562
Policy Entropy: 1.96212
Value Function Loss: 0.07693

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13558
Policy Update Magnitude: 0.58700
Value Function Update Magnitude: 0.55813

Collected Steps per Second: 15,360.41040
Overall Steps per Second: 7,066.23931

Timestep Collection Time: 3.25616
Timestep Consumption Time: 3.82200
PPO Batch Consumption Time: 0.50657
Total Iteration Time: 7.07816

Cumulative Model Updates: 97,238
Cumulative Timesteps: 811,046,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,736.71503
Policy Entropy: 1.97602
Value Function Loss: 0.07614

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.58655
Value Function Update Magnitude: 0.57581

Collected Steps per Second: 15,339.79269
Overall Steps per Second: 7,106.61192

Timestep Collection Time: 3.26054
Timestep Consumption Time: 3.77741
PPO Batch Consumption Time: 0.50524
Total Iteration Time: 7.03795

Cumulative Model Updates: 97,244
Cumulative Timesteps: 811,096,272

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 811096272...
Checkpoint 811096272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,783.26511
Policy Entropy: 1.96082
Value Function Loss: 0.07845

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.58622
Value Function Update Magnitude: 0.56436

Collected Steps per Second: 15,338.63011
Overall Steps per Second: 7,105.06993

Timestep Collection Time: 3.26118
Timestep Consumption Time: 3.77915
PPO Batch Consumption Time: 0.50640
Total Iteration Time: 7.04032

Cumulative Model Updates: 97,250
Cumulative Timesteps: 811,146,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,080.25049
Policy Entropy: 1.97697
Value Function Loss: 0.08459

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.58888
Value Function Update Magnitude: 0.55508

Collected Steps per Second: 15,767.06156
Overall Steps per Second: 7,122.99488

Timestep Collection Time: 3.17244
Timestep Consumption Time: 3.84989
PPO Batch Consumption Time: 0.50801
Total Iteration Time: 7.02233

Cumulative Model Updates: 97,256
Cumulative Timesteps: 811,196,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 811196314...
Checkpoint 811196314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,163.12486
Policy Entropy: 1.96081
Value Function Loss: 0.08355

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13957
Policy Update Magnitude: 0.58945
Value Function Update Magnitude: 0.63178

Collected Steps per Second: 15,460.60080
Overall Steps per Second: 7,068.39448

Timestep Collection Time: 3.23493
Timestep Consumption Time: 3.84079
PPO Batch Consumption Time: 0.50889
Total Iteration Time: 7.07572

Cumulative Model Updates: 97,262
Cumulative Timesteps: 811,246,328

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,065.77923
Policy Entropy: 1.96392
Value Function Loss: 0.08155

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.14004
Policy Update Magnitude: 0.59226
Value Function Update Magnitude: 0.63530

Collected Steps per Second: 15,379.20056
Overall Steps per Second: 7,064.00928

Timestep Collection Time: 3.25375
Timestep Consumption Time: 3.83005
PPO Batch Consumption Time: 0.50485
Total Iteration Time: 7.08380

Cumulative Model Updates: 97,268
Cumulative Timesteps: 811,296,368

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 811296368...
Checkpoint 811296368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,792.09299
Policy Entropy: 1.94417
Value Function Loss: 0.08096

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.56722
Value Function Update Magnitude: 0.54850

Collected Steps per Second: 15,272.07518
Overall Steps per Second: 6,945.79311

Timestep Collection Time: 3.27460
Timestep Consumption Time: 3.92544
PPO Batch Consumption Time: 0.52835
Total Iteration Time: 7.20004

Cumulative Model Updates: 97,274
Cumulative Timesteps: 811,346,378

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,355.82390
Policy Entropy: 1.92719
Value Function Loss: 0.08037

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.58292
Value Function Update Magnitude: 0.50125

Collected Steps per Second: 15,584.03043
Overall Steps per Second: 7,087.69667

Timestep Collection Time: 3.21008
Timestep Consumption Time: 3.84807
PPO Batch Consumption Time: 0.50943
Total Iteration Time: 7.05815

Cumulative Model Updates: 97,280
Cumulative Timesteps: 811,396,404

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 811396404...
Checkpoint 811396404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,652.63824
Policy Entropy: 1.92708
Value Function Loss: 0.07855

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.58925
Value Function Update Magnitude: 0.41658

Collected Steps per Second: 15,585.78512
Overall Steps per Second: 7,080.78065

Timestep Collection Time: 3.21087
Timestep Consumption Time: 3.85671
PPO Batch Consumption Time: 0.51420
Total Iteration Time: 7.06758

Cumulative Model Updates: 97,286
Cumulative Timesteps: 811,446,448

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,955.71080
Policy Entropy: 1.93424
Value Function Loss: 0.07253

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.58478
Value Function Update Magnitude: 0.44493

Collected Steps per Second: 15,534.85484
Overall Steps per Second: 7,056.27631

Timestep Collection Time: 3.21960
Timestep Consumption Time: 3.86856
PPO Batch Consumption Time: 0.51327
Total Iteration Time: 7.08816

Cumulative Model Updates: 97,292
Cumulative Timesteps: 811,496,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 811496464...
Checkpoint 811496464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,100.25518
Policy Entropy: 1.93905
Value Function Loss: 0.07336

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12990
Policy Update Magnitude: 0.55884
Value Function Update Magnitude: 0.54355

Collected Steps per Second: 15,246.54502
Overall Steps per Second: 6,826.32084

Timestep Collection Time: 3.27943
Timestep Consumption Time: 4.04516
PPO Batch Consumption Time: 0.54392
Total Iteration Time: 7.32459

Cumulative Model Updates: 97,298
Cumulative Timesteps: 811,546,464

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,523.10125
Policy Entropy: 1.94506
Value Function Loss: 0.07488

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13406
Policy Update Magnitude: 0.56757
Value Function Update Magnitude: 0.62422

Collected Steps per Second: 15,707.53431
Overall Steps per Second: 7,000.75946

Timestep Collection Time: 3.18370
Timestep Consumption Time: 3.95953
PPO Batch Consumption Time: 0.52461
Total Iteration Time: 7.14322

Cumulative Model Updates: 97,304
Cumulative Timesteps: 811,596,472

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 811596472...
Checkpoint 811596472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,518.75356
Policy Entropy: 1.95857
Value Function Loss: 0.07222

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.57235
Value Function Update Magnitude: 0.62694

Collected Steps per Second: 15,476.79630
Overall Steps per Second: 7,040.47539

Timestep Collection Time: 3.23232
Timestep Consumption Time: 3.87316
PPO Batch Consumption Time: 0.51252
Total Iteration Time: 7.10549

Cumulative Model Updates: 97,310
Cumulative Timesteps: 811,646,498

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,863.31366
Policy Entropy: 1.95900
Value Function Loss: 0.07200

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.57076
Value Function Update Magnitude: 0.61390

Collected Steps per Second: 15,047.02292
Overall Steps per Second: 6,932.31589

Timestep Collection Time: 3.32332
Timestep Consumption Time: 3.89015
PPO Batch Consumption Time: 0.51931
Total Iteration Time: 7.21346

Cumulative Model Updates: 97,316
Cumulative Timesteps: 811,696,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 811696504...
Checkpoint 811696504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,493.50365
Policy Entropy: 1.95349
Value Function Loss: 0.06868

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13263
Policy Update Magnitude: 0.56833
Value Function Update Magnitude: 0.61622

Collected Steps per Second: 15,306.51005
Overall Steps per Second: 6,851.33589

Timestep Collection Time: 3.26711
Timestep Consumption Time: 4.03191
PPO Batch Consumption Time: 0.53900
Total Iteration Time: 7.29901

Cumulative Model Updates: 97,322
Cumulative Timesteps: 811,746,512

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,020.54997
Policy Entropy: 1.94310
Value Function Loss: 0.06896

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13106
Policy Update Magnitude: 0.56652
Value Function Update Magnitude: 0.62739

Collected Steps per Second: 15,305.70253
Overall Steps per Second: 6,868.61459

Timestep Collection Time: 3.26715
Timestep Consumption Time: 4.01321
PPO Batch Consumption Time: 0.53569
Total Iteration Time: 7.28036

Cumulative Model Updates: 97,328
Cumulative Timesteps: 811,796,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 811796518...
Checkpoint 811796518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,379.90092
Policy Entropy: 1.94573
Value Function Loss: 0.07383

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.57344
Value Function Update Magnitude: 0.61887

Collected Steps per Second: 15,443.95871
Overall Steps per Second: 6,968.44117

Timestep Collection Time: 3.23945
Timestep Consumption Time: 3.94006
PPO Batch Consumption Time: 0.52334
Total Iteration Time: 7.17951

Cumulative Model Updates: 97,334
Cumulative Timesteps: 811,846,548

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,427.62887
Policy Entropy: 1.94450
Value Function Loss: 0.07858

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14152
Policy Update Magnitude: 0.56540
Value Function Update Magnitude: 0.57902

Collected Steps per Second: 15,423.32604
Overall Steps per Second: 7,083.24964

Timestep Collection Time: 3.24431
Timestep Consumption Time: 3.81996
PPO Batch Consumption Time: 0.51252
Total Iteration Time: 7.06427

Cumulative Model Updates: 97,340
Cumulative Timesteps: 811,896,586

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 811896586...
Checkpoint 811896586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,353.68027
Policy Entropy: 1.94448
Value Function Loss: 0.07912

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.54195
Value Function Update Magnitude: 0.58732

Collected Steps per Second: 15,440.32716
Overall Steps per Second: 7,074.57568

Timestep Collection Time: 3.23931
Timestep Consumption Time: 3.83051
PPO Batch Consumption Time: 0.50814
Total Iteration Time: 7.06982

Cumulative Model Updates: 97,346
Cumulative Timesteps: 811,946,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,458.56522
Policy Entropy: 1.94987
Value Function Loss: 0.07180

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.53398
Value Function Update Magnitude: 0.59861

Collected Steps per Second: 15,012.07088
Overall Steps per Second: 6,948.58115

Timestep Collection Time: 3.33385
Timestep Consumption Time: 3.86877
PPO Batch Consumption Time: 0.51534
Total Iteration Time: 7.20262

Cumulative Model Updates: 97,352
Cumulative Timesteps: 811,996,650

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 811996650...
Checkpoint 811996650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,873.81257
Policy Entropy: 1.94827
Value Function Loss: 0.06995

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.15386
Policy Update Magnitude: 0.51244
Value Function Update Magnitude: 0.55034

Collected Steps per Second: 15,269.48004
Overall Steps per Second: 6,869.61352

Timestep Collection Time: 3.27542
Timestep Consumption Time: 4.00505
PPO Batch Consumption Time: 0.53686
Total Iteration Time: 7.28047

Cumulative Model Updates: 97,358
Cumulative Timesteps: 812,046,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,129.12479
Policy Entropy: 1.94534
Value Function Loss: 0.07151

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.14576
Policy Update Magnitude: 0.52175
Value Function Update Magnitude: 0.56690

Collected Steps per Second: 15,600.03243
Overall Steps per Second: 7,127.59116

Timestep Collection Time: 3.20666
Timestep Consumption Time: 3.81170
PPO Batch Consumption Time: 0.50427
Total Iteration Time: 7.01836

Cumulative Model Updates: 97,364
Cumulative Timesteps: 812,096,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 812096688...
Checkpoint 812096688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,168.04148
Policy Entropy: 1.94725
Value Function Loss: 0.07445

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.55379
Value Function Update Magnitude: 0.53981

Collected Steps per Second: 15,475.58725
Overall Steps per Second: 6,873.90969

Timestep Collection Time: 3.23102
Timestep Consumption Time: 4.04315
PPO Batch Consumption Time: 0.53851
Total Iteration Time: 7.27417

Cumulative Model Updates: 97,370
Cumulative Timesteps: 812,146,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,798.43390
Policy Entropy: 1.94609
Value Function Loss: 0.07203

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.56709
Value Function Update Magnitude: 0.54557

Collected Steps per Second: 15,161.79405
Overall Steps per Second: 6,852.11380

Timestep Collection Time: 3.29935
Timestep Consumption Time: 4.00118
PPO Batch Consumption Time: 0.53612
Total Iteration Time: 7.30052

Cumulative Model Updates: 97,376
Cumulative Timesteps: 812,196,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 812196714...
Checkpoint 812196714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,000.65588
Policy Entropy: 1.94341
Value Function Loss: 0.07045

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.13034
Policy Update Magnitude: 0.56420
Value Function Update Magnitude: 0.52670

Collected Steps per Second: 15,313.63327
Overall Steps per Second: 7,037.59571

Timestep Collection Time: 3.26624
Timestep Consumption Time: 3.84102
PPO Batch Consumption Time: 0.51090
Total Iteration Time: 7.10726

Cumulative Model Updates: 97,382
Cumulative Timesteps: 812,246,732

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,813.24906
Policy Entropy: 1.94575
Value Function Loss: 0.06412

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.57307

Collected Steps per Second: 15,647.21603
Overall Steps per Second: 7,032.82705

Timestep Collection Time: 3.19814
Timestep Consumption Time: 3.91735
PPO Batch Consumption Time: 0.52033
Total Iteration Time: 7.11549

Cumulative Model Updates: 97,388
Cumulative Timesteps: 812,296,774

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 812296774...
Checkpoint 812296774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,332.53396
Policy Entropy: 1.94556
Value Function Loss: 0.06195

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.15807
Policy Update Magnitude: 0.47652
Value Function Update Magnitude: 0.53344

Collected Steps per Second: 15,347.60958
Overall Steps per Second: 6,974.04842

Timestep Collection Time: 3.25953
Timestep Consumption Time: 3.91363
PPO Batch Consumption Time: 0.52392
Total Iteration Time: 7.17317

Cumulative Model Updates: 97,394
Cumulative Timesteps: 812,346,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,547.04199
Policy Entropy: 1.94694
Value Function Loss: 0.06972

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.14680
Policy Update Magnitude: 0.48059
Value Function Update Magnitude: 0.49882

Collected Steps per Second: 15,773.47804
Overall Steps per Second: 7,082.47721

Timestep Collection Time: 3.17077
Timestep Consumption Time: 3.89089
PPO Batch Consumption Time: 0.51768
Total Iteration Time: 7.06165

Cumulative Model Updates: 97,400
Cumulative Timesteps: 812,396,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 812396814...
Checkpoint 812396814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,729.67585
Policy Entropy: 1.94865
Value Function Loss: 0.07602

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.15627
Policy Update Magnitude: 0.51410
Value Function Update Magnitude: 0.47830

Collected Steps per Second: 15,380.26320
Overall Steps per Second: 7,048.85761

Timestep Collection Time: 3.25248
Timestep Consumption Time: 3.84427
PPO Batch Consumption Time: 0.50943
Total Iteration Time: 7.09675

Cumulative Model Updates: 97,406
Cumulative Timesteps: 812,446,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,196.11632
Policy Entropy: 1.94595
Value Function Loss: 0.07963

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.15876
Policy Update Magnitude: 0.52792
Value Function Update Magnitude: 0.41654

Collected Steps per Second: 15,635.23187
Overall Steps per Second: 7,076.84115

Timestep Collection Time: 3.19803
Timestep Consumption Time: 3.86755
PPO Batch Consumption Time: 0.51330
Total Iteration Time: 7.06558

Cumulative Model Updates: 97,412
Cumulative Timesteps: 812,496,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 812496840...
Checkpoint 812496840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,255.61810
Policy Entropy: 1.93828
Value Function Loss: 0.07817

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.16107
Policy Update Magnitude: 0.56420
Value Function Update Magnitude: 0.47364

Collected Steps per Second: 15,540.78153
Overall Steps per Second: 7,114.09533

Timestep Collection Time: 3.21760
Timestep Consumption Time: 3.81126
PPO Batch Consumption Time: 0.50558
Total Iteration Time: 7.02886

Cumulative Model Updates: 97,418
Cumulative Timesteps: 812,546,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,333.75272
Policy Entropy: 1.93410
Value Function Loss: 0.07608

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.16163
Policy Update Magnitude: 0.57519
Value Function Update Magnitude: 0.50584

Collected Steps per Second: 15,684.10107
Overall Steps per Second: 7,118.79636

Timestep Collection Time: 3.18858
Timestep Consumption Time: 3.83648
PPO Batch Consumption Time: 0.50772
Total Iteration Time: 7.02506

Cumulative Model Updates: 97,424
Cumulative Timesteps: 812,596,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 812596854...
Checkpoint 812596854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,219.15217
Policy Entropy: 1.93701
Value Function Loss: 0.07734

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.16644
Policy Update Magnitude: 0.54777
Value Function Update Magnitude: 0.53113

Collected Steps per Second: 15,160.71844
Overall Steps per Second: 6,891.61003

Timestep Collection Time: 3.29839
Timestep Consumption Time: 3.95768
PPO Batch Consumption Time: 0.54000
Total Iteration Time: 7.25607

Cumulative Model Updates: 97,430
Cumulative Timesteps: 812,646,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,483.01613
Policy Entropy: 1.95239
Value Function Loss: 0.07321

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.15386
Policy Update Magnitude: 0.54457
Value Function Update Magnitude: 0.54751

Collected Steps per Second: 15,252.50561
Overall Steps per Second: 6,992.78211

Timestep Collection Time: 3.27907
Timestep Consumption Time: 3.87316
PPO Batch Consumption Time: 0.52599
Total Iteration Time: 7.15223

Cumulative Model Updates: 97,436
Cumulative Timesteps: 812,696,874

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 812696874...
Checkpoint 812696874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,146.11069
Policy Entropy: 1.95804
Value Function Loss: 0.07155

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.55169
Value Function Update Magnitude: 0.54826

Collected Steps per Second: 15,050.26532
Overall Steps per Second: 7,079.09123

Timestep Collection Time: 3.32406
Timestep Consumption Time: 3.74295
PPO Batch Consumption Time: 0.50706
Total Iteration Time: 7.06701

Cumulative Model Updates: 97,442
Cumulative Timesteps: 812,746,902

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,712.81190
Policy Entropy: 1.95167
Value Function Loss: 0.06612

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13930
Policy Update Magnitude: 0.53424
Value Function Update Magnitude: 0.54183

Collected Steps per Second: 15,415.22442
Overall Steps per Second: 7,038.93485

Timestep Collection Time: 3.24484
Timestep Consumption Time: 3.86134
PPO Batch Consumption Time: 0.52452
Total Iteration Time: 7.10619

Cumulative Model Updates: 97,448
Cumulative Timesteps: 812,796,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 812796922...
Checkpoint 812796922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,754.12215
Policy Entropy: 1.94790
Value Function Loss: 0.06527

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.52514
Value Function Update Magnitude: 0.57342

Collected Steps per Second: 14,827.54809
Overall Steps per Second: 6,854.05402

Timestep Collection Time: 3.37372
Timestep Consumption Time: 3.92473
PPO Batch Consumption Time: 0.52534
Total Iteration Time: 7.29845

Cumulative Model Updates: 97,454
Cumulative Timesteps: 812,846,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,690.90307
Policy Entropy: 1.94239
Value Function Loss: 0.06896

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.53996
Value Function Update Magnitude: 0.53582

Collected Steps per Second: 15,382.75941
Overall Steps per Second: 6,895.37100

Timestep Collection Time: 3.25104
Timestep Consumption Time: 4.00165
PPO Batch Consumption Time: 0.53351
Total Iteration Time: 7.25269

Cumulative Model Updates: 97,460
Cumulative Timesteps: 812,896,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 812896956...
Checkpoint 812896956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,514.16091
Policy Entropy: 1.94586
Value Function Loss: 0.07380

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.57091
Value Function Update Magnitude: 0.59972

Collected Steps per Second: 15,276.44502
Overall Steps per Second: 6,930.74831

Timestep Collection Time: 3.27432
Timestep Consumption Time: 3.94279
PPO Batch Consumption Time: 0.53175
Total Iteration Time: 7.21711

Cumulative Model Updates: 97,466
Cumulative Timesteps: 812,946,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,610.03630
Policy Entropy: 1.94380
Value Function Loss: 0.07621

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.57201
Value Function Update Magnitude: 0.66918

Collected Steps per Second: 15,363.67937
Overall Steps per Second: 7,144.59065

Timestep Collection Time: 3.25534
Timestep Consumption Time: 3.74492
PPO Batch Consumption Time: 0.49723
Total Iteration Time: 7.00026

Cumulative Model Updates: 97,472
Cumulative Timesteps: 812,996,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 812996990...
Checkpoint 812996990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,216.09899
Policy Entropy: 1.94382
Value Function Loss: 0.07730

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.16410
Policy Update Magnitude: 0.50505
Value Function Update Magnitude: 0.62927

Collected Steps per Second: 15,016.81905
Overall Steps per Second: 6,816.44540

Timestep Collection Time: 3.33253
Timestep Consumption Time: 4.00913
PPO Batch Consumption Time: 0.54077
Total Iteration Time: 7.34166

Cumulative Model Updates: 97,478
Cumulative Timesteps: 813,047,034

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,949.63376
Policy Entropy: 1.93974
Value Function Loss: 0.07943

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.15944
Policy Update Magnitude: 0.48132
Value Function Update Magnitude: 0.63100

Collected Steps per Second: 15,504.38689
Overall Steps per Second: 6,932.24124

Timestep Collection Time: 3.22567
Timestep Consumption Time: 3.98874
PPO Batch Consumption Time: 0.53867
Total Iteration Time: 7.21441

Cumulative Model Updates: 97,484
Cumulative Timesteps: 813,097,046

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 813097046...
Checkpoint 813097046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,678.57682
Policy Entropy: 1.95224
Value Function Loss: 0.07273

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.15889
Policy Update Magnitude: 0.47515
Value Function Update Magnitude: 0.68395

Collected Steps per Second: 15,509.80628
Overall Steps per Second: 7,010.10187

Timestep Collection Time: 3.22531
Timestep Consumption Time: 3.91067
PPO Batch Consumption Time: 0.52029
Total Iteration Time: 7.13599

Cumulative Model Updates: 97,490
Cumulative Timesteps: 813,147,070

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,661.80341
Policy Entropy: 1.94091
Value Function Loss: 0.07168

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.15155
Policy Update Magnitude: 0.48963
Value Function Update Magnitude: 0.68371

Collected Steps per Second: 15,543.31902
Overall Steps per Second: 6,982.56262

Timestep Collection Time: 3.21810
Timestep Consumption Time: 3.94546
PPO Batch Consumption Time: 0.52568
Total Iteration Time: 7.16356

Cumulative Model Updates: 97,496
Cumulative Timesteps: 813,197,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 813197090...
Checkpoint 813197090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,866.94513
Policy Entropy: 1.93939
Value Function Loss: 0.07299

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.15232
Policy Update Magnitude: 0.49360
Value Function Update Magnitude: 0.66149

Collected Steps per Second: 14,880.34292
Overall Steps per Second: 6,824.95739

Timestep Collection Time: 3.36215
Timestep Consumption Time: 3.96830
PPO Batch Consumption Time: 0.52768
Total Iteration Time: 7.33045

Cumulative Model Updates: 97,502
Cumulative Timesteps: 813,247,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,417.22167
Policy Entropy: 1.93158
Value Function Loss: 0.07504

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.55744
Value Function Update Magnitude: 0.57285

Collected Steps per Second: 15,433.37622
Overall Steps per Second: 6,901.73507

Timestep Collection Time: 3.24116
Timestep Consumption Time: 4.00659
PPO Batch Consumption Time: 0.53526
Total Iteration Time: 7.24774

Cumulative Model Updates: 97,508
Cumulative Timesteps: 813,297,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 813297142...
Checkpoint 813297142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,163.70188
Policy Entropy: 1.95066
Value Function Loss: 0.07926

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.14086
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.52392

Collected Steps per Second: 15,508.92734
Overall Steps per Second: 7,060.97448

Timestep Collection Time: 3.22485
Timestep Consumption Time: 3.85831
PPO Batch Consumption Time: 0.51954
Total Iteration Time: 7.08316

Cumulative Model Updates: 97,514
Cumulative Timesteps: 813,347,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,633.04647
Policy Entropy: 1.95809
Value Function Loss: 0.07538

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.57825
Value Function Update Magnitude: 0.60126

Collected Steps per Second: 15,679.40232
Overall Steps per Second: 7,128.68476

Timestep Collection Time: 3.19081
Timestep Consumption Time: 3.82731
PPO Batch Consumption Time: 0.50372
Total Iteration Time: 7.01812

Cumulative Model Updates: 97,520
Cumulative Timesteps: 813,397,186

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 813397186...
Checkpoint 813397186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,612.30882
Policy Entropy: 1.96101
Value Function Loss: 0.07194

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.56665
Value Function Update Magnitude: 0.64830

Collected Steps per Second: 15,127.64213
Overall Steps per Second: 6,843.18617

Timestep Collection Time: 3.30600
Timestep Consumption Time: 4.00229
PPO Batch Consumption Time: 0.53281
Total Iteration Time: 7.30829

Cumulative Model Updates: 97,526
Cumulative Timesteps: 813,447,198

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,773.75621
Policy Entropy: 1.94231
Value Function Loss: 0.07257

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.56202
Value Function Update Magnitude: 0.64881

Collected Steps per Second: 15,599.48523
Overall Steps per Second: 7,086.26663

Timestep Collection Time: 3.20562
Timestep Consumption Time: 3.85113
PPO Batch Consumption Time: 0.50942
Total Iteration Time: 7.05675

Cumulative Model Updates: 97,532
Cumulative Timesteps: 813,497,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 813497204...
Checkpoint 813497204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,527.59733
Policy Entropy: 1.94216
Value Function Loss: 0.06856

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.56039
Value Function Update Magnitude: 0.64466

Collected Steps per Second: 14,913.21235
Overall Steps per Second: 6,789.10325

Timestep Collection Time: 3.35541
Timestep Consumption Time: 4.01522
PPO Batch Consumption Time: 0.53710
Total Iteration Time: 7.37063

Cumulative Model Updates: 97,538
Cumulative Timesteps: 813,547,244

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,896.02132
Policy Entropy: 1.94813
Value Function Loss: 0.07137

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.16035
Policy Update Magnitude: 0.51977
Value Function Update Magnitude: 0.64747

Collected Steps per Second: 15,753.67779
Overall Steps per Second: 7,152.80251

Timestep Collection Time: 3.17399
Timestep Consumption Time: 3.81656
PPO Batch Consumption Time: 0.50415
Total Iteration Time: 6.99055

Cumulative Model Updates: 97,544
Cumulative Timesteps: 813,597,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 813597246...
Checkpoint 813597246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,134.80641
Policy Entropy: 1.98287
Value Function Loss: 0.06615

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.15065
Policy Update Magnitude: 0.48009
Value Function Update Magnitude: 0.65296

Collected Steps per Second: 15,276.43709
Overall Steps per Second: 6,993.89188

Timestep Collection Time: 3.27432
Timestep Consumption Time: 3.87763
PPO Batch Consumption Time: 0.51859
Total Iteration Time: 7.15196

Cumulative Model Updates: 97,550
Cumulative Timesteps: 813,647,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,310.41061
Policy Entropy: 1.96789
Value Function Loss: 0.07295

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.52768
Value Function Update Magnitude: 0.65389

Collected Steps per Second: 15,746.58485
Overall Steps per Second: 7,018.68227

Timestep Collection Time: 3.17542
Timestep Consumption Time: 3.94871
PPO Batch Consumption Time: 0.52544
Total Iteration Time: 7.12413

Cumulative Model Updates: 97,556
Cumulative Timesteps: 813,697,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 813697268...
Checkpoint 813697268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,350.85940
Policy Entropy: 1.97163
Value Function Loss: 0.07380

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.16646
Policy Update Magnitude: 0.51333
Value Function Update Magnitude: 0.64718

Collected Steps per Second: 15,300.50071
Overall Steps per Second: 7,096.17964

Timestep Collection Time: 3.26865
Timestep Consumption Time: 3.77908
PPO Batch Consumption Time: 0.50064
Total Iteration Time: 7.04774

Cumulative Model Updates: 97,562
Cumulative Timesteps: 813,747,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,956.25757
Policy Entropy: 1.95969
Value Function Loss: 0.07783

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.16255
Policy Update Magnitude: 0.51920
Value Function Update Magnitude: 0.64210

Collected Steps per Second: 15,504.43683
Overall Steps per Second: 6,906.93329

Timestep Collection Time: 3.22592
Timestep Consumption Time: 4.01550
PPO Batch Consumption Time: 0.53907
Total Iteration Time: 7.24142

Cumulative Model Updates: 97,568
Cumulative Timesteps: 813,797,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 813797296...
Checkpoint 813797296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,505.13390
Policy Entropy: 1.97916
Value Function Loss: 0.07506

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.15698
Policy Update Magnitude: 0.55223
Value Function Update Magnitude: 0.57218

Collected Steps per Second: 15,266.49247
Overall Steps per Second: 6,821.84282

Timestep Collection Time: 3.27646
Timestep Consumption Time: 4.05587
PPO Batch Consumption Time: 0.54121
Total Iteration Time: 7.33233

Cumulative Model Updates: 97,574
Cumulative Timesteps: 813,847,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,409.95892
Policy Entropy: 1.97440
Value Function Loss: 0.08030

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.15209
Policy Update Magnitude: 0.57334
Value Function Update Magnitude: 0.58417

Collected Steps per Second: 15,541.81182
Overall Steps per Second: 6,894.65228

Timestep Collection Time: 3.21739
Timestep Consumption Time: 4.03519
PPO Batch Consumption Time: 0.53705
Total Iteration Time: 7.25258

Cumulative Model Updates: 97,580
Cumulative Timesteps: 813,897,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 813897320...
Checkpoint 813897320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,014.74386
Policy Entropy: 1.97661
Value Function Loss: 0.07763

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.15526
Policy Update Magnitude: 0.57367
Value Function Update Magnitude: 0.66360

Collected Steps per Second: 15,323.25882
Overall Steps per Second: 6,875.81949

Timestep Collection Time: 3.26445
Timestep Consumption Time: 4.01061
PPO Batch Consumption Time: 0.53514
Total Iteration Time: 7.27506

Cumulative Model Updates: 97,586
Cumulative Timesteps: 813,947,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,173.77894
Policy Entropy: 1.97304
Value Function Loss: 0.07439

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.15434
Policy Update Magnitude: 0.54011
Value Function Update Magnitude: 0.70001

Collected Steps per Second: 15,353.66679
Overall Steps per Second: 7,099.98818

Timestep Collection Time: 3.25850
Timestep Consumption Time: 3.78799
PPO Batch Consumption Time: 0.50165
Total Iteration Time: 7.04649

Cumulative Model Updates: 97,592
Cumulative Timesteps: 813,997,372

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 813997372...
Checkpoint 813997372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,589.45638
Policy Entropy: 1.98804
Value Function Loss: 0.07280

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.14586
Policy Update Magnitude: 0.55530
Value Function Update Magnitude: 0.71278

Collected Steps per Second: 15,507.44908
Overall Steps per Second: 7,028.70494

Timestep Collection Time: 3.22477
Timestep Consumption Time: 3.89005
PPO Batch Consumption Time: 0.51872
Total Iteration Time: 7.11482

Cumulative Model Updates: 97,598
Cumulative Timesteps: 814,047,380

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,689.58649
Policy Entropy: 1.98651
Value Function Loss: 0.07805

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.58322
Value Function Update Magnitude: 0.69722

Collected Steps per Second: 15,561.56012
Overall Steps per Second: 7,033.38487

Timestep Collection Time: 3.21626
Timestep Consumption Time: 3.89980
PPO Batch Consumption Time: 0.52247
Total Iteration Time: 7.11606

Cumulative Model Updates: 97,604
Cumulative Timesteps: 814,097,430

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 814097430...
Checkpoint 814097430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,047.89220
Policy Entropy: 1.99259
Value Function Loss: 0.07634

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.14827
Policy Update Magnitude: 0.57211
Value Function Update Magnitude: 0.72397

Collected Steps per Second: 15,517.14592
Overall Steps per Second: 6,950.87243

Timestep Collection Time: 3.22405
Timestep Consumption Time: 3.97332
PPO Batch Consumption Time: 0.52949
Total Iteration Time: 7.19737

Cumulative Model Updates: 97,610
Cumulative Timesteps: 814,147,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,743.28845
Policy Entropy: 2.00391
Value Function Loss: 0.07410

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.14552
Policy Update Magnitude: 0.53873
Value Function Update Magnitude: 0.69200

Collected Steps per Second: 15,657.56758
Overall Steps per Second: 7,026.04711

Timestep Collection Time: 3.19360
Timestep Consumption Time: 3.92335
PPO Batch Consumption Time: 0.52191
Total Iteration Time: 7.11695

Cumulative Model Updates: 97,616
Cumulative Timesteps: 814,197,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 814197462...
Checkpoint 814197462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,883.08256
Policy Entropy: 1.98491
Value Function Loss: 0.06828

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.54895
Value Function Update Magnitude: 0.60479

Collected Steps per Second: 15,362.23717
Overall Steps per Second: 6,884.62340

Timestep Collection Time: 3.25578
Timestep Consumption Time: 4.00911
PPO Batch Consumption Time: 0.53395
Total Iteration Time: 7.26489

Cumulative Model Updates: 97,622
Cumulative Timesteps: 814,247,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,384.92740
Policy Entropy: 1.97593
Value Function Loss: 0.07232

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13957
Policy Update Magnitude: 0.55337
Value Function Update Magnitude: 0.59233

Collected Steps per Second: 15,532.87668
Overall Steps per Second: 6,999.38743

Timestep Collection Time: 3.22104
Timestep Consumption Time: 3.92702
PPO Batch Consumption Time: 0.52791
Total Iteration Time: 7.14805

Cumulative Model Updates: 97,628
Cumulative Timesteps: 814,297,510

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 814297510...
Checkpoint 814297510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,751.82012
Policy Entropy: 1.96486
Value Function Loss: 0.06932

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.52605
Value Function Update Magnitude: 0.56775

Collected Steps per Second: 15,635.19308
Overall Steps per Second: 6,997.84051

Timestep Collection Time: 3.19855
Timestep Consumption Time: 3.94794
PPO Batch Consumption Time: 0.52434
Total Iteration Time: 7.14649

Cumulative Model Updates: 97,634
Cumulative Timesteps: 814,347,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,693.10918
Policy Entropy: 1.98134
Value Function Loss: 0.07469

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.55611
Value Function Update Magnitude: 0.50827

Collected Steps per Second: 15,721.03219
Overall Steps per Second: 7,162.24092

Timestep Collection Time: 3.18223
Timestep Consumption Time: 3.80273
PPO Batch Consumption Time: 0.50052
Total Iteration Time: 6.98496

Cumulative Model Updates: 97,640
Cumulative Timesteps: 814,397,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 814397548...
Checkpoint 814397548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,512.61451
Policy Entropy: 1.99377
Value Function Loss: 0.07395

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.57403
Value Function Update Magnitude: 0.62428

Collected Steps per Second: 15,258.03270
Overall Steps per Second: 7,053.05574

Timestep Collection Time: 3.27840
Timestep Consumption Time: 3.81384
PPO Batch Consumption Time: 0.50436
Total Iteration Time: 7.09225

Cumulative Model Updates: 97,646
Cumulative Timesteps: 814,447,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,292.12470
Policy Entropy: 2.00256
Value Function Loss: 0.07589

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.57655
Value Function Update Magnitude: 0.63342

Collected Steps per Second: 15,417.37990
Overall Steps per Second: 7,007.90557

Timestep Collection Time: 3.24361
Timestep Consumption Time: 3.89233
PPO Batch Consumption Time: 0.51241
Total Iteration Time: 7.13594

Cumulative Model Updates: 97,652
Cumulative Timesteps: 814,497,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 814497578...
Checkpoint 814497578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,436.97396
Policy Entropy: 1.99738
Value Function Loss: 0.07625

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.56237
Value Function Update Magnitude: 0.56924

Collected Steps per Second: 15,218.53576
Overall Steps per Second: 6,847.07050

Timestep Collection Time: 3.28691
Timestep Consumption Time: 4.01869
PPO Batch Consumption Time: 0.53903
Total Iteration Time: 7.30561

Cumulative Model Updates: 97,658
Cumulative Timesteps: 814,547,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,008.67630
Policy Entropy: 1.98920
Value Function Loss: 0.07804

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.56856
Value Function Update Magnitude: 0.60312

Collected Steps per Second: 15,537.05698
Overall Steps per Second: 6,937.50616

Timestep Collection Time: 3.21824
Timestep Consumption Time: 3.98925
PPO Batch Consumption Time: 0.52959
Total Iteration Time: 7.20749

Cumulative Model Updates: 97,664
Cumulative Timesteps: 814,597,602

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 814597602...
Checkpoint 814597602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,754.41489
Policy Entropy: 1.97314
Value Function Loss: 0.07742

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13600
Policy Update Magnitude: 0.58404
Value Function Update Magnitude: 0.68689

Collected Steps per Second: 15,485.14175
Overall Steps per Second: 7,007.58052

Timestep Collection Time: 3.23174
Timestep Consumption Time: 3.90967
PPO Batch Consumption Time: 0.52150
Total Iteration Time: 7.14141

Cumulative Model Updates: 97,670
Cumulative Timesteps: 814,647,646

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,693.08201
Policy Entropy: 1.95872
Value Function Loss: 0.07389

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.57990
Value Function Update Magnitude: 0.70576

Collected Steps per Second: 15,650.78691
Overall Steps per Second: 7,111.34467

Timestep Collection Time: 3.19639
Timestep Consumption Time: 3.83829
PPO Batch Consumption Time: 0.50723
Total Iteration Time: 7.03468

Cumulative Model Updates: 97,676
Cumulative Timesteps: 814,697,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 814697672...
Checkpoint 814697672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,509.16760
Policy Entropy: 1.94808
Value Function Loss: 0.07536

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.14072
Policy Update Magnitude: 0.57675
Value Function Update Magnitude: 0.70454

Collected Steps per Second: 15,430.51361
Overall Steps per Second: 6,988.10643

Timestep Collection Time: 3.24189
Timestep Consumption Time: 3.91656
PPO Batch Consumption Time: 0.52071
Total Iteration Time: 7.15845

Cumulative Model Updates: 97,682
Cumulative Timesteps: 814,747,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,240.96745
Policy Entropy: 1.94485
Value Function Loss: 0.06865

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.56435
Value Function Update Magnitude: 0.65454

Collected Steps per Second: 15,674.27395
Overall Steps per Second: 6,997.53682

Timestep Collection Time: 3.19096
Timestep Consumption Time: 3.95670
PPO Batch Consumption Time: 0.52684
Total Iteration Time: 7.14766

Cumulative Model Updates: 97,688
Cumulative Timesteps: 814,797,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 814797712...
Checkpoint 814797712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,319.17879
Policy Entropy: 1.95601
Value Function Loss: 0.07165

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.56498
Value Function Update Magnitude: 0.54187

Collected Steps per Second: 15,277.52594
Overall Steps per Second: 7,059.55974

Timestep Collection Time: 3.27488
Timestep Consumption Time: 3.81225
PPO Batch Consumption Time: 0.50189
Total Iteration Time: 7.08713

Cumulative Model Updates: 97,694
Cumulative Timesteps: 814,847,744

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,153.64793
Policy Entropy: 1.95553
Value Function Loss: 0.06739

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.51476

Collected Steps per Second: 15,568.21688
Overall Steps per Second: 6,994.83497

Timestep Collection Time: 3.21283
Timestep Consumption Time: 3.93788
PPO Batch Consumption Time: 0.52434
Total Iteration Time: 7.15070

Cumulative Model Updates: 97,700
Cumulative Timesteps: 814,897,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 814897762...
Checkpoint 814897762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,714.67249
Policy Entropy: 1.95139
Value Function Loss: 0.07375

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14824
Policy Update Magnitude: 0.55955
Value Function Update Magnitude: 0.54466

Collected Steps per Second: 15,462.35610
Overall Steps per Second: 7,068.24582

Timestep Collection Time: 3.23521
Timestep Consumption Time: 3.84207
PPO Batch Consumption Time: 0.51206
Total Iteration Time: 7.07729

Cumulative Model Updates: 97,706
Cumulative Timesteps: 814,947,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,518.63425
Policy Entropy: 1.95870
Value Function Loss: 0.07513

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.14422
Policy Update Magnitude: 0.56859
Value Function Update Magnitude: 0.61071

Collected Steps per Second: 15,218.57125
Overall Steps per Second: 6,967.52526

Timestep Collection Time: 3.28664
Timestep Consumption Time: 3.89209
PPO Batch Consumption Time: 0.51602
Total Iteration Time: 7.17873

Cumulative Model Updates: 97,712
Cumulative Timesteps: 814,997,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 814997804...
Checkpoint 814997804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,338.32481
Policy Entropy: 1.96279
Value Function Loss: 0.07379

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.14567
Policy Update Magnitude: 0.55946
Value Function Update Magnitude: 0.65345

Collected Steps per Second: 15,255.51617
Overall Steps per Second: 7,028.55636

Timestep Collection Time: 3.27777
Timestep Consumption Time: 3.83664
PPO Batch Consumption Time: 0.50691
Total Iteration Time: 7.11441

Cumulative Model Updates: 97,718
Cumulative Timesteps: 815,047,808

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,993.95936
Policy Entropy: 1.96867
Value Function Loss: 0.07382

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.53834
Value Function Update Magnitude: 0.71161

Collected Steps per Second: 15,587.07834
Overall Steps per Second: 7,115.26639

Timestep Collection Time: 3.20945
Timestep Consumption Time: 3.82134
PPO Batch Consumption Time: 0.50338
Total Iteration Time: 7.03080

Cumulative Model Updates: 97,724
Cumulative Timesteps: 815,097,834

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 815097834...
Checkpoint 815097834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,274.58752
Policy Entropy: 1.95985
Value Function Loss: 0.06974

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.14326
Policy Update Magnitude: 0.50651
Value Function Update Magnitude: 0.71620

Collected Steps per Second: 15,343.92515
Overall Steps per Second: 7,034.28540

Timestep Collection Time: 3.26005
Timestep Consumption Time: 3.85112
PPO Batch Consumption Time: 0.51142
Total Iteration Time: 7.11117

Cumulative Model Updates: 97,730
Cumulative Timesteps: 815,147,856

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,163.85716
Policy Entropy: 1.96196
Value Function Loss: 0.06897

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.16848
Policy Update Magnitude: 0.49865
Value Function Update Magnitude: 0.61271

Collected Steps per Second: 15,657.63883
Overall Steps per Second: 6,897.95222

Timestep Collection Time: 3.19448
Timestep Consumption Time: 4.05666
PPO Batch Consumption Time: 0.54188
Total Iteration Time: 7.25114

Cumulative Model Updates: 97,736
Cumulative Timesteps: 815,197,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 815197874...
Checkpoint 815197874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,955.71007
Policy Entropy: 1.97252
Value Function Loss: 0.06555

Mean KL Divergence: 0.03455
SB3 Clip Fraction: 0.22002
Policy Update Magnitude: 0.42884
Value Function Update Magnitude: 0.58959

Collected Steps per Second: 15,517.38644
Overall Steps per Second: 6,893.28991

Timestep Collection Time: 3.22219
Timestep Consumption Time: 4.03124
PPO Batch Consumption Time: 0.53824
Total Iteration Time: 7.25343

Cumulative Model Updates: 97,742
Cumulative Timesteps: 815,247,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,118.60512
Policy Entropy: 1.97687
Value Function Loss: 0.06230

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.18149
Policy Update Magnitude: 0.40940
Value Function Update Magnitude: 0.55314

Collected Steps per Second: 15,668.12180
Overall Steps per Second: 6,945.08018

Timestep Collection Time: 3.19183
Timestep Consumption Time: 4.00895
PPO Batch Consumption Time: 0.53574
Total Iteration Time: 7.20078

Cumulative Model Updates: 97,748
Cumulative Timesteps: 815,297,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 815297884...
Checkpoint 815297884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,004.38228
Policy Entropy: 1.95044
Value Function Loss: 0.06533

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.15836
Policy Update Magnitude: 0.46654
Value Function Update Magnitude: 0.57677

Collected Steps per Second: 15,295.00847
Overall Steps per Second: 7,003.25837

Timestep Collection Time: 3.27061
Timestep Consumption Time: 3.87235
PPO Batch Consumption Time: 0.51380
Total Iteration Time: 7.14296

Cumulative Model Updates: 97,754
Cumulative Timesteps: 815,347,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,890.20409
Policy Entropy: 1.95416
Value Function Loss: 0.06186

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.15827
Policy Update Magnitude: 0.51778
Value Function Update Magnitude: 0.63546

Collected Steps per Second: 15,700.74444
Overall Steps per Second: 7,127.75397

Timestep Collection Time: 3.18584
Timestep Consumption Time: 3.83180
PPO Batch Consumption Time: 0.50675
Total Iteration Time: 7.01764

Cumulative Model Updates: 97,760
Cumulative Timesteps: 815,397,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 815397928...
Checkpoint 815397928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,698.42464
Policy Entropy: 1.96244
Value Function Loss: 0.06450

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.54914
Value Function Update Magnitude: 0.65921

Collected Steps per Second: 15,379.83091
Overall Steps per Second: 7,061.28436

Timestep Collection Time: 3.25283
Timestep Consumption Time: 3.83200
PPO Batch Consumption Time: 0.50721
Total Iteration Time: 7.08483

Cumulative Model Updates: 97,766
Cumulative Timesteps: 815,447,956

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,618.29165
Policy Entropy: 1.97149
Value Function Loss: 0.06452

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.55627
Value Function Update Magnitude: 0.59043

Collected Steps per Second: 15,503.69436
Overall Steps per Second: 7,112.68525

Timestep Collection Time: 3.22697
Timestep Consumption Time: 3.80694
PPO Batch Consumption Time: 0.50355
Total Iteration Time: 7.03391

Cumulative Model Updates: 97,772
Cumulative Timesteps: 815,497,986

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 815497986...
Checkpoint 815497986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,725.58223
Policy Entropy: 1.95681
Value Function Loss: 0.07636

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.14491
Policy Update Magnitude: 0.55670
Value Function Update Magnitude: 0.54934

Collected Steps per Second: 15,547.01321
Overall Steps per Second: 7,050.27373

Timestep Collection Time: 3.21785
Timestep Consumption Time: 3.87804
PPO Batch Consumption Time: 0.51623
Total Iteration Time: 7.09589

Cumulative Model Updates: 97,778
Cumulative Timesteps: 815,548,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,682.23696
Policy Entropy: 1.95967
Value Function Loss: 0.07789

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13543
Policy Update Magnitude: 0.56168
Value Function Update Magnitude: 0.54600

Collected Steps per Second: 15,658.91004
Overall Steps per Second: 6,905.70564

Timestep Collection Time: 3.19384
Timestep Consumption Time: 4.04829
PPO Batch Consumption Time: 0.54319
Total Iteration Time: 7.24213

Cumulative Model Updates: 97,784
Cumulative Timesteps: 815,598,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 815598026...
Checkpoint 815598026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,254.89022
Policy Entropy: 1.95143
Value Function Loss: 0.07596

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.56964
Value Function Update Magnitude: 0.54419

Collected Steps per Second: 14,338.43311
Overall Steps per Second: 6,646.04670

Timestep Collection Time: 3.48881
Timestep Consumption Time: 4.03808
PPO Batch Consumption Time: 0.52899
Total Iteration Time: 7.52688

Cumulative Model Updates: 97,790
Cumulative Timesteps: 815,648,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,855.47601
Policy Entropy: 1.93387
Value Function Loss: 0.07067

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.14777
Policy Update Magnitude: 0.56682
Value Function Update Magnitude: 0.62228

Collected Steps per Second: 15,555.46663
Overall Steps per Second: 6,949.66709

Timestep Collection Time: 3.21610
Timestep Consumption Time: 3.98251
PPO Batch Consumption Time: 0.53046
Total Iteration Time: 7.19862

Cumulative Model Updates: 97,796
Cumulative Timesteps: 815,698,078

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 815698078...
Checkpoint 815698078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,303.72358
Policy Entropy: 1.91618
Value Function Loss: 0.07125

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.56853
Value Function Update Magnitude: 0.57019

Collected Steps per Second: 15,538.48724
Overall Steps per Second: 7,035.79560

Timestep Collection Time: 3.22026
Timestep Consumption Time: 3.89166
PPO Batch Consumption Time: 0.51501
Total Iteration Time: 7.11192

Cumulative Model Updates: 97,802
Cumulative Timesteps: 815,748,116

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,143.21830
Policy Entropy: 1.90620
Value Function Loss: 0.07420

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.57053
Value Function Update Magnitude: 0.55948

Collected Steps per Second: 15,465.81169
Overall Steps per Second: 7,090.41772

Timestep Collection Time: 3.23565
Timestep Consumption Time: 3.82204
PPO Batch Consumption Time: 0.50428
Total Iteration Time: 7.05769

Cumulative Model Updates: 97,808
Cumulative Timesteps: 815,798,158

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 815798158...
Checkpoint 815798158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,074.97901
Policy Entropy: 1.92596
Value Function Loss: 0.07402

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.56593
Value Function Update Magnitude: 0.54231

Collected Steps per Second: 15,565.10921
Overall Steps per Second: 7,020.01806

Timestep Collection Time: 3.21283
Timestep Consumption Time: 3.91080
PPO Batch Consumption Time: 0.52038
Total Iteration Time: 7.12363

Cumulative Model Updates: 97,814
Cumulative Timesteps: 815,848,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,556.35113
Policy Entropy: 1.91480
Value Function Loss: 0.07656

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.56335
Value Function Update Magnitude: 0.64519

Collected Steps per Second: 15,709.45714
Overall Steps per Second: 7,156.58049

Timestep Collection Time: 3.18420
Timestep Consumption Time: 3.80545
PPO Batch Consumption Time: 0.50131
Total Iteration Time: 6.98965

Cumulative Model Updates: 97,820
Cumulative Timesteps: 815,898,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 815898188...
Checkpoint 815898188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,263.97632
Policy Entropy: 1.91610
Value Function Loss: 0.07608

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.57122
Value Function Update Magnitude: 0.73149

Collected Steps per Second: 15,515.68138
Overall Steps per Second: 7,017.58325

Timestep Collection Time: 3.22280
Timestep Consumption Time: 3.90273
PPO Batch Consumption Time: 0.51938
Total Iteration Time: 7.12553

Cumulative Model Updates: 97,826
Cumulative Timesteps: 815,948,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,123.12985
Policy Entropy: 1.91743
Value Function Loss: 0.07285

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.57281
Value Function Update Magnitude: 0.75733

Collected Steps per Second: 15,447.14767
Overall Steps per Second: 6,906.34172

Timestep Collection Time: 3.23749
Timestep Consumption Time: 4.00368
PPO Batch Consumption Time: 0.53430
Total Iteration Time: 7.24117

Cumulative Model Updates: 97,832
Cumulative Timesteps: 815,998,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 815998202...
Checkpoint 815998202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,963.26383
Policy Entropy: 1.92390
Value Function Loss: 0.07440

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.54999
Value Function Update Magnitude: 0.69163

Collected Steps per Second: 15,289.56209
Overall Steps per Second: 7,059.55891

Timestep Collection Time: 3.27112
Timestep Consumption Time: 3.81346
PPO Batch Consumption Time: 0.50227
Total Iteration Time: 7.08458

Cumulative Model Updates: 97,838
Cumulative Timesteps: 816,048,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,320.33364
Policy Entropy: 1.92998
Value Function Loss: 0.07445

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.53153
Value Function Update Magnitude: 0.67559

Collected Steps per Second: 15,707.11017
Overall Steps per Second: 7,041.84359

Timestep Collection Time: 3.18391
Timestep Consumption Time: 3.91793
PPO Batch Consumption Time: 0.51954
Total Iteration Time: 7.10183

Cumulative Model Updates: 97,844
Cumulative Timesteps: 816,098,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 816098226...
Checkpoint 816098226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,594.78183
Policy Entropy: 1.93072
Value Function Loss: 0.07497

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.16737
Policy Update Magnitude: 0.49533
Value Function Update Magnitude: 0.63222

Collected Steps per Second: 15,392.14122
Overall Steps per Second: 6,979.60010

Timestep Collection Time: 3.25075
Timestep Consumption Time: 3.91814
PPO Batch Consumption Time: 0.52018
Total Iteration Time: 7.16889

Cumulative Model Updates: 97,850
Cumulative Timesteps: 816,148,262

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,387.70059
Policy Entropy: 1.92699
Value Function Loss: 0.06948

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.15825
Policy Update Magnitude: 0.51801
Value Function Update Magnitude: 0.58642

Collected Steps per Second: 15,425.36762
Overall Steps per Second: 7,017.93887

Timestep Collection Time: 3.24271
Timestep Consumption Time: 3.88474
PPO Batch Consumption Time: 0.50981
Total Iteration Time: 7.12745

Cumulative Model Updates: 97,856
Cumulative Timesteps: 816,198,282

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 816198282...
Checkpoint 816198282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,654.44372
Policy Entropy: 1.93651
Value Function Loss: 0.06667

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.15622
Policy Update Magnitude: 0.51087
Value Function Update Magnitude: 0.56244

Collected Steps per Second: 15,546.28248
Overall Steps per Second: 7,089.40934

Timestep Collection Time: 3.21813
Timestep Consumption Time: 3.83887
PPO Batch Consumption Time: 0.50917
Total Iteration Time: 7.05701

Cumulative Model Updates: 97,862
Cumulative Timesteps: 816,248,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,219.10505
Policy Entropy: 1.93228
Value Function Loss: 0.06535

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.15278
Policy Update Magnitude: 0.52037
Value Function Update Magnitude: 0.62259

Collected Steps per Second: 15,645.16334
Overall Steps per Second: 7,135.65298

Timestep Collection Time: 3.19818
Timestep Consumption Time: 3.81394
PPO Batch Consumption Time: 0.50195
Total Iteration Time: 7.01211

Cumulative Model Updates: 97,868
Cumulative Timesteps: 816,298,348

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 816298348...
Checkpoint 816298348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,795.30627
Policy Entropy: 1.91866
Value Function Loss: 0.06886

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.55136
Value Function Update Magnitude: 0.62201

Collected Steps per Second: 15,432.19587
Overall Steps per Second: 6,971.55343

Timestep Collection Time: 3.24192
Timestep Consumption Time: 3.93438
PPO Batch Consumption Time: 0.52713
Total Iteration Time: 7.17631

Cumulative Model Updates: 97,874
Cumulative Timesteps: 816,348,378

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,131.06972
Policy Entropy: 1.91425
Value Function Loss: 0.07392

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.13799
Policy Update Magnitude: 0.56152
Value Function Update Magnitude: 0.56298

Collected Steps per Second: 15,602.26814
Overall Steps per Second: 7,053.38103

Timestep Collection Time: 3.20530
Timestep Consumption Time: 3.88491
PPO Batch Consumption Time: 0.51667
Total Iteration Time: 7.09022

Cumulative Model Updates: 97,880
Cumulative Timesteps: 816,398,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 816398388...
Checkpoint 816398388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,270.16884
Policy Entropy: 1.91704
Value Function Loss: 0.07612

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.13848
Policy Update Magnitude: 0.55662
Value Function Update Magnitude: 0.45400

Collected Steps per Second: 15,423.99374
Overall Steps per Second: 7,065.20348

Timestep Collection Time: 3.24235
Timestep Consumption Time: 3.83600
PPO Batch Consumption Time: 0.50930
Total Iteration Time: 7.07835

Cumulative Model Updates: 97,886
Cumulative Timesteps: 816,448,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,604.30899
Policy Entropy: 1.93000
Value Function Loss: 0.07697

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.55611
Value Function Update Magnitude: 0.40433

Collected Steps per Second: 15,621.80076
Overall Steps per Second: 7,010.45399

Timestep Collection Time: 3.20194
Timestep Consumption Time: 3.93312
PPO Batch Consumption Time: 0.52385
Total Iteration Time: 7.13506

Cumulative Model Updates: 97,892
Cumulative Timesteps: 816,498,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 816498418...
Checkpoint 816498418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,142.32810
Policy Entropy: 1.93731
Value Function Loss: 0.08006

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.16310
Policy Update Magnitude: 0.52935
Value Function Update Magnitude: 0.49911

Collected Steps per Second: 15,478.19627
Overall Steps per Second: 7,083.90158

Timestep Collection Time: 3.23164
Timestep Consumption Time: 3.82944
PPO Batch Consumption Time: 0.51273
Total Iteration Time: 7.06108

Cumulative Model Updates: 97,898
Cumulative Timesteps: 816,548,438

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,020.43295
Policy Entropy: 1.93378
Value Function Loss: 0.07792

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.15888
Policy Update Magnitude: 0.50219
Value Function Update Magnitude: 0.53267

Collected Steps per Second: 15,559.82091
Overall Steps per Second: 7,026.30798

Timestep Collection Time: 3.21520
Timestep Consumption Time: 3.90489
PPO Batch Consumption Time: 0.51916
Total Iteration Time: 7.12010

Cumulative Model Updates: 97,904
Cumulative Timesteps: 816,598,466

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 816598466...
Checkpoint 816598466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,999.13512
Policy Entropy: 1.91892
Value Function Loss: 0.07977

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.16534
Policy Update Magnitude: 0.47198
Value Function Update Magnitude: 0.44654

Collected Steps per Second: 15,373.74309
Overall Steps per Second: 6,933.15085

Timestep Collection Time: 3.25386
Timestep Consumption Time: 3.96133
PPO Batch Consumption Time: 0.52833
Total Iteration Time: 7.21519

Cumulative Model Updates: 97,910
Cumulative Timesteps: 816,648,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,291.85096
Policy Entropy: 1.91726
Value Function Loss: 0.07575

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.15207
Policy Update Magnitude: 0.47406
Value Function Update Magnitude: 0.42679

Collected Steps per Second: 15,667.45164
Overall Steps per Second: 7,084.87332

Timestep Collection Time: 3.19286
Timestep Consumption Time: 3.86782
PPO Batch Consumption Time: 0.51274
Total Iteration Time: 7.06068

Cumulative Model Updates: 97,916
Cumulative Timesteps: 816,698,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 816698514...
Checkpoint 816698514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,686.94189
Policy Entropy: 1.93028
Value Function Loss: 0.08153

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.15821
Policy Update Magnitude: 0.48092
Value Function Update Magnitude: 0.44458

Collected Steps per Second: 15,296.51942
Overall Steps per Second: 6,948.55566

Timestep Collection Time: 3.26911
Timestep Consumption Time: 3.92749
PPO Batch Consumption Time: 0.52550
Total Iteration Time: 7.19660

Cumulative Model Updates: 97,922
Cumulative Timesteps: 816,748,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,617.71745
Policy Entropy: 1.94437
Value Function Loss: 0.08307

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.16441
Policy Update Magnitude: 0.51321
Value Function Update Magnitude: 0.44853

Collected Steps per Second: 15,614.86644
Overall Steps per Second: 7,016.65272

Timestep Collection Time: 3.20208
Timestep Consumption Time: 3.92383
PPO Batch Consumption Time: 0.52645
Total Iteration Time: 7.12590

Cumulative Model Updates: 97,928
Cumulative Timesteps: 816,798,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 816798520...
Checkpoint 816798520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,868.96199
Policy Entropy: 1.93761
Value Function Loss: 0.08554

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.15325
Policy Update Magnitude: 0.56222
Value Function Update Magnitude: 0.49994

Collected Steps per Second: 15,743.28016
Overall Steps per Second: 7,165.61888

Timestep Collection Time: 3.17888
Timestep Consumption Time: 3.80530
PPO Batch Consumption Time: 0.50259
Total Iteration Time: 6.98418

Cumulative Model Updates: 97,934
Cumulative Timesteps: 816,848,566

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,989.61174
Policy Entropy: 1.94169
Value Function Loss: 0.07682

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.17808
Policy Update Magnitude: 0.53906
Value Function Update Magnitude: 0.61222

Collected Steps per Second: 15,760.46414
Overall Steps per Second: 7,020.78513

Timestep Collection Time: 3.17338
Timestep Consumption Time: 3.95032
PPO Batch Consumption Time: 0.52737
Total Iteration Time: 7.12370

Cumulative Model Updates: 97,940
Cumulative Timesteps: 816,898,580

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 816898580...
Checkpoint 816898580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,330.61116
Policy Entropy: 1.92568
Value Function Loss: 0.07365

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.16817
Policy Update Magnitude: 0.49623
Value Function Update Magnitude: 0.60985

Collected Steps per Second: 15,328.85886
Overall Steps per Second: 7,039.79901

Timestep Collection Time: 3.26234
Timestep Consumption Time: 3.84127
PPO Batch Consumption Time: 0.51302
Total Iteration Time: 7.10361

Cumulative Model Updates: 97,946
Cumulative Timesteps: 816,948,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,634.29911
Policy Entropy: 1.92431
Value Function Loss: 0.07092

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.53551
Value Function Update Magnitude: 0.66906

Collected Steps per Second: 15,411.85530
Overall Steps per Second: 7,045.85548

Timestep Collection Time: 3.24529
Timestep Consumption Time: 3.85335
PPO Batch Consumption Time: 0.51358
Total Iteration Time: 7.09864

Cumulative Model Updates: 97,952
Cumulative Timesteps: 816,998,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 816998604...
Checkpoint 816998604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,104.59527
Policy Entropy: 1.92979
Value Function Loss: 0.07306

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.54865
Value Function Update Magnitude: 0.59462

Collected Steps per Second: 15,073.66052
Overall Steps per Second: 6,884.59204

Timestep Collection Time: 3.31864
Timestep Consumption Time: 3.94744
PPO Batch Consumption Time: 0.52474
Total Iteration Time: 7.26608

Cumulative Model Updates: 97,958
Cumulative Timesteps: 817,048,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,237.88993
Policy Entropy: 1.93966
Value Function Loss: 0.07441

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.15750
Policy Update Magnitude: 0.50585
Value Function Update Magnitude: 0.62060

Collected Steps per Second: 15,483.96750
Overall Steps per Second: 6,942.37821

Timestep Collection Time: 3.22928
Timestep Consumption Time: 3.97316
PPO Batch Consumption Time: 0.53496
Total Iteration Time: 7.20243

Cumulative Model Updates: 97,964
Cumulative Timesteps: 817,098,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 817098630...
Checkpoint 817098630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,583.30392
Policy Entropy: 1.94059
Value Function Loss: 0.07341

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.15747
Policy Update Magnitude: 0.47134
Value Function Update Magnitude: 0.63672

Collected Steps per Second: 15,474.14991
Overall Steps per Second: 6,914.50437

Timestep Collection Time: 3.23236
Timestep Consumption Time: 4.00142
PPO Batch Consumption Time: 0.53526
Total Iteration Time: 7.23378

Cumulative Model Updates: 97,970
Cumulative Timesteps: 817,148,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,615.02788
Policy Entropy: 1.93403
Value Function Loss: 0.07196

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14462
Policy Update Magnitude: 0.50924
Value Function Update Magnitude: 0.65573

Collected Steps per Second: 15,518.53174
Overall Steps per Second: 7,092.31333

Timestep Collection Time: 3.22311
Timestep Consumption Time: 3.82931
PPO Batch Consumption Time: 0.50700
Total Iteration Time: 7.05242

Cumulative Model Updates: 97,976
Cumulative Timesteps: 817,198,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 817198666...
Checkpoint 817198666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,126.09859
Policy Entropy: 1.92781
Value Function Loss: 0.07508

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.15806
Policy Update Magnitude: 0.50781
Value Function Update Magnitude: 0.69429

Collected Steps per Second: 15,272.60470
Overall Steps per Second: 6,864.01367

Timestep Collection Time: 3.27580
Timestep Consumption Time: 4.01294
PPO Batch Consumption Time: 0.53675
Total Iteration Time: 7.28874

Cumulative Model Updates: 97,982
Cumulative Timesteps: 817,248,696

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,367.21145
Policy Entropy: 1.92171
Value Function Loss: 0.07502

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.14925
Policy Update Magnitude: 0.51974
Value Function Update Magnitude: 0.63070

Collected Steps per Second: 15,572.78930
Overall Steps per Second: 7,062.04495

Timestep Collection Time: 3.21381
Timestep Consumption Time: 3.87309
PPO Batch Consumption Time: 0.51212
Total Iteration Time: 7.08690

Cumulative Model Updates: 97,988
Cumulative Timesteps: 817,298,744

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 817298744...
Checkpoint 817298744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,425.11404
Policy Entropy: 1.94258
Value Function Loss: 0.07658

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.15274
Policy Update Magnitude: 0.52014
Value Function Update Magnitude: 0.53818

Collected Steps per Second: 15,410.68819
Overall Steps per Second: 7,029.71378

Timestep Collection Time: 3.24606
Timestep Consumption Time: 3.87002
PPO Batch Consumption Time: 0.51198
Total Iteration Time: 7.11608

Cumulative Model Updates: 97,994
Cumulative Timesteps: 817,348,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,989.64113
Policy Entropy: 1.93215
Value Function Loss: 0.07684

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.15252
Policy Update Magnitude: 0.55821
Value Function Update Magnitude: 0.46144

Collected Steps per Second: 15,513.95081
Overall Steps per Second: 6,965.90604

Timestep Collection Time: 3.22316
Timestep Consumption Time: 3.95523
PPO Batch Consumption Time: 0.52798
Total Iteration Time: 7.17839

Cumulative Model Updates: 98,000
Cumulative Timesteps: 817,398,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 817398772...
Checkpoint 817398772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,910.69034
Policy Entropy: 1.94887
Value Function Loss: 0.08434

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.15020
Policy Update Magnitude: 0.55808
Value Function Update Magnitude: 0.36789

Collected Steps per Second: 15,365.52997
Overall Steps per Second: 6,925.34629

Timestep Collection Time: 3.25573
Timestep Consumption Time: 3.96788
PPO Batch Consumption Time: 0.53038
Total Iteration Time: 7.22361

Cumulative Model Updates: 98,006
Cumulative Timesteps: 817,448,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,134.23489
Policy Entropy: 1.94284
Value Function Loss: 0.08744

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.14635
Policy Update Magnitude: 0.54754
Value Function Update Magnitude: 0.29332

Collected Steps per Second: 15,608.18598
Overall Steps per Second: 7,101.99259

Timestep Collection Time: 3.20473
Timestep Consumption Time: 3.83837
PPO Batch Consumption Time: 0.51049
Total Iteration Time: 7.04309

Cumulative Model Updates: 98,012
Cumulative Timesteps: 817,498,818

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 817498818...
Checkpoint 817498818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,333.45255
Policy Entropy: 1.95039
Value Function Loss: 0.09085

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.55065
Value Function Update Magnitude: 0.27717

Collected Steps per Second: 15,518.92800
Overall Steps per Second: 7,018.82993

Timestep Collection Time: 3.22355
Timestep Consumption Time: 3.90385
PPO Batch Consumption Time: 0.51797
Total Iteration Time: 7.12740

Cumulative Model Updates: 98,018
Cumulative Timesteps: 817,548,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,692.34668
Policy Entropy: 1.94166
Value Function Loss: 0.08256

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.14888
Policy Update Magnitude: 0.56118
Value Function Update Magnitude: 0.28554

Collected Steps per Second: 15,369.01046
Overall Steps per Second: 6,956.27278

Timestep Collection Time: 3.25538
Timestep Consumption Time: 3.93698
PPO Batch Consumption Time: 0.51949
Total Iteration Time: 7.19236

Cumulative Model Updates: 98,024
Cumulative Timesteps: 817,598,876

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 817598876...
Checkpoint 817598876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,796.03733
Policy Entropy: 1.95009
Value Function Loss: 0.07922

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.16197
Policy Update Magnitude: 0.51665
Value Function Update Magnitude: 0.38060

Collected Steps per Second: 15,037.35340
Overall Steps per Second: 7,131.93421

Timestep Collection Time: 3.32519
Timestep Consumption Time: 3.68582
PPO Batch Consumption Time: 0.48621
Total Iteration Time: 7.01100

Cumulative Model Updates: 98,030
Cumulative Timesteps: 817,648,878

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,065.74276
Policy Entropy: 1.94751
Value Function Loss: 0.07117

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.51262
Value Function Update Magnitude: 0.57625

Collected Steps per Second: 16,238.42336
Overall Steps per Second: 8,789.44678

Timestep Collection Time: 3.08109
Timestep Consumption Time: 2.61119
PPO Batch Consumption Time: 0.29707
Total Iteration Time: 5.69228

Cumulative Model Updates: 98,036
Cumulative Timesteps: 817,698,910

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 817698910...
Checkpoint 817698910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,340.40565
Policy Entropy: 1.95277
Value Function Loss: 0.07468

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.15152
Policy Update Magnitude: 0.57047
Value Function Update Magnitude: 0.66386

Collected Steps per Second: 19,203.02346
Overall Steps per Second: 9,691.97899

Timestep Collection Time: 2.60428
Timestep Consumption Time: 2.55566
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 5.15994

Cumulative Model Updates: 98,042
Cumulative Timesteps: 817,748,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,258.08722
Policy Entropy: 1.93497
Value Function Loss: 0.07272

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.17292
Policy Update Magnitude: 0.56007
Value Function Update Magnitude: 0.69533

Collected Steps per Second: 19,859.23858
Overall Steps per Second: 9,890.19670

Timestep Collection Time: 2.51782
Timestep Consumption Time: 2.53789
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 5.05571

Cumulative Model Updates: 98,048
Cumulative Timesteps: 817,798,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 817798922...
Checkpoint 817798922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,999.31601
Policy Entropy: 1.93314
Value Function Loss: 0.07802

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.17447
Policy Update Magnitude: 0.51305
Value Function Update Magnitude: 0.73055

Collected Steps per Second: 20,473.54214
Overall Steps per Second: 10,041.06257

Timestep Collection Time: 2.44315
Timestep Consumption Time: 2.53839
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.98154

Cumulative Model Updates: 98,054
Cumulative Timesteps: 817,848,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,107.02366
Policy Entropy: 1.93495
Value Function Loss: 0.07823

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.16489
Policy Update Magnitude: 0.50616
Value Function Update Magnitude: 0.68310

Collected Steps per Second: 21,545.55084
Overall Steps per Second: 10,436.75351

Timestep Collection Time: 2.32159
Timestep Consumption Time: 2.47109
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.79268

Cumulative Model Updates: 98,060
Cumulative Timesteps: 817,898,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 817898962...
Checkpoint 817898962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,425.42285
Policy Entropy: 1.93870
Value Function Loss: 0.08391

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.15069
Policy Update Magnitude: 0.52385
Value Function Update Magnitude: 0.54798

Collected Steps per Second: 20,968.59400
Overall Steps per Second: 10,220.73771

Timestep Collection Time: 2.38643
Timestep Consumption Time: 2.50950
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.89593

Cumulative Model Updates: 98,066
Cumulative Timesteps: 817,949,002

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,561.05257
Policy Entropy: 1.95950
Value Function Loss: 0.08941

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.16724
Policy Update Magnitude: 0.51734
Value Function Update Magnitude: 0.66282

Collected Steps per Second: 22,039.87616
Overall Steps per Second: 10,460.53393

Timestep Collection Time: 2.26925
Timestep Consumption Time: 2.51196
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.78121

Cumulative Model Updates: 98,072
Cumulative Timesteps: 817,999,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 817999016...
Checkpoint 817999016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,126.94717
Policy Entropy: 1.96248
Value Function Loss: 0.09204

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.17841
Policy Update Magnitude: 0.51459
Value Function Update Magnitude: 0.60847

Collected Steps per Second: 21,396.93116
Overall Steps per Second: 10,297.27251

Timestep Collection Time: 2.33809
Timestep Consumption Time: 2.52028
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.85837

Cumulative Model Updates: 98,078
Cumulative Timesteps: 818,049,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,190.43351
Policy Entropy: 1.96777
Value Function Loss: 0.09329

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.16030
Policy Update Magnitude: 0.54075
Value Function Update Magnitude: 0.52712

Collected Steps per Second: 21,766.23802
Overall Steps per Second: 10,414.09247

Timestep Collection Time: 2.29833
Timestep Consumption Time: 2.50535
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.80368

Cumulative Model Updates: 98,084
Cumulative Timesteps: 818,099,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 818099070...
Checkpoint 818099070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,247.08228
Policy Entropy: 1.94384
Value Function Loss: 0.08536

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.16385
Policy Update Magnitude: 0.55033
Value Function Update Magnitude: 0.50329

Collected Steps per Second: 21,601.48448
Overall Steps per Second: 10,313.22535

Timestep Collection Time: 2.31558
Timestep Consumption Time: 2.53450
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.85008

Cumulative Model Updates: 98,090
Cumulative Timesteps: 818,149,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,091.22286
Policy Entropy: 1.92500
Value Function Loss: 0.08412

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.18262
Policy Update Magnitude: 0.53940
Value Function Update Magnitude: 0.48524

Collected Steps per Second: 22,072.65495
Overall Steps per Second: 10,401.81600

Timestep Collection Time: 2.26615
Timestep Consumption Time: 2.54262
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.80878

Cumulative Model Updates: 98,096
Cumulative Timesteps: 818,199,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 818199110...
Checkpoint 818199110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,056.69324
Policy Entropy: 1.91642
Value Function Loss: 0.08129

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.17682
Policy Update Magnitude: 0.52960
Value Function Update Magnitude: 0.50775

Collected Steps per Second: 21,148.93790
Overall Steps per Second: 10,182.94340

Timestep Collection Time: 2.36627
Timestep Consumption Time: 2.54823
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.91449

Cumulative Model Updates: 98,102
Cumulative Timesteps: 818,249,154

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,819.49562
Policy Entropy: 1.91458
Value Function Loss: 0.07748

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.17527
Policy Update Magnitude: 0.48712
Value Function Update Magnitude: 0.44969

Collected Steps per Second: 21,555.01116
Overall Steps per Second: 10,435.44159

Timestep Collection Time: 2.32104
Timestep Consumption Time: 2.47320
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.79424

Cumulative Model Updates: 98,108
Cumulative Timesteps: 818,299,184

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 818299184...
Checkpoint 818299184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,447.87899
Policy Entropy: 1.91720
Value Function Loss: 0.07638

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15999
Policy Update Magnitude: 0.46050
Value Function Update Magnitude: 0.47740

Collected Steps per Second: 20,843.67105
Overall Steps per Second: 10,153.86397

Timestep Collection Time: 2.39939
Timestep Consumption Time: 2.52603
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.92542

Cumulative Model Updates: 98,114
Cumulative Timesteps: 818,349,196

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,481.54718
Policy Entropy: 1.91624
Value Function Loss: 0.07492

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.14665
Policy Update Magnitude: 0.48219
Value Function Update Magnitude: 0.55253

Collected Steps per Second: 21,783.59889
Overall Steps per Second: 10,473.77995

Timestep Collection Time: 2.29650
Timestep Consumption Time: 2.47981
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.77631

Cumulative Model Updates: 98,120
Cumulative Timesteps: 818,399,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 818399222...
Checkpoint 818399222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,496.05798
Policy Entropy: 1.94027
Value Function Loss: 0.08152

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.15177
Policy Update Magnitude: 0.52553
Value Function Update Magnitude: 0.67474

Collected Steps per Second: 20,742.93335
Overall Steps per Second: 10,129.68587

Timestep Collection Time: 2.41065
Timestep Consumption Time: 2.52573
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.93638

Cumulative Model Updates: 98,126
Cumulative Timesteps: 818,449,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,008.68048
Policy Entropy: 1.96153
Value Function Loss: 0.07560

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.16536
Policy Update Magnitude: 0.50024
Value Function Update Magnitude: 0.69463

Collected Steps per Second: 20,738.91730
Overall Steps per Second: 10,164.98029

Timestep Collection Time: 2.41237
Timestep Consumption Time: 2.50943
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.92180

Cumulative Model Updates: 98,132
Cumulative Timesteps: 818,499,256

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 818499256...
Checkpoint 818499256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,124.43789
Policy Entropy: 1.96365
Value Function Loss: 0.07248

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.52903
Value Function Update Magnitude: 0.61762

Collected Steps per Second: 20,161.78437
Overall Steps per Second: 10,108.92394

Timestep Collection Time: 2.48113
Timestep Consumption Time: 2.46737
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.94850

Cumulative Model Updates: 98,138
Cumulative Timesteps: 818,549,280

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,278.15544
Policy Entropy: 1.95852
Value Function Loss: 0.07316

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12650
Policy Update Magnitude: 0.56508
Value Function Update Magnitude: 0.55222

Collected Steps per Second: 22,143.30434
Overall Steps per Second: 10,460.99399

Timestep Collection Time: 2.25883
Timestep Consumption Time: 2.52255
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.78138

Cumulative Model Updates: 98,144
Cumulative Timesteps: 818,599,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 818599298...
Checkpoint 818599298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,528.20616
Policy Entropy: 1.94639
Value Function Loss: 0.07325

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13562
Policy Update Magnitude: 0.56503
Value Function Update Magnitude: 0.62365

Collected Steps per Second: 21,473.07547
Overall Steps per Second: 10,254.75332

Timestep Collection Time: 2.32971
Timestep Consumption Time: 2.54861
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.87832

Cumulative Model Updates: 98,150
Cumulative Timesteps: 818,649,324

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,902.83572
Policy Entropy: 1.94679
Value Function Loss: 0.07648

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.57322
Value Function Update Magnitude: 0.66053

Collected Steps per Second: 22,171.44842
Overall Steps per Second: 10,478.18506

Timestep Collection Time: 2.25633
Timestep Consumption Time: 2.51797
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.77430

Cumulative Model Updates: 98,156
Cumulative Timesteps: 818,699,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 818699350...
Checkpoint 818699350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,329.16415
Policy Entropy: 1.94976
Value Function Loss: 0.07778

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.58149
Value Function Update Magnitude: 0.62188

Collected Steps per Second: 21,615.72487
Overall Steps per Second: 10,324.82877

Timestep Collection Time: 2.31406
Timestep Consumption Time: 2.53058
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.84463

Cumulative Model Updates: 98,162
Cumulative Timesteps: 818,749,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,798.16843
Policy Entropy: 1.95474
Value Function Loss: 0.07645

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13596
Policy Update Magnitude: 0.57659
Value Function Update Magnitude: 0.55129

Collected Steps per Second: 22,345.09703
Overall Steps per Second: 10,515.66842

Timestep Collection Time: 2.23870
Timestep Consumption Time: 2.51839
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.75709

Cumulative Model Updates: 98,168
Cumulative Timesteps: 818,799,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 818799394...
Checkpoint 818799394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,051.75976
Policy Entropy: 1.95434
Value Function Loss: 0.07899

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.57450
Value Function Update Magnitude: 0.64683

Collected Steps per Second: 21,770.81229
Overall Steps per Second: 10,434.40693

Timestep Collection Time: 2.29730
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.79318

Cumulative Model Updates: 98,174
Cumulative Timesteps: 818,849,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,245.12852
Policy Entropy: 1.95131
Value Function Loss: 0.07445

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.58411
Value Function Update Magnitude: 0.69661

Collected Steps per Second: 22,235.23912
Overall Steps per Second: 10,488.47589

Timestep Collection Time: 2.24904
Timestep Consumption Time: 2.51886
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.76790

Cumulative Model Updates: 98,180
Cumulative Timesteps: 818,899,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 818899416...
Checkpoint 818899416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,018.37153
Policy Entropy: 1.95473
Value Function Loss: 0.07930

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.58724
Value Function Update Magnitude: 0.67773

Collected Steps per Second: 21,349.07986
Overall Steps per Second: 10,385.58762

Timestep Collection Time: 2.34305
Timestep Consumption Time: 2.47343
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.81648

Cumulative Model Updates: 98,186
Cumulative Timesteps: 818,949,438

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,859.95237
Policy Entropy: 1.94514
Value Function Loss: 0.07562

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.58386
Value Function Update Magnitude: 0.66170

Collected Steps per Second: 21,816.52282
Overall Steps per Second: 10,380.42612

Timestep Collection Time: 2.29230
Timestep Consumption Time: 2.52542
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.81772

Cumulative Model Updates: 98,192
Cumulative Timesteps: 818,999,448

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 818999448...
Checkpoint 818999448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,567.54308
Policy Entropy: 1.93647
Value Function Loss: 0.07879

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13161
Policy Update Magnitude: 0.58993
Value Function Update Magnitude: 0.68486

Collected Steps per Second: 21,078.53317
Overall Steps per Second: 10,187.46293

Timestep Collection Time: 2.37246
Timestep Consumption Time: 2.53632
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.90878

Cumulative Model Updates: 98,198
Cumulative Timesteps: 819,049,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,776.32845
Policy Entropy: 1.92859
Value Function Loss: 0.08028

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.59468
Value Function Update Magnitude: 0.64976

Collected Steps per Second: 21,562.46861
Overall Steps per Second: 10,398.53383

Timestep Collection Time: 2.31996
Timestep Consumption Time: 2.49072
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.81068

Cumulative Model Updates: 98,204
Cumulative Timesteps: 819,099,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 819099480...
Checkpoint 819099480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,282.31198
Policy Entropy: 1.91779
Value Function Loss: 0.07901

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.57312
Value Function Update Magnitude: 0.64395

Collected Steps per Second: 20,989.15109
Overall Steps per Second: 10,179.39432

Timestep Collection Time: 2.38333
Timestep Consumption Time: 2.53091
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.91424

Cumulative Model Updates: 98,210
Cumulative Timesteps: 819,149,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,793.05748
Policy Entropy: 1.92031
Value Function Loss: 0.07504

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14764
Policy Update Magnitude: 0.53886
Value Function Update Magnitude: 0.61140

Collected Steps per Second: 21,608.19352
Overall Steps per Second: 10,446.66294

Timestep Collection Time: 2.31431
Timestep Consumption Time: 2.47268
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.78698

Cumulative Model Updates: 98,216
Cumulative Timesteps: 819,199,512

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 819199512...
Checkpoint 819199512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,698.80571
Policy Entropy: 1.92050
Value Function Loss: 0.07701

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.14476
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.60211

Collected Steps per Second: 21,128.85369
Overall Steps per Second: 10,197.58873

Timestep Collection Time: 2.36691
Timestep Consumption Time: 2.53720
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.90410

Cumulative Model Updates: 98,222
Cumulative Timesteps: 819,249,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,804.86517
Policy Entropy: 1.92557
Value Function Loss: 0.07877

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.15975
Policy Update Magnitude: 0.52388
Value Function Update Magnitude: 0.69952

Collected Steps per Second: 22,176.09945
Overall Steps per Second: 10,544.89087

Timestep Collection Time: 2.25639
Timestep Consumption Time: 2.48884
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.74524

Cumulative Model Updates: 98,228
Cumulative Timesteps: 819,299,560

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 819299560...
Checkpoint 819299560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,405.43001
Policy Entropy: 1.92700
Value Function Loss: 0.08179

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.15045
Policy Update Magnitude: 0.54880
Value Function Update Magnitude: 0.61872

Collected Steps per Second: 21,780.97497
Overall Steps per Second: 10,507.44107

Timestep Collection Time: 2.29576
Timestep Consumption Time: 2.46315
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.75891

Cumulative Model Updates: 98,234
Cumulative Timesteps: 819,349,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,585.24717
Policy Entropy: 1.91209
Value Function Loss: 0.07861

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.58576
Value Function Update Magnitude: 0.49320

Collected Steps per Second: 21,967.02636
Overall Steps per Second: 10,563.67971

Timestep Collection Time: 2.27723
Timestep Consumption Time: 2.45824
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.73547

Cumulative Model Updates: 98,240
Cumulative Timesteps: 819,399,588

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 819399588...
Checkpoint 819399588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,597.65097
Policy Entropy: 1.91902
Value Function Loss: 0.08525

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14732
Policy Update Magnitude: 0.59441
Value Function Update Magnitude: 0.45651

Collected Steps per Second: 21,535.93125
Overall Steps per Second: 10,352.16312

Timestep Collection Time: 2.32263
Timestep Consumption Time: 2.50921
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.83184

Cumulative Model Updates: 98,246
Cumulative Timesteps: 819,449,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,641.11167
Policy Entropy: 1.90711
Value Function Loss: 0.08093

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14428
Policy Update Magnitude: 0.58988
Value Function Update Magnitude: 0.44696

Collected Steps per Second: 22,228.86964
Overall Steps per Second: 10,641.92036

Timestep Collection Time: 2.25050
Timestep Consumption Time: 2.45035
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.70084

Cumulative Model Updates: 98,252
Cumulative Timesteps: 819,499,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 819499634...
Checkpoint 819499634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,938.88467
Policy Entropy: 1.91786
Value Function Loss: 0.08390

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.59072
Value Function Update Magnitude: 0.42983

Collected Steps per Second: 21,794.65178
Overall Steps per Second: 10,376.50733

Timestep Collection Time: 2.29469
Timestep Consumption Time: 2.52504
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.81973

Cumulative Model Updates: 98,258
Cumulative Timesteps: 819,549,646

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,556.54726
Policy Entropy: 1.91479
Value Function Loss: 0.08145

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.59135
Value Function Update Magnitude: 0.44077

Collected Steps per Second: 22,355.37892
Overall Steps per Second: 10,514.60604

Timestep Collection Time: 2.23731
Timestep Consumption Time: 2.51950
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.75681

Cumulative Model Updates: 98,264
Cumulative Timesteps: 819,599,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 819599662...
Checkpoint 819599662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,935.62113
Policy Entropy: 1.90636
Value Function Loss: 0.08399

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.59771
Value Function Update Magnitude: 0.42549

Collected Steps per Second: 21,311.14130
Overall Steps per Second: 10,424.31249

Timestep Collection Time: 2.34732
Timestep Consumption Time: 2.45146
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.79878

Cumulative Model Updates: 98,270
Cumulative Timesteps: 819,649,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,667.53577
Policy Entropy: 1.90629
Value Function Loss: 0.08379

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.59654
Value Function Update Magnitude: 0.41142

Collected Steps per Second: 21,023.49985
Overall Steps per Second: 10,216.70699

Timestep Collection Time: 2.38076
Timestep Consumption Time: 2.51827
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.89903

Cumulative Model Updates: 98,276
Cumulative Timesteps: 819,699,738

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 819699738...
Checkpoint 819699738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,791.13643
Policy Entropy: 1.90689
Value Function Loss: 0.08197

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.58182
Value Function Update Magnitude: 0.50302

Collected Steps per Second: 20,535.65046
Overall Steps per Second: 10,131.46763

Timestep Collection Time: 2.43567
Timestep Consumption Time: 2.50123
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.93690

Cumulative Model Updates: 98,282
Cumulative Timesteps: 819,749,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,495.87391
Policy Entropy: 1.90490
Value Function Loss: 0.07992

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.59278
Value Function Update Magnitude: 0.59627

Collected Steps per Second: 21,028.14476
Overall Steps per Second: 10,351.93388

Timestep Collection Time: 2.37834
Timestep Consumption Time: 2.45284
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.83117

Cumulative Model Updates: 98,288
Cumulative Timesteps: 819,799,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 819799768...
Checkpoint 819799768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,176.23138
Policy Entropy: 1.89934
Value Function Loss: 0.07900

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.59797
Value Function Update Magnitude: 0.60742

Collected Steps per Second: 21,374.08038
Overall Steps per Second: 10,255.17204

Timestep Collection Time: 2.34003
Timestep Consumption Time: 2.53712
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.87715

Cumulative Model Updates: 98,294
Cumulative Timesteps: 819,849,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,298.21041
Policy Entropy: 1.90331
Value Function Loss: 0.08289

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.58812
Value Function Update Magnitude: 0.61646

Collected Steps per Second: 22,272.79218
Overall Steps per Second: 10,361.72550

Timestep Collection Time: 2.24525
Timestep Consumption Time: 2.58097
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.82622

Cumulative Model Updates: 98,300
Cumulative Timesteps: 819,899,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 819899792...
Checkpoint 819899792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,417.00090
Policy Entropy: 1.89535
Value Function Loss: 0.08001

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14837
Policy Update Magnitude: 0.56912
Value Function Update Magnitude: 0.66672

Collected Steps per Second: 21,486.50408
Overall Steps per Second: 10,304.62502

Timestep Collection Time: 2.32816
Timestep Consumption Time: 2.52636
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.85452

Cumulative Model Updates: 98,306
Cumulative Timesteps: 819,949,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,680.60763
Policy Entropy: 1.90000
Value Function Loss: 0.08340

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13578
Policy Update Magnitude: 0.56097
Value Function Update Magnitude: 0.52252

Collected Steps per Second: 22,203.63437
Overall Steps per Second: 10,442.99038

Timestep Collection Time: 2.25296
Timestep Consumption Time: 2.53723
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.79020

Cumulative Model Updates: 98,312
Cumulative Timesteps: 819,999,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 819999840...
Checkpoint 819999840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,214.99193
Policy Entropy: 1.88763
Value Function Loss: 0.07985

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.56277
Value Function Update Magnitude: 0.46492

Collected Steps per Second: 21,729.74859
Overall Steps per Second: 10,388.98891

Timestep Collection Time: 2.30348
Timestep Consumption Time: 2.51451
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.81799

Cumulative Model Updates: 98,318
Cumulative Timesteps: 820,049,894

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,008.43625
Policy Entropy: 1.89060
Value Function Loss: 0.08377

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.16603
Policy Update Magnitude: 0.52844
Value Function Update Magnitude: 0.47914

Collected Steps per Second: 22,540.14417
Overall Steps per Second: 10,713.17566

Timestep Collection Time: 2.22022
Timestep Consumption Time: 2.45104
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.67126

Cumulative Model Updates: 98,324
Cumulative Timesteps: 820,099,938

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 820099938...
Checkpoint 820099938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,040.21902
Policy Entropy: 1.90477
Value Function Loss: 0.08425

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.15889
Policy Update Magnitude: 0.50414
Value Function Update Magnitude: 0.59220

Collected Steps per Second: 21,215.06409
Overall Steps per Second: 10,249.78997

Timestep Collection Time: 2.35814
Timestep Consumption Time: 2.52274
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.88088

Cumulative Model Updates: 98,330
Cumulative Timesteps: 820,149,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,856.74286
Policy Entropy: 1.90074
Value Function Loss: 0.08242

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.15417
Policy Update Magnitude: 0.54207
Value Function Update Magnitude: 0.63205

Collected Steps per Second: 22,295.05034
Overall Steps per Second: 10,457.56138

Timestep Collection Time: 2.24355
Timestep Consumption Time: 2.53959
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.78314

Cumulative Model Updates: 98,336
Cumulative Timesteps: 820,199,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 820199986...
Checkpoint 820199986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,670.35843
Policy Entropy: 1.90802
Value Function Loss: 0.07939

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.16283
Policy Update Magnitude: 0.51482
Value Function Update Magnitude: 0.62363

Collected Steps per Second: 21,135.01006
Overall Steps per Second: 10,228.39515

Timestep Collection Time: 2.36574
Timestep Consumption Time: 2.52261
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.88835

Cumulative Model Updates: 98,342
Cumulative Timesteps: 820,249,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,688.30251
Policy Entropy: 1.89336
Value Function Loss: 0.08346

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.15534
Policy Update Magnitude: 0.52466
Value Function Update Magnitude: 0.69113

Collected Steps per Second: 21,365.04833
Overall Steps per Second: 10,410.51443

Timestep Collection Time: 2.34149
Timestep Consumption Time: 2.46385
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.80533

Cumulative Model Updates: 98,348
Cumulative Timesteps: 820,300,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 820300012...
Checkpoint 820300012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,281.98188
Policy Entropy: 1.90934
Value Function Loss: 0.08743

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.15828
Policy Update Magnitude: 0.53149
Value Function Update Magnitude: 0.73120

Collected Steps per Second: 21,125.58727
Overall Steps per Second: 10,282.89071

Timestep Collection Time: 2.36784
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.86459

Cumulative Model Updates: 98,354
Cumulative Timesteps: 820,350,034

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,397.69702
Policy Entropy: 1.91461
Value Function Loss: 0.08931

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.57121
Value Function Update Magnitude: 0.72746

Collected Steps per Second: 21,495.53895
Overall Steps per Second: 10,259.17239

Timestep Collection Time: 2.32709
Timestep Consumption Time: 2.54874
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.87583

Cumulative Model Updates: 98,360
Cumulative Timesteps: 820,400,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 820400056...
Checkpoint 820400056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,374.06378
Policy Entropy: 1.93024
Value Function Loss: 0.08157

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.59950
Value Function Update Magnitude: 0.73927

Collected Steps per Second: 21,507.64713
Overall Steps per Second: 10,378.50520

Timestep Collection Time: 2.32689
Timestep Consumption Time: 2.49519
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.82208

Cumulative Model Updates: 98,366
Cumulative Timesteps: 820,450,102

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,335.45373
Policy Entropy: 1.92373
Value Function Loss: 0.07782

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.13938
Policy Update Magnitude: 0.59020
Value Function Update Magnitude: 0.71140

Collected Steps per Second: 22,398.37682
Overall Steps per Second: 10,487.07396

Timestep Collection Time: 2.23364
Timestep Consumption Time: 2.53699
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.77063

Cumulative Model Updates: 98,372
Cumulative Timesteps: 820,500,132

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 820500132...
Checkpoint 820500132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,844.80944
Policy Entropy: 1.92039
Value Function Loss: 0.08098

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.58968
Value Function Update Magnitude: 0.62709

Collected Steps per Second: 21,554.26884
Overall Steps per Second: 10,355.11264

Timestep Collection Time: 2.31973
Timestep Consumption Time: 2.50881
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.82853

Cumulative Model Updates: 98,378
Cumulative Timesteps: 820,550,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,925.04569
Policy Entropy: 1.90272
Value Function Loss: 0.08508

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.50943

Collected Steps per Second: 22,509.53344
Overall Steps per Second: 10,664.04505

Timestep Collection Time: 2.22155
Timestep Consumption Time: 2.46767
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.68921

Cumulative Model Updates: 98,384
Cumulative Timesteps: 820,600,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 820600138...
Checkpoint 820600138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,767.89947
Policy Entropy: 1.90303
Value Function Loss: 0.08586

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.55579
Value Function Update Magnitude: 0.52311

Collected Steps per Second: 21,748.37054
Overall Steps per Second: 10,413.86081

Timestep Collection Time: 2.29976
Timestep Consumption Time: 2.50307
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.80283

Cumulative Model Updates: 98,390
Cumulative Timesteps: 820,650,154

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,316.99094
Policy Entropy: 1.89663
Value Function Loss: 0.08144

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.58023
Value Function Update Magnitude: 0.55834

Collected Steps per Second: 21,319.08424
Overall Steps per Second: 10,466.82771

Timestep Collection Time: 2.34607
Timestep Consumption Time: 2.43246
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.77853

Cumulative Model Updates: 98,396
Cumulative Timesteps: 820,700,170

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 820700170...
Checkpoint 820700170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,494.16095
Policy Entropy: 1.91045
Value Function Loss: 0.07773

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14451
Policy Update Magnitude: 0.57020
Value Function Update Magnitude: 0.64513

Collected Steps per Second: 20,913.41856
Overall Steps per Second: 10,505.79908

Timestep Collection Time: 2.39196
Timestep Consumption Time: 2.36960
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.76156

Cumulative Model Updates: 98,402
Cumulative Timesteps: 820,750,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,636.45764
Policy Entropy: 1.90986
Value Function Loss: 0.07797

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.15790
Policy Update Magnitude: 0.51996
Value Function Update Magnitude: 0.70854

Collected Steps per Second: 20,847.84604
Overall Steps per Second: 10,490.98683

Timestep Collection Time: 2.39862
Timestep Consumption Time: 2.36795
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.76657

Cumulative Model Updates: 98,408
Cumulative Timesteps: 820,800,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 820800200...
Checkpoint 820800200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,804.33231
Policy Entropy: 1.91435
Value Function Loss: 0.07695

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.16162
Policy Update Magnitude: 0.52001
Value Function Update Magnitude: 0.64778

Collected Steps per Second: 20,374.98960
Overall Steps per Second: 10,145.26077

Timestep Collection Time: 2.45468
Timestep Consumption Time: 2.47511
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.92979

Cumulative Model Updates: 98,414
Cumulative Timesteps: 820,850,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,913.05423
Policy Entropy: 1.90408
Value Function Loss: 0.07610

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.16457
Policy Update Magnitude: 0.54076
Value Function Update Magnitude: 0.57558

Collected Steps per Second: 21,618.88536
Overall Steps per Second: 10,460.83687

Timestep Collection Time: 2.31289
Timestep Consumption Time: 2.46704
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.77992

Cumulative Model Updates: 98,420
Cumulative Timesteps: 820,900,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 820900216...
Checkpoint 820900216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,992.51174
Policy Entropy: 1.89626
Value Function Loss: 0.07406

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.16263
Policy Update Magnitude: 0.53088
Value Function Update Magnitude: 0.55858

Collected Steps per Second: 21,047.21102
Overall Steps per Second: 10,178.30581

Timestep Collection Time: 2.37808
Timestep Consumption Time: 2.53944
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.91752

Cumulative Model Updates: 98,426
Cumulative Timesteps: 820,950,268

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,192.21794
Policy Entropy: 1.88521
Value Function Loss: 0.07406

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.15305
Policy Update Magnitude: 0.55979
Value Function Update Magnitude: 0.54964

Collected Steps per Second: 22,181.36016
Overall Steps per Second: 10,482.01179

Timestep Collection Time: 2.25469
Timestep Consumption Time: 2.51654
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.77122

Cumulative Model Updates: 98,432
Cumulative Timesteps: 821,000,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 821000280...
Checkpoint 821000280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,397.68178
Policy Entropy: 1.88926
Value Function Loss: 0.07520

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.15163
Policy Update Magnitude: 0.58048
Value Function Update Magnitude: 0.51640

Collected Steps per Second: 21,332.37143
Overall Steps per Second: 10,332.88703

Timestep Collection Time: 2.34423
Timestep Consumption Time: 2.49546
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.83969

Cumulative Model Updates: 98,438
Cumulative Timesteps: 821,050,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,099.62050
Policy Entropy: 1.87925
Value Function Loss: 0.07472

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.14839
Policy Update Magnitude: 0.58038
Value Function Update Magnitude: 0.47643

Collected Steps per Second: 22,386.64985
Overall Steps per Second: 10,734.14434

Timestep Collection Time: 2.23374
Timestep Consumption Time: 2.42485
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.65859

Cumulative Model Updates: 98,444
Cumulative Timesteps: 821,100,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 821100294...
Checkpoint 821100294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,758.26351
Policy Entropy: 1.87907
Value Function Loss: 0.07484

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.15241
Policy Update Magnitude: 0.57652
Value Function Update Magnitude: 0.46089

Collected Steps per Second: 21,784.04345
Overall Steps per Second: 10,360.48542

Timestep Collection Time: 2.29526
Timestep Consumption Time: 2.53077
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.82603

Cumulative Model Updates: 98,450
Cumulative Timesteps: 821,150,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,343.70091
Policy Entropy: 1.88071
Value Function Loss: 0.06995

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.55811
Value Function Update Magnitude: 0.56525

Collected Steps per Second: 22,308.18408
Overall Steps per Second: 10,488.57899

Timestep Collection Time: 2.24133
Timestep Consumption Time: 2.52576
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.76709

Cumulative Model Updates: 98,456
Cumulative Timesteps: 821,200,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 821200294...
Checkpoint 821200294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,178.18260
Policy Entropy: 1.89338
Value Function Loss: 0.07441

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.57286
Value Function Update Magnitude: 0.63687

Collected Steps per Second: 21,445.22556
Overall Steps per Second: 10,483.86451

Timestep Collection Time: 2.33245
Timestep Consumption Time: 2.43869
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.77114

Cumulative Model Updates: 98,462
Cumulative Timesteps: 821,250,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,848.42276
Policy Entropy: 1.87987
Value Function Loss: 0.07222

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.57536
Value Function Update Magnitude: 0.62611

Collected Steps per Second: 22,008.57533
Overall Steps per Second: 10,474.70049

Timestep Collection Time: 2.27266
Timestep Consumption Time: 2.50246
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.77512

Cumulative Model Updates: 98,468
Cumulative Timesteps: 821,300,332

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 821300332...
Checkpoint 821300332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,408.74720
Policy Entropy: 1.86975
Value Function Loss: 0.08015

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.58205
Value Function Update Magnitude: 0.63743

Collected Steps per Second: 20,852.36143
Overall Steps per Second: 10,192.73172

Timestep Collection Time: 2.39886
Timestep Consumption Time: 2.50875
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.90761

Cumulative Model Updates: 98,474
Cumulative Timesteps: 821,350,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,548.91557
Policy Entropy: 1.85593
Value Function Loss: 0.07679

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.14516
Policy Update Magnitude: 0.55839
Value Function Update Magnitude: 0.68931

Collected Steps per Second: 21,838.97213
Overall Steps per Second: 10,449.36206

Timestep Collection Time: 2.28967
Timestep Consumption Time: 2.49570
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.78536

Cumulative Model Updates: 98,480
Cumulative Timesteps: 821,400,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 821400358...
Checkpoint 821400358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,575.46264
Policy Entropy: 1.84888
Value Function Loss: 0.08142

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.55805
Value Function Update Magnitude: 0.72457

Collected Steps per Second: 20,830.58774
Overall Steps per Second: 10,219.62890

Timestep Collection Time: 2.40233
Timestep Consumption Time: 2.49432
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.89666

Cumulative Model Updates: 98,486
Cumulative Timesteps: 821,450,400

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,027.44633
Policy Entropy: 1.85550
Value Function Loss: 0.07257

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.58811
Value Function Update Magnitude: 0.73933

Collected Steps per Second: 21,904.14940
Overall Steps per Second: 10,422.86120

Timestep Collection Time: 2.28368
Timestep Consumption Time: 2.51558
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.79926

Cumulative Model Updates: 98,492
Cumulative Timesteps: 821,500,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 821500422...
Checkpoint 821500422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,617.84437
Policy Entropy: 1.85108
Value Function Loss: 0.07281

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14371
Policy Update Magnitude: 0.59177
Value Function Update Magnitude: 0.74567

Collected Steps per Second: 21,401.65662
Overall Steps per Second: 10,229.99282

Timestep Collection Time: 2.33730
Timestep Consumption Time: 2.55244
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.88974

Cumulative Model Updates: 98,498
Cumulative Timesteps: 821,550,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,832.89012
Policy Entropy: 1.85388
Value Function Loss: 0.06716

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.14682
Policy Update Magnitude: 0.57681
Value Function Update Magnitude: 0.74700

Collected Steps per Second: 22,342.71159
Overall Steps per Second: 10,464.33477

Timestep Collection Time: 2.23822
Timestep Consumption Time: 2.54067
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.77890

Cumulative Model Updates: 98,504
Cumulative Timesteps: 821,600,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 821600452...
Checkpoint 821600452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,861.09295
Policy Entropy: 1.84784
Value Function Loss: 0.07164

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.57513
Value Function Update Magnitude: 0.69802

Collected Steps per Second: 21,635.72930
Overall Steps per Second: 10,276.88885

Timestep Collection Time: 2.31210
Timestep Consumption Time: 2.55552
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.86762

Cumulative Model Updates: 98,510
Cumulative Timesteps: 821,650,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,720.25057
Policy Entropy: 1.85159
Value Function Loss: 0.07200

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.58894
Value Function Update Magnitude: 0.69756

Collected Steps per Second: 22,284.85513
Overall Steps per Second: 10,443.18054

Timestep Collection Time: 2.24493
Timestep Consumption Time: 2.54556
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.79049

Cumulative Model Updates: 98,516
Cumulative Timesteps: 821,700,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 821700504...
Checkpoint 821700504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,278.03289
Policy Entropy: 1.84521
Value Function Loss: 0.07303

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.59627
Value Function Update Magnitude: 0.64362

Collected Steps per Second: 21,803.63507
Overall Steps per Second: 10,537.30742

Timestep Collection Time: 2.29320
Timestep Consumption Time: 2.45185
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.74505

Cumulative Model Updates: 98,522
Cumulative Timesteps: 821,750,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,636.22357
Policy Entropy: 1.84094
Value Function Loss: 0.08002

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.60017
Value Function Update Magnitude: 0.58626

Collected Steps per Second: 22,238.68182
Overall Steps per Second: 10,499.04273

Timestep Collection Time: 2.24887
Timestep Consumption Time: 2.51461
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.76348

Cumulative Model Updates: 98,528
Cumulative Timesteps: 821,800,516

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 821800516...
Checkpoint 821800516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,860.02090
Policy Entropy: 1.83502
Value Function Loss: 0.08155

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.60314
Value Function Update Magnitude: 0.66905

Collected Steps per Second: 21,528.12230
Overall Steps per Second: 10,299.35596

Timestep Collection Time: 2.32384
Timestep Consumption Time: 2.53355
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.85739

Cumulative Model Updates: 98,534
Cumulative Timesteps: 821,850,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,074.99887
Policy Entropy: 1.84914
Value Function Loss: 0.08218

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.14896
Policy Update Magnitude: 0.58555
Value Function Update Magnitude: 0.75105

Collected Steps per Second: 22,288.07448
Overall Steps per Second: 10,523.21678

Timestep Collection Time: 2.24425
Timestep Consumption Time: 2.50905
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.75330

Cumulative Model Updates: 98,540
Cumulative Timesteps: 821,900,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 821900564...
Checkpoint 821900564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,720.41716
Policy Entropy: 1.85929
Value Function Loss: 0.08161

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.16106
Policy Update Magnitude: 0.51883
Value Function Update Magnitude: 0.73965

Collected Steps per Second: 21,861.88253
Overall Steps per Second: 10,593.71518

Timestep Collection Time: 2.28736
Timestep Consumption Time: 2.43299
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.72035

Cumulative Model Updates: 98,546
Cumulative Timesteps: 821,950,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,211.71639
Policy Entropy: 1.84754
Value Function Loss: 0.07794

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.13558
Policy Update Magnitude: 0.52827
Value Function Update Magnitude: 0.74811

Collected Steps per Second: 21,553.86819
Overall Steps per Second: 10,342.02614

Timestep Collection Time: 2.32098
Timestep Consumption Time: 2.51618
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.83716

Cumulative Model Updates: 98,552
Cumulative Timesteps: 822,000,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 822000596...
Checkpoint 822000596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,027.98613
Policy Entropy: 1.84964
Value Function Loss: 0.07462

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.57272
Value Function Update Magnitude: 0.70844

Collected Steps per Second: 21,147.32707
Overall Steps per Second: 10,238.03576

Timestep Collection Time: 2.36474
Timestep Consumption Time: 2.51979
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.88453

Cumulative Model Updates: 98,558
Cumulative Timesteps: 822,050,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,092.05752
Policy Entropy: 1.84576
Value Function Loss: 0.07813

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.15439
Policy Update Magnitude: 0.56650
Value Function Update Magnitude: 0.56821

Collected Steps per Second: 21,569.15285
Overall Steps per Second: 10,471.93288

Timestep Collection Time: 2.31905
Timestep Consumption Time: 2.45752
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.77658

Cumulative Model Updates: 98,564
Cumulative Timesteps: 822,100,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 822100624...
Checkpoint 822100624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,564.68556
Policy Entropy: 1.86019
Value Function Loss: 0.08489

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.16484
Policy Update Magnitude: 0.52917
Value Function Update Magnitude: 0.48884

Collected Steps per Second: 21,462.88870
Overall Steps per Second: 10,321.51956

Timestep Collection Time: 2.33100
Timestep Consumption Time: 2.51615
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.84715

Cumulative Model Updates: 98,570
Cumulative Timesteps: 822,150,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,550.75848
Policy Entropy: 1.86655
Value Function Loss: 0.09043

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.16507
Policy Update Magnitude: 0.49784
Value Function Update Magnitude: 0.44905

Collected Steps per Second: 21,565.65091
Overall Steps per Second: 10,332.44059

Timestep Collection Time: 2.31971
Timestep Consumption Time: 2.52194
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.84164

Cumulative Model Updates: 98,576
Cumulative Timesteps: 822,200,680

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 822200680...
Checkpoint 822200680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,556.86245
Policy Entropy: 1.85796
Value Function Loss: 0.08628

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.15258
Policy Update Magnitude: 0.53684
Value Function Update Magnitude: 0.50477

Collected Steps per Second: 21,807.10589
Overall Steps per Second: 10,301.19018

Timestep Collection Time: 2.29411
Timestep Consumption Time: 2.56241
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.85653

Cumulative Model Updates: 98,582
Cumulative Timesteps: 822,250,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,100.97155
Policy Entropy: 1.85536
Value Function Loss: 0.08324

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.17175
Policy Update Magnitude: 0.54508
Value Function Update Magnitude: 0.46130

Collected Steps per Second: 22,136.21857
Overall Steps per Second: 10,425.55520

Timestep Collection Time: 2.25910
Timestep Consumption Time: 2.53757
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.79667

Cumulative Model Updates: 98,588
Cumulative Timesteps: 822,300,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 822300716...
Checkpoint 822300716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,050.82977
Policy Entropy: 1.84380
Value Function Loss: 0.08034

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.17178
Policy Update Magnitude: 0.52765
Value Function Update Magnitude: 0.43547

Collected Steps per Second: 21,541.96589
Overall Steps per Second: 10,464.15565

Timestep Collection Time: 2.32142
Timestep Consumption Time: 2.45756
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.77898

Cumulative Model Updates: 98,594
Cumulative Timesteps: 822,350,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,916.62930
Policy Entropy: 1.86482
Value Function Loss: 0.08353

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.15809
Policy Update Magnitude: 0.57051
Value Function Update Magnitude: 0.42976

Collected Steps per Second: 22,073.41601
Overall Steps per Second: 10,593.86697

Timestep Collection Time: 2.26517
Timestep Consumption Time: 2.45454
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.71971

Cumulative Model Updates: 98,600
Cumulative Timesteps: 822,400,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 822400724...
Checkpoint 822400724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,484.62426
Policy Entropy: 1.85486
Value Function Loss: 0.08466

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.15980
Policy Update Magnitude: 0.57553
Value Function Update Magnitude: 0.46831

Collected Steps per Second: 21,774.17993
Overall Steps per Second: 10,507.95096

Timestep Collection Time: 2.29712
Timestep Consumption Time: 2.46289
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.76001

Cumulative Model Updates: 98,606
Cumulative Timesteps: 822,450,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,373.44584
Policy Entropy: 1.85878
Value Function Loss: 0.08191

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.17820
Policy Update Magnitude: 0.53000
Value Function Update Magnitude: 0.57534

Collected Steps per Second: 21,905.75802
Overall Steps per Second: 10,523.66227

Timestep Collection Time: 2.28269
Timestep Consumption Time: 2.46889
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.75158

Cumulative Model Updates: 98,612
Cumulative Timesteps: 822,500,746

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 822500746...
Checkpoint 822500746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,954.83755
Policy Entropy: 1.84503
Value Function Loss: 0.08272

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.17044
Policy Update Magnitude: 0.47927
Value Function Update Magnitude: 0.59041

Collected Steps per Second: 21,486.92216
Overall Steps per Second: 10,316.30325

Timestep Collection Time: 2.32811
Timestep Consumption Time: 2.52091
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.84902

Cumulative Model Updates: 98,618
Cumulative Timesteps: 822,550,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,690.20947
Policy Entropy: 1.85294
Value Function Loss: 0.07698

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.14982
Policy Update Magnitude: 0.47819
Value Function Update Magnitude: 0.63358

Collected Steps per Second: 22,256.62563
Overall Steps per Second: 10,450.00105

Timestep Collection Time: 2.24661
Timestep Consumption Time: 2.53827
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.78488

Cumulative Model Updates: 98,624
Cumulative Timesteps: 822,600,772

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 822600772...
Checkpoint 822600772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,643.34145
Policy Entropy: 1.85227
Value Function Loss: 0.08152

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.48605
Value Function Update Magnitude: 0.59667

Collected Steps per Second: 20,815.71191
Overall Steps per Second: 10,346.46831

Timestep Collection Time: 2.40309
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.83469

Cumulative Model Updates: 98,630
Cumulative Timesteps: 822,650,794

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,619.62777
Policy Entropy: 1.85851
Value Function Loss: 0.08102

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.15701
Policy Update Magnitude: 0.50666
Value Function Update Magnitude: 0.67868

Collected Steps per Second: 20,604.74765
Overall Steps per Second: 10,298.10550

Timestep Collection Time: 2.42692
Timestep Consumption Time: 2.42893
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.85584

Cumulative Model Updates: 98,636
Cumulative Timesteps: 822,700,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 822700800...
Checkpoint 822700800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,690.09931
Policy Entropy: 1.87685
Value Function Loss: 0.08694

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.16003
Policy Update Magnitude: 0.52963
Value Function Update Magnitude: 0.71861

Collected Steps per Second: 20,119.81058
Overall Steps per Second: 10,208.97664

Timestep Collection Time: 2.48601
Timestep Consumption Time: 2.41341
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.89941

Cumulative Model Updates: 98,642
Cumulative Timesteps: 822,750,818

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,943.65672
Policy Entropy: 1.87697
Value Function Loss: 0.08561

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.57598
Value Function Update Magnitude: 0.76858

Collected Steps per Second: 21,005.56183
Overall Steps per Second: 10,479.29244

Timestep Collection Time: 2.38213
Timestep Consumption Time: 2.39281
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.77494

Cumulative Model Updates: 98,648
Cumulative Timesteps: 822,800,856

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 822800856...
Checkpoint 822800856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,959.90335
Policy Entropy: 1.87641
Value Function Loss: 0.08294

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14826
Policy Update Magnitude: 0.60927
Value Function Update Magnitude: 0.82672

Collected Steps per Second: 20,263.42041
Overall Steps per Second: 10,149.91564

Timestep Collection Time: 2.46790
Timestep Consumption Time: 2.45904
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.92694

Cumulative Model Updates: 98,654
Cumulative Timesteps: 822,850,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,406.14330
Policy Entropy: 1.88051
Value Function Loss: 0.08008

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.14961
Policy Update Magnitude: 0.60772
Value Function Update Magnitude: 0.80565

Collected Steps per Second: 20,986.02421
Overall Steps per Second: 10,470.30294

Timestep Collection Time: 2.38301
Timestep Consumption Time: 2.39335
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.77637

Cumulative Model Updates: 98,660
Cumulative Timesteps: 822,900,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 822900874...
Checkpoint 822900874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,352.46977
Policy Entropy: 1.87753
Value Function Loss: 0.08126

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14715
Policy Update Magnitude: 0.61415
Value Function Update Magnitude: 0.75206

Collected Steps per Second: 21,099.17672
Overall Steps per Second: 10,317.10074

Timestep Collection Time: 2.36986
Timestep Consumption Time: 2.47666
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.84652

Cumulative Model Updates: 98,666
Cumulative Timesteps: 822,950,876

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,248.05650
Policy Entropy: 1.88220
Value Function Loss: 0.08606

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.15012
Policy Update Magnitude: 0.61608
Value Function Update Magnitude: 0.76449

Collected Steps per Second: 21,761.93417
Overall Steps per Second: 10,383.76682

Timestep Collection Time: 2.29777
Timestep Consumption Time: 2.51782
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.81559

Cumulative Model Updates: 98,672
Cumulative Timesteps: 823,000,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 823000880...
Checkpoint 823000880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,273.57838
Policy Entropy: 1.87535
Value Function Loss: 0.08805

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.16221
Policy Update Magnitude: 0.56562
Value Function Update Magnitude: 0.64902

Collected Steps per Second: 21,486.25827
Overall Steps per Second: 10,514.77393

Timestep Collection Time: 2.32837
Timestep Consumption Time: 2.42951
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.75788

Cumulative Model Updates: 98,678
Cumulative Timesteps: 823,050,908

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,670.12022
Policy Entropy: 1.88138
Value Function Loss: 0.08571

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.17028
Policy Update Magnitude: 0.51036
Value Function Update Magnitude: 0.63646

Collected Steps per Second: 22,208.37688
Overall Steps per Second: 10,528.27960

Timestep Collection Time: 2.25266
Timestep Consumption Time: 2.49911
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.75177

Cumulative Model Updates: 98,684
Cumulative Timesteps: 823,100,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 823100936...
Checkpoint 823100936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,776.09788
Policy Entropy: 1.88859
Value Function Loss: 0.07786

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.16352
Policy Update Magnitude: 0.47430
Value Function Update Magnitude: 0.62979

Collected Steps per Second: 21,991.06723
Overall Steps per Second: 10,643.44502

Timestep Collection Time: 2.27374
Timestep Consumption Time: 2.42417
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.69792

Cumulative Model Updates: 98,690
Cumulative Timesteps: 823,150,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,796.10556
Policy Entropy: 1.86820
Value Function Loss: 0.07422

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.15318
Policy Update Magnitude: 0.48480
Value Function Update Magnitude: 0.59509

Collected Steps per Second: 22,240.88304
Overall Steps per Second: 10,423.71169

Timestep Collection Time: 2.24856
Timestep Consumption Time: 2.54915
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.79772

Cumulative Model Updates: 98,696
Cumulative Timesteps: 823,200,948

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 823200948...
Checkpoint 823200948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,392.83582
Policy Entropy: 1.87562
Value Function Loss: 0.07603

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.14533
Policy Update Magnitude: 0.50141
Value Function Update Magnitude: 0.66951

Collected Steps per Second: 21,404.60934
Overall Steps per Second: 10,274.03542

Timestep Collection Time: 2.33679
Timestep Consumption Time: 2.53160
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.86839

Cumulative Model Updates: 98,702
Cumulative Timesteps: 823,250,966

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,147.79378
Policy Entropy: 1.88058
Value Function Loss: 0.07511

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.15175
Policy Update Magnitude: 0.51014
Value Function Update Magnitude: 0.69674

Collected Steps per Second: 22,084.17833
Overall Steps per Second: 10,439.69607

Timestep Collection Time: 2.26506
Timestep Consumption Time: 2.52646
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.79152

Cumulative Model Updates: 98,708
Cumulative Timesteps: 823,300,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 823300988...
Checkpoint 823300988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,178.16909
Policy Entropy: 1.88185
Value Function Loss: 0.07733

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.16192
Policy Update Magnitude: 0.49232
Value Function Update Magnitude: 0.68527

Collected Steps per Second: 20,886.26778
Overall Steps per Second: 10,199.50025

Timestep Collection Time: 2.39526
Timestep Consumption Time: 2.50969
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.90495

Cumulative Model Updates: 98,714
Cumulative Timesteps: 823,351,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,431.05646
Policy Entropy: 1.89834
Value Function Loss: 0.08375

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.14362
Policy Update Magnitude: 0.56031
Value Function Update Magnitude: 0.71250

Collected Steps per Second: 21,498.25002
Overall Steps per Second: 10,432.82516

Timestep Collection Time: 2.32577
Timestep Consumption Time: 2.46679
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.79257

Cumulative Model Updates: 98,720
Cumulative Timesteps: 823,401,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 823401016...
Checkpoint 823401016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,185.57212
Policy Entropy: 1.90199
Value Function Loss: 0.08867

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.14802
Policy Update Magnitude: 0.61210
Value Function Update Magnitude: 0.73122

Collected Steps per Second: 21,064.50486
Overall Steps per Second: 10,226.30109

Timestep Collection Time: 2.37366
Timestep Consumption Time: 2.51569
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.88935

Cumulative Model Updates: 98,726
Cumulative Timesteps: 823,451,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,892.62756
Policy Entropy: 1.91978
Value Function Loss: 0.09121

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.62159
Value Function Update Magnitude: 0.69943

Collected Steps per Second: 22,250.05221
Overall Steps per Second: 10,430.45407

Timestep Collection Time: 2.24746
Timestep Consumption Time: 2.54678
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.79423

Cumulative Model Updates: 98,732
Cumulative Timesteps: 823,501,022

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 823501022...
Checkpoint 823501022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,828.23949
Policy Entropy: 1.90252
Value Function Loss: 0.09409

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.62652
Value Function Update Magnitude: 0.65293

Collected Steps per Second: 21,821.69438
Overall Steps per Second: 10,340.25488

Timestep Collection Time: 2.29203
Timestep Consumption Time: 2.54499
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.83702

Cumulative Model Updates: 98,738
Cumulative Timesteps: 823,551,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,645.57092
Policy Entropy: 1.89945
Value Function Loss: 0.09137

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.15578
Policy Update Magnitude: 0.61991
Value Function Update Magnitude: 0.68873

Collected Steps per Second: 22,332.51308
Overall Steps per Second: 10,506.90522

Timestep Collection Time: 2.23889
Timestep Consumption Time: 2.51989
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.75878

Cumulative Model Updates: 98,744
Cumulative Timesteps: 823,601,038

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 823601038...
Checkpoint 823601038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,491.42663
Policy Entropy: 1.88600
Value Function Loss: 0.08616

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.15626
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.70824

Collected Steps per Second: 21,697.46279
Overall Steps per Second: 10,512.22103

Timestep Collection Time: 2.30562
Timestep Consumption Time: 2.45323
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.75884

Cumulative Model Updates: 98,750
Cumulative Timesteps: 823,651,064

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,986.55993
Policy Entropy: 1.89048
Value Function Loss: 0.07754

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.16600
Policy Update Magnitude: 0.55106
Value Function Update Magnitude: 0.64569

Collected Steps per Second: 22,175.40393
Overall Steps per Second: 10,443.47968

Timestep Collection Time: 2.25619
Timestep Consumption Time: 2.53455
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.79074

Cumulative Model Updates: 98,756
Cumulative Timesteps: 823,701,096

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 823701096...
Checkpoint 823701096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,760.17448
Policy Entropy: 1.89357
Value Function Loss: 0.08031

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.15975
Policy Update Magnitude: 0.58726
Value Function Update Magnitude: 0.65343

Collected Steps per Second: 21,706.30586
Overall Steps per Second: 10,554.47827

Timestep Collection Time: 2.30468
Timestep Consumption Time: 2.43511
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.73979

Cumulative Model Updates: 98,762
Cumulative Timesteps: 823,751,122

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,333.14909
Policy Entropy: 1.88950
Value Function Loss: 0.08214

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.16879
Policy Update Magnitude: 0.58296
Value Function Update Magnitude: 0.68306

Collected Steps per Second: 21,982.02142
Overall Steps per Second: 10,494.20861

Timestep Collection Time: 2.27504
Timestep Consumption Time: 2.49044
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.76549

Cumulative Model Updates: 98,768
Cumulative Timesteps: 823,801,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 823801132...
Checkpoint 823801132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,877.91043
Policy Entropy: 1.88121
Value Function Loss: 0.08015

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.16619
Policy Update Magnitude: 0.52455
Value Function Update Magnitude: 0.71038

Collected Steps per Second: 21,120.56718
Overall Steps per Second: 10,243.02301

Timestep Collection Time: 2.36850
Timestep Consumption Time: 2.51522
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.88371

Cumulative Model Updates: 98,774
Cumulative Timesteps: 823,851,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,366.82629
Policy Entropy: 1.88261
Value Function Loss: 0.07800

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.16137
Policy Update Magnitude: 0.50670
Value Function Update Magnitude: 0.71483

Collected Steps per Second: 21,808.82134
Overall Steps per Second: 10,466.86439

Timestep Collection Time: 2.29320
Timestep Consumption Time: 2.48493
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.77813

Cumulative Model Updates: 98,780
Cumulative Timesteps: 823,901,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 823901168...
Checkpoint 823901168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,916.96848
Policy Entropy: 1.89247
Value Function Loss: 0.07597

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.15592
Policy Update Magnitude: 0.50219
Value Function Update Magnitude: 0.73300

Collected Steps per Second: 21,082.32109
Overall Steps per Second: 10,190.53281

Timestep Collection Time: 2.37213
Timestep Consumption Time: 2.53537
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.90750

Cumulative Model Updates: 98,786
Cumulative Timesteps: 823,951,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,830.76593
Policy Entropy: 1.90215
Value Function Loss: 0.08050

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14618
Policy Update Magnitude: 0.54749
Value Function Update Magnitude: 0.75628

Collected Steps per Second: 21,575.56955
Overall Steps per Second: 10,447.39933

Timestep Collection Time: 2.31836
Timestep Consumption Time: 2.46943
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.78779

Cumulative Model Updates: 98,792
Cumulative Timesteps: 824,001,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 824001198...
Checkpoint 824001198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,312.64419
Policy Entropy: 1.89661
Value Function Loss: 0.08082

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.15046
Policy Update Magnitude: 0.58775
Value Function Update Magnitude: 0.74441

Collected Steps per Second: 21,108.99853
Overall Steps per Second: 10,233.59430

Timestep Collection Time: 2.36951
Timestep Consumption Time: 2.51812
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.88763

Cumulative Model Updates: 98,798
Cumulative Timesteps: 824,051,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,577.63483
Policy Entropy: 1.90585
Value Function Loss: 0.08448

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.16424
Policy Update Magnitude: 0.54418
Value Function Update Magnitude: 0.69124

Collected Steps per Second: 21,758.05502
Overall Steps per Second: 10,535.72702

Timestep Collection Time: 2.29929
Timestep Consumption Time: 2.44913
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.74841

Cumulative Model Updates: 98,804
Cumulative Timesteps: 824,101,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 824101244...
Checkpoint 824101244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,073.88711
Policy Entropy: 1.90863
Value Function Loss: 0.08143

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14949
Policy Update Magnitude: 0.55643
Value Function Update Magnitude: 0.73483

Collected Steps per Second: 20,906.45628
Overall Steps per Second: 10,137.30431

Timestep Collection Time: 2.39161
Timestep Consumption Time: 2.54067
PPO Batch Consumption Time: 0.29621
Total Iteration Time: 4.93228

Cumulative Model Updates: 98,810
Cumulative Timesteps: 824,151,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,712.38821
Policy Entropy: 1.91267
Value Function Loss: 0.08119

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.15487
Policy Update Magnitude: 0.59352
Value Function Update Magnitude: 0.71675

Collected Steps per Second: 21,420.99849
Overall Steps per Second: 10,412.97932

Timestep Collection Time: 2.33425
Timestep Consumption Time: 2.46764
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.80189

Cumulative Model Updates: 98,816
Cumulative Timesteps: 824,201,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 824201246...
Checkpoint 824201246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,012.12369
Policy Entropy: 1.90263
Value Function Loss: 0.08449

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.14534
Policy Update Magnitude: 0.61021
Value Function Update Magnitude: 0.72363

Collected Steps per Second: 20,928.05416
Overall Steps per Second: 10,194.09952

Timestep Collection Time: 2.39038
Timestep Consumption Time: 2.51697
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.90735

Cumulative Model Updates: 98,822
Cumulative Timesteps: 824,251,272

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,232.46733
Policy Entropy: 1.90373
Value Function Loss: 0.09184

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.14466
Policy Update Magnitude: 0.61614
Value Function Update Magnitude: 0.66802

Collected Steps per Second: 21,987.91249
Overall Steps per Second: 10,496.98033

Timestep Collection Time: 2.27480
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.76499

Cumulative Model Updates: 98,828
Cumulative Timesteps: 824,301,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 824301290...
Checkpoint 824301290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,655.90576
Policy Entropy: 1.91200
Value Function Loss: 0.09167

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.14192
Policy Update Magnitude: 0.61508
Value Function Update Magnitude: 0.67929

Collected Steps per Second: 22,001.06500
Overall Steps per Second: 10,369.81327

Timestep Collection Time: 2.27344
Timestep Consumption Time: 2.54999
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.82342

Cumulative Model Updates: 98,834
Cumulative Timesteps: 824,351,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,106.56188
Policy Entropy: 1.91293
Value Function Loss: 0.08270

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.15349
Policy Update Magnitude: 0.59332
Value Function Update Magnitude: 0.75009

Collected Steps per Second: 22,194.48503
Overall Steps per Second: 10,419.11277

Timestep Collection Time: 2.25281
Timestep Consumption Time: 2.54606
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.79887

Cumulative Model Updates: 98,840
Cumulative Timesteps: 824,401,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 824401308...
Checkpoint 824401308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,672.59051
Policy Entropy: 1.90920
Value Function Loss: 0.07826

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.16657
Policy Update Magnitude: 0.52350
Value Function Update Magnitude: 0.74065

Collected Steps per Second: 22,051.34757
Overall Steps per Second: 10,461.95017

Timestep Collection Time: 2.26825
Timestep Consumption Time: 2.51269
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.78094

Cumulative Model Updates: 98,846
Cumulative Timesteps: 824,451,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,820.33342
Policy Entropy: 1.88351
Value Function Loss: 0.07944

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.17200
Policy Update Magnitude: 0.52240
Value Function Update Magnitude: 0.64471

Collected Steps per Second: 22,274.18741
Overall Steps per Second: 10,528.38778

Timestep Collection Time: 2.24475
Timestep Consumption Time: 2.50431
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.74907

Cumulative Model Updates: 98,852
Cumulative Timesteps: 824,501,326

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 824501326...
Checkpoint 824501326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,204.99002
Policy Entropy: 1.89071
Value Function Loss: 0.08309

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.16256
Policy Update Magnitude: 0.55253
Value Function Update Magnitude: 0.58491

Collected Steps per Second: 21,916.23529
Overall Steps per Second: 10,565.81839

Timestep Collection Time: 2.28315
Timestep Consumption Time: 2.45269
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.73584

Cumulative Model Updates: 98,858
Cumulative Timesteps: 824,551,364

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,545.10914
Policy Entropy: 1.90748
Value Function Loss: 0.08419

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.16449
Policy Update Magnitude: 0.59184
Value Function Update Magnitude: 0.64920

Collected Steps per Second: 22,228.74566
Overall Steps per Second: 10,512.76069

Timestep Collection Time: 2.25069
Timestep Consumption Time: 2.50829
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.75898

Cumulative Model Updates: 98,864
Cumulative Timesteps: 824,601,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 824601394...
Checkpoint 824601394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,612.60983
Policy Entropy: 1.90964
Value Function Loss: 0.08200

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.16283
Policy Update Magnitude: 0.60671
Value Function Update Magnitude: 0.68265

Collected Steps per Second: 21,310.40729
Overall Steps per Second: 10,277.01551

Timestep Collection Time: 2.34730
Timestep Consumption Time: 2.52006
PPO Batch Consumption Time: 0.29866
Total Iteration Time: 4.86737

Cumulative Model Updates: 98,870
Cumulative Timesteps: 824,651,416

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,331.73867
Policy Entropy: 1.90720
Value Function Loss: 0.08057

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.15571
Policy Update Magnitude: 0.59828
Value Function Update Magnitude: 0.66096

Collected Steps per Second: 22,322.30311
Overall Steps per Second: 10,528.11690

Timestep Collection Time: 2.24099
Timestep Consumption Time: 2.51048
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.75147

Cumulative Model Updates: 98,876
Cumulative Timesteps: 824,701,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 824701440...
Checkpoint 824701440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,070.06548
Policy Entropy: 1.89928
Value Function Loss: 0.07910

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.58587
Value Function Update Magnitude: 0.62787

Collected Steps per Second: 21,723.93502
Overall Steps per Second: 10,556.30758

Timestep Collection Time: 2.30290
Timestep Consumption Time: 2.43626
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.73916

Cumulative Model Updates: 98,882
Cumulative Timesteps: 824,751,468

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,646.76865
Policy Entropy: 1.91742
Value Function Loss: 0.07868

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.14372
Policy Update Magnitude: 0.59446
Value Function Update Magnitude: 0.56237

Collected Steps per Second: 22,035.10826
Overall Steps per Second: 10,434.77811

Timestep Collection Time: 2.27029
Timestep Consumption Time: 2.52387
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.79416

Cumulative Model Updates: 98,888
Cumulative Timesteps: 824,801,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 824801494...
Checkpoint 824801494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,114.19109
Policy Entropy: 1.91474
Value Function Loss: 0.07835

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.59274
Value Function Update Magnitude: 0.44417

Collected Steps per Second: 21,267.96695
Overall Steps per Second: 10,222.84181

Timestep Collection Time: 2.35283
Timestep Consumption Time: 2.54209
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.89492

Cumulative Model Updates: 98,894
Cumulative Timesteps: 824,851,534

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,302.28624
Policy Entropy: 1.91327
Value Function Loss: 0.07687

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.58437
Value Function Update Magnitude: 0.40841

Collected Steps per Second: 21,764.27041
Overall Steps per Second: 10,534.48396

Timestep Collection Time: 2.29826
Timestep Consumption Time: 2.44995
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.74822

Cumulative Model Updates: 98,900
Cumulative Timesteps: 824,901,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 824901554...
Checkpoint 824901554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,741.46600
Policy Entropy: 1.90450
Value Function Loss: 0.07995

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.57612
Value Function Update Magnitude: 0.51873

Collected Steps per Second: 21,646.79290
Overall Steps per Second: 10,452.90007

Timestep Collection Time: 2.31083
Timestep Consumption Time: 2.47464
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.78547

Cumulative Model Updates: 98,906
Cumulative Timesteps: 824,951,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,500.57252
Policy Entropy: 1.90743
Value Function Loss: 0.08302

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.59054
Value Function Update Magnitude: 0.66397

Collected Steps per Second: 22,023.85805
Overall Steps per Second: 10,456.44846

Timestep Collection Time: 2.27054
Timestep Consumption Time: 2.51177
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.78231

Cumulative Model Updates: 98,912
Cumulative Timesteps: 825,001,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 825001582...
Checkpoint 825001582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,292.40269
Policy Entropy: 1.89955
Value Function Loss: 0.08289

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14575
Policy Update Magnitude: 0.60113
Value Function Update Magnitude: 0.71499

Collected Steps per Second: 21,952.20961
Overall Steps per Second: 10,400.40369

Timestep Collection Time: 2.27840
Timestep Consumption Time: 2.53064
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.80904

Cumulative Model Updates: 98,918
Cumulative Timesteps: 825,051,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,360.38039
Policy Entropy: 1.89473
Value Function Loss: 0.08018

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.60248
Value Function Update Magnitude: 0.71901

Collected Steps per Second: 22,673.33058
Overall Steps per Second: 10,733.71454

Timestep Collection Time: 2.20691
Timestep Consumption Time: 2.45485
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.66176

Cumulative Model Updates: 98,924
Cumulative Timesteps: 825,101,636

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 825101636...
Checkpoint 825101636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,212.71129
Policy Entropy: 1.89255
Value Function Loss: 0.08285

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.60170
Value Function Update Magnitude: 0.70238

Collected Steps per Second: 21,666.27620
Overall Steps per Second: 10,345.06228

Timestep Collection Time: 2.30875
Timestep Consumption Time: 2.52660
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.83535

Cumulative Model Updates: 98,930
Cumulative Timesteps: 825,151,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,240.01836
Policy Entropy: 1.88200
Value Function Loss: 0.07896

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13712
Policy Update Magnitude: 0.59896
Value Function Update Magnitude: 0.66071

Collected Steps per Second: 22,312.39621
Overall Steps per Second: 10,505.51941

Timestep Collection Time: 2.24144
Timestep Consumption Time: 2.51910
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.76055

Cumulative Model Updates: 98,936
Cumulative Timesteps: 825,201,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 825201670...
Checkpoint 825201670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,673.08812
Policy Entropy: 1.85886
Value Function Loss: 0.08322

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.14472
Policy Update Magnitude: 0.60035
Value Function Update Magnitude: 0.62606

Collected Steps per Second: 22,152.91572
Overall Steps per Second: 10,509.69366

Timestep Collection Time: 2.25722
Timestep Consumption Time: 2.50067
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.75789

Cumulative Model Updates: 98,942
Cumulative Timesteps: 825,251,674

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,060.51518
Policy Entropy: 1.86956
Value Function Loss: 0.08208

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.15427
Policy Update Magnitude: 0.57806
Value Function Update Magnitude: 0.70876

Collected Steps per Second: 21,781.59265
Overall Steps per Second: 10,427.73652

Timestep Collection Time: 2.29616
Timestep Consumption Time: 2.50009
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.79625

Cumulative Model Updates: 98,948
Cumulative Timesteps: 825,301,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 825301688...
Checkpoint 825301688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,635.63874
Policy Entropy: 1.86584
Value Function Loss: 0.08641

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.16055
Policy Update Magnitude: 0.51653
Value Function Update Magnitude: 0.62908

Collected Steps per Second: 21,355.22009
Overall Steps per Second: 10,265.95457

Timestep Collection Time: 2.34341
Timestep Consumption Time: 2.53135
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.87475

Cumulative Model Updates: 98,954
Cumulative Timesteps: 825,351,732

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,962.96899
Policy Entropy: 1.88458
Value Function Loss: 0.08234

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.15917
Policy Update Magnitude: 0.50381
Value Function Update Magnitude: 0.63294

Collected Steps per Second: 21,591.18056
Overall Steps per Second: 10,502.36016

Timestep Collection Time: 2.31650
Timestep Consumption Time: 2.44586
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.76236

Cumulative Model Updates: 98,960
Cumulative Timesteps: 825,401,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 825401748...
Checkpoint 825401748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,287.61755
Policy Entropy: 1.87837
Value Function Loss: 0.08405

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.15800
Policy Update Magnitude: 0.51050
Value Function Update Magnitude: 0.69283

Collected Steps per Second: 21,260.85870
Overall Steps per Second: 10,342.21127

Timestep Collection Time: 2.35249
Timestep Consumption Time: 2.48361
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.83610

Cumulative Model Updates: 98,966
Cumulative Timesteps: 825,451,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,198.54072
Policy Entropy: 1.87976
Value Function Loss: 0.08320

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.54726
Value Function Update Magnitude: 0.68054

Collected Steps per Second: 21,997.42243
Overall Steps per Second: 10,429.99126

Timestep Collection Time: 2.27354
Timestep Consumption Time: 2.52148
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.79502

Cumulative Model Updates: 98,972
Cumulative Timesteps: 825,501,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 825501776...
Checkpoint 825501776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,941.49435
Policy Entropy: 1.88002
Value Function Loss: 0.08335

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.59819
Value Function Update Magnitude: 0.60143

Collected Steps per Second: 21,703.30548
Overall Steps per Second: 10,429.24451

Timestep Collection Time: 2.30444
Timestep Consumption Time: 2.49111
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.79555

Cumulative Model Updates: 98,978
Cumulative Timesteps: 825,551,790

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,595.21080
Policy Entropy: 1.87625
Value Function Loss: 0.08053

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.59066
Value Function Update Magnitude: 0.50298

Collected Steps per Second: 21,927.67200
Overall Steps per Second: 10,541.54584

Timestep Collection Time: 2.28104
Timestep Consumption Time: 2.46380
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.74484

Cumulative Model Updates: 98,984
Cumulative Timesteps: 825,601,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 825601808...
Checkpoint 825601808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,637.24007
Policy Entropy: 1.85802
Value Function Loss: 0.07806

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13434
Policy Update Magnitude: 0.57187
Value Function Update Magnitude: 0.44809

Collected Steps per Second: 21,903.47043
Overall Steps per Second: 10,504.85836

Timestep Collection Time: 2.28384
Timestep Consumption Time: 2.47815
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.76199

Cumulative Model Updates: 98,990
Cumulative Timesteps: 825,651,832

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,006.05858
Policy Entropy: 1.85726
Value Function Loss: 0.07592

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.57967
Value Function Update Magnitude: 0.45821

Collected Steps per Second: 22,306.76346
Overall Steps per Second: 10,545.34861

Timestep Collection Time: 2.24156
Timestep Consumption Time: 2.50005
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.74162

Cumulative Model Updates: 98,996
Cumulative Timesteps: 825,701,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 825701834...
Checkpoint 825701834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,190.18701
Policy Entropy: 1.86850
Value Function Loss: 0.08097

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.58533
Value Function Update Magnitude: 0.39172

Collected Steps per Second: 21,995.07275
Overall Steps per Second: 10,659.76891

Timestep Collection Time: 2.27324
Timestep Consumption Time: 2.41730
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.69053

Cumulative Model Updates: 99,002
Cumulative Timesteps: 825,751,834

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,963.21807
Policy Entropy: 1.88590
Value Function Loss: 0.08726

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.58644
Value Function Update Magnitude: 0.30630

Collected Steps per Second: 22,429.04384
Overall Steps per Second: 10,479.83919

Timestep Collection Time: 2.23077
Timestep Consumption Time: 2.54354
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.77431

Cumulative Model Updates: 99,008
Cumulative Timesteps: 825,801,868

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 825801868...
Checkpoint 825801868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,988.59776
Policy Entropy: 1.87427
Value Function Loss: 0.08777

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.15578
Policy Update Magnitude: 0.53483
Value Function Update Magnitude: 0.27906

Collected Steps per Second: 22,116.96286
Overall Steps per Second: 10,627.45311

Timestep Collection Time: 2.26188
Timestep Consumption Time: 2.44536
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.70724

Cumulative Model Updates: 99,014
Cumulative Timesteps: 825,851,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,757.51733
Policy Entropy: 1.85367
Value Function Loss: 0.08829

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.15904
Policy Update Magnitude: 0.50896
Value Function Update Magnitude: 0.33478

Collected Steps per Second: 21,423.89670
Overall Steps per Second: 10,404.71980

Timestep Collection Time: 2.33459
Timestep Consumption Time: 2.47246
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.80705

Cumulative Model Updates: 99,020
Cumulative Timesteps: 825,901,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 825901910...
Checkpoint 825901910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,012.93271
Policy Entropy: 1.84526
Value Function Loss: 0.08800

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.15900
Policy Update Magnitude: 0.46933
Value Function Update Magnitude: 0.33087

Collected Steps per Second: 20,844.68745
Overall Steps per Second: 10,166.06938

Timestep Collection Time: 2.39946
Timestep Consumption Time: 2.52044
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.91990

Cumulative Model Updates: 99,026
Cumulative Timesteps: 825,951,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,393.51445
Policy Entropy: 1.84337
Value Function Loss: 0.08458

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.14618
Policy Update Magnitude: 0.47902
Value Function Update Magnitude: 0.29943

Collected Steps per Second: 20,904.16623
Overall Steps per Second: 10,054.04532

Timestep Collection Time: 2.39187
Timestep Consumption Time: 2.58125
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.97312

Cumulative Model Updates: 99,032
Cumulative Timesteps: 826,001,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 826001926...
Checkpoint 826001926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,968.53303
Policy Entropy: 1.84017
Value Function Loss: 0.07595

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.52153
Value Function Update Magnitude: 0.34428

Collected Steps per Second: 20,689.67314
Overall Steps per Second: 10,243.66098

Timestep Collection Time: 2.41773
Timestep Consumption Time: 2.46549
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.88322

Cumulative Model Updates: 99,038
Cumulative Timesteps: 826,051,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,560.58681
Policy Entropy: 1.82808
Value Function Loss: 0.07213

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.13632
Policy Update Magnitude: 0.56188
Value Function Update Magnitude: 0.45140

Collected Steps per Second: 21,895.21048
Overall Steps per Second: 10,450.18405

Timestep Collection Time: 2.28434
Timestep Consumption Time: 2.50180
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.78614

Cumulative Model Updates: 99,044
Cumulative Timesteps: 826,101,964

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 826101964...
Checkpoint 826101964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,388.10672
Policy Entropy: 1.83169
Value Function Loss: 0.07189

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.57889
Value Function Update Magnitude: 0.54907

Collected Steps per Second: 21,695.02503
Overall Steps per Second: 10,293.83288

Timestep Collection Time: 2.30495
Timestep Consumption Time: 2.55291
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.85786

Cumulative Model Updates: 99,050
Cumulative Timesteps: 826,151,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,596.36004
Policy Entropy: 1.84163
Value Function Loss: 0.07561

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.59571
Value Function Update Magnitude: 0.60127

Collected Steps per Second: 22,088.56264
Overall Steps per Second: 10,355.56459

Timestep Collection Time: 2.26398
Timestep Consumption Time: 2.56512
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.82909

Cumulative Model Updates: 99,056
Cumulative Timesteps: 826,201,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 826201978...
Checkpoint 826201978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,247.10661
Policy Entropy: 1.84176
Value Function Loss: 0.07662

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.59646
Value Function Update Magnitude: 0.68054

Collected Steps per Second: 21,646.18267
Overall Steps per Second: 10,270.65940

Timestep Collection Time: 2.30988
Timestep Consumption Time: 2.55836
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.86824

Cumulative Model Updates: 99,062
Cumulative Timesteps: 826,251,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,484.58072
Policy Entropy: 1.85534
Value Function Loss: 0.07275

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13519
Policy Update Magnitude: 0.58559
Value Function Update Magnitude: 0.70326

Collected Steps per Second: 22,083.96544
Overall Steps per Second: 10,410.06521

Timestep Collection Time: 2.26418
Timestep Consumption Time: 2.53906
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.80324

Cumulative Model Updates: 99,068
Cumulative Timesteps: 826,301,980

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 826301980...
Checkpoint 826301980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,126.58639
Policy Entropy: 1.85018
Value Function Loss: 0.06983

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.57221
Value Function Update Magnitude: 0.66211

Collected Steps per Second: 21,786.43925
Overall Steps per Second: 10,557.43617

Timestep Collection Time: 2.29657
Timestep Consumption Time: 2.44265
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.73922

Cumulative Model Updates: 99,074
Cumulative Timesteps: 826,352,014

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,107.22651
Policy Entropy: 1.84432
Value Function Loss: 0.07067

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.56682
Value Function Update Magnitude: 0.60086

Collected Steps per Second: 22,182.68637
Overall Steps per Second: 10,500.91101

Timestep Collection Time: 2.25410
Timestep Consumption Time: 2.50758
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.76168

Cumulative Model Updates: 99,080
Cumulative Timesteps: 826,402,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 826402016...
Checkpoint 826402016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,708.18425
Policy Entropy: 1.83706
Value Function Loss: 0.07206

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.57607
Value Function Update Magnitude: 0.54436

Collected Steps per Second: 22,006.29753
Overall Steps per Second: 10,604.44331

Timestep Collection Time: 2.27362
Timestep Consumption Time: 2.44459
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.71821

Cumulative Model Updates: 99,086
Cumulative Timesteps: 826,452,050

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,914.08207
Policy Entropy: 1.83410
Value Function Loss: 0.07256

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.57956
Value Function Update Magnitude: 0.55048

Collected Steps per Second: 22,160.09207
Overall Steps per Second: 10,526.42631

Timestep Collection Time: 2.25766
Timestep Consumption Time: 2.49514
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.75280

Cumulative Model Updates: 99,092
Cumulative Timesteps: 826,502,080

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 826502080...
Checkpoint 826502080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,351.50830
Policy Entropy: 1.82299
Value Function Loss: 0.07273

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.57099
Value Function Update Magnitude: 0.47363

Collected Steps per Second: 21,750.31826
Overall Steps per Second: 10,562.83611

Timestep Collection Time: 2.29928
Timestep Consumption Time: 2.43525
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.73452

Cumulative Model Updates: 99,098
Cumulative Timesteps: 826,552,090

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,074.87811
Policy Entropy: 1.83375
Value Function Loss: 0.07709

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13316
Policy Update Magnitude: 0.58033
Value Function Update Magnitude: 0.43345

Collected Steps per Second: 21,220.39735
Overall Steps per Second: 10,184.42067

Timestep Collection Time: 2.35632
Timestep Consumption Time: 2.55334
PPO Batch Consumption Time: 0.29975
Total Iteration Time: 4.90966

Cumulative Model Updates: 99,104
Cumulative Timesteps: 826,602,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 826602092...
Checkpoint 826602092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,726.00661
Policy Entropy: 1.83566
Value Function Loss: 0.07287

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.14058
Policy Update Magnitude: 0.58076
Value Function Update Magnitude: 0.59391

Collected Steps per Second: 20,540.22348
Overall Steps per Second: 10,276.21868

Timestep Collection Time: 2.43522
Timestep Consumption Time: 2.43233
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.86755

Cumulative Model Updates: 99,110
Cumulative Timesteps: 826,652,112

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,066.14603
Policy Entropy: 1.84115
Value Function Loss: 0.07265

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.55937
Value Function Update Magnitude: 0.66431

Collected Steps per Second: 21,330.69354
Overall Steps per Second: 10,499.44091

Timestep Collection Time: 2.34563
Timestep Consumption Time: 2.41976
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.76540

Cumulative Model Updates: 99,116
Cumulative Timesteps: 826,702,146

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 826702146...
Checkpoint 826702146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,007.67762
Policy Entropy: 1.84157
Value Function Loss: 0.07608

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.56726
Value Function Update Magnitude: 0.60629

Collected Steps per Second: 20,922.35409
Overall Steps per Second: 10,437.32736

Timestep Collection Time: 2.39027
Timestep Consumption Time: 2.40119
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.79146

Cumulative Model Updates: 99,122
Cumulative Timesteps: 826,752,156

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,067.95058
Policy Entropy: 1.84328
Value Function Loss: 0.07253

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.56871
Value Function Update Magnitude: 0.56870

Collected Steps per Second: 21,336.06841
Overall Steps per Second: 10,462.18961

Timestep Collection Time: 2.34504
Timestep Consumption Time: 2.43732
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.78236

Cumulative Model Updates: 99,128
Cumulative Timesteps: 826,802,190

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 826802190...
Checkpoint 826802190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,968.17748
Policy Entropy: 1.84555
Value Function Loss: 0.07222

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.56504
Value Function Update Magnitude: 0.64298

Collected Steps per Second: 20,462.95640
Overall Steps per Second: 10,229.30794

Timestep Collection Time: 2.44579
Timestep Consumption Time: 2.44682
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.89261

Cumulative Model Updates: 99,134
Cumulative Timesteps: 826,852,238

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,268.36337
Policy Entropy: 1.84072
Value Function Loss: 0.06869

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.56787
Value Function Update Magnitude: 0.59080

Collected Steps per Second: 21,633.87028
Overall Steps per Second: 10,516.85015

Timestep Collection Time: 2.31156
Timestep Consumption Time: 2.44348
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.75504

Cumulative Model Updates: 99,140
Cumulative Timesteps: 826,902,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 826902246...
Checkpoint 826902246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,398.93344
Policy Entropy: 1.82464
Value Function Loss: 0.06987

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.56840
Value Function Update Magnitude: 0.53967

Collected Steps per Second: 20,476.98299
Overall Steps per Second: 10,116.27649

Timestep Collection Time: 2.44196
Timestep Consumption Time: 2.50096
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.94293

Cumulative Model Updates: 99,146
Cumulative Timesteps: 826,952,250

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,737.60910
Policy Entropy: 1.83197
Value Function Loss: 0.07520

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.57219
Value Function Update Magnitude: 0.49053

Collected Steps per Second: 22,217.12355
Overall Steps per Second: 10,497.88273

Timestep Collection Time: 2.25070
Timestep Consumption Time: 2.51255
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.76325

Cumulative Model Updates: 99,152
Cumulative Timesteps: 827,002,254

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 827002254...
Checkpoint 827002254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,567.66006
Policy Entropy: 1.82710
Value Function Loss: 0.08082

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14678
Policy Update Magnitude: 0.53813
Value Function Update Magnitude: 0.42889

Collected Steps per Second: 21,140.03345
Overall Steps per Second: 10,294.08363

Timestep Collection Time: 2.36594
Timestep Consumption Time: 2.49278
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.85871

Cumulative Model Updates: 99,158
Cumulative Timesteps: 827,052,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,416.52370
Policy Entropy: 1.83764
Value Function Loss: 0.07875

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.53666
Value Function Update Magnitude: 0.44870

Collected Steps per Second: 22,327.91126
Overall Steps per Second: 10,737.17628

Timestep Collection Time: 2.24051
Timestep Consumption Time: 2.41863
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.65914

Cumulative Model Updates: 99,164
Cumulative Timesteps: 827,102,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 827102296...
Checkpoint 827102296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,531.59796
Policy Entropy: 1.81958
Value Function Loss: 0.07747

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.57068
Value Function Update Magnitude: 0.62192

Collected Steps per Second: 21,347.67177
Overall Steps per Second: 10,384.91265

Timestep Collection Time: 2.34283
Timestep Consumption Time: 2.47319
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.81603

Cumulative Model Updates: 99,170
Cumulative Timesteps: 827,152,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,937.18355
Policy Entropy: 1.81826
Value Function Loss: 0.06962

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.57114
Value Function Update Magnitude: 0.71045

Collected Steps per Second: 22,156.96450
Overall Steps per Second: 10,486.61426

Timestep Collection Time: 2.25690
Timestep Consumption Time: 2.51166
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.76856

Cumulative Model Updates: 99,176
Cumulative Timesteps: 827,202,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 827202316...
Checkpoint 827202316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,964.18780
Policy Entropy: 1.80610
Value Function Loss: 0.07520

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.57821
Value Function Update Magnitude: 0.72669

Collected Steps per Second: 21,499.34290
Overall Steps per Second: 10,331.46775

Timestep Collection Time: 2.32575
Timestep Consumption Time: 2.51403
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.83978

Cumulative Model Updates: 99,182
Cumulative Timesteps: 827,252,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,858.21309
Policy Entropy: 1.81154
Value Function Loss: 0.07501

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.14514
Policy Update Magnitude: 0.57171
Value Function Update Magnitude: 0.74076

Collected Steps per Second: 22,187.74698
Overall Steps per Second: 10,561.35118

Timestep Collection Time: 2.25476
Timestep Consumption Time: 2.48214
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.73689

Cumulative Model Updates: 99,188
Cumulative Timesteps: 827,302,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 827302346...
Checkpoint 827302346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,145.66504
Policy Entropy: 1.80287
Value Function Loss: 0.07804

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.14633
Policy Update Magnitude: 0.54197
Value Function Update Magnitude: 0.75840

Collected Steps per Second: 21,905.92402
Overall Steps per Second: 10,574.17741

Timestep Collection Time: 2.28294
Timestep Consumption Time: 2.44650
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.72945

Cumulative Model Updates: 99,194
Cumulative Timesteps: 827,352,356

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,245.39177
Policy Entropy: 1.80418
Value Function Loss: 0.07783

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14552
Policy Update Magnitude: 0.55334
Value Function Update Magnitude: 0.77030

Collected Steps per Second: 22,078.09349
Overall Steps per Second: 10,463.97617

Timestep Collection Time: 2.26541
Timestep Consumption Time: 2.51441
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.77983

Cumulative Model Updates: 99,200
Cumulative Timesteps: 827,402,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 827402372...
Checkpoint 827402372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.14900
Policy Entropy: 1.80896
Value Function Loss: 0.07240

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14176
Policy Update Magnitude: 0.56896
Value Function Update Magnitude: 0.74639

Collected Steps per Second: 21,881.13919
Overall Steps per Second: 10,416.45492

Timestep Collection Time: 2.28562
Timestep Consumption Time: 2.51563
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.80125

Cumulative Model Updates: 99,206
Cumulative Timesteps: 827,452,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,740.91347
Policy Entropy: 1.80633
Value Function Loss: 0.07513

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.15657
Policy Update Magnitude: 0.56183
Value Function Update Magnitude: 0.69728

Collected Steps per Second: 21,819.53340
Overall Steps per Second: 10,381.01195

Timestep Collection Time: 2.29226
Timestep Consumption Time: 2.52577
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.81803

Cumulative Model Updates: 99,212
Cumulative Timesteps: 827,502,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 827502400...
Checkpoint 827502400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,897.79349
Policy Entropy: 1.80465
Value Function Loss: 0.07473

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.16685
Policy Update Magnitude: 0.55907
Value Function Update Magnitude: 0.65359

Collected Steps per Second: 21,597.24235
Overall Steps per Second: 10,496.25204

Timestep Collection Time: 2.31548
Timestep Consumption Time: 2.44889
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.76437

Cumulative Model Updates: 99,218
Cumulative Timesteps: 827,552,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,654.56511
Policy Entropy: 1.80435
Value Function Loss: 0.08030

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.15438
Policy Update Magnitude: 0.58227
Value Function Update Magnitude: 0.65743

Collected Steps per Second: 21,518.25583
Overall Steps per Second: 10,440.88473

Timestep Collection Time: 2.32361
Timestep Consumption Time: 2.46526
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.78887

Cumulative Model Updates: 99,224
Cumulative Timesteps: 827,602,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 827602408...
Checkpoint 827602408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,141.10932
Policy Entropy: 1.80232
Value Function Loss: 0.07730

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.15737
Policy Update Magnitude: 0.57023
Value Function Update Magnitude: 0.61912

Collected Steps per Second: 21,123.77093
Overall Steps per Second: 10,230.06014

Timestep Collection Time: 2.36710
Timestep Consumption Time: 2.52066
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.88775

Cumulative Model Updates: 99,230
Cumulative Timesteps: 827,652,410

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,031.81941
Policy Entropy: 1.80494
Value Function Loss: 0.07731

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.16192
Policy Update Magnitude: 0.54575
Value Function Update Magnitude: 0.59672

Collected Steps per Second: 22,155.19952
Overall Steps per Second: 10,482.93468

Timestep Collection Time: 2.25771
Timestep Consumption Time: 2.51386
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.77156

Cumulative Model Updates: 99,236
Cumulative Timesteps: 827,702,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 827702430...
Checkpoint 827702430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,329.39915
Policy Entropy: 1.81078
Value Function Loss: 0.07807

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.16203
Policy Update Magnitude: 0.55336
Value Function Update Magnitude: 0.62002

Collected Steps per Second: 21,674.45573
Overall Steps per Second: 10,375.56482

Timestep Collection Time: 2.30723
Timestep Consumption Time: 2.51255
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.81979

Cumulative Model Updates: 99,242
Cumulative Timesteps: 827,752,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,626.95371
Policy Entropy: 1.80970
Value Function Loss: 0.07697

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.15876
Policy Update Magnitude: 0.58179
Value Function Update Magnitude: 0.63082

Collected Steps per Second: 22,370.50100
Overall Steps per Second: 10,645.43461

Timestep Collection Time: 2.23544
Timestep Consumption Time: 2.46216
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.69760

Cumulative Model Updates: 99,248
Cumulative Timesteps: 827,802,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 827802446...
Checkpoint 827802446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,775.08586
Policy Entropy: 1.79496
Value Function Loss: 0.08273

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.16153
Policy Update Magnitude: 0.57599
Value Function Update Magnitude: 0.66225

Collected Steps per Second: 21,530.74681
Overall Steps per Second: 10,402.66124

Timestep Collection Time: 2.32291
Timestep Consumption Time: 2.48490
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.80781

Cumulative Model Updates: 99,254
Cumulative Timesteps: 827,852,460

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,640.00446
Policy Entropy: 1.79529
Value Function Loss: 0.07960

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.18036
Policy Update Magnitude: 0.49455
Value Function Update Magnitude: 0.64529

Collected Steps per Second: 21,618.68115
Overall Steps per Second: 10,154.70060

Timestep Collection Time: 2.31476
Timestep Consumption Time: 2.61321
PPO Batch Consumption Time: 0.30674
Total Iteration Time: 4.92796

Cumulative Model Updates: 99,260
Cumulative Timesteps: 827,902,502

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 827902502...
Checkpoint 827902502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,067.19769
Policy Entropy: 1.79573
Value Function Loss: 0.08039

Mean KL Divergence: 0.02202
SB3 Clip Fraction: 0.17945
Policy Update Magnitude: 0.48199
Value Function Update Magnitude: 0.68677

Collected Steps per Second: 21,028.88823
Overall Steps per Second: 10,359.18455

Timestep Collection Time: 2.37806
Timestep Consumption Time: 2.44934
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.82741

Cumulative Model Updates: 99,266
Cumulative Timesteps: 827,952,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,744.69018
Policy Entropy: 1.80714
Value Function Loss: 0.08327

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.16186
Policy Update Magnitude: 0.49614
Value Function Update Magnitude: 0.65255

Collected Steps per Second: 22,174.90669
Overall Steps per Second: 10,431.36673

Timestep Collection Time: 2.25615
Timestep Consumption Time: 2.53996
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.79611

Cumulative Model Updates: 99,272
Cumulative Timesteps: 828,002,540

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 828002540...
Checkpoint 828002540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,225.81869
Policy Entropy: 1.80479
Value Function Loss: 0.08198

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.17866
Policy Update Magnitude: 0.47672
Value Function Update Magnitude: 0.64408

Collected Steps per Second: 22,061.70414
Overall Steps per Second: 10,643.24565

Timestep Collection Time: 2.26719
Timestep Consumption Time: 2.43232
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.69951

Cumulative Model Updates: 99,278
Cumulative Timesteps: 828,052,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,883.54318
Policy Entropy: 1.78739
Value Function Loss: 0.08073

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.17459
Policy Update Magnitude: 0.48597
Value Function Update Magnitude: 0.65581

Collected Steps per Second: 21,840.69033
Overall Steps per Second: 10,544.06952

Timestep Collection Time: 2.28940
Timestep Consumption Time: 2.45280
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.74219

Cumulative Model Updates: 99,284
Cumulative Timesteps: 828,102,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 828102560...
Checkpoint 828102560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,769.87153
Policy Entropy: 1.76710
Value Function Loss: 0.07340

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.19085
Policy Update Magnitude: 0.49381
Value Function Update Magnitude: 0.68852

Collected Steps per Second: 21,629.33461
Overall Steps per Second: 10,517.32010

Timestep Collection Time: 2.31186
Timestep Consumption Time: 2.44258
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.75444

Cumulative Model Updates: 99,290
Cumulative Timesteps: 828,152,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,028.19959
Policy Entropy: 1.75385
Value Function Loss: 0.07057

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.19334
Policy Update Magnitude: 0.49430
Value Function Update Magnitude: 0.71555

Collected Steps per Second: 21,741.25971
Overall Steps per Second: 10,511.61994

Timestep Collection Time: 2.30023
Timestep Consumption Time: 2.45736
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.75759

Cumulative Model Updates: 99,296
Cumulative Timesteps: 828,202,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 828202574...
Checkpoint 828202574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,233.99129
Policy Entropy: 1.77190
Value Function Loss: 0.07194

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.16298
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.74643

Collected Steps per Second: 21,884.23193
Overall Steps per Second: 10,565.54995

Timestep Collection Time: 2.28521
Timestep Consumption Time: 2.44810
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.73331

Cumulative Model Updates: 99,302
Cumulative Timesteps: 828,252,584

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,139.20426
Policy Entropy: 1.80083
Value Function Loss: 0.07010

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.15383
Policy Update Magnitude: 0.57476
Value Function Update Magnitude: 0.75554

Collected Steps per Second: 21,128.72181
Overall Steps per Second: 10,247.14779

Timestep Collection Time: 2.36664
Timestep Consumption Time: 2.51316
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.87980

Cumulative Model Updates: 99,308
Cumulative Timesteps: 828,302,588

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 828302588...
Checkpoint 828302588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,168.03136
Policy Entropy: 1.82897
Value Function Loss: 0.06688

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.57112
Value Function Update Magnitude: 0.74455

Collected Steps per Second: 21,751.21087
Overall Steps per Second: 10,533.32344

Timestep Collection Time: 2.29872
Timestep Consumption Time: 2.44812
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.74684

Cumulative Model Updates: 99,314
Cumulative Timesteps: 828,352,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,317.67238
Policy Entropy: 1.82210
Value Function Loss: 0.06258

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.56224
Value Function Update Magnitude: 0.70179

Collected Steps per Second: 21,617.68528
Overall Steps per Second: 10,401.56819

Timestep Collection Time: 2.31412
Timestep Consumption Time: 2.49534
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.80947

Cumulative Model Updates: 99,320
Cumulative Timesteps: 828,402,614

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 828402614...
Checkpoint 828402614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,985.23742
Policy Entropy: 1.80661
Value Function Loss: 0.06590

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.55361
Value Function Update Magnitude: 0.65684

Collected Steps per Second: 21,121.20939
Overall Steps per Second: 10,210.35266

Timestep Collection Time: 2.36824
Timestep Consumption Time: 2.53071
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.89895

Cumulative Model Updates: 99,326
Cumulative Timesteps: 828,452,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,987.16870
Policy Entropy: 1.78428
Value Function Loss: 0.06976

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.55531
Value Function Update Magnitude: 0.66906

Collected Steps per Second: 21,730.98324
Overall Steps per Second: 10,543.32224

Timestep Collection Time: 2.30114
Timestep Consumption Time: 2.44177
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.74291

Cumulative Model Updates: 99,332
Cumulative Timesteps: 828,502,640

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 828502640...
Checkpoint 828502640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,663.69200
Policy Entropy: 1.78553
Value Function Loss: 0.07286

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.14735
Policy Update Magnitude: 0.55511
Value Function Update Magnitude: 0.65571

Collected Steps per Second: 20,951.61310
Overall Steps per Second: 10,028.67579

Timestep Collection Time: 2.38712
Timestep Consumption Time: 2.59998
PPO Batch Consumption Time: 0.30589
Total Iteration Time: 4.98710

Cumulative Model Updates: 99,338
Cumulative Timesteps: 828,552,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,214.98384
Policy Entropy: 1.78362
Value Function Loss: 0.07770

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.15864
Policy Update Magnitude: 0.56985
Value Function Update Magnitude: 0.66882

Collected Steps per Second: 22,139.18295
Overall Steps per Second: 10,520.83098

Timestep Collection Time: 2.25925
Timestep Consumption Time: 2.49493
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.75419

Cumulative Model Updates: 99,344
Cumulative Timesteps: 828,602,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 828602672...
Checkpoint 828602672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,518.92641
Policy Entropy: 1.79335
Value Function Loss: 0.07818

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.16123
Policy Update Magnitude: 0.56780
Value Function Update Magnitude: 0.65594

Collected Steps per Second: 21,968.49774
Overall Steps per Second: 10,558.27524

Timestep Collection Time: 2.27690
Timestep Consumption Time: 2.46062
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.73752

Cumulative Model Updates: 99,350
Cumulative Timesteps: 828,652,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,774.58486
Policy Entropy: 1.78984
Value Function Loss: 0.07741

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.18848
Policy Update Magnitude: 0.53902
Value Function Update Magnitude: 0.59099

Collected Steps per Second: 21,498.84407
Overall Steps per Second: 10,652.67269

Timestep Collection Time: 2.32757
Timestep Consumption Time: 2.36985
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.69741

Cumulative Model Updates: 99,356
Cumulative Timesteps: 828,702,732

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 828702732...
Checkpoint 828702732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,359.22927
Policy Entropy: 1.79109
Value Function Loss: 0.07783

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.17876
Policy Update Magnitude: 0.52423
Value Function Update Magnitude: 0.65572

Collected Steps per Second: 20,826.18388
Overall Steps per Second: 10,471.58994

Timestep Collection Time: 2.40082
Timestep Consumption Time: 2.37400
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.77482

Cumulative Model Updates: 99,362
Cumulative Timesteps: 828,752,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,434.29463
Policy Entropy: 1.79454
Value Function Loss: 0.07765

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.15818
Policy Update Magnitude: 0.56439
Value Function Update Magnitude: 0.67151

Collected Steps per Second: 21,415.72552
Overall Steps per Second: 10,536.65478

Timestep Collection Time: 2.33604
Timestep Consumption Time: 2.41196
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.74800

Cumulative Model Updates: 99,368
Cumulative Timesteps: 828,802,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 828802760...
Checkpoint 828802760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,710.87948
Policy Entropy: 1.80610
Value Function Loss: 0.07836

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.15348
Policy Update Magnitude: 0.56212
Value Function Update Magnitude: 0.64797

Collected Steps per Second: 21,332.91864
Overall Steps per Second: 10,584.26702

Timestep Collection Time: 2.34586
Timestep Consumption Time: 2.38229
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.72815

Cumulative Model Updates: 99,374
Cumulative Timesteps: 828,852,804

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,883.06385
Policy Entropy: 1.81530
Value Function Loss: 0.07869

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.16135
Policy Update Magnitude: 0.55991
Value Function Update Magnitude: 0.67290

Collected Steps per Second: 21,276.82471
Overall Steps per Second: 10,583.22471

Timestep Collection Time: 2.35101
Timestep Consumption Time: 2.37553
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.72654

Cumulative Model Updates: 99,380
Cumulative Timesteps: 828,902,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 828902826...
Checkpoint 828902826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,067.79359
Policy Entropy: 1.82193
Value Function Loss: 0.07787

Mean KL Divergence: 0.02202
SB3 Clip Fraction: 0.18491
Policy Update Magnitude: 0.53855
Value Function Update Magnitude: 0.68266

Collected Steps per Second: 20,801.49913
Overall Steps per Second: 10,363.49597

Timestep Collection Time: 2.40406
Timestep Consumption Time: 2.42134
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.82540

Cumulative Model Updates: 99,386
Cumulative Timesteps: 828,952,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,337.92245
Policy Entropy: 1.81527
Value Function Loss: 0.07651

Mean KL Divergence: 0.02215
SB3 Clip Fraction: 0.18119
Policy Update Magnitude: 0.52367
Value Function Update Magnitude: 0.67035

Collected Steps per Second: 20,987.75071
Overall Steps per Second: 10,337.24582

Timestep Collection Time: 2.38234
Timestep Consumption Time: 2.45454
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.83688

Cumulative Model Updates: 99,392
Cumulative Timesteps: 829,002,834

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 829002834...
Checkpoint 829002834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,692.81690
Policy Entropy: 1.82125
Value Function Loss: 0.07513

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.17582
Policy Update Magnitude: 0.50817
Value Function Update Magnitude: 0.64875

Collected Steps per Second: 20,523.39328
Overall Steps per Second: 10,121.42842

Timestep Collection Time: 2.43819
Timestep Consumption Time: 2.50577
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.94397

Cumulative Model Updates: 99,398
Cumulative Timesteps: 829,052,874

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,061.44435
Policy Entropy: 1.81552
Value Function Loss: 0.07171

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.17175
Policy Update Magnitude: 0.47616
Value Function Update Magnitude: 0.66948

Collected Steps per Second: 21,540.95141
Overall Steps per Second: 10,542.96502

Timestep Collection Time: 2.32227
Timestep Consumption Time: 2.42250
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.74478

Cumulative Model Updates: 99,404
Cumulative Timesteps: 829,102,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 829102898...
Checkpoint 829102898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,860.04701
Policy Entropy: 1.80896
Value Function Loss: 0.07404

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.16103
Policy Update Magnitude: 0.47159
Value Function Update Magnitude: 0.63606

Collected Steps per Second: 21,331.62062
Overall Steps per Second: 10,511.50935

Timestep Collection Time: 2.34544
Timestep Consumption Time: 2.41430
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.75974

Cumulative Model Updates: 99,410
Cumulative Timesteps: 829,152,930

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,802.69297
Policy Entropy: 1.80662
Value Function Loss: 0.08043

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.15826
Policy Update Magnitude: 0.50757
Value Function Update Magnitude: 0.65070

Collected Steps per Second: 21,932.02379
Overall Steps per Second: 10,413.60084

Timestep Collection Time: 2.28050
Timestep Consumption Time: 2.52245
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.80295

Cumulative Model Updates: 99,416
Cumulative Timesteps: 829,202,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 829202946...
Checkpoint 829202946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,627.46826
Policy Entropy: 1.81226
Value Function Loss: 0.08631

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.52642
Value Function Update Magnitude: 0.61222

Collected Steps per Second: 21,922.28746
Overall Steps per Second: 10,334.40349

Timestep Collection Time: 2.28170
Timestep Consumption Time: 2.55845
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.84014

Cumulative Model Updates: 99,422
Cumulative Timesteps: 829,252,966

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,165.01572
Policy Entropy: 1.81710
Value Function Loss: 0.08151

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.14979
Policy Update Magnitude: 0.56803
Value Function Update Magnitude: 0.69254

Collected Steps per Second: 22,244.82596
Overall Steps per Second: 10,568.66245

Timestep Collection Time: 2.24879
Timestep Consumption Time: 2.48445
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.73324

Cumulative Model Updates: 99,428
Cumulative Timesteps: 829,302,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 829302990...
Checkpoint 829302990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,444.63347
Policy Entropy: 1.81705
Value Function Loss: 0.07973

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.58279
Value Function Update Magnitude: 0.75272

Collected Steps per Second: 22,185.70160
Overall Steps per Second: 10,516.03907

Timestep Collection Time: 2.25370
Timestep Consumption Time: 2.50094
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.75464

Cumulative Model Updates: 99,434
Cumulative Timesteps: 829,352,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,239.87865
Policy Entropy: 1.81999
Value Function Loss: 0.07574

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.14882
Policy Update Magnitude: 0.58661
Value Function Update Magnitude: 0.75120

Collected Steps per Second: 21,993.73285
Overall Steps per Second: 10,398.14379

Timestep Collection Time: 2.27392
Timestep Consumption Time: 2.53578
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.80970

Cumulative Model Updates: 99,440
Cumulative Timesteps: 829,403,002

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 829403002...
Checkpoint 829403002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,254.65515
Policy Entropy: 1.82632
Value Function Loss: 0.07765

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.14548
Policy Update Magnitude: 0.58985
Value Function Update Magnitude: 0.73528

Collected Steps per Second: 21,603.47709
Overall Steps per Second: 10,355.03734

Timestep Collection Time: 2.31463
Timestep Consumption Time: 2.51433
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.82895

Cumulative Model Updates: 99,446
Cumulative Timesteps: 829,453,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,449.02954
Policy Entropy: 1.81060
Value Function Loss: 0.07652

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14691
Policy Update Magnitude: 0.59309
Value Function Update Magnitude: 0.68854

Collected Steps per Second: 22,683.45890
Overall Steps per Second: 10,742.78550

Timestep Collection Time: 2.20504
Timestep Consumption Time: 2.45092
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.65596

Cumulative Model Updates: 99,452
Cumulative Timesteps: 829,503,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 829503024...
Checkpoint 829503024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,751.61795
Policy Entropy: 1.80221
Value Function Loss: 0.07471

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.56802
Value Function Update Magnitude: 0.67520

Collected Steps per Second: 21,708.53866
Overall Steps per Second: 10,397.62894

Timestep Collection Time: 2.30333
Timestep Consumption Time: 2.50565
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.80898

Cumulative Model Updates: 99,458
Cumulative Timesteps: 829,553,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,855.97769
Policy Entropy: 1.80490
Value Function Loss: 0.06969

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.12953
Policy Update Magnitude: 0.56792
Value Function Update Magnitude: 0.69392

Collected Steps per Second: 21,640.47501
Overall Steps per Second: 10,241.98292

Timestep Collection Time: 2.31178
Timestep Consumption Time: 2.57282
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.88460

Cumulative Model Updates: 99,464
Cumulative Timesteps: 829,603,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 829603054...
Checkpoint 829603054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,561.85590
Policy Entropy: 1.80811
Value Function Loss: 0.07427

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.13994
Policy Update Magnitude: 0.57414
Value Function Update Magnitude: 0.70888

Collected Steps per Second: 21,277.89986
Overall Steps per Second: 10,210.24525

Timestep Collection Time: 2.35098
Timestep Consumption Time: 2.54841
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.89939

Cumulative Model Updates: 99,470
Cumulative Timesteps: 829,653,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,965.89972
Policy Entropy: 1.81850
Value Function Loss: 0.07958

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.14200
Policy Update Magnitude: 0.57284
Value Function Update Magnitude: 0.72862

Collected Steps per Second: 21,779.25426
Overall Steps per Second: 10,515.53107

Timestep Collection Time: 2.29751
Timestep Consumption Time: 2.46098
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.75849

Cumulative Model Updates: 99,476
Cumulative Timesteps: 829,703,116

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 829703116...
Checkpoint 829703116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,605.87106
Policy Entropy: 1.81404
Value Function Loss: 0.07942

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.59521
Value Function Update Magnitude: 0.74933

Collected Steps per Second: 20,169.65939
Overall Steps per Second: 10,167.44900

Timestep Collection Time: 2.48105
Timestep Consumption Time: 2.44073
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.92179

Cumulative Model Updates: 99,482
Cumulative Timesteps: 829,753,158

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,634.28018
Policy Entropy: 1.82054
Value Function Loss: 0.07542

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.58711
Value Function Update Magnitude: 0.75511

Collected Steps per Second: 21,789.30021
Overall Steps per Second: 10,493.00726

Timestep Collection Time: 2.29516
Timestep Consumption Time: 2.47087
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.76603

Cumulative Model Updates: 99,488
Cumulative Timesteps: 829,803,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 829803168...
Checkpoint 829803168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,234.46407
Policy Entropy: 1.81021
Value Function Loss: 0.07333

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.16971
Policy Update Magnitude: 0.54131
Value Function Update Magnitude: 0.71682

Collected Steps per Second: 21,332.24661
Overall Steps per Second: 10,105.04667

Timestep Collection Time: 2.34490
Timestep Consumption Time: 2.60530
PPO Batch Consumption Time: 0.30644
Total Iteration Time: 4.95020

Cumulative Model Updates: 99,494
Cumulative Timesteps: 829,853,190

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,099.15824
Policy Entropy: 1.82015
Value Function Loss: 0.06761

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.17030
Policy Update Magnitude: 0.47934
Value Function Update Magnitude: 0.63463

Collected Steps per Second: 22,422.55924
Overall Steps per Second: 10,591.75758

Timestep Collection Time: 2.23008
Timestep Consumption Time: 2.49095
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.72103

Cumulative Model Updates: 99,500
Cumulative Timesteps: 829,903,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 829903194...
Checkpoint 829903194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,957.30215
Policy Entropy: 1.83315
Value Function Loss: 0.06870

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.16681
Policy Update Magnitude: 0.46777
Value Function Update Magnitude: 0.49452

Collected Steps per Second: 21,486.18353
Overall Steps per Second: 10,312.60438

Timestep Collection Time: 2.32838
Timestep Consumption Time: 2.52277
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.85115

Cumulative Model Updates: 99,506
Cumulative Timesteps: 829,953,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,990.18321
Policy Entropy: 1.81624
Value Function Loss: 0.06901

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.17155
Policy Update Magnitude: 0.45542
Value Function Update Magnitude: 0.60529

Collected Steps per Second: 21,842.23359
Overall Steps per Second: 10,368.92925

Timestep Collection Time: 2.29015
Timestep Consumption Time: 2.53407
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.82422

Cumulative Model Updates: 99,512
Cumulative Timesteps: 830,003,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 830003244...
Checkpoint 830003244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,120.06265
Policy Entropy: 1.81297
Value Function Loss: 0.07139

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.15989
Policy Update Magnitude: 0.48563
Value Function Update Magnitude: 0.66087

Collected Steps per Second: 22,162.24067
Overall Steps per Second: 10,653.10028

Timestep Collection Time: 2.25636
Timestep Consumption Time: 2.43767
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.69403

Cumulative Model Updates: 99,518
Cumulative Timesteps: 830,053,250

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,362.92180
Policy Entropy: 1.81937
Value Function Loss: 0.07993

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.15317
Policy Update Magnitude: 0.50779
Value Function Update Magnitude: 0.63999

Collected Steps per Second: 22,298.52361
Overall Steps per Second: 10,613.54995

Timestep Collection Time: 2.24365
Timestep Consumption Time: 2.47014
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.71379

Cumulative Model Updates: 99,524
Cumulative Timesteps: 830,103,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 830103280...
Checkpoint 830103280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,854.44923
Policy Entropy: 1.83970
Value Function Loss: 0.08370

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.14871
Policy Update Magnitude: 0.51110
Value Function Update Magnitude: 0.61930

Collected Steps per Second: 21,718.92670
Overall Steps per Second: 10,396.48691

Timestep Collection Time: 2.30242
Timestep Consumption Time: 2.50748
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.80989

Cumulative Model Updates: 99,530
Cumulative Timesteps: 830,153,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,775.05373
Policy Entropy: 1.85566
Value Function Loss: 0.08620

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.14838
Policy Update Magnitude: 0.52162
Value Function Update Magnitude: 0.66196

Collected Steps per Second: 22,060.81152
Overall Steps per Second: 10,477.92408

Timestep Collection Time: 2.26692
Timestep Consumption Time: 2.50598
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.77289

Cumulative Model Updates: 99,536
Cumulative Timesteps: 830,203,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 830203296...
Checkpoint 830203296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,200.54656
Policy Entropy: 1.84691
Value Function Loss: 0.08002

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.15767
Policy Update Magnitude: 0.51155
Value Function Update Magnitude: 0.68522

Collected Steps per Second: 21,511.98419
Overall Steps per Second: 10,304.23967

Timestep Collection Time: 2.32438
Timestep Consumption Time: 2.52819
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.85257

Cumulative Model Updates: 99,542
Cumulative Timesteps: 830,253,298

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,879.54888
Policy Entropy: 1.86450
Value Function Loss: 0.08075

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.16145
Policy Update Magnitude: 0.52253
Value Function Update Magnitude: 0.71254

Collected Steps per Second: 21,604.30096
Overall Steps per Second: 10,404.28711

Timestep Collection Time: 2.31537
Timestep Consumption Time: 2.49245
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.80783

Cumulative Model Updates: 99,548
Cumulative Timesteps: 830,303,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 830303320...
Checkpoint 830303320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,143.60382
Policy Entropy: 1.86389
Value Function Loss: 0.08040

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.55083
Value Function Update Magnitude: 0.65021

Collected Steps per Second: 21,403.68645
Overall Steps per Second: 10,543.70595

Timestep Collection Time: 2.33698
Timestep Consumption Time: 2.40708
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.74406

Cumulative Model Updates: 99,554
Cumulative Timesteps: 830,353,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,348.84235
Policy Entropy: 1.84977
Value Function Loss: 0.07901

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14488
Policy Update Magnitude: 0.56788
Value Function Update Magnitude: 0.58577

Collected Steps per Second: 21,980.74951
Overall Steps per Second: 10,536.98114

Timestep Collection Time: 2.27554
Timestep Consumption Time: 2.47136
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.74690

Cumulative Model Updates: 99,560
Cumulative Timesteps: 830,403,358

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 830403358...
Checkpoint 830403358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,364.25018
Policy Entropy: 1.83774
Value Function Loss: 0.07891

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.15384
Policy Update Magnitude: 0.56009
Value Function Update Magnitude: 0.55823

Collected Steps per Second: 22,013.48223
Overall Steps per Second: 10,387.32661

Timestep Collection Time: 2.27179
Timestep Consumption Time: 2.54273
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.81452

Cumulative Model Updates: 99,566
Cumulative Timesteps: 830,453,368

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,510.19355
Policy Entropy: 1.84539
Value Function Loss: 0.08449

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.56638
Value Function Update Magnitude: 0.57284

Collected Steps per Second: 22,060.43375
Overall Steps per Second: 10,469.37108

Timestep Collection Time: 2.26768
Timestep Consumption Time: 2.51064
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.77832

Cumulative Model Updates: 99,572
Cumulative Timesteps: 830,503,394

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 830503394...
Checkpoint 830503394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,526.47019
Policy Entropy: 1.85725
Value Function Loss: 0.08847

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.15400
Policy Update Magnitude: 0.58863
Value Function Update Magnitude: 0.63667

Collected Steps per Second: 21,743.62484
Overall Steps per Second: 10,390.06554

Timestep Collection Time: 2.30044
Timestep Consumption Time: 2.51377
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.81421

Cumulative Model Updates: 99,578
Cumulative Timesteps: 830,553,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,630.99093
Policy Entropy: 1.84708
Value Function Loss: 0.08721

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.15072
Policy Update Magnitude: 0.56400
Value Function Update Magnitude: 0.62229

Collected Steps per Second: 22,049.80894
Overall Steps per Second: 10,467.37948

Timestep Collection Time: 2.26895
Timestep Consumption Time: 2.51066
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.77961

Cumulative Model Updates: 99,584
Cumulative Timesteps: 830,603,444

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 830603444...
Checkpoint 830603444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,800.40212
Policy Entropy: 1.82987
Value Function Loss: 0.09168

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.56601
Value Function Update Magnitude: 0.51746

Collected Steps per Second: 21,333.46253
Overall Steps per Second: 10,113.04083

Timestep Collection Time: 2.34467
Timestep Consumption Time: 2.60142
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.94609

Cumulative Model Updates: 99,590
Cumulative Timesteps: 830,653,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,324.10220
Policy Entropy: 1.81673
Value Function Loss: 0.09288

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.58535
Value Function Update Magnitude: 0.41417

Collected Steps per Second: 20,778.58065
Overall Steps per Second: 10,154.19024

Timestep Collection Time: 2.40700
Timestep Consumption Time: 2.51846
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.92545

Cumulative Model Updates: 99,596
Cumulative Timesteps: 830,703,478

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 830703478...
Checkpoint 830703478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,287.34752
Policy Entropy: 1.81149
Value Function Loss: 0.08911

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.58944
Value Function Update Magnitude: 0.40118

Collected Steps per Second: 20,609.51495
Overall Steps per Second: 10,137.82571

Timestep Collection Time: 2.42723
Timestep Consumption Time: 2.50716
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.93439

Cumulative Model Updates: 99,602
Cumulative Timesteps: 830,753,502

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,395.01118
Policy Entropy: 1.81327
Value Function Loss: 0.08362

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.15025
Policy Update Magnitude: 0.55968
Value Function Update Magnitude: 0.43992

Collected Steps per Second: 20,840.42554
Overall Steps per Second: 10,043.37214

Timestep Collection Time: 2.40081
Timestep Consumption Time: 2.58098
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.98179

Cumulative Model Updates: 99,608
Cumulative Timesteps: 830,803,536

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 830803536...
Checkpoint 830803536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,674.84310
Policy Entropy: 1.81148
Value Function Loss: 0.07895

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.15121
Policy Update Magnitude: 0.50718
Value Function Update Magnitude: 0.50437

Collected Steps per Second: 21,753.53892
Overall Steps per Second: 10,339.58037

Timestep Collection Time: 2.29967
Timestep Consumption Time: 2.53863
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.83830

Cumulative Model Updates: 99,614
Cumulative Timesteps: 830,853,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,351.91548
Policy Entropy: 1.80657
Value Function Loss: 0.07944

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.15472
Policy Update Magnitude: 0.48661
Value Function Update Magnitude: 0.62159

Collected Steps per Second: 21,301.87940
Overall Steps per Second: 10,415.96150

Timestep Collection Time: 2.34749
Timestep Consumption Time: 2.45341
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.80090

Cumulative Model Updates: 99,620
Cumulative Timesteps: 830,903,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 830903568...
Checkpoint 830903568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,796.90133
Policy Entropy: 1.80178
Value Function Loss: 0.07845

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.15005
Policy Update Magnitude: 0.55162
Value Function Update Magnitude: 0.59001

Collected Steps per Second: 21,311.48574
Overall Steps per Second: 10,253.34871

Timestep Collection Time: 2.34756
Timestep Consumption Time: 2.53182
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.87938

Cumulative Model Updates: 99,626
Cumulative Timesteps: 830,953,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,281.69678
Policy Entropy: 1.79736
Value Function Loss: 0.07425

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15966
Policy Update Magnitude: 0.56421
Value Function Update Magnitude: 0.51979

Collected Steps per Second: 21,780.97475
Overall Steps per Second: 10,374.64132

Timestep Collection Time: 2.29567
Timestep Consumption Time: 2.52396
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.81964

Cumulative Model Updates: 99,632
Cumulative Timesteps: 831,003,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 831003600...
Checkpoint 831003600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,781.71229
Policy Entropy: 1.79115
Value Function Loss: 0.07148

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.17636
Policy Update Magnitude: 0.51608
Value Function Update Magnitude: 0.59280

Collected Steps per Second: 21,653.39791
Overall Steps per Second: 10,342.63120

Timestep Collection Time: 2.30966
Timestep Consumption Time: 2.52586
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.83552

Cumulative Model Updates: 99,638
Cumulative Timesteps: 831,053,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,248.12135
Policy Entropy: 1.80442
Value Function Loss: 0.07397

Mean KL Divergence: 0.02671
SB3 Clip Fraction: 0.20602
Policy Update Magnitude: 0.46402
Value Function Update Magnitude: 0.64328

Collected Steps per Second: 22,174.36931
Overall Steps per Second: 10,197.52044

Timestep Collection Time: 2.25585
Timestep Consumption Time: 2.64946
PPO Batch Consumption Time: 0.30172
Total Iteration Time: 4.90531

Cumulative Model Updates: 99,644
Cumulative Timesteps: 831,103,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 831103634...
Checkpoint 831103634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,406.52138
Policy Entropy: 1.82463
Value Function Loss: 0.07553

Mean KL Divergence: 0.03164
SB3 Clip Fraction: 0.21819
Policy Update Magnitude: 0.46788
Value Function Update Magnitude: 0.67594

Collected Steps per Second: 21,818.37468
Overall Steps per Second: 10,304.78550

Timestep Collection Time: 2.29275
Timestep Consumption Time: 2.56170
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.85444

Cumulative Model Updates: 99,650
Cumulative Timesteps: 831,153,658

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,749.81538
Policy Entropy: 1.82623
Value Function Loss: 0.07848

Mean KL Divergence: 0.02713
SB3 Clip Fraction: 0.21959
Policy Update Magnitude: 0.47567
Value Function Update Magnitude: 0.59528

Collected Steps per Second: 22,260.21157
Overall Steps per Second: 10,411.61837

Timestep Collection Time: 2.24724
Timestep Consumption Time: 2.55739
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.80463

Cumulative Model Updates: 99,656
Cumulative Timesteps: 831,203,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 831203682...
Checkpoint 831203682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,483.85488
Policy Entropy: 1.82242
Value Function Loss: 0.08538

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.16988
Policy Update Magnitude: 0.51204
Value Function Update Magnitude: 0.44222

Collected Steps per Second: 21,838.81552
Overall Steps per Second: 10,387.18952

Timestep Collection Time: 2.29069
Timestep Consumption Time: 2.52543
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.81612

Cumulative Model Updates: 99,662
Cumulative Timesteps: 831,253,708

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,134.44865
Policy Entropy: 1.81612
Value Function Loss: 0.08783

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.17248
Policy Update Magnitude: 0.54928
Value Function Update Magnitude: 0.40198

Collected Steps per Second: 22,110.19937
Overall Steps per Second: 10,458.30753

Timestep Collection Time: 2.26321
Timestep Consumption Time: 2.52150
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.78471

Cumulative Model Updates: 99,668
Cumulative Timesteps: 831,303,748

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 831303748...
Checkpoint 831303748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,327.61188
Policy Entropy: 1.82580
Value Function Loss: 0.09127

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.18806
Policy Update Magnitude: 0.52517
Value Function Update Magnitude: 0.39562

Collected Steps per Second: 21,938.71192
Overall Steps per Second: 10,542.22595

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.46395
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.74321

Cumulative Model Updates: 99,674
Cumulative Timesteps: 831,353,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,447.30620
Policy Entropy: 1.83435
Value Function Loss: 0.08460

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.15884
Policy Update Magnitude: 0.54369
Value Function Update Magnitude: 0.42688

Collected Steps per Second: 21,966.17032
Overall Steps per Second: 10,472.70153

Timestep Collection Time: 2.27686
Timestep Consumption Time: 2.49879
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.77565

Cumulative Model Updates: 99,680
Cumulative Timesteps: 831,403,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 831403766...
Checkpoint 831403766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,336.59006
Policy Entropy: 1.81735
Value Function Loss: 0.08170

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.15554
Policy Update Magnitude: 0.57331
Value Function Update Magnitude: 0.46631

Collected Steps per Second: 21,742.71457
Overall Steps per Second: 10,539.32678

Timestep Collection Time: 2.29999
Timestep Consumption Time: 2.44491
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.74490

Cumulative Model Updates: 99,686
Cumulative Timesteps: 831,453,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,221.87491
Policy Entropy: 1.81102
Value Function Loss: 0.08129

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.58290
Value Function Update Magnitude: 0.48370

Collected Steps per Second: 21,065.77866
Overall Steps per Second: 10,541.87483

Timestep Collection Time: 2.37475
Timestep Consumption Time: 2.37070
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.74546

Cumulative Model Updates: 99,692
Cumulative Timesteps: 831,503,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 831503800...
Checkpoint 831503800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,455.66626
Policy Entropy: 1.80963
Value Function Loss: 0.08406

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14601
Policy Update Magnitude: 0.58951
Value Function Update Magnitude: 0.45187

Collected Steps per Second: 20,202.30170
Overall Steps per Second: 10,214.29413

Timestep Collection Time: 2.47596
Timestep Consumption Time: 2.42110
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.89706

Cumulative Model Updates: 99,698
Cumulative Timesteps: 831,553,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,208.27780
Policy Entropy: 1.85655
Value Function Loss: 0.09032

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.57714
Value Function Update Magnitude: 0.37796

Collected Steps per Second: 19,896.63674
Overall Steps per Second: 10,003.56836

Timestep Collection Time: 2.51490
Timestep Consumption Time: 2.48712
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 5.00202

Cumulative Model Updates: 99,704
Cumulative Timesteps: 831,603,858

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 831603858...
Checkpoint 831603858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,527.24901
Policy Entropy: 1.87622
Value Function Loss: 0.09106

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.58405
Value Function Update Magnitude: 0.41111

Collected Steps per Second: 20,948.69768
Overall Steps per Second: 10,279.28227

Timestep Collection Time: 2.38717
Timestep Consumption Time: 2.47777
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.86493

Cumulative Model Updates: 99,710
Cumulative Timesteps: 831,653,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,948.77479
Policy Entropy: 1.87507
Value Function Loss: 0.08602

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.57832
Value Function Update Magnitude: 0.38437

Collected Steps per Second: 21,590.79164
Overall Steps per Second: 10,479.39326

Timestep Collection Time: 2.31617
Timestep Consumption Time: 2.45586
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.77203

Cumulative Model Updates: 99,716
Cumulative Timesteps: 831,703,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 831703874...
Checkpoint 831703874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,692.60819
Policy Entropy: 1.85633
Value Function Loss: 0.08704

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13012
Policy Update Magnitude: 0.58002
Value Function Update Magnitude: 0.37183

Collected Steps per Second: 21,188.22466
Overall Steps per Second: 10,376.01415

Timestep Collection Time: 2.36093
Timestep Consumption Time: 2.46019
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.82112

Cumulative Model Updates: 99,722
Cumulative Timesteps: 831,753,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,032.43967
Policy Entropy: 1.83988
Value Function Loss: 0.08599

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.57468
Value Function Update Magnitude: 0.40570

Collected Steps per Second: 22,342.06114
Overall Steps per Second: 10,569.66086

Timestep Collection Time: 2.23901
Timestep Consumption Time: 2.49379
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.73279

Cumulative Model Updates: 99,728
Cumulative Timesteps: 831,803,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 831803922...
Checkpoint 831803922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,775.84401
Policy Entropy: 1.83772
Value Function Loss: 0.09247

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.17149
Policy Update Magnitude: 0.50517
Value Function Update Magnitude: 0.36769

Collected Steps per Second: 21,307.94341
Overall Steps per Second: 10,292.29666

Timestep Collection Time: 2.34739
Timestep Consumption Time: 2.51236
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.85975

Cumulative Model Updates: 99,734
Cumulative Timesteps: 831,853,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,793.56839
Policy Entropy: 1.82632
Value Function Loss: 0.09013

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.16686
Policy Update Magnitude: 0.51257
Value Function Update Magnitude: 0.33322

Collected Steps per Second: 22,419.28108
Overall Steps per Second: 10,588.48567

Timestep Collection Time: 2.23058
Timestep Consumption Time: 2.49229
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.72287

Cumulative Model Updates: 99,740
Cumulative Timesteps: 831,903,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 831903948...
Checkpoint 831903948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,341.11403
Policy Entropy: 1.83473
Value Function Loss: 0.08433

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.15347
Policy Update Magnitude: 0.55314
Value Function Update Magnitude: 0.34712

Collected Steps per Second: 21,854.12331
Overall Steps per Second: 10,536.90115

Timestep Collection Time: 2.29037
Timestep Consumption Time: 2.45998
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.75035

Cumulative Model Updates: 99,746
Cumulative Timesteps: 831,954,002

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,702.45532
Policy Entropy: 1.84446
Value Function Loss: 0.08292

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.15664
Policy Update Magnitude: 0.57049
Value Function Update Magnitude: 0.45402

Collected Steps per Second: 21,682.82203
Overall Steps per Second: 10,427.56652

Timestep Collection Time: 2.30597
Timestep Consumption Time: 2.48901
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.79498

Cumulative Model Updates: 99,752
Cumulative Timesteps: 832,004,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 832004002...
Checkpoint 832004002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,589.01018
Policy Entropy: 1.85193
Value Function Loss: 0.08545

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.16260
Policy Update Magnitude: 0.56014
Value Function Update Magnitude: 0.52591

Collected Steps per Second: 20,952.95554
Overall Steps per Second: 10,206.62288

Timestep Collection Time: 2.38649
Timestep Consumption Time: 2.51268
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.89917

Cumulative Model Updates: 99,758
Cumulative Timesteps: 832,054,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,848.14925
Policy Entropy: 1.86350
Value Function Loss: 0.09149

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.17512
Policy Update Magnitude: 0.52374
Value Function Update Magnitude: 0.64208

Collected Steps per Second: 21,681.02634
Overall Steps per Second: 10,479.76310

Timestep Collection Time: 2.30718
Timestep Consumption Time: 2.46602
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.77320

Cumulative Model Updates: 99,764
Cumulative Timesteps: 832,104,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 832104028...
Checkpoint 832104028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,480.85864
Policy Entropy: 1.86505
Value Function Loss: 0.08827

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.15939
Policy Update Magnitude: 0.54252
Value Function Update Magnitude: 0.73775

Collected Steps per Second: 20,823.39338
Overall Steps per Second: 10,169.73672

Timestep Collection Time: 2.40297
Timestep Consumption Time: 2.51731
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.92028

Cumulative Model Updates: 99,770
Cumulative Timesteps: 832,154,066

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,821.74986
Policy Entropy: 1.86058
Value Function Loss: 0.08037

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.15541
Policy Update Magnitude: 0.57024
Value Function Update Magnitude: 0.76445

Collected Steps per Second: 22,118.42020
Overall Steps per Second: 10,512.54203

Timestep Collection Time: 2.26065
Timestep Consumption Time: 2.49576
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.75641

Cumulative Model Updates: 99,776
Cumulative Timesteps: 832,204,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 832204068...
Checkpoint 832204068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,828.02984
Policy Entropy: 1.86992
Value Function Loss: 0.07321

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.58065
Value Function Update Magnitude: 0.71182

Collected Steps per Second: 21,934.84388
Overall Steps per Second: 10,527.46656

Timestep Collection Time: 2.28066
Timestep Consumption Time: 2.47129
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.75195

Cumulative Model Updates: 99,782
Cumulative Timesteps: 832,254,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,429.11254
Policy Entropy: 1.86298
Value Function Loss: 0.07361

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14088
Policy Update Magnitude: 0.56135
Value Function Update Magnitude: 0.71932

Collected Steps per Second: 22,396.34736
Overall Steps per Second: 10,568.26141

Timestep Collection Time: 2.23277
Timestep Consumption Time: 2.49894
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.73171

Cumulative Model Updates: 99,788
Cumulative Timesteps: 832,304,100

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 832304100...
Checkpoint 832304100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,251.28923
Policy Entropy: 1.87432
Value Function Loss: 0.07893

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.58022
Value Function Update Magnitude: 0.73101

Collected Steps per Second: 21,581.04852
Overall Steps per Second: 10,312.48143

Timestep Collection Time: 2.31713
Timestep Consumption Time: 2.53195
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.84908

Cumulative Model Updates: 99,794
Cumulative Timesteps: 832,354,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,124.38419
Policy Entropy: 1.86218
Value Function Loss: 0.07779

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.59733
Value Function Update Magnitude: 0.78454

Collected Steps per Second: 22,206.91534
Overall Steps per Second: 10,320.25819

Timestep Collection Time: 2.25200
Timestep Consumption Time: 2.59381
PPO Batch Consumption Time: 0.30385
Total Iteration Time: 4.84581

Cumulative Model Updates: 99,800
Cumulative Timesteps: 832,404,116

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 832404116...
Checkpoint 832404116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,906.70056
Policy Entropy: 1.87829
Value Function Loss: 0.07827

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.14863
Policy Update Magnitude: 0.58191
Value Function Update Magnitude: 0.71089

Collected Steps per Second: 21,734.44732
Overall Steps per Second: 10,488.27138

Timestep Collection Time: 2.30059
Timestep Consumption Time: 2.46683
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.76742

Cumulative Model Updates: 99,806
Cumulative Timesteps: 832,454,118

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,314.87580
Policy Entropy: 1.87142
Value Function Loss: 0.08148

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14298
Policy Update Magnitude: 0.56623
Value Function Update Magnitude: 0.67670

Collected Steps per Second: 22,203.67944
Overall Steps per Second: 10,648.31731

Timestep Collection Time: 2.25197
Timestep Consumption Time: 2.44380
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.69577

Cumulative Model Updates: 99,812
Cumulative Timesteps: 832,504,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 832504120...
Checkpoint 832504120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,702.79678
Policy Entropy: 1.87606
Value Function Loss: 0.08085

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.13986
Policy Update Magnitude: 0.58919
Value Function Update Magnitude: 0.73198

Collected Steps per Second: 21,585.31898
Overall Steps per Second: 10,513.49153

Timestep Collection Time: 2.31871
Timestep Consumption Time: 2.44184
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.76055

Cumulative Model Updates: 99,818
Cumulative Timesteps: 832,554,170

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,379.10573
Policy Entropy: 1.87930
Value Function Loss: 0.08368

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.15302
Policy Update Magnitude: 0.58140
Value Function Update Magnitude: 0.75371

Collected Steps per Second: 21,856.60016
Overall Steps per Second: 10,525.00277

Timestep Collection Time: 2.28929
Timestep Consumption Time: 2.46473
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.75401

Cumulative Model Updates: 99,824
Cumulative Timesteps: 832,604,206

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 832604206...
Checkpoint 832604206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,722.72603
Policy Entropy: 1.85785
Value Function Loss: 0.07491

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.55675
Value Function Update Magnitude: 0.71633

Collected Steps per Second: 20,616.93546
Overall Steps per Second: 10,248.19003

Timestep Collection Time: 2.42655
Timestep Consumption Time: 2.45509
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.88164

Cumulative Model Updates: 99,830
Cumulative Timesteps: 832,654,234

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,694.07670
Policy Entropy: 1.85266
Value Function Loss: 0.07099

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.56545
Value Function Update Magnitude: 0.66240

Collected Steps per Second: 22,073.14827
Overall Steps per Second: 10,412.13443

Timestep Collection Time: 2.26665
Timestep Consumption Time: 2.53852
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.80516

Cumulative Model Updates: 99,836
Cumulative Timesteps: 832,704,266

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 832704266...
Checkpoint 832704266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,219.77289
Policy Entropy: 1.82716
Value Function Loss: 0.07415

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.57740
Value Function Update Magnitude: 0.64739

Collected Steps per Second: 21,220.50859
Overall Steps per Second: 10,218.77039

Timestep Collection Time: 2.35621
Timestep Consumption Time: 2.53675
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.89296

Cumulative Model Updates: 99,842
Cumulative Timesteps: 832,754,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,289.17178
Policy Entropy: 1.85707
Value Function Loss: 0.08451

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.59256
Value Function Update Magnitude: 0.64651

Collected Steps per Second: 21,908.77472
Overall Steps per Second: 10,422.05248

Timestep Collection Time: 2.28228
Timestep Consumption Time: 2.51543
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.79771

Cumulative Model Updates: 99,848
Cumulative Timesteps: 832,804,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 832804268...
Checkpoint 832804268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,059.12876
Policy Entropy: 1.86767
Value Function Loss: 0.08285

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.58525
Value Function Update Magnitude: 0.63193

Collected Steps per Second: 21,605.48899
Overall Steps per Second: 10,221.07176

Timestep Collection Time: 2.31460
Timestep Consumption Time: 2.57804
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.89264

Cumulative Model Updates: 99,854
Cumulative Timesteps: 832,854,276

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,797.23016
Policy Entropy: 1.85623
Value Function Loss: 0.07952

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.55282
Value Function Update Magnitude: 0.56542

Collected Steps per Second: 22,158.20176
Overall Steps per Second: 10,466.24397

Timestep Collection Time: 2.25740
Timestep Consumption Time: 2.52177
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.77917

Cumulative Model Updates: 99,860
Cumulative Timesteps: 832,904,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 832904296...
Checkpoint 832904296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,068.72397
Policy Entropy: 1.85628
Value Function Loss: 0.07576

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.55624
Value Function Update Magnitude: 0.61871

Collected Steps per Second: 21,679.89493
Overall Steps per Second: 10,352.06865

Timestep Collection Time: 2.30693
Timestep Consumption Time: 2.52437
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.83130

Cumulative Model Updates: 99,866
Cumulative Timesteps: 832,954,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,332.15952
Policy Entropy: 1.88556
Value Function Loss: 0.07894

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13703
Policy Update Magnitude: 0.56175
Value Function Update Magnitude: 0.69357

Collected Steps per Second: 22,409.43849
Overall Steps per Second: 10,688.09734

Timestep Collection Time: 2.23192
Timestep Consumption Time: 2.44768
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.67960

Cumulative Model Updates: 99,872
Cumulative Timesteps: 833,004,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 833004326...
Checkpoint 833004326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,525.42398
Policy Entropy: 1.90746
Value Function Loss: 0.08259

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.54779
Value Function Update Magnitude: 0.69766

Collected Steps per Second: 21,478.78663
Overall Steps per Second: 9,896.82058

Timestep Collection Time: 2.32825
Timestep Consumption Time: 2.72469
PPO Batch Consumption Time: 0.32775
Total Iteration Time: 5.05294

Cumulative Model Updates: 99,878
Cumulative Timesteps: 833,054,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,551.25422
Policy Entropy: 1.89416
Value Function Loss: 0.08588

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13739
Policy Update Magnitude: 0.58514
Value Function Update Magnitude: 0.74350

Collected Steps per Second: 21,502.33980
Overall Steps per Second: 10,400.17399

Timestep Collection Time: 2.32579
Timestep Consumption Time: 2.48278
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.80857

Cumulative Model Updates: 99,884
Cumulative Timesteps: 833,104,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 833104344...
Checkpoint 833104344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,691.88542
Policy Entropy: 1.87193
Value Function Loss: 0.08446

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.14772
Policy Update Magnitude: 0.56280
Value Function Update Magnitude: 0.75932

Collected Steps per Second: 21,943.79361
Overall Steps per Second: 10,623.24616

Timestep Collection Time: 2.27900
Timestep Consumption Time: 2.42860
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.70760

Cumulative Model Updates: 99,890
Cumulative Timesteps: 833,154,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,902.59074
Policy Entropy: 1.86699
Value Function Loss: 0.08130

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.15891
Policy Update Magnitude: 0.50699
Value Function Update Magnitude: 0.70974

Collected Steps per Second: 21,830.04087
Overall Steps per Second: 10,588.36218

Timestep Collection Time: 2.29134
Timestep Consumption Time: 2.43272
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.72405

Cumulative Model Updates: 99,896
Cumulative Timesteps: 833,204,374

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 833204374...
Checkpoint 833204374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,082.48487
Policy Entropy: 1.87846
Value Function Loss: 0.08074

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.53519
Value Function Update Magnitude: 0.63536

Collected Steps per Second: 21,333.12264
Overall Steps per Second: 10,538.26386

Timestep Collection Time: 2.34405
Timestep Consumption Time: 2.40113
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.74518

Cumulative Model Updates: 99,902
Cumulative Timesteps: 833,254,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,932.43680
Policy Entropy: 1.87520
Value Function Loss: 0.07907

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.14579
Policy Update Magnitude: 0.56033
Value Function Update Magnitude: 0.63236

Collected Steps per Second: 21,191.11245
Overall Steps per Second: 10,490.24275

Timestep Collection Time: 2.36137
Timestep Consumption Time: 2.40878
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.77015

Cumulative Model Updates: 99,908
Cumulative Timesteps: 833,304,420

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 833304420...
Checkpoint 833304420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,833.72649
Policy Entropy: 1.86406
Value Function Loss: 0.07561

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.56500
Value Function Update Magnitude: 0.63942

Collected Steps per Second: 20,812.39054
Overall Steps per Second: 10,464.63463

Timestep Collection Time: 2.40347
Timestep Consumption Time: 2.37663
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.78010

Cumulative Model Updates: 99,914
Cumulative Timesteps: 833,354,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,842.08599
Policy Entropy: 1.85694
Value Function Loss: 0.07459

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.56740
Value Function Update Magnitude: 0.61425

Collected Steps per Second: 21,705.74870
Overall Steps per Second: 10,553.54023

Timestep Collection Time: 2.30483
Timestep Consumption Time: 2.43557
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.74040

Cumulative Model Updates: 99,920
Cumulative Timesteps: 833,404,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 833404470...
Checkpoint 833404470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,043.94428
Policy Entropy: 1.87175
Value Function Loss: 0.08554

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.58885
Value Function Update Magnitude: 0.58383

Collected Steps per Second: 21,653.39322
Overall Steps per Second: 10,478.75317

Timestep Collection Time: 2.31095
Timestep Consumption Time: 2.46442
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.77538

Cumulative Model Updates: 99,926
Cumulative Timesteps: 833,454,510

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,234.45110
Policy Entropy: 1.88920
Value Function Loss: 0.09728

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14283
Policy Update Magnitude: 0.61354
Value Function Update Magnitude: 0.59107

Collected Steps per Second: 21,926.58776
Overall Steps per Second: 10,607.41561

Timestep Collection Time: 2.28052
Timestep Consumption Time: 2.43354
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.71406

Cumulative Model Updates: 99,932
Cumulative Timesteps: 833,504,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 833504514...
Checkpoint 833504514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,046.76880
Policy Entropy: 1.89900
Value Function Loss: 0.09945

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.15384
Policy Update Magnitude: 0.59601
Value Function Update Magnitude: 0.65064

Collected Steps per Second: 21,554.56541
Overall Steps per Second: 10,561.00110

Timestep Collection Time: 2.32109
Timestep Consumption Time: 2.41615
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.73724

Cumulative Model Updates: 99,938
Cumulative Timesteps: 833,554,544

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,116.18540
Policy Entropy: 1.88739
Value Function Loss: 0.08586

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.16600
Policy Update Magnitude: 0.52349
Value Function Update Magnitude: 0.57032

Collected Steps per Second: 22,348.31238
Overall Steps per Second: 10,748.55663

Timestep Collection Time: 2.23847
Timestep Consumption Time: 2.41574
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.65421

Cumulative Model Updates: 99,944
Cumulative Timesteps: 833,604,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 833604570...
Checkpoint 833604570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,708.50571
Policy Entropy: 1.86991
Value Function Loss: 0.08492

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.50527
Value Function Update Magnitude: 0.53523

Collected Steps per Second: 21,836.45838
Overall Steps per Second: 10,588.32638

Timestep Collection Time: 2.28975
Timestep Consumption Time: 2.43243
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.72218

Cumulative Model Updates: 99,950
Cumulative Timesteps: 833,654,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,319.96362
Policy Entropy: 1.84893
Value Function Loss: 0.08247

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.54938
Value Function Update Magnitude: 0.47004

Collected Steps per Second: 22,681.91775
Overall Steps per Second: 10,649.78349

Timestep Collection Time: 2.20528
Timestep Consumption Time: 2.49153
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.69681

Cumulative Model Updates: 99,956
Cumulative Timesteps: 833,704,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 833704590...
Checkpoint 833704590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,174.20581
Policy Entropy: 1.85568
Value Function Loss: 0.08742

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.15463
Policy Update Magnitude: 0.52407
Value Function Update Magnitude: 0.50753

Collected Steps per Second: 21,855.56261
Overall Steps per Second: 10,558.26633

Timestep Collection Time: 2.28866
Timestep Consumption Time: 2.44886
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.73752

Cumulative Model Updates: 99,962
Cumulative Timesteps: 833,754,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,673.47043
Policy Entropy: 1.86344
Value Function Loss: 0.08392

Mean KL Divergence: 0.03033
SB3 Clip Fraction: 0.20686
Policy Update Magnitude: 0.44919
Value Function Update Magnitude: 0.60345

Collected Steps per Second: 21,824.92142
Overall Steps per Second: 10,490.57315

Timestep Collection Time: 2.29169
Timestep Consumption Time: 2.47602
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.76771

Cumulative Model Updates: 99,968
Cumulative Timesteps: 833,804,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 833804626...
Checkpoint 833804626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,599.27083
Policy Entropy: 1.87374
Value Function Loss: 0.08791

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.16844
Policy Update Magnitude: 0.44669
Value Function Update Magnitude: 0.55578

Collected Steps per Second: 21,506.56572
Overall Steps per Second: 10,353.29673

Timestep Collection Time: 2.32524
Timestep Consumption Time: 2.50491
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.83015

Cumulative Model Updates: 99,974
Cumulative Timesteps: 833,854,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,528.84688
Policy Entropy: 1.86905
Value Function Loss: 0.09803

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.14425
Policy Update Magnitude: 0.48848
Value Function Update Magnitude: 0.39867

Collected Steps per Second: 21,986.34743
Overall Steps per Second: 10,466.32229

Timestep Collection Time: 2.27450
Timestep Consumption Time: 2.50349
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.77799

Cumulative Model Updates: 99,980
Cumulative Timesteps: 833,904,642

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 833904642...
Checkpoint 833904642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,149.55482
Policy Entropy: 1.85973
Value Function Loss: 0.09317

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.15075
Policy Update Magnitude: 0.53342
Value Function Update Magnitude: 0.31468

Collected Steps per Second: 21,644.85962
Overall Steps per Second: 10,526.02120

Timestep Collection Time: 2.31113
Timestep Consumption Time: 2.44129
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.75241

Cumulative Model Updates: 99,986
Cumulative Timesteps: 833,954,666

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,702.42135
Policy Entropy: 1.85318
Value Function Loss: 0.09670

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.16870
Policy Update Magnitude: 0.54402
Value Function Update Magnitude: 0.29631

Collected Steps per Second: 22,006.50569
Overall Steps per Second: 10,401.56504

Timestep Collection Time: 2.27306
Timestep Consumption Time: 2.53603
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.80908

Cumulative Model Updates: 99,992
Cumulative Timesteps: 834,004,688

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 834004688...
Checkpoint 834004688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,119.61571
Policy Entropy: 1.85553
Value Function Loss: 0.09872

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.16334
Policy Update Magnitude: 0.53632
Value Function Update Magnitude: 0.25625

Collected Steps per Second: 21,747.87634
Overall Steps per Second: 10,318.72868

Timestep Collection Time: 2.30045
Timestep Consumption Time: 2.54801
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.84847

Cumulative Model Updates: 99,998
Cumulative Timesteps: 834,054,718

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,514.16655
Policy Entropy: 1.87024
Value Function Loss: 0.10514

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.15028
Policy Update Magnitude: 0.52854
Value Function Update Magnitude: 0.25265

Collected Steps per Second: 22,596.26545
Overall Steps per Second: 10,712.96663

Timestep Collection Time: 2.21337
Timestep Consumption Time: 2.45517
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.66855

Cumulative Model Updates: 100,004
Cumulative Timesteps: 834,104,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 834104732...
Checkpoint 834104732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,084.02592
Policy Entropy: 1.87760
Value Function Loss: 0.10438

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.16169
Policy Update Magnitude: 0.51464
Value Function Update Magnitude: 0.23889

Collected Steps per Second: 22,001.68425
Overall Steps per Second: 10,611.37260

Timestep Collection Time: 2.27283
Timestep Consumption Time: 2.43967
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.71249

Cumulative Model Updates: 100,010
Cumulative Timesteps: 834,154,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,410.74542
Policy Entropy: 1.89089
Value Function Loss: 0.08952

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.16027
Policy Update Magnitude: 0.52697
Value Function Update Magnitude: 0.30950

Collected Steps per Second: 22,327.63496
Overall Steps per Second: 10,542.18884

Timestep Collection Time: 2.23956
Timestep Consumption Time: 2.50367
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.74323

Cumulative Model Updates: 100,016
Cumulative Timesteps: 834,204,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 834204742...
Checkpoint 834204742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,101.70320
Policy Entropy: 1.89525
Value Function Loss: 0.08697

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.15590
Policy Update Magnitude: 0.52742
Value Function Update Magnitude: 0.52813

Collected Steps per Second: 22,298.57679
Overall Steps per Second: 10,668.44950

Timestep Collection Time: 2.24418
Timestep Consumption Time: 2.44647
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.69065

Cumulative Model Updates: 100,022
Cumulative Timesteps: 834,254,784

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,971.56598
Policy Entropy: 1.88671
Value Function Loss: 0.08261

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.16061
Policy Update Magnitude: 0.50973
Value Function Update Magnitude: 0.53441

Collected Steps per Second: 22,357.76511
Overall Steps per Second: 10,521.26705

Timestep Collection Time: 2.23672
Timestep Consumption Time: 2.51632
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.75304

Cumulative Model Updates: 100,028
Cumulative Timesteps: 834,304,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 834304792...
Checkpoint 834304792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,796.91712
Policy Entropy: 1.90365
Value Function Loss: 0.09004

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.15350
Policy Update Magnitude: 0.53687
Value Function Update Magnitude: 0.55545

Collected Steps per Second: 21,936.08246
Overall Steps per Second: 10,619.47895

Timestep Collection Time: 2.28063
Timestep Consumption Time: 2.43034
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.71097

Cumulative Model Updates: 100,034
Cumulative Timesteps: 834,354,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,588.66555
Policy Entropy: 1.88842
Value Function Loss: 0.09013

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.16648
Policy Update Magnitude: 0.53496
Value Function Update Magnitude: 0.58643

Collected Steps per Second: 22,001.16960
Overall Steps per Second: 10,416.07798

Timestep Collection Time: 2.27361
Timestep Consumption Time: 2.52878
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.80238

Cumulative Model Updates: 100,040
Cumulative Timesteps: 834,404,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 834404842...
Checkpoint 834404842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,129.21309
Policy Entropy: 1.90760
Value Function Loss: 0.09323

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.15508
Policy Update Magnitude: 0.54354
Value Function Update Magnitude: 0.61936

Collected Steps per Second: 21,599.10202
Overall Steps per Second: 10,530.11012

Timestep Collection Time: 2.31630
Timestep Consumption Time: 2.43484
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.75114

Cumulative Model Updates: 100,046
Cumulative Timesteps: 834,454,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,951.03950
Policy Entropy: 1.89620
Value Function Loss: 0.08796

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.16104
Policy Update Magnitude: 0.58587
Value Function Update Magnitude: 0.64083

Collected Steps per Second: 21,937.23556
Overall Steps per Second: 10,518.57478

Timestep Collection Time: 2.27969
Timestep Consumption Time: 2.47476
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.75445

Cumulative Model Updates: 100,052
Cumulative Timesteps: 834,504,882

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 834504882...
Checkpoint 834504882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,361.08115
Policy Entropy: 1.90029
Value Function Loss: 0.08943

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.16269
Policy Update Magnitude: 0.58577
Value Function Update Magnitude: 0.62801

Collected Steps per Second: 21,969.98530
Overall Steps per Second: 10,593.87144

Timestep Collection Time: 2.27747
Timestep Consumption Time: 2.44564
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.72311

Cumulative Model Updates: 100,058
Cumulative Timesteps: 834,554,918

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,160.54893
Policy Entropy: 1.90023
Value Function Loss: 0.08259

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14895
Policy Update Magnitude: 0.60139
Value Function Update Magnitude: 0.65354

Collected Steps per Second: 21,984.92090
Overall Steps per Second: 10,557.39310

Timestep Collection Time: 2.27620
Timestep Consumption Time: 2.46380
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.74000

Cumulative Model Updates: 100,064
Cumulative Timesteps: 834,604,960

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 834604960...
Checkpoint 834604960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,410.72733
Policy Entropy: 1.90531
Value Function Loss: 0.08038

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.59939
Value Function Update Magnitude: 0.65286

Collected Steps per Second: 22,164.32506
Overall Steps per Second: 10,592.15192

Timestep Collection Time: 2.25588
Timestep Consumption Time: 2.46460
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.72048

Cumulative Model Updates: 100,070
Cumulative Timesteps: 834,654,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,494.39496
Policy Entropy: 1.90174
Value Function Loss: 0.07803

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.58517
Value Function Update Magnitude: 0.62972

Collected Steps per Second: 22,442.30066
Overall Steps per Second: 10,548.25096

Timestep Collection Time: 2.22909
Timestep Consumption Time: 2.51349
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.74259

Cumulative Model Updates: 100,076
Cumulative Timesteps: 834,704,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 834704986...
Checkpoint 834704986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,251.34868
Policy Entropy: 1.89225
Value Function Loss: 0.08022

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.14030
Policy Update Magnitude: 0.58361
Value Function Update Magnitude: 0.65891

Collected Steps per Second: 22,330.37731
Overall Steps per Second: 10,546.78973

Timestep Collection Time: 2.23919
Timestep Consumption Time: 2.50178
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.74097

Cumulative Model Updates: 100,082
Cumulative Timesteps: 834,754,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,008.82907
Policy Entropy: 1.90109
Value Function Loss: 0.08316

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.58438
Value Function Update Magnitude: 0.68280

Collected Steps per Second: 22,303.13981
Overall Steps per Second: 10,498.49685

Timestep Collection Time: 2.24291
Timestep Consumption Time: 2.52196
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.76487

Cumulative Model Updates: 100,088
Cumulative Timesteps: 834,805,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 834805012...
Checkpoint 834805012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,246.78808
Policy Entropy: 1.92205
Value Function Loss: 0.07882

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.57178
Value Function Update Magnitude: 0.69068

Collected Steps per Second: 22,177.09869
Overall Steps per Second: 10,659.33290

Timestep Collection Time: 2.25593
Timestep Consumption Time: 2.43761
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.69354

Cumulative Model Updates: 100,094
Cumulative Timesteps: 834,855,042

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,538.54128
Policy Entropy: 1.93097
Value Function Loss: 0.07845

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.58283
Value Function Update Magnitude: 0.62287

Collected Steps per Second: 22,404.15822
Overall Steps per Second: 10,535.27113

Timestep Collection Time: 2.23280
Timestep Consumption Time: 2.51544
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.74824

Cumulative Model Updates: 100,100
Cumulative Timesteps: 834,905,066

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 834905066...
Checkpoint 834905066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,302.66222
Policy Entropy: 1.93168
Value Function Loss: 0.07674

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.58863
Value Function Update Magnitude: 0.58318

Collected Steps per Second: 21,804.96447
Overall Steps per Second: 10,584.25341

Timestep Collection Time: 2.29434
Timestep Consumption Time: 2.43230
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.72664

Cumulative Model Updates: 100,106
Cumulative Timesteps: 834,955,094

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,509.66556
Policy Entropy: 1.91240
Value Function Loss: 0.07879

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.58685
Value Function Update Magnitude: 0.59774

Collected Steps per Second: 22,120.44175
Overall Steps per Second: 10,448.46689

Timestep Collection Time: 2.26234
Timestep Consumption Time: 2.52726
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.78960

Cumulative Model Updates: 100,112
Cumulative Timesteps: 835,005,138

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 835005138...
Checkpoint 835005138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,293.51768
Policy Entropy: 1.92132
Value Function Loss: 0.07789

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.58290
Value Function Update Magnitude: 0.65503

Collected Steps per Second: 21,531.62523
Overall Steps per Second: 10,479.50681

Timestep Collection Time: 2.32235
Timestep Consumption Time: 2.44925
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.77160

Cumulative Model Updates: 100,118
Cumulative Timesteps: 835,055,142

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,382.98094
Policy Entropy: 1.90390
Value Function Loss: 0.07390

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.57779
Value Function Update Magnitude: 0.69131

Collected Steps per Second: 22,121.68012
Overall Steps per Second: 10,625.55581

Timestep Collection Time: 2.26167
Timestep Consumption Time: 2.44698
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.70865

Cumulative Model Updates: 100,124
Cumulative Timesteps: 835,105,174

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 835105174...
Checkpoint 835105174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,539.02100
Policy Entropy: 1.92685
Value Function Loss: 0.07861

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.58561
Value Function Update Magnitude: 0.64719

Collected Steps per Second: 21,712.54768
Overall Steps per Second: 10,513.95379

Timestep Collection Time: 2.30355
Timestep Consumption Time: 2.45355
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.75711

Cumulative Model Updates: 100,130
Cumulative Timesteps: 835,155,190

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,174.26550
Policy Entropy: 1.91634
Value Function Loss: 0.08203

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.60151
Value Function Update Magnitude: 0.67662

Collected Steps per Second: 22,231.67118
Overall Steps per Second: 10,482.40401

Timestep Collection Time: 2.24904
Timestep Consumption Time: 2.52085
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.76990

Cumulative Model Updates: 100,136
Cumulative Timesteps: 835,205,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 835205190...
Checkpoint 835205190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,964.12329
Policy Entropy: 1.92740
Value Function Loss: 0.08712

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.60740
Value Function Update Magnitude: 0.65254

Collected Steps per Second: 22,125.72858
Overall Steps per Second: 10,633.19028

Timestep Collection Time: 2.26090
Timestep Consumption Time: 2.44362
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.70451

Cumulative Model Updates: 100,142
Cumulative Timesteps: 835,255,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,485.18310
Policy Entropy: 1.92024
Value Function Loss: 0.08909

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.14018
Policy Update Magnitude: 0.58509
Value Function Update Magnitude: 0.68428

Collected Steps per Second: 22,470.41890
Overall Steps per Second: 10,597.20934

Timestep Collection Time: 2.22577
Timestep Consumption Time: 2.49377
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.71954

Cumulative Model Updates: 100,148
Cumulative Timesteps: 835,305,228

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 835305228...
Checkpoint 835305228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,094.23007
Policy Entropy: 1.91831
Value Function Loss: 0.08468

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.15745
Policy Update Magnitude: 0.55095
Value Function Update Magnitude: 0.73417

Collected Steps per Second: 21,384.89789
Overall Steps per Second: 10,201.99610

Timestep Collection Time: 2.33885
Timestep Consumption Time: 2.56372
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.90257

Cumulative Model Updates: 100,154
Cumulative Timesteps: 835,355,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,789.50048
Policy Entropy: 1.90955
Value Function Loss: 0.08212

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.14893
Policy Update Magnitude: 0.55465
Value Function Update Magnitude: 0.67830

Collected Steps per Second: 22,503.29071
Overall Steps per Second: 10,611.30086

Timestep Collection Time: 2.22323
Timestep Consumption Time: 2.49155
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.71478

Cumulative Model Updates: 100,160
Cumulative Timesteps: 835,405,274

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 835405274...
Checkpoint 835405274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,384.99817
Policy Entropy: 1.91446
Value Function Loss: 0.08374

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.15148
Policy Update Magnitude: 0.54696
Value Function Update Magnitude: 0.64501

Collected Steps per Second: 22,151.16389
Overall Steps per Second: 10,511.96665

Timestep Collection Time: 2.25830
Timestep Consumption Time: 2.50047
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.75877

Cumulative Model Updates: 100,166
Cumulative Timesteps: 835,455,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,435.81165
Policy Entropy: 1.91359
Value Function Loss: 0.08379

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.15811
Policy Update Magnitude: 0.54808
Value Function Update Magnitude: 0.73520

Collected Steps per Second: 21,862.12362
Overall Steps per Second: 10,466.52792

Timestep Collection Time: 2.28825
Timestep Consumption Time: 2.49137
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.77962

Cumulative Model Updates: 100,172
Cumulative Timesteps: 835,505,324

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 835505324...
Checkpoint 835505324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,766.77025
Policy Entropy: 1.92517
Value Function Loss: 0.08364

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.14887
Policy Update Magnitude: 0.56488
Value Function Update Magnitude: 0.70044

Collected Steps per Second: 21,491.38289
Overall Steps per Second: 10,535.61608

Timestep Collection Time: 2.32782
Timestep Consumption Time: 2.42065
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.74846

Cumulative Model Updates: 100,178
Cumulative Timesteps: 835,555,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,992.39550
Policy Entropy: 1.93042
Value Function Loss: 0.08457

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.56764
Value Function Update Magnitude: 0.57129

Collected Steps per Second: 21,779.15003
Overall Steps per Second: 10,535.04131

Timestep Collection Time: 2.29605
Timestep Consumption Time: 2.45059
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.74664

Cumulative Model Updates: 100,184
Cumulative Timesteps: 835,605,358

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 835605358...
Checkpoint 835605358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,726.14473
Policy Entropy: 1.94042
Value Function Loss: 0.08856

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.15174
Policy Update Magnitude: 0.52357
Value Function Update Magnitude: 0.47070

Collected Steps per Second: 21,848.64693
Overall Steps per Second: 10,654.28909

Timestep Collection Time: 2.28957
Timestep Consumption Time: 2.40563
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.69520

Cumulative Model Updates: 100,190
Cumulative Timesteps: 835,655,382

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,422.69645
Policy Entropy: 1.92103
Value Function Loss: 0.08875

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.15630
Policy Update Magnitude: 0.54245
Value Function Update Magnitude: 0.41645

Collected Steps per Second: 22,228.00896
Overall Steps per Second: 10,417.90567

Timestep Collection Time: 2.25112
Timestep Consumption Time: 2.55195
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.80308

Cumulative Model Updates: 100,196
Cumulative Timesteps: 835,705,420

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 835705420...
Checkpoint 835705420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,346.65302
Policy Entropy: 1.88143
Value Function Loss: 0.08282

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.15606
Policy Update Magnitude: 0.51241
Value Function Update Magnitude: 0.54561

Collected Steps per Second: 22,182.47491
Overall Steps per Second: 10,558.06292

Timestep Collection Time: 2.25502
Timestep Consumption Time: 2.48278
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.73780

Cumulative Model Updates: 100,202
Cumulative Timesteps: 835,755,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,775.21185
Policy Entropy: 1.88551
Value Function Loss: 0.07568

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.14759
Policy Update Magnitude: 0.53924
Value Function Update Magnitude: 0.54932

Collected Steps per Second: 21,903.50787
Overall Steps per Second: 10,526.61051

Timestep Collection Time: 2.28292
Timestep Consumption Time: 2.46732
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.75025

Cumulative Model Updates: 100,208
Cumulative Timesteps: 835,805,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 835805446...
Checkpoint 835805446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,446.75041
Policy Entropy: 1.89885
Value Function Loss: 0.07209

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.54756
Value Function Update Magnitude: 0.58115

Collected Steps per Second: 22,081.88971
Overall Steps per Second: 10,601.04555

Timestep Collection Time: 2.26548
Timestep Consumption Time: 2.45349
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.71897

Cumulative Model Updates: 100,214
Cumulative Timesteps: 835,855,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,126.88567
Policy Entropy: 1.91513
Value Function Loss: 0.07259

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.15314
Policy Update Magnitude: 0.51900
Value Function Update Magnitude: 0.67224

Collected Steps per Second: 22,427.78484
Overall Steps per Second: 10,520.31806

Timestep Collection Time: 2.23027
Timestep Consumption Time: 2.52434
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.75461

Cumulative Model Updates: 100,220
Cumulative Timesteps: 835,905,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 835905492...
Checkpoint 835905492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,269.59172
Policy Entropy: 1.90930
Value Function Loss: 0.07120

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.54992
Value Function Update Magnitude: 0.70933

Collected Steps per Second: 21,942.20931
Overall Steps per Second: 10,606.20016

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.43610
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.71536

Cumulative Model Updates: 100,226
Cumulative Timesteps: 835,955,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,215.48974
Policy Entropy: 1.91784
Value Function Loss: 0.07237

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.57610
Value Function Update Magnitude: 0.75490

Collected Steps per Second: 22,249.38318
Overall Steps per Second: 10,548.00339

Timestep Collection Time: 2.24734
Timestep Consumption Time: 2.49308
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.74042

Cumulative Model Updates: 100,232
Cumulative Timesteps: 836,005,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 836005506...
Checkpoint 836005506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,128.12227
Policy Entropy: 1.91732
Value Function Loss: 0.06804

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.57224
Value Function Update Magnitude: 0.67320

Collected Steps per Second: 21,836.20948
Overall Steps per Second: 10,549.36582

Timestep Collection Time: 2.28977
Timestep Consumption Time: 2.44985
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.73962

Cumulative Model Updates: 100,238
Cumulative Timesteps: 836,055,506

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,267.97476
Policy Entropy: 1.91557
Value Function Loss: 0.07817

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.57673
Value Function Update Magnitude: 0.59857

Collected Steps per Second: 21,977.86943
Overall Steps per Second: 10,511.55919

Timestep Collection Time: 2.27629
Timestep Consumption Time: 2.48304
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.75933

Cumulative Model Updates: 100,244
Cumulative Timesteps: 836,105,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 836105534...
Checkpoint 836105534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,372.76482
Policy Entropy: 1.92146
Value Function Loss: 0.07763

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.57850
Value Function Update Magnitude: 0.67363

Collected Steps per Second: 21,660.44905
Overall Steps per Second: 10,586.53466

Timestep Collection Time: 2.30882
Timestep Consumption Time: 2.41511
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.72393

Cumulative Model Updates: 100,250
Cumulative Timesteps: 836,155,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,290.91268
Policy Entropy: 1.92025
Value Function Loss: 0.07596

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.58423
Value Function Update Magnitude: 0.69155

Collected Steps per Second: 21,743.40719
Overall Steps per Second: 10,530.39041

Timestep Collection Time: 2.30010
Timestep Consumption Time: 2.44920
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.74930

Cumulative Model Updates: 100,256
Cumulative Timesteps: 836,205,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 836205556...
Checkpoint 836205556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,033.98402
Policy Entropy: 1.93261
Value Function Loss: 0.07235

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.57541
Value Function Update Magnitude: 0.66037

Collected Steps per Second: 21,454.97658
Overall Steps per Second: 10,492.51781

Timestep Collection Time: 2.33074
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.76587

Cumulative Model Updates: 100,262
Cumulative Timesteps: 836,255,562

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,749.02045
Policy Entropy: 1.93162
Value Function Loss: 0.07154

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.57252
Value Function Update Magnitude: 0.65703

Collected Steps per Second: 22,022.14017
Overall Steps per Second: 10,591.12113

Timestep Collection Time: 2.27062
Timestep Consumption Time: 2.45069
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.72131

Cumulative Model Updates: 100,268
Cumulative Timesteps: 836,305,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 836305566...
Checkpoint 836305566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,322.58994
Policy Entropy: 1.95673
Value Function Loss: 0.07792

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.57777
Value Function Update Magnitude: 0.68158

Collected Steps per Second: 22,236.27570
Overall Steps per Second: 10,595.75383

Timestep Collection Time: 2.24903
Timestep Consumption Time: 2.47079
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.71982

Cumulative Model Updates: 100,274
Cumulative Timesteps: 836,355,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,087.55535
Policy Entropy: 1.94524
Value Function Loss: 0.07877

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.58026
Value Function Update Magnitude: 0.63759

Collected Steps per Second: 22,319.55139
Overall Steps per Second: 10,502.51737

Timestep Collection Time: 2.24144
Timestep Consumption Time: 2.52199
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.76343

Cumulative Model Updates: 100,280
Cumulative Timesteps: 836,405,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 836405604...
Checkpoint 836405604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,759.00569
Policy Entropy: 1.94728
Value Function Loss: 0.08867

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.59435
Value Function Update Magnitude: 0.58620

Collected Steps per Second: 21,924.26028
Overall Steps per Second: 10,471.96052

Timestep Collection Time: 2.28076
Timestep Consumption Time: 2.49428
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.77504

Cumulative Model Updates: 100,286
Cumulative Timesteps: 836,455,608

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,874.06543
Policy Entropy: 1.93461
Value Function Loss: 0.08127

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13598
Policy Update Magnitude: 0.59934
Value Function Update Magnitude: 0.66697

Collected Steps per Second: 22,440.02274
Overall Steps per Second: 10,552.66158

Timestep Collection Time: 2.22905
Timestep Consumption Time: 2.51098
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.74004

Cumulative Model Updates: 100,292
Cumulative Timesteps: 836,505,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 836505628...
Checkpoint 836505628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,999.23166
Policy Entropy: 1.92653
Value Function Loss: 0.07961

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.58981
Value Function Update Magnitude: 0.74246

Collected Steps per Second: 22,351.01438
Overall Steps per Second: 10,714.73373

Timestep Collection Time: 2.23865
Timestep Consumption Time: 2.43119
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.66983

Cumulative Model Updates: 100,298
Cumulative Timesteps: 836,555,664

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,588.27010
Policy Entropy: 1.91235
Value Function Loss: 0.07358

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.58908
Value Function Update Magnitude: 0.72215

Collected Steps per Second: 21,930.84571
Overall Steps per Second: 10,383.18969

Timestep Collection Time: 2.28071
Timestep Consumption Time: 2.53649
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.81721

Cumulative Model Updates: 100,304
Cumulative Timesteps: 836,605,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 836605682...
Checkpoint 836605682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,862.84205
Policy Entropy: 1.92160
Value Function Loss: 0.07010

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.58465
Value Function Update Magnitude: 0.70574

Collected Steps per Second: 21,835.54785
Overall Steps per Second: 10,588.94683

Timestep Collection Time: 2.29103
Timestep Consumption Time: 2.43333
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.72436

Cumulative Model Updates: 100,310
Cumulative Timesteps: 836,655,708

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,380.12143
Policy Entropy: 1.91865
Value Function Loss: 0.06675

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.57869
Value Function Update Magnitude: 0.68941

Collected Steps per Second: 21,750.99936
Overall Steps per Second: 10,531.33452

Timestep Collection Time: 2.29994
Timestep Consumption Time: 2.45026
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.75021

Cumulative Model Updates: 100,316
Cumulative Timesteps: 836,705,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 836705734...
Checkpoint 836705734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,815.10679
Policy Entropy: 1.92022
Value Function Loss: 0.06495

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.57209
Value Function Update Magnitude: 0.65808

Collected Steps per Second: 19,694.60057
Overall Steps per Second: 9,710.04814

Timestep Collection Time: 2.53897
Timestep Consumption Time: 2.61075
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 5.14972

Cumulative Model Updates: 100,322
Cumulative Timesteps: 836,755,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,528.51817
Policy Entropy: 1.91763
Value Function Loss: 0.06670

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.56816
Value Function Update Magnitude: 0.56938

Collected Steps per Second: 20,747.30955
Overall Steps per Second: 10,055.07682

Timestep Collection Time: 2.41140
Timestep Consumption Time: 2.56420
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.97560

Cumulative Model Updates: 100,328
Cumulative Timesteps: 836,805,768

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 836805768...
Checkpoint 836805768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,819.48086
Policy Entropy: 1.91539
Value Function Loss: 0.06821

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.54184
Value Function Update Magnitude: 0.56690

Collected Steps per Second: 21,485.87682
Overall Steps per Second: 10,306.07646

Timestep Collection Time: 2.32804
Timestep Consumption Time: 2.52541
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.85345

Cumulative Model Updates: 100,334
Cumulative Timesteps: 836,855,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,356.44123
Policy Entropy: 1.91230
Value Function Loss: 0.06600

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14310
Policy Update Magnitude: 0.53741
Value Function Update Magnitude: 0.57883

Collected Steps per Second: 20,277.16586
Overall Steps per Second: 10,037.59039

Timestep Collection Time: 2.46662
Timestep Consumption Time: 2.51625
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.98287

Cumulative Model Updates: 100,340
Cumulative Timesteps: 836,905,804

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 836905804...
Checkpoint 836905804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,632.21828
Policy Entropy: 1.89905
Value Function Loss: 0.06471

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.15436
Policy Update Magnitude: 0.53165
Value Function Update Magnitude: 0.62369

Collected Steps per Second: 21,756.22808
Overall Steps per Second: 10,556.75290

Timestep Collection Time: 2.30021
Timestep Consumption Time: 2.44026
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.74047

Cumulative Model Updates: 100,346
Cumulative Timesteps: 836,955,848

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,766.55484
Policy Entropy: 1.89036
Value Function Loss: 0.06647

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.14573
Policy Update Magnitude: 0.55278
Value Function Update Magnitude: 0.59450

Collected Steps per Second: 22,401.90030
Overall Steps per Second: 10,622.22108

Timestep Collection Time: 2.23240
Timestep Consumption Time: 2.47566
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.70805

Cumulative Model Updates: 100,352
Cumulative Timesteps: 837,005,858

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 837005858...
Checkpoint 837005858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,662.21042
Policy Entropy: 1.90222
Value Function Loss: 0.07229

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.15397
Policy Update Magnitude: 0.54781
Value Function Update Magnitude: 0.58224

Collected Steps per Second: 22,157.94012
Overall Steps per Second: 10,537.81664

Timestep Collection Time: 2.25779
Timestep Consumption Time: 2.48968
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.74747

Cumulative Model Updates: 100,358
Cumulative Timesteps: 837,055,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,703.60953
Policy Entropy: 1.92071
Value Function Loss: 0.08169

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.15409
Policy Update Magnitude: 0.53408
Value Function Update Magnitude: 0.60596

Collected Steps per Second: 22,394.01752
Overall Steps per Second: 10,480.94349

Timestep Collection Time: 2.23399
Timestep Consumption Time: 2.53924
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.77323

Cumulative Model Updates: 100,364
Cumulative Timesteps: 837,105,914

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 837105914...
Checkpoint 837105914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,800.68414
Policy Entropy: 1.92954
Value Function Loss: 0.08185

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.15757
Policy Update Magnitude: 0.57174
Value Function Update Magnitude: 0.60857

Collected Steps per Second: 22,244.07229
Overall Steps per Second: 10,684.14644

Timestep Collection Time: 2.24815
Timestep Consumption Time: 2.43243
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.68058

Cumulative Model Updates: 100,370
Cumulative Timesteps: 837,155,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,359.25173
Policy Entropy: 1.92670
Value Function Loss: 0.08117

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.15128
Policy Update Magnitude: 0.57743
Value Function Update Magnitude: 0.66542

Collected Steps per Second: 22,123.85955
Overall Steps per Second: 10,442.69060

Timestep Collection Time: 2.26018
Timestep Consumption Time: 2.52824
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.78842

Cumulative Model Updates: 100,376
Cumulative Timesteps: 837,205,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 837205926...
Checkpoint 837205926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,052.49696
Policy Entropy: 1.90885
Value Function Loss: 0.07494

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.15298
Policy Update Magnitude: 0.58135
Value Function Update Magnitude: 0.69067

Collected Steps per Second: 20,902.96740
Overall Steps per Second: 10,170.44195

Timestep Collection Time: 2.39239
Timestep Consumption Time: 2.52461
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.91699

Cumulative Model Updates: 100,382
Cumulative Timesteps: 837,255,934

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,588.01121
Policy Entropy: 1.90438
Value Function Loss: 0.07149

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.15401
Policy Update Magnitude: 0.57692
Value Function Update Magnitude: 0.64366

Collected Steps per Second: 22,046.21349
Overall Steps per Second: 10,499.72574

Timestep Collection Time: 2.26914
Timestep Consumption Time: 2.49536
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.76451

Cumulative Model Updates: 100,388
Cumulative Timesteps: 837,305,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 837305960...
Checkpoint 837305960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,863.07146
Policy Entropy: 1.90014
Value Function Loss: 0.06695

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.57515
Value Function Update Magnitude: 0.57656

Collected Steps per Second: 21,534.89620
Overall Steps per Second: 10,534.57735

Timestep Collection Time: 2.32218
Timestep Consumption Time: 2.42485
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.74703

Cumulative Model Updates: 100,394
Cumulative Timesteps: 837,355,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,576.25371
Policy Entropy: 1.90952
Value Function Loss: 0.06436

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.56913
Value Function Update Magnitude: 0.57568

Collected Steps per Second: 21,909.74977
Overall Steps per Second: 10,571.35134

Timestep Collection Time: 2.28291
Timestep Consumption Time: 2.44856
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.73147

Cumulative Model Updates: 100,400
Cumulative Timesteps: 837,405,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 837405986...
Checkpoint 837405986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,514.54058
Policy Entropy: 1.91504
Value Function Loss: 0.06656

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.56936
Value Function Update Magnitude: 0.54015

Collected Steps per Second: 22,118.90928
Overall Steps per Second: 10,550.46764

Timestep Collection Time: 2.26187
Timestep Consumption Time: 2.48010
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.74197

Cumulative Model Updates: 100,406
Cumulative Timesteps: 837,456,016

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,445.86904
Policy Entropy: 1.92181
Value Function Loss: 0.06761

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.56546
Value Function Update Magnitude: 0.44811

Collected Steps per Second: 22,389.03163
Overall Steps per Second: 10,486.86104

Timestep Collection Time: 2.23359
Timestep Consumption Time: 2.53504
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.76863

Cumulative Model Updates: 100,412
Cumulative Timesteps: 837,506,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 837506024...
Checkpoint 837506024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,352.48653
Policy Entropy: 1.92361
Value Function Loss: 0.06888

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.54061
Value Function Update Magnitude: 0.45958

Collected Steps per Second: 21,784.88597
Overall Steps per Second: 10,551.16306

Timestep Collection Time: 2.29609
Timestep Consumption Time: 2.44462
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.74071

Cumulative Model Updates: 100,418
Cumulative Timesteps: 837,556,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,141.29464
Policy Entropy: 1.93224
Value Function Loss: 0.06935

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.55478
Value Function Update Magnitude: 0.53717

Collected Steps per Second: 22,440.45084
Overall Steps per Second: 10,593.62348

Timestep Collection Time: 2.22910
Timestep Consumption Time: 2.49280
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.72190

Cumulative Model Updates: 100,424
Cumulative Timesteps: 837,606,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 837606066...
Checkpoint 837606066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,376.41057
Policy Entropy: 1.94419
Value Function Loss: 0.07343

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.56466
Value Function Update Magnitude: 0.54087

Collected Steps per Second: 22,104.30725
Overall Steps per Second: 10,618.28351

Timestep Collection Time: 2.26282
Timestep Consumption Time: 2.44774
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.71055

Cumulative Model Updates: 100,430
Cumulative Timesteps: 837,656,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,216.32072
Policy Entropy: 1.94472
Value Function Loss: 0.07182

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.56411
Value Function Update Magnitude: 0.61253

Collected Steps per Second: 22,379.71240
Overall Steps per Second: 10,538.52570

Timestep Collection Time: 2.23533
Timestep Consumption Time: 2.51164
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.74696

Cumulative Model Updates: 100,436
Cumulative Timesteps: 837,706,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 837706110...
Checkpoint 837706110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,728.60466
Policy Entropy: 1.94269
Value Function Loss: 0.06842

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.55161
Value Function Update Magnitude: 0.65314

Collected Steps per Second: 21,844.38040
Overall Steps per Second: 10,554.26271

Timestep Collection Time: 2.29020
Timestep Consumption Time: 2.44988
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.74008

Cumulative Model Updates: 100,442
Cumulative Timesteps: 837,756,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,881.94380
Policy Entropy: 1.94967
Value Function Loss: 0.06719

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.54460

Collected Steps per Second: 21,799.63867
Overall Steps per Second: 10,409.65157

Timestep Collection Time: 2.29444
Timestep Consumption Time: 2.51052
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.80496

Cumulative Model Updates: 100,448
Cumulative Timesteps: 837,806,156

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 837806156...
Checkpoint 837806156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,707.64722
Policy Entropy: 1.95652
Value Function Loss: 0.07220

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.53376
Value Function Update Magnitude: 0.45917

Collected Steps per Second: 21,228.16804
Overall Steps per Second: 10,229.81176

Timestep Collection Time: 2.35574
Timestep Consumption Time: 2.53272
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.88846

Cumulative Model Updates: 100,454
Cumulative Timesteps: 837,856,164

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,832.19348
Policy Entropy: 1.92268
Value Function Loss: 0.07342

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.53178
Value Function Update Magnitude: 0.41078

Collected Steps per Second: 22,212.94055
Overall Steps per Second: 10,468.14564

Timestep Collection Time: 2.25103
Timestep Consumption Time: 2.52556
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.77659

Cumulative Model Updates: 100,460
Cumulative Timesteps: 837,906,166

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 837906166...
Checkpoint 837906166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,970.38970
Policy Entropy: 1.90724
Value Function Loss: 0.06957

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.16727
Policy Update Magnitude: 0.48580
Value Function Update Magnitude: 0.42729

Collected Steps per Second: 21,796.82568
Overall Steps per Second: 10,418.86201

Timestep Collection Time: 2.29391
Timestep Consumption Time: 2.50508
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.79899

Cumulative Model Updates: 100,466
Cumulative Timesteps: 837,956,166

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,756.85808
Policy Entropy: 1.90774
Value Function Loss: 0.06808

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.15622
Policy Update Magnitude: 0.49628
Value Function Update Magnitude: 0.41681

Collected Steps per Second: 21,943.29432
Overall Steps per Second: 10,438.64452

Timestep Collection Time: 2.27915
Timestep Consumption Time: 2.51190
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.79104

Cumulative Model Updates: 100,472
Cumulative Timesteps: 838,006,178

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 838006178...
Checkpoint 838006178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,309.66294
Policy Entropy: 1.93820
Value Function Loss: 0.07451

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.15644
Policy Update Magnitude: 0.53800
Value Function Update Magnitude: 0.48628

Collected Steps per Second: 21,901.46783
Overall Steps per Second: 10,514.81776

Timestep Collection Time: 2.28341
Timestep Consumption Time: 2.47274
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.75615

Cumulative Model Updates: 100,478
Cumulative Timesteps: 838,056,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,150.80398
Policy Entropy: 1.96037
Value Function Loss: 0.07465

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.15157
Policy Update Magnitude: 0.55840
Value Function Update Magnitude: 0.61024

Collected Steps per Second: 22,644.16752
Overall Steps per Second: 10,729.44200

Timestep Collection Time: 2.20843
Timestep Consumption Time: 2.45239
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.66082

Cumulative Model Updates: 100,484
Cumulative Timesteps: 838,106,196

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 838106196...
Checkpoint 838106196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,201.31620
Policy Entropy: 1.97214
Value Function Loss: 0.07732

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.57270
Value Function Update Magnitude: 0.60177

Collected Steps per Second: 21,921.75871
Overall Steps per Second: 10,648.66288

Timestep Collection Time: 2.28139
Timestep Consumption Time: 2.41517
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.69655

Cumulative Model Updates: 100,490
Cumulative Timesteps: 838,156,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,898.56162
Policy Entropy: 1.97299
Value Function Loss: 0.07494

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.14077
Policy Update Magnitude: 0.57948
Value Function Update Magnitude: 0.60041

Collected Steps per Second: 22,412.65762
Overall Steps per Second: 10,539.88040

Timestep Collection Time: 2.23177
Timestep Consumption Time: 2.51401
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.74578

Cumulative Model Updates: 100,496
Cumulative Timesteps: 838,206,228

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 838206228...
Checkpoint 838206228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,467.01645
Policy Entropy: 1.96401
Value Function Loss: 0.07289

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.55761
Value Function Update Magnitude: 0.52254

Collected Steps per Second: 21,976.84700
Overall Steps per Second: 10,681.98295

Timestep Collection Time: 2.27640
Timestep Consumption Time: 2.40700
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.68340

Cumulative Model Updates: 100,502
Cumulative Timesteps: 838,256,256

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,764.61233
Policy Entropy: 1.95880
Value Function Loss: 0.07072

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.55609
Value Function Update Magnitude: 0.44808

Collected Steps per Second: 21,860.32942
Overall Steps per Second: 10,408.60584

Timestep Collection Time: 2.28761
Timestep Consumption Time: 2.51687
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.80449

Cumulative Model Updates: 100,508
Cumulative Timesteps: 838,306,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 838306264...
Checkpoint 838306264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,139.58227
Policy Entropy: 1.94727
Value Function Loss: 0.07118

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.55726
Value Function Update Magnitude: 0.42209

Collected Steps per Second: 21,774.87479
Overall Steps per Second: 10,562.99741

Timestep Collection Time: 2.29668
Timestep Consumption Time: 2.43777
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.73445

Cumulative Model Updates: 100,514
Cumulative Timesteps: 838,356,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,303.70562
Policy Entropy: 1.94985
Value Function Loss: 0.07148

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.55760
Value Function Update Magnitude: 0.40948

Collected Steps per Second: 22,013.18784
Overall Steps per Second: 10,523.86184

Timestep Collection Time: 2.27218
Timestep Consumption Time: 2.48063
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.75282

Cumulative Model Updates: 100,520
Cumulative Timesteps: 838,406,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 838406292...
Checkpoint 838406292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,062.77225
Policy Entropy: 1.95100
Value Function Loss: 0.07160

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.56674
Value Function Update Magnitude: 0.56327

Collected Steps per Second: 21,525.13810
Overall Steps per Second: 10,364.50062

Timestep Collection Time: 2.32370
Timestep Consumption Time: 2.50219
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.82590

Cumulative Model Updates: 100,526
Cumulative Timesteps: 838,456,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,203.36034
Policy Entropy: 1.95293
Value Function Loss: 0.07007

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.57014
Value Function Update Magnitude: 0.57698

Collected Steps per Second: 22,006.79771
Overall Steps per Second: 10,419.37061

Timestep Collection Time: 2.27321
Timestep Consumption Time: 2.52804
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.80125

Cumulative Model Updates: 100,532
Cumulative Timesteps: 838,506,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 838506336...
Checkpoint 838506336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,251.63157
Policy Entropy: 1.94709
Value Function Loss: 0.06887

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.56101
Value Function Update Magnitude: 0.59945

Collected Steps per Second: 21,770.07532
Overall Steps per Second: 10,571.12482

Timestep Collection Time: 2.29728
Timestep Consumption Time: 2.43372
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.73100

Cumulative Model Updates: 100,538
Cumulative Timesteps: 838,556,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,947.97307
Policy Entropy: 1.94079
Value Function Loss: 0.07085

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13251
Policy Update Magnitude: 0.56976
Value Function Update Magnitude: 0.64409

Collected Steps per Second: 21,736.90116
Overall Steps per Second: 10,453.18347

Timestep Collection Time: 2.30042
Timestep Consumption Time: 2.48319
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.78361

Cumulative Model Updates: 100,544
Cumulative Timesteps: 838,606,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 838606352...
Checkpoint 838606352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,442.27286
Policy Entropy: 1.94030
Value Function Loss: 0.06914

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13406
Policy Update Magnitude: 0.57348
Value Function Update Magnitude: 0.65361

Collected Steps per Second: 22,228.52497
Overall Steps per Second: 10,649.36760

Timestep Collection Time: 2.24981
Timestep Consumption Time: 2.44624
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.69605

Cumulative Model Updates: 100,550
Cumulative Timesteps: 838,656,362

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,940.25063
Policy Entropy: 1.93255
Value Function Loss: 0.06516

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.57002
Value Function Update Magnitude: 0.67494

Collected Steps per Second: 22,384.92418
Overall Steps per Second: 10,548.22282

Timestep Collection Time: 2.23391
Timestep Consumption Time: 2.50679
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.74070

Cumulative Model Updates: 100,556
Cumulative Timesteps: 838,706,368

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 838706368...
Checkpoint 838706368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,411.58967
Policy Entropy: 1.92936
Value Function Loss: 0.06353

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.54539
Value Function Update Magnitude: 0.67186

Collected Steps per Second: 22,285.13230
Overall Steps per Second: 10,574.53747

Timestep Collection Time: 2.24553
Timestep Consumption Time: 2.48678
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.73231

Cumulative Model Updates: 100,562
Cumulative Timesteps: 838,756,410

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,420.28303
Policy Entropy: 1.93392
Value Function Loss: 0.06634

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12608
Policy Update Magnitude: 0.55841
Value Function Update Magnitude: 0.69071

Collected Steps per Second: 21,958.05507
Overall Steps per Second: 10,402.46854

Timestep Collection Time: 2.27762
Timestep Consumption Time: 2.53009
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.80771

Cumulative Model Updates: 100,568
Cumulative Timesteps: 838,806,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 838806422...
Checkpoint 838806422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,036.99341
Policy Entropy: 1.94255
Value Function Loss: 0.07067

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.57065
Value Function Update Magnitude: 0.64209

Collected Steps per Second: 22,085.94084
Overall Steps per Second: 10,611.56716

Timestep Collection Time: 2.26416
Timestep Consumption Time: 2.44825
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.71240

Cumulative Model Updates: 100,574
Cumulative Timesteps: 838,856,428

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,415.66845
Policy Entropy: 1.93891
Value Function Loss: 0.07421

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.57995
Value Function Update Magnitude: 0.57242

Collected Steps per Second: 22,371.91569
Overall Steps per Second: 10,514.69391

Timestep Collection Time: 2.23700
Timestep Consumption Time: 2.52262
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.75963

Cumulative Model Updates: 100,580
Cumulative Timesteps: 838,906,474

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 838906474...
Checkpoint 838906474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,284.73328
Policy Entropy: 1.95180
Value Function Loss: 0.07800

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.58498
Value Function Update Magnitude: 0.53031

Collected Steps per Second: 21,469.08154
Overall Steps per Second: 10,506.14982

Timestep Collection Time: 2.33014
Timestep Consumption Time: 2.43145
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.76159

Cumulative Model Updates: 100,586
Cumulative Timesteps: 838,956,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,964.48920
Policy Entropy: 1.95981
Value Function Loss: 0.08136

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.58697
Value Function Update Magnitude: 0.66186

Collected Steps per Second: 21,938.43112
Overall Steps per Second: 10,528.76136

Timestep Collection Time: 2.28075
Timestep Consumption Time: 2.47157
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.75232

Cumulative Model Updates: 100,592
Cumulative Timesteps: 839,006,536

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 839006536...
Checkpoint 839006536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,698.74568
Policy Entropy: 1.97867
Value Function Loss: 0.08167

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.59266
Value Function Update Magnitude: 0.69528

Collected Steps per Second: 21,939.56049
Overall Steps per Second: 10,668.65205

Timestep Collection Time: 2.27972
Timestep Consumption Time: 2.40841
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.68813

Cumulative Model Updates: 100,598
Cumulative Timesteps: 839,056,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,707.99825
Policy Entropy: 1.97963
Value Function Loss: 0.07768

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.14339
Policy Update Magnitude: 0.58273
Value Function Update Magnitude: 0.54584

Collected Steps per Second: 21,523.06179
Overall Steps per Second: 10,462.70630

Timestep Collection Time: 2.32328
Timestep Consumption Time: 2.45599
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.77926

Cumulative Model Updates: 100,604
Cumulative Timesteps: 839,106,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 839106556...
Checkpoint 839106556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,106.11134
Policy Entropy: 1.96472
Value Function Loss: 0.08356

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.57997
Value Function Update Magnitude: 0.46246

Collected Steps per Second: 21,983.23238
Overall Steps per Second: 10,587.52350

Timestep Collection Time: 2.27482
Timestep Consumption Time: 2.44847
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.72330

Cumulative Model Updates: 100,610
Cumulative Timesteps: 839,156,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,509.69937
Policy Entropy: 1.95820
Value Function Loss: 0.07809

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.57666
Value Function Update Magnitude: 0.52322

Collected Steps per Second: 22,424.31737
Overall Steps per Second: 10,458.84482

Timestep Collection Time: 2.23115
Timestep Consumption Time: 2.55255
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.78370

Cumulative Model Updates: 100,616
Cumulative Timesteps: 839,206,596

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 839206596...
Checkpoint 839206596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,498.60864
Policy Entropy: 1.97884
Value Function Loss: 0.08793

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.15874
Policy Update Magnitude: 0.52717
Value Function Update Magnitude: 0.61784

Collected Steps per Second: 21,825.52862
Overall Steps per Second: 10,365.53432

Timestep Collection Time: 2.29126
Timestep Consumption Time: 2.53319
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.82445

Cumulative Model Updates: 100,622
Cumulative Timesteps: 839,256,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,275.40978
Policy Entropy: 1.98433
Value Function Loss: 0.08557

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.16041
Policy Update Magnitude: 0.48084
Value Function Update Magnitude: 0.65875

Collected Steps per Second: 22,503.71564
Overall Steps per Second: 10,698.54990

Timestep Collection Time: 2.22257
Timestep Consumption Time: 2.45246
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.67503

Cumulative Model Updates: 100,628
Cumulative Timesteps: 839,306,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 839306620...
Checkpoint 839306620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,505.38804
Policy Entropy: 1.98288
Value Function Loss: 0.09174

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.54074
Value Function Update Magnitude: 0.62458

Collected Steps per Second: 22,282.39188
Overall Steps per Second: 10,658.06624

Timestep Collection Time: 2.24491
Timestep Consumption Time: 2.44844
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.69335

Cumulative Model Updates: 100,634
Cumulative Timesteps: 839,356,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,876.26869
Policy Entropy: 1.95279
Value Function Loss: 0.08464

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.58351
Value Function Update Magnitude: 0.51684

Collected Steps per Second: 22,468.76461
Overall Steps per Second: 10,490.65869

Timestep Collection Time: 2.22540
Timestep Consumption Time: 2.54094
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.76634

Cumulative Model Updates: 100,640
Cumulative Timesteps: 839,406,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 839406644...
Checkpoint 839406644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,614.01294
Policy Entropy: 1.93703
Value Function Loss: 0.07966

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.15567
Policy Update Magnitude: 0.55809
Value Function Update Magnitude: 0.47420

Collected Steps per Second: 22,001.74912
Overall Steps per Second: 10,599.21310

Timestep Collection Time: 2.27291
Timestep Consumption Time: 2.44518
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.71809

Cumulative Model Updates: 100,646
Cumulative Timesteps: 839,456,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,435.03130
Policy Entropy: 1.93301
Value Function Loss: 0.07285

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.15299
Policy Update Magnitude: 0.50414
Value Function Update Magnitude: 0.48495

Collected Steps per Second: 22,368.88725
Overall Steps per Second: 10,528.17665

Timestep Collection Time: 2.23587
Timestep Consumption Time: 2.51462
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.75049

Cumulative Model Updates: 100,652
Cumulative Timesteps: 839,506,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 839506666...
Checkpoint 839506666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,909.17575
Policy Entropy: 1.95717
Value Function Loss: 0.07590

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.15117
Policy Update Magnitude: 0.50365
Value Function Update Magnitude: 0.42242

Collected Steps per Second: 22,065.51482
Overall Steps per Second: 10,598.63538

Timestep Collection Time: 2.26689
Timestep Consumption Time: 2.45259
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.71948

Cumulative Model Updates: 100,658
Cumulative Timesteps: 839,556,686

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,583.01304
Policy Entropy: 1.96462
Value Function Loss: 0.07517

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.51048
Value Function Update Magnitude: 0.42398

Collected Steps per Second: 21,553.58882
Overall Steps per Second: 10,492.62455

Timestep Collection Time: 2.32082
Timestep Consumption Time: 2.44653
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.76735

Cumulative Model Updates: 100,664
Cumulative Timesteps: 839,606,708

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 839606708...
Checkpoint 839606708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,818.18892
Policy Entropy: 1.97662
Value Function Loss: 0.07595

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.54428
Value Function Update Magnitude: 0.57733

Collected Steps per Second: 21,724.25845
Overall Steps per Second: 10,542.64346

Timestep Collection Time: 2.30240
Timestep Consumption Time: 2.44195
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.74435

Cumulative Model Updates: 100,670
Cumulative Timesteps: 839,656,726

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,905.03925
Policy Entropy: 1.94990
Value Function Loss: 0.07381

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.14965
Policy Update Magnitude: 0.52700
Value Function Update Magnitude: 0.57345

Collected Steps per Second: 22,062.96337
Overall Steps per Second: 10,624.25200

Timestep Collection Time: 2.26742
Timestep Consumption Time: 2.44124
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.70866

Cumulative Model Updates: 100,676
Cumulative Timesteps: 839,706,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 839706752...
Checkpoint 839706752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,336.94712
Policy Entropy: 1.94538
Value Function Loss: 0.07553

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.54002
Value Function Update Magnitude: 0.51871

Collected Steps per Second: 21,785.60903
Overall Steps per Second: 10,553.41194

Timestep Collection Time: 2.29619
Timestep Consumption Time: 2.44388
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.74008

Cumulative Model Updates: 100,682
Cumulative Timesteps: 839,756,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,131.30509
Policy Entropy: 1.93141
Value Function Loss: 0.07687

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.14982
Policy Update Magnitude: 0.54071
Value Function Update Magnitude: 0.52909

Collected Steps per Second: 22,385.90999
Overall Steps per Second: 10,467.75849

Timestep Collection Time: 2.23355
Timestep Consumption Time: 2.54302
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.77657

Cumulative Model Updates: 100,688
Cumulative Timesteps: 839,806,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 839806776...
Checkpoint 839806776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,259.56281
Policy Entropy: 1.94195
Value Function Loss: 0.07725

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.15170
Policy Update Magnitude: 0.54265
Value Function Update Magnitude: 0.55971

Collected Steps per Second: 22,120.35063
Overall Steps per Second: 10,636.71572

Timestep Collection Time: 2.26036
Timestep Consumption Time: 2.44034
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.70070

Cumulative Model Updates: 100,694
Cumulative Timesteps: 839,856,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,329.72181
Policy Entropy: 1.92544
Value Function Loss: 0.07539

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.17021
Policy Update Magnitude: 0.53674
Value Function Update Magnitude: 0.62547

Collected Steps per Second: 22,344.04630
Overall Steps per Second: 10,525.70739

Timestep Collection Time: 2.23809
Timestep Consumption Time: 2.51294
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.75103

Cumulative Model Updates: 100,700
Cumulative Timesteps: 839,906,784

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 839906784...
Checkpoint 839906784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,458.46014
Policy Entropy: 1.92838
Value Function Loss: 0.07479

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.16665
Policy Update Magnitude: 0.52298
Value Function Update Magnitude: 0.51026

Collected Steps per Second: 21,700.25663
Overall Steps per Second: 10,516.48564

Timestep Collection Time: 2.30495
Timestep Consumption Time: 2.45120
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.75615

Cumulative Model Updates: 100,706
Cumulative Timesteps: 839,956,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,095.01839
Policy Entropy: 1.93751
Value Function Loss: 0.08113

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.16698
Policy Update Magnitude: 0.54508
Value Function Update Magnitude: 0.42309

Collected Steps per Second: 22,188.83027
Overall Steps per Second: 10,480.91339

Timestep Collection Time: 2.25384
Timestep Consumption Time: 2.51769
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.77153

Cumulative Model Updates: 100,712
Cumulative Timesteps: 840,006,812

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 840006812...
Checkpoint 840006812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,156.65369
Policy Entropy: 1.94345
Value Function Loss: 0.07665

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.15149
Policy Update Magnitude: 0.55872
Value Function Update Magnitude: 0.40262

Collected Steps per Second: 22,020.33782
Overall Steps per Second: 10,596.52239

Timestep Collection Time: 2.27135
Timestep Consumption Time: 2.44868
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.72004

Cumulative Model Updates: 100,718
Cumulative Timesteps: 840,056,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,819.77264
Policy Entropy: 1.92593
Value Function Loss: 0.07628

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.58132
Value Function Update Magnitude: 0.50009

Collected Steps per Second: 22,442.25139
Overall Steps per Second: 10,524.31105

Timestep Collection Time: 2.22963
Timestep Consumption Time: 2.52488
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.75452

Cumulative Model Updates: 100,724
Cumulative Timesteps: 840,106,866

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 840106866...
Checkpoint 840106866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,192.35998
Policy Entropy: 1.93586
Value Function Loss: 0.07377

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.59079
Value Function Update Magnitude: 0.56075

Collected Steps per Second: 21,465.95546
Overall Steps per Second: 10,347.70764

Timestep Collection Time: 2.32964
Timestep Consumption Time: 2.50312
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.83276

Cumulative Model Updates: 100,730
Cumulative Timesteps: 840,156,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,099.94929
Policy Entropy: 1.94612
Value Function Loss: 0.07815

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.58394
Value Function Update Magnitude: 0.51076

Collected Steps per Second: 22,038.61264
Overall Steps per Second: 10,480.03619

Timestep Collection Time: 2.26993
Timestep Consumption Time: 2.50353
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.77346

Cumulative Model Updates: 100,736
Cumulative Timesteps: 840,206,900

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 840206900...
Checkpoint 840206900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,479.12410
Policy Entropy: 1.96070
Value Function Loss: 0.07886

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.57407
Value Function Update Magnitude: 0.51432

Collected Steps per Second: 21,787.58407
Overall Steps per Second: 10,449.57279

Timestep Collection Time: 2.29700
Timestep Consumption Time: 2.49229
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.78929

Cumulative Model Updates: 100,742
Cumulative Timesteps: 840,256,946

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,082.81689
Policy Entropy: 1.94906
Value Function Loss: 0.07103

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.56792
Value Function Update Magnitude: 0.57460

Collected Steps per Second: 22,122.37558
Overall Steps per Second: 10,492.89426

Timestep Collection Time: 2.26016
Timestep Consumption Time: 2.50497
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.76513

Cumulative Model Updates: 100,748
Cumulative Timesteps: 840,306,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 840306946...
Checkpoint 840306946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,546.94914
Policy Entropy: 1.93405
Value Function Loss: 0.06910

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.56501
Value Function Update Magnitude: 0.57280

Collected Steps per Second: 21,522.52291
Overall Steps per Second: 10,336.15271

Timestep Collection Time: 2.32380
Timestep Consumption Time: 2.51495
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.83874

Cumulative Model Updates: 100,754
Cumulative Timesteps: 840,356,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,828.96223
Policy Entropy: 1.92773
Value Function Loss: 0.07101

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.57928
Value Function Update Magnitude: 0.60374

Collected Steps per Second: 22,474.44482
Overall Steps per Second: 10,531.77526

Timestep Collection Time: 2.22528
Timestep Consumption Time: 2.52339
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.74868

Cumulative Model Updates: 100,760
Cumulative Timesteps: 840,406,972

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 840406972...
Checkpoint 840406972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,538.40225
Policy Entropy: 1.92734
Value Function Loss: 0.07343

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.58039
Value Function Update Magnitude: 0.68692

Collected Steps per Second: 22,448.34450
Overall Steps per Second: 10,513.36157

Timestep Collection Time: 2.22787
Timestep Consumption Time: 2.52912
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.75699

Cumulative Model Updates: 100,766
Cumulative Timesteps: 840,456,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,335.27672
Policy Entropy: 1.92934
Value Function Loss: 0.07279

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.14113
Policy Update Magnitude: 0.56969
Value Function Update Magnitude: 0.66414

Collected Steps per Second: 22,444.41092
Overall Steps per Second: 10,712.95922

Timestep Collection Time: 2.22773
Timestep Consumption Time: 2.43952
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.66724

Cumulative Model Updates: 100,772
Cumulative Timesteps: 840,506,984

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 840506984...
Checkpoint 840506984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,183.09276
Policy Entropy: 1.92158
Value Function Loss: 0.07239

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.57916
Value Function Update Magnitude: 0.65164

Collected Steps per Second: 21,536.82686
Overall Steps per Second: 10,308.08866

Timestep Collection Time: 2.32179
Timestep Consumption Time: 2.52916
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.85095

Cumulative Model Updates: 100,778
Cumulative Timesteps: 840,556,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,648.79251
Policy Entropy: 1.91222
Value Function Loss: 0.07431

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13034
Policy Update Magnitude: 0.59264
Value Function Update Magnitude: 0.63390

Collected Steps per Second: 22,388.08809
Overall Steps per Second: 10,585.83801

Timestep Collection Time: 2.23467
Timestep Consumption Time: 2.49146
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.72613

Cumulative Model Updates: 100,784
Cumulative Timesteps: 840,607,018

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 840607018...
Checkpoint 840607018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,261.02420
Policy Entropy: 1.89712
Value Function Loss: 0.07587

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.58997
Value Function Update Magnitude: 0.69232

Collected Steps per Second: 21,945.68520
Overall Steps per Second: 10,489.05178

Timestep Collection Time: 2.27917
Timestep Consumption Time: 2.48942
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.76859

Cumulative Model Updates: 100,790
Cumulative Timesteps: 840,657,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,060.54533
Policy Entropy: 1.89724
Value Function Loss: 0.07413

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.57081
Value Function Update Magnitude: 0.70251

Collected Steps per Second: 22,558.21405
Overall Steps per Second: 10,586.63809

Timestep Collection Time: 2.21720
Timestep Consumption Time: 2.50725
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.72445

Cumulative Model Updates: 100,796
Cumulative Timesteps: 840,707,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 840707052...
Checkpoint 840707052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,441.38214
Policy Entropy: 1.92204
Value Function Loss: 0.08086

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.15204
Policy Update Magnitude: 0.52147
Value Function Update Magnitude: 0.59987

Collected Steps per Second: 22,145.32749
Overall Steps per Second: 10,520.48141

Timestep Collection Time: 2.25908
Timestep Consumption Time: 2.49622
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.75530

Cumulative Model Updates: 100,802
Cumulative Timesteps: 840,757,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,930.94014
Policy Entropy: 1.92949
Value Function Loss: 0.08194

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.14912
Policy Update Magnitude: 0.53456
Value Function Update Magnitude: 0.53678

Collected Steps per Second: 21,959.61874
Overall Steps per Second: 10,487.57979

Timestep Collection Time: 2.27791
Timestep Consumption Time: 2.49173
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.76964

Cumulative Model Updates: 100,808
Cumulative Timesteps: 840,807,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 840807102...
Checkpoint 840807102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,491.23933
Policy Entropy: 1.91631
Value Function Loss: 0.08564

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.15464
Policy Update Magnitude: 0.52374
Value Function Update Magnitude: 0.50941

Collected Steps per Second: 21,291.42945
Overall Steps per Second: 10,295.93940

Timestep Collection Time: 2.34902
Timestep Consumption Time: 2.50862
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.85764

Cumulative Model Updates: 100,814
Cumulative Timesteps: 840,857,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,106.70875
Policy Entropy: 1.90433
Value Function Loss: 0.08249

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.14606
Policy Update Magnitude: 0.52666
Value Function Update Magnitude: 0.52349

Collected Steps per Second: 22,401.73853
Overall Steps per Second: 10,585.54049

Timestep Collection Time: 2.23251
Timestep Consumption Time: 2.49205
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.72456

Cumulative Model Updates: 100,820
Cumulative Timesteps: 840,907,128

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 840907128...
Checkpoint 840907128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,444.36867
Policy Entropy: 1.90320
Value Function Loss: 0.08423

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.15373
Policy Update Magnitude: 0.52160
Value Function Update Magnitude: 0.60000

Collected Steps per Second: 22,215.93102
Overall Steps per Second: 10,408.20756

Timestep Collection Time: 2.25253
Timestep Consumption Time: 2.55541
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.80794

Cumulative Model Updates: 100,826
Cumulative Timesteps: 840,957,170

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,120.94112
Policy Entropy: 1.90507
Value Function Loss: 0.07562

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.14579
Policy Update Magnitude: 0.55893
Value Function Update Magnitude: 0.69013

Collected Steps per Second: 20,322.65063
Overall Steps per Second: 10,164.69295

Timestep Collection Time: 2.46041
Timestep Consumption Time: 2.45878
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.91918

Cumulative Model Updates: 100,832
Cumulative Timesteps: 841,007,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 841007172...
Checkpoint 841007172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,589.33632
Policy Entropy: 1.89516
Value Function Loss: 0.07367

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.57492
Value Function Update Magnitude: 0.66715

Collected Steps per Second: 21,426.56514
Overall Steps per Second: 10,470.06935

Timestep Collection Time: 2.33374
Timestep Consumption Time: 2.44216
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.77590

Cumulative Model Updates: 100,838
Cumulative Timesteps: 841,057,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,547.77095
Policy Entropy: 1.88766
Value Function Loss: 0.07056

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.57886
Value Function Update Magnitude: 0.66002

Collected Steps per Second: 21,667.67062
Overall Steps per Second: 10,566.27367

Timestep Collection Time: 2.30805
Timestep Consumption Time: 2.42494
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.73298

Cumulative Model Updates: 100,844
Cumulative Timesteps: 841,107,186

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 841107186...
Checkpoint 841107186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,117.43305
Policy Entropy: 1.90030
Value Function Loss: 0.06947

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.57588
Value Function Update Magnitude: 0.58125

Collected Steps per Second: 20,699.69915
Overall Steps per Second: 10,446.70077

Timestep Collection Time: 2.41675
Timestep Consumption Time: 2.37194
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.78869

Cumulative Model Updates: 100,850
Cumulative Timesteps: 841,157,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,690.45614
Policy Entropy: 1.91289
Value Function Loss: 0.07395

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.13879
Policy Update Magnitude: 0.56631
Value Function Update Magnitude: 0.54295

Collected Steps per Second: 21,638.13678
Overall Steps per Second: 10,523.36039

Timestep Collection Time: 2.31074
Timestep Consumption Time: 2.44060
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.75133

Cumulative Model Updates: 100,856
Cumulative Timesteps: 841,207,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 841207212...
Checkpoint 841207212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,162.48207
Policy Entropy: 1.92480
Value Function Loss: 0.08153

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.14928
Policy Update Magnitude: 0.58014
Value Function Update Magnitude: 0.54487

Collected Steps per Second: 22,110.52007
Overall Steps per Second: 10,275.95594

Timestep Collection Time: 2.26272
Timestep Consumption Time: 2.60592
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.86865

Cumulative Model Updates: 100,862
Cumulative Timesteps: 841,257,242

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,864.09996
Policy Entropy: 1.95681
Value Function Loss: 0.08764

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.15932
Policy Update Magnitude: 0.54597
Value Function Update Magnitude: 0.44629

Collected Steps per Second: 22,144.42074
Overall Steps per Second: 10,568.94507

Timestep Collection Time: 2.25971
Timestep Consumption Time: 2.47491
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.73463

Cumulative Model Updates: 100,868
Cumulative Timesteps: 841,307,282

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 841307282...
Checkpoint 841307282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,064.45922
Policy Entropy: 1.95868
Value Function Loss: 0.09434

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.16757
Policy Update Magnitude: 0.51261
Value Function Update Magnitude: 0.41671

Collected Steps per Second: 21,561.76734
Overall Steps per Second: 10,520.68801

Timestep Collection Time: 2.31929
Timestep Consumption Time: 2.43401
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.75330

Cumulative Model Updates: 100,874
Cumulative Timesteps: 841,357,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,043.45050
Policy Entropy: 1.95649
Value Function Loss: 0.08762

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.55112
Value Function Update Magnitude: 0.42814

Collected Steps per Second: 21,751.29581
Overall Steps per Second: 10,496.12704

Timestep Collection Time: 2.30018
Timestep Consumption Time: 2.46653
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.76671

Cumulative Model Updates: 100,880
Cumulative Timesteps: 841,407,322

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 841407322...
Checkpoint 841407322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,002.77404
Policy Entropy: 1.92759
Value Function Loss: 0.07907

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.57796
Value Function Update Magnitude: 0.53265

Collected Steps per Second: 21,733.11586
Overall Steps per Second: 10,588.84452

Timestep Collection Time: 2.30202
Timestep Consumption Time: 2.42277
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.72478

Cumulative Model Updates: 100,886
Cumulative Timesteps: 841,457,352

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,928.60065
Policy Entropy: 1.92530
Value Function Loss: 0.06915

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.56886
Value Function Update Magnitude: 0.61378

Collected Steps per Second: 21,958.55927
Overall Steps per Second: 10,482.79869

Timestep Collection Time: 2.27711
Timestep Consumption Time: 2.49280
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.76991

Cumulative Model Updates: 100,892
Cumulative Timesteps: 841,507,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 841507354...
Checkpoint 841507354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,790.50705
Policy Entropy: 1.92160
Value Function Loss: 0.06504

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.57439
Value Function Update Magnitude: 0.60071

Collected Steps per Second: 21,961.01054
Overall Steps per Second: 10,582.29234

Timestep Collection Time: 2.27849
Timestep Consumption Time: 2.44997
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.72847

Cumulative Model Updates: 100,898
Cumulative Timesteps: 841,557,392

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,707.93460
Policy Entropy: 1.92527
Value Function Loss: 0.07141

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.57573
Value Function Update Magnitude: 0.54080

Collected Steps per Second: 22,104.48288
Overall Steps per Second: 10,470.98828

Timestep Collection Time: 2.26289
Timestep Consumption Time: 2.51412
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.77701

Cumulative Model Updates: 100,904
Cumulative Timesteps: 841,607,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 841607412...
Checkpoint 841607412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,300.20919
Policy Entropy: 1.93005
Value Function Loss: 0.07147

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.57531
Value Function Update Magnitude: 0.53138

Collected Steps per Second: 21,921.52363
Overall Steps per Second: 10,533.37805

Timestep Collection Time: 2.28150
Timestep Consumption Time: 2.46664
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.74814

Cumulative Model Updates: 100,910
Cumulative Timesteps: 841,657,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,836.09325
Policy Entropy: 1.92654
Value Function Loss: 0.07891

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.57729
Value Function Update Magnitude: 0.47206

Collected Steps per Second: 22,315.39566
Overall Steps per Second: 10,553.61642

Timestep Collection Time: 2.24105
Timestep Consumption Time: 2.49761
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.73866

Cumulative Model Updates: 100,916
Cumulative Timesteps: 841,707,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 841707436...
Checkpoint 841707436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,854.94743
Policy Entropy: 1.90150
Value Function Loss: 0.07566

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.58112
Value Function Update Magnitude: 0.51156

Collected Steps per Second: 22,042.48165
Overall Steps per Second: 10,602.14907

Timestep Collection Time: 2.26880
Timestep Consumption Time: 2.44817
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.71697

Cumulative Model Updates: 100,922
Cumulative Timesteps: 841,757,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,743.83604
Policy Entropy: 1.89941
Value Function Loss: 0.07260

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.57461
Value Function Update Magnitude: 0.61936

Collected Steps per Second: 22,355.44078
Overall Steps per Second: 10,505.93163

Timestep Collection Time: 2.23659
Timestep Consumption Time: 2.52262
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.75922

Cumulative Model Updates: 100,928
Cumulative Timesteps: 841,807,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 841807446...
Checkpoint 841807446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,997.39979
Policy Entropy: 1.92426
Value Function Loss: 0.07227

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.57160
Value Function Update Magnitude: 0.55817

Collected Steps per Second: 21,889.67434
Overall Steps per Second: 10,574.82564

Timestep Collection Time: 2.28500
Timestep Consumption Time: 2.44491
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.72991

Cumulative Model Updates: 100,934
Cumulative Timesteps: 841,857,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,316.35269
Policy Entropy: 1.93438
Value Function Loss: 0.07571

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.56625
Value Function Update Magnitude: 0.55172

Collected Steps per Second: 22,226.03211
Overall Steps per Second: 10,519.77275

Timestep Collection Time: 2.24970
Timestep Consumption Time: 2.50344
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.75314

Cumulative Model Updates: 100,940
Cumulative Timesteps: 841,907,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 841907466...
Checkpoint 841907466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,798.19341
Policy Entropy: 1.94402
Value Function Loss: 0.08028

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14278
Policy Update Magnitude: 0.56209
Value Function Update Magnitude: 0.58556

Collected Steps per Second: 21,942.98071
Overall Steps per Second: 10,609.10903

Timestep Collection Time: 2.27964
Timestep Consumption Time: 2.43537
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.71500

Cumulative Model Updates: 100,946
Cumulative Timesteps: 841,957,488

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,137.21240
Policy Entropy: 1.95318
Value Function Loss: 0.07981

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.56814
Value Function Update Magnitude: 0.63074

Collected Steps per Second: 21,693.50397
Overall Steps per Second: 10,477.39043

Timestep Collection Time: 2.30530
Timestep Consumption Time: 2.46784
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.77314

Cumulative Model Updates: 100,952
Cumulative Timesteps: 842,007,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 842007498...
Checkpoint 842007498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,123.91705
Policy Entropy: 1.95206
Value Function Loss: 0.07898

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.57844
Value Function Update Magnitude: 0.70090

Collected Steps per Second: 21,344.20430
Overall Steps per Second: 10,305.93819

Timestep Collection Time: 2.34302
Timestep Consumption Time: 2.50952
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.85254

Cumulative Model Updates: 100,958
Cumulative Timesteps: 842,057,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,470.41254
Policy Entropy: 1.95714
Value Function Loss: 0.07675

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.57865
Value Function Update Magnitude: 0.67324

Collected Steps per Second: 21,728.67945
Overall Steps per Second: 10,348.77734

Timestep Collection Time: 2.30184
Timestep Consumption Time: 2.53119
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.83303

Cumulative Model Updates: 100,964
Cumulative Timesteps: 842,107,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 842107524...
Checkpoint 842107524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,706.33428
Policy Entropy: 1.94547
Value Function Loss: 0.07291

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.56880
Value Function Update Magnitude: 0.60394

Collected Steps per Second: 21,453.60026
Overall Steps per Second: 10,363.47134

Timestep Collection Time: 2.33080
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.82502

Cumulative Model Updates: 100,970
Cumulative Timesteps: 842,157,528

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,327.70464
Policy Entropy: 1.93229
Value Function Loss: 0.07012

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.56074
Value Function Update Magnitude: 0.57699

Collected Steps per Second: 21,694.31602
Overall Steps per Second: 10,643.47547

Timestep Collection Time: 2.30530
Timestep Consumption Time: 2.39354
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.69884

Cumulative Model Updates: 100,976
Cumulative Timesteps: 842,207,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 842207540...
Checkpoint 842207540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,398.21358
Policy Entropy: 1.93094
Value Function Loss: 0.06688

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.54732
Value Function Update Magnitude: 0.57483

Collected Steps per Second: 21,233.75133
Overall Steps per Second: 10,427.84213

Timestep Collection Time: 2.35578
Timestep Consumption Time: 2.44119
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.79697

Cumulative Model Updates: 100,982
Cumulative Timesteps: 842,257,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,387.10847
Policy Entropy: 1.93820
Value Function Loss: 0.06426

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.54804
Value Function Update Magnitude: 0.57916

Collected Steps per Second: 22,112.65192
Overall Steps per Second: 10,824.14488

Timestep Collection Time: 2.26260
Timestep Consumption Time: 2.35966
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.62226

Cumulative Model Updates: 100,988
Cumulative Timesteps: 842,307,594

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 842307594...
Checkpoint 842307594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,080.64619
Policy Entropy: 1.94336
Value Function Loss: 0.06797

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.54024
Value Function Update Magnitude: 0.52191

Collected Steps per Second: 21,712.85151
Overall Steps per Second: 10,602.25501

Timestep Collection Time: 2.30380
Timestep Consumption Time: 2.41426
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.71805

Cumulative Model Updates: 100,994
Cumulative Timesteps: 842,357,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,203.63761
Policy Entropy: 1.95081
Value Function Loss: 0.07109

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.14762
Policy Update Magnitude: 0.50103
Value Function Update Magnitude: 0.58561

Collected Steps per Second: 21,893.94623
Overall Steps per Second: 10,613.91238

Timestep Collection Time: 2.28556
Timestep Consumption Time: 2.42900
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.71457

Cumulative Model Updates: 101,000
Cumulative Timesteps: 842,407,656

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 842407656...
Checkpoint 842407656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,917.68931
Policy Entropy: 1.93961
Value Function Loss: 0.06951

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13838
Policy Update Magnitude: 0.54741
Value Function Update Magnitude: 0.61534

Collected Steps per Second: 21,220.38919
Overall Steps per Second: 10,439.17113

Timestep Collection Time: 2.35688
Timestep Consumption Time: 2.43411
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.79099

Cumulative Model Updates: 101,006
Cumulative Timesteps: 842,457,670

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,002.29139
Policy Entropy: 1.92982
Value Function Loss: 0.06970

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.56471
Value Function Update Magnitude: 0.63417

Collected Steps per Second: 22,257.32737
Overall Steps per Second: 10,556.27762

Timestep Collection Time: 2.24690
Timestep Consumption Time: 2.49056
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.73747

Cumulative Model Updates: 101,012
Cumulative Timesteps: 842,507,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 842507680...
Checkpoint 842507680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,287.73069
Policy Entropy: 1.94423
Value Function Loss: 0.06626

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.15804
Policy Update Magnitude: 0.53795
Value Function Update Magnitude: 0.66677

Collected Steps per Second: 21,417.26828
Overall Steps per Second: 10,499.59539

Timestep Collection Time: 2.33494
Timestep Consumption Time: 2.42791
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.76285

Cumulative Model Updates: 101,018
Cumulative Timesteps: 842,557,688

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,527.31104
Policy Entropy: 1.93737
Value Function Loss: 0.07083

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.17511
Policy Update Magnitude: 0.49931
Value Function Update Magnitude: 0.67163

Collected Steps per Second: 21,944.32996
Overall Steps per Second: 10,506.01088

Timestep Collection Time: 2.27849
Timestep Consumption Time: 2.48069
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.75918

Cumulative Model Updates: 101,024
Cumulative Timesteps: 842,607,688

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 842607688...
Checkpoint 842607688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,817.41834
Policy Entropy: 1.94543
Value Function Loss: 0.07745

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.17709
Policy Update Magnitude: 0.52449
Value Function Update Magnitude: 0.62630

Collected Steps per Second: 21,615.88108
Overall Steps per Second: 10,562.78020

Timestep Collection Time: 2.31450
Timestep Consumption Time: 2.42194
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.73644

Cumulative Model Updates: 101,030
Cumulative Timesteps: 842,657,718

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,958.16870
Policy Entropy: 1.93163
Value Function Loss: 0.07806

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.16482
Policy Update Magnitude: 0.55720
Value Function Update Magnitude: 0.57221

Collected Steps per Second: 22,291.76560
Overall Steps per Second: 10,516.11604

Timestep Collection Time: 2.24298
Timestep Consumption Time: 2.51163
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.75461

Cumulative Model Updates: 101,036
Cumulative Timesteps: 842,707,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 842707718...
Checkpoint 842707718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,520.03685
Policy Entropy: 1.91911
Value Function Loss: 0.07481

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.16276
Policy Update Magnitude: 0.54183
Value Function Update Magnitude: 0.54380

Collected Steps per Second: 21,835.72138
Overall Steps per Second: 10,560.06780

Timestep Collection Time: 2.29093
Timestep Consumption Time: 2.44617
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.73709

Cumulative Model Updates: 101,042
Cumulative Timesteps: 842,757,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,263.30107
Policy Entropy: 1.92786
Value Function Loss: 0.07371

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.15185
Policy Update Magnitude: 0.51425
Value Function Update Magnitude: 0.53143

Collected Steps per Second: 22,294.78374
Overall Steps per Second: 10,559.89197

Timestep Collection Time: 2.24322
Timestep Consumption Time: 2.49282
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.73603

Cumulative Model Updates: 101,048
Cumulative Timesteps: 842,807,754

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 842807754...
Checkpoint 842807754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,386.41766
Policy Entropy: 1.92678
Value Function Loss: 0.07748

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.15622
Policy Update Magnitude: 0.53268
Value Function Update Magnitude: 0.58898

Collected Steps per Second: 22,294.74556
Overall Steps per Second: 10,692.85297

Timestep Collection Time: 2.24394
Timestep Consumption Time: 2.43470
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.67864

Cumulative Model Updates: 101,054
Cumulative Timesteps: 842,857,782

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,916.76975
Policy Entropy: 1.94529
Value Function Loss: 0.07590

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.16077
Policy Update Magnitude: 0.51391
Value Function Update Magnitude: 0.60425

Collected Steps per Second: 21,629.30752
Overall Steps per Second: 10,415.05695

Timestep Collection Time: 2.31270
Timestep Consumption Time: 2.49016
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.80285

Cumulative Model Updates: 101,060
Cumulative Timesteps: 842,907,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 842907804...
Checkpoint 842907804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,175.46141
Policy Entropy: 1.95045
Value Function Loss: 0.07425

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.15518
Policy Update Magnitude: 0.53859
Value Function Update Magnitude: 0.52634

Collected Steps per Second: 21,611.39850
Overall Steps per Second: 10,407.86859

Timestep Collection Time: 2.31526
Timestep Consumption Time: 2.49226
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.80752

Cumulative Model Updates: 101,066
Cumulative Timesteps: 842,957,840

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,559.05754
Policy Entropy: 1.96044
Value Function Loss: 0.07168

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.56898
Value Function Update Magnitude: 0.52477

Collected Steps per Second: 21,748.55115
Overall Steps per Second: 10,419.21386

Timestep Collection Time: 2.29928
Timestep Consumption Time: 2.50012
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.79940

Cumulative Model Updates: 101,072
Cumulative Timesteps: 843,007,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 843007846...
Checkpoint 843007846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,077.64124
Policy Entropy: 1.96962
Value Function Loss: 0.07691

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.58038
Value Function Update Magnitude: 0.52500

Collected Steps per Second: 21,591.71628
Overall Steps per Second: 10,441.42197

Timestep Collection Time: 2.31570
Timestep Consumption Time: 2.47292
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.78862

Cumulative Model Updates: 101,078
Cumulative Timesteps: 843,057,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,055.18463
Policy Entropy: 1.95554
Value Function Loss: 0.07551

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.58359
Value Function Update Magnitude: 0.54715

Collected Steps per Second: 22,402.39761
Overall Steps per Second: 10,491.84570

Timestep Collection Time: 2.23289
Timestep Consumption Time: 2.53482
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.76770

Cumulative Model Updates: 101,084
Cumulative Timesteps: 843,107,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 843107868...
Checkpoint 843107868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,907.01250
Policy Entropy: 1.93980
Value Function Loss: 0.07752

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.57474
Value Function Update Magnitude: 0.61597

Collected Steps per Second: 22,181.94376
Overall Steps per Second: 10,577.11444

Timestep Collection Time: 2.25409
Timestep Consumption Time: 2.47310
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.72719

Cumulative Model Updates: 101,090
Cumulative Timesteps: 843,157,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,591.49229
Policy Entropy: 1.92883
Value Function Loss: 0.07723

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.57783
Value Function Update Magnitude: 0.58613

Collected Steps per Second: 22,174.41932
Overall Steps per Second: 10,497.75597

Timestep Collection Time: 2.25602
Timestep Consumption Time: 2.50938
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.76540

Cumulative Model Updates: 101,096
Cumulative Timesteps: 843,207,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 843207894...
Checkpoint 843207894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,117.74892
Policy Entropy: 1.94114
Value Function Loss: 0.07594

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.58584
Value Function Update Magnitude: 0.64187

Collected Steps per Second: 22,274.94161
Overall Steps per Second: 10,680.97366

Timestep Collection Time: 2.24602
Timestep Consumption Time: 2.43801
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.68403

Cumulative Model Updates: 101,102
Cumulative Timesteps: 843,257,924

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,874.51483
Policy Entropy: 1.95820
Value Function Loss: 0.07778

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12579
Policy Update Magnitude: 0.58832
Value Function Update Magnitude: 0.67571

Collected Steps per Second: 21,796.38314
Overall Steps per Second: 10,440.04330

Timestep Collection Time: 2.29478
Timestep Consumption Time: 2.49619
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.79098

Cumulative Model Updates: 101,108
Cumulative Timesteps: 843,307,942

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 843307942...
Checkpoint 843307942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,069.33891
Policy Entropy: 1.98571
Value Function Loss: 0.07706

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.58911
Value Function Update Magnitude: 0.72181

Collected Steps per Second: 21,766.09268
Overall Steps per Second: 10,605.02467

Timestep Collection Time: 2.29733
Timestep Consumption Time: 2.41779
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.71512

Cumulative Model Updates: 101,114
Cumulative Timesteps: 843,357,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,264.88617
Policy Entropy: 1.96762
Value Function Loss: 0.07351

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.57802
Value Function Update Magnitude: 0.73142

Collected Steps per Second: 21,972.39341
Overall Steps per Second: 10,468.76304

Timestep Collection Time: 2.27567
Timestep Consumption Time: 2.50063
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.77630

Cumulative Model Updates: 101,120
Cumulative Timesteps: 843,407,948

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 843407948...
Checkpoint 843407948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,000.65110
Policy Entropy: 1.94772
Value Function Loss: 0.06870

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.56965
Value Function Update Magnitude: 0.70771

Collected Steps per Second: 21,788.70999
Overall Steps per Second: 10,551.04747

Timestep Collection Time: 2.29495
Timestep Consumption Time: 2.44430
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.73925

Cumulative Model Updates: 101,126
Cumulative Timesteps: 843,457,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,564.85585
Policy Entropy: 1.91433
Value Function Loss: 0.06960

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.57656
Value Function Update Magnitude: 0.64568

Collected Steps per Second: 21,821.85045
Overall Steps per Second: 10,535.68026

Timestep Collection Time: 2.29146
Timestep Consumption Time: 2.45469
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.74616

Cumulative Model Updates: 101,132
Cumulative Timesteps: 843,507,956

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 843507956...
Checkpoint 843507956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,109.90494
Policy Entropy: 1.90451
Value Function Loss: 0.07648

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.58882
Value Function Update Magnitude: 0.59358

Collected Steps per Second: 21,527.03802
Overall Steps per Second: 10,336.52148

Timestep Collection Time: 2.32470
Timestep Consumption Time: 2.51677
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.84147

Cumulative Model Updates: 101,138
Cumulative Timesteps: 843,558,000

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,334.23843
Policy Entropy: 1.91297
Value Function Loss: 0.07656

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.58719
Value Function Update Magnitude: 0.56320

Collected Steps per Second: 21,730.54858
Overall Steps per Second: 10,363.80929

Timestep Collection Time: 2.30137
Timestep Consumption Time: 2.52408
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.82545

Cumulative Model Updates: 101,144
Cumulative Timesteps: 843,608,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 843608010...
Checkpoint 843608010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,584.98536
Policy Entropy: 1.92450
Value Function Loss: 0.07699

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15997
Policy Update Magnitude: 0.56902
Value Function Update Magnitude: 0.47539

Collected Steps per Second: 21,824.04960
Overall Steps per Second: 10,509.31968

Timestep Collection Time: 2.29233
Timestep Consumption Time: 2.46801
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.76035

Cumulative Model Updates: 101,150
Cumulative Timesteps: 843,658,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,890.65039
Policy Entropy: 1.94678
Value Function Loss: 0.07604

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.51656
Value Function Update Magnitude: 0.39146

Collected Steps per Second: 22,236.25101
Overall Steps per Second: 10,540.51937

Timestep Collection Time: 2.24966
Timestep Consumption Time: 2.49622
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.74588

Cumulative Model Updates: 101,156
Cumulative Timesteps: 843,708,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 843708062...
Checkpoint 843708062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,369.29684
Policy Entropy: 1.94302
Value Function Loss: 0.07882

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.54701
Value Function Update Magnitude: 0.34663

Collected Steps per Second: 22,198.71625
Overall Steps per Second: 10,622.38080

Timestep Collection Time: 2.25238
Timestep Consumption Time: 2.45466
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.70704

Cumulative Model Updates: 101,162
Cumulative Timesteps: 843,758,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,156.67654
Policy Entropy: 1.95587
Value Function Loss: 0.07834

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.57743
Value Function Update Magnitude: 0.54822

Collected Steps per Second: 22,352.88123
Overall Steps per Second: 10,490.50187

Timestep Collection Time: 2.23721
Timestep Consumption Time: 2.52977
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.76698

Cumulative Model Updates: 101,168
Cumulative Timesteps: 843,808,070

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 843808070...
Checkpoint 843808070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,626.36579
Policy Entropy: 1.95912
Value Function Loss: 0.07788

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.57939
Value Function Update Magnitude: 0.58134

Collected Steps per Second: 21,972.93422
Overall Steps per Second: 10,574.79000

Timestep Collection Time: 2.27653
Timestep Consumption Time: 2.45378
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.73031

Cumulative Model Updates: 101,174
Cumulative Timesteps: 843,858,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,028.84174
Policy Entropy: 1.96530
Value Function Loss: 0.07529

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.58441
Value Function Update Magnitude: 0.65184

Collected Steps per Second: 22,383.33021
Overall Steps per Second: 10,521.02217

Timestep Collection Time: 2.23479
Timestep Consumption Time: 2.51969
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.75448

Cumulative Model Updates: 101,180
Cumulative Timesteps: 843,908,114

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 843908114...
Checkpoint 843908114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,983.19954
Policy Entropy: 1.93949
Value Function Loss: 0.06966

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.13636
Policy Update Magnitude: 0.57998
Value Function Update Magnitude: 0.73285

Collected Steps per Second: 22,197.60654
Overall Steps per Second: 10,625.48244

Timestep Collection Time: 2.25322
Timestep Consumption Time: 2.45396
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.70717

Cumulative Model Updates: 101,186
Cumulative Timesteps: 843,958,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,853.15618
Policy Entropy: 1.93594
Value Function Loss: 0.07080

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.57482
Value Function Update Magnitude: 0.71959

Collected Steps per Second: 21,804.60388
Overall Steps per Second: 10,437.14127

Timestep Collection Time: 2.29383
Timestep Consumption Time: 2.49829
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.79212

Cumulative Model Updates: 101,192
Cumulative Timesteps: 844,008,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 844008146...
Checkpoint 844008146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,314.76754
Policy Entropy: 1.94197
Value Function Loss: 0.07346

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.57858
Value Function Update Magnitude: 0.70899

Collected Steps per Second: 21,852.75629
Overall Steps per Second: 10,573.23331

Timestep Collection Time: 2.28850
Timestep Consumption Time: 2.44137
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.72987

Cumulative Model Updates: 101,198
Cumulative Timesteps: 844,058,156

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,864.47943
Policy Entropy: 1.93033
Value Function Loss: 0.07571

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.58675
Value Function Update Magnitude: 0.75170

Collected Steps per Second: 22,066.35481
Overall Steps per Second: 10,588.63239

Timestep Collection Time: 2.26653
Timestep Consumption Time: 2.45684
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.72337

Cumulative Model Updates: 101,204
Cumulative Timesteps: 844,108,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 844108170...
Checkpoint 844108170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,533.02748
Policy Entropy: 1.91531
Value Function Loss: 0.07626

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.58805
Value Function Update Magnitude: 0.77889

Collected Steps per Second: 21,193.41162
Overall Steps per Second: 10,272.35628

Timestep Collection Time: 2.35998
Timestep Consumption Time: 2.50901
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.86899

Cumulative Model Updates: 101,210
Cumulative Timesteps: 844,158,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,961.38230
Policy Entropy: 1.92310
Value Function Loss: 0.08272

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.60579
Value Function Update Magnitude: 0.84123

Collected Steps per Second: 21,779.30341
Overall Steps per Second: 10,387.15242

Timestep Collection Time: 2.29594
Timestep Consumption Time: 2.51808
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.81402

Cumulative Model Updates: 101,216
Cumulative Timesteps: 844,208,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 844208190...
Checkpoint 844208190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,280.75452
Policy Entropy: 1.95985
Value Function Loss: 0.08176

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.14802
Policy Update Magnitude: 0.60446
Value Function Update Magnitude: 0.79631

Collected Steps per Second: 22,014.80069
Overall Steps per Second: 10,608.61058

Timestep Collection Time: 2.27138
Timestep Consumption Time: 2.44215
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.71353

Cumulative Model Updates: 101,222
Cumulative Timesteps: 844,258,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,010.69474
Policy Entropy: 1.96792
Value Function Loss: 0.08091

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.16109
Policy Update Magnitude: 0.54894
Value Function Update Magnitude: 0.59937

Collected Steps per Second: 22,026.99624
Overall Steps per Second: 10,424.84690

Timestep Collection Time: 2.27085
Timestep Consumption Time: 2.52730
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.79815

Cumulative Model Updates: 101,228
Cumulative Timesteps: 844,308,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 844308214...
Checkpoint 844308214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,885.48324
Policy Entropy: 1.95857
Value Function Loss: 0.07607

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.54018
Value Function Update Magnitude: 0.51777

Collected Steps per Second: 21,835.87696
Overall Steps per Second: 10,542.94146

Timestep Collection Time: 2.29063
Timestep Consumption Time: 2.45358
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.74422

Cumulative Model Updates: 101,234
Cumulative Timesteps: 844,358,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,992.07307
Policy Entropy: 1.94299
Value Function Loss: 0.07675

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.56382
Value Function Update Magnitude: 0.50793

Collected Steps per Second: 22,206.94901
Overall Steps per Second: 10,521.80219

Timestep Collection Time: 2.25173
Timestep Consumption Time: 2.50069
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.75242

Cumulative Model Updates: 101,240
Cumulative Timesteps: 844,408,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 844408236...
Checkpoint 844408236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,751.81703
Policy Entropy: 1.94383
Value Function Loss: 0.07835

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12742
Policy Update Magnitude: 0.58095
Value Function Update Magnitude: 0.59991

Collected Steps per Second: 21,864.85215
Overall Steps per Second: 10,375.67403

Timestep Collection Time: 2.28906
Timestep Consumption Time: 2.53472
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.82378

Cumulative Model Updates: 101,246
Cumulative Timesteps: 844,458,286

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,499.49607
Policy Entropy: 1.96593
Value Function Loss: 0.07583

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.58531
Value Function Update Magnitude: 0.65384

Collected Steps per Second: 22,659.54183
Overall Steps per Second: 10,737.88519

Timestep Collection Time: 2.20693
Timestep Consumption Time: 2.45023
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.65716

Cumulative Model Updates: 101,252
Cumulative Timesteps: 844,508,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 844508294...
Checkpoint 844508294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,196.29447
Policy Entropy: 1.96928
Value Function Loss: 0.07521

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.58593
Value Function Update Magnitude: 0.64719

Collected Steps per Second: 21,970.74106
Overall Steps per Second: 10,584.47638

Timestep Collection Time: 2.27812
Timestep Consumption Time: 2.45069
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.72881

Cumulative Model Updates: 101,258
Cumulative Timesteps: 844,558,346

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,772.40197
Policy Entropy: 1.95620
Value Function Loss: 0.07429

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.57813
Value Function Update Magnitude: 0.60688

Collected Steps per Second: 22,092.45773
Overall Steps per Second: 10,520.48657

Timestep Collection Time: 2.26503
Timestep Consumption Time: 2.49141
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.75643

Cumulative Model Updates: 101,264
Cumulative Timesteps: 844,608,386

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 844608386...
Checkpoint 844608386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,574.55934
Policy Entropy: 1.93351
Value Function Loss: 0.07323

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.57298
Value Function Update Magnitude: 0.65934

Collected Steps per Second: 21,602.99624
Overall Steps per Second: 10,390.58143

Timestep Collection Time: 2.31477
Timestep Consumption Time: 2.49786
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.81263

Cumulative Model Updates: 101,270
Cumulative Timesteps: 844,658,392

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,143.83201
Policy Entropy: 1.92066
Value Function Loss: 0.06984

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.57520
Value Function Update Magnitude: 0.65644

Collected Steps per Second: 21,913.06116
Overall Steps per Second: 10,613.89764

Timestep Collection Time: 2.28202
Timestep Consumption Time: 2.42935
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.71137

Cumulative Model Updates: 101,276
Cumulative Timesteps: 844,708,398

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 844708398...
Checkpoint 844708398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,765.27061
Policy Entropy: 1.91732
Value Function Loss: 0.06772

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.57089
Value Function Update Magnitude: 0.56986

Collected Steps per Second: 21,399.22724
Overall Steps per Second: 10,269.09024

Timestep Collection Time: 2.33719
Timestep Consumption Time: 2.53316
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.87034

Cumulative Model Updates: 101,282
Cumulative Timesteps: 844,758,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,097.00244
Policy Entropy: 1.92992
Value Function Loss: 0.06902

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13519
Policy Update Magnitude: 0.57416
Value Function Update Magnitude: 0.55741

Collected Steps per Second: 21,848.07646
Overall Steps per Second: 10,447.36551

Timestep Collection Time: 2.28945
Timestep Consumption Time: 2.49836
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.78781

Cumulative Model Updates: 101,288
Cumulative Timesteps: 844,808,432

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 844808432...
Checkpoint 844808432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,136.56545
Policy Entropy: 1.93108
Value Function Loss: 0.07126

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.57856
Value Function Update Magnitude: 0.57979

Collected Steps per Second: 21,483.07597
Overall Steps per Second: 10,301.59797

Timestep Collection Time: 2.32881
Timestep Consumption Time: 2.52772
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.85653

Cumulative Model Updates: 101,294
Cumulative Timesteps: 844,858,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,217.47986
Policy Entropy: 1.93831
Value Function Loss: 0.07717

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.58186
Value Function Update Magnitude: 0.62652

Collected Steps per Second: 22,639.36245
Overall Steps per Second: 10,577.37239

Timestep Collection Time: 2.20863
Timestep Consumption Time: 2.51863
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.72726

Cumulative Model Updates: 101,300
Cumulative Timesteps: 844,908,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 844908464...
Checkpoint 844908464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,439.33435
Policy Entropy: 1.93106
Value Function Loss: 0.07991

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.59201
Value Function Update Magnitude: 0.66753

Collected Steps per Second: 22,140.75499
Overall Steps per Second: 10,451.16827

Timestep Collection Time: 2.26000
Timestep Consumption Time: 2.52779
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.78779

Cumulative Model Updates: 101,306
Cumulative Timesteps: 844,958,502

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,172.23102
Policy Entropy: 1.93900
Value Function Loss: 0.08241

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.14901
Policy Update Magnitude: 0.59692
Value Function Update Magnitude: 0.68559

Collected Steps per Second: 22,272.31985
Overall Steps per Second: 10,448.55378

Timestep Collection Time: 2.24584
Timestep Consumption Time: 2.54143
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.78727

Cumulative Model Updates: 101,312
Cumulative Timesteps: 845,008,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 845008522...
Checkpoint 845008522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,228.59161
Policy Entropy: 1.95407
Value Function Loss: 0.07986

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.14624
Policy Update Magnitude: 0.60255
Value Function Update Magnitude: 0.64107

Collected Steps per Second: 22,163.04657
Overall Steps per Second: 10,688.97569

Timestep Collection Time: 2.25817
Timestep Consumption Time: 2.42403
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.68221

Cumulative Model Updates: 101,318
Cumulative Timesteps: 845,058,570

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,918.12268
Policy Entropy: 1.96868
Value Function Loss: 0.07686

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.14502
Policy Update Magnitude: 0.59858
Value Function Update Magnitude: 0.60308

Collected Steps per Second: 21,661.78695
Overall Steps per Second: 10,541.86190

Timestep Collection Time: 2.30932
Timestep Consumption Time: 2.43595
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.74527

Cumulative Model Updates: 101,324
Cumulative Timesteps: 845,108,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 845108594...
Checkpoint 845108594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,566.87075
Policy Entropy: 1.96500
Value Function Loss: 0.07338

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.59806
Value Function Update Magnitude: 0.64280

Collected Steps per Second: 21,356.14464
Overall Steps per Second: 10,543.09033

Timestep Collection Time: 2.34246
Timestep Consumption Time: 2.40244
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.74491

Cumulative Model Updates: 101,330
Cumulative Timesteps: 845,158,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,054.40775
Policy Entropy: 1.94984
Value Function Loss: 0.07380

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.14131
Policy Update Magnitude: 0.58657
Value Function Update Magnitude: 0.60090

Collected Steps per Second: 21,676.12454
Overall Steps per Second: 10,484.85602

Timestep Collection Time: 2.30669
Timestep Consumption Time: 2.46210
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.76878

Cumulative Model Updates: 101,336
Cumulative Timesteps: 845,208,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 845208620...
Checkpoint 845208620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,423.01032
Policy Entropy: 1.95276
Value Function Loss: 0.07610

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.59410
Value Function Update Magnitude: 0.63455

Collected Steps per Second: 21,451.81003
Overall Steps per Second: 10,604.77982

Timestep Collection Time: 2.33211
Timestep Consumption Time: 2.38538
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.71750

Cumulative Model Updates: 101,342
Cumulative Timesteps: 845,258,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,101.39958
Policy Entropy: 1.95830
Value Function Loss: 0.07786

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.58256
Value Function Update Magnitude: 0.55638

Collected Steps per Second: 21,409.40606
Overall Steps per Second: 10,499.83113

Timestep Collection Time: 2.33654
Timestep Consumption Time: 2.42772
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.76427

Cumulative Model Updates: 101,348
Cumulative Timesteps: 845,308,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 845308672...
Checkpoint 845308672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,840.66770
Policy Entropy: 1.96600
Value Function Loss: 0.07892

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.58450
Value Function Update Magnitude: 0.45656

Collected Steps per Second: 21,079.94470
Overall Steps per Second: 10,553.94719

Timestep Collection Time: 2.37287
Timestep Consumption Time: 2.36659
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.73946

Cumulative Model Updates: 101,354
Cumulative Timesteps: 845,358,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,782.57786
Policy Entropy: 1.95660
Value Function Loss: 0.08189

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.58836
Value Function Update Magnitude: 0.42306

Collected Steps per Second: 21,128.31021
Overall Steps per Second: 10,479.63462

Timestep Collection Time: 2.36810
Timestep Consumption Time: 2.40630
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.77440

Cumulative Model Updates: 101,360
Cumulative Timesteps: 845,408,726

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 845408726...
Checkpoint 845408726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,205.02627
Policy Entropy: 1.97448
Value Function Loss: 0.08326

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.58497
Value Function Update Magnitude: 0.38301

Collected Steps per Second: 21,514.15026
Overall Steps per Second: 10,238.26553

Timestep Collection Time: 2.32507
Timestep Consumption Time: 2.56071
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.88579

Cumulative Model Updates: 101,366
Cumulative Timesteps: 845,458,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,539.97370
Policy Entropy: 1.96036
Value Function Loss: 0.08117

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.55993
Value Function Update Magnitude: 0.38261

Collected Steps per Second: 22,258.27098
Overall Steps per Second: 10,551.01189

Timestep Collection Time: 2.24690
Timestep Consumption Time: 2.49312
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.74002

Cumulative Model Updates: 101,372
Cumulative Timesteps: 845,508,760

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 845508760...
Checkpoint 845508760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,313.87988
Policy Entropy: 1.95559
Value Function Loss: 0.08377

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.55530
Value Function Update Magnitude: 0.45516

Collected Steps per Second: 22,291.71728
Overall Steps per Second: 10,547.96692

Timestep Collection Time: 2.24317
Timestep Consumption Time: 2.49746
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.74063

Cumulative Model Updates: 101,378
Cumulative Timesteps: 845,558,764

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,702.00476
Policy Entropy: 1.94374
Value Function Loss: 0.07848

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.57937
Value Function Update Magnitude: 0.59311

Collected Steps per Second: 22,583.82082
Overall Steps per Second: 10,771.44237

Timestep Collection Time: 2.21645
Timestep Consumption Time: 2.43065
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.64710

Cumulative Model Updates: 101,384
Cumulative Timesteps: 845,608,820

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 845608820...
Checkpoint 845608820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,669.93407
Policy Entropy: 1.94654
Value Function Loss: 0.07763

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.58846
Value Function Update Magnitude: 0.65149

Collected Steps per Second: 21,864.65028
Overall Steps per Second: 10,634.84954

Timestep Collection Time: 2.28789
Timestep Consumption Time: 2.41589
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.70378

Cumulative Model Updates: 101,390
Cumulative Timesteps: 845,658,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,134.47202
Policy Entropy: 1.95601
Value Function Loss: 0.07334

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.15479
Policy Update Magnitude: 0.55948
Value Function Update Magnitude: 0.62095

Collected Steps per Second: 22,654.63047
Overall Steps per Second: 10,679.83235

Timestep Collection Time: 2.20714
Timestep Consumption Time: 2.47477
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.68191

Cumulative Model Updates: 101,396
Cumulative Timesteps: 845,708,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 845708846...
Checkpoint 845708846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,486.22350
Policy Entropy: 1.96829
Value Function Loss: 0.06911

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.49551
Value Function Update Magnitude: 0.66190

Collected Steps per Second: 22,240.00656
Overall Steps per Second: 10,504.92223

Timestep Collection Time: 2.24892
Timestep Consumption Time: 2.51228
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.76120

Cumulative Model Updates: 101,402
Cumulative Timesteps: 845,758,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,272.41612
Policy Entropy: 1.95863
Value Function Loss: 0.06837

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.50664
Value Function Update Magnitude: 0.65185

Collected Steps per Second: 21,715.18335
Overall Steps per Second: 10,437.68455

Timestep Collection Time: 2.30281
Timestep Consumption Time: 2.48810
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.79091

Cumulative Model Updates: 101,408
Cumulative Timesteps: 845,808,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 845808868...
Checkpoint 845808868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,021.48997
Policy Entropy: 1.93587
Value Function Loss: 0.06842

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.15148
Policy Update Magnitude: 0.53723
Value Function Update Magnitude: 0.60760

Collected Steps per Second: 21,662.49771
Overall Steps per Second: 10,386.98595

Timestep Collection Time: 2.30841
Timestep Consumption Time: 2.50588
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.81429

Cumulative Model Updates: 101,414
Cumulative Timesteps: 845,858,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,479.95954
Policy Entropy: 1.90822
Value Function Loss: 0.07116

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.14039
Policy Update Magnitude: 0.55196
Value Function Update Magnitude: 0.48030

Collected Steps per Second: 21,942.06923
Overall Steps per Second: 10,503.91886

Timestep Collection Time: 2.27937
Timestep Consumption Time: 2.48210
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.76146

Cumulative Model Updates: 101,420
Cumulative Timesteps: 845,908,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 845908888...
Checkpoint 845908888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,153.44374
Policy Entropy: 1.92894
Value Function Loss: 0.07486

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.14494
Policy Update Magnitude: 0.53971
Value Function Update Magnitude: 0.39788

Collected Steps per Second: 21,866.74229
Overall Steps per Second: 10,435.73720

Timestep Collection Time: 2.28722
Timestep Consumption Time: 2.50535
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.79257

Cumulative Model Updates: 101,426
Cumulative Timesteps: 845,958,902

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,427.97987
Policy Entropy: 1.92018
Value Function Loss: 0.07491

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.52129
Value Function Update Magnitude: 0.40824

Collected Steps per Second: 22,112.93241
Overall Steps per Second: 10,441.01846

Timestep Collection Time: 2.26257
Timestep Consumption Time: 2.52930
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.79187

Cumulative Model Updates: 101,432
Cumulative Timesteps: 846,008,934

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 846008934...
Checkpoint 846008934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,909.32583
Policy Entropy: 1.92820
Value Function Loss: 0.07491

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14174
Policy Update Magnitude: 0.52825
Value Function Update Magnitude: 0.36817

Collected Steps per Second: 22,161.37399
Overall Steps per Second: 10,589.15973

Timestep Collection Time: 2.25771
Timestep Consumption Time: 2.46731
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.72502

Cumulative Model Updates: 101,438
Cumulative Timesteps: 846,058,968

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,751.15578
Policy Entropy: 1.90978
Value Function Loss: 0.07346

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.16053
Policy Update Magnitude: 0.51382
Value Function Update Magnitude: 0.38979

Collected Steps per Second: 22,323.21813
Overall Steps per Second: 10,492.26577

Timestep Collection Time: 2.24018
Timestep Consumption Time: 2.52600
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.76618

Cumulative Model Updates: 101,444
Cumulative Timesteps: 846,108,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 846108976...
Checkpoint 846108976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,487.53936
Policy Entropy: 1.92026
Value Function Loss: 0.07704

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.16488
Policy Update Magnitude: 0.50139
Value Function Update Magnitude: 0.47035

Collected Steps per Second: 22,053.90727
Overall Steps per Second: 10,634.41874

Timestep Collection Time: 2.26753
Timestep Consumption Time: 2.43493
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.70247

Cumulative Model Updates: 101,450
Cumulative Timesteps: 846,158,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,297.69884
Policy Entropy: 1.92086
Value Function Loss: 0.07648

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.17714
Policy Update Magnitude: 0.52179
Value Function Update Magnitude: 0.59500

Collected Steps per Second: 22,351.29753
Overall Steps per Second: 10,461.50896

Timestep Collection Time: 2.23835
Timestep Consumption Time: 2.54394
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.78229

Cumulative Model Updates: 101,456
Cumulative Timesteps: 846,209,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 846209014...
Checkpoint 846209014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,738.56678
Policy Entropy: 1.93231
Value Function Loss: 0.07820

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.17821
Policy Update Magnitude: 0.48512
Value Function Update Magnitude: 0.62527

Collected Steps per Second: 22,102.26496
Overall Steps per Second: 10,613.61309

Timestep Collection Time: 2.26294
Timestep Consumption Time: 2.44950
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.71244

Cumulative Model Updates: 101,462
Cumulative Timesteps: 846,259,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,536.15121
Policy Entropy: 1.93917
Value Function Loss: 0.07505

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.53167
Value Function Update Magnitude: 0.62831

Collected Steps per Second: 22,683.00585
Overall Steps per Second: 10,632.88582

Timestep Collection Time: 2.20553
Timestep Consumption Time: 2.49950
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.70503

Cumulative Model Updates: 101,468
Cumulative Timesteps: 846,309,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 846309058...
Checkpoint 846309058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,450.46014
Policy Entropy: 1.95114
Value Function Loss: 0.07378

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.57066
Value Function Update Magnitude: 0.55631

Collected Steps per Second: 21,407.89472
Overall Steps per Second: 10,543.99138

Timestep Collection Time: 2.33689
Timestep Consumption Time: 2.40780
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.74469

Cumulative Model Updates: 101,474
Cumulative Timesteps: 846,359,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,662.60956
Policy Entropy: 1.95160
Value Function Loss: 0.06996

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.57272
Value Function Update Magnitude: 0.61410

Collected Steps per Second: 21,399.39533
Overall Steps per Second: 10,431.17665

Timestep Collection Time: 2.33680
Timestep Consumption Time: 2.45710
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.79390

Cumulative Model Updates: 101,480
Cumulative Timesteps: 846,409,092

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 846409092...
Checkpoint 846409092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,868.77020
Policy Entropy: 1.94316
Value Function Loss: 0.07068

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.16272
Policy Update Magnitude: 0.54872
Value Function Update Magnitude: 0.66090

Collected Steps per Second: 20,483.56946
Overall Steps per Second: 10,260.87690

Timestep Collection Time: 2.44245
Timestep Consumption Time: 2.43336
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.87580

Cumulative Model Updates: 101,486
Cumulative Timesteps: 846,459,122

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,772.98383
Policy Entropy: 1.94524
Value Function Loss: 0.07446

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.16806
Policy Update Magnitude: 0.47341
Value Function Update Magnitude: 0.65520

Collected Steps per Second: 21,474.45315
Overall Steps per Second: 10,531.31235

Timestep Collection Time: 2.32863
Timestep Consumption Time: 2.41969
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.74832

Cumulative Model Updates: 101,492
Cumulative Timesteps: 846,509,128

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 846509128...
Checkpoint 846509128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,380.19679
Policy Entropy: 1.93835
Value Function Loss: 0.07383

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.15314
Policy Update Magnitude: 0.46595
Value Function Update Magnitude: 0.63065

Collected Steps per Second: 21,434.88002
Overall Steps per Second: 10,514.71993

Timestep Collection Time: 2.33265
Timestep Consumption Time: 2.42259
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.75524

Cumulative Model Updates: 101,498
Cumulative Timesteps: 846,559,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,360.61595
Policy Entropy: 1.93547
Value Function Loss: 0.07146

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.14646
Policy Update Magnitude: 0.50462
Value Function Update Magnitude: 0.61508

Collected Steps per Second: 21,600.96808
Overall Steps per Second: 10,521.86229

Timestep Collection Time: 2.31610
Timestep Consumption Time: 2.43876
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.75486

Cumulative Model Updates: 101,504
Cumulative Timesteps: 846,609,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 846609158...
Checkpoint 846609158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,889.87957
Policy Entropy: 1.93002
Value Function Loss: 0.06959

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.54081
Value Function Update Magnitude: 0.64956

Collected Steps per Second: 20,880.66197
Overall Steps per Second: 10,132.99675

Timestep Collection Time: 2.39619
Timestep Consumption Time: 2.54154
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.93773

Cumulative Model Updates: 101,510
Cumulative Timesteps: 846,659,192

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,374.16715
Policy Entropy: 1.93765
Value Function Loss: 0.06798

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.55323
Value Function Update Magnitude: 0.63597

Collected Steps per Second: 22,427.26533
Overall Steps per Second: 10,639.41008

Timestep Collection Time: 2.22979
Timestep Consumption Time: 2.47047
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.70026

Cumulative Model Updates: 101,516
Cumulative Timesteps: 846,709,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 846709200...
Checkpoint 846709200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,911.10756
Policy Entropy: 1.93930
Value Function Loss: 0.07415

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12962
Policy Update Magnitude: 0.57044
Value Function Update Magnitude: 0.68102

Collected Steps per Second: 22,068.02449
Overall Steps per Second: 10,500.54251

Timestep Collection Time: 2.26663
Timestep Consumption Time: 2.49694
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.76356

Cumulative Model Updates: 101,522
Cumulative Timesteps: 846,759,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,461.89649
Policy Entropy: 1.94462
Value Function Loss: 0.07574

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.58436
Value Function Update Magnitude: 0.69517

Collected Steps per Second: 22,402.46484
Overall Steps per Second: 10,503.08302

Timestep Collection Time: 2.23288
Timestep Consumption Time: 2.52972
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.76260

Cumulative Model Updates: 101,528
Cumulative Timesteps: 846,809,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 846809242...
Checkpoint 846809242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,183.04261
Policy Entropy: 1.94290
Value Function Loss: 0.07640

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.57070
Value Function Update Magnitude: 0.62146

Collected Steps per Second: 22,296.83232
Overall Steps per Second: 10,546.65967

Timestep Collection Time: 2.24292
Timestep Consumption Time: 2.49887
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.74179

Cumulative Model Updates: 101,534
Cumulative Timesteps: 846,859,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,388.11329
Policy Entropy: 1.94593
Value Function Loss: 0.07697

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.56099
Value Function Update Magnitude: 0.50326

Collected Steps per Second: 22,338.88521
Overall Steps per Second: 10,476.69814

Timestep Collection Time: 2.23897
Timestep Consumption Time: 2.53506
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.77402

Cumulative Model Updates: 101,540
Cumulative Timesteps: 846,909,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 846909268...
Checkpoint 846909268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,115.19486
Policy Entropy: 1.94581
Value Function Loss: 0.07331

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.56798
Value Function Update Magnitude: 0.58665

Collected Steps per Second: 21,925.49776
Overall Steps per Second: 10,559.87923

Timestep Collection Time: 2.28127
Timestep Consumption Time: 2.45534
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.73661

Cumulative Model Updates: 101,546
Cumulative Timesteps: 846,959,286

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,219.65326
Policy Entropy: 1.94193
Value Function Loss: 0.06807

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.57067
Value Function Update Magnitude: 0.67990

Collected Steps per Second: 21,916.06962
Overall Steps per Second: 10,557.64609

Timestep Collection Time: 2.28180
Timestep Consumption Time: 2.45487
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.73666

Cumulative Model Updates: 101,552
Cumulative Timesteps: 847,009,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 847009294...
Checkpoint 847009294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,844.80594
Policy Entropy: 1.94077
Value Function Loss: 0.06392

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.56074
Value Function Update Magnitude: 0.68371

Collected Steps per Second: 21,661.17832
Overall Steps per Second: 10,518.68792

Timestep Collection Time: 2.30883
Timestep Consumption Time: 2.44575
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.75459

Cumulative Model Updates: 101,558
Cumulative Timesteps: 847,059,306

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,948.04228
Policy Entropy: 1.91807
Value Function Loss: 0.06577

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.54906
Value Function Update Magnitude: 0.66359

Collected Steps per Second: 21,933.79237
Overall Steps per Second: 10,577.55713

Timestep Collection Time: 2.27986
Timestep Consumption Time: 2.44770
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.72756

Cumulative Model Updates: 101,564
Cumulative Timesteps: 847,109,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 847109312...
Checkpoint 847109312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,170.41583
Policy Entropy: 1.91624
Value Function Loss: 0.07024

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.16064
Policy Update Magnitude: 0.50679
Value Function Update Magnitude: 0.65305

Collected Steps per Second: 21,642.22774
Overall Steps per Second: 10,545.40274

Timestep Collection Time: 2.31178
Timestep Consumption Time: 2.43266
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.74444

Cumulative Model Updates: 101,570
Cumulative Timesteps: 847,159,344

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,035.43614
Policy Entropy: 1.93134
Value Function Loss: 0.07594

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.15760
Policy Update Magnitude: 0.50548
Value Function Update Magnitude: 0.71744

Collected Steps per Second: 22,449.16220
Overall Steps per Second: 10,543.04816

Timestep Collection Time: 2.22734
Timestep Consumption Time: 2.51531
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.74265

Cumulative Model Updates: 101,576
Cumulative Timesteps: 847,209,346

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 847209346...
Checkpoint 847209346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,013.31265
Policy Entropy: 1.93688
Value Function Loss: 0.07308

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.16199
Policy Update Magnitude: 0.54289
Value Function Update Magnitude: 0.73121

Collected Steps per Second: 22,135.70868
Overall Steps per Second: 10,626.26767

Timestep Collection Time: 2.25979
Timestep Consumption Time: 2.44760
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.70739

Cumulative Model Updates: 101,582
Cumulative Timesteps: 847,259,368

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,520.89323
Policy Entropy: 1.93233
Value Function Loss: 0.07366

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.15870
Policy Update Magnitude: 0.53499
Value Function Update Magnitude: 0.73250

Collected Steps per Second: 22,080.72209
Overall Steps per Second: 10,432.01020

Timestep Collection Time: 2.26442
Timestep Consumption Time: 2.52852
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.79294

Cumulative Model Updates: 101,588
Cumulative Timesteps: 847,309,368

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 847309368...
Checkpoint 847309368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,835.21226
Policy Entropy: 1.91154
Value Function Loss: 0.07186

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.14691
Policy Update Magnitude: 0.52755
Value Function Update Magnitude: 0.73938

Collected Steps per Second: 22,144.17640
Overall Steps per Second: 10,666.33650

Timestep Collection Time: 2.25956
Timestep Consumption Time: 2.43146
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.69102

Cumulative Model Updates: 101,594
Cumulative Timesteps: 847,359,404

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,806.68929
Policy Entropy: 1.92008
Value Function Loss: 0.07675

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.15604
Policy Update Magnitude: 0.54826
Value Function Update Magnitude: 0.75530

Collected Steps per Second: 22,391.03685
Overall Steps per Second: 10,519.46692

Timestep Collection Time: 2.23393
Timestep Consumption Time: 2.52106
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.75499

Cumulative Model Updates: 101,600
Cumulative Timesteps: 847,409,424

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 847409424...
Checkpoint 847409424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,449.46842
Policy Entropy: 1.90657
Value Function Loss: 0.07514

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.15350
Policy Update Magnitude: 0.53830
Value Function Update Magnitude: 0.75546

Collected Steps per Second: 22,191.50000
Overall Steps per Second: 10,558.86513

Timestep Collection Time: 2.25447
Timestep Consumption Time: 2.48373
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.73820

Cumulative Model Updates: 101,606
Cumulative Timesteps: 847,459,454

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,666.28052
Policy Entropy: 1.90016
Value Function Loss: 0.07840

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.15788
Policy Update Magnitude: 0.56224
Value Function Update Magnitude: 0.78365

Collected Steps per Second: 21,893.99420
Overall Steps per Second: 10,447.25793

Timestep Collection Time: 2.28464
Timestep Consumption Time: 2.50321
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.78786

Cumulative Model Updates: 101,612
Cumulative Timesteps: 847,509,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 847509474...
Checkpoint 847509474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,099.25644
Policy Entropy: 1.89069
Value Function Loss: 0.07502

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.16910
Policy Update Magnitude: 0.54960
Value Function Update Magnitude: 0.71135

Collected Steps per Second: 21,467.73867
Overall Steps per Second: 10,320.44079

Timestep Collection Time: 2.32917
Timestep Consumption Time: 2.51578
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.84495

Cumulative Model Updates: 101,618
Cumulative Timesteps: 847,559,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,219.15492
Policy Entropy: 1.89818
Value Function Loss: 0.07350

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.15697
Policy Update Magnitude: 0.56670
Value Function Update Magnitude: 0.55063

Collected Steps per Second: 22,101.90348
Overall Steps per Second: 10,489.60215

Timestep Collection Time: 2.26306
Timestep Consumption Time: 2.50528
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.76834

Cumulative Model Updates: 101,624
Cumulative Timesteps: 847,609,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 847609494...
Checkpoint 847609494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,494.04686
Policy Entropy: 1.91170
Value Function Loss: 0.07410

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.15898
Policy Update Magnitude: 0.57470
Value Function Update Magnitude: 0.60319

Collected Steps per Second: 21,287.06173
Overall Steps per Second: 10,426.36509

Timestep Collection Time: 2.35007
Timestep Consumption Time: 2.44796
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.79803

Cumulative Model Updates: 101,630
Cumulative Timesteps: 847,659,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,918.56562
Policy Entropy: 1.91772
Value Function Loss: 0.07593

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.15526
Policy Update Magnitude: 0.57499
Value Function Update Magnitude: 0.62696

Collected Steps per Second: 22,390.95492
Overall Steps per Second: 10,519.59929

Timestep Collection Time: 2.23322
Timestep Consumption Time: 2.52019
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.75341

Cumulative Model Updates: 101,636
Cumulative Timesteps: 847,709,524

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 847709524...
Checkpoint 847709524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,401.22497
Policy Entropy: 1.92610
Value Function Loss: 0.07839

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.16785
Policy Update Magnitude: 0.57561
Value Function Update Magnitude: 0.60888

Collected Steps per Second: 22,315.32022
Overall Steps per Second: 10,571.51564

Timestep Collection Time: 2.24115
Timestep Consumption Time: 2.48967
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.73083

Cumulative Model Updates: 101,642
Cumulative Timesteps: 847,759,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,169.14904
Policy Entropy: 1.93958
Value Function Loss: 0.07990

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.16545
Policy Update Magnitude: 0.54154
Value Function Update Magnitude: 0.54725

Collected Steps per Second: 22,463.77358
Overall Steps per Second: 10,492.20191

Timestep Collection Time: 2.22661
Timestep Consumption Time: 2.54055
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.76716

Cumulative Model Updates: 101,648
Cumulative Timesteps: 847,809,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 847809554...
Checkpoint 847809554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,437.53697
Policy Entropy: 1.92657
Value Function Loss: 0.07820

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.14947
Policy Update Magnitude: 0.51904
Value Function Update Magnitude: 0.57816

Collected Steps per Second: 22,265.09285
Overall Steps per Second: 10,701.01305

Timestep Collection Time: 2.24666
Timestep Consumption Time: 2.42785
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.67451

Cumulative Model Updates: 101,654
Cumulative Timesteps: 847,859,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,445.93421
Policy Entropy: 1.90835
Value Function Loss: 0.07264

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.55774
Value Function Update Magnitude: 0.68056

Collected Steps per Second: 21,541.33509
Overall Steps per Second: 10,527.26679

Timestep Collection Time: 2.32112
Timestep Consumption Time: 2.42845
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.74957

Cumulative Model Updates: 101,660
Cumulative Timesteps: 847,909,576

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 847909576...
Checkpoint 847909576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,202.55353
Policy Entropy: 1.89282
Value Function Loss: 0.07863

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.56465
Value Function Update Magnitude: 0.60775

Collected Steps per Second: 21,564.29556
Overall Steps per Second: 10,540.02870

Timestep Collection Time: 2.31865
Timestep Consumption Time: 2.42517
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.74382

Cumulative Model Updates: 101,666
Cumulative Timesteps: 847,959,576

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,072.48193
Policy Entropy: 1.89296
Value Function Loss: 0.07976

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.13680
Policy Update Magnitude: 0.58585
Value Function Update Magnitude: 0.50009

Collected Steps per Second: 21,726.40850
Overall Steps per Second: 10,538.34740

Timestep Collection Time: 2.30208
Timestep Consumption Time: 2.44401
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.74610

Cumulative Model Updates: 101,672
Cumulative Timesteps: 848,009,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 848009592...
Checkpoint 848009592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,555.90363
Policy Entropy: 1.89398
Value Function Loss: 0.09185

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.61245
Value Function Update Magnitude: 0.47388

Collected Steps per Second: 20,909.51585
Overall Steps per Second: 10,503.62118

Timestep Collection Time: 2.39154
Timestep Consumption Time: 2.36929
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.76083

Cumulative Model Updates: 101,678
Cumulative Timesteps: 848,059,598

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,140.84531
Policy Entropy: 1.89220
Value Function Loss: 0.08989

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.14407
Policy Update Magnitude: 0.62261
Value Function Update Magnitude: 0.52577

Collected Steps per Second: 21,207.76100
Overall Steps per Second: 10,474.75239

Timestep Collection Time: 2.35810
Timestep Consumption Time: 2.41624
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.77434

Cumulative Model Updates: 101,684
Cumulative Timesteps: 848,109,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 848109608...
Checkpoint 848109608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,659.52173
Policy Entropy: 1.91161
Value Function Loss: 0.09287

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.15430
Policy Update Magnitude: 0.60287
Value Function Update Magnitude: 0.61181

Collected Steps per Second: 20,963.66268
Overall Steps per Second: 10,540.67641

Timestep Collection Time: 2.38508
Timestep Consumption Time: 2.35845
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.74353

Cumulative Model Updates: 101,690
Cumulative Timesteps: 848,159,608

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,744.19242
Policy Entropy: 1.91451
Value Function Loss: 0.08677

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.17066
Policy Update Magnitude: 0.52919
Value Function Update Magnitude: 0.64625

Collected Steps per Second: 21,131.80112
Overall Steps per Second: 10,530.72154

Timestep Collection Time: 2.36686
Timestep Consumption Time: 2.38267
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.74953

Cumulative Model Updates: 101,696
Cumulative Timesteps: 848,209,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 848209624...
Checkpoint 848209624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,293.30835
Policy Entropy: 1.92161
Value Function Loss: 0.07990

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.16376
Policy Update Magnitude: 0.52286
Value Function Update Magnitude: 0.61937

Collected Steps per Second: 21,209.75286
Overall Steps per Second: 10,584.91033

Timestep Collection Time: 2.35901
Timestep Consumption Time: 2.36791
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.72692

Cumulative Model Updates: 101,702
Cumulative Timesteps: 848,259,658

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,877.35406
Policy Entropy: 1.91233
Value Function Loss: 0.07791

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.14746
Policy Update Magnitude: 0.52047
Value Function Update Magnitude: 0.60854

Collected Steps per Second: 21,629.85581
Overall Steps per Second: 10,528.81185

Timestep Collection Time: 2.31310
Timestep Consumption Time: 2.43881
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.75191

Cumulative Model Updates: 101,708
Cumulative Timesteps: 848,309,690

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 848309690...
Checkpoint 848309690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,388.51561
Policy Entropy: 1.92499
Value Function Loss: 0.07447

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.56426
Value Function Update Magnitude: 0.51242

Collected Steps per Second: 21,677.51944
Overall Steps per Second: 10,583.69230

Timestep Collection Time: 2.30718
Timestep Consumption Time: 2.41839
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.72557

Cumulative Model Updates: 101,714
Cumulative Timesteps: 848,359,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,763.18276
Policy Entropy: 1.91283
Value Function Loss: 0.08160

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.14754
Policy Update Magnitude: 0.59703
Value Function Update Magnitude: 0.58861

Collected Steps per Second: 22,250.05357
Overall Steps per Second: 10,516.64070

Timestep Collection Time: 2.24790
Timestep Consumption Time: 2.50799
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.75589

Cumulative Model Updates: 101,720
Cumulative Timesteps: 848,409,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 848409720...
Checkpoint 848409720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,572.11734
Policy Entropy: 1.90574
Value Function Loss: 0.08355

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.16315
Policy Update Magnitude: 0.56845
Value Function Update Magnitude: 0.52775

Collected Steps per Second: 22,143.57237
Overall Steps per Second: 10,692.40003

Timestep Collection Time: 2.25853
Timestep Consumption Time: 2.41881
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.67734

Cumulative Model Updates: 101,726
Cumulative Timesteps: 848,459,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,384.38269
Policy Entropy: 1.89546
Value Function Loss: 0.08462

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.15100
Policy Update Magnitude: 0.57568
Value Function Update Magnitude: 0.43686

Collected Steps per Second: 22,359.34307
Overall Steps per Second: 10,620.87788

Timestep Collection Time: 2.23647
Timestep Consumption Time: 2.47180
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.70827

Cumulative Model Updates: 101,732
Cumulative Timesteps: 848,509,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 848509738...
Checkpoint 848509738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,737.91658
Policy Entropy: 1.90603
Value Function Loss: 0.08222

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.58118
Value Function Update Magnitude: 0.43154

Collected Steps per Second: 20,699.77815
Overall Steps per Second: 10,370.42259

Timestep Collection Time: 2.41635
Timestep Consumption Time: 2.40679
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.82314

Cumulative Model Updates: 101,738
Cumulative Timesteps: 848,559,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,080.38121
Policy Entropy: 1.91075
Value Function Loss: 0.07709

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.14786
Policy Update Magnitude: 0.55774
Value Function Update Magnitude: 0.44543

Collected Steps per Second: 22,175.24581
Overall Steps per Second: 10,508.77933

Timestep Collection Time: 2.25513
Timestep Consumption Time: 2.50356
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.75869

Cumulative Model Updates: 101,744
Cumulative Timesteps: 848,609,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 848609764...
Checkpoint 848609764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,049.76441
Policy Entropy: 1.91971
Value Function Loss: 0.07570

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.56056
Value Function Update Magnitude: 0.44285

Collected Steps per Second: 21,536.69869
Overall Steps per Second: 10,322.32940

Timestep Collection Time: 2.32264
Timestep Consumption Time: 2.52336
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.84600

Cumulative Model Updates: 101,750
Cumulative Timesteps: 848,659,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,725.83177
Policy Entropy: 1.90287
Value Function Loss: 0.07398

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.57595
Value Function Update Magnitude: 0.46592

Collected Steps per Second: 21,977.13069
Overall Steps per Second: 10,386.97935

Timestep Collection Time: 2.27600
Timestep Consumption Time: 2.53964
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.81564

Cumulative Model Updates: 101,756
Cumulative Timesteps: 848,709,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 848709806...
Checkpoint 848709806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,025.11176
Policy Entropy: 1.91238
Value Function Loss: 0.06950

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.13476
Policy Update Magnitude: 0.57808
Value Function Update Magnitude: 0.43916

Collected Steps per Second: 22,409.86306
Overall Steps per Second: 10,631.72429

Timestep Collection Time: 2.23223
Timestep Consumption Time: 2.47293
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.70516

Cumulative Model Updates: 101,762
Cumulative Timesteps: 848,759,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,543.83246
Policy Entropy: 1.91745
Value Function Loss: 0.07334

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.57752
Value Function Update Magnitude: 0.41492

Collected Steps per Second: 22,384.10838
Overall Steps per Second: 10,490.86832

Timestep Collection Time: 2.23560
Timestep Consumption Time: 2.53445
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.77005

Cumulative Model Updates: 101,768
Cumulative Timesteps: 848,809,872

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 848809872...
Checkpoint 848809872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,555.06153
Policy Entropy: 1.92805
Value Function Loss: 0.07245

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.58303
Value Function Update Magnitude: 0.44064

Collected Steps per Second: 21,625.35231
Overall Steps per Second: 10,539.79557

Timestep Collection Time: 2.31303
Timestep Consumption Time: 2.43280
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.74582

Cumulative Model Updates: 101,774
Cumulative Timesteps: 848,859,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,094.10187
Policy Entropy: 1.93847
Value Function Loss: 0.07673

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.57713
Value Function Update Magnitude: 0.46305

Collected Steps per Second: 22,478.05404
Overall Steps per Second: 10,537.73607

Timestep Collection Time: 2.22564
Timestep Consumption Time: 2.52187
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.74751

Cumulative Model Updates: 101,780
Cumulative Timesteps: 848,909,920

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 848909920...
Checkpoint 848909920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,652.94626
Policy Entropy: 1.93709
Value Function Loss: 0.07581

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.16341
Policy Update Magnitude: 0.52144
Value Function Update Magnitude: 0.56937

Collected Steps per Second: 22,180.49340
Overall Steps per Second: 10,728.00058

Timestep Collection Time: 2.25450
Timestep Consumption Time: 2.40676
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.66126

Cumulative Model Updates: 101,786
Cumulative Timesteps: 848,959,926

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,665.40404
Policy Entropy: 1.93432
Value Function Loss: 0.07861

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.15724
Policy Update Magnitude: 0.55881
Value Function Update Magnitude: 0.56540

Collected Steps per Second: 22,423.37972
Overall Steps per Second: 10,758.06168

Timestep Collection Time: 2.22999
Timestep Consumption Time: 2.41806
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.64805

Cumulative Model Updates: 101,792
Cumulative Timesteps: 849,009,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 849009930...
Checkpoint 849009930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,283.59518
Policy Entropy: 1.92547
Value Function Loss: 0.08261

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.14527
Policy Update Magnitude: 0.59047
Value Function Update Magnitude: 0.58402

Collected Steps per Second: 21,639.49578
Overall Steps per Second: 10,356.23523

Timestep Collection Time: 2.31105
Timestep Consumption Time: 2.51792
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.82897

Cumulative Model Updates: 101,798
Cumulative Timesteps: 849,059,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,266.08901
Policy Entropy: 1.90005
Value Function Loss: 0.08262

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.60739
Value Function Update Magnitude: 0.59035

Collected Steps per Second: 22,054.96825
Overall Steps per Second: 10,474.11903

Timestep Collection Time: 2.26752
Timestep Consumption Time: 2.50711
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.77463

Cumulative Model Updates: 101,804
Cumulative Timesteps: 849,109,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 849109950...
Checkpoint 849109950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,308.22882
Policy Entropy: 1.89697
Value Function Loss: 0.08223

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.60330
Value Function Update Magnitude: 0.47877

Collected Steps per Second: 21,331.24909
Overall Steps per Second: 10,424.40959

Timestep Collection Time: 2.34445
Timestep Consumption Time: 2.45295
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.79739

Cumulative Model Updates: 101,810
Cumulative Timesteps: 849,159,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,509.24870
Policy Entropy: 1.89679
Value Function Loss: 0.08160

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.59552
Value Function Update Magnitude: 0.43397

Collected Steps per Second: 21,934.24648
Overall Steps per Second: 10,591.42091

Timestep Collection Time: 2.27981
Timestep Consumption Time: 2.44155
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.72137

Cumulative Model Updates: 101,816
Cumulative Timesteps: 849,209,966

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 849209966...
Checkpoint 849209966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,131.73324
Policy Entropy: 1.89627
Value Function Loss: 0.08240

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.15823
Policy Update Magnitude: 0.56674
Value Function Update Magnitude: 0.39400

Collected Steps per Second: 21,865.37798
Overall Steps per Second: 10,537.61899

Timestep Collection Time: 2.28681
Timestep Consumption Time: 2.45828
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.74509

Cumulative Model Updates: 101,822
Cumulative Timesteps: 849,259,968

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,383.13826
Policy Entropy: 1.88780
Value Function Loss: 0.08617

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.16203
Policy Update Magnitude: 0.51471
Value Function Update Magnitude: 0.35077

Collected Steps per Second: 22,592.21979
Overall Steps per Second: 10,549.58324

Timestep Collection Time: 2.21324
Timestep Consumption Time: 2.52647
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.73971

Cumulative Model Updates: 101,828
Cumulative Timesteps: 849,309,970

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 849309970...
Checkpoint 849309970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,324.74313
Policy Entropy: 1.87757
Value Function Loss: 0.08439

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.14635
Policy Update Magnitude: 0.56343
Value Function Update Magnitude: 0.36182

Collected Steps per Second: 21,712.84084
Overall Steps per Second: 10,528.30462

Timestep Collection Time: 2.30435
Timestep Consumption Time: 2.44798
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.75233

Cumulative Model Updates: 101,834
Cumulative Timesteps: 849,360,004

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,080.14472
Policy Entropy: 1.89349
Value Function Loss: 0.08728

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.15853
Policy Update Magnitude: 0.57649
Value Function Update Magnitude: 0.42763

Collected Steps per Second: 22,542.17739
Overall Steps per Second: 10,524.55173

Timestep Collection Time: 2.21984
Timestep Consumption Time: 2.53476
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.75460

Cumulative Model Updates: 101,840
Cumulative Timesteps: 849,410,044

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 849410044...
Checkpoint 849410044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,399.22062
Policy Entropy: 1.90984
Value Function Loss: 0.08117

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.57552
Value Function Update Magnitude: 0.48541

Collected Steps per Second: 22,144.90584
Overall Steps per Second: 10,595.92583

Timestep Collection Time: 2.25903
Timestep Consumption Time: 2.46222
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.72125

Cumulative Model Updates: 101,846
Cumulative Timesteps: 849,460,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,389.08619
Policy Entropy: 1.92311
Value Function Loss: 0.08243

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.57663
Value Function Update Magnitude: 0.61957

Collected Steps per Second: 22,370.09276
Overall Steps per Second: 10,494.34294

Timestep Collection Time: 2.23557
Timestep Consumption Time: 2.52985
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.76542

Cumulative Model Updates: 101,852
Cumulative Timesteps: 849,510,080

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 849510080...
Checkpoint 849510080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,448.32742
Policy Entropy: 1.92339
Value Function Loss: 0.07476

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.56883
Value Function Update Magnitude: 0.60698

Collected Steps per Second: 21,897.86360
Overall Steps per Second: 10,600.09201

Timestep Collection Time: 2.28369
Timestep Consumption Time: 2.43400
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.71769

Cumulative Model Updates: 101,858
Cumulative Timesteps: 849,560,088

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,826.03094
Policy Entropy: 1.90017
Value Function Loss: 0.07476

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.14363
Policy Update Magnitude: 0.55743
Value Function Update Magnitude: 0.59355

Collected Steps per Second: 21,984.59198
Overall Steps per Second: 10,523.80148

Timestep Collection Time: 2.27541
Timestep Consumption Time: 2.47800
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.75342

Cumulative Model Updates: 101,864
Cumulative Timesteps: 849,610,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 849610112...
Checkpoint 849610112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,000.06680
Policy Entropy: 1.89449
Value Function Loss: 0.07611

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.58120
Value Function Update Magnitude: 0.61575

Collected Steps per Second: 21,179.08568
Overall Steps per Second: 10,241.82312

Timestep Collection Time: 2.36176
Timestep Consumption Time: 2.52213
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.88390

Cumulative Model Updates: 101,870
Cumulative Timesteps: 849,660,132

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,850.41850
Policy Entropy: 1.88421
Value Function Loss: 0.07834

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.59107
Value Function Update Magnitude: 0.59951

Collected Steps per Second: 22,261.72112
Overall Steps per Second: 10,531.15725

Timestep Collection Time: 2.24816
Timestep Consumption Time: 2.50421
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.75237

Cumulative Model Updates: 101,876
Cumulative Timesteps: 849,710,180

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 849710180...
Checkpoint 849710180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,667.95848
Policy Entropy: 1.88652
Value Function Loss: 0.07342

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.58797
Value Function Update Magnitude: 0.52013

Collected Steps per Second: 21,848.13541
Overall Steps per Second: 10,494.53773

Timestep Collection Time: 2.28917
Timestep Consumption Time: 2.47655
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.76572

Cumulative Model Updates: 101,882
Cumulative Timesteps: 849,760,194

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,197.29077
Policy Entropy: 1.88421
Value Function Loss: 0.06678

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.57043
Value Function Update Magnitude: 0.48947

Collected Steps per Second: 21,888.22005
Overall Steps per Second: 10,445.83685

Timestep Collection Time: 2.28488
Timestep Consumption Time: 2.50286
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.78774

Cumulative Model Updates: 101,888
Cumulative Timesteps: 849,810,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 849810206...
Checkpoint 849810206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,470.83295
Policy Entropy: 1.86410
Value Function Loss: 0.06965

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.57877
Value Function Update Magnitude: 0.60513

Collected Steps per Second: 21,753.19683
Overall Steps per Second: 10,244.18454

Timestep Collection Time: 2.29888
Timestep Consumption Time: 2.58272
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.88160

Cumulative Model Updates: 101,894
Cumulative Timesteps: 849,860,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,862.05167
Policy Entropy: 1.86673
Value Function Loss: 0.07357

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.58538
Value Function Update Magnitude: 0.67640

Collected Steps per Second: 21,462.15088
Overall Steps per Second: 10,418.77804

Timestep Collection Time: 2.32987
Timestep Consumption Time: 2.46954
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.79941

Cumulative Model Updates: 101,900
Cumulative Timesteps: 849,910,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 849910218...
Checkpoint 849910218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,476.68629
Policy Entropy: 1.85221
Value Function Loss: 0.07840

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.14131
Policy Update Magnitude: 0.57596
Value Function Update Magnitude: 0.67111

Collected Steps per Second: 22,459.92038
Overall Steps per Second: 10,753.71538

Timestep Collection Time: 2.22681
Timestep Consumption Time: 2.42405
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.65086

Cumulative Model Updates: 101,906
Cumulative Timesteps: 849,960,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,206.05975
Policy Entropy: 1.85141
Value Function Loss: 0.07890

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.57700
Value Function Update Magnitude: 0.72453

Collected Steps per Second: 21,865.46771
Overall Steps per Second: 10,730.64467

Timestep Collection Time: 2.28772
Timestep Consumption Time: 2.37389
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.66160

Cumulative Model Updates: 101,912
Cumulative Timesteps: 850,010,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 850010254...
Checkpoint 850010254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,790.01352
Policy Entropy: 1.83904
Value Function Loss: 0.07903

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.58386
Value Function Update Magnitude: 0.73409

Collected Steps per Second: 21,169.01421
Overall Steps per Second: 10,433.47540

Timestep Collection Time: 2.36308
Timestep Consumption Time: 2.43149
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.79457

Cumulative Model Updates: 101,918
Cumulative Timesteps: 850,060,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,477.01290
Policy Entropy: 1.85550
Value Function Loss: 0.07851

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.16179
Policy Update Magnitude: 0.54975
Value Function Update Magnitude: 0.64570

Collected Steps per Second: 21,737.86751
Overall Steps per Second: 10,684.74025

Timestep Collection Time: 2.30142
Timestep Consumption Time: 2.38077
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.68219

Cumulative Model Updates: 101,924
Cumulative Timesteps: 850,110,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 850110306...
Checkpoint 850110306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,601.69301
Policy Entropy: 1.83261
Value Function Loss: 0.07341

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.16104
Policy Update Magnitude: 0.48565
Value Function Update Magnitude: 0.69625

Collected Steps per Second: 21,447.36838
Overall Steps per Second: 10,651.25653

Timestep Collection Time: 2.33138
Timestep Consumption Time: 2.36309
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.69447

Cumulative Model Updates: 101,930
Cumulative Timesteps: 850,160,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,258.24091
Policy Entropy: 1.83065
Value Function Loss: 0.06929

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.15795
Policy Update Magnitude: 0.45339
Value Function Update Magnitude: 0.68722

Collected Steps per Second: 20,345.96109
Overall Steps per Second: 10,088.71394

Timestep Collection Time: 2.45779
Timestep Consumption Time: 2.49884
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.95663

Cumulative Model Updates: 101,936
Cumulative Timesteps: 850,210,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 850210314...
Checkpoint 850210314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,841.94359
Policy Entropy: 1.82559
Value Function Loss: 0.07075

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.15240
Policy Update Magnitude: 0.48449
Value Function Update Magnitude: 0.62142

Collected Steps per Second: 21,779.77081
Overall Steps per Second: 10,588.74206

Timestep Collection Time: 2.29580
Timestep Consumption Time: 2.42639
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.72219

Cumulative Model Updates: 101,942
Cumulative Timesteps: 850,260,316

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,300.93444
Policy Entropy: 1.82524
Value Function Loss: 0.07508

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.16278
Policy Update Magnitude: 0.49403
Value Function Update Magnitude: 0.61118

Collected Steps per Second: 21,702.97497
Overall Steps per Second: 10,508.22449

Timestep Collection Time: 2.30466
Timestep Consumption Time: 2.45523
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.75989

Cumulative Model Updates: 101,948
Cumulative Timesteps: 850,310,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 850310334...
Checkpoint 850310334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,813.43947
Policy Entropy: 1.83992
Value Function Loss: 0.07952

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.16857
Policy Update Magnitude: 0.52470
Value Function Update Magnitude: 0.66504

Collected Steps per Second: 21,592.87719
Overall Steps per Second: 10,578.83478

Timestep Collection Time: 2.31678
Timestep Consumption Time: 2.41209
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.72888

Cumulative Model Updates: 101,954
Cumulative Timesteps: 850,360,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,308.17580
Policy Entropy: 1.83655
Value Function Loss: 0.08635

Mean KL Divergence: 0.02364
SB3 Clip Fraction: 0.19633
Policy Update Magnitude: 0.51852
Value Function Update Magnitude: 0.61765

Collected Steps per Second: 21,868.74034
Overall Steps per Second: 10,492.68245

Timestep Collection Time: 2.28747
Timestep Consumption Time: 2.48005
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.76751

Cumulative Model Updates: 101,960
Cumulative Timesteps: 850,410,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 850410384...
Checkpoint 850410384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,130.35563
Policy Entropy: 1.85376
Value Function Loss: 0.08898

Mean KL Divergence: 0.02350
SB3 Clip Fraction: 0.19000
Policy Update Magnitude: 0.56194
Value Function Update Magnitude: 0.53082

Collected Steps per Second: 21,567.65052
Overall Steps per Second: 10,362.26412

Timestep Collection Time: 2.31940
Timestep Consumption Time: 2.50812
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.82752

Cumulative Model Updates: 101,966
Cumulative Timesteps: 850,460,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,736.07678
Policy Entropy: 1.83943
Value Function Loss: 0.08663

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.17433
Policy Update Magnitude: 0.59416
Value Function Update Magnitude: 0.68095

Collected Steps per Second: 22,768.25291
Overall Steps per Second: 10,725.42155

Timestep Collection Time: 2.19613
Timestep Consumption Time: 2.46588
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.66201

Cumulative Model Updates: 101,972
Cumulative Timesteps: 850,510,410

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 850510410...
Checkpoint 850510410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,626.66924
Policy Entropy: 1.83741
Value Function Loss: 0.08236

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.18024
Policy Update Magnitude: 0.56768
Value Function Update Magnitude: 0.78589

Collected Steps per Second: 21,302.78588
Overall Steps per Second: 10,254.85277

Timestep Collection Time: 2.34805
Timestep Consumption Time: 2.52964
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.87769

Cumulative Model Updates: 101,978
Cumulative Timesteps: 850,560,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,595.41895
Policy Entropy: 1.81621
Value Function Loss: 0.07962

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.16993
Policy Update Magnitude: 0.57420
Value Function Update Magnitude: 0.72830

Collected Steps per Second: 22,519.22010
Overall Steps per Second: 10,529.92213

Timestep Collection Time: 2.22059
Timestep Consumption Time: 2.52835
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.74894

Cumulative Model Updates: 101,984
Cumulative Timesteps: 850,610,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 850610436...
Checkpoint 850610436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,059.05700
Policy Entropy: 1.81848
Value Function Loss: 0.08665

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.17280
Policy Update Magnitude: 0.56336
Value Function Update Magnitude: 0.55508

Collected Steps per Second: 22,144.85135
Overall Steps per Second: 10,567.38738

Timestep Collection Time: 2.25804
Timestep Consumption Time: 2.47388
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.73192

Cumulative Model Updates: 101,990
Cumulative Timesteps: 850,660,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,082.53187
Policy Entropy: 1.83422
Value Function Loss: 0.08863

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.15974
Policy Update Magnitude: 0.59670
Value Function Update Magnitude: 0.52958

Collected Steps per Second: 22,610.14005
Overall Steps per Second: 10,601.75601

Timestep Collection Time: 2.21317
Timestep Consumption Time: 2.50681
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.71997

Cumulative Model Updates: 101,996
Cumulative Timesteps: 850,710,480

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 850710480...
Checkpoint 850710480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,535.18525
Policy Entropy: 1.84174
Value Function Loss: 0.08454

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.15429
Policy Update Magnitude: 0.60945
Value Function Update Magnitude: 0.54556

Collected Steps per Second: 22,238.46887
Overall Steps per Second: 10,508.41392

Timestep Collection Time: 2.24881
Timestep Consumption Time: 2.51024
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.75904

Cumulative Model Updates: 102,002
Cumulative Timesteps: 850,760,490

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,328.78185
Policy Entropy: 1.85425
Value Function Loss: 0.07979

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.15176
Policy Update Magnitude: 0.60054
Value Function Update Magnitude: 0.55072

Collected Steps per Second: 21,694.85877
Overall Steps per Second: 10,438.11111

Timestep Collection Time: 2.30469
Timestep Consumption Time: 2.48545
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.79014

Cumulative Model Updates: 102,008
Cumulative Timesteps: 850,810,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 850810490...
Checkpoint 850810490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,930.29983
Policy Entropy: 1.84648
Value Function Loss: 0.07607

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14660
Policy Update Magnitude: 0.56918
Value Function Update Magnitude: 0.47585

Collected Steps per Second: 21,532.92093
Overall Steps per Second: 10,355.14610

Timestep Collection Time: 2.32249
Timestep Consumption Time: 2.50699
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.82948

Cumulative Model Updates: 102,014
Cumulative Timesteps: 850,860,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,133.46155
Policy Entropy: 1.85565
Value Function Loss: 0.08587

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.15475
Policy Update Magnitude: 0.52547
Value Function Update Magnitude: 0.46653

Collected Steps per Second: 22,310.68134
Overall Steps per Second: 10,696.04041

Timestep Collection Time: 2.24207
Timestep Consumption Time: 2.43462
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.67668

Cumulative Model Updates: 102,020
Cumulative Timesteps: 850,910,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 850910522...
Checkpoint 850910522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,775.02618
Policy Entropy: 1.86608
Value Function Loss: 0.08489

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.16089
Policy Update Magnitude: 0.53034
Value Function Update Magnitude: 0.64339

Collected Steps per Second: 22,019.20591
Overall Steps per Second: 10,618.31381

Timestep Collection Time: 2.27129
Timestep Consumption Time: 2.43869
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.70998

Cumulative Model Updates: 102,026
Cumulative Timesteps: 850,960,534

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,939.80220
Policy Entropy: 1.87073
Value Function Loss: 0.08247

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.16429
Policy Update Magnitude: 0.53189
Value Function Update Magnitude: 0.69318

Collected Steps per Second: 22,254.98460
Overall Steps per Second: 10,463.44847

Timestep Collection Time: 2.24750
Timestep Consumption Time: 2.53276
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.78026

Cumulative Model Updates: 102,032
Cumulative Timesteps: 851,010,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 851010552...
Checkpoint 851010552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,819.58036
Policy Entropy: 1.88165
Value Function Loss: 0.08011

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.15941
Policy Update Magnitude: 0.55974
Value Function Update Magnitude: 0.70561

Collected Steps per Second: 21,923.03897
Overall Steps per Second: 10,447.93969

Timestep Collection Time: 2.28134
Timestep Consumption Time: 2.50563
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.78697

Cumulative Model Updates: 102,038
Cumulative Timesteps: 851,060,566

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,096.52182
Policy Entropy: 1.87937
Value Function Loss: 0.07985

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.15291
Policy Update Magnitude: 0.58882
Value Function Update Magnitude: 0.73850

Collected Steps per Second: 22,571.32783
Overall Steps per Second: 10,729.83980

Timestep Collection Time: 2.21564
Timestep Consumption Time: 2.44519
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.66083

Cumulative Model Updates: 102,044
Cumulative Timesteps: 851,110,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 851110576...
Checkpoint 851110576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,155.22299
Policy Entropy: 1.88651
Value Function Loss: 0.07592

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14322
Policy Update Magnitude: 0.60348
Value Function Update Magnitude: 0.82667

Collected Steps per Second: 22,077.95194
Overall Steps per Second: 10,635.84921

Timestep Collection Time: 2.26561
Timestep Consumption Time: 2.43735
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.70296

Cumulative Model Updates: 102,050
Cumulative Timesteps: 851,160,596

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,192.45718
Policy Entropy: 1.89736
Value Function Loss: 0.07816

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.60829
Value Function Update Magnitude: 0.74911

Collected Steps per Second: 22,394.18047
Overall Steps per Second: 10,543.48395

Timestep Collection Time: 2.23353
Timestep Consumption Time: 2.51045
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.74397

Cumulative Model Updates: 102,056
Cumulative Timesteps: 851,210,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 851210614...
Checkpoint 851210614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,355.25033
Policy Entropy: 1.90041
Value Function Loss: 0.08064

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.14606
Policy Update Magnitude: 0.60926
Value Function Update Magnitude: 0.72028

Collected Steps per Second: 21,753.50676
Overall Steps per Second: 10,544.11610

Timestep Collection Time: 2.29968
Timestep Consumption Time: 2.44477
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.74445

Cumulative Model Updates: 102,062
Cumulative Timesteps: 851,260,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,540.78176
Policy Entropy: 1.88142
Value Function Loss: 0.07763

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.60120
Value Function Update Magnitude: 0.74085

Collected Steps per Second: 22,058.96460
Overall Steps per Second: 10,451.85704

Timestep Collection Time: 2.26738
Timestep Consumption Time: 2.51799
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.78537

Cumulative Model Updates: 102,068
Cumulative Timesteps: 851,310,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 851310656...
Checkpoint 851310656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,676.41569
Policy Entropy: 1.85565
Value Function Loss: 0.07267

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.16738
Policy Update Magnitude: 0.56494
Value Function Update Magnitude: 0.74758

Collected Steps per Second: 21,527.73785
Overall Steps per Second: 10,376.56231

Timestep Collection Time: 2.32389
Timestep Consumption Time: 2.49736
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.82125

Cumulative Model Updates: 102,074
Cumulative Timesteps: 851,360,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,066.72332
Policy Entropy: 1.84699
Value Function Loss: 0.07269

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.16926
Policy Update Magnitude: 0.50045
Value Function Update Magnitude: 0.72830

Collected Steps per Second: 21,842.47299
Overall Steps per Second: 10,394.20493

Timestep Collection Time: 2.29013
Timestep Consumption Time: 2.52236
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.81249

Cumulative Model Updates: 102,080
Cumulative Timesteps: 851,410,706

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 851410706...
Checkpoint 851410706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,476.67539
Policy Entropy: 1.87527
Value Function Loss: 0.07676

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.16645
Policy Update Magnitude: 0.49913
Value Function Update Magnitude: 0.70118

Collected Steps per Second: 21,131.35053
Overall Steps per Second: 10,265.48874

Timestep Collection Time: 2.36615
Timestep Consumption Time: 2.50454
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.87069

Cumulative Model Updates: 102,086
Cumulative Timesteps: 851,460,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,241.34925
Policy Entropy: 1.88705
Value Function Loss: 0.07733

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.15972
Policy Update Magnitude: 0.56112
Value Function Update Magnitude: 0.70204

Collected Steps per Second: 22,950.52845
Overall Steps per Second: 10,692.82010

Timestep Collection Time: 2.17964
Timestep Consumption Time: 2.49863
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.67828

Cumulative Model Updates: 102,092
Cumulative Timesteps: 851,510,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 851510730...
Checkpoint 851510730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,085.23829
Policy Entropy: 1.90349
Value Function Loss: 0.07601

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.15186
Policy Update Magnitude: 0.56304
Value Function Update Magnitude: 0.66978

Collected Steps per Second: 21,346.98238
Overall Steps per Second: 10,590.28862

Timestep Collection Time: 2.34253
Timestep Consumption Time: 2.37934
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.72187

Cumulative Model Updates: 102,098
Cumulative Timesteps: 851,560,736

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,853.10008
Policy Entropy: 1.90858
Value Function Loss: 0.07773

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.15084
Policy Update Magnitude: 0.55877
Value Function Update Magnitude: 0.62468

Collected Steps per Second: 21,950.59077
Overall Steps per Second: 10,589.71297

Timestep Collection Time: 2.27903
Timestep Consumption Time: 2.44499
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.72402

Cumulative Model Updates: 102,104
Cumulative Timesteps: 851,610,762

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 851610762...
Checkpoint 851610762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,484.44532
Policy Entropy: 1.90640
Value Function Loss: 0.07599

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.56637
Value Function Update Magnitude: 0.58357

Collected Steps per Second: 21,124.07575
Overall Steps per Second: 10,545.93376

Timestep Collection Time: 2.36725
Timestep Consumption Time: 2.37448
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.74173

Cumulative Model Updates: 102,110
Cumulative Timesteps: 851,660,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,212.65582
Policy Entropy: 1.89993
Value Function Loss: 0.08040

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.14242
Policy Update Magnitude: 0.57307
Value Function Update Magnitude: 0.55698

Collected Steps per Second: 21,609.44200
Overall Steps per Second: 10,486.88645

Timestep Collection Time: 2.31454
Timestep Consumption Time: 2.45484
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.76939

Cumulative Model Updates: 102,116
Cumulative Timesteps: 851,710,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 851710784...
Checkpoint 851710784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,328.71298
Policy Entropy: 1.88328
Value Function Loss: 0.08016

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.58249
Value Function Update Magnitude: 0.47592

Collected Steps per Second: 21,313.77368
Overall Steps per Second: 10,332.87172

Timestep Collection Time: 2.34731
Timestep Consumption Time: 2.49452
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.84183

Cumulative Model Updates: 102,122
Cumulative Timesteps: 851,760,814

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,846.34172
Policy Entropy: 1.88010
Value Function Loss: 0.08211

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.58415
Value Function Update Magnitude: 0.46056

Collected Steps per Second: 22,361.41454
Overall Steps per Second: 10,733.61433

Timestep Collection Time: 2.23734
Timestep Consumption Time: 2.42372
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.66106

Cumulative Model Updates: 102,128
Cumulative Timesteps: 851,810,844

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 851810844...
Checkpoint 851810844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,043.50008
Policy Entropy: 1.87771
Value Function Loss: 0.07909

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.58023
Value Function Update Magnitude: 0.47303

Collected Steps per Second: 21,879.31637
Overall Steps per Second: 10,635.18113

Timestep Collection Time: 2.28563
Timestep Consumption Time: 2.41650
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.70213

Cumulative Model Updates: 102,134
Cumulative Timesteps: 851,860,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,453.70453
Policy Entropy: 1.89942
Value Function Loss: 0.07651

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.57773
Value Function Update Magnitude: 0.44477

Collected Steps per Second: 22,025.15785
Overall Steps per Second: 10,494.64020

Timestep Collection Time: 2.27031
Timestep Consumption Time: 2.49440
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.76472

Cumulative Model Updates: 102,140
Cumulative Timesteps: 851,910,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 851910856...
Checkpoint 851910856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,836.21705
Policy Entropy: 1.90186
Value Function Loss: 0.07519

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.56431
Value Function Update Magnitude: 0.44685

Collected Steps per Second: 21,218.23582
Overall Steps per Second: 10,352.01617

Timestep Collection Time: 2.35665
Timestep Consumption Time: 2.47371
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.83036

Cumulative Model Updates: 102,146
Cumulative Timesteps: 851,960,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,518.72394
Policy Entropy: 1.90111
Value Function Loss: 0.07201

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.58353

Collected Steps per Second: 22,214.74386
Overall Steps per Second: 10,660.28374

Timestep Collection Time: 2.25094
Timestep Consumption Time: 2.43974
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.69068

Cumulative Model Updates: 102,152
Cumulative Timesteps: 852,010,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 852010864...
Checkpoint 852010864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,192.93480
Policy Entropy: 1.90413
Value Function Loss: 0.07931

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.56738
Value Function Update Magnitude: 0.65821

Collected Steps per Second: 21,940.71901
Overall Steps per Second: 10,404.74015

Timestep Collection Time: 2.28005
Timestep Consumption Time: 2.52795
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.80800

Cumulative Model Updates: 102,158
Cumulative Timesteps: 852,060,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,783.66030
Policy Entropy: 1.90366
Value Function Loss: 0.07625

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.56909
Value Function Update Magnitude: 0.66492

Collected Steps per Second: 22,764.64250
Overall Steps per Second: 10,723.06884

Timestep Collection Time: 2.19727
Timestep Consumption Time: 2.46744
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.66471

Cumulative Model Updates: 102,164
Cumulative Timesteps: 852,110,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 852110910...
Checkpoint 852110910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,917.55167
Policy Entropy: 1.90856
Value Function Loss: 0.07760

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.16098
Policy Update Magnitude: 0.52552
Value Function Update Magnitude: 0.60419

Collected Steps per Second: 22,167.59532
Overall Steps per Second: 10,627.26419

Timestep Collection Time: 2.25636
Timestep Consumption Time: 2.45022
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.70657

Cumulative Model Updates: 102,170
Cumulative Timesteps: 852,160,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,204.84887
Policy Entropy: 1.90911
Value Function Loss: 0.07892

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.15894
Policy Update Magnitude: 0.51307
Value Function Update Magnitude: 0.51931

Collected Steps per Second: 22,312.31784
Overall Steps per Second: 10,499.90821

Timestep Collection Time: 2.24127
Timestep Consumption Time: 2.52144
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.76271

Cumulative Model Updates: 102,176
Cumulative Timesteps: 852,210,936

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 852210936...
Checkpoint 852210936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,989.01547
Policy Entropy: 1.92018
Value Function Loss: 0.08064

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.15380
Policy Update Magnitude: 0.50684
Value Function Update Magnitude: 0.47052

Collected Steps per Second: 21,936.27446
Overall Steps per Second: 10,682.76326

Timestep Collection Time: 2.28006
Timestep Consumption Time: 2.40188
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.68193

Cumulative Model Updates: 102,182
Cumulative Timesteps: 852,260,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,378.80843
Policy Entropy: 1.90505
Value Function Loss: 0.08414

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.15556
Policy Update Magnitude: 0.53891
Value Function Update Magnitude: 0.47115

Collected Steps per Second: 21,617.42024
Overall Steps per Second: 10,409.59633

Timestep Collection Time: 2.31378
Timestep Consumption Time: 2.49121
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.80499

Cumulative Model Updates: 102,188
Cumulative Timesteps: 852,310,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 852310970...
Checkpoint 852310970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,281.51258
Policy Entropy: 1.89344
Value Function Loss: 0.08167

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.16923
Policy Update Magnitude: 0.50308
Value Function Update Magnitude: 0.47311

Collected Steps per Second: 21,727.81579
Overall Steps per Second: 10,401.62800

Timestep Collection Time: 2.30175
Timestep Consumption Time: 2.50634
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.80809

Cumulative Model Updates: 102,194
Cumulative Timesteps: 852,360,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,009.25216
Policy Entropy: 1.87900
Value Function Loss: 0.07915

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.16326
Policy Update Magnitude: 0.49978
Value Function Update Magnitude: 0.49293

Collected Steps per Second: 22,300.31522
Overall Steps per Second: 10,655.14218

Timestep Collection Time: 2.24374
Timestep Consumption Time: 2.45221
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.69595

Cumulative Model Updates: 102,200
Cumulative Timesteps: 852,411,018

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 852411018...
Checkpoint 852411018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,211.81871
Policy Entropy: 1.89596
Value Function Loss: 0.07468

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.15043
Policy Update Magnitude: 0.47347
Value Function Update Magnitude: 0.64339

Collected Steps per Second: 21,394.67872
Overall Steps per Second: 10,251.56372

Timestep Collection Time: 2.33712
Timestep Consumption Time: 2.54038
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.87750

Cumulative Model Updates: 102,206
Cumulative Timesteps: 852,461,020

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,123.32311
Policy Entropy: 1.88860
Value Function Loss: 0.07391

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14348
Policy Update Magnitude: 0.48537
Value Function Update Magnitude: 0.66987

Collected Steps per Second: 21,812.69459
Overall Steps per Second: 10,475.80300

Timestep Collection Time: 2.29279
Timestep Consumption Time: 2.48126
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.77405

Cumulative Model Updates: 102,212
Cumulative Timesteps: 852,511,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 852511032...
Checkpoint 852511032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,339.17740
Policy Entropy: 1.90484
Value Function Loss: 0.07795

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.53949
Value Function Update Magnitude: 0.72453

Collected Steps per Second: 21,880.87949
Overall Steps per Second: 10,665.12850

Timestep Collection Time: 2.28729
Timestep Consumption Time: 2.40538
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.69268

Cumulative Model Updates: 102,218
Cumulative Timesteps: 852,561,080

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,905.63653
Policy Entropy: 1.88100
Value Function Loss: 0.07361

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.57803
Value Function Update Magnitude: 0.75776

Collected Steps per Second: 22,309.24352
Overall Steps per Second: 10,402.98258

Timestep Collection Time: 2.24221
Timestep Consumption Time: 2.56622
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.80843

Cumulative Model Updates: 102,224
Cumulative Timesteps: 852,611,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 852611102...
Checkpoint 852611102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,806.92090
Policy Entropy: 1.89680
Value Function Loss: 0.07467

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13900
Policy Update Magnitude: 0.57069
Value Function Update Magnitude: 0.73561

Collected Steps per Second: 21,669.04864
Overall Steps per Second: 10,563.49560

Timestep Collection Time: 2.30873
Timestep Consumption Time: 2.42720
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.73593

Cumulative Model Updates: 102,230
Cumulative Timesteps: 852,661,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,625.27413
Policy Entropy: 1.88840
Value Function Loss: 0.07256

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.57818
Value Function Update Magnitude: 0.70847

Collected Steps per Second: 22,326.93301
Overall Steps per Second: 10,556.14087

Timestep Collection Time: 2.24007
Timestep Consumption Time: 2.49783
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.73791

Cumulative Model Updates: 102,236
Cumulative Timesteps: 852,711,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 852711144...
Checkpoint 852711144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,429.41390
Policy Entropy: 1.88604
Value Function Loss: 0.07830

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.59106
Value Function Update Magnitude: 0.65717

Collected Steps per Second: 22,331.55812
Overall Steps per Second: 10,654.86348

Timestep Collection Time: 2.23907
Timestep Consumption Time: 2.45381
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.69288

Cumulative Model Updates: 102,242
Cumulative Timesteps: 852,761,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,379.11418
Policy Entropy: 1.87869
Value Function Loss: 0.07110

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.14696
Policy Update Magnitude: 0.58969
Value Function Update Magnitude: 0.63524

Collected Steps per Second: 22,423.15276
Overall Steps per Second: 10,540.34979

Timestep Collection Time: 2.23100
Timestep Consumption Time: 2.51514
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.74614

Cumulative Model Updates: 102,248
Cumulative Timesteps: 852,811,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 852811172...
Checkpoint 852811172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,837.57018
Policy Entropy: 1.89235
Value Function Loss: 0.07306

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.15721
Policy Update Magnitude: 0.56446
Value Function Update Magnitude: 0.63262

Collected Steps per Second: 22,151.56277
Overall Steps per Second: 10,520.54440

Timestep Collection Time: 2.25781
Timestep Consumption Time: 2.49613
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.75394

Cumulative Model Updates: 102,254
Cumulative Timesteps: 852,861,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,502.35956
Policy Entropy: 1.88459
Value Function Loss: 0.06901

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.16965
Policy Update Magnitude: 0.51290
Value Function Update Magnitude: 0.61201

Collected Steps per Second: 22,427.71519
Overall Steps per Second: 10,522.87721

Timestep Collection Time: 2.23001
Timestep Consumption Time: 2.52287
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.75288

Cumulative Model Updates: 102,260
Cumulative Timesteps: 852,911,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 852911200...
Checkpoint 852911200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,218.56858
Policy Entropy: 1.89694
Value Function Loss: 0.07124

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.15507
Policy Update Magnitude: 0.51748
Value Function Update Magnitude: 0.58381

Collected Steps per Second: 21,479.38848
Overall Steps per Second: 10,503.61973

Timestep Collection Time: 2.32846
Timestep Consumption Time: 2.43313
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.76160

Cumulative Model Updates: 102,266
Cumulative Timesteps: 852,961,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,558.77389
Policy Entropy: 1.87972
Value Function Loss: 0.06947

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.15315
Policy Update Magnitude: 0.52320
Value Function Update Magnitude: 0.63342

Collected Steps per Second: 22,190.46648
Overall Steps per Second: 10,533.10891

Timestep Collection Time: 2.25394
Timestep Consumption Time: 2.49451
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.74846

Cumulative Model Updates: 102,272
Cumulative Timesteps: 853,011,230

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 853011230...
Checkpoint 853011230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,100.21937
Policy Entropy: 1.88679
Value Function Loss: 0.07247

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.16031
Policy Update Magnitude: 0.53949
Value Function Update Magnitude: 0.70441

Collected Steps per Second: 21,740.55363
Overall Steps per Second: 10,496.88076

Timestep Collection Time: 2.30040
Timestep Consumption Time: 2.46406
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.76446

Cumulative Model Updates: 102,278
Cumulative Timesteps: 853,061,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,054.99476
Policy Entropy: 1.86812
Value Function Loss: 0.07396

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.16042
Policy Update Magnitude: 0.54639
Value Function Update Magnitude: 0.74389

Collected Steps per Second: 22,071.46142
Overall Steps per Second: 10,572.74653

Timestep Collection Time: 2.26600
Timestep Consumption Time: 2.46446
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.73046

Cumulative Model Updates: 102,284
Cumulative Timesteps: 853,111,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 853111256...
Checkpoint 853111256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,713.36741
Policy Entropy: 1.88183
Value Function Loss: 0.07478

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.15002
Policy Update Magnitude: 0.58092
Value Function Update Magnitude: 0.76450

Collected Steps per Second: 21,844.42623
Overall Steps per Second: 10,347.64029

Timestep Collection Time: 2.28955
Timestep Consumption Time: 2.54382
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.83337

Cumulative Model Updates: 102,290
Cumulative Timesteps: 853,161,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,818.71302
Policy Entropy: 1.88554
Value Function Loss: 0.07492

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.58025
Value Function Update Magnitude: 0.75597

Collected Steps per Second: 22,842.22891
Overall Steps per Second: 10,726.39871

Timestep Collection Time: 2.18902
Timestep Consumption Time: 2.47257
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.66158

Cumulative Model Updates: 102,296
Cumulative Timesteps: 853,211,272

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 853211272...
Checkpoint 853211272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,620.38598
Policy Entropy: 1.88761
Value Function Loss: 0.08195

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14194
Policy Update Magnitude: 0.59605
Value Function Update Magnitude: 0.76605

Collected Steps per Second: 22,162.96262
Overall Steps per Second: 10,635.43660

Timestep Collection Time: 2.25629
Timestep Consumption Time: 2.44554
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.70183

Cumulative Model Updates: 102,302
Cumulative Timesteps: 853,261,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,214.70018
Policy Entropy: 1.89738
Value Function Loss: 0.07903

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.59894
Value Function Update Magnitude: 0.71127

Collected Steps per Second: 22,542.12393
Overall Steps per Second: 10,546.62667

Timestep Collection Time: 2.21842
Timestep Consumption Time: 2.52319
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.74161

Cumulative Model Updates: 102,308
Cumulative Timesteps: 853,311,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 853311286...
Checkpoint 853311286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,474.64936
Policy Entropy: 1.89761
Value Function Loss: 0.07720

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13349
Policy Update Magnitude: 0.58765
Value Function Update Magnitude: 0.69990

Collected Steps per Second: 22,032.86552
Overall Steps per Second: 10,616.19163

Timestep Collection Time: 2.27015
Timestep Consumption Time: 2.44133
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.71148

Cumulative Model Updates: 102,314
Cumulative Timesteps: 853,361,304

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,239.39148
Policy Entropy: 1.88478
Value Function Loss: 0.07330

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.59222
Value Function Update Magnitude: 0.66003

Collected Steps per Second: 22,576.51459
Overall Steps per Second: 10,564.51873

Timestep Collection Time: 2.21496
Timestep Consumption Time: 2.51843
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.73339

Cumulative Model Updates: 102,320
Cumulative Timesteps: 853,411,310

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 853411310...
Checkpoint 853411310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,272.85704
Policy Entropy: 1.86988
Value Function Loss: 0.07060

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.58217
Value Function Update Magnitude: 0.73516

Collected Steps per Second: 22,189.15235
Overall Steps per Second: 10,608.23313

Timestep Collection Time: 2.25543
Timestep Consumption Time: 2.46223
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.71766

Cumulative Model Updates: 102,326
Cumulative Timesteps: 853,461,356

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,515.41495
Policy Entropy: 1.86764
Value Function Loss: 0.07888

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.58331
Value Function Update Magnitude: 0.76867

Collected Steps per Second: 21,538.17675
Overall Steps per Second: 10,416.38764

Timestep Collection Time: 2.32183
Timestep Consumption Time: 2.47907
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.80090

Cumulative Model Updates: 102,332
Cumulative Timesteps: 853,511,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 853511364...
Checkpoint 853511364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,026.56805
Policy Entropy: 1.86019
Value Function Loss: 0.08026

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.58885
Value Function Update Magnitude: 0.77928

Collected Steps per Second: 21,570.52495
Overall Steps per Second: 10,359.73320

Timestep Collection Time: 2.31946
Timestep Consumption Time: 2.51001
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.82947

Cumulative Model Updates: 102,338
Cumulative Timesteps: 853,561,396

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,681.82862
Policy Entropy: 1.86363
Value Function Loss: 0.08514

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.59277
Value Function Update Magnitude: 0.73131

Collected Steps per Second: 21,816.36103
Overall Steps per Second: 10,426.64884

Timestep Collection Time: 2.29232
Timestep Consumption Time: 2.50405
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.79636

Cumulative Model Updates: 102,344
Cumulative Timesteps: 853,611,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 853611406...
Checkpoint 853611406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,009.16449
Policy Entropy: 1.84853
Value Function Loss: 0.07931

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14576
Policy Update Magnitude: 0.58772
Value Function Update Magnitude: 0.69716

Collected Steps per Second: 21,381.08762
Overall Steps per Second: 10,442.68892

Timestep Collection Time: 2.33926
Timestep Consumption Time: 2.45031
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.78957

Cumulative Model Updates: 102,350
Cumulative Timesteps: 853,661,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,731.10404
Policy Entropy: 1.83870
Value Function Loss: 0.07785

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.56234
Value Function Update Magnitude: 0.65509

Collected Steps per Second: 22,523.76996
Overall Steps per Second: 10,531.93981

Timestep Collection Time: 2.22077
Timestep Consumption Time: 2.52860
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.74936

Cumulative Model Updates: 102,356
Cumulative Timesteps: 853,711,442

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 853711442...
Checkpoint 853711442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,930.14274
Policy Entropy: 1.83973
Value Function Loss: 0.07359

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.15794
Policy Update Magnitude: 0.53711
Value Function Update Magnitude: 0.63996

Collected Steps per Second: 21,826.48832
Overall Steps per Second: 10,547.44054

Timestep Collection Time: 2.29244
Timestep Consumption Time: 2.45146
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.74390

Cumulative Model Updates: 102,362
Cumulative Timesteps: 853,761,478

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,511.22163
Policy Entropy: 1.85753
Value Function Loss: 0.07430

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.50251
Value Function Update Magnitude: 0.59488

Collected Steps per Second: 22,230.94541
Overall Steps per Second: 10,541.32987

Timestep Collection Time: 2.25020
Timestep Consumption Time: 2.49531
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.74551

Cumulative Model Updates: 102,368
Cumulative Timesteps: 853,811,502

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 853811502...
Checkpoint 853811502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,358.12051
Policy Entropy: 1.87372
Value Function Loss: 0.07726

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.54178
Value Function Update Magnitude: 0.54327

Collected Steps per Second: 22,088.43332
Overall Steps per Second: 10,614.05480

Timestep Collection Time: 2.26408
Timestep Consumption Time: 2.44760
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.71168

Cumulative Model Updates: 102,374
Cumulative Timesteps: 853,861,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,043.39568
Policy Entropy: 1.87766
Value Function Loss: 0.08388

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.14090
Policy Update Magnitude: 0.57821
Value Function Update Magnitude: 0.57829

Collected Steps per Second: 22,322.84656
Overall Steps per Second: 10,511.07286

Timestep Collection Time: 2.24004
Timestep Consumption Time: 2.51723
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.75727

Cumulative Model Updates: 102,380
Cumulative Timesteps: 853,911,516

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 853911516...
Checkpoint 853911516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,788.28510
Policy Entropy: 1.88329
Value Function Loss: 0.08607

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.59321
Value Function Update Magnitude: 0.64556

Collected Steps per Second: 22,317.36358
Overall Steps per Second: 10,600.04780

Timestep Collection Time: 2.24148
Timestep Consumption Time: 2.47774
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.71922

Cumulative Model Updates: 102,386
Cumulative Timesteps: 853,961,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,327.31976
Policy Entropy: 1.87884
Value Function Loss: 0.08332

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14349
Policy Update Magnitude: 0.57365
Value Function Update Magnitude: 0.63491

Collected Steps per Second: 22,540.15960
Overall Steps per Second: 10,620.10578

Timestep Collection Time: 2.21853
Timestep Consumption Time: 2.49009
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.70862

Cumulative Model Updates: 102,392
Cumulative Timesteps: 854,011,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 854011546...
Checkpoint 854011546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,340.68633
Policy Entropy: 1.87151
Value Function Loss: 0.08023

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.56651
Value Function Update Magnitude: 0.70637

Collected Steps per Second: 20,743.00803
Overall Steps per Second: 10,452.73200

Timestep Collection Time: 2.41267
Timestep Consumption Time: 2.37517
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.78784

Cumulative Model Updates: 102,398
Cumulative Timesteps: 854,061,592

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,642.84061
Policy Entropy: 1.85003
Value Function Loss: 0.08010

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.57595
Value Function Update Magnitude: 0.76909

Collected Steps per Second: 21,291.49047
Overall Steps per Second: 10,509.93066

Timestep Collection Time: 2.34883
Timestep Consumption Time: 2.40953
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.75836

Cumulative Model Updates: 102,404
Cumulative Timesteps: 854,111,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 854111602...
Checkpoint 854111602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,418.82879
Policy Entropy: 1.85101
Value Function Loss: 0.08248

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.56232
Value Function Update Magnitude: 0.79817

Collected Steps per Second: 21,273.35883
Overall Steps per Second: 10,616.86111

Timestep Collection Time: 2.35120
Timestep Consumption Time: 2.35998
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.71119

Cumulative Model Updates: 102,410
Cumulative Timesteps: 854,161,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,190.38509
Policy Entropy: 1.87139
Value Function Loss: 0.08011

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.14255
Policy Update Magnitude: 0.57247
Value Function Update Magnitude: 0.80256

Collected Steps per Second: 20,413.61928
Overall Steps per Second: 10,380.91758

Timestep Collection Time: 2.45189
Timestep Consumption Time: 2.36965
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.82154

Cumulative Model Updates: 102,416
Cumulative Timesteps: 854,211,672

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 854211672...
Checkpoint 854211672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,780.58670
Policy Entropy: 1.87990
Value Function Loss: 0.07961

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.16256
Policy Update Magnitude: 0.54573
Value Function Update Magnitude: 0.73710

Collected Steps per Second: 21,113.89896
Overall Steps per Second: 10,433.06046

Timestep Collection Time: 2.36877
Timestep Consumption Time: 2.42503
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.79380

Cumulative Model Updates: 102,422
Cumulative Timesteps: 854,261,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,802.44628
Policy Entropy: 1.88208
Value Function Loss: 0.07378

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.15364
Policy Update Magnitude: 0.54157
Value Function Update Magnitude: 0.79040

Collected Steps per Second: 21,558.17414
Overall Steps per Second: 10,674.89039

Timestep Collection Time: 2.32023
Timestep Consumption Time: 2.36553
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.68576

Cumulative Model Updates: 102,428
Cumulative Timesteps: 854,311,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 854311706...
Checkpoint 854311706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,533.27432
Policy Entropy: 1.88004
Value Function Loss: 0.07121

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.56399
Value Function Update Magnitude: 0.78922

Collected Steps per Second: 21,391.62306
Overall Steps per Second: 10,332.32200

Timestep Collection Time: 2.33821
Timestep Consumption Time: 2.50272
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.84093

Cumulative Model Updates: 102,434
Cumulative Timesteps: 854,361,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,393.82805
Policy Entropy: 1.88146
Value Function Loss: 0.06959

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.14220
Policy Update Magnitude: 0.57482
Value Function Update Magnitude: 0.70050

Collected Steps per Second: 22,206.44616
Overall Steps per Second: 10,471.10094

Timestep Collection Time: 2.25250
Timestep Consumption Time: 2.52446
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.77696

Cumulative Model Updates: 102,440
Cumulative Timesteps: 854,411,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 854411744...
Checkpoint 854411744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,512.67721
Policy Entropy: 1.87947
Value Function Loss: 0.07212

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.57006
Value Function Update Magnitude: 0.65106

Collected Steps per Second: 21,632.76660
Overall Steps per Second: 10,504.72470

Timestep Collection Time: 2.31233
Timestep Consumption Time: 2.44953
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.76186

Cumulative Model Updates: 102,446
Cumulative Timesteps: 854,461,766

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,846.92516
Policy Entropy: 1.85527
Value Function Loss: 0.07156

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.14715
Policy Update Magnitude: 0.56299
Value Function Update Magnitude: 0.61754

Collected Steps per Second: 22,303.64483
Overall Steps per Second: 10,556.04657

Timestep Collection Time: 2.24197
Timestep Consumption Time: 2.49504
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.73700

Cumulative Model Updates: 102,452
Cumulative Timesteps: 854,511,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 854511770...
Checkpoint 854511770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,541.87588
Policy Entropy: 1.86350
Value Function Loss: 0.07188

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.57414
Value Function Update Magnitude: 0.68177

Collected Steps per Second: 22,334.41466
Overall Steps per Second: 10,586.31636

Timestep Collection Time: 2.23986
Timestep Consumption Time: 2.48567
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.72553

Cumulative Model Updates: 102,458
Cumulative Timesteps: 854,561,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,135.89555
Policy Entropy: 1.85094
Value Function Loss: 0.06748

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.57600
Value Function Update Magnitude: 0.76322

Collected Steps per Second: 22,399.25563
Overall Steps per Second: 10,621.97747

Timestep Collection Time: 2.23329
Timestep Consumption Time: 2.47619
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.70948

Cumulative Model Updates: 102,464
Cumulative Timesteps: 854,611,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 854611820...
Checkpoint 854611820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,248.04867
Policy Entropy: 1.86131
Value Function Loss: 0.07257

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.57552
Value Function Update Magnitude: 0.74137

Collected Steps per Second: 22,159.92942
Overall Steps per Second: 10,469.91861

Timestep Collection Time: 2.25705
Timestep Consumption Time: 2.52007
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.77711

Cumulative Model Updates: 102,470
Cumulative Timesteps: 854,661,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,818.38998
Policy Entropy: 1.86030
Value Function Loss: 0.07679

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.57910
Value Function Update Magnitude: 0.63237

Collected Steps per Second: 22,351.52441
Overall Steps per Second: 10,473.69477

Timestep Collection Time: 2.23824
Timestep Consumption Time: 2.53830
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.77654

Cumulative Model Updates: 102,476
Cumulative Timesteps: 854,711,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 854711864...
Checkpoint 854711864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,722.38771
Policy Entropy: 1.86964
Value Function Loss: 0.07835

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.57066
Value Function Update Magnitude: 0.53303

Collected Steps per Second: 21,284.80831
Overall Steps per Second: 10,282.71355

Timestep Collection Time: 2.34928
Timestep Consumption Time: 2.51364
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.86292

Cumulative Model Updates: 102,482
Cumulative Timesteps: 854,761,868

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,724.67331
Policy Entropy: 1.87095
Value Function Loss: 0.08038

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.14258
Policy Update Magnitude: 0.56417
Value Function Update Magnitude: 0.49378

Collected Steps per Second: 22,087.36706
Overall Steps per Second: 10,460.58980

Timestep Collection Time: 2.26383
Timestep Consumption Time: 2.51621
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.78004

Cumulative Model Updates: 102,488
Cumulative Timesteps: 854,811,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 854811870...
Checkpoint 854811870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,340.67842
Policy Entropy: 1.85406
Value Function Loss: 0.07634

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.14600
Policy Update Magnitude: 0.56231
Value Function Update Magnitude: 0.50544

Collected Steps per Second: 21,671.27368
Overall Steps per Second: 10,605.24690

Timestep Collection Time: 2.30739
Timestep Consumption Time: 2.40764
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.71502

Cumulative Model Updates: 102,494
Cumulative Timesteps: 854,861,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,358.63288
Policy Entropy: 1.86134
Value Function Loss: 0.07733

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.54478
Value Function Update Magnitude: 0.59699

Collected Steps per Second: 22,078.88804
Overall Steps per Second: 10,460.65919

Timestep Collection Time: 2.26461
Timestep Consumption Time: 2.51521
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.77981

Cumulative Model Updates: 102,500
Cumulative Timesteps: 854,911,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 854911874...
Checkpoint 854911874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,998.51580
Policy Entropy: 1.88511
Value Function Loss: 0.07367

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.54187
Value Function Update Magnitude: 0.61631

Collected Steps per Second: 21,652.21750
Overall Steps per Second: 10,582.36292

Timestep Collection Time: 2.31043
Timestep Consumption Time: 2.41687
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.72730

Cumulative Model Updates: 102,506
Cumulative Timesteps: 854,961,900

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,988.56909
Policy Entropy: 1.90135
Value Function Loss: 0.07642

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12808
Policy Update Magnitude: 0.56121
Value Function Update Magnitude: 0.55625

Collected Steps per Second: 22,345.16790
Overall Steps per Second: 10,440.24116

Timestep Collection Time: 2.23869
Timestep Consumption Time: 2.55277
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.79146

Cumulative Model Updates: 102,512
Cumulative Timesteps: 855,011,924

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 855011924...
Checkpoint 855011924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,486.80581
Policy Entropy: 1.92003
Value Function Loss: 0.07666

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.55273
Value Function Update Magnitude: 0.51357

Collected Steps per Second: 22,293.40147
Overall Steps per Second: 10,608.90409

Timestep Collection Time: 2.24344
Timestep Consumption Time: 2.47090
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.71434

Cumulative Model Updates: 102,518
Cumulative Timesteps: 855,061,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,066.85440
Policy Entropy: 1.93091
Value Function Loss: 0.07984

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.53702
Value Function Update Magnitude: 0.55741

Collected Steps per Second: 22,586.67199
Overall Steps per Second: 10,547.99960

Timestep Collection Time: 2.21467
Timestep Consumption Time: 2.52765
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.74232

Cumulative Model Updates: 102,524
Cumulative Timesteps: 855,111,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 855111960...
Checkpoint 855111960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,488.51293
Policy Entropy: 1.94019
Value Function Loss: 0.07639

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.15712
Policy Update Magnitude: 0.50434
Value Function Update Magnitude: 0.66608

Collected Steps per Second: 22,137.74186
Overall Steps per Second: 10,624.89997

Timestep Collection Time: 2.25967
Timestep Consumption Time: 2.44852
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.70819

Cumulative Model Updates: 102,530
Cumulative Timesteps: 855,161,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,681.15754
Policy Entropy: 1.93190
Value Function Loss: 0.07518

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.54773
Value Function Update Magnitude: 0.65223

Collected Steps per Second: 21,845.98151
Overall Steps per Second: 10,435.79878

Timestep Collection Time: 2.29031
Timestep Consumption Time: 2.50415
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.79446

Cumulative Model Updates: 102,536
Cumulative Timesteps: 855,212,018

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 855212018...
Checkpoint 855212018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,973.88828
Policy Entropy: 1.91712
Value Function Loss: 0.07619

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.58133
Value Function Update Magnitude: 0.64247

Collected Steps per Second: 22,291.73344
Overall Steps per Second: 10,661.90312

Timestep Collection Time: 2.24514
Timestep Consumption Time: 2.44896
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.69410

Cumulative Model Updates: 102,542
Cumulative Timesteps: 855,262,066

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,333.78311
Policy Entropy: 1.92253
Value Function Loss: 0.08185

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14301
Policy Update Magnitude: 0.57972
Value Function Update Magnitude: 0.66083

Collected Steps per Second: 22,145.71243
Overall Steps per Second: 10,469.97990

Timestep Collection Time: 2.25877
Timestep Consumption Time: 2.51889
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.77766

Cumulative Model Updates: 102,548
Cumulative Timesteps: 855,312,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 855312088...
Checkpoint 855312088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,811.92857
Policy Entropy: 1.92435
Value Function Loss: 0.07763

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.15828
Policy Update Magnitude: 0.52532
Value Function Update Magnitude: 0.72033

Collected Steps per Second: 21,871.86795
Overall Steps per Second: 10,588.65802

Timestep Collection Time: 2.28604
Timestep Consumption Time: 2.43599
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.72203

Cumulative Model Updates: 102,554
Cumulative Timesteps: 855,362,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,279.37934
Policy Entropy: 1.91097
Value Function Loss: 0.07910

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.15077
Policy Update Magnitude: 0.51251
Value Function Update Magnitude: 0.69500

Collected Steps per Second: 21,839.15166
Overall Steps per Second: 10,442.25616

Timestep Collection Time: 2.29084
Timestep Consumption Time: 2.50027
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.79111

Cumulative Model Updates: 102,560
Cumulative Timesteps: 855,412,118

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 855412118...
Checkpoint 855412118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,056.26003
Policy Entropy: 1.91391
Value Function Loss: 0.07859

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.54827
Value Function Update Magnitude: 0.72134

Collected Steps per Second: 21,708.53232
Overall Steps per Second: 10,409.31840

Timestep Collection Time: 2.30435
Timestep Consumption Time: 2.50135
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.80569

Cumulative Model Updates: 102,566
Cumulative Timesteps: 855,462,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,366.19103
Policy Entropy: 1.91099
Value Function Loss: 0.08189

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.15062
Policy Update Magnitude: 0.55622
Value Function Update Magnitude: 0.77350

Collected Steps per Second: 21,807.03876
Overall Steps per Second: 10,361.08218

Timestep Collection Time: 2.29302
Timestep Consumption Time: 2.53312
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.82614

Cumulative Model Updates: 102,572
Cumulative Timesteps: 855,512,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 855512146...
Checkpoint 855512146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,388.16258
Policy Entropy: 1.89250
Value Function Loss: 0.07172

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.56604
Value Function Update Magnitude: 0.71555

Collected Steps per Second: 22,119.73447
Overall Steps per Second: 10,647.34431

Timestep Collection Time: 2.26115
Timestep Consumption Time: 2.43636
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.69751

Cumulative Model Updates: 102,578
Cumulative Timesteps: 855,562,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,438.95397
Policy Entropy: 1.87737
Value Function Loss: 0.06916

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.56870
Value Function Update Magnitude: 0.69369

Collected Steps per Second: 22,370.08481
Overall Steps per Second: 10,495.25662

Timestep Collection Time: 2.23566
Timestep Consumption Time: 2.52954
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.76520

Cumulative Model Updates: 102,584
Cumulative Timesteps: 855,612,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 855612174...
Checkpoint 855612174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,877.92050
Policy Entropy: 1.87632
Value Function Loss: 0.07606

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.57356
Value Function Update Magnitude: 0.64237

Collected Steps per Second: 22,231.64618
Overall Steps per Second: 10,475.54781

Timestep Collection Time: 2.24959
Timestep Consumption Time: 2.52458
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.77417

Cumulative Model Updates: 102,590
Cumulative Timesteps: 855,662,186

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,456.99581
Policy Entropy: 1.89808
Value Function Loss: 0.08705

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14853
Policy Update Magnitude: 0.57010
Value Function Update Magnitude: 0.64019

Collected Steps per Second: 22,389.64981
Overall Steps per Second: 10,597.45942

Timestep Collection Time: 2.23443
Timestep Consumption Time: 2.48633
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.72075

Cumulative Model Updates: 102,596
Cumulative Timesteps: 855,712,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 855712214...
Checkpoint 855712214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,728.98062
Policy Entropy: 1.90777
Value Function Loss: 0.09109

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.16606
Policy Update Magnitude: 0.52012
Value Function Update Magnitude: 0.73195

Collected Steps per Second: 22,315.07253
Overall Steps per Second: 10,579.73280

Timestep Collection Time: 2.24091
Timestep Consumption Time: 2.48568
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.72658

Cumulative Model Updates: 102,602
Cumulative Timesteps: 855,762,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,091.15824
Policy Entropy: 1.90873
Value Function Loss: 0.08772

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.16208
Policy Update Magnitude: 0.49180
Value Function Update Magnitude: 0.68020

Collected Steps per Second: 22,039.55797
Overall Steps per Second: 10,506.65740

Timestep Collection Time: 2.26956
Timestep Consumption Time: 2.49124
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.76079

Cumulative Model Updates: 102,608
Cumulative Timesteps: 855,812,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 855812240...
Checkpoint 855812240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,773.51680
Policy Entropy: 1.91112
Value Function Loss: 0.08185

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.14952
Policy Update Magnitude: 0.52043
Value Function Update Magnitude: 0.66193

Collected Steps per Second: 21,964.33825
Overall Steps per Second: 10,579.18679

Timestep Collection Time: 2.27751
Timestep Consumption Time: 2.45102
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.72853

Cumulative Model Updates: 102,614
Cumulative Timesteps: 855,862,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,898.23866
Policy Entropy: 1.93451
Value Function Loss: 0.08141

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.15150
Policy Update Magnitude: 0.57105
Value Function Update Magnitude: 0.66431

Collected Steps per Second: 22,356.89009
Overall Steps per Second: 10,587.68871

Timestep Collection Time: 2.23689
Timestep Consumption Time: 2.48652
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.72341

Cumulative Model Updates: 102,620
Cumulative Timesteps: 855,912,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 855912274...
Checkpoint 855912274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,519.26763
Policy Entropy: 1.93161
Value Function Loss: 0.08155

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.15567
Policy Update Magnitude: 0.58605
Value Function Update Magnitude: 0.67561

Collected Steps per Second: 21,528.33807
Overall Steps per Second: 10,520.23979

Timestep Collection Time: 2.32271
Timestep Consumption Time: 2.43042
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.75312

Cumulative Model Updates: 102,626
Cumulative Timesteps: 855,962,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,762.50424
Policy Entropy: 1.92636
Value Function Loss: 0.07903

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.16063
Policy Update Magnitude: 0.55705
Value Function Update Magnitude: 0.71667

Collected Steps per Second: 21,626.97311
Overall Steps per Second: 10,383.70096

Timestep Collection Time: 2.31267
Timestep Consumption Time: 2.50411
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.81678

Cumulative Model Updates: 102,632
Cumulative Timesteps: 856,012,294

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 856012294...
Checkpoint 856012294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,894.90920
Policy Entropy: 1.90267
Value Function Loss: 0.07873

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.16713
Policy Update Magnitude: 0.52398
Value Function Update Magnitude: 0.77443

Collected Steps per Second: 21,767.29714
Overall Steps per Second: 10,389.33968

Timestep Collection Time: 2.29712
Timestep Consumption Time: 2.51570
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.81282

Cumulative Model Updates: 102,638
Cumulative Timesteps: 856,062,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,768.98122
Policy Entropy: 1.91371
Value Function Loss: 0.07620

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.14786
Policy Update Magnitude: 0.53819
Value Function Update Magnitude: 0.66075

Collected Steps per Second: 21,201.79269
Overall Steps per Second: 10,297.14243

Timestep Collection Time: 2.35905
Timestep Consumption Time: 2.49822
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.85727

Cumulative Model Updates: 102,644
Cumulative Timesteps: 856,112,312

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 856112312...
Checkpoint 856112312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,789.07190
Policy Entropy: 1.92751
Value Function Loss: 0.07816

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.14442
Policy Update Magnitude: 0.56604
Value Function Update Magnitude: 0.62095

Collected Steps per Second: 21,490.34697
Overall Steps per Second: 10,304.62130

Timestep Collection Time: 2.32663
Timestep Consumption Time: 2.52557
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.85219

Cumulative Model Updates: 102,650
Cumulative Timesteps: 856,162,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,192.50155
Policy Entropy: 1.95205
Value Function Loss: 0.08289

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.58141
Value Function Update Magnitude: 0.69654

Collected Steps per Second: 22,369.86680
Overall Steps per Second: 10,423.97262

Timestep Collection Time: 2.23586
Timestep Consumption Time: 2.56231
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.79817

Cumulative Model Updates: 102,656
Cumulative Timesteps: 856,212,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 856212328...
Checkpoint 856212328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,886.61778
Policy Entropy: 1.94368
Value Function Loss: 0.08552

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.59544
Value Function Update Magnitude: 0.65354

Collected Steps per Second: 22,336.05782
Overall Steps per Second: 10,517.98578

Timestep Collection Time: 2.23943
Timestep Consumption Time: 2.51624
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.75566

Cumulative Model Updates: 102,662
Cumulative Timesteps: 856,262,348

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,265.05732
Policy Entropy: 1.92635
Value Function Loss: 0.08033

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.15809
Policy Update Magnitude: 0.56985
Value Function Update Magnitude: 0.59588

Collected Steps per Second: 22,156.70825
Overall Steps per Second: 10,502.96678

Timestep Collection Time: 2.25719
Timestep Consumption Time: 2.50451
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.76170

Cumulative Model Updates: 102,668
Cumulative Timesteps: 856,312,360

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 856312360...
Checkpoint 856312360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,348.24302
Policy Entropy: 1.90860
Value Function Loss: 0.08279

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.15155
Policy Update Magnitude: 0.55769
Value Function Update Magnitude: 0.64861

Collected Steps per Second: 22,321.21636
Overall Steps per Second: 10,698.05207

Timestep Collection Time: 2.24047
Timestep Consumption Time: 2.43421
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.67468

Cumulative Model Updates: 102,674
Cumulative Timesteps: 856,362,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,449.80502
Policy Entropy: 1.90647
Value Function Loss: 0.07486

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.57033
Value Function Update Magnitude: 0.64626

Collected Steps per Second: 22,520.50513
Overall Steps per Second: 10,606.54853

Timestep Collection Time: 2.22055
Timestep Consumption Time: 2.49427
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.71482

Cumulative Model Updates: 102,680
Cumulative Timesteps: 856,412,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 856412378...
Checkpoint 856412378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,005.52468
Policy Entropy: 1.93256
Value Function Loss: 0.08362

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.16891
Policy Update Magnitude: 0.52357
Value Function Update Magnitude: 0.60534

Collected Steps per Second: 21,749.43217
Overall Steps per Second: 10,401.52771

Timestep Collection Time: 2.29974
Timestep Consumption Time: 2.50898
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.80872

Cumulative Model Updates: 102,686
Cumulative Timesteps: 856,462,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,464.30447
Policy Entropy: 1.92984
Value Function Loss: 0.08533

Mean KL Divergence: 0.02664
SB3 Clip Fraction: 0.20021
Policy Update Magnitude: 0.47207
Value Function Update Magnitude: 0.60085

Collected Steps per Second: 22,345.33650
Overall Steps per Second: 10,504.36889

Timestep Collection Time: 2.23850
Timestep Consumption Time: 2.52333
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.76183

Cumulative Model Updates: 102,692
Cumulative Timesteps: 856,512,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 856512416...
Checkpoint 856512416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,725.70695
Policy Entropy: 1.94307
Value Function Loss: 0.09193

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.17718
Policy Update Magnitude: 0.47835
Value Function Update Magnitude: 0.65981

Collected Steps per Second: 21,872.64427
Overall Steps per Second: 10,573.89728

Timestep Collection Time: 2.28724
Timestep Consumption Time: 2.44403
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.73127

Cumulative Model Updates: 102,698
Cumulative Timesteps: 856,562,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,843.57706
Policy Entropy: 1.93404
Value Function Loss: 0.08796

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.16482
Policy Update Magnitude: 0.48943
Value Function Update Magnitude: 0.62520

Collected Steps per Second: 21,993.67391
Overall Steps per Second: 10,489.42000

Timestep Collection Time: 2.27420
Timestep Consumption Time: 2.49422
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.76842

Cumulative Model Updates: 102,704
Cumulative Timesteps: 856,612,462

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 856612462...
Checkpoint 856612462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,924.92005
Policy Entropy: 1.93465
Value Function Loss: 0.08596

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.15731
Policy Update Magnitude: 0.47925
Value Function Update Magnitude: 0.61428

Collected Steps per Second: 21,530.41970
Overall Steps per Second: 10,365.27823

Timestep Collection Time: 2.32285
Timestep Consumption Time: 2.50210
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.82495

Cumulative Model Updates: 102,710
Cumulative Timesteps: 856,662,474

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,038.36366
Policy Entropy: 1.92793
Value Function Loss: 0.08172

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.48589
Value Function Update Magnitude: 0.58342

Collected Steps per Second: 22,238.28395
Overall Steps per Second: 10,646.43737

Timestep Collection Time: 2.24882
Timestep Consumption Time: 2.44852
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.69735

Cumulative Model Updates: 102,716
Cumulative Timesteps: 856,712,484

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 856712484...
Checkpoint 856712484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,298.42756
Policy Entropy: 1.91773
Value Function Loss: 0.07765

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.51126
Value Function Update Magnitude: 0.53329

Collected Steps per Second: 21,818.60122
Overall Steps per Second: 10,339.25502

Timestep Collection Time: 2.29245
Timestep Consumption Time: 2.54523
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.83768

Cumulative Model Updates: 102,722
Cumulative Timesteps: 856,762,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,735.00339
Policy Entropy: 1.92901
Value Function Loss: 0.08146

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.15539
Policy Update Magnitude: 0.50002
Value Function Update Magnitude: 0.46995

Collected Steps per Second: 22,745.00913
Overall Steps per Second: 10,749.18409

Timestep Collection Time: 2.19925
Timestep Consumption Time: 2.45431
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.65356

Cumulative Model Updates: 102,728
Cumulative Timesteps: 856,812,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 856812524...
Checkpoint 856812524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,191.95863
Policy Entropy: 1.91968
Value Function Loss: 0.08832

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.16388
Policy Update Magnitude: 0.49374
Value Function Update Magnitude: 0.46414

Collected Steps per Second: 21,943.91437
Overall Steps per Second: 10,447.64521

Timestep Collection Time: 2.27908
Timestep Consumption Time: 2.50783
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.78692

Cumulative Model Updates: 102,734
Cumulative Timesteps: 856,862,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,962.77097
Policy Entropy: 1.90290
Value Function Loss: 0.09209

Mean KL Divergence: 0.02525
SB3 Clip Fraction: 0.18994
Policy Update Magnitude: 0.47949
Value Function Update Magnitude: 0.42283

Collected Steps per Second: 22,749.18082
Overall Steps per Second: 10,795.34688

Timestep Collection Time: 2.19823
Timestep Consumption Time: 2.43413
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.63237

Cumulative Model Updates: 102,740
Cumulative Timesteps: 856,912,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 856912544...
Checkpoint 856912544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,274.59573
Policy Entropy: 1.90927
Value Function Loss: 0.09658

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.16314
Policy Update Magnitude: 0.54338
Value Function Update Magnitude: 0.39929

Collected Steps per Second: 22,083.28984
Overall Steps per Second: 10,594.68125

Timestep Collection Time: 2.26470
Timestep Consumption Time: 2.45578
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.72048

Cumulative Model Updates: 102,746
Cumulative Timesteps: 856,962,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,547.45673
Policy Entropy: 1.90697
Value Function Loss: 0.09323

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.14999
Policy Update Magnitude: 0.56613
Value Function Update Magnitude: 0.43757

Collected Steps per Second: 22,315.76911
Overall Steps per Second: 10,504.08832

Timestep Collection Time: 2.24182
Timestep Consumption Time: 2.52089
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.76272

Cumulative Model Updates: 102,752
Cumulative Timesteps: 857,012,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 857012584...
Checkpoint 857012584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,310.72611
Policy Entropy: 1.89120
Value Function Loss: 0.08926

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.15563
Policy Update Magnitude: 0.54726
Value Function Update Magnitude: 0.39106

Collected Steps per Second: 22,072.63479
Overall Steps per Second: 10,619.89187

Timestep Collection Time: 2.26643
Timestep Consumption Time: 2.44417
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.71059

Cumulative Model Updates: 102,758
Cumulative Timesteps: 857,062,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,537.30057
Policy Entropy: 1.86557
Value Function Loss: 0.08079

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.16330
Policy Update Magnitude: 0.51968
Value Function Update Magnitude: 0.40181

Collected Steps per Second: 21,498.32052
Overall Steps per Second: 10,503.64459

Timestep Collection Time: 2.32707
Timestep Consumption Time: 2.43585
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.76292

Cumulative Model Updates: 102,764
Cumulative Timesteps: 857,112,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 857112638...
Checkpoint 857112638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,576.63089
Policy Entropy: 1.86588
Value Function Loss: 0.08136

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.15833
Policy Update Magnitude: 0.55074
Value Function Update Magnitude: 0.43537

Collected Steps per Second: 21,844.07955
Overall Steps per Second: 10,571.18770

Timestep Collection Time: 2.29032
Timestep Consumption Time: 2.44235
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.73268

Cumulative Model Updates: 102,770
Cumulative Timesteps: 857,162,668

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,115.79632
Policy Entropy: 1.89355
Value Function Loss: 0.08026

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.16121
Policy Update Magnitude: 0.52450
Value Function Update Magnitude: 0.48959

Collected Steps per Second: 21,885.68336
Overall Steps per Second: 10,450.15152

Timestep Collection Time: 2.28533
Timestep Consumption Time: 2.50082
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.78615

Cumulative Model Updates: 102,776
Cumulative Timesteps: 857,212,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 857212684...
Checkpoint 857212684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,641.18395
Policy Entropy: 1.89474
Value Function Loss: 0.08321

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.16392
Policy Update Magnitude: 0.51379
Value Function Update Magnitude: 0.49102

Collected Steps per Second: 21,860.56323
Overall Steps per Second: 10,562.52341

Timestep Collection Time: 2.28869
Timestep Consumption Time: 2.44806
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.73675

Cumulative Model Updates: 102,782
Cumulative Timesteps: 857,262,716

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,616.29907
Policy Entropy: 1.90456
Value Function Loss: 0.08369

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.15962
Policy Update Magnitude: 0.51879
Value Function Update Magnitude: 0.61884

Collected Steps per Second: 22,388.38075
Overall Steps per Second: 10,536.20059

Timestep Collection Time: 2.23384
Timestep Consumption Time: 2.51285
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.74668

Cumulative Model Updates: 102,788
Cumulative Timesteps: 857,312,728

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 857312728...
Checkpoint 857312728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,116.29977
Policy Entropy: 1.89500
Value Function Loss: 0.08082

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.15751
Policy Update Magnitude: 0.50885
Value Function Update Magnitude: 0.64846

Collected Steps per Second: 21,979.18941
Overall Steps per Second: 10,557.36341

Timestep Collection Time: 2.27606
Timestep Consumption Time: 2.46243
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.73849

Cumulative Model Updates: 102,794
Cumulative Timesteps: 857,362,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,070.14785
Policy Entropy: 1.89653
Value Function Loss: 0.08206

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.15036
Policy Update Magnitude: 0.53006
Value Function Update Magnitude: 0.58524

Collected Steps per Second: 22,096.18539
Overall Steps per Second: 10,495.30684

Timestep Collection Time: 2.26338
Timestep Consumption Time: 2.50180
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.76518

Cumulative Model Updates: 102,800
Cumulative Timesteps: 857,412,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 857412766...
Checkpoint 857412766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,838.40485
Policy Entropy: 1.88649
Value Function Loss: 0.07846

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.15517
Policy Update Magnitude: 0.50648
Value Function Update Magnitude: 0.59763

Collected Steps per Second: 22,248.14118
Overall Steps per Second: 10,651.38366

Timestep Collection Time: 2.24855
Timestep Consumption Time: 2.44812
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.69667

Cumulative Model Updates: 102,806
Cumulative Timesteps: 857,462,792

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,167.10735
Policy Entropy: 1.89332
Value Function Loss: 0.08082

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.16359
Policy Update Magnitude: 0.50912
Value Function Update Magnitude: 0.61030

Collected Steps per Second: 22,117.65611
Overall Steps per Second: 10,470.38383

Timestep Collection Time: 2.26109
Timestep Consumption Time: 2.51524
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.77633

Cumulative Model Updates: 102,812
Cumulative Timesteps: 857,512,802

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 857512802...
Checkpoint 857512802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,655.56318
Policy Entropy: 1.90515
Value Function Loss: 0.08089

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.15714
Policy Update Magnitude: 0.56314
Value Function Update Magnitude: 0.66219

Collected Steps per Second: 22,026.96804
Overall Steps per Second: 10,617.01978

Timestep Collection Time: 2.27113
Timestep Consumption Time: 2.44074
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.71187

Cumulative Model Updates: 102,818
Cumulative Timesteps: 857,562,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,201.10892
Policy Entropy: 1.90003
Value Function Loss: 0.08069

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.14727
Policy Update Magnitude: 0.58703
Value Function Update Magnitude: 0.68834

Collected Steps per Second: 22,295.11752
Overall Steps per Second: 10,464.95730

Timestep Collection Time: 2.24291
Timestep Consumption Time: 2.53551
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.77842

Cumulative Model Updates: 102,824
Cumulative Timesteps: 857,612,834

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 857612834...
Checkpoint 857612834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,016.00277
Policy Entropy: 1.88164
Value Function Loss: 0.07681

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.14551
Policy Update Magnitude: 0.59678
Value Function Update Magnitude: 0.62537

Collected Steps per Second: 21,480.66815
Overall Steps per Second: 10,313.68783

Timestep Collection Time: 2.32851
Timestep Consumption Time: 2.52116
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.84967

Cumulative Model Updates: 102,830
Cumulative Timesteps: 857,662,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,603.31334
Policy Entropy: 1.86987
Value Function Loss: 0.07172

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.59326
Value Function Update Magnitude: 0.63186

Collected Steps per Second: 22,086.62788
Overall Steps per Second: 10,475.62061

Timestep Collection Time: 2.26517
Timestep Consumption Time: 2.51068
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.77585

Cumulative Model Updates: 102,836
Cumulative Timesteps: 857,712,882

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 857712882...
Checkpoint 857712882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,880.33962
Policy Entropy: 1.88168
Value Function Loss: 0.07363

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.57920
Value Function Update Magnitude: 0.62000

Collected Steps per Second: 21,862.88686
Overall Steps per Second: 10,577.92640

Timestep Collection Time: 2.28780
Timestep Consumption Time: 2.44072
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.72853

Cumulative Model Updates: 102,842
Cumulative Timesteps: 857,762,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,784.64583
Policy Entropy: 1.87684
Value Function Loss: 0.07745

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.58613
Value Function Update Magnitude: 0.51912

Collected Steps per Second: 22,545.14958
Overall Steps per Second: 10,492.27025

Timestep Collection Time: 2.21830
Timestep Consumption Time: 2.54825
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.76656

Cumulative Model Updates: 102,848
Cumulative Timesteps: 857,812,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 857812912...
Checkpoint 857812912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,186.89960
Policy Entropy: 1.87178
Value Function Loss: 0.07968

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.58245
Value Function Update Magnitude: 0.46393

Collected Steps per Second: 21,901.33589
Overall Steps per Second: 10,524.95164

Timestep Collection Time: 2.28315
Timestep Consumption Time: 2.46785
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.75100

Cumulative Model Updates: 102,854
Cumulative Timesteps: 857,862,916

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,844.41457
Policy Entropy: 1.85470
Value Function Loss: 0.07341

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.58692
Value Function Update Magnitude: 0.44123

Collected Steps per Second: 22,368.29214
Overall Steps per Second: 10,519.13664

Timestep Collection Time: 2.23531
Timestep Consumption Time: 2.51793
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.75324

Cumulative Model Updates: 102,860
Cumulative Timesteps: 857,912,916

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 857912916...
Checkpoint 857912916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,412.34916
Policy Entropy: 1.84729
Value Function Loss: 0.07021

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.12953
Policy Update Magnitude: 0.57814
Value Function Update Magnitude: 0.41146

Collected Steps per Second: 21,823.87538
Overall Steps per Second: 10,503.60385

Timestep Collection Time: 2.29171
Timestep Consumption Time: 2.46989
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.76160

Cumulative Model Updates: 102,866
Cumulative Timesteps: 857,962,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,397.73531
Policy Entropy: 1.83908
Value Function Loss: 0.07137

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.57901
Value Function Update Magnitude: 0.52905

Collected Steps per Second: 22,188.46332
Overall Steps per Second: 10,539.64984

Timestep Collection Time: 2.25369
Timestep Consumption Time: 2.49087
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.74456

Cumulative Model Updates: 102,872
Cumulative Timesteps: 858,012,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 858012936...
Checkpoint 858012936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,088.40075
Policy Entropy: 1.86553
Value Function Loss: 0.06823

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.56724
Value Function Update Magnitude: 0.57966

Collected Steps per Second: 22,194.00147
Overall Steps per Second: 10,664.97469

Timestep Collection Time: 2.25358
Timestep Consumption Time: 2.43616
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.68974

Cumulative Model Updates: 102,878
Cumulative Timesteps: 858,062,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,826.34671
Policy Entropy: 1.87003
Value Function Loss: 0.07280

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.57460
Value Function Update Magnitude: 0.59706

Collected Steps per Second: 22,234.01180
Overall Steps per Second: 10,516.19150

Timestep Collection Time: 2.24926
Timestep Consumption Time: 2.50627
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.75552

Cumulative Model Updates: 102,884
Cumulative Timesteps: 858,112,962

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 858112962...
Checkpoint 858112962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,740.17881
Policy Entropy: 1.85796
Value Function Loss: 0.07162

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.58051
Value Function Update Magnitude: 0.63160

Collected Steps per Second: 21,197.24459
Overall Steps per Second: 10,312.86318

Timestep Collection Time: 2.35908
Timestep Consumption Time: 2.48982
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.84890

Cumulative Model Updates: 102,890
Cumulative Timesteps: 858,162,968

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,092.69148
Policy Entropy: 1.83875
Value Function Loss: 0.07166

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13366
Policy Update Magnitude: 0.58572
Value Function Update Magnitude: 0.57788

Collected Steps per Second: 22,163.54316
Overall Steps per Second: 10,647.34794

Timestep Collection Time: 2.25623
Timestep Consumption Time: 2.44034
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.69657

Cumulative Model Updates: 102,896
Cumulative Timesteps: 858,212,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 858212974...
Checkpoint 858212974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,782.58308
Policy Entropy: 1.83509
Value Function Loss: 0.07157

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.13822
Policy Update Magnitude: 0.58441
Value Function Update Magnitude: 0.53743

Collected Steps per Second: 21,026.96536
Overall Steps per Second: 10,199.17118

Timestep Collection Time: 2.37847
Timestep Consumption Time: 2.52507
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.90354

Cumulative Model Updates: 102,902
Cumulative Timesteps: 858,262,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,979.98605
Policy Entropy: 1.84391
Value Function Loss: 0.06765

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.56639
Value Function Update Magnitude: 0.57517

Collected Steps per Second: 21,483.09860
Overall Steps per Second: 10,450.51130

Timestep Collection Time: 2.32741
Timestep Consumption Time: 2.45704
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.78445

Cumulative Model Updates: 102,908
Cumulative Timesteps: 858,312,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 858312986...
Checkpoint 858312986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,522.76013
Policy Entropy: 1.86064
Value Function Loss: 0.07018

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.55469
Value Function Update Magnitude: 0.57502

Collected Steps per Second: 21,696.85656
Overall Steps per Second: 10,327.82291

Timestep Collection Time: 2.30577
Timestep Consumption Time: 2.53823
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.84400

Cumulative Model Updates: 102,914
Cumulative Timesteps: 858,363,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,207.78302
Policy Entropy: 1.86984
Value Function Loss: 0.07171

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.57325
Value Function Update Magnitude: 0.53777

Collected Steps per Second: 22,498.66672
Overall Steps per Second: 10,511.96357

Timestep Collection Time: 2.22253
Timestep Consumption Time: 2.53433
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.75687

Cumulative Model Updates: 102,920
Cumulative Timesteps: 858,413,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 858413018...
Checkpoint 858413018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,486.68272
Policy Entropy: 1.86619
Value Function Loss: 0.07435

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.14484
Policy Update Magnitude: 0.56864
Value Function Update Magnitude: 0.50574

Collected Steps per Second: 22,121.55939
Overall Steps per Second: 10,457.56041

Timestep Collection Time: 2.26033
Timestep Consumption Time: 2.52109
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.78142

Cumulative Model Updates: 102,926
Cumulative Timesteps: 858,463,020

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,795.36375
Policy Entropy: 1.85002
Value Function Loss: 0.07299

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.16378
Policy Update Magnitude: 0.51471
Value Function Update Magnitude: 0.55858

Collected Steps per Second: 22,534.44578
Overall Steps per Second: 10,579.50944

Timestep Collection Time: 2.21971
Timestep Consumption Time: 2.50829
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.72801

Cumulative Model Updates: 102,932
Cumulative Timesteps: 858,513,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 858513040...
Checkpoint 858513040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,512.49060
Policy Entropy: 1.84789
Value Function Loss: 0.06815

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.54636
Value Function Update Magnitude: 0.61061

Collected Steps per Second: 21,885.86659
Overall Steps per Second: 10,567.52872

Timestep Collection Time: 2.28568
Timestep Consumption Time: 2.44807
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.73375

Cumulative Model Updates: 102,938
Cumulative Timesteps: 858,563,064

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,755.09506
Policy Entropy: 1.84849
Value Function Loss: 0.06946

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.57664
Value Function Update Magnitude: 0.67808

Collected Steps per Second: 21,912.75881
Overall Steps per Second: 10,602.73536

Timestep Collection Time: 2.28232
Timestep Consumption Time: 2.43457
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.71690

Cumulative Model Updates: 102,944
Cumulative Timesteps: 858,613,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 858613076...
Checkpoint 858613076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,065.84071
Policy Entropy: 1.84120
Value Function Loss: 0.07084

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.58792
Value Function Update Magnitude: 0.72826

Collected Steps per Second: 21,684.65398
Overall Steps per Second: 10,565.33297

Timestep Collection Time: 2.30670
Timestep Consumption Time: 2.42765
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.73435

Cumulative Model Updates: 102,950
Cumulative Timesteps: 858,663,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,538.86921
Policy Entropy: 1.83372
Value Function Loss: 0.07541

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.59081
Value Function Update Magnitude: 0.71256

Collected Steps per Second: 21,248.56991
Overall Steps per Second: 10,458.78156

Timestep Collection Time: 2.35413
Timestep Consumption Time: 2.42864
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.78278

Cumulative Model Updates: 102,956
Cumulative Timesteps: 858,713,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 858713118...
Checkpoint 858713118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,692.78578
Policy Entropy: 1.85152
Value Function Loss: 0.07629

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.59055
Value Function Update Magnitude: 0.66489

Collected Steps per Second: 21,244.15100
Overall Steps per Second: 10,569.54112

Timestep Collection Time: 2.35425
Timestep Consumption Time: 2.37765
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.73190

Cumulative Model Updates: 102,962
Cumulative Timesteps: 858,763,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,339.92380
Policy Entropy: 1.85159
Value Function Loss: 0.07969

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.58951
Value Function Update Magnitude: 0.54977

Collected Steps per Second: 21,652.64866
Overall Steps per Second: 10,548.33044

Timestep Collection Time: 2.31122
Timestep Consumption Time: 2.43304
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.74426

Cumulative Model Updates: 102,968
Cumulative Timesteps: 858,813,176

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 858813176...
Checkpoint 858813176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,389.81180
Policy Entropy: 1.84873
Value Function Loss: 0.08255

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.14885
Policy Update Magnitude: 0.59642
Value Function Update Magnitude: 0.48043

Collected Steps per Second: 20,971.58472
Overall Steps per Second: 10,249.05289

Timestep Collection Time: 2.38427
Timestep Consumption Time: 2.49442
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.87869

Cumulative Model Updates: 102,974
Cumulative Timesteps: 858,863,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,983.81355
Policy Entropy: 1.84371
Value Function Loss: 0.08591

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.15356
Policy Update Magnitude: 0.58708
Value Function Update Magnitude: 0.44293

Collected Steps per Second: 22,052.44875
Overall Steps per Second: 10,677.31232

Timestep Collection Time: 2.26732
Timestep Consumption Time: 2.41550
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.68283

Cumulative Model Updates: 102,980
Cumulative Timesteps: 858,913,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 858913178...
Checkpoint 858913178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,875.26030
Policy Entropy: 1.84585
Value Function Loss: 0.09048

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.15427
Policy Update Magnitude: 0.59262
Value Function Update Magnitude: 0.44102

Collected Steps per Second: 21,643.32679
Overall Steps per Second: 10,424.13157

Timestep Collection Time: 2.31027
Timestep Consumption Time: 2.48648
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.79675

Cumulative Model Updates: 102,986
Cumulative Timesteps: 858,963,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,877.52405
Policy Entropy: 1.85133
Value Function Loss: 0.09014

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.15660
Policy Update Magnitude: 0.59608
Value Function Update Magnitude: 0.44332

Collected Steps per Second: 22,642.05600
Overall Steps per Second: 10,773.63388

Timestep Collection Time: 2.20934
Timestep Consumption Time: 2.43385
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.64319

Cumulative Model Updates: 102,992
Cumulative Timesteps: 859,013,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 859013204...
Checkpoint 859013204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,247.00167
Policy Entropy: 1.83680
Value Function Loss: 0.08545

Mean KL Divergence: 0.02169
SB3 Clip Fraction: 0.17774
Policy Update Magnitude: 0.56981
Value Function Update Magnitude: 0.50502

Collected Steps per Second: 21,930.01975
Overall Steps per Second: 10,591.16627

Timestep Collection Time: 2.28071
Timestep Consumption Time: 2.44172
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.72243

Cumulative Model Updates: 102,998
Cumulative Timesteps: 859,063,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,934.66168
Policy Entropy: 1.82568
Value Function Loss: 0.08113

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.17440
Policy Update Magnitude: 0.55649
Value Function Update Magnitude: 0.61942

Collected Steps per Second: 22,219.37841
Overall Steps per Second: 10,480.83354

Timestep Collection Time: 2.25128
Timestep Consumption Time: 2.52143
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.77271

Cumulative Model Updates: 103,004
Cumulative Timesteps: 859,113,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 859113242...
Checkpoint 859113242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,286.07164
Policy Entropy: 1.80502
Value Function Loss: 0.07516

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.17505
Policy Update Magnitude: 0.56060
Value Function Update Magnitude: 0.64017

Collected Steps per Second: 22,188.67590
Overall Steps per Second: 10,667.49640

Timestep Collection Time: 2.25340
Timestep Consumption Time: 2.43373
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.68714

Cumulative Model Updates: 103,010
Cumulative Timesteps: 859,163,242

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,382.93635
Policy Entropy: 1.82195
Value Function Loss: 0.07538

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.15791
Policy Update Magnitude: 0.57128
Value Function Update Magnitude: 0.61675

Collected Steps per Second: 21,988.94311
Overall Steps per Second: 10,418.21015

Timestep Collection Time: 2.27505
Timestep Consumption Time: 2.52673
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.80178

Cumulative Model Updates: 103,016
Cumulative Timesteps: 859,213,268

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 859213268...
Checkpoint 859213268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,871.10846
Policy Entropy: 1.82516
Value Function Loss: 0.07432

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14377
Policy Update Magnitude: 0.57326
Value Function Update Magnitude: 0.48371

Collected Steps per Second: 21,892.78704
Overall Steps per Second: 10,575.85881

Timestep Collection Time: 2.28532
Timestep Consumption Time: 2.44546
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.73077

Cumulative Model Updates: 103,022
Cumulative Timesteps: 859,263,300

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,628.21988
Policy Entropy: 1.84293
Value Function Loss: 0.07616

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.13838
Policy Update Magnitude: 0.58189
Value Function Update Magnitude: 0.50888

Collected Steps per Second: 22,229.76297
Overall Steps per Second: 10,545.72671

Timestep Collection Time: 2.25059
Timestep Consumption Time: 2.49352
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.74410

Cumulative Model Updates: 103,028
Cumulative Timesteps: 859,313,330

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 859313330...
Checkpoint 859313330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,592.39052
Policy Entropy: 1.83416
Value Function Loss: 0.07073

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.56830
Value Function Update Magnitude: 0.66372

Collected Steps per Second: 21,390.85934
Overall Steps per Second: 10,355.34469

Timestep Collection Time: 2.33745
Timestep Consumption Time: 2.49098
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.82842

Cumulative Model Updates: 103,034
Cumulative Timesteps: 859,363,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,908.80196
Policy Entropy: 1.82474
Value Function Loss: 0.06899

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.56816
Value Function Update Magnitude: 0.72985

Collected Steps per Second: 22,120.73319
Overall Steps per Second: 10,619.35373

Timestep Collection Time: 2.26096
Timestep Consumption Time: 2.44875
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.70970

Cumulative Model Updates: 103,040
Cumulative Timesteps: 859,413,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 859413344...
Checkpoint 859413344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,325.69002
Policy Entropy: 1.81193
Value Function Loss: 0.06907

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.58219
Value Function Update Magnitude: 0.73628

Collected Steps per Second: 21,727.52360
Overall Steps per Second: 10,373.83853

Timestep Collection Time: 2.30224
Timestep Consumption Time: 2.51970
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.82194

Cumulative Model Updates: 103,046
Cumulative Timesteps: 859,463,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,218.70904
Policy Entropy: 1.81836
Value Function Loss: 0.07175

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.16482
Policy Update Magnitude: 0.56543
Value Function Update Magnitude: 0.73376

Collected Steps per Second: 22,101.02369
Overall Steps per Second: 10,487.02891

Timestep Collection Time: 2.26297
Timestep Consumption Time: 2.50616
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.76913

Cumulative Model Updates: 103,052
Cumulative Timesteps: 859,513,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 859513380...
Checkpoint 859513380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,871.20991
Policy Entropy: 1.83070
Value Function Loss: 0.07199

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.53480
Value Function Update Magnitude: 0.73358

Collected Steps per Second: 22,049.88642
Overall Steps per Second: 10,553.38843

Timestep Collection Time: 2.26822
Timestep Consumption Time: 2.47092
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.73914

Cumulative Model Updates: 103,058
Cumulative Timesteps: 859,563,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,554.89976
Policy Entropy: 1.84382
Value Function Loss: 0.07069

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.56822
Value Function Update Magnitude: 0.65476

Collected Steps per Second: 22,393.19667
Overall Steps per Second: 10,492.36603

Timestep Collection Time: 2.23345
Timestep Consumption Time: 2.53326
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.76670

Cumulative Model Updates: 103,064
Cumulative Timesteps: 859,613,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 859613408...
Checkpoint 859613408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,091.76452
Policy Entropy: 1.85263
Value Function Loss: 0.07109

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.56377
Value Function Update Magnitude: 0.62782

Collected Steps per Second: 22,384.31150
Overall Steps per Second: 10,432.84148

Timestep Collection Time: 2.23371
Timestep Consumption Time: 2.55885
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.79256

Cumulative Model Updates: 103,070
Cumulative Timesteps: 859,663,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,283.94076
Policy Entropy: 1.84025
Value Function Loss: 0.07303

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.16012
Policy Update Magnitude: 0.50763
Value Function Update Magnitude: 0.65057

Collected Steps per Second: 22,442.09757
Overall Steps per Second: 10,570.40677

Timestep Collection Time: 2.22876
Timestep Consumption Time: 2.50313
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.73189

Cumulative Model Updates: 103,076
Cumulative Timesteps: 859,713,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 859713426...
Checkpoint 859713426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,602.79503
Policy Entropy: 1.82746
Value Function Loss: 0.07387

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.14870
Policy Update Magnitude: 0.47516
Value Function Update Magnitude: 0.74897

Collected Steps per Second: 22,085.10363
Overall Steps per Second: 10,636.53344

Timestep Collection Time: 2.26497
Timestep Consumption Time: 2.43788
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.70285

Cumulative Model Updates: 103,082
Cumulative Timesteps: 859,763,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,931.97791
Policy Entropy: 1.81016
Value Function Loss: 0.07257

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.14773
Policy Update Magnitude: 0.49240
Value Function Update Magnitude: 0.72569

Collected Steps per Second: 21,919.94814
Overall Steps per Second: 10,604.39900

Timestep Collection Time: 2.28148
Timestep Consumption Time: 2.43448
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.71597

Cumulative Model Updates: 103,088
Cumulative Timesteps: 859,813,458

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 859813458...
Checkpoint 859813458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,575.61027
Policy Entropy: 1.81690
Value Function Loss: 0.07503

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.14632
Policy Update Magnitude: 0.52587
Value Function Update Magnitude: 0.54885

Collected Steps per Second: 20,295.76343
Overall Steps per Second: 10,226.37260

Timestep Collection Time: 2.46396
Timestep Consumption Time: 2.42614
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.89010

Cumulative Model Updates: 103,094
Cumulative Timesteps: 859,863,466

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,708.69952
Policy Entropy: 1.81717
Value Function Loss: 0.07486

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.57123
Value Function Update Magnitude: 0.56552

Collected Steps per Second: 21,383.96644
Overall Steps per Second: 10,513.19465

Timestep Collection Time: 2.33970
Timestep Consumption Time: 2.41928
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.75897

Cumulative Model Updates: 103,100
Cumulative Timesteps: 859,913,498

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 859913498...
Checkpoint 859913498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,077.96755
Policy Entropy: 1.82754
Value Function Loss: 0.07464

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.56776
Value Function Update Magnitude: 0.70463

Collected Steps per Second: 21,341.73994
Overall Steps per Second: 10,454.69723

Timestep Collection Time: 2.34508
Timestep Consumption Time: 2.44205
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.78713

Cumulative Model Updates: 103,106
Cumulative Timesteps: 859,963,546

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,754.23376
Policy Entropy: 1.82860
Value Function Loss: 0.07557

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.57645
Value Function Update Magnitude: 0.75986

Collected Steps per Second: 21,467.18043
Overall Steps per Second: 10,436.22463

Timestep Collection Time: 2.32942
Timestep Consumption Time: 2.46216
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.79158

Cumulative Model Updates: 103,112
Cumulative Timesteps: 860,013,552

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 860013552...
Checkpoint 860013552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,330.63612
Policy Entropy: 1.82650
Value Function Loss: 0.07909

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14449
Policy Update Magnitude: 0.57717
Value Function Update Magnitude: 0.72661

Collected Steps per Second: 20,828.65905
Overall Steps per Second: 10,295.36003

Timestep Collection Time: 2.40188
Timestep Consumption Time: 2.45739
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.85928

Cumulative Model Updates: 103,118
Cumulative Timesteps: 860,063,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,901.85332
Policy Entropy: 1.82287
Value Function Loss: 0.08026

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.15232
Policy Update Magnitude: 0.56141
Value Function Update Magnitude: 0.73306

Collected Steps per Second: 21,885.06256
Overall Steps per Second: 10,458.98706

Timestep Collection Time: 2.28558
Timestep Consumption Time: 2.49691
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.78249

Cumulative Model Updates: 103,124
Cumulative Timesteps: 860,113,600

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 860113600...
Checkpoint 860113600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,397.28308
Policy Entropy: 1.81248
Value Function Loss: 0.07539

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.16422
Policy Update Magnitude: 0.55698
Value Function Update Magnitude: 0.79671

Collected Steps per Second: 21,695.51725
Overall Steps per Second: 10,493.98471

Timestep Collection Time: 2.30555
Timestep Consumption Time: 2.46099
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.76654

Cumulative Model Updates: 103,130
Cumulative Timesteps: 860,163,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,626.29822
Policy Entropy: 1.81749
Value Function Loss: 0.07701

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.15830
Policy Update Magnitude: 0.52576
Value Function Update Magnitude: 0.79654

Collected Steps per Second: 22,303.11203
Overall Steps per Second: 10,558.90437

Timestep Collection Time: 2.24256
Timestep Consumption Time: 2.49430
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.73686

Cumulative Model Updates: 103,136
Cumulative Timesteps: 860,213,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 860213636...
Checkpoint 860213636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,263.60865
Policy Entropy: 1.80590
Value Function Loss: 0.07123

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.14986
Policy Update Magnitude: 0.53869
Value Function Update Magnitude: 0.77691

Collected Steps per Second: 22,217.70813
Overall Steps per Second: 10,543.32490

Timestep Collection Time: 2.25073
Timestep Consumption Time: 2.49218
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.74291

Cumulative Model Updates: 103,142
Cumulative Timesteps: 860,263,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,584.85684
Policy Entropy: 1.81126
Value Function Loss: 0.07106

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.17380
Policy Update Magnitude: 0.49910
Value Function Update Magnitude: 0.77644

Collected Steps per Second: 22,277.59641
Overall Steps per Second: 10,568.94222

Timestep Collection Time: 2.24441
Timestep Consumption Time: 2.48644
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.73084

Cumulative Model Updates: 103,148
Cumulative Timesteps: 860,313,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 860313642...
Checkpoint 860313642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,539.32980
Policy Entropy: 1.81645
Value Function Loss: 0.07146

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.15695
Policy Update Magnitude: 0.48243
Value Function Update Magnitude: 0.76087

Collected Steps per Second: 22,014.48182
Overall Steps per Second: 10,554.11243

Timestep Collection Time: 2.27141
Timestep Consumption Time: 2.46645
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.73787

Cumulative Model Updates: 103,154
Cumulative Timesteps: 860,363,646

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,952.50650
Policy Entropy: 1.82833
Value Function Loss: 0.07669

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.15729
Policy Update Magnitude: 0.50559
Value Function Update Magnitude: 0.72196

Collected Steps per Second: 21,579.37251
Overall Steps per Second: 10,410.03370

Timestep Collection Time: 2.31860
Timestep Consumption Time: 2.48772
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.80632

Cumulative Model Updates: 103,160
Cumulative Timesteps: 860,413,680

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 860413680...
Checkpoint 860413680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,686.84790
Policy Entropy: 1.84737
Value Function Loss: 0.07922

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.16662
Policy Update Magnitude: 0.51502
Value Function Update Magnitude: 0.78337

Collected Steps per Second: 21,457.53679
Overall Steps per Second: 10,418.93977

Timestep Collection Time: 2.33037
Timestep Consumption Time: 2.46897
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.79934

Cumulative Model Updates: 103,166
Cumulative Timesteps: 860,463,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,947.72276
Policy Entropy: 1.84250
Value Function Loss: 0.07767

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.15426
Policy Update Magnitude: 0.55539
Value Function Update Magnitude: 0.70703

Collected Steps per Second: 22,142.65886
Overall Steps per Second: 10,625.97497

Timestep Collection Time: 2.25872
Timestep Consumption Time: 2.44805
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.70677

Cumulative Model Updates: 103,172
Cumulative Timesteps: 860,513,698

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 860513698...
Checkpoint 860513698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,878.43115
Policy Entropy: 1.85123
Value Function Loss: 0.07594

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.15232
Policy Update Magnitude: 0.59032
Value Function Update Magnitude: 0.65513

Collected Steps per Second: 21,558.03519
Overall Steps per Second: 10,268.17005

Timestep Collection Time: 2.31941
Timestep Consumption Time: 2.55020
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.86961

Cumulative Model Updates: 103,178
Cumulative Timesteps: 860,563,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,494.89424
Policy Entropy: 1.83465
Value Function Loss: 0.07143

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.16512
Policy Update Magnitude: 0.53981
Value Function Update Magnitude: 0.64194

Collected Steps per Second: 22,330.08074
Overall Steps per Second: 10,446.88651

Timestep Collection Time: 2.23958
Timestep Consumption Time: 2.54749
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.78707

Cumulative Model Updates: 103,184
Cumulative Timesteps: 860,613,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 860613710...
Checkpoint 860613710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,480.59785
Policy Entropy: 1.82208
Value Function Loss: 0.07283

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.15431
Policy Update Magnitude: 0.51255
Value Function Update Magnitude: 0.61535

Collected Steps per Second: 22,123.81159
Overall Steps per Second: 10,508.01795

Timestep Collection Time: 2.26037
Timestep Consumption Time: 2.49866
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.75903

Cumulative Model Updates: 103,190
Cumulative Timesteps: 860,663,718

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,218.05532
Policy Entropy: 1.81276
Value Function Loss: 0.07464

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.17547
Policy Update Magnitude: 0.48131
Value Function Update Magnitude: 0.71852

Collected Steps per Second: 22,373.72287
Overall Steps per Second: 10,606.37066

Timestep Collection Time: 2.23503
Timestep Consumption Time: 2.47968
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.71471

Cumulative Model Updates: 103,196
Cumulative Timesteps: 860,713,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 860713724...
Checkpoint 860713724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,829.50354
Policy Entropy: 1.82589
Value Function Loss: 0.07360

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.15361
Policy Update Magnitude: 0.54075
Value Function Update Magnitude: 0.77690

Collected Steps per Second: 22,023.93826
Overall Steps per Second: 10,597.56534

Timestep Collection Time: 2.27026
Timestep Consumption Time: 2.44781
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.71806

Cumulative Model Updates: 103,202
Cumulative Timesteps: 860,763,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,016.60951
Policy Entropy: 1.83499
Value Function Loss: 0.07069

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.15669
Policy Update Magnitude: 0.57822
Value Function Update Magnitude: 0.74906

Collected Steps per Second: 22,166.16442
Overall Steps per Second: 10,479.89337

Timestep Collection Time: 2.25632
Timestep Consumption Time: 2.51605
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.77238

Cumulative Model Updates: 103,208
Cumulative Timesteps: 860,813,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 860813738...
Checkpoint 860813738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,653.60037
Policy Entropy: 1.83963
Value Function Loss: 0.07333

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.16533
Policy Update Magnitude: 0.54943
Value Function Update Magnitude: 0.70053

Collected Steps per Second: 21,875.87031
Overall Steps per Second: 10,577.33231

Timestep Collection Time: 2.28690
Timestep Consumption Time: 2.44283
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.72974

Cumulative Model Updates: 103,214
Cumulative Timesteps: 860,863,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,237.42304
Policy Entropy: 1.84435
Value Function Loss: 0.07538

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.16578
Policy Update Magnitude: 0.55845
Value Function Update Magnitude: 0.65896

Collected Steps per Second: 22,264.57696
Overall Steps per Second: 10,541.75468

Timestep Collection Time: 2.24653
Timestep Consumption Time: 2.49822
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.74475

Cumulative Model Updates: 103,220
Cumulative Timesteps: 860,913,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 860913784...
Checkpoint 860913784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,468.83093
Policy Entropy: 1.84138
Value Function Loss: 0.07976

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.16349
Policy Update Magnitude: 0.55076
Value Function Update Magnitude: 0.56776

Collected Steps per Second: 22,045.01590
Overall Steps per Second: 10,601.69494

Timestep Collection Time: 2.26899
Timestep Consumption Time: 2.44912
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.71811

Cumulative Model Updates: 103,226
Cumulative Timesteps: 860,963,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,103.27224
Policy Entropy: 1.83807
Value Function Loss: 0.08293

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.16559
Policy Update Magnitude: 0.54332
Value Function Update Magnitude: 0.53044

Collected Steps per Second: 22,161.13377
Overall Steps per Second: 10,466.43470

Timestep Collection Time: 2.25647
Timestep Consumption Time: 2.52128
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.77775

Cumulative Model Updates: 103,232
Cumulative Timesteps: 861,013,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 861013810...
Checkpoint 861013810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,138.00426
Policy Entropy: 1.82980
Value Function Loss: 0.08342

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.15566
Policy Update Magnitude: 0.55990
Value Function Update Magnitude: 0.54757

Collected Steps per Second: 21,346.58965
Overall Steps per Second: 10,279.20336

Timestep Collection Time: 2.34482
Timestep Consumption Time: 2.52462
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.86944

Cumulative Model Updates: 103,238
Cumulative Timesteps: 861,063,864

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,584.26578
Policy Entropy: 1.81757
Value Function Loss: 0.08078

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.16505
Policy Update Magnitude: 0.54847
Value Function Update Magnitude: 0.53752

Collected Steps per Second: 22,087.48644
Overall Steps per Second: 10,423.18307

Timestep Collection Time: 2.26517
Timestep Consumption Time: 2.53490
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.80007

Cumulative Model Updates: 103,244
Cumulative Timesteps: 861,113,896

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 861113896...
Checkpoint 861113896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,841.59229
Policy Entropy: 1.82346
Value Function Loss: 0.08318

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.17282
Policy Update Magnitude: 0.50745
Value Function Update Magnitude: 0.58085

Collected Steps per Second: 21,933.01832
Overall Steps per Second: 10,615.82507

Timestep Collection Time: 2.27967
Timestep Consumption Time: 2.43028
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.70995

Cumulative Model Updates: 103,250
Cumulative Timesteps: 861,163,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,772.21760
Policy Entropy: 1.83627
Value Function Loss: 0.08240

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.16816
Policy Update Magnitude: 0.51934
Value Function Update Magnitude: 0.58851

Collected Steps per Second: 22,410.45383
Overall Steps per Second: 10,450.63883

Timestep Collection Time: 2.23226
Timestep Consumption Time: 2.55462
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.78688

Cumulative Model Updates: 103,256
Cumulative Timesteps: 861,213,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 861213922...
Checkpoint 861213922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,858.16277
Policy Entropy: 1.83980
Value Function Loss: 0.07863

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.16201
Policy Update Magnitude: 0.52920
Value Function Update Magnitude: 0.53229

Collected Steps per Second: 22,032.56880
Overall Steps per Second: 10,508.38450

Timestep Collection Time: 2.26973
Timestep Consumption Time: 2.48914
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.75887

Cumulative Model Updates: 103,262
Cumulative Timesteps: 861,263,930

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,164.12799
Policy Entropy: 1.81965
Value Function Loss: 0.07430

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.15681
Policy Update Magnitude: 0.54829
Value Function Update Magnitude: 0.65754

Collected Steps per Second: 22,371.01956
Overall Steps per Second: 10,595.56638

Timestep Collection Time: 2.23655
Timestep Consumption Time: 2.48561
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.72216

Cumulative Model Updates: 103,268
Cumulative Timesteps: 861,313,964

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 861313964...
Checkpoint 861313964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,968.32953
Policy Entropy: 1.80864
Value Function Loss: 0.07313

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.15045
Policy Update Magnitude: 0.59004
Value Function Update Magnitude: 0.73925

Collected Steps per Second: 21,992.48484
Overall Steps per Second: 10,614.05771

Timestep Collection Time: 2.27487
Timestep Consumption Time: 2.43869
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.71356

Cumulative Model Updates: 103,274
Cumulative Timesteps: 861,363,994

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,018.08874
Policy Entropy: 1.81351
Value Function Loss: 0.07046

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.15676
Policy Update Magnitude: 0.58076
Value Function Update Magnitude: 0.76311

Collected Steps per Second: 22,589.43949
Overall Steps per Second: 10,571.91396

Timestep Collection Time: 2.21422
Timestep Consumption Time: 2.51699
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.73122

Cumulative Model Updates: 103,280
Cumulative Timesteps: 861,414,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 861414012...
Checkpoint 861414012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,728.92154
Policy Entropy: 1.81812
Value Function Loss: 0.07430

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.16757
Policy Update Magnitude: 0.53329
Value Function Update Magnitude: 0.73665

Collected Steps per Second: 21,266.72972
Overall Steps per Second: 10,448.86632

Timestep Collection Time: 2.35194
Timestep Consumption Time: 2.43499
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.78693

Cumulative Model Updates: 103,286
Cumulative Timesteps: 861,464,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,554.56712
Policy Entropy: 1.81478
Value Function Loss: 0.07863

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.16780
Policy Update Magnitude: 0.49749
Value Function Update Magnitude: 0.72352

Collected Steps per Second: 22,544.72578
Overall Steps per Second: 10,540.32951

Timestep Collection Time: 2.21835
Timestep Consumption Time: 2.52648
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.74482

Cumulative Model Updates: 103,292
Cumulative Timesteps: 861,514,042

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 861514042...
Checkpoint 861514042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,547.60149
Policy Entropy: 1.80836
Value Function Loss: 0.07611

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.15205
Policy Update Magnitude: 0.55769
Value Function Update Magnitude: 0.73420

Collected Steps per Second: 21,727.62654
Overall Steps per Second: 10,613.36709

Timestep Collection Time: 2.30168
Timestep Consumption Time: 2.41030
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.71198

Cumulative Model Updates: 103,298
Cumulative Timesteps: 861,564,052

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,100.84909
Policy Entropy: 1.81239
Value Function Loss: 0.07365

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.15113
Policy Update Magnitude: 0.58006
Value Function Update Magnitude: 0.72247

Collected Steps per Second: 22,457.63983
Overall Steps per Second: 10,517.55297

Timestep Collection Time: 2.22730
Timestep Consumption Time: 2.52855
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.75586

Cumulative Model Updates: 103,304
Cumulative Timesteps: 861,614,072

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 861614072...
Checkpoint 861614072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,733.71547
Policy Entropy: 1.81120
Value Function Loss: 0.07248

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.14720
Policy Update Magnitude: 0.59693
Value Function Update Magnitude: 0.71762

Collected Steps per Second: 21,626.76231
Overall Steps per Second: 10,521.38379

Timestep Collection Time: 2.31371
Timestep Consumption Time: 2.44213
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.75584

Cumulative Model Updates: 103,310
Cumulative Timesteps: 861,664,110

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,507.22909
Policy Entropy: 1.81235
Value Function Loss: 0.07999

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.60336
Value Function Update Magnitude: 0.64198

Collected Steps per Second: 22,441.34261
Overall Steps per Second: 10,522.64740

Timestep Collection Time: 2.22892
Timestep Consumption Time: 2.52463
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.75356

Cumulative Model Updates: 103,316
Cumulative Timesteps: 861,714,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 861714130...
Checkpoint 861714130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,267.17876
Policy Entropy: 1.82383
Value Function Loss: 0.08187

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.60365
Value Function Update Magnitude: 0.50038

Collected Steps per Second: 21,447.77451
Overall Steps per Second: 10,326.42467

Timestep Collection Time: 2.33255
Timestep Consumption Time: 2.51211
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.84466

Cumulative Model Updates: 103,322
Cumulative Timesteps: 861,764,158

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,406.55781
Policy Entropy: 1.82604
Value Function Loss: 0.08149

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14546
Policy Update Magnitude: 0.59985
Value Function Update Magnitude: 0.47259

Collected Steps per Second: 22,280.61409
Overall Steps per Second: 10,703.16225

Timestep Collection Time: 2.24590
Timestep Consumption Time: 2.42936
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.67525

Cumulative Model Updates: 103,328
Cumulative Timesteps: 861,814,198

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 861814198...
Checkpoint 861814198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,348.47344
Policy Entropy: 1.83293
Value Function Loss: 0.07685

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.14723
Policy Update Magnitude: 0.58794
Value Function Update Magnitude: 0.60120

Collected Steps per Second: 21,803.72178
Overall Steps per Second: 10,395.18971

Timestep Collection Time: 2.29392
Timestep Consumption Time: 2.51754
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.81146

Cumulative Model Updates: 103,334
Cumulative Timesteps: 861,864,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,859.60281
Policy Entropy: 1.80976
Value Function Loss: 0.07460

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.59024
Value Function Update Magnitude: 0.74796

Collected Steps per Second: 22,200.51899
Overall Steps per Second: 10,548.80340

Timestep Collection Time: 2.25220
Timestep Consumption Time: 2.48767
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.73987

Cumulative Model Updates: 103,340
Cumulative Timesteps: 861,914,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 861914214...
Checkpoint 861914214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,421.51740
Policy Entropy: 1.82173
Value Function Loss: 0.06922

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.58363
Value Function Update Magnitude: 0.78742

Collected Steps per Second: 21,834.46250
Overall Steps per Second: 10,431.89236

Timestep Collection Time: 2.29023
Timestep Consumption Time: 2.50334
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.79357

Cumulative Model Updates: 103,346
Cumulative Timesteps: 861,964,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,845.32825
Policy Entropy: 1.81737
Value Function Loss: 0.07027

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.56321
Value Function Update Magnitude: 0.80775

Collected Steps per Second: 22,359.70272
Overall Steps per Second: 10,524.78516

Timestep Collection Time: 2.23715
Timestep Consumption Time: 2.51563
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.75278

Cumulative Model Updates: 103,352
Cumulative Timesteps: 862,014,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 862014242...
Checkpoint 862014242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,655.06243
Policy Entropy: 1.83433
Value Function Loss: 0.07368

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.57517
Value Function Update Magnitude: 0.75197

Collected Steps per Second: 21,478.54428
Overall Steps per Second: 10,470.79827

Timestep Collection Time: 2.32902
Timestep Consumption Time: 2.44846
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.77748

Cumulative Model Updates: 103,358
Cumulative Timesteps: 862,064,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,068.07728
Policy Entropy: 1.81886
Value Function Loss: 0.07806

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.17241
Policy Update Magnitude: 0.54318
Value Function Update Magnitude: 0.66599

Collected Steps per Second: 22,252.70903
Overall Steps per Second: 10,532.16428

Timestep Collection Time: 2.24746
Timestep Consumption Time: 2.50105
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.74850

Cumulative Model Updates: 103,364
Cumulative Timesteps: 862,114,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 862114278...
Checkpoint 862114278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,421.66055
Policy Entropy: 1.83651
Value Function Loss: 0.08467

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.16755
Policy Update Magnitude: 0.51028
Value Function Update Magnitude: 0.63207

Collected Steps per Second: 21,438.84379
Overall Steps per Second: 10,334.24709

Timestep Collection Time: 2.33240
Timestep Consumption Time: 2.50627
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.83867

Cumulative Model Updates: 103,370
Cumulative Timesteps: 862,164,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,191.75530
Policy Entropy: 1.83245
Value Function Loss: 0.08331

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.15227
Policy Update Magnitude: 0.54068
Value Function Update Magnitude: 0.69173

Collected Steps per Second: 22,420.93378
Overall Steps per Second: 10,676.36818

Timestep Collection Time: 2.23122
Timestep Consumption Time: 2.45446
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.68568

Cumulative Model Updates: 103,376
Cumulative Timesteps: 862,214,308

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 862214308...
Checkpoint 862214308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,819.87793
Policy Entropy: 1.82952
Value Function Loss: 0.08399

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.15070
Policy Update Magnitude: 0.58445
Value Function Update Magnitude: 0.69799

Collected Steps per Second: 21,451.96336
Overall Steps per Second: 10,397.39602

Timestep Collection Time: 2.33200
Timestep Consumption Time: 2.47940
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.81140

Cumulative Model Updates: 103,382
Cumulative Timesteps: 862,264,334

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,517.17308
Policy Entropy: 1.81745
Value Function Loss: 0.08029

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.15492
Policy Update Magnitude: 0.57790
Value Function Update Magnitude: 0.66856

Collected Steps per Second: 22,561.38903
Overall Steps per Second: 10,727.99430

Timestep Collection Time: 2.21635
Timestep Consumption Time: 2.44472
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.66108

Cumulative Model Updates: 103,388
Cumulative Timesteps: 862,314,338

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 862314338...
Checkpoint 862314338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,549.71667
Policy Entropy: 1.82614
Value Function Loss: 0.07905

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.16369
Policy Update Magnitude: 0.52749
Value Function Update Magnitude: 0.74964

Collected Steps per Second: 21,644.22030
Overall Steps per Second: 10,594.31315

Timestep Collection Time: 2.31212
Timestep Consumption Time: 2.41155
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.72367

Cumulative Model Updates: 103,394
Cumulative Timesteps: 862,364,382

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,913.30897
Policy Entropy: 1.82839
Value Function Loss: 0.07526

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.14109
Policy Update Magnitude: 0.55343
Value Function Update Magnitude: 0.78686

Collected Steps per Second: 22,385.21834
Overall Steps per Second: 10,532.58450

Timestep Collection Time: 2.23380
Timestep Consumption Time: 2.51376
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.74755

Cumulative Model Updates: 103,400
Cumulative Timesteps: 862,414,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 862414386...
Checkpoint 862414386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,429.01180
Policy Entropy: 1.81716
Value Function Loss: 0.07864

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.14283
Policy Update Magnitude: 0.59391
Value Function Update Magnitude: 0.81723

Collected Steps per Second: 21,159.67401
Overall Steps per Second: 10,262.03375

Timestep Collection Time: 2.36365
Timestep Consumption Time: 2.51005
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.87369

Cumulative Model Updates: 103,406
Cumulative Timesteps: 862,464,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,961.25848
Policy Entropy: 1.79836
Value Function Loss: 0.07863

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.15165
Policy Update Magnitude: 0.60049
Value Function Update Magnitude: 0.82050

Collected Steps per Second: 22,263.06569
Overall Steps per Second: 10,514.01285

Timestep Collection Time: 2.24668
Timestep Consumption Time: 2.51059
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.75727

Cumulative Model Updates: 103,412
Cumulative Timesteps: 862,514,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 862514418...
Checkpoint 862514418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,383.49305
Policy Entropy: 1.77435
Value Function Loss: 0.08013

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.15452
Policy Update Magnitude: 0.59786
Value Function Update Magnitude: 0.73771

Collected Steps per Second: 21,433.56501
Overall Steps per Second: 10,454.39290

Timestep Collection Time: 2.33428
Timestep Consumption Time: 2.45146
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.78574

Cumulative Model Updates: 103,418
Cumulative Timesteps: 862,564,450

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,506.70191
Policy Entropy: 1.80421
Value Function Loss: 0.08103

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.17497
Policy Update Magnitude: 0.53769
Value Function Update Magnitude: 0.66901

Collected Steps per Second: 22,409.50017
Overall Steps per Second: 10,581.37016

Timestep Collection Time: 2.23218
Timestep Consumption Time: 2.49519
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.72737

Cumulative Model Updates: 103,424
Cumulative Timesteps: 862,614,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 862614472...
Checkpoint 862614472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,745.27379
Policy Entropy: 1.82265
Value Function Loss: 0.07817

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.16252
Policy Update Magnitude: 0.48598
Value Function Update Magnitude: 0.62868

Collected Steps per Second: 21,338.06527
Overall Steps per Second: 10,293.59144

Timestep Collection Time: 2.34436
Timestep Consumption Time: 2.51537
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.85972

Cumulative Model Updates: 103,430
Cumulative Timesteps: 862,664,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,327.72068
Policy Entropy: 1.84263
Value Function Loss: 0.07261

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.14352
Policy Update Magnitude: 0.52688
Value Function Update Magnitude: 0.62221

Collected Steps per Second: 22,564.12089
Overall Steps per Second: 10,707.00307

Timestep Collection Time: 2.21617
Timestep Consumption Time: 2.45423
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.67040

Cumulative Model Updates: 103,436
Cumulative Timesteps: 862,714,502

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 862714502...
Checkpoint 862714502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,465.93852
Policy Entropy: 1.83253
Value Function Loss: 0.06799

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.14732
Policy Update Magnitude: 0.56021
Value Function Update Magnitude: 0.63208

Collected Steps per Second: 21,789.19522
Overall Steps per Second: 10,616.73203

Timestep Collection Time: 2.29646
Timestep Consumption Time: 2.41667
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.71313

Cumulative Model Updates: 103,442
Cumulative Timesteps: 862,764,540

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,115.94239
Policy Entropy: 1.83400
Value Function Loss: 0.06896

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.56924
Value Function Update Magnitude: 0.61641

Collected Steps per Second: 22,391.01466
Overall Steps per Second: 10,486.47251

Timestep Collection Time: 2.23429
Timestep Consumption Time: 2.53643
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.77072

Cumulative Model Updates: 103,448
Cumulative Timesteps: 862,814,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 862814568...
Checkpoint 862814568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,016.82193
Policy Entropy: 1.83046
Value Function Loss: 0.06895

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.56986
Value Function Update Magnitude: 0.72224

Collected Steps per Second: 21,391.08210
Overall Steps per Second: 10,328.51075

Timestep Collection Time: 2.33920
Timestep Consumption Time: 2.50545
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.84465

Cumulative Model Updates: 103,454
Cumulative Timesteps: 862,864,606

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,841.02598
Policy Entropy: 1.83293
Value Function Loss: 0.07000

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.56965
Value Function Update Magnitude: 0.64229

Collected Steps per Second: 22,506.76584
Overall Steps per Second: 10,711.63948

Timestep Collection Time: 2.22271
Timestep Consumption Time: 2.44754
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.67025

Cumulative Model Updates: 103,460
Cumulative Timesteps: 862,914,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 862914632...
Checkpoint 862914632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,226.88656
Policy Entropy: 1.83189
Value Function Loss: 0.07592

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.15062
Policy Update Magnitude: 0.55154
Value Function Update Magnitude: 0.55704

Collected Steps per Second: 21,583.78113
Overall Steps per Second: 10,341.87693

Timestep Collection Time: 2.31767
Timestep Consumption Time: 2.51937
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.83703

Cumulative Model Updates: 103,466
Cumulative Timesteps: 862,964,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,456.31226
Policy Entropy: 1.83852
Value Function Loss: 0.08058

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.15604
Policy Update Magnitude: 0.56368
Value Function Update Magnitude: 0.53974

Collected Steps per Second: 22,419.65197
Overall Steps per Second: 10,574.05636

Timestep Collection Time: 2.23054
Timestep Consumption Time: 2.49877
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.72931

Cumulative Model Updates: 103,472
Cumulative Timesteps: 863,014,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 863014664...
Checkpoint 863014664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,534.64078
Policy Entropy: 1.84161
Value Function Loss: 0.08091

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.58853
Value Function Update Magnitude: 0.57496

Collected Steps per Second: 21,229.09062
Overall Steps per Second: 10,395.37900

Timestep Collection Time: 2.35724
Timestep Consumption Time: 2.45663
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.81387

Cumulative Model Updates: 103,478
Cumulative Timesteps: 863,064,706

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,123.37379
Policy Entropy: 1.83372
Value Function Loss: 0.07439

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.14586
Policy Update Magnitude: 0.59371
Value Function Update Magnitude: 0.70108

Collected Steps per Second: 22,559.77170
Overall Steps per Second: 10,574.63699

Timestep Collection Time: 2.21802
Timestep Consumption Time: 2.51387
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.73189

Cumulative Model Updates: 103,484
Cumulative Timesteps: 863,114,744

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 863114744...
Checkpoint 863114744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,744.76898
Policy Entropy: 1.82119
Value Function Loss: 0.07039

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.14108
Policy Update Magnitude: 0.58712
Value Function Update Magnitude: 0.65213

Collected Steps per Second: 21,757.17884
Overall Steps per Second: 10,525.68406

Timestep Collection Time: 2.29901
Timestep Consumption Time: 2.45317
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.75219

Cumulative Model Updates: 103,490
Cumulative Timesteps: 863,164,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,364.89187
Policy Entropy: 1.82384
Value Function Loss: 0.06867

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.57862
Value Function Update Magnitude: 0.71199

Collected Steps per Second: 22,347.77178
Overall Steps per Second: 10,504.42189

Timestep Collection Time: 2.23772
Timestep Consumption Time: 2.52294
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.76066

Cumulative Model Updates: 103,496
Cumulative Timesteps: 863,214,772

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 863214772...
Checkpoint 863214772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,825.32263
Policy Entropy: 1.82440
Value Function Loss: 0.06801

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.14433
Policy Update Magnitude: 0.54809
Value Function Update Magnitude: 0.69586

Collected Steps per Second: 21,309.73905
Overall Steps per Second: 10,224.22006

Timestep Collection Time: 2.34719
Timestep Consumption Time: 2.54492
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.89211

Cumulative Model Updates: 103,502
Cumulative Timesteps: 863,264,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,760.03478
Policy Entropy: 1.81284
Value Function Loss: 0.07053

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.15958
Policy Update Magnitude: 0.50068
Value Function Update Magnitude: 0.61547

Collected Steps per Second: 22,363.29579
Overall Steps per Second: 10,543.77075

Timestep Collection Time: 2.23634
Timestep Consumption Time: 2.50693
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.74327

Cumulative Model Updates: 103,508
Cumulative Timesteps: 863,314,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 863314802...
Checkpoint 863314802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,970.53836
Policy Entropy: 1.81728
Value Function Loss: 0.07212

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.51178
Value Function Update Magnitude: 0.60935

Collected Steps per Second: 21,740.13342
Overall Steps per Second: 10,549.08557

Timestep Collection Time: 2.30183
Timestep Consumption Time: 2.44190
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.74373

Cumulative Model Updates: 103,514
Cumulative Timesteps: 863,364,844

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,922.65365
Policy Entropy: 1.80715
Value Function Loss: 0.07098

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.54674
Value Function Update Magnitude: 0.58061

Collected Steps per Second: 22,169.20939
Overall Steps per Second: 10,453.46335

Timestep Collection Time: 2.25547
Timestep Consumption Time: 2.52782
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.78330

Cumulative Model Updates: 103,520
Cumulative Timesteps: 863,414,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 863414846...
Checkpoint 863414846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,568.80996
Policy Entropy: 1.80440
Value Function Loss: 0.06879

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.15985
Policy Update Magnitude: 0.52245
Value Function Update Magnitude: 0.63207

Collected Steps per Second: 21,569.36600
Overall Steps per Second: 10,500.11834

Timestep Collection Time: 2.31986
Timestep Consumption Time: 2.44561
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.76547

Cumulative Model Updates: 103,526
Cumulative Timesteps: 863,464,884

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,741.88016
Policy Entropy: 1.79567
Value Function Loss: 0.07680

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.15907
Policy Update Magnitude: 0.47656
Value Function Update Magnitude: 0.62217

Collected Steps per Second: 22,421.30661
Overall Steps per Second: 10,519.01127

Timestep Collection Time: 2.23127
Timestep Consumption Time: 2.52469
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.75596

Cumulative Model Updates: 103,532
Cumulative Timesteps: 863,514,912

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 863514912...
Checkpoint 863514912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,923.73552
Policy Entropy: 1.81287
Value Function Loss: 0.07719

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.14773
Policy Update Magnitude: 0.50565
Value Function Update Magnitude: 0.72096

Collected Steps per Second: 21,518.42326
Overall Steps per Second: 10,349.44319

Timestep Collection Time: 2.32461
Timestep Consumption Time: 2.50869
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.83330

Cumulative Model Updates: 103,538
Cumulative Timesteps: 863,564,934

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,709.23211
Policy Entropy: 1.83519
Value Function Loss: 0.08002

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.15189
Policy Update Magnitude: 0.49814
Value Function Update Magnitude: 0.77769

Collected Steps per Second: 21,337.83952
Overall Steps per Second: 10,259.80340

Timestep Collection Time: 2.34344
Timestep Consumption Time: 2.53034
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.87378

Cumulative Model Updates: 103,544
Cumulative Timesteps: 863,614,938

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 863614938...
Checkpoint 863614938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,903.84781
Policy Entropy: 1.83333
Value Function Loss: 0.07573

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.52757
Value Function Update Magnitude: 0.76380

Collected Steps per Second: 21,302.14109
Overall Steps per Second: 10,286.66741

Timestep Collection Time: 2.34718
Timestep Consumption Time: 2.51348
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.86066

Cumulative Model Updates: 103,550
Cumulative Timesteps: 863,664,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,045.88815
Policy Entropy: 1.83215
Value Function Loss: 0.07450

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.15049
Policy Update Magnitude: 0.57069
Value Function Update Magnitude: 0.67550

Collected Steps per Second: 22,419.43956
Overall Steps per Second: 10,564.53449

Timestep Collection Time: 2.23021
Timestep Consumption Time: 2.50261
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.73282

Cumulative Model Updates: 103,556
Cumulative Timesteps: 863,714,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 863714938...
Checkpoint 863714938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,803.99798
Policy Entropy: 1.82775
Value Function Loss: 0.07048

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.14978
Policy Update Magnitude: 0.56094
Value Function Update Magnitude: 0.65051

Collected Steps per Second: 21,767.12311
Overall Steps per Second: 10,441.11084

Timestep Collection Time: 2.29796
Timestep Consumption Time: 2.49272
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.79068

Cumulative Model Updates: 103,562
Cumulative Timesteps: 863,764,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,656.86864
Policy Entropy: 1.83521
Value Function Loss: 0.07613

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.15381
Policy Update Magnitude: 0.53815
Value Function Update Magnitude: 0.64036

Collected Steps per Second: 22,418.95706
Overall Steps per Second: 10,513.72538

Timestep Collection Time: 2.23115
Timestep Consumption Time: 2.52644
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.75759

Cumulative Model Updates: 103,568
Cumulative Timesteps: 863,814,978

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 863814978...
Checkpoint 863814978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,958.87476
Policy Entropy: 1.81960
Value Function Loss: 0.07636

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.16138
Policy Update Magnitude: 0.54246
Value Function Update Magnitude: 0.62782

Collected Steps per Second: 21,519.80110
Overall Steps per Second: 10,498.49701

Timestep Collection Time: 2.32381
Timestep Consumption Time: 2.43954
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.76335

Cumulative Model Updates: 103,574
Cumulative Timesteps: 863,864,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,034.36735
Policy Entropy: 1.83078
Value Function Loss: 0.07965

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.15340
Policy Update Magnitude: 0.56350
Value Function Update Magnitude: 0.65104

Collected Steps per Second: 21,850.34692
Overall Steps per Second: 10,577.54929

Timestep Collection Time: 2.28948
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.72945

Cumulative Model Updates: 103,580
Cumulative Timesteps: 863,915,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 863915012...
Checkpoint 863915012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,538.35644
Policy Entropy: 1.81051
Value Function Loss: 0.07487

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.16083
Policy Update Magnitude: 0.56132
Value Function Update Magnitude: 0.61446

Collected Steps per Second: 21,527.43905
Overall Steps per Second: 10,526.52830

Timestep Collection Time: 2.32280
Timestep Consumption Time: 2.42748
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.75028

Cumulative Model Updates: 103,586
Cumulative Timesteps: 863,965,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,776.68082
Policy Entropy: 1.80799
Value Function Loss: 0.07598

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.18345
Policy Update Magnitude: 0.49666
Value Function Update Magnitude: 0.63848

Collected Steps per Second: 22,292.07441
Overall Steps per Second: 10,548.66428

Timestep Collection Time: 2.24331
Timestep Consumption Time: 2.49739
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.74069

Cumulative Model Updates: 103,592
Cumulative Timesteps: 864,015,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 864015024...
Checkpoint 864015024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,330.96609
Policy Entropy: 1.81023
Value Function Loss: 0.07199

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.16618
Policy Update Magnitude: 0.49020
Value Function Update Magnitude: 0.67205

Collected Steps per Second: 21,508.41756
Overall Steps per Second: 10,352.06459

Timestep Collection Time: 2.32504
Timestep Consumption Time: 2.50568
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.83073

Cumulative Model Updates: 103,598
Cumulative Timesteps: 864,065,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,862.12268
Policy Entropy: 1.81582
Value Function Loss: 0.07423

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.14869
Policy Update Magnitude: 0.52238
Value Function Update Magnitude: 0.71489

Collected Steps per Second: 22,518.38840
Overall Steps per Second: 10,736.35014

Timestep Collection Time: 2.22059
Timestep Consumption Time: 2.43686
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.65745

Cumulative Model Updates: 103,604
Cumulative Timesteps: 864,115,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 864115036...
Checkpoint 864115036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,053.67436
Policy Entropy: 1.83029
Value Function Loss: 0.07209

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.15836
Policy Update Magnitude: 0.51263
Value Function Update Magnitude: 0.69513

Collected Steps per Second: 21,633.56826
Overall Steps per Second: 10,537.36831

Timestep Collection Time: 2.31335
Timestep Consumption Time: 2.43603
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.74938

Cumulative Model Updates: 103,610
Cumulative Timesteps: 864,165,082

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,705.24640
Policy Entropy: 1.82379
Value Function Loss: 0.07556

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.52055
Value Function Update Magnitude: 0.67431

Collected Steps per Second: 22,448.82868
Overall Steps per Second: 10,530.12969

Timestep Collection Time: 2.22729
Timestep Consumption Time: 2.52099
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.74828

Cumulative Model Updates: 103,616
Cumulative Timesteps: 864,215,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 864215082...
Checkpoint 864215082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,236.36407
Policy Entropy: 1.81516
Value Function Loss: 0.07813

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.56816
Value Function Update Magnitude: 0.65105

Collected Steps per Second: 21,189.39290
Overall Steps per Second: 10,275.60540

Timestep Collection Time: 2.36033
Timestep Consumption Time: 2.50692
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.86726

Cumulative Model Updates: 103,622
Cumulative Timesteps: 864,265,096

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,650.29703
Policy Entropy: 1.82081
Value Function Loss: 0.07954

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.14373
Policy Update Magnitude: 0.57161
Value Function Update Magnitude: 0.67575

Collected Steps per Second: 21,721.21760
Overall Steps per Second: 10,607.84792

Timestep Collection Time: 2.30282
Timestep Consumption Time: 2.41256
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.71538

Cumulative Model Updates: 103,628
Cumulative Timesteps: 864,315,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 864315116...
Checkpoint 864315116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,287.88519
Policy Entropy: 1.81514
Value Function Loss: 0.07884

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.14447
Policy Update Magnitude: 0.56466
Value Function Update Magnitude: 0.70284

Collected Steps per Second: 21,264.53124
Overall Steps per Second: 10,424.08032

Timestep Collection Time: 2.35190
Timestep Consumption Time: 2.44584
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.79774

Cumulative Model Updates: 103,634
Cumulative Timesteps: 864,365,128

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,020.11508
Policy Entropy: 1.81353
Value Function Loss: 0.07606

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13766
Policy Update Magnitude: 0.57670
Value Function Update Magnitude: 0.63786

Collected Steps per Second: 21,937.16058
Overall Steps per Second: 10,648.02774

Timestep Collection Time: 2.27997
Timestep Consumption Time: 2.41724
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.69721

Cumulative Model Updates: 103,640
Cumulative Timesteps: 864,415,144

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 864415144...
Checkpoint 864415144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,060.34854
Policy Entropy: 1.79428
Value Function Loss: 0.07442

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.57774
Value Function Update Magnitude: 0.64635

Collected Steps per Second: 21,011.21865
Overall Steps per Second: 10,440.32823

Timestep Collection Time: 2.38120
Timestep Consumption Time: 2.41098
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.79219

Cumulative Model Updates: 103,646
Cumulative Timesteps: 864,465,176

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,931.67825
Policy Entropy: 1.79654
Value Function Loss: 0.06838

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.14885
Policy Update Magnitude: 0.56094
Value Function Update Magnitude: 0.69453

Collected Steps per Second: 21,763.18910
Overall Steps per Second: 10,547.91891

Timestep Collection Time: 2.29783
Timestep Consumption Time: 2.44320
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.74103

Cumulative Model Updates: 103,652
Cumulative Timesteps: 864,515,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 864515184...
Checkpoint 864515184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,898.67385
Policy Entropy: 1.78583
Value Function Loss: 0.06782

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.55143
Value Function Update Magnitude: 0.70629

Collected Steps per Second: 20,626.97901
Overall Steps per Second: 10,455.64013

Timestep Collection Time: 2.42508
Timestep Consumption Time: 2.35914
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.78421

Cumulative Model Updates: 103,658
Cumulative Timesteps: 864,565,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,507.73622
Policy Entropy: 1.76772
Value Function Loss: 0.06672

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.55555
Value Function Update Magnitude: 0.70988

Collected Steps per Second: 21,638.77775
Overall Steps per Second: 10,559.23838

Timestep Collection Time: 2.31187
Timestep Consumption Time: 2.42578
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.73765

Cumulative Model Updates: 103,664
Cumulative Timesteps: 864,615,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 864615232...
Checkpoint 864615232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,273.07234
Policy Entropy: 1.76338
Value Function Loss: 0.06495

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.16689
Policy Update Magnitude: 0.50777
Value Function Update Magnitude: 0.69755

Collected Steps per Second: 21,843.84735
Overall Steps per Second: 10,604.88513

Timestep Collection Time: 2.29090
Timestep Consumption Time: 2.42787
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.71877

Cumulative Model Updates: 103,670
Cumulative Timesteps: 864,665,274

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,947.11123
Policy Entropy: 1.77225
Value Function Loss: 0.06483

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.52083
Value Function Update Magnitude: 0.69695

Collected Steps per Second: 22,359.58002
Overall Steps per Second: 10,603.34060

Timestep Collection Time: 2.23645
Timestep Consumption Time: 2.47961
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.71606

Cumulative Model Updates: 103,676
Cumulative Timesteps: 864,715,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 864715280...
Checkpoint 864715280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,010.00931
Policy Entropy: 1.77558
Value Function Loss: 0.06329

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.15797
Policy Update Magnitude: 0.53935
Value Function Update Magnitude: 0.70691

Collected Steps per Second: 21,521.40799
Overall Steps per Second: 10,552.50533

Timestep Collection Time: 2.32457
Timestep Consumption Time: 2.41630
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.74086

Cumulative Model Updates: 103,682
Cumulative Timesteps: 864,765,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,410.41070
Policy Entropy: 1.77218
Value Function Loss: 0.06640

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.15108
Policy Update Magnitude: 0.51260
Value Function Update Magnitude: 0.64232

Collected Steps per Second: 22,659.90894
Overall Steps per Second: 10,733.15199

Timestep Collection Time: 2.20654
Timestep Consumption Time: 2.45192
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.65846

Cumulative Model Updates: 103,688
Cumulative Timesteps: 864,815,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 864815308...
Checkpoint 864815308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,841.92127
Policy Entropy: 1.76744
Value Function Loss: 0.07740

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.15292
Policy Update Magnitude: 0.54444
Value Function Update Magnitude: 0.58851

Collected Steps per Second: 21,384.47775
Overall Steps per Second: 10,286.33473

Timestep Collection Time: 2.33871
Timestep Consumption Time: 2.52328
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.86198

Cumulative Model Updates: 103,694
Cumulative Timesteps: 864,865,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,944.32196
Policy Entropy: 1.78505
Value Function Loss: 0.07539

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.56459
Value Function Update Magnitude: 0.67027

Collected Steps per Second: 22,679.68156
Overall Steps per Second: 10,611.30895

Timestep Collection Time: 2.20515
Timestep Consumption Time: 2.50794
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.71308

Cumulative Model Updates: 103,700
Cumulative Timesteps: 864,915,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 864915332...
Checkpoint 864915332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,488.04854
Policy Entropy: 1.77499
Value Function Loss: 0.07077

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14247
Policy Update Magnitude: 0.56962
Value Function Update Magnitude: 0.72655

Collected Steps per Second: 21,921.37569
Overall Steps per Second: 10,518.53317

Timestep Collection Time: 2.28334
Timestep Consumption Time: 2.47531
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.75865

Cumulative Model Updates: 103,706
Cumulative Timesteps: 864,965,386

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,932.07534
Policy Entropy: 1.76676
Value Function Loss: 0.06310

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.55189
Value Function Update Magnitude: 0.64996

Collected Steps per Second: 22,390.32778
Overall Steps per Second: 10,538.99650

Timestep Collection Time: 2.23346
Timestep Consumption Time: 2.51158
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.74504

Cumulative Model Updates: 103,712
Cumulative Timesteps: 865,015,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 865015394...
Checkpoint 865015394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,694.97290
Policy Entropy: 1.74511
Value Function Loss: 0.06896

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.54129
Value Function Update Magnitude: 0.60160

Collected Steps per Second: 21,500.43494
Overall Steps per Second: 10,483.76143

Timestep Collection Time: 2.32619
Timestep Consumption Time: 2.44443
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.77062

Cumulative Model Updates: 103,718
Cumulative Timesteps: 865,065,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,047.42018
Policy Entropy: 1.75963
Value Function Loss: 0.06863

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.56132
Value Function Update Magnitude: 0.64730

Collected Steps per Second: 22,411.27508
Overall Steps per Second: 10,511.87092

Timestep Collection Time: 2.23218
Timestep Consumption Time: 2.52682
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.75900

Cumulative Model Updates: 103,724
Cumulative Timesteps: 865,115,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 865115434...
Checkpoint 865115434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,665.04984
Policy Entropy: 1.76216
Value Function Loss: 0.06967

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.56351
Value Function Update Magnitude: 0.56902

Collected Steps per Second: 20,994.60735
Overall Steps per Second: 10,176.19356

Timestep Collection Time: 2.38271
Timestep Consumption Time: 2.53308
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.91579

Cumulative Model Updates: 103,730
Cumulative Timesteps: 865,165,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,613.72777
Policy Entropy: 1.75325
Value Function Loss: 0.07180

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.56333
Value Function Update Magnitude: 0.52733

Collected Steps per Second: 22,490.99172
Overall Steps per Second: 10,553.37524

Timestep Collection Time: 2.22498
Timestep Consumption Time: 2.51682
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.74180

Cumulative Model Updates: 103,736
Cumulative Timesteps: 865,215,500

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 865215500...
Checkpoint 865215500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,340.55988
Policy Entropy: 1.75356
Value Function Loss: 0.07592

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.55500
Value Function Update Magnitude: 0.50462

Collected Steps per Second: 21,784.35500
Overall Steps per Second: 10,550.67643

Timestep Collection Time: 2.29651
Timestep Consumption Time: 2.44518
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.74169

Cumulative Model Updates: 103,742
Cumulative Timesteps: 865,265,528

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,870.21959
Policy Entropy: 1.76836
Value Function Loss: 0.07680

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.57202
Value Function Update Magnitude: 0.52571

Collected Steps per Second: 22,582.24438
Overall Steps per Second: 10,655.86911

Timestep Collection Time: 2.21439
Timestep Consumption Time: 2.47842
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.69281

Cumulative Model Updates: 103,748
Cumulative Timesteps: 865,315,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 865315534...
Checkpoint 865315534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,631.27833
Policy Entropy: 1.77695
Value Function Loss: 0.07505

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.13680
Policy Update Magnitude: 0.57165
Value Function Update Magnitude: 0.49525

Collected Steps per Second: 21,480.27156
Overall Steps per Second: 10,504.39845

Timestep Collection Time: 2.32865
Timestep Consumption Time: 2.43317
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.76181

Cumulative Model Updates: 103,754
Cumulative Timesteps: 865,365,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,198.59389
Policy Entropy: 1.77820
Value Function Loss: 0.06840

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.57279
Value Function Update Magnitude: 0.48479

Collected Steps per Second: 22,427.28521
Overall Steps per Second: 10,583.08099

Timestep Collection Time: 2.22987
Timestep Consumption Time: 2.49559
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.72547

Cumulative Model Updates: 103,760
Cumulative Timesteps: 865,415,564

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 865415564...
Checkpoint 865415564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,541.79659
Policy Entropy: 1.77983
Value Function Loss: 0.06872

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.57137
Value Function Update Magnitude: 0.42785

Collected Steps per Second: 21,469.17937
Overall Steps per Second: 10,469.18542

Timestep Collection Time: 2.32901
Timestep Consumption Time: 2.44710
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.77611

Cumulative Model Updates: 103,766
Cumulative Timesteps: 865,465,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,166.50794
Policy Entropy: 1.77050
Value Function Loss: 0.06925

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.57172
Value Function Update Magnitude: 0.46589

Collected Steps per Second: 21,772.90726
Overall Steps per Second: 10,419.95050

Timestep Collection Time: 2.29763
Timestep Consumption Time: 2.50336
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.80098

Cumulative Model Updates: 103,772
Cumulative Timesteps: 865,515,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 865515592...
Checkpoint 865515592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,102.39021
Policy Entropy: 1.77573
Value Function Loss: 0.07712

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.56769
Value Function Update Magnitude: 0.43794

Collected Steps per Second: 21,400.15963
Overall Steps per Second: 10,326.88678

Timestep Collection Time: 2.33746
Timestep Consumption Time: 2.50640
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.84386

Cumulative Model Updates: 103,778
Cumulative Timesteps: 865,565,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,757.30081
Policy Entropy: 1.77878
Value Function Loss: 0.07803

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.15164
Policy Update Magnitude: 0.55015
Value Function Update Magnitude: 0.42124

Collected Steps per Second: 22,534.46842
Overall Steps per Second: 10,721.30066

Timestep Collection Time: 2.21909
Timestep Consumption Time: 2.44508
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.66417

Cumulative Model Updates: 103,784
Cumulative Timesteps: 865,615,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 865615620...
Checkpoint 865615620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,745.12622
Policy Entropy: 1.79228
Value Function Loss: 0.07763

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.14797
Policy Update Magnitude: 0.55583
Value Function Update Magnitude: 0.46307

Collected Steps per Second: 21,529.12540
Overall Steps per Second: 10,304.82711

Timestep Collection Time: 2.32466
Timestep Consumption Time: 2.53209
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.85675

Cumulative Model Updates: 103,790
Cumulative Timesteps: 865,665,668

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,553.39961
Policy Entropy: 1.78901
Value Function Loss: 0.07201

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14715
Policy Update Magnitude: 0.56143
Value Function Update Magnitude: 0.55831

Collected Steps per Second: 22,275.15933
Overall Steps per Second: 10,521.45521

Timestep Collection Time: 2.24501
Timestep Consumption Time: 2.50794
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.75295

Cumulative Model Updates: 103,796
Cumulative Timesteps: 865,715,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 865715676...
Checkpoint 865715676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,447.40694
Policy Entropy: 1.80217
Value Function Loss: 0.07344

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.56995
Value Function Update Magnitude: 0.64843

Collected Steps per Second: 21,864.34443
Overall Steps per Second: 10,573.02018

Timestep Collection Time: 2.28692
Timestep Consumption Time: 2.44229
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.72921

Cumulative Model Updates: 103,802
Cumulative Timesteps: 865,765,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,712.13867
Policy Entropy: 1.79283
Value Function Loss: 0.07066

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.57922
Value Function Update Magnitude: 0.70929

Collected Steps per Second: 22,702.26802
Overall Steps per Second: 10,805.72782

Timestep Collection Time: 2.20304
Timestep Consumption Time: 2.42543
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.62847

Cumulative Model Updates: 103,808
Cumulative Timesteps: 865,815,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 865815692...
Checkpoint 865815692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,047.56033
Policy Entropy: 1.78751
Value Function Loss: 0.06566

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.14635
Policy Update Magnitude: 0.56873
Value Function Update Magnitude: 0.73379

Collected Steps per Second: 21,627.13797
Overall Steps per Second: 10,360.83511

Timestep Collection Time: 2.31293
Timestep Consumption Time: 2.51506
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.82799

Cumulative Model Updates: 103,814
Cumulative Timesteps: 865,865,714

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,922.25019
Policy Entropy: 1.77658
Value Function Loss: 0.06666

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.14117
Policy Update Magnitude: 0.56522
Value Function Update Magnitude: 0.70783

Collected Steps per Second: 22,847.54422
Overall Steps per Second: 10,835.12220

Timestep Collection Time: 2.18912
Timestep Consumption Time: 2.42698
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.61610

Cumulative Model Updates: 103,820
Cumulative Timesteps: 865,915,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 865915730...
Checkpoint 865915730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,801.64481
Policy Entropy: 1.77975
Value Function Loss: 0.07173

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.58183
Value Function Update Magnitude: 0.63644

Collected Steps per Second: 21,863.94453
Overall Steps per Second: 10,590.34148

Timestep Collection Time: 2.28852
Timestep Consumption Time: 2.43617
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.72468

Cumulative Model Updates: 103,826
Cumulative Timesteps: 865,965,766

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,746.58121
Policy Entropy: 1.78131
Value Function Loss: 0.07426

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.57645
Value Function Update Magnitude: 0.53164

Collected Steps per Second: 22,692.52567
Overall Steps per Second: 10,643.50551

Timestep Collection Time: 2.20346
Timestep Consumption Time: 2.49443
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.69789

Cumulative Model Updates: 103,832
Cumulative Timesteps: 866,015,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 866015768...
Checkpoint 866015768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,524.21160
Policy Entropy: 1.77807
Value Function Loss: 0.07375

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.14656
Policy Update Magnitude: 0.56575
Value Function Update Magnitude: 0.61037

Collected Steps per Second: 21,415.79885
Overall Steps per Second: 10,464.00792

Timestep Collection Time: 2.33519
Timestep Consumption Time: 2.44405
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.77924

Cumulative Model Updates: 103,838
Cumulative Timesteps: 866,065,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,289.20656
Policy Entropy: 1.76705
Value Function Loss: 0.07284

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.16522
Policy Update Magnitude: 0.50545
Value Function Update Magnitude: 0.63203

Collected Steps per Second: 22,607.89464
Overall Steps per Second: 10,605.85159

Timestep Collection Time: 2.21241
Timestep Consumption Time: 2.50366
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.71608

Cumulative Model Updates: 103,844
Cumulative Timesteps: 866,115,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 866115796...
Checkpoint 866115796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,195.65154
Policy Entropy: 1.77226
Value Function Loss: 0.06739

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.15105
Policy Update Magnitude: 0.49928
Value Function Update Magnitude: 0.68250

Collected Steps per Second: 21,873.64137
Overall Steps per Second: 10,429.83232

Timestep Collection Time: 2.28677
Timestep Consumption Time: 2.50909
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.79586

Cumulative Model Updates: 103,850
Cumulative Timesteps: 866,165,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,527.40906
Policy Entropy: 1.76454
Value Function Loss: 0.05964

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.52864
Value Function Update Magnitude: 0.70998

Collected Steps per Second: 22,458.55563
Overall Steps per Second: 10,531.05324

Timestep Collection Time: 2.22641
Timestep Consumption Time: 2.52164
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.74805

Cumulative Model Updates: 103,856
Cumulative Timesteps: 866,215,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 866215818...
Checkpoint 866215818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,570.67617
Policy Entropy: 1.78112
Value Function Loss: 0.06043

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.16356
Policy Update Magnitude: 0.49076
Value Function Update Magnitude: 0.64379

Collected Steps per Second: 21,421.52379
Overall Steps per Second: 10,484.34281

Timestep Collection Time: 2.33513
Timestep Consumption Time: 2.43599
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.77111

Cumulative Model Updates: 103,862
Cumulative Timesteps: 866,265,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,082.43329
Policy Entropy: 1.76482
Value Function Loss: 0.06415

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.15689
Policy Update Magnitude: 0.46254
Value Function Update Magnitude: 0.64561

Collected Steps per Second: 22,209.61563
Overall Steps per Second: 10,533.29619

Timestep Collection Time: 2.25191
Timestep Consumption Time: 2.49627
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.74818

Cumulative Model Updates: 103,868
Cumulative Timesteps: 866,315,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 866315854...
Checkpoint 866315854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,750.82585
Policy Entropy: 1.77011
Value Function Loss: 0.06858

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.52465
Value Function Update Magnitude: 0.69353

Collected Steps per Second: 20,671.41223
Overall Steps per Second: 10,145.90853

Timestep Collection Time: 2.42006
Timestep Consumption Time: 2.51060
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.93066

Cumulative Model Updates: 103,874
Cumulative Timesteps: 866,365,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,303.58678
Policy Entropy: 1.76285
Value Function Loss: 0.07311

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.16287
Policy Update Magnitude: 0.55459
Value Function Update Magnitude: 0.64907

Collected Steps per Second: 22,026.31143
Overall Steps per Second: 10,518.47045

Timestep Collection Time: 2.27056
Timestep Consumption Time: 2.48413
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.75468

Cumulative Model Updates: 103,880
Cumulative Timesteps: 866,415,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 866415892...
Checkpoint 866415892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,922.81100
Policy Entropy: 1.77027
Value Function Loss: 0.07322

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.15332
Policy Update Magnitude: 0.55477
Value Function Update Magnitude: 0.59052

Collected Steps per Second: 21,407.38401
Overall Steps per Second: 10,350.28699

Timestep Collection Time: 2.33676
Timestep Consumption Time: 2.49634
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.83310

Cumulative Model Updates: 103,886
Cumulative Timesteps: 866,465,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,074.44694
Policy Entropy: 1.77336
Value Function Loss: 0.06823

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.15326
Policy Update Magnitude: 0.53417
Value Function Update Magnitude: 0.59325

Collected Steps per Second: 22,406.87445
Overall Steps per Second: 10,709.06005

Timestep Collection Time: 2.23324
Timestep Consumption Time: 2.43944
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.67268

Cumulative Model Updates: 103,892
Cumulative Timesteps: 866,515,956

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 866515956...
Checkpoint 866515956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,442.98900
Policy Entropy: 1.77241
Value Function Loss: 0.06246

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.14921
Policy Update Magnitude: 0.52822
Value Function Update Magnitude: 0.62755

Collected Steps per Second: 21,430.58268
Overall Steps per Second: 10,299.28120

Timestep Collection Time: 2.33330
Timestep Consumption Time: 2.52180
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.85510

Cumulative Model Updates: 103,898
Cumulative Timesteps: 866,565,960

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,849.77477
Policy Entropy: 1.77072
Value Function Loss: 0.06242

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.54803
Value Function Update Magnitude: 0.63993

Collected Steps per Second: 22,342.05941
Overall Steps per Second: 10,557.65485

Timestep Collection Time: 2.23811
Timestep Consumption Time: 2.49817
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.73628

Cumulative Model Updates: 103,904
Cumulative Timesteps: 866,615,964

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 866615964...
Checkpoint 866615964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,661.11880
Policy Entropy: 1.75311
Value Function Loss: 0.06695

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.54747
Value Function Update Magnitude: 0.65280

Collected Steps per Second: 21,850.00463
Overall Steps per Second: 10,410.08483

Timestep Collection Time: 2.28906
Timestep Consumption Time: 2.51551
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.80457

Cumulative Model Updates: 103,910
Cumulative Timesteps: 866,665,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,963.78875
Policy Entropy: 1.74444
Value Function Loss: 0.07580

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.17383
Policy Update Magnitude: 0.51779
Value Function Update Magnitude: 0.59491

Collected Steps per Second: 22,277.27237
Overall Steps per Second: 10,474.81318

Timestep Collection Time: 2.24543
Timestep Consumption Time: 2.53003
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.77546

Cumulative Model Updates: 103,916
Cumulative Timesteps: 866,716,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 866716002...
Checkpoint 866716002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,591.94240
Policy Entropy: 1.75625
Value Function Loss: 0.07760

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.17234
Policy Update Magnitude: 0.52394
Value Function Update Magnitude: 0.57968

Collected Steps per Second: 21,265.32511
Overall Steps per Second: 10,265.62911

Timestep Collection Time: 2.35200
Timestep Consumption Time: 2.52018
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.87218

Cumulative Model Updates: 103,922
Cumulative Timesteps: 866,766,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,179.04946
Policy Entropy: 1.75924
Value Function Loss: 0.07596

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.16691
Policy Update Magnitude: 0.53253
Value Function Update Magnitude: 0.57018

Collected Steps per Second: 22,247.82686
Overall Steps per Second: 10,485.58108

Timestep Collection Time: 2.24777
Timestep Consumption Time: 2.52145
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.76922

Cumulative Model Updates: 103,928
Cumulative Timesteps: 866,816,026

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 866816026...
Checkpoint 866816026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,506.00695
Policy Entropy: 1.76791
Value Function Loss: 0.07033

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.15671
Policy Update Magnitude: 0.54050
Value Function Update Magnitude: 0.55782

Collected Steps per Second: 21,648.91299
Overall Steps per Second: 10,488.36989

Timestep Collection Time: 2.31060
Timestep Consumption Time: 2.45868
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.76928

Cumulative Model Updates: 103,934
Cumulative Timesteps: 866,866,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,117.31631
Policy Entropy: 1.75749
Value Function Loss: 0.06687

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.14721
Policy Update Magnitude: 0.56985
Value Function Update Magnitude: 0.63913

Collected Steps per Second: 22,504.72291
Overall Steps per Second: 10,524.60429

Timestep Collection Time: 2.22193
Timestep Consumption Time: 2.52922
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.75115

Cumulative Model Updates: 103,940
Cumulative Timesteps: 866,916,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 866916052...
Checkpoint 866916052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,121.40303
Policy Entropy: 1.76128
Value Function Loss: 0.06363

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.62948

Collected Steps per Second: 21,396.66637
Overall Steps per Second: 10,354.43636

Timestep Collection Time: 2.33756
Timestep Consumption Time: 2.49283
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.83039

Cumulative Model Updates: 103,946
Cumulative Timesteps: 866,966,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,447.65960
Policy Entropy: 1.76436
Value Function Loss: 0.06654

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.57510
Value Function Update Magnitude: 0.52231

Collected Steps per Second: 22,736.14268
Overall Steps per Second: 10,696.23931

Timestep Collection Time: 2.20125
Timestep Consumption Time: 2.47777
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.67903

Cumulative Model Updates: 103,952
Cumulative Timesteps: 867,016,116

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 867016116...
Checkpoint 867016116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,675.96006
Policy Entropy: 1.77458
Value Function Loss: 0.07382

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.58412
Value Function Update Magnitude: 0.50289

Collected Steps per Second: 21,331.53062
Overall Steps per Second: 10,279.58232

Timestep Collection Time: 2.34432
Timestep Consumption Time: 2.52047
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.86479

Cumulative Model Updates: 103,958
Cumulative Timesteps: 867,066,124

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,675.18824
Policy Entropy: 1.80894
Value Function Loss: 0.07866

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.58405
Value Function Update Magnitude: 0.57217

Collected Steps per Second: 22,627.94482
Overall Steps per Second: 10,741.23633

Timestep Collection Time: 2.21125
Timestep Consumption Time: 2.44706
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.65831

Cumulative Model Updates: 103,964
Cumulative Timesteps: 867,116,160

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 867116160...
Checkpoint 867116160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,834.07446
Policy Entropy: 1.80882
Value Function Loss: 0.07972

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.14961
Policy Update Magnitude: 0.57733
Value Function Update Magnitude: 0.66981

Collected Steps per Second: 21,437.52190
Overall Steps per Second: 10,319.37828

Timestep Collection Time: 2.33292
Timestep Consumption Time: 2.51350
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.84642

Cumulative Model Updates: 103,970
Cumulative Timesteps: 867,166,172

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,222.97186
Policy Entropy: 1.79906
Value Function Loss: 0.07590

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.57090
Value Function Update Magnitude: 0.64023

Collected Steps per Second: 22,626.21168
Overall Steps per Second: 10,768.19850

Timestep Collection Time: 2.21115
Timestep Consumption Time: 2.43494
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.64609

Cumulative Model Updates: 103,976
Cumulative Timesteps: 867,216,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 867216202...
Checkpoint 867216202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,835.19030
Policy Entropy: 1.76974
Value Function Loss: 0.07540

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.57901
Value Function Update Magnitude: 0.63236

Collected Steps per Second: 21,383.37280
Overall Steps per Second: 10,307.29233

Timestep Collection Time: 2.34051
Timestep Consumption Time: 2.51508
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.85559

Cumulative Model Updates: 103,982
Cumulative Timesteps: 867,266,250

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,349.67300
Policy Entropy: 1.76334
Value Function Loss: 0.07689

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.58533
Value Function Update Magnitude: 0.58803

Collected Steps per Second: 22,310.38382
Overall Steps per Second: 10,496.04063

Timestep Collection Time: 2.24209
Timestep Consumption Time: 2.52370
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.76580

Cumulative Model Updates: 103,988
Cumulative Timesteps: 867,316,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 867316272...
Checkpoint 867316272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,349.37480
Policy Entropy: 1.77139
Value Function Loss: 0.07548

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.58611
Value Function Update Magnitude: 0.60337

Collected Steps per Second: 21,780.33726
Overall Steps per Second: 10,508.99811

Timestep Collection Time: 2.29647
Timestep Consumption Time: 2.46307
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.75954

Cumulative Model Updates: 103,994
Cumulative Timesteps: 867,366,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,250.52351
Policy Entropy: 1.78536
Value Function Loss: 0.07332

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.14452
Policy Update Magnitude: 0.57802
Value Function Update Magnitude: 0.62054

Collected Steps per Second: 22,394.05423
Overall Steps per Second: 10,507.23763

Timestep Collection Time: 2.23363
Timestep Consumption Time: 2.52690
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.76053

Cumulative Model Updates: 104,000
Cumulative Timesteps: 867,416,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 867416310...
Checkpoint 867416310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,091.46114
Policy Entropy: 1.78251
Value Function Loss: 0.07233

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.14564
Policy Update Magnitude: 0.57492
Value Function Update Magnitude: 0.59750

Collected Steps per Second: 20,846.72292
Overall Steps per Second: 10,398.28447

Timestep Collection Time: 2.40019
Timestep Consumption Time: 2.41176
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.81195

Cumulative Model Updates: 104,006
Cumulative Timesteps: 867,466,346

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,299.38590
Policy Entropy: 1.78162
Value Function Loss: 0.07603

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.58394
Value Function Update Magnitude: 0.58554

Collected Steps per Second: 21,948.74676
Overall Steps per Second: 10,795.50992

Timestep Collection Time: 2.27849
Timestep Consumption Time: 2.35399
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.63248

Cumulative Model Updates: 104,012
Cumulative Timesteps: 867,516,356

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 867516356...
Checkpoint 867516356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,397.72576
Policy Entropy: 1.78740
Value Function Loss: 0.07226

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.15949
Policy Update Magnitude: 0.57191
Value Function Update Magnitude: 0.65502

Collected Steps per Second: 20,764.40900
Overall Steps per Second: 10,489.22436

Timestep Collection Time: 2.40931
Timestep Consumption Time: 2.36015
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.76947

Cumulative Model Updates: 104,018
Cumulative Timesteps: 867,566,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,245.45886
Policy Entropy: 1.79418
Value Function Loss: 0.06999

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.16560
Policy Update Magnitude: 0.53029
Value Function Update Magnitude: 0.63177

Collected Steps per Second: 21,705.06826
Overall Steps per Second: 10,522.89191

Timestep Collection Time: 2.30416
Timestep Consumption Time: 2.44852
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.75269

Cumulative Model Updates: 104,024
Cumulative Timesteps: 867,616,396

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 867616396...
Checkpoint 867616396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,094.22527
Policy Entropy: 1.80376
Value Function Loss: 0.06864

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.16290
Policy Update Magnitude: 0.54082
Value Function Update Magnitude: 0.64357

Collected Steps per Second: 20,573.97930
Overall Steps per Second: 10,273.47119

Timestep Collection Time: 2.43103
Timestep Consumption Time: 2.43743
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.86846

Cumulative Model Updates: 104,030
Cumulative Timesteps: 867,666,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,627.68448
Policy Entropy: 1.80844
Value Function Loss: 0.06766

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.15835
Policy Update Magnitude: 0.57187
Value Function Update Magnitude: 0.67978

Collected Steps per Second: 21,884.31772
Overall Steps per Second: 10,748.82900

Timestep Collection Time: 2.28556
Timestep Consumption Time: 2.36778
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.65334

Cumulative Model Updates: 104,036
Cumulative Timesteps: 867,716,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 867716430...
Checkpoint 867716430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,719.66388
Policy Entropy: 1.80844
Value Function Loss: 0.06931

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.15480
Policy Update Magnitude: 0.57761
Value Function Update Magnitude: 0.70791

Collected Steps per Second: 20,544.18091
Overall Steps per Second: 10,309.90610

Timestep Collection Time: 2.43456
Timestep Consumption Time: 2.41670
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.85126

Cumulative Model Updates: 104,042
Cumulative Timesteps: 867,766,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,292.55113
Policy Entropy: 1.79124
Value Function Loss: 0.06768

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14598
Policy Update Magnitude: 0.57438
Value Function Update Magnitude: 0.61715

Collected Steps per Second: 22,573.09562
Overall Steps per Second: 10,783.40093

Timestep Collection Time: 2.21680
Timestep Consumption Time: 2.42367
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.64047

Cumulative Model Updates: 104,048
Cumulative Timesteps: 867,816,486

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 867816486...
Checkpoint 867816486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,516.12866
Policy Entropy: 1.78283
Value Function Loss: 0.06995

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14361
Policy Update Magnitude: 0.57636
Value Function Update Magnitude: 0.64931

Collected Steps per Second: 21,563.97035
Overall Steps per Second: 10,387.78718

Timestep Collection Time: 2.31933
Timestep Consumption Time: 2.49536
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.81469

Cumulative Model Updates: 104,054
Cumulative Timesteps: 867,866,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,513.04592
Policy Entropy: 1.77153
Value Function Loss: 0.07029

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.14254
Policy Update Magnitude: 0.58377
Value Function Update Magnitude: 0.67786

Collected Steps per Second: 22,504.20919
Overall Steps per Second: 10,776.51931

Timestep Collection Time: 2.22270
Timestep Consumption Time: 2.41888
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.64157

Cumulative Model Updates: 104,060
Cumulative Timesteps: 867,916,520

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 867916520...
Checkpoint 867916520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,871.33838
Policy Entropy: 1.77997
Value Function Loss: 0.07267

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14583
Policy Update Magnitude: 0.58732
Value Function Update Magnitude: 0.58465

Collected Steps per Second: 21,431.68709
Overall Steps per Second: 10,292.24456

Timestep Collection Time: 2.33383
Timestep Consumption Time: 2.52594
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.85978

Cumulative Model Updates: 104,066
Cumulative Timesteps: 867,966,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,810.67004
Policy Entropy: 1.80016
Value Function Loss: 0.07575

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.14974
Policy Update Magnitude: 0.59014
Value Function Update Magnitude: 0.51025

Collected Steps per Second: 22,542.97423
Overall Steps per Second: 10,599.90445

Timestep Collection Time: 2.21870
Timestep Consumption Time: 2.49984
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.71853

Cumulative Model Updates: 104,072
Cumulative Timesteps: 868,016,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 868016554...
Checkpoint 868016554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,572.53035
Policy Entropy: 1.80747
Value Function Loss: 0.07571

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.58796
Value Function Update Magnitude: 0.44632

Collected Steps per Second: 21,499.25677
Overall Steps per Second: 10,452.29843

Timestep Collection Time: 2.32780
Timestep Consumption Time: 2.46024
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.78804

Cumulative Model Updates: 104,078
Cumulative Timesteps: 868,066,600

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,822.70672
Policy Entropy: 1.79330
Value Function Loss: 0.07417

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.58865
Value Function Update Magnitude: 0.42725

Collected Steps per Second: 22,431.03443
Overall Steps per Second: 10,487.34187

Timestep Collection Time: 2.22995
Timestep Consumption Time: 2.53961
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.76956

Cumulative Model Updates: 104,084
Cumulative Timesteps: 868,116,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 868116620...
Checkpoint 868116620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,536.35756
Policy Entropy: 1.76661
Value Function Loss: 0.06854

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.57444
Value Function Update Magnitude: 0.42052

Collected Steps per Second: 21,542.26085
Overall Steps per Second: 10,511.20732

Timestep Collection Time: 2.32204
Timestep Consumption Time: 2.43688
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.75892

Cumulative Model Updates: 104,090
Cumulative Timesteps: 868,166,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,332.18189
Policy Entropy: 1.77937
Value Function Loss: 0.07130

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.57866
Value Function Update Magnitude: 0.38182

Collected Steps per Second: 22,479.57282
Overall Steps per Second: 10,632.60221

Timestep Collection Time: 2.22558
Timestep Consumption Time: 2.47976
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.70534

Cumulative Model Updates: 104,096
Cumulative Timesteps: 868,216,672

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 868216672...
Checkpoint 868216672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,953.56865
Policy Entropy: 1.79058
Value Function Loss: 0.06934

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.57690
Value Function Update Magnitude: 0.48624

Collected Steps per Second: 21,762.75343
Overall Steps per Second: 10,547.72838

Timestep Collection Time: 2.29760
Timestep Consumption Time: 2.44295
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.74055

Cumulative Model Updates: 104,102
Cumulative Timesteps: 868,266,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,587.90137
Policy Entropy: 1.79011
Value Function Loss: 0.07266

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.14278
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.48971

Collected Steps per Second: 22,794.25024
Overall Steps per Second: 10,787.91136

Timestep Collection Time: 2.19433
Timestep Consumption Time: 2.44216
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.63649

Cumulative Model Updates: 104,108
Cumulative Timesteps: 868,316,692

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 868316692...
Checkpoint 868316692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,907.31047
Policy Entropy: 1.77251
Value Function Loss: 0.06893

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.55775
Value Function Update Magnitude: 0.54376

Collected Steps per Second: 21,073.84948
Overall Steps per Second: 10,266.69156

Timestep Collection Time: 2.37337
Timestep Consumption Time: 2.49831
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.87168

Cumulative Model Updates: 104,114
Cumulative Timesteps: 868,366,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,294.55217
Policy Entropy: 1.77782
Value Function Loss: 0.07137

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.55198
Value Function Update Magnitude: 0.64055

Collected Steps per Second: 22,395.99738
Overall Steps per Second: 10,507.76634

Timestep Collection Time: 2.23326
Timestep Consumption Time: 2.52665
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.75991

Cumulative Model Updates: 104,120
Cumulative Timesteps: 868,416,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 868416724...
Checkpoint 868416724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,423.79442
Policy Entropy: 1.77356
Value Function Loss: 0.07658

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.16550
Policy Update Magnitude: 0.52876
Value Function Update Magnitude: 0.65257

Collected Steps per Second: 21,855.59128
Overall Steps per Second: 10,649.71459

Timestep Collection Time: 2.28774
Timestep Consumption Time: 2.40722
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.69496

Cumulative Model Updates: 104,126
Cumulative Timesteps: 868,466,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,688.87550
Policy Entropy: 1.77904
Value Function Loss: 0.07701

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.16295
Policy Update Magnitude: 0.54798
Value Function Update Magnitude: 0.61908

Collected Steps per Second: 22,720.63402
Overall Steps per Second: 10,785.93878

Timestep Collection Time: 2.20196
Timestep Consumption Time: 2.43648
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.63845

Cumulative Model Updates: 104,132
Cumulative Timesteps: 868,516,754

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 868516754...
Checkpoint 868516754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,188.28827
Policy Entropy: 1.77102
Value Function Loss: 0.07320

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.17529
Policy Update Magnitude: 0.55420
Value Function Update Magnitude: 0.65473

Collected Steps per Second: 21,295.76347
Overall Steps per Second: 10,276.60026

Timestep Collection Time: 2.35014
Timestep Consumption Time: 2.51995
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.87009

Cumulative Model Updates: 104,138
Cumulative Timesteps: 868,566,802

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,309.78374
Policy Entropy: 1.78434
Value Function Loss: 0.06854

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.16734
Policy Update Magnitude: 0.54766
Value Function Update Magnitude: 0.69273

Collected Steps per Second: 22,505.15642
Overall Steps per Second: 10,546.17187

Timestep Collection Time: 2.22189
Timestep Consumption Time: 2.51955
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.74144

Cumulative Model Updates: 104,144
Cumulative Timesteps: 868,616,806

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 868616806...
Checkpoint 868616806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,225.48457
Policy Entropy: 1.79665
Value Function Loss: 0.06997

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.16904
Policy Update Magnitude: 0.49235
Value Function Update Magnitude: 0.60489

Collected Steps per Second: 21,605.46723
Overall Steps per Second: 10,501.37195

Timestep Collection Time: 2.31469
Timestep Consumption Time: 2.44754
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.76223

Cumulative Model Updates: 104,150
Cumulative Timesteps: 868,666,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,322.15345
Policy Entropy: 1.80323
Value Function Loss: 0.07464

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.16169
Policy Update Magnitude: 0.49232
Value Function Update Magnitude: 0.56807

Collected Steps per Second: 22,278.16108
Overall Steps per Second: 10,467.28418

Timestep Collection Time: 2.24543
Timestep Consumption Time: 2.53365
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.77908

Cumulative Model Updates: 104,156
Cumulative Timesteps: 868,716,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 868716840...
Checkpoint 868716840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,750.65237
Policy Entropy: 1.79457
Value Function Loss: 0.07603

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.15492
Policy Update Magnitude: 0.53505
Value Function Update Magnitude: 0.58065

Collected Steps per Second: 21,541.72902
Overall Steps per Second: 10,384.22418

Timestep Collection Time: 2.32247
Timestep Consumption Time: 2.49542
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.81789

Cumulative Model Updates: 104,162
Cumulative Timesteps: 868,766,870

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,304.92616
Policy Entropy: 1.79659
Value Function Loss: 0.07184

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.16617
Policy Update Magnitude: 0.52375
Value Function Update Magnitude: 0.60434

Collected Steps per Second: 22,543.73037
Overall Steps per Second: 10,703.40557

Timestep Collection Time: 2.21871
Timestep Consumption Time: 2.45438
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.67309

Cumulative Model Updates: 104,168
Cumulative Timesteps: 868,816,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 868816888...
Checkpoint 868816888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,499.22227
Policy Entropy: 1.79351
Value Function Loss: 0.07091

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.16790
Policy Update Magnitude: 0.50047
Value Function Update Magnitude: 0.60893

Collected Steps per Second: 21,751.87630
Overall Steps per Second: 10,546.98965

Timestep Collection Time: 2.29930
Timestep Consumption Time: 2.44272
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.74202

Cumulative Model Updates: 104,174
Cumulative Timesteps: 868,866,902

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,024.85271
Policy Entropy: 1.81236
Value Function Loss: 0.07317

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.15537
Policy Update Magnitude: 0.53052
Value Function Update Magnitude: 0.66284

Collected Steps per Second: 22,275.87721
Overall Steps per Second: 10,555.23387

Timestep Collection Time: 2.24575
Timestep Consumption Time: 2.49370
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.73945

Cumulative Model Updates: 104,180
Cumulative Timesteps: 868,916,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 868916928...
Checkpoint 868916928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,844.45711
Policy Entropy: 1.80183
Value Function Loss: 0.07471

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.15931
Policy Update Magnitude: 0.57466
Value Function Update Magnitude: 0.70804

Collected Steps per Second: 21,155.25651
Overall Steps per Second: 10,249.93017

Timestep Collection Time: 2.36424
Timestep Consumption Time: 2.51541
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.87964

Cumulative Model Updates: 104,186
Cumulative Timesteps: 868,966,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,916.54524
Policy Entropy: 1.80782
Value Function Loss: 0.07943

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.15677
Policy Update Magnitude: 0.59304
Value Function Update Magnitude: 0.70853

Collected Steps per Second: 22,447.53105
Overall Steps per Second: 10,488.60655

Timestep Collection Time: 2.22884
Timestep Consumption Time: 2.54129
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.77013

Cumulative Model Updates: 104,192
Cumulative Timesteps: 869,016,976

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 869016976...
Checkpoint 869016976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,987.78873
Policy Entropy: 1.78628
Value Function Loss: 0.07533

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.16290
Policy Update Magnitude: 0.58801
Value Function Update Magnitude: 0.64882

Collected Steps per Second: 21,619.65568
Overall Steps per Second: 10,480.43761

Timestep Collection Time: 2.31401
Timestep Consumption Time: 2.45946
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.77346

Cumulative Model Updates: 104,198
Cumulative Timesteps: 869,067,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,767.85104
Policy Entropy: 1.79349
Value Function Loss: 0.07599

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.16831
Policy Update Magnitude: 0.51960
Value Function Update Magnitude: 0.55921

Collected Steps per Second: 22,548.71131
Overall Steps per Second: 10,520.00887

Timestep Collection Time: 2.21804
Timestep Consumption Time: 2.53614
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.75418

Cumulative Model Updates: 104,204
Cumulative Timesteps: 869,117,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 869117018...
Checkpoint 869117018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,132.90495
Policy Entropy: 1.75972
Value Function Loss: 0.07497

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.15947
Policy Update Magnitude: 0.47656
Value Function Update Magnitude: 0.44874

Collected Steps per Second: 21,815.13407
Overall Steps per Second: 10,551.11674

Timestep Collection Time: 2.29391
Timestep Consumption Time: 2.44890
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.74282

Cumulative Model Updates: 104,210
Cumulative Timesteps: 869,167,060

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,299.65651
Policy Entropy: 1.77180
Value Function Loss: 0.07542

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.52890
Value Function Update Magnitude: 0.57958

Collected Steps per Second: 22,337.13673
Overall Steps per Second: 10,512.96950

Timestep Collection Time: 2.23851
Timestep Consumption Time: 2.51771
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.75622

Cumulative Model Updates: 104,216
Cumulative Timesteps: 869,217,062

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 869217062...
Checkpoint 869217062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,226.96532
Policy Entropy: 1.75638
Value Function Loss: 0.07632

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.59090
Value Function Update Magnitude: 0.60458

Collected Steps per Second: 20,005.91713
Overall Steps per Second: 10,114.97747

Timestep Collection Time: 2.49986
Timestep Consumption Time: 2.44449
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.94435

Cumulative Model Updates: 104,222
Cumulative Timesteps: 869,267,074

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,968.73779
Policy Entropy: 1.77689
Value Function Loss: 0.07484

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14074
Policy Update Magnitude: 0.59726
Value Function Update Magnitude: 0.58192

Collected Steps per Second: 22,387.20481
Overall Steps per Second: 10,561.60473

Timestep Collection Time: 2.23387
Timestep Consumption Time: 2.50121
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.73508

Cumulative Model Updates: 104,228
Cumulative Timesteps: 869,317,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 869317084...
Checkpoint 869317084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,440.88945
Policy Entropy: 1.78515
Value Function Loss: 0.06990

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.57803
Value Function Update Magnitude: 0.58126

Collected Steps per Second: 21,630.56131
Overall Steps per Second: 10,370.63158

Timestep Collection Time: 2.31219
Timestep Consumption Time: 2.51047
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.82266

Cumulative Model Updates: 104,234
Cumulative Timesteps: 869,367,098

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,280.18668
Policy Entropy: 1.79153
Value Function Loss: 0.06506

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.57110
Value Function Update Magnitude: 0.59961

Collected Steps per Second: 22,464.25856
Overall Steps per Second: 10,708.32018

Timestep Collection Time: 2.22647
Timestep Consumption Time: 2.44429
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.67076

Cumulative Model Updates: 104,240
Cumulative Timesteps: 869,417,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 869417114...
Checkpoint 869417114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,477.01944
Policy Entropy: 1.77648
Value Function Loss: 0.06658

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.14018
Policy Update Magnitude: 0.55455
Value Function Update Magnitude: 0.58263

Collected Steps per Second: 21,503.44674
Overall Steps per Second: 10,313.70843

Timestep Collection Time: 2.32595
Timestep Consumption Time: 2.52352
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.84947

Cumulative Model Updates: 104,246
Cumulative Timesteps: 869,467,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,752.84350
Policy Entropy: 1.78386
Value Function Loss: 0.06776

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.15908
Policy Update Magnitude: 0.49863
Value Function Update Magnitude: 0.63188

Collected Steps per Second: 22,703.89539
Overall Steps per Second: 10,747.70405

Timestep Collection Time: 2.20279
Timestep Consumption Time: 2.45048
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.65327

Cumulative Model Updates: 104,252
Cumulative Timesteps: 869,517,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 869517142...
Checkpoint 869517142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,469.25323
Policy Entropy: 1.78719
Value Function Loss: 0.06696

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14042
Policy Update Magnitude: 0.50179
Value Function Update Magnitude: 0.59519

Collected Steps per Second: 21,386.73414
Overall Steps per Second: 10,299.27240

Timestep Collection Time: 2.33930
Timestep Consumption Time: 2.51832
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.85762

Cumulative Model Updates: 104,258
Cumulative Timesteps: 869,567,172

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,733.89443
Policy Entropy: 1.78319
Value Function Loss: 0.06681

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13420
Policy Update Magnitude: 0.57702
Value Function Update Magnitude: 0.60039

Collected Steps per Second: 22,544.91128
Overall Steps per Second: 10,790.60867

Timestep Collection Time: 2.21797
Timestep Consumption Time: 2.41606
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.63403

Cumulative Model Updates: 104,264
Cumulative Timesteps: 869,617,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 869617176...
Checkpoint 869617176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,101.36747
Policy Entropy: 1.77205
Value Function Loss: 0.06643

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.59612
Value Function Update Magnitude: 0.55905

Collected Steps per Second: 21,226.98926
Overall Steps per Second: 10,232.01272

Timestep Collection Time: 2.35577
Timestep Consumption Time: 2.53144
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.88721

Cumulative Model Updates: 104,270
Cumulative Timesteps: 869,667,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,713.92513
Policy Entropy: 1.76466
Value Function Loss: 0.06745

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.13989
Policy Update Magnitude: 0.59652
Value Function Update Magnitude: 0.61640

Collected Steps per Second: 22,750.69214
Overall Steps per Second: 10,665.91668

Timestep Collection Time: 2.19835
Timestep Consumption Time: 2.49079
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.68914

Cumulative Model Updates: 104,276
Cumulative Timesteps: 869,717,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 869717196...
Checkpoint 869717196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,007.59482
Policy Entropy: 1.76884
Value Function Loss: 0.07135

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.59723
Value Function Update Magnitude: 0.67660

Collected Steps per Second: 21,377.18404
Overall Steps per Second: 10,436.30823

Timestep Collection Time: 2.33894
Timestep Consumption Time: 2.45202
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.79097

Cumulative Model Updates: 104,282
Cumulative Timesteps: 869,767,196

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,540.04040
Policy Entropy: 1.77755
Value Function Loss: 0.07059

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.60033
Value Function Update Magnitude: 0.63793

Collected Steps per Second: 22,439.18771
Overall Steps per Second: 10,523.89179

Timestep Collection Time: 2.22869
Timestep Consumption Time: 2.52335
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.75204

Cumulative Model Updates: 104,288
Cumulative Timesteps: 869,817,206

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 869817206...
Checkpoint 869817206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,572.02112
Policy Entropy: 1.77140
Value Function Loss: 0.07415

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.59485
Value Function Update Magnitude: 0.70120

Collected Steps per Second: 21,641.12874
Overall Steps per Second: 10,499.72612

Timestep Collection Time: 2.31079
Timestep Consumption Time: 2.45201
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.76279

Cumulative Model Updates: 104,294
Cumulative Timesteps: 869,867,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,910.12335
Policy Entropy: 1.77213
Value Function Loss: 0.07720

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.14372
Policy Update Magnitude: 0.60214
Value Function Update Magnitude: 0.67900

Collected Steps per Second: 22,598.57492
Overall Steps per Second: 10,550.97803

Timestep Collection Time: 2.21288
Timestep Consumption Time: 2.52677
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.73966

Cumulative Model Updates: 104,300
Cumulative Timesteps: 869,917,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 869917222...
Checkpoint 869917222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,074.98967
Policy Entropy: 1.77632
Value Function Loss: 0.07512

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.16862
Policy Update Magnitude: 0.57567
Value Function Update Magnitude: 0.62767

Collected Steps per Second: 21,034.11021
Overall Steps per Second: 10,197.38849

Timestep Collection Time: 2.37757
Timestep Consumption Time: 2.52663
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.90420

Cumulative Model Updates: 104,306
Cumulative Timesteps: 869,967,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,402.66807
Policy Entropy: 1.78043
Value Function Loss: 0.07501

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.16449
Policy Update Magnitude: 0.51247
Value Function Update Magnitude: 0.60372

Collected Steps per Second: 22,423.27386
Overall Steps per Second: 10,560.53817

Timestep Collection Time: 2.23036
Timestep Consumption Time: 2.50538
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.73574

Cumulative Model Updates: 104,312
Cumulative Timesteps: 870,017,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 870017244...
Checkpoint 870017244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,770.50329
Policy Entropy: 1.78651
Value Function Loss: 0.07134

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.14923
Policy Update Magnitude: 0.51888
Value Function Update Magnitude: 0.58860

Collected Steps per Second: 21,759.11586
Overall Steps per Second: 10,446.26236

Timestep Collection Time: 2.29798
Timestep Consumption Time: 2.48861
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.78659

Cumulative Model Updates: 104,318
Cumulative Timesteps: 870,067,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,109.77749
Policy Entropy: 1.80416
Value Function Loss: 0.07050

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.16401
Policy Update Magnitude: 0.50808
Value Function Update Magnitude: 0.58760

Collected Steps per Second: 22,495.67329
Overall Steps per Second: 10,530.00964

Timestep Collection Time: 2.22363
Timestep Consumption Time: 2.52680
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.75042

Cumulative Model Updates: 104,324
Cumulative Timesteps: 870,117,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 870117268...
Checkpoint 870117268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,558.10125
Policy Entropy: 1.79720
Value Function Loss: 0.07039

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.15890
Policy Update Magnitude: 0.52878
Value Function Update Magnitude: 0.56864

Collected Steps per Second: 21,300.69050
Overall Steps per Second: 10,287.39164

Timestep Collection Time: 2.34800
Timestep Consumption Time: 2.51368
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.86168

Cumulative Model Updates: 104,330
Cumulative Timesteps: 870,167,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,976.37303
Policy Entropy: 1.79378
Value Function Loss: 0.07218

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.15879
Policy Update Magnitude: 0.57065
Value Function Update Magnitude: 0.56523

Collected Steps per Second: 21,990.89270
Overall Steps per Second: 10,421.93722

Timestep Collection Time: 2.27503
Timestep Consumption Time: 2.52542
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.80045

Cumulative Model Updates: 104,336
Cumulative Timesteps: 870,217,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 870217312...
Checkpoint 870217312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,986.19236
Policy Entropy: 1.78318
Value Function Loss: 0.07495

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.16474
Policy Update Magnitude: 0.57448
Value Function Update Magnitude: 0.49141

Collected Steps per Second: 21,729.54564
Overall Steps per Second: 10,496.80599

Timestep Collection Time: 2.30120
Timestep Consumption Time: 2.46254
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.76373

Cumulative Model Updates: 104,342
Cumulative Timesteps: 870,267,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,968.24242
Policy Entropy: 1.79047
Value Function Loss: 0.06997

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14629
Policy Update Magnitude: 0.57229
Value Function Update Magnitude: 0.47794

Collected Steps per Second: 22,384.63466
Overall Steps per Second: 10,494.29489

Timestep Collection Time: 2.23376
Timestep Consumption Time: 2.53092
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.76468

Cumulative Model Updates: 104,348
Cumulative Timesteps: 870,317,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 870317318...
Checkpoint 870317318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,215.35204
Policy Entropy: 1.77945
Value Function Loss: 0.06774

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.58286
Value Function Update Magnitude: 0.59428

Collected Steps per Second: 21,820.99433
Overall Steps per Second: 10,546.22620

Timestep Collection Time: 2.29339
Timestep Consumption Time: 2.45182
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.74520

Cumulative Model Updates: 104,354
Cumulative Timesteps: 870,367,362

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,776.99883
Policy Entropy: 1.77761
Value Function Loss: 0.06767

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.58695
Value Function Update Magnitude: 0.67251

Collected Steps per Second: 22,675.53026
Overall Steps per Second: 10,590.11106

Timestep Collection Time: 2.20502
Timestep Consumption Time: 2.51637
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.72139

Cumulative Model Updates: 104,360
Cumulative Timesteps: 870,417,362

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 870417362...
Checkpoint 870417362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,922.34887
Policy Entropy: 1.77793
Value Function Loss: 0.07050

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14494
Policy Update Magnitude: 0.59470
Value Function Update Magnitude: 0.73172

Collected Steps per Second: 22,217.22762
Overall Steps per Second: 10,537.12770

Timestep Collection Time: 2.25177
Timestep Consumption Time: 2.49602
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.74778

Cumulative Model Updates: 104,366
Cumulative Timesteps: 870,467,390

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,210.28136
Policy Entropy: 1.79540
Value Function Loss: 0.06779

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14477
Policy Update Magnitude: 0.58978
Value Function Update Magnitude: 0.71732

Collected Steps per Second: 22,210.09497
Overall Steps per Second: 10,506.04737

Timestep Collection Time: 2.25168
Timestep Consumption Time: 2.50844
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.76012

Cumulative Model Updates: 104,372
Cumulative Timesteps: 870,517,400

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 870517400...
Checkpoint 870517400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,534.27224
Policy Entropy: 1.79700
Value Function Loss: 0.06617

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.58185
Value Function Update Magnitude: 0.68316

Collected Steps per Second: 22,251.60998
Overall Steps per Second: 10,630.63214

Timestep Collection Time: 2.24712
Timestep Consumption Time: 2.45646
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.70358

Cumulative Model Updates: 104,378
Cumulative Timesteps: 870,567,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,908.56199
Policy Entropy: 1.80344
Value Function Loss: 0.06572

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.14018
Policy Update Magnitude: 0.57699
Value Function Update Magnitude: 0.68996

Collected Steps per Second: 22,472.85806
Overall Steps per Second: 10,529.65574

Timestep Collection Time: 2.22597
Timestep Consumption Time: 2.52480
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.75077

Cumulative Model Updates: 104,384
Cumulative Timesteps: 870,617,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 870617426...
Checkpoint 870617426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,057.24282
Policy Entropy: 1.79729
Value Function Loss: 0.06481

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13543
Policy Update Magnitude: 0.57128
Value Function Update Magnitude: 0.68164

Collected Steps per Second: 21,685.64348
Overall Steps per Second: 10,505.72185

Timestep Collection Time: 2.30678
Timestep Consumption Time: 2.45482
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.76160

Cumulative Model Updates: 104,390
Cumulative Timesteps: 870,667,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,825.90514
Policy Entropy: 1.79886
Value Function Loss: 0.06768

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.56215
Value Function Update Magnitude: 0.66659

Collected Steps per Second: 22,180.45148
Overall Steps per Second: 10,547.10920

Timestep Collection Time: 2.25469
Timestep Consumption Time: 2.48690
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.74158

Cumulative Model Updates: 104,396
Cumulative Timesteps: 870,717,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 870717460...
Checkpoint 870717460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,285.57771
Policy Entropy: 1.77966
Value Function Loss: 0.06582

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.15461
Policy Update Magnitude: 0.51595
Value Function Update Magnitude: 0.65661

Collected Steps per Second: 21,609.73323
Overall Steps per Second: 10,530.37275

Timestep Collection Time: 2.31377
Timestep Consumption Time: 2.43440
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.74817

Cumulative Model Updates: 104,402
Cumulative Timesteps: 870,767,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,990.50735
Policy Entropy: 1.76970
Value Function Loss: 0.06458

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.15215
Policy Update Magnitude: 0.46586
Value Function Update Magnitude: 0.62518

Collected Steps per Second: 21,968.16162
Overall Steps per Second: 10,557.11621

Timestep Collection Time: 2.27730
Timestep Consumption Time: 2.46150
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.73879

Cumulative Model Updates: 104,408
Cumulative Timesteps: 870,817,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 870817488...
Checkpoint 870817488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,522.82937
Policy Entropy: 1.75917
Value Function Loss: 0.06183

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.50315
Value Function Update Magnitude: 0.61184

Collected Steps per Second: 21,480.75487
Overall Steps per Second: 10,312.46088

Timestep Collection Time: 2.32850
Timestep Consumption Time: 2.52175
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.85025

Cumulative Model Updates: 104,414
Cumulative Timesteps: 870,867,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,640.97387
Policy Entropy: 1.77714
Value Function Loss: 0.06574

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12840
Policy Update Magnitude: 0.55440
Value Function Update Magnitude: 0.57064

Collected Steps per Second: 22,415.35135
Overall Steps per Second: 10,453.33755

Timestep Collection Time: 2.23151
Timestep Consumption Time: 2.55357
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.78507

Cumulative Model Updates: 104,420
Cumulative Timesteps: 870,917,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 870917526...
Checkpoint 870917526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,838.94250
Policy Entropy: 1.78721
Value Function Loss: 0.06485

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.56367
Value Function Update Magnitude: 0.63273

Collected Steps per Second: 22,314.78693
Overall Steps per Second: 10,494.67974

Timestep Collection Time: 2.24067
Timestep Consumption Time: 2.52365
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.76432

Cumulative Model Updates: 104,426
Cumulative Timesteps: 870,967,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,600.04191
Policy Entropy: 1.80180
Value Function Loss: 0.07011

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13227
Policy Update Magnitude: 0.57916
Value Function Update Magnitude: 0.67469

Collected Steps per Second: 22,312.04782
Overall Steps per Second: 10,467.49518

Timestep Collection Time: 2.24220
Timestep Consumption Time: 2.53717
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.77937

Cumulative Model Updates: 104,432
Cumulative Timesteps: 871,017,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 871017554...
Checkpoint 871017554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,579.61526
Policy Entropy: 1.81323
Value Function Loss: 0.06993

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.57709
Value Function Update Magnitude: 0.70235

Collected Steps per Second: 22,382.96249
Overall Steps per Second: 10,642.82411

Timestep Collection Time: 2.23447
Timestep Consumption Time: 2.46485
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.69932

Cumulative Model Updates: 104,438
Cumulative Timesteps: 871,067,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,508.47689
Policy Entropy: 1.81334
Value Function Loss: 0.06683

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.58247
Value Function Update Magnitude: 0.70006

Collected Steps per Second: 22,462.84496
Overall Steps per Second: 10,555.46644

Timestep Collection Time: 2.22732
Timestep Consumption Time: 2.51259
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.73991

Cumulative Model Updates: 104,444
Cumulative Timesteps: 871,117,600

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 871117600...
Checkpoint 871117600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,528.99280
Policy Entropy: 1.80784
Value Function Loss: 0.06393

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.56381
Value Function Update Magnitude: 0.67407

Collected Steps per Second: 21,021.83648
Overall Steps per Second: 10,203.66205

Timestep Collection Time: 2.37857
Timestep Consumption Time: 2.52182
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.90040

Cumulative Model Updates: 104,450
Cumulative Timesteps: 871,167,602

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,380.01212
Policy Entropy: 1.78279
Value Function Loss: 0.05692

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.54529
Value Function Update Magnitude: 0.66704

Collected Steps per Second: 21,823.92205
Overall Steps per Second: 10,373.99589

Timestep Collection Time: 2.29171
Timestep Consumption Time: 2.52939
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.82109

Cumulative Model Updates: 104,456
Cumulative Timesteps: 871,217,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 871217616...
Checkpoint 871217616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,855.61221
Policy Entropy: 1.76937
Value Function Loss: 0.06279

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.55274
Value Function Update Magnitude: 0.64175

Collected Steps per Second: 21,441.04555
Overall Steps per Second: 10,294.25916

Timestep Collection Time: 2.33300
Timestep Consumption Time: 2.52621
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.85921

Cumulative Model Updates: 104,462
Cumulative Timesteps: 871,267,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,705.32093
Policy Entropy: 1.76612
Value Function Loss: 0.06532

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.56897
Value Function Update Magnitude: 0.66705

Collected Steps per Second: 22,245.64498
Overall Steps per Second: 10,532.99986

Timestep Collection Time: 2.24862
Timestep Consumption Time: 2.50045
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.74907

Cumulative Model Updates: 104,468
Cumulative Timesteps: 871,317,660

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 871317660...
Checkpoint 871317660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,841.55036
Policy Entropy: 1.76611
Value Function Loss: 0.06356

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.56348
Value Function Update Magnitude: 0.67249

Collected Steps per Second: 22,383.96727
Overall Steps per Second: 10,488.41988

Timestep Collection Time: 2.23383
Timestep Consumption Time: 2.53352
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.76735

Cumulative Model Updates: 104,474
Cumulative Timesteps: 871,367,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,416.35100
Policy Entropy: 1.77423
Value Function Loss: 0.06287

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.56451
Value Function Update Magnitude: 0.65285

Collected Steps per Second: 22,210.55048
Overall Steps per Second: 10,447.21454

Timestep Collection Time: 2.25235
Timestep Consumption Time: 2.53610
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.78845

Cumulative Model Updates: 104,480
Cumulative Timesteps: 871,417,688

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 871417688...
Checkpoint 871417688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,687.09164
Policy Entropy: 1.77952
Value Function Loss: 0.06286

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.14282
Policy Update Magnitude: 0.56358
Value Function Update Magnitude: 0.60836

Collected Steps per Second: 21,810.71971
Overall Steps per Second: 10,517.30346

Timestep Collection Time: 2.29318
Timestep Consumption Time: 2.46241
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.75559

Cumulative Model Updates: 104,486
Cumulative Timesteps: 871,467,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,910.78375
Policy Entropy: 1.78214
Value Function Loss: 0.06182

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.56089
Value Function Update Magnitude: 0.58733

Collected Steps per Second: 22,516.74936
Overall Steps per Second: 10,549.25850

Timestep Collection Time: 2.22137
Timestep Consumption Time: 2.52001
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.74138

Cumulative Model Updates: 104,492
Cumulative Timesteps: 871,517,722

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 871517722...
Checkpoint 871517722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,094.71933
Policy Entropy: 1.77245
Value Function Loss: 0.06066

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.14186
Policy Update Magnitude: 0.55839
Value Function Update Magnitude: 0.59597

Collected Steps per Second: 21,944.37330
Overall Steps per Second: 10,601.58683

Timestep Collection Time: 2.27849
Timestep Consumption Time: 2.43779
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.71628

Cumulative Model Updates: 104,498
Cumulative Timesteps: 871,567,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,493.50194
Policy Entropy: 1.77202
Value Function Loss: 0.06130

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.14355
Policy Update Magnitude: 0.55484
Value Function Update Magnitude: 0.59743

Collected Steps per Second: 22,446.98435
Overall Steps per Second: 10,560.75354

Timestep Collection Time: 2.22765
Timestep Consumption Time: 2.50724
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.73489

Cumulative Model Updates: 104,504
Cumulative Timesteps: 871,617,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 871617726...
Checkpoint 871617726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,469.86796
Policy Entropy: 1.77276
Value Function Loss: 0.06434

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.16986
Policy Update Magnitude: 0.48408
Value Function Update Magnitude: 0.60478

Collected Steps per Second: 21,773.17325
Overall Steps per Second: 10,564.43278

Timestep Collection Time: 2.29787
Timestep Consumption Time: 2.43802
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.73589

Cumulative Model Updates: 104,510
Cumulative Timesteps: 871,667,758

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,688.94971
Policy Entropy: 1.77431
Value Function Loss: 0.06553

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.16192
Policy Update Magnitude: 0.48259
Value Function Update Magnitude: 0.55043

Collected Steps per Second: 21,726.63584
Overall Steps per Second: 10,571.35211

Timestep Collection Time: 2.30169
Timestep Consumption Time: 2.42883
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.73052

Cumulative Model Updates: 104,516
Cumulative Timesteps: 871,717,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 871717766...
Checkpoint 871717766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,973.55058
Policy Entropy: 1.76842
Value Function Loss: 0.06821

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.15465
Policy Update Magnitude: 0.49071
Value Function Update Magnitude: 0.45194

Collected Steps per Second: 21,282.06107
Overall Steps per Second: 10,333.26931

Timestep Collection Time: 2.35099
Timestep Consumption Time: 2.49104
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.84203

Cumulative Model Updates: 104,522
Cumulative Timesteps: 871,767,800

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,583.96048
Policy Entropy: 1.77520
Value Function Loss: 0.07074

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.54023
Value Function Update Magnitude: 0.39040

Collected Steps per Second: 22,268.28871
Overall Steps per Second: 10,668.31426

Timestep Collection Time: 2.24588
Timestep Consumption Time: 2.44202
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.68790

Cumulative Model Updates: 104,528
Cumulative Timesteps: 871,817,812

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 871817812...
Checkpoint 871817812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,261.50383
Policy Entropy: 1.78225
Value Function Loss: 0.07625

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.57114
Value Function Update Magnitude: 0.38171

Collected Steps per Second: 21,465.04347
Overall Steps per Second: 10,282.13115

Timestep Collection Time: 2.33151
Timestep Consumption Time: 2.53577
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.86728

Cumulative Model Updates: 104,534
Cumulative Timesteps: 871,867,858

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,611.04234
Policy Entropy: 1.78611
Value Function Loss: 0.07857

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.57947
Value Function Update Magnitude: 0.34703

Collected Steps per Second: 22,368.61812
Overall Steps per Second: 10,454.14977

Timestep Collection Time: 2.23670
Timestep Consumption Time: 2.54915
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.78585

Cumulative Model Updates: 104,540
Cumulative Timesteps: 871,917,890

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 871917890...
Checkpoint 871917890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,713.42884
Policy Entropy: 1.78575
Value Function Loss: 0.07335

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.16589
Policy Update Magnitude: 0.54155
Value Function Update Magnitude: 0.45716

Collected Steps per Second: 21,096.04445
Overall Steps per Second: 10,558.96968

Timestep Collection Time: 2.37087
Timestep Consumption Time: 2.36595
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.73683

Cumulative Model Updates: 104,546
Cumulative Timesteps: 871,967,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,060.76832
Policy Entropy: 1.78256
Value Function Loss: 0.07012

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.16226
Policy Update Magnitude: 0.50273
Value Function Update Magnitude: 0.52684

Collected Steps per Second: 21,340.15727
Overall Steps per Second: 10,512.89838

Timestep Collection Time: 2.34469
Timestep Consumption Time: 2.41480
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.75949

Cumulative Model Updates: 104,552
Cumulative Timesteps: 872,017,942

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 872017942...
Checkpoint 872017942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,017.88836
Policy Entropy: 1.79507
Value Function Loss: 0.06600

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.15430
Policy Update Magnitude: 0.50737
Value Function Update Magnitude: 0.62326

Collected Steps per Second: 21,489.01946
Overall Steps per Second: 10,659.02613

Timestep Collection Time: 2.32686
Timestep Consumption Time: 2.36418
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.69105

Cumulative Model Updates: 104,558
Cumulative Timesteps: 872,067,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,582.33714
Policy Entropy: 1.79329
Value Function Loss: 0.06625

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.15684
Policy Update Magnitude: 0.50665
Value Function Update Magnitude: 0.67319

Collected Steps per Second: 21,766.45723
Overall Steps per Second: 10,606.89034

Timestep Collection Time: 2.29803
Timestep Consumption Time: 2.41777
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.71580

Cumulative Model Updates: 104,564
Cumulative Timesteps: 872,117,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 872117964...
Checkpoint 872117964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,693.89609
Policy Entropy: 1.78435
Value Function Loss: 0.06658

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.16974
Policy Update Magnitude: 0.51572
Value Function Update Magnitude: 0.65692

Collected Steps per Second: 21,193.82685
Overall Steps per Second: 10,485.05448

Timestep Collection Time: 2.36069
Timestep Consumption Time: 2.41106
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.77174

Cumulative Model Updates: 104,570
Cumulative Timesteps: 872,167,996

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,204.30068
Policy Entropy: 1.77569
Value Function Loss: 0.06492

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.17301
Policy Update Magnitude: 0.49929
Value Function Update Magnitude: 0.65550

Collected Steps per Second: 22,389.14833
Overall Steps per Second: 10,615.49626

Timestep Collection Time: 2.23340
Timestep Consumption Time: 2.47707
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.71047

Cumulative Model Updates: 104,576
Cumulative Timesteps: 872,218,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 872218000...
Checkpoint 872218000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,719.87838
Policy Entropy: 1.78081
Value Function Loss: 0.06432

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.16393
Policy Update Magnitude: 0.49574
Value Function Update Magnitude: 0.65001

Collected Steps per Second: 21,213.07377
Overall Steps per Second: 10,495.07514

Timestep Collection Time: 2.35760
Timestep Consumption Time: 2.40768
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.76528

Cumulative Model Updates: 104,582
Cumulative Timesteps: 872,268,012

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,222.19294
Policy Entropy: 1.78589
Value Function Loss: 0.06655

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.53815
Value Function Update Magnitude: 0.64235

Collected Steps per Second: 22,142.45746
Overall Steps per Second: 10,557.47688

Timestep Collection Time: 2.25820
Timestep Consumption Time: 2.47797
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.73617

Cumulative Model Updates: 104,588
Cumulative Timesteps: 872,318,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 872318014...
Checkpoint 872318014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,578.40409
Policy Entropy: 1.77856
Value Function Loss: 0.06547

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.16502
Policy Update Magnitude: 0.54482
Value Function Update Magnitude: 0.59899

Collected Steps per Second: 21,641.31506
Overall Steps per Second: 10,536.77251

Timestep Collection Time: 2.31132
Timestep Consumption Time: 2.43586
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.74718

Cumulative Model Updates: 104,594
Cumulative Timesteps: 872,368,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,296.72568
Policy Entropy: 1.77684
Value Function Loss: 0.07067

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.16745
Policy Update Magnitude: 0.51707
Value Function Update Magnitude: 0.58562

Collected Steps per Second: 22,058.68897
Overall Steps per Second: 10,439.18318

Timestep Collection Time: 2.26777
Timestep Consumption Time: 2.52418
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.79195

Cumulative Model Updates: 104,600
Cumulative Timesteps: 872,418,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 872418058...
Checkpoint 872418058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,413.16145
Policy Entropy: 1.78177
Value Function Loss: 0.07347

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.15990
Policy Update Magnitude: 0.56389
Value Function Update Magnitude: 0.57077

Collected Steps per Second: 21,475.10860
Overall Steps per Second: 10,310.18213

Timestep Collection Time: 2.32967
Timestep Consumption Time: 2.52281
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.85248

Cumulative Model Updates: 104,606
Cumulative Timesteps: 872,468,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,370.90934
Policy Entropy: 1.77850
Value Function Loss: 0.07622

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.15325
Policy Update Magnitude: 0.58872
Value Function Update Magnitude: 0.54478

Collected Steps per Second: 22,626.64542
Overall Steps per Second: 10,658.82016

Timestep Collection Time: 2.21023
Timestep Consumption Time: 2.48166
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.69189

Cumulative Model Updates: 104,612
Cumulative Timesteps: 872,518,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 872518098...
Checkpoint 872518098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,355.11084
Policy Entropy: 1.76699
Value Function Loss: 0.07357

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.59475
Value Function Update Magnitude: 0.56544

Collected Steps per Second: 22,313.98167
Overall Steps per Second: 10,641.22440

Timestep Collection Time: 2.24146
Timestep Consumption Time: 2.45875
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.70021

Cumulative Model Updates: 104,618
Cumulative Timesteps: 872,568,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,093.42299
Policy Entropy: 1.76671
Value Function Loss: 0.06833

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.15011
Policy Update Magnitude: 0.59207
Value Function Update Magnitude: 0.62915

Collected Steps per Second: 22,164.56583
Overall Steps per Second: 10,522.60342

Timestep Collection Time: 2.25639
Timestep Consumption Time: 2.49642
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.75282

Cumulative Model Updates: 104,624
Cumulative Timesteps: 872,618,126

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 872618126...
Checkpoint 872618126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,812.13831
Policy Entropy: 1.76881
Value Function Loss: 0.06968

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.59075
Value Function Update Magnitude: 0.70380

Collected Steps per Second: 21,951.29960
Overall Steps per Second: 10,641.12196

Timestep Collection Time: 2.27804
Timestep Consumption Time: 2.42127
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.69932

Cumulative Model Updates: 104,630
Cumulative Timesteps: 872,668,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,344.71666
Policy Entropy: 1.77856
Value Function Loss: 0.06864

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.58479
Value Function Update Magnitude: 0.71822

Collected Steps per Second: 22,534.05771
Overall Steps per Second: 10,583.21131

Timestep Collection Time: 2.22019
Timestep Consumption Time: 2.50710
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.72730

Cumulative Model Updates: 104,636
Cumulative Timesteps: 872,718,162

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 872718162...
Checkpoint 872718162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,327.98122
Policy Entropy: 1.76819
Value Function Loss: 0.06911

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.58271
Value Function Update Magnitude: 0.65323

Collected Steps per Second: 21,801.29660
Overall Steps per Second: 10,554.78354

Timestep Collection Time: 2.29399
Timestep Consumption Time: 2.44433
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.73833

Cumulative Model Updates: 104,642
Cumulative Timesteps: 872,768,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,678.52627
Policy Entropy: 1.76273
Value Function Loss: 0.06602

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.58050
Value Function Update Magnitude: 0.61234

Collected Steps per Second: 22,163.79240
Overall Steps per Second: 10,465.27220

Timestep Collection Time: 2.25710
Timestep Consumption Time: 2.52309
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.78019

Cumulative Model Updates: 104,648
Cumulative Timesteps: 872,818,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 872818200...
Checkpoint 872818200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,209.56460
Policy Entropy: 1.76045
Value Function Loss: 0.06793

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.58209
Value Function Update Magnitude: 0.54339

Collected Steps per Second: 21,383.67431
Overall Steps per Second: 10,342.39973

Timestep Collection Time: 2.33889
Timestep Consumption Time: 2.49693
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.83582

Cumulative Model Updates: 104,654
Cumulative Timesteps: 872,868,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,383.42582
Policy Entropy: 1.77377
Value Function Loss: 0.07128

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.59290
Value Function Update Magnitude: 0.49992

Collected Steps per Second: 22,240.69437
Overall Steps per Second: 10,628.70381

Timestep Collection Time: 2.24867
Timestep Consumption Time: 2.45670
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.70537

Cumulative Model Updates: 104,660
Cumulative Timesteps: 872,918,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 872918226...
Checkpoint 872918226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,487.81264
Policy Entropy: 1.78176
Value Function Loss: 0.07334

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.16434
Policy Update Magnitude: 0.56194
Value Function Update Magnitude: 0.58515

Collected Steps per Second: 21,602.36356
Overall Steps per Second: 10,343.25365

Timestep Collection Time: 2.31586
Timestep Consumption Time: 2.52092
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.83678

Cumulative Model Updates: 104,666
Cumulative Timesteps: 872,968,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,016.72076
Policy Entropy: 1.78698
Value Function Loss: 0.07105

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.16071
Policy Update Magnitude: 0.49600
Value Function Update Magnitude: 0.61283

Collected Steps per Second: 22,411.68843
Overall Steps per Second: 10,421.59134

Timestep Collection Time: 2.23116
Timestep Consumption Time: 2.56696
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.79812

Cumulative Model Updates: 104,672
Cumulative Timesteps: 873,018,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 873018258...
Checkpoint 873018258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,293.91813
Policy Entropy: 1.77223
Value Function Loss: 0.06794

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.16238
Policy Update Magnitude: 0.50737
Value Function Update Magnitude: 0.66169

Collected Steps per Second: 22,180.35624
Overall Steps per Second: 10,657.96972

Timestep Collection Time: 2.25524
Timestep Consumption Time: 2.43815
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.69339

Cumulative Model Updates: 104,678
Cumulative Timesteps: 873,068,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,520.34705
Policy Entropy: 1.79100
Value Function Loss: 0.06953

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.50761
Value Function Update Magnitude: 0.67514

Collected Steps per Second: 22,375.67760
Overall Steps per Second: 10,769.52662

Timestep Collection Time: 2.23457
Timestep Consumption Time: 2.40816
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.64273

Cumulative Model Updates: 104,684
Cumulative Timesteps: 873,118,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 873118280...
Checkpoint 873118280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,361.31045
Policy Entropy: 1.77847
Value Function Loss: 0.07181

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.15661
Policy Update Magnitude: 0.53209
Value Function Update Magnitude: 0.63953

Collected Steps per Second: 22,062.95121
Overall Steps per Second: 10,625.03621

Timestep Collection Time: 2.26751
Timestep Consumption Time: 2.44099
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.70850

Cumulative Model Updates: 104,690
Cumulative Timesteps: 873,168,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,686.51602
Policy Entropy: 1.78832
Value Function Loss: 0.07119

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.16461
Policy Update Magnitude: 0.54589
Value Function Update Magnitude: 0.68890

Collected Steps per Second: 22,296.22294
Overall Steps per Second: 10,560.27866

Timestep Collection Time: 2.24289
Timestep Consumption Time: 2.49259
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.73548

Cumulative Model Updates: 104,696
Cumulative Timesteps: 873,218,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 873218316...
Checkpoint 873218316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,946.76063
Policy Entropy: 1.75903
Value Function Loss: 0.06905

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.15503
Policy Update Magnitude: 0.58351
Value Function Update Magnitude: 0.68609

Collected Steps per Second: 21,447.02076
Overall Steps per Second: 10,339.30985

Timestep Collection Time: 2.33179
Timestep Consumption Time: 2.50509
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.83688

Cumulative Model Updates: 104,702
Cumulative Timesteps: 873,268,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,831.89436
Policy Entropy: 1.76346
Value Function Loss: 0.07203

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.14951
Policy Update Magnitude: 0.58894
Value Function Update Magnitude: 0.52731

Collected Steps per Second: 21,807.71590
Overall Steps per Second: 10,413.01308

Timestep Collection Time: 2.29295
Timestep Consumption Time: 2.50912
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.80207

Cumulative Model Updates: 104,708
Cumulative Timesteps: 873,318,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 873318330...
Checkpoint 873318330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,386.59945
Policy Entropy: 1.76686
Value Function Loss: 0.08225

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.59047
Value Function Update Magnitude: 0.41883

Collected Steps per Second: 21,758.74099
Overall Steps per Second: 10,517.73282

Timestep Collection Time: 2.30022
Timestep Consumption Time: 2.45841
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.75863

Cumulative Model Updates: 104,714
Cumulative Timesteps: 873,368,380

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,229.98233
Policy Entropy: 1.78554
Value Function Loss: 0.07699

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.15092
Policy Update Magnitude: 0.57837
Value Function Update Magnitude: 0.44387

Collected Steps per Second: 22,145.70765
Overall Steps per Second: 10,427.73699

Timestep Collection Time: 2.25804
Timestep Consumption Time: 2.53743
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.79548

Cumulative Model Updates: 104,720
Cumulative Timesteps: 873,418,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 873418386...
Checkpoint 873418386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,314.67122
Policy Entropy: 1.80329
Value Function Loss: 0.07796

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14895
Policy Update Magnitude: 0.56445
Value Function Update Magnitude: 0.49053

Collected Steps per Second: 21,702.69727
Overall Steps per Second: 10,378.03293

Timestep Collection Time: 2.30386
Timestep Consumption Time: 2.51401
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.81787

Cumulative Model Updates: 104,726
Cumulative Timesteps: 873,468,386

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,081.17917
Policy Entropy: 1.80946
Value Function Loss: 0.07232

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14983
Policy Update Magnitude: 0.57718
Value Function Update Magnitude: 0.55917

Collected Steps per Second: 22,574.02232
Overall Steps per Second: 10,671.44862

Timestep Collection Time: 2.21662
Timestep Consumption Time: 2.47234
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.68896

Cumulative Model Updates: 104,732
Cumulative Timesteps: 873,518,424

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 873518424...
Checkpoint 873518424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,594.75247
Policy Entropy: 1.81687
Value Function Loss: 0.07203

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.58708
Value Function Update Magnitude: 0.50322

Collected Steps per Second: 22,137.27420
Overall Steps per Second: 10,670.03002

Timestep Collection Time: 2.25945
Timestep Consumption Time: 2.42826
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.68771

Cumulative Model Updates: 104,738
Cumulative Timesteps: 873,568,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,284.59785
Policy Entropy: 1.81136
Value Function Loss: 0.06999

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.14511
Policy Update Magnitude: 0.59052
Value Function Update Magnitude: 0.62939

Collected Steps per Second: 22,295.83148
Overall Steps per Second: 10,542.08558

Timestep Collection Time: 2.24356
Timestep Consumption Time: 2.50142
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.74498

Cumulative Model Updates: 104,744
Cumulative Timesteps: 873,618,464

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 873618464...
Checkpoint 873618464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,625.82436
Policy Entropy: 1.80212
Value Function Loss: 0.06891

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.14813
Policy Update Magnitude: 0.58496
Value Function Update Magnitude: 0.66374

Collected Steps per Second: 21,954.77383
Overall Steps per Second: 10,562.06926

Timestep Collection Time: 2.27796
Timestep Consumption Time: 2.45710
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.73506

Cumulative Model Updates: 104,750
Cumulative Timesteps: 873,668,476

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,641.02203
Policy Entropy: 1.79520
Value Function Loss: 0.07017

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.14819
Policy Update Magnitude: 0.58108
Value Function Update Magnitude: 0.64596

Collected Steps per Second: 22,583.06019
Overall Steps per Second: 10,563.50030

Timestep Collection Time: 2.21502
Timestep Consumption Time: 2.52034
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.73536

Cumulative Model Updates: 104,756
Cumulative Timesteps: 873,718,498

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 873718498...
Checkpoint 873718498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,659.15628
Policy Entropy: 1.78868
Value Function Loss: 0.07033

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.58602
Value Function Update Magnitude: 0.59176

Collected Steps per Second: 22,139.51666
Overall Steps per Second: 10,564.85618

Timestep Collection Time: 2.25985
Timestep Consumption Time: 2.47585
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.73570

Cumulative Model Updates: 104,762
Cumulative Timesteps: 873,768,530

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,010.17354
Policy Entropy: 1.78233
Value Function Loss: 0.06677

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.58217
Value Function Update Magnitude: 0.63159

Collected Steps per Second: 22,104.05699
Overall Steps per Second: 10,483.20623

Timestep Collection Time: 2.26293
Timestep Consumption Time: 2.50851
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.77144

Cumulative Model Updates: 104,768
Cumulative Timesteps: 873,818,550

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 873818550...
Checkpoint 873818550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,820.51763
Policy Entropy: 1.78252
Value Function Loss: 0.06512

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14040
Policy Update Magnitude: 0.56884
Value Function Update Magnitude: 0.65358

Collected Steps per Second: 21,752.66640
Overall Steps per Second: 9,792.95719

Timestep Collection Time: 2.29903
Timestep Consumption Time: 2.80770
PPO Batch Consumption Time: 0.33944
Total Iteration Time: 5.10673

Cumulative Model Updates: 104,774
Cumulative Timesteps: 873,868,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,160.80951
Policy Entropy: 1.79562
Value Function Loss: 0.06777

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.14040
Policy Update Magnitude: 0.55219
Value Function Update Magnitude: 0.54775

Collected Steps per Second: 10,039.03711
Overall Steps per Second: 6,362.19217

Timestep Collection Time: 4.98195
Timestep Consumption Time: 2.87918
PPO Batch Consumption Time: 0.32649
Total Iteration Time: 7.86113

Cumulative Model Updates: 104,780
Cumulative Timesteps: 873,918,574

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 873918574...
Checkpoint 873918574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,602.85511
Policy Entropy: 1.79018
Value Function Loss: 0.07323

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.16659
Policy Update Magnitude: 0.50331
Value Function Update Magnitude: 0.45271

Collected Steps per Second: 16,184.89171
Overall Steps per Second: 8,846.14295

Timestep Collection Time: 3.09004
Timestep Consumption Time: 2.56350
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 5.65354

Cumulative Model Updates: 104,786
Cumulative Timesteps: 873,968,586

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,126.72269
Policy Entropy: 1.77906
Value Function Loss: 0.07625

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.15067
Policy Update Magnitude: 0.48151
Value Function Update Magnitude: 0.47781

Collected Steps per Second: 20,814.48321
Overall Steps per Second: 9,975.82806

Timestep Collection Time: 2.40438
Timestep Consumption Time: 2.61234
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 5.01673

Cumulative Model Updates: 104,792
Cumulative Timesteps: 874,018,632

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 874018632...
Checkpoint 874018632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,634.97176
Policy Entropy: 1.77116
Value Function Loss: 0.07680

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.15331
Policy Update Magnitude: 0.55596
Value Function Update Magnitude: 0.58883

Collected Steps per Second: 21,291.43827
Overall Steps per Second: 9,869.64119

Timestep Collection Time: 2.34949
Timestep Consumption Time: 2.71898
PPO Batch Consumption Time: 0.32561
Total Iteration Time: 5.06847

Cumulative Model Updates: 104,798
Cumulative Timesteps: 874,068,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,167.49239
Policy Entropy: 1.78106
Value Function Loss: 0.07339

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.17079
Policy Update Magnitude: 0.53209
Value Function Update Magnitude: 0.56283

Collected Steps per Second: 19,801.04838
Overall Steps per Second: 9,771.86431

Timestep Collection Time: 2.52673
Timestep Consumption Time: 2.59327
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 5.12001

Cumulative Model Updates: 104,804
Cumulative Timesteps: 874,118,688

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 874118688...
Checkpoint 874118688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,810.11602
Policy Entropy: 1.78437
Value Function Loss: 0.06853

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.15675
Policy Update Magnitude: 0.52661
Value Function Update Magnitude: 0.53170

Collected Steps per Second: 22,283.94880
Overall Steps per Second: 10,684.39064

Timestep Collection Time: 2.24431
Timestep Consumption Time: 2.43654
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.68085

Cumulative Model Updates: 104,810
Cumulative Timesteps: 874,168,700

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,288.63844
Policy Entropy: 1.77936
Value Function Loss: 0.06421

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.14511
Policy Update Magnitude: 0.55293
Value Function Update Magnitude: 0.58667

Collected Steps per Second: 22,725.70722
Overall Steps per Second: 10,589.94053

Timestep Collection Time: 2.20086
Timestep Consumption Time: 2.52212
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.72297

Cumulative Model Updates: 104,816
Cumulative Timesteps: 874,218,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 874218716...
Checkpoint 874218716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,092.45492
Policy Entropy: 1.76943
Value Function Loss: 0.06606

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13856
Policy Update Magnitude: 0.56640
Value Function Update Magnitude: 0.58082

Collected Steps per Second: 21,893.95058
Overall Steps per Second: 10,439.30950

Timestep Collection Time: 2.28492
Timestep Consumption Time: 2.50716
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.79208

Cumulative Model Updates: 104,822
Cumulative Timesteps: 874,268,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,159.91854
Policy Entropy: 1.78448
Value Function Loss: 0.06780

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.58019
Value Function Update Magnitude: 0.46552

Collected Steps per Second: 22,569.16086
Overall Steps per Second: 10,532.69475

Timestep Collection Time: 2.21621
Timestep Consumption Time: 2.53262
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.74883

Cumulative Model Updates: 104,828
Cumulative Timesteps: 874,318,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 874318760...
Checkpoint 874318760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,584.25440
Policy Entropy: 1.77840
Value Function Loss: 0.07214

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.14452
Policy Update Magnitude: 0.58686
Value Function Update Magnitude: 0.45884

Collected Steps per Second: 22,091.48675
Overall Steps per Second: 10,571.18810

Timestep Collection Time: 2.26359
Timestep Consumption Time: 2.46682
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.73040

Cumulative Model Updates: 104,834
Cumulative Timesteps: 874,368,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,817.23876
Policy Entropy: 1.78670
Value Function Loss: 0.07579

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.14705
Policy Update Magnitude: 0.59567
Value Function Update Magnitude: 0.52964

Collected Steps per Second: 22,517.36345
Overall Steps per Second: 10,583.83610

Timestep Collection Time: 2.22166
Timestep Consumption Time: 2.50498
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.72664

Cumulative Model Updates: 104,840
Cumulative Timesteps: 874,418,792

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 874418792...
Checkpoint 874418792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,302.53084
Policy Entropy: 1.77906
Value Function Loss: 0.08011

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.15014
Policy Update Magnitude: 0.60493
Value Function Update Magnitude: 0.55053

Collected Steps per Second: 21,829.87740
Overall Steps per Second: 10,492.51908

Timestep Collection Time: 2.29053
Timestep Consumption Time: 2.47496
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.76549

Cumulative Model Updates: 104,846
Cumulative Timesteps: 874,468,794

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,796.91451
Policy Entropy: 1.80398
Value Function Loss: 0.07903

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.16228
Policy Update Magnitude: 0.58052
Value Function Update Magnitude: 0.53205

Collected Steps per Second: 22,374.74058
Overall Steps per Second: 10,507.57610

Timestep Collection Time: 2.23520
Timestep Consumption Time: 2.52441
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.75961

Cumulative Model Updates: 104,852
Cumulative Timesteps: 874,518,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 874518806...
Checkpoint 874518806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,459.94101
Policy Entropy: 1.80152
Value Function Loss: 0.07538

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.17513
Policy Update Magnitude: 0.50507
Value Function Update Magnitude: 0.41878

Collected Steps per Second: 21,029.91870
Overall Steps per Second: 9,769.46481

Timestep Collection Time: 2.37890
Timestep Consumption Time: 2.74196
PPO Batch Consumption Time: 0.31758
Total Iteration Time: 5.12085

Cumulative Model Updates: 104,858
Cumulative Timesteps: 874,568,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,959.34894
Policy Entropy: 1.79992
Value Function Loss: 0.07650

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.17798
Policy Update Magnitude: 0.49435
Value Function Update Magnitude: 0.37900

Collected Steps per Second: 20,239.17666
Overall Steps per Second: 9,994.28758

Timestep Collection Time: 2.47085
Timestep Consumption Time: 2.53281
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 5.00366

Cumulative Model Updates: 104,864
Cumulative Timesteps: 874,618,842

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 874618842...
Checkpoint 874618842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,961.40576
Policy Entropy: 1.76974
Value Function Loss: 0.07790

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.18383
Policy Update Magnitude: 0.50521
Value Function Update Magnitude: 0.55966

Collected Steps per Second: 20,818.75011
Overall Steps per Second: 9,958.40668

Timestep Collection Time: 2.40216
Timestep Consumption Time: 2.61973
PPO Batch Consumption Time: 0.30484
Total Iteration Time: 5.02189

Cumulative Model Updates: 104,870
Cumulative Timesteps: 874,668,852

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,686.62015
Policy Entropy: 1.77366
Value Function Loss: 0.07881

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.17515
Policy Update Magnitude: 0.51255
Value Function Update Magnitude: 0.64459

Collected Steps per Second: 19,269.21708
Overall Steps per Second: 9,719.48689

Timestep Collection Time: 2.59512
Timestep Consumption Time: 2.54980
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 5.14492

Cumulative Model Updates: 104,876
Cumulative Timesteps: 874,718,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 874718858...
Checkpoint 874718858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,692.86900
Policy Entropy: 1.76378
Value Function Loss: 0.08077

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.18021
Policy Update Magnitude: 0.53029
Value Function Update Magnitude: 0.57741

Collected Steps per Second: 19,307.44951
Overall Steps per Second: 9,870.07906

Timestep Collection Time: 2.59206
Timestep Consumption Time: 2.47842
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 5.07048

Cumulative Model Updates: 104,882
Cumulative Timesteps: 874,768,904

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,587.67531
Policy Entropy: 1.77289
Value Function Loss: 0.08184

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.15536
Policy Update Magnitude: 0.57517
Value Function Update Magnitude: 0.48388

Collected Steps per Second: 18,189.11634
Overall Steps per Second: 9,343.00210

Timestep Collection Time: 2.74989
Timestep Consumption Time: 2.60364
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 5.35353

Cumulative Model Updates: 104,888
Cumulative Timesteps: 874,818,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 874818922...
Checkpoint 874818922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,967.07606
Policy Entropy: 1.78112
Value Function Loss: 0.08249

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.15262
Policy Update Magnitude: 0.60432
Value Function Update Magnitude: 0.54168

Collected Steps per Second: 21,647.94096
Overall Steps per Second: 10,329.37497

Timestep Collection Time: 2.31034
Timestep Consumption Time: 2.53158
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.84192

Cumulative Model Updates: 104,894
Cumulative Timesteps: 874,868,936

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,769.75515
Policy Entropy: 1.79302
Value Function Loss: 0.07258

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.14258
Policy Update Magnitude: 0.59818
Value Function Update Magnitude: 0.62120

Collected Steps per Second: 21,017.27370
Overall Steps per Second: 10,073.85337

Timestep Collection Time: 2.37976
Timestep Consumption Time: 2.58518
PPO Batch Consumption Time: 0.30111
Total Iteration Time: 4.96493

Cumulative Model Updates: 104,900
Cumulative Timesteps: 874,918,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 874918952...
Checkpoint 874918952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,315.63919
Policy Entropy: 1.78371
Value Function Loss: 0.07153

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.58883
Value Function Update Magnitude: 0.58165

Collected Steps per Second: 19,420.73508
Overall Steps per Second: 9,484.16084

Timestep Collection Time: 2.57601
Timestep Consumption Time: 2.69889
PPO Batch Consumption Time: 0.31794
Total Iteration Time: 5.27490

Cumulative Model Updates: 104,906
Cumulative Timesteps: 874,968,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,519.76960
Policy Entropy: 1.76954
Value Function Loss: 0.06596

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.57022
Value Function Update Magnitude: 0.63301

Collected Steps per Second: 20,674.02410
Overall Steps per Second: 9,933.87267

Timestep Collection Time: 2.41985
Timestep Consumption Time: 2.61625
PPO Batch Consumption Time: 0.30054
Total Iteration Time: 5.03610

Cumulative Model Updates: 104,912
Cumulative Timesteps: 875,019,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 875019008...
Checkpoint 875019008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,260.49811
Policy Entropy: 1.76099
Value Function Loss: 0.06997

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.16467
Policy Update Magnitude: 0.50270
Value Function Update Magnitude: 0.65806

Collected Steps per Second: 19,521.41999
Overall Steps per Second: 9,448.93564

Timestep Collection Time: 2.56211
Timestep Consumption Time: 2.73119
PPO Batch Consumption Time: 0.30948
Total Iteration Time: 5.29329

Cumulative Model Updates: 104,918
Cumulative Timesteps: 875,069,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,597.77479
Policy Entropy: 1.74932
Value Function Loss: 0.06838

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.16456
Policy Update Magnitude: 0.47411
Value Function Update Magnitude: 0.64987

Collected Steps per Second: 18,091.58031
Overall Steps per Second: 9,429.09423

Timestep Collection Time: 2.76405
Timestep Consumption Time: 2.53932
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 5.30337

Cumulative Model Updates: 104,924
Cumulative Timesteps: 875,119,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 875119030...
Checkpoint 875119030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,132.33704
Policy Entropy: 1.75055
Value Function Loss: 0.07044

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.15043
Policy Update Magnitude: 0.48644
Value Function Update Magnitude: 0.65630

Collected Steps per Second: 19,733.59606
Overall Steps per Second: 9,569.60956

Timestep Collection Time: 2.53507
Timestep Consumption Time: 2.69252
PPO Batch Consumption Time: 0.31633
Total Iteration Time: 5.22759

Cumulative Model Updates: 104,930
Cumulative Timesteps: 875,169,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,368.50648
Policy Entropy: 1.75332
Value Function Loss: 0.06783

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.15151
Policy Update Magnitude: 0.49437
Value Function Update Magnitude: 0.66155

Collected Steps per Second: 15,717.08172
Overall Steps per Second: 8,425.03864

Timestep Collection Time: 3.18316
Timestep Consumption Time: 2.75509
PPO Batch Consumption Time: 0.31259
Total Iteration Time: 5.93825

Cumulative Model Updates: 104,936
Cumulative Timesteps: 875,219,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 875219086...
Checkpoint 875219086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,611.77540
Policy Entropy: 1.77052
Value Function Loss: 0.06724

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.48924
Value Function Update Magnitude: 0.64780

Collected Steps per Second: 16,484.86788
Overall Steps per Second: 7,116.30828

Timestep Collection Time: 3.03430
Timestep Consumption Time: 3.99463
PPO Batch Consumption Time: 0.50074
Total Iteration Time: 7.02893

Cumulative Model Updates: 104,942
Cumulative Timesteps: 875,269,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,106.02286
Policy Entropy: 1.77628
Value Function Loss: 0.06714

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.51030
Value Function Update Magnitude: 0.61243

Collected Steps per Second: 14,165.32156
Overall Steps per Second: 6,808.44829

Timestep Collection Time: 3.52989
Timestep Consumption Time: 3.81422
PPO Batch Consumption Time: 0.48819
Total Iteration Time: 7.34411

Cumulative Model Updates: 104,948
Cumulative Timesteps: 875,319,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 875319108...
Checkpoint 875319108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,473.13290
Policy Entropy: 1.78017
Value Function Loss: 0.07333

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.16244
Policy Update Magnitude: 0.51257
Value Function Update Magnitude: 0.54383

Collected Steps per Second: 15,074.71636
Overall Steps per Second: 7,283.89706

Timestep Collection Time: 3.31774
Timestep Consumption Time: 3.54864
PPO Batch Consumption Time: 0.45987
Total Iteration Time: 6.86638

Cumulative Model Updates: 104,954
Cumulative Timesteps: 875,369,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,381.53133
Policy Entropy: 1.77883
Value Function Loss: 0.07399

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.15786
Policy Update Magnitude: 0.55556
Value Function Update Magnitude: 0.43857

Collected Steps per Second: 15,321.68369
Overall Steps per Second: 7,472.52617

Timestep Collection Time: 3.26518
Timestep Consumption Time: 3.42975
PPO Batch Consumption Time: 0.44516
Total Iteration Time: 6.69492

Cumulative Model Updates: 104,960
Cumulative Timesteps: 875,419,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 875419150...
Checkpoint 875419150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,009.10511
Policy Entropy: 1.77757
Value Function Loss: 0.07008

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.15348
Policy Update Magnitude: 0.57161
Value Function Update Magnitude: 0.51313

Collected Steps per Second: 15,599.43339
Overall Steps per Second: 7,269.47691

Timestep Collection Time: 3.20755
Timestep Consumption Time: 3.67547
PPO Batch Consumption Time: 0.48388
Total Iteration Time: 6.88303

Cumulative Model Updates: 104,966
Cumulative Timesteps: 875,469,186

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,749.24127
Policy Entropy: 1.78217
Value Function Loss: 0.06497

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.57312
Value Function Update Magnitude: 0.45758

Collected Steps per Second: 14,707.64072
Overall Steps per Second: 7,007.04469

Timestep Collection Time: 3.40055
Timestep Consumption Time: 3.73713
PPO Batch Consumption Time: 0.49085
Total Iteration Time: 7.13767

Cumulative Model Updates: 104,972
Cumulative Timesteps: 875,519,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 875519200...
Checkpoint 875519200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,976.65339
Policy Entropy: 1.78613
Value Function Loss: 0.06643

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.57591
Value Function Update Magnitude: 0.51958

Collected Steps per Second: 14,976.24611
Overall Steps per Second: 7,334.95637

Timestep Collection Time: 3.34116
Timestep Consumption Time: 3.48070
PPO Batch Consumption Time: 0.46427
Total Iteration Time: 6.82185

Cumulative Model Updates: 104,978
Cumulative Timesteps: 875,569,238

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,609.71421
Policy Entropy: 1.78612
Value Function Loss: 0.06916

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.57916
Value Function Update Magnitude: 0.53729

Collected Steps per Second: 14,415.82342
Overall Steps per Second: 7,277.41300

Timestep Collection Time: 3.46855
Timestep Consumption Time: 3.40230
PPO Batch Consumption Time: 0.44987
Total Iteration Time: 6.87085

Cumulative Model Updates: 104,984
Cumulative Timesteps: 875,619,240

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 875619240...
Checkpoint 875619240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,219.26760
Policy Entropy: 1.77555
Value Function Loss: 0.06934

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.57767
Value Function Update Magnitude: 0.61180

Collected Steps per Second: 14,853.27732
Overall Steps per Second: 7,978.91519

Timestep Collection Time: 3.36640
Timestep Consumption Time: 2.90037
PPO Batch Consumption Time: 0.36948
Total Iteration Time: 6.26677

Cumulative Model Updates: 104,990
Cumulative Timesteps: 875,669,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,272.69045
Policy Entropy: 1.79256
Value Function Loss: 0.06721

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.57385
Value Function Update Magnitude: 0.68331

Collected Steps per Second: 17,444.57218
Overall Steps per Second: 8,932.98542

Timestep Collection Time: 2.86634
Timestep Consumption Time: 2.73112
PPO Batch Consumption Time: 0.30893
Total Iteration Time: 5.59746

Cumulative Model Updates: 104,996
Cumulative Timesteps: 875,719,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Paused, press any key to resume
Resuming...

Saving checkpoint 875719244...
Checkpoint 875719244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,524.42273
Policy Entropy: 1.79515
Value Function Loss: 0.06955

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.57667
Value Function Update Magnitude: 0.57553

Collected Steps per Second: 20,498.25978
Overall Steps per Second: 10,212.29985

Timestep Collection Time: 2.43972
Timestep Consumption Time: 2.45732
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.89704

Cumulative Model Updates: 105,002
Cumulative Timesteps: 875,769,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,225.64622
Policy Entropy: 1.78967
Value Function Loss: 0.06843

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.57443
Value Function Update Magnitude: 0.45991

Collected Steps per Second: 20,905.49797
Overall Steps per Second: 10,364.87803

Timestep Collection Time: 2.39181
Timestep Consumption Time: 2.43237
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.82418

Cumulative Model Updates: 105,008
Cumulative Timesteps: 875,819,256

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 875819256...
Checkpoint 875819256 saved!
