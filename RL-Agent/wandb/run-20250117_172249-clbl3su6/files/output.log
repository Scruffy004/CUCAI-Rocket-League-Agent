Created new wandb run! clbl3su6
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.15351
Policy Entropy: 4.49940
Value Function Loss: nan

Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.59392
Value Function Update Magnitude: 0.64261

Collected Steps per Second: 19,753.21001
Overall Steps per Second: 11,448.89754

Timestep Collection Time: 2.53336
Timestep Consumption Time: 1.83754
PPO Batch Consumption Time: 0.45208
Total Iteration Time: 4.37090

Cumulative Model Updates: 2
Cumulative Timesteps: 50,042

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.20390
Policy Entropy: 4.49892
Value Function Loss: 234.16490

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.80104
Value Function Update Magnitude: 1.02574

Collected Steps per Second: 18,801.10093
Overall Steps per Second: 10,153.05765

Timestep Collection Time: 2.66048
Timestep Consumption Time: 2.26611
PPO Batch Consumption Time: 0.35968
Total Iteration Time: 4.92659

Cumulative Model Updates: 6
Cumulative Timesteps: 100,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 100062...
Checkpoint 100062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.10417
Policy Entropy: 4.49321
Value Function Loss: 154.61109

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.02246
Policy Update Magnitude: 0.78978
Value Function Update Magnitude: 1.02436

Collected Steps per Second: 22,903.56019
Overall Steps per Second: 10,124.47460

Timestep Collection Time: 2.18377
Timestep Consumption Time: 2.75634
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.94011

Cumulative Model Updates: 12
Cumulative Timesteps: 150,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.76329
Policy Entropy: 4.49026
Value Function Loss: 2.49073

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.01753
Policy Update Magnitude: 0.53257
Value Function Update Magnitude: 0.85307

Collected Steps per Second: 21,467.54973
Overall Steps per Second: 9,846.64348

Timestep Collection Time: 2.32919
Timestep Consumption Time: 2.74889
PPO Batch Consumption Time: 0.31168
Total Iteration Time: 5.07808

Cumulative Model Updates: 18
Cumulative Timesteps: 200,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 200080...
Checkpoint 200080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.18328
Policy Entropy: 4.48996
Value Function Loss: 1.78665

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.00451
Policy Update Magnitude: 0.34857
Value Function Update Magnitude: 0.56697

Collected Steps per Second: 20,155.05063
Overall Steps per Second: 9,994.38658

Timestep Collection Time: 2.48087
Timestep Consumption Time: 2.52214
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 5.00301

Cumulative Model Updates: 24
Cumulative Timesteps: 250,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.98164
Policy Entropy: 4.48987
Value Function Loss: 1.71032

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00291
Policy Update Magnitude: 0.28843
Value Function Update Magnitude: 0.62212

Collected Steps per Second: 21,908.48823
Overall Steps per Second: 10,020.37155

Timestep Collection Time: 2.28268
Timestep Consumption Time: 2.70816
PPO Batch Consumption Time: 0.30191
Total Iteration Time: 4.99083

Cumulative Model Updates: 30
Cumulative Timesteps: 300,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 300092...
Checkpoint 300092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.15259
Policy Entropy: 4.48827
Value Function Loss: 1.39309

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.28475
Value Function Update Magnitude: 0.63161

Collected Steps per Second: 21,565.10202
Overall Steps per Second: 10,000.08476

Timestep Collection Time: 2.31967
Timestep Consumption Time: 2.68268
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 5.00236

Cumulative Model Updates: 36
Cumulative Timesteps: 350,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.69699
Policy Entropy: 4.48478
Value Function Loss: 1.29983

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00005
Policy Update Magnitude: 0.30582
Value Function Update Magnitude: 0.63234

Collected Steps per Second: 19,804.95647
Overall Steps per Second: 9,326.01655

Timestep Collection Time: 2.52492
Timestep Consumption Time: 2.83707
PPO Batch Consumption Time: 0.32460
Total Iteration Time: 5.36199

Cumulative Model Updates: 42
Cumulative Timesteps: 400,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 400122...
Checkpoint 400122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.49251
Policy Entropy: 4.47984
Value Function Loss: 1.19189

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01218
Policy Update Magnitude: 0.29631
Value Function Update Magnitude: 0.60586

Collected Steps per Second: 19,568.26426
Overall Steps per Second: 8,985.00518

Timestep Collection Time: 2.55608
Timestep Consumption Time: 3.01075
PPO Batch Consumption Time: 0.32276
Total Iteration Time: 5.56683

Cumulative Model Updates: 48
Cumulative Timesteps: 450,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.22019
Policy Entropy: 4.48285
Value Function Loss: 1.36723

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.00122
Policy Update Magnitude: 0.31831
Value Function Update Magnitude: 0.57409

Collected Steps per Second: 20,439.95301
Overall Steps per Second: 9,482.81358

Timestep Collection Time: 2.44727
Timestep Consumption Time: 2.82775
PPO Batch Consumption Time: 0.32859
Total Iteration Time: 5.27502

Cumulative Model Updates: 54
Cumulative Timesteps: 500,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 500162...
Checkpoint 500162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.46741
Policy Entropy: 4.48177
Value Function Loss: 1.30535

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.00643
Policy Update Magnitude: 0.33743
Value Function Update Magnitude: 0.54132

Collected Steps per Second: 19,325.75972
Overall Steps per Second: 8,762.12064

Timestep Collection Time: 2.58732
Timestep Consumption Time: 3.11929
PPO Batch Consumption Time: 0.36024
Total Iteration Time: 5.70661

Cumulative Model Updates: 60
Cumulative Timesteps: 550,164

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.82160
Policy Entropy: 4.47324
Value Function Loss: 1.31921

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.31261
Value Function Update Magnitude: 0.74640

Collected Steps per Second: 18,906.33402
Overall Steps per Second: 8,749.55192

Timestep Collection Time: 2.64493
Timestep Consumption Time: 3.07033
PPO Batch Consumption Time: 0.36330
Total Iteration Time: 5.71526

Cumulative Model Updates: 66
Cumulative Timesteps: 600,170

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 600170...
Checkpoint 600170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.66376
Policy Entropy: 4.47514
Value Function Loss: 1.31834

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.00147
Policy Update Magnitude: 0.31952
Value Function Update Magnitude: 0.62036

Collected Steps per Second: 19,002.40741
Overall Steps per Second: 8,866.87175

Timestep Collection Time: 2.63282
Timestep Consumption Time: 3.00953
PPO Batch Consumption Time: 0.36233
Total Iteration Time: 5.64235

Cumulative Model Updates: 72
Cumulative Timesteps: 650,200

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.28769
Policy Entropy: 4.46942
Value Function Loss: 1.30614

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01697
Policy Update Magnitude: 0.33648
Value Function Update Magnitude: 0.67607

Collected Steps per Second: 19,150.13575
Overall Steps per Second: 8,676.17795

Timestep Collection Time: 2.61137
Timestep Consumption Time: 3.15246
PPO Batch Consumption Time: 0.35972
Total Iteration Time: 5.76383

Cumulative Model Updates: 78
Cumulative Timesteps: 700,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 700208...
Checkpoint 700208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.12635
Policy Entropy: 4.45955
Value Function Loss: 1.38387

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.01578
Policy Update Magnitude: 0.32855
Value Function Update Magnitude: 0.60186

Collected Steps per Second: 18,996.34123
Overall Steps per Second: 8,724.95178

Timestep Collection Time: 2.63209
Timestep Consumption Time: 3.09860
PPO Batch Consumption Time: 0.36035
Total Iteration Time: 5.73069

Cumulative Model Updates: 84
Cumulative Timesteps: 750,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.73744
Policy Entropy: 4.45641
Value Function Loss: 1.32968

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02038
Policy Update Magnitude: 0.34006
Value Function Update Magnitude: 0.49847

Collected Steps per Second: 19,299.94766
Overall Steps per Second: 8,742.84512

Timestep Collection Time: 2.59296
Timestep Consumption Time: 3.13103
PPO Batch Consumption Time: 0.36249
Total Iteration Time: 5.72399

Cumulative Model Updates: 90
Cumulative Timesteps: 800,252

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 800252...
Checkpoint 800252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.50900
Policy Entropy: 4.45717
Value Function Loss: 1.31977

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.00826
Policy Update Magnitude: 0.36714
Value Function Update Magnitude: 0.50346

Collected Steps per Second: 19,308.64117
Overall Steps per Second: 8,761.20275

Timestep Collection Time: 2.59045
Timestep Consumption Time: 3.11859
PPO Batch Consumption Time: 0.36150
Total Iteration Time: 5.70903

Cumulative Model Updates: 96
Cumulative Timesteps: 850,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.80086
Policy Entropy: 4.45021
Value Function Loss: 1.30708

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02916
Policy Update Magnitude: 0.34628
Value Function Update Magnitude: 0.52843

Collected Steps per Second: 19,292.04736
Overall Steps per Second: 8,906.09302

Timestep Collection Time: 2.59247
Timestep Consumption Time: 3.02324
PPO Batch Consumption Time: 0.36292
Total Iteration Time: 5.61571

Cumulative Model Updates: 102
Cumulative Timesteps: 900,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 900284...
Checkpoint 900284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.17277
Policy Entropy: 4.45186
Value Function Loss: 1.25132

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.00971
Policy Update Magnitude: 0.35468
Value Function Update Magnitude: 0.41972

Collected Steps per Second: 19,368.83739
Overall Steps per Second: 8,782.94377

Timestep Collection Time: 2.58209
Timestep Consumption Time: 3.11213
PPO Batch Consumption Time: 0.36036
Total Iteration Time: 5.69422

Cumulative Model Updates: 108
Cumulative Timesteps: 950,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.58156
Policy Entropy: 4.44334
Value Function Loss: 1.25953

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.01279
Policy Update Magnitude: 0.37130
Value Function Update Magnitude: 0.39229

Collected Steps per Second: 18,924.97200
Overall Steps per Second: 8,621.99823

Timestep Collection Time: 2.64328
Timestep Consumption Time: 3.15862
PPO Batch Consumption Time: 0.36652
Total Iteration Time: 5.80190

Cumulative Model Updates: 114
Cumulative Timesteps: 1,000,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1000320...
Checkpoint 1000320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.75460
Policy Entropy: 4.44591
Value Function Loss: 1.25881

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01504
Policy Update Magnitude: 0.37598
Value Function Update Magnitude: 0.42312

Collected Steps per Second: 19,949.51140
Overall Steps per Second: 8,796.04298

Timestep Collection Time: 2.50643
Timestep Consumption Time: 3.17817
PPO Batch Consumption Time: 0.36543
Total Iteration Time: 5.68460

Cumulative Model Updates: 120
Cumulative Timesteps: 1,050,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.59160
Policy Entropy: 4.43514
Value Function Loss: 1.27349

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 0.36763
Value Function Update Magnitude: 0.40675

Collected Steps per Second: 19,332.26701
Overall Steps per Second: 8,634.41276

Timestep Collection Time: 2.58645
Timestep Consumption Time: 3.20456
PPO Batch Consumption Time: 0.36509
Total Iteration Time: 5.79101

Cumulative Model Updates: 126
Cumulative Timesteps: 1,100,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1100324...
Checkpoint 1100324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.90902
Policy Entropy: 4.44338
Value Function Loss: 1.28202

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01817
Policy Update Magnitude: 0.37947
Value Function Update Magnitude: 0.43774

Collected Steps per Second: 19,404.44904
Overall Steps per Second: 8,833.55787

Timestep Collection Time: 2.57693
Timestep Consumption Time: 3.08375
PPO Batch Consumption Time: 0.36319
Total Iteration Time: 5.66069

Cumulative Model Updates: 132
Cumulative Timesteps: 1,150,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.78579
Policy Entropy: 4.43960
Value Function Loss: 1.26290

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.01544
Policy Update Magnitude: 0.41129
Value Function Update Magnitude: 0.42719

Collected Steps per Second: 19,428.45362
Overall Steps per Second: 8,706.30587

Timestep Collection Time: 2.57375
Timestep Consumption Time: 3.16967
PPO Batch Consumption Time: 0.36290
Total Iteration Time: 5.74342

Cumulative Model Updates: 138
Cumulative Timesteps: 1,200,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1200332...
Checkpoint 1200332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.68326
Policy Entropy: 4.43510
Value Function Loss: 1.25803

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02301
Policy Update Magnitude: 0.41256
Value Function Update Magnitude: 0.39147

Collected Steps per Second: 19,630.32523
Overall Steps per Second: 9,811.77493

Timestep Collection Time: 2.54861
Timestep Consumption Time: 2.55037
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 5.09898

Cumulative Model Updates: 144
Cumulative Timesteps: 1,250,362

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.97066
Policy Entropy: 4.43710
Value Function Loss: 1.29547

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.01408
Policy Update Magnitude: 0.41748
Value Function Update Magnitude: 0.38045

Collected Steps per Second: 22,331.53927
Overall Steps per Second: 10,065.63544

Timestep Collection Time: 2.24060
Timestep Consumption Time: 2.73037
PPO Batch Consumption Time: 0.31278
Total Iteration Time: 4.97097

Cumulative Model Updates: 150
Cumulative Timesteps: 1,300,398

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1300398...
Checkpoint 1300398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.32293
Policy Entropy: 4.42754
Value Function Loss: 1.31654

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01382
Policy Update Magnitude: 0.45449
Value Function Update Magnitude: 0.39205

Collected Steps per Second: 22,429.98231
Overall Steps per Second: 10,345.09217

Timestep Collection Time: 2.23005
Timestep Consumption Time: 2.60509
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.83514

Cumulative Model Updates: 156
Cumulative Timesteps: 1,350,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.26953
Policy Entropy: 4.43503
Value Function Loss: 1.29421

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01392
Policy Update Magnitude: 0.47855
Value Function Update Magnitude: 0.37591

Collected Steps per Second: 21,755.51750
Overall Steps per Second: 10,377.80191

Timestep Collection Time: 2.29900
Timestep Consumption Time: 2.52051
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.81952

Cumulative Model Updates: 162
Cumulative Timesteps: 1,400,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1400434...
Checkpoint 1400434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.16735
Policy Entropy: 4.42204
Value Function Loss: 1.32091

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02209
Policy Update Magnitude: 0.51000
Value Function Update Magnitude: 0.33367

Collected Steps per Second: 20,454.35212
Overall Steps per Second: 8,724.92330

Timestep Collection Time: 2.44515
Timestep Consumption Time: 3.28716
PPO Batch Consumption Time: 0.38785
Total Iteration Time: 5.73231

Cumulative Model Updates: 168
Cumulative Timesteps: 1,450,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.55526
Policy Entropy: 4.42462
Value Function Loss: 1.26632

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02409
Policy Update Magnitude: 0.51547
Value Function Update Magnitude: 0.40413

Collected Steps per Second: 19,234.03188
Overall Steps per Second: 8,555.96924

Timestep Collection Time: 2.60112
Timestep Consumption Time: 3.24626
PPO Batch Consumption Time: 0.39226
Total Iteration Time: 5.84738

Cumulative Model Updates: 174
Cumulative Timesteps: 1,500,478

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1500478...
Checkpoint 1500478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.23589
Policy Entropy: 4.41331
Value Function Loss: 1.27464

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02411
Policy Update Magnitude: 0.50716
Value Function Update Magnitude: 0.35252

Collected Steps per Second: 19,333.32877
Overall Steps per Second: 8,567.44016

Timestep Collection Time: 2.58662
Timestep Consumption Time: 3.25036
PPO Batch Consumption Time: 0.39025
Total Iteration Time: 5.83698

Cumulative Model Updates: 180
Cumulative Timesteps: 1,550,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.17607
Policy Entropy: 4.41058
Value Function Loss: 1.27624

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.49737
Value Function Update Magnitude: 0.29437

Collected Steps per Second: 19,498.59377
Overall Steps per Second: 8,585.04306

Timestep Collection Time: 2.56460
Timestep Consumption Time: 3.26019
PPO Batch Consumption Time: 0.38771
Total Iteration Time: 5.82478

Cumulative Model Updates: 186
Cumulative Timesteps: 1,600,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1600492...
Checkpoint 1600492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.47012
Policy Entropy: 4.41352
Value Function Loss: 1.31935

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.49337
Value Function Update Magnitude: 0.32490

Collected Steps per Second: 19,185.98523
Overall Steps per Second: 8,472.68798

Timestep Collection Time: 2.60722
Timestep Consumption Time: 3.29670
PPO Batch Consumption Time: 0.39177
Total Iteration Time: 5.90391

Cumulative Model Updates: 192
Cumulative Timesteps: 1,650,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.84033
Policy Entropy: 4.41521
Value Function Loss: 1.37088

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02273
Policy Update Magnitude: 0.51444
Value Function Update Magnitude: 0.32771

Collected Steps per Second: 20,126.07928
Overall Steps per Second: 8,707.86534

Timestep Collection Time: 2.48553
Timestep Consumption Time: 3.25916
PPO Batch Consumption Time: 0.38628
Total Iteration Time: 5.74469

Cumulative Model Updates: 198
Cumulative Timesteps: 1,700,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1700538...
Checkpoint 1700538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.52964
Policy Entropy: 4.40619
Value Function Loss: 1.34964

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.03306
Policy Update Magnitude: 0.55621
Value Function Update Magnitude: 0.24745

Collected Steps per Second: 18,532.28127
Overall Steps per Second: 8,302.74589

Timestep Collection Time: 2.69864
Timestep Consumption Time: 3.32491
PPO Batch Consumption Time: 0.38604
Total Iteration Time: 6.02355

Cumulative Model Updates: 204
Cumulative Timesteps: 1,750,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.22561
Policy Entropy: 4.39201
Value Function Loss: 1.36555

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.03586
Policy Update Magnitude: 0.58583
Value Function Update Magnitude: 0.24809

Collected Steps per Second: 19,050.79418
Overall Steps per Second: 8,537.32430

Timestep Collection Time: 2.62456
Timestep Consumption Time: 3.23207
PPO Batch Consumption Time: 0.39453
Total Iteration Time: 5.85664

Cumulative Model Updates: 210
Cumulative Timesteps: 1,800,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1800550...
Checkpoint 1800550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.58025
Policy Entropy: 4.38378
Value Function Loss: 1.30743

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04078
Policy Update Magnitude: 0.59078
Value Function Update Magnitude: 0.22665

Collected Steps per Second: 19,091.29117
Overall Steps per Second: 8,345.19893

Timestep Collection Time: 2.62057
Timestep Consumption Time: 3.37450
PPO Batch Consumption Time: 0.39314
Total Iteration Time: 5.99506

Cumulative Model Updates: 216
Cumulative Timesteps: 1,850,580

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.23675
Policy Entropy: 4.38404
Value Function Loss: 1.26539

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.03649
Policy Update Magnitude: 0.61798
Value Function Update Magnitude: 0.22096

Collected Steps per Second: 19,574.34852
Overall Steps per Second: 8,590.29436

Timestep Collection Time: 2.55528
Timestep Consumption Time: 3.26733
PPO Batch Consumption Time: 0.38748
Total Iteration Time: 5.82262

Cumulative Model Updates: 222
Cumulative Timesteps: 1,900,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1900598...
Checkpoint 1900598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.24274
Policy Entropy: 4.37448
Value Function Loss: 1.29149

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.04931
Policy Update Magnitude: 0.59926
Value Function Update Magnitude: 0.19551

Collected Steps per Second: 20,123.99264
Overall Steps per Second: 9,147.32638

Timestep Collection Time: 2.48470
Timestep Consumption Time: 2.98160
PPO Batch Consumption Time: 0.35836
Total Iteration Time: 5.46630

Cumulative Model Updates: 228
Cumulative Timesteps: 1,950,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.51298
Policy Entropy: 4.37307
Value Function Loss: 1.25914

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04479
Policy Update Magnitude: 0.60273
Value Function Update Magnitude: 0.19084

Collected Steps per Second: 19,372.01126
Overall Steps per Second: 8,753.02951

Timestep Collection Time: 2.58300
Timestep Consumption Time: 3.13364
PPO Batch Consumption Time: 0.37012
Total Iteration Time: 5.71665

Cumulative Model Updates: 234
Cumulative Timesteps: 2,000,638

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2000638...
Checkpoint 2000638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.72918
Policy Entropy: 4.35130
Value Function Loss: 1.29322

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.05855
Policy Update Magnitude: 0.59224
Value Function Update Magnitude: 0.18898

Collected Steps per Second: 19,558.08073
Overall Steps per Second: 8,895.33784

Timestep Collection Time: 2.55792
Timestep Consumption Time: 3.06615
PPO Batch Consumption Time: 0.36630
Total Iteration Time: 5.62407

Cumulative Model Updates: 240
Cumulative Timesteps: 2,050,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.31190
Policy Entropy: 4.34520
Value Function Loss: 1.35872

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.05716
Policy Update Magnitude: 0.59432
Value Function Update Magnitude: 0.20249

Collected Steps per Second: 19,681.60444
Overall Steps per Second: 8,807.54439

Timestep Collection Time: 2.54105
Timestep Consumption Time: 3.13726
PPO Batch Consumption Time: 0.37014
Total Iteration Time: 5.67831

Cumulative Model Updates: 246
Cumulative Timesteps: 2,100,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2100678...
Checkpoint 2100678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.50805
Policy Entropy: 4.34093
Value Function Loss: 1.36151

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06033
Policy Update Magnitude: 0.59914
Value Function Update Magnitude: 0.22006

Collected Steps per Second: 19,329.96612
Overall Steps per Second: 8,767.38681

Timestep Collection Time: 2.58790
Timestep Consumption Time: 3.11779
PPO Batch Consumption Time: 0.37170
Total Iteration Time: 5.70569

Cumulative Model Updates: 252
Cumulative Timesteps: 2,150,702

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.89866
Policy Entropy: 4.33603
Value Function Loss: 1.38827

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05432
Policy Update Magnitude: 0.57581
Value Function Update Magnitude: 0.22216

Collected Steps per Second: 20,404.32132
Overall Steps per Second: 8,932.51118

Timestep Collection Time: 2.45252
Timestep Consumption Time: 3.14971
PPO Batch Consumption Time: 0.36567
Total Iteration Time: 5.60223

Cumulative Model Updates: 258
Cumulative Timesteps: 2,200,744

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2200744...
Checkpoint 2200744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.84177
Policy Entropy: 4.33539
Value Function Loss: 1.39054

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05598
Policy Update Magnitude: 0.58407
Value Function Update Magnitude: 0.20528

Collected Steps per Second: 19,635.26953
Overall Steps per Second: 8,804.66950

Timestep Collection Time: 2.54807
Timestep Consumption Time: 3.13437
PPO Batch Consumption Time: 0.37151
Total Iteration Time: 5.68244

Cumulative Model Updates: 264
Cumulative Timesteps: 2,250,776

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.54133
Policy Entropy: 4.31095
Value Function Loss: 1.44585

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.55627
Value Function Update Magnitude: 0.21272

Collected Steps per Second: 19,700.92935
Overall Steps per Second: 8,949.18741

Timestep Collection Time: 2.53887
Timestep Consumption Time: 3.05025
PPO Batch Consumption Time: 0.36546
Total Iteration Time: 5.58911

Cumulative Model Updates: 270
Cumulative Timesteps: 2,300,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2300794...
Checkpoint 2300794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132.67646
Policy Entropy: 4.30084
Value Function Loss: 1.46212

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07600
Policy Update Magnitude: 0.54926
Value Function Update Magnitude: 0.21363

Collected Steps per Second: 19,521.04315
Overall Steps per Second: 8,791.80613

Timestep Collection Time: 2.56185
Timestep Consumption Time: 3.12640
PPO Batch Consumption Time: 0.35980
Total Iteration Time: 5.68825

Cumulative Model Updates: 276
Cumulative Timesteps: 2,350,804

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.66173
Policy Entropy: 4.29208
Value Function Loss: 1.48612

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06983
Policy Update Magnitude: 0.54913
Value Function Update Magnitude: 0.22085

Collected Steps per Second: 21,339.63302
Overall Steps per Second: 9,822.39866

Timestep Collection Time: 2.34306
Timestep Consumption Time: 2.74735
PPO Batch Consumption Time: 0.31577
Total Iteration Time: 5.09041

Cumulative Model Updates: 282
Cumulative Timesteps: 2,400,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2400804...
Checkpoint 2400804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160.42410
Policy Entropy: 4.29762
Value Function Loss: 1.50835

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.53626
Value Function Update Magnitude: 0.20862

Collected Steps per Second: 20,379.74572
Overall Steps per Second: 9,937.02270

Timestep Collection Time: 2.45587
Timestep Consumption Time: 2.58085
PPO Batch Consumption Time: 0.30008
Total Iteration Time: 5.03672

Cumulative Model Updates: 288
Cumulative Timesteps: 2,450,854

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.05933
Policy Entropy: 4.29185
Value Function Loss: 1.50626

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05738
Policy Update Magnitude: 0.51699
Value Function Update Magnitude: 0.19216

Collected Steps per Second: 21,527.60698
Overall Steps per Second: 10,097.50878

Timestep Collection Time: 2.32325
Timestep Consumption Time: 2.62985
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.95310

Cumulative Model Updates: 294
Cumulative Timesteps: 2,500,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2500868...
Checkpoint 2500868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.76272
Policy Entropy: 4.26297
Value Function Loss: 1.55811

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.52125
Value Function Update Magnitude: 0.19233

Collected Steps per Second: 21,486.63728
Overall Steps per Second: 10,177.10772

Timestep Collection Time: 2.32749
Timestep Consumption Time: 2.58648
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.91397

Cumulative Model Updates: 300
Cumulative Timesteps: 2,550,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.88771
Policy Entropy: 4.25910
Value Function Loss: 1.58807

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.53160
Value Function Update Magnitude: 0.19735

Collected Steps per Second: 22,466.22689
Overall Steps per Second: 10,067.70695

Timestep Collection Time: 2.22654
Timestep Consumption Time: 2.74202
PPO Batch Consumption Time: 0.31174
Total Iteration Time: 4.96856

Cumulative Model Updates: 306
Cumulative Timesteps: 2,600,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2600900...
Checkpoint 2600900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.59857
Policy Entropy: 4.23744
Value Function Loss: 1.68769

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07829
Policy Update Magnitude: 0.54250
Value Function Update Magnitude: 0.19804

Collected Steps per Second: 21,617.51169
Overall Steps per Second: 10,090.43310

Timestep Collection Time: 2.31423
Timestep Consumption Time: 2.64373
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.95796

Cumulative Model Updates: 312
Cumulative Timesteps: 2,650,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.26509
Policy Entropy: 4.24062
Value Function Loss: 1.65640

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.50997
Value Function Update Magnitude: 0.21059

Collected Steps per Second: 21,660.78107
Overall Steps per Second: 10,146.56275

Timestep Collection Time: 2.31044
Timestep Consumption Time: 2.62187
PPO Batch Consumption Time: 0.30523
Total Iteration Time: 4.93231

Cumulative Model Updates: 318
Cumulative Timesteps: 2,700,974

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2700974...
Checkpoint 2700974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105.58598
Policy Entropy: 4.23872
Value Function Loss: 1.66757

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.48312
Value Function Update Magnitude: 0.21888

Collected Steps per Second: 21,515.18463
Overall Steps per Second: 9,993.58104

Timestep Collection Time: 2.32413
Timestep Consumption Time: 2.67949
PPO Batch Consumption Time: 0.30048
Total Iteration Time: 5.00361

Cumulative Model Updates: 324
Cumulative Timesteps: 2,750,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.74103
Policy Entropy: 4.23718
Value Function Loss: 1.60538

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07732
Policy Update Magnitude: 0.48946
Value Function Update Magnitude: 0.20620

Collected Steps per Second: 20,052.89976
Overall Steps per Second: 9,275.41758

Timestep Collection Time: 2.49430
Timestep Consumption Time: 2.89823
PPO Batch Consumption Time: 0.33676
Total Iteration Time: 5.39253

Cumulative Model Updates: 330
Cumulative Timesteps: 2,800,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2800996...
Checkpoint 2800996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132.32858
Policy Entropy: 4.20777
Value Function Loss: 1.61483

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08421
Policy Update Magnitude: 0.49104
Value Function Update Magnitude: 0.19458

Collected Steps per Second: 20,122.09657
Overall Steps per Second: 8,821.55268

Timestep Collection Time: 2.48682
Timestep Consumption Time: 3.18565
PPO Batch Consumption Time: 0.37238
Total Iteration Time: 5.67247

Cumulative Model Updates: 336
Cumulative Timesteps: 2,851,036

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.50528
Policy Entropy: 4.18887
Value Function Loss: 1.64574

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.09516
Policy Update Magnitude: 0.48545
Value Function Update Magnitude: 0.18463

Collected Steps per Second: 19,158.64802
Overall Steps per Second: 8,677.33115

Timestep Collection Time: 2.61094
Timestep Consumption Time: 3.15374
PPO Batch Consumption Time: 0.36688
Total Iteration Time: 5.76468

Cumulative Model Updates: 342
Cumulative Timesteps: 2,901,058

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2901058...
Checkpoint 2901058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129.47402
Policy Entropy: 4.18704
Value Function Loss: 1.65715

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.47588
Value Function Update Magnitude: 0.18370

Collected Steps per Second: 19,500.03273
Overall Steps per Second: 8,817.43076

Timestep Collection Time: 2.56512
Timestep Consumption Time: 3.10773
PPO Batch Consumption Time: 0.36143
Total Iteration Time: 5.67285

Cumulative Model Updates: 348
Cumulative Timesteps: 2,951,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.94557
Policy Entropy: 4.17117
Value Function Loss: 1.71395

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.47186
Value Function Update Magnitude: 0.21566

Collected Steps per Second: 20,221.21033
Overall Steps per Second: 9,569.88845

Timestep Collection Time: 2.47265
Timestep Consumption Time: 2.75207
PPO Batch Consumption Time: 0.31364
Total Iteration Time: 5.22472

Cumulative Model Updates: 354
Cumulative Timesteps: 3,001,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3001078...
Checkpoint 3001078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.93260
Policy Entropy: 4.18199
Value Function Loss: 1.68833

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11476
Policy Update Magnitude: 0.46173
Value Function Update Magnitude: 0.22896

Collected Steps per Second: 21,492.89128
Overall Steps per Second: 9,997.97510

Timestep Collection Time: 2.32691
Timestep Consumption Time: 2.67530
PPO Batch Consumption Time: 0.30514
Total Iteration Time: 5.00221

Cumulative Model Updates: 360
Cumulative Timesteps: 3,051,090

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.88111
Policy Entropy: 4.16731
Value Function Loss: 1.69344

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06802
Policy Update Magnitude: 0.47135
Value Function Update Magnitude: 0.21403

Collected Steps per Second: 20,678.02536
Overall Steps per Second: 10,128.31898

Timestep Collection Time: 2.41822
Timestep Consumption Time: 2.51883
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.93705

Cumulative Model Updates: 366
Cumulative Timesteps: 3,101,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3101094...
Checkpoint 3101094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.56667
Policy Entropy: 4.15539
Value Function Loss: 1.78679

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.47158
Value Function Update Magnitude: 0.19076

Collected Steps per Second: 20,651.83063
Overall Steps per Second: 9,747.84144

Timestep Collection Time: 2.42225
Timestep Consumption Time: 2.70955
PPO Batch Consumption Time: 0.31070
Total Iteration Time: 5.13180

Cumulative Model Updates: 372
Cumulative Timesteps: 3,151,118

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.70950
Policy Entropy: 4.16207
Value Function Loss: 1.83722

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08681
Policy Update Magnitude: 0.47140
Value Function Update Magnitude: 0.17812

Collected Steps per Second: 20,699.39460
Overall Steps per Second: 9,917.82773

Timestep Collection Time: 2.41698
Timestep Consumption Time: 2.62747
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 5.04445

Cumulative Model Updates: 378
Cumulative Timesteps: 3,201,148

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3201148...
Checkpoint 3201148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.03094
Policy Entropy: 4.15001
Value Function Loss: 1.83072

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06950
Policy Update Magnitude: 0.49234
Value Function Update Magnitude: 0.16900

Collected Steps per Second: 22,338.29255
Overall Steps per Second: 9,981.06806

Timestep Collection Time: 2.23929
Timestep Consumption Time: 2.77239
PPO Batch Consumption Time: 0.31049
Total Iteration Time: 5.01169

Cumulative Model Updates: 384
Cumulative Timesteps: 3,251,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.41605
Policy Entropy: 4.13442
Value Function Loss: 1.79058

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.08102
Policy Update Magnitude: 0.50969
Value Function Update Magnitude: 0.15816

Collected Steps per Second: 22,109.46040
Overall Steps per Second: 9,539.90813

Timestep Collection Time: 2.26184
Timestep Consumption Time: 2.98014
PPO Batch Consumption Time: 0.35159
Total Iteration Time: 5.24198

Cumulative Model Updates: 390
Cumulative Timesteps: 3,301,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3301178...
Checkpoint 3301178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.74873
Policy Entropy: 4.13098
Value Function Loss: 1.80128

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.49741
Value Function Update Magnitude: 0.15794

Collected Steps per Second: 21,798.20457
Overall Steps per Second: 10,011.57528

Timestep Collection Time: 2.29450
Timestep Consumption Time: 2.70132
PPO Batch Consumption Time: 0.31460
Total Iteration Time: 4.99582

Cumulative Model Updates: 396
Cumulative Timesteps: 3,351,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.59940
Policy Entropy: 4.12851
Value Function Loss: 1.90083

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.11353
Policy Update Magnitude: 0.50124
Value Function Update Magnitude: 0.18446

Collected Steps per Second: 21,689.90588
Overall Steps per Second: 9,934.19854

Timestep Collection Time: 2.30651
Timestep Consumption Time: 2.72943
PPO Batch Consumption Time: 0.30990
Total Iteration Time: 5.03594

Cumulative Model Updates: 402
Cumulative Timesteps: 3,401,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3401222...
Checkpoint 3401222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.56138
Policy Entropy: 4.12524
Value Function Loss: 1.92374

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.47345
Value Function Update Magnitude: 0.18035

Collected Steps per Second: 20,724.12082
Overall Steps per Second: 9,578.09072

Timestep Collection Time: 2.41294
Timestep Consumption Time: 2.80794
PPO Batch Consumption Time: 0.33024
Total Iteration Time: 5.22087

Cumulative Model Updates: 408
Cumulative Timesteps: 3,451,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.81456
Policy Entropy: 4.10250
Value Function Loss: 1.93486

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10921
Policy Update Magnitude: 0.47725
Value Function Update Magnitude: 0.17185

Collected Steps per Second: 23,133.85158
Overall Steps per Second: 9,983.44230

Timestep Collection Time: 2.16220
Timestep Consumption Time: 2.84810
PPO Batch Consumption Time: 0.32904
Total Iteration Time: 5.01030

Cumulative Model Updates: 414
Cumulative Timesteps: 3,501,248

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3501248...
Checkpoint 3501248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.02664
Policy Entropy: 4.08379
Value Function Loss: 1.93513

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11875
Policy Update Magnitude: 0.43725
Value Function Update Magnitude: 0.15645

Collected Steps per Second: 21,805.31097
Overall Steps per Second: 9,720.00880

Timestep Collection Time: 2.29412
Timestep Consumption Time: 2.85238
PPO Batch Consumption Time: 0.33136
Total Iteration Time: 5.14650

Cumulative Model Updates: 420
Cumulative Timesteps: 3,551,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.33098
Policy Entropy: 4.08202
Value Function Loss: 1.94498

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.44919
Value Function Update Magnitude: 0.15839

Collected Steps per Second: 21,470.42360
Overall Steps per Second: 9,909.36069

Timestep Collection Time: 2.33009
Timestep Consumption Time: 2.71847
PPO Batch Consumption Time: 0.30685
Total Iteration Time: 5.04856

Cumulative Model Updates: 426
Cumulative Timesteps: 3,601,300

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3601300...
Checkpoint 3601300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152.61040
Policy Entropy: 4.06698
Value Function Loss: 1.89208

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.47233
Value Function Update Magnitude: 0.16935

Collected Steps per Second: 21,959.48638
Overall Steps per Second: 10,200.19452

Timestep Collection Time: 2.27765
Timestep Consumption Time: 2.62579
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.90344

Cumulative Model Updates: 432
Cumulative Timesteps: 3,651,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.84125
Policy Entropy: 4.04819
Value Function Loss: 1.89266

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.49020
Value Function Update Magnitude: 0.15468

Collected Steps per Second: 20,952.62262
Overall Steps per Second: 9,981.61796

Timestep Collection Time: 2.38739
Timestep Consumption Time: 2.62403
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 5.01141

Cumulative Model Updates: 438
Cumulative Timesteps: 3,701,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3701338...
Checkpoint 3701338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.13044
Policy Entropy: 4.02288
Value Function Loss: 1.84321

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.10077
Policy Update Magnitude: 0.48846
Value Function Update Magnitude: 0.16163

Collected Steps per Second: 20,905.23390
Overall Steps per Second: 9,997.59811

Timestep Collection Time: 2.39347
Timestep Consumption Time: 2.61133
PPO Batch Consumption Time: 0.30758
Total Iteration Time: 5.00480

Cumulative Model Updates: 444
Cumulative Timesteps: 3,751,374

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.45479
Policy Entropy: 4.00452
Value Function Loss: 1.96514

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.16419
Policy Update Magnitude: 0.47138
Value Function Update Magnitude: 0.19001

Collected Steps per Second: 21,990.02184
Overall Steps per Second: 9,946.31581

Timestep Collection Time: 2.27585
Timestep Consumption Time: 2.75576
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 5.03161

Cumulative Model Updates: 450
Cumulative Timesteps: 3,801,420

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 3801420...
Checkpoint 3801420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.58913
Policy Entropy: 4.03137
Value Function Loss: 2.02230

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.16995
Policy Update Magnitude: 0.40154
Value Function Update Magnitude: 0.18243

Collected Steps per Second: 21,711.31238
Overall Steps per Second: 9,660.53289

Timestep Collection Time: 2.30387
Timestep Consumption Time: 2.87390
PPO Batch Consumption Time: 0.33630
Total Iteration Time: 5.17777

Cumulative Model Updates: 456
Cumulative Timesteps: 3,851,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.70693
Policy Entropy: 4.04501
Value Function Loss: 2.22517

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.15585
Policy Update Magnitude: 0.40183
Value Function Update Magnitude: 0.19795

Collected Steps per Second: 20,212.68675
Overall Steps per Second: 9,091.28808

Timestep Collection Time: 2.47389
Timestep Consumption Time: 3.02632
PPO Batch Consumption Time: 0.35216
Total Iteration Time: 5.50021

Cumulative Model Updates: 462
Cumulative Timesteps: 3,901,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3901444...
Checkpoint 3901444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.83738
Policy Entropy: 4.07336
Value Function Loss: 2.30443

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.13476
Policy Update Magnitude: 0.43370
Value Function Update Magnitude: 0.22780

Collected Steps per Second: 19,994.73684
Overall Steps per Second: 9,025.39520

Timestep Collection Time: 2.50116
Timestep Consumption Time: 3.03987
PPO Batch Consumption Time: 0.35460
Total Iteration Time: 5.54103

Cumulative Model Updates: 468
Cumulative Timesteps: 3,951,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.53881
Policy Entropy: 4.05168
Value Function Loss: 2.33848

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.44193
Value Function Update Magnitude: 0.24518

Collected Steps per Second: 19,207.73527
Overall Steps per Second: 8,940.78963

Timestep Collection Time: 2.60343
Timestep Consumption Time: 2.98959
PPO Batch Consumption Time: 0.34855
Total Iteration Time: 5.59302

Cumulative Model Updates: 474
Cumulative Timesteps: 4,001,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 4001460...
Checkpoint 4001460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162.95543
Policy Entropy: 4.02655
Value Function Loss: 2.40903

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.14923
Policy Update Magnitude: 0.42945
Value Function Update Magnitude: 0.24427

Collected Steps per Second: 20,472.00774
Overall Steps per Second: 9,113.28914

Timestep Collection Time: 2.44363
Timestep Consumption Time: 3.04572
PPO Batch Consumption Time: 0.35667
Total Iteration Time: 5.48935

Cumulative Model Updates: 480
Cumulative Timesteps: 4,051,486

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.56065
Policy Entropy: 4.00152
Value Function Loss: 2.45355

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.47732
Value Function Update Magnitude: 0.25337

Collected Steps per Second: 19,696.42425
Overall Steps per Second: 8,973.71642

Timestep Collection Time: 2.53894
Timestep Consumption Time: 3.03378
PPO Batch Consumption Time: 0.35697
Total Iteration Time: 5.57272

Cumulative Model Updates: 486
Cumulative Timesteps: 4,101,494

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 4101494...
Checkpoint 4101494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.93907
Policy Entropy: 3.99284
Value Function Loss: 2.57934

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.50702
Value Function Update Magnitude: 0.23789

Collected Steps per Second: 19,665.37179
Overall Steps per Second: 9,110.45458

Timestep Collection Time: 2.54346
Timestep Consumption Time: 2.94672
PPO Batch Consumption Time: 0.35330
Total Iteration Time: 5.49018

Cumulative Model Updates: 492
Cumulative Timesteps: 4,151,512

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.27155
Policy Entropy: 4.00456
Value Function Loss: 2.62704

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.16609
Policy Update Magnitude: 0.44010
Value Function Update Magnitude: 0.24254

Collected Steps per Second: 19,990.34527
Overall Steps per Second: 9,086.94890

Timestep Collection Time: 2.50261
Timestep Consumption Time: 3.00287
PPO Batch Consumption Time: 0.34933
Total Iteration Time: 5.50548

Cumulative Model Updates: 498
Cumulative Timesteps: 4,201,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 4201540...
Checkpoint 4201540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.66350
Policy Entropy: 4.00552
Value Function Loss: 2.59622

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.16347
Policy Update Magnitude: 0.41504
Value Function Update Magnitude: 0.23998

Collected Steps per Second: 19,813.63711
Overall Steps per Second: 9,067.97755

Timestep Collection Time: 2.52483
Timestep Consumption Time: 2.99195
PPO Batch Consumption Time: 0.35162
Total Iteration Time: 5.51678

Cumulative Model Updates: 504
Cumulative Timesteps: 4,251,566

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.49183
Policy Entropy: 3.99520
Value Function Loss: 2.62551

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14699
Policy Update Magnitude: 0.44940
Value Function Update Magnitude: 0.24460

Collected Steps per Second: 20,501.42848
Overall Steps per Second: 9,124.86184

Timestep Collection Time: 2.43895
Timestep Consumption Time: 3.04080
PPO Batch Consumption Time: 0.35590
Total Iteration Time: 5.47975

Cumulative Model Updates: 510
Cumulative Timesteps: 4,301,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 4301568...
Checkpoint 4301568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.32640
Policy Entropy: 3.95951
Value Function Loss: 2.57143

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.45096
Value Function Update Magnitude: 0.25807

Collected Steps per Second: 19,806.16051
Overall Steps per Second: 8,997.95430

Timestep Collection Time: 2.52527
Timestep Consumption Time: 3.03332
PPO Batch Consumption Time: 0.34885
Total Iteration Time: 5.55860

Cumulative Model Updates: 516
Cumulative Timesteps: 4,351,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.31633
Policy Entropy: 3.95226
Value Function Loss: 2.61939

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11967
Policy Update Magnitude: 0.43745
Value Function Update Magnitude: 0.27526

Collected Steps per Second: 19,399.27017
Overall Steps per Second: 8,809.54348

Timestep Collection Time: 2.57896
Timestep Consumption Time: 3.10011
PPO Batch Consumption Time: 0.36868
Total Iteration Time: 5.67907

Cumulative Model Updates: 522
Cumulative Timesteps: 4,401,614

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 4401614...
Checkpoint 4401614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.81209
Policy Entropy: 3.93362
Value Function Loss: 2.55707

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.48524
Value Function Update Magnitude: 0.27109

Collected Steps per Second: 19,574.57879
Overall Steps per Second: 8,715.43140

Timestep Collection Time: 2.55464
Timestep Consumption Time: 3.18300
PPO Batch Consumption Time: 0.36789
Total Iteration Time: 5.73764

Cumulative Model Updates: 528
Cumulative Timesteps: 4,451,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.66636
Policy Entropy: 3.92714
Value Function Loss: 2.71208

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.48707
Value Function Update Magnitude: 0.27311

Collected Steps per Second: 19,667.42598
Overall Steps per Second: 9,619.62061

Timestep Collection Time: 2.54370
Timestep Consumption Time: 2.65692
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 5.20062

Cumulative Model Updates: 534
Cumulative Timesteps: 4,501,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 4501648...
Checkpoint 4501648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.49573
Policy Entropy: 3.91719
Value Function Loss: 2.79595

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06890
Policy Update Magnitude: 0.49731
Value Function Update Magnitude: 0.22323

Collected Steps per Second: 22,129.20682
Overall Steps per Second: 10,476.20661

Timestep Collection Time: 2.26027
Timestep Consumption Time: 2.51417
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.77444

Cumulative Model Updates: 540
Cumulative Timesteps: 4,551,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.06573
Policy Entropy: 3.91894
Value Function Loss: 2.81839

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.16266
Policy Update Magnitude: 0.46173
Value Function Update Magnitude: 0.20910

Collected Steps per Second: 22,463.78458
Overall Steps per Second: 10,304.53658

Timestep Collection Time: 2.22741
Timestep Consumption Time: 2.62832
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.85573

Cumulative Model Updates: 546
Cumulative Timesteps: 4,601,702

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 4601702...
Checkpoint 4601702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.46491
Policy Entropy: 3.90718
Value Function Loss: 2.99524

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.18768
Policy Update Magnitude: 0.37461
Value Function Update Magnitude: 0.20171

Collected Steps per Second: 20,919.49778
Overall Steps per Second: 9,961.28686

Timestep Collection Time: 2.39136
Timestep Consumption Time: 2.63068
PPO Batch Consumption Time: 0.31088
Total Iteration Time: 5.02204

Cumulative Model Updates: 552
Cumulative Timesteps: 4,651,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.62438
Policy Entropy: 3.90905
Value Function Loss: 3.15685

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15085
Policy Update Magnitude: 0.35126
Value Function Update Magnitude: 0.20031

Collected Steps per Second: 22,208.18155
Overall Steps per Second: 10,211.40199

Timestep Collection Time: 2.25250
Timestep Consumption Time: 2.64633
PPO Batch Consumption Time: 0.29951
Total Iteration Time: 4.89884

Cumulative Model Updates: 558
Cumulative Timesteps: 4,701,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 4701752...
Checkpoint 4701752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.46922
Policy Entropy: 3.90768
Value Function Loss: 3.45150

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.38594
Value Function Update Magnitude: 0.21760

Collected Steps per Second: 22,069.45750
Overall Steps per Second: 10,268.84425

Timestep Collection Time: 2.26639
Timestep Consumption Time: 2.60446
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.87085

Cumulative Model Updates: 564
Cumulative Timesteps: 4,751,770

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.16833
Policy Entropy: 3.89717
Value Function Loss: 3.38922

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.40887
Value Function Update Magnitude: 0.25971

Collected Steps per Second: 22,112.67729
Overall Steps per Second: 10,224.29687

Timestep Collection Time: 2.26160
Timestep Consumption Time: 2.62969
PPO Batch Consumption Time: 0.30950
Total Iteration Time: 4.89129

Cumulative Model Updates: 570
Cumulative Timesteps: 4,801,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 4801780...
Checkpoint 4801780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.21549
Policy Entropy: 3.88275
Value Function Loss: 3.44250

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.42875
Value Function Update Magnitude: 0.26128

Collected Steps per Second: 22,016.72555
Overall Steps per Second: 10,245.79735

Timestep Collection Time: 2.27227
Timestep Consumption Time: 2.61051
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.88278

Cumulative Model Updates: 576
Cumulative Timesteps: 4,851,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.07551
Policy Entropy: 3.86473
Value Function Loss: 3.27969

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.15895
Policy Update Magnitude: 0.40005
Value Function Update Magnitude: 0.24801

Collected Steps per Second: 20,385.36195
Overall Steps per Second: 9,621.05537

Timestep Collection Time: 2.45519
Timestep Consumption Time: 2.74694
PPO Batch Consumption Time: 0.31716
Total Iteration Time: 5.20213

Cumulative Model Updates: 582
Cumulative Timesteps: 4,901,858

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 4901858...
Checkpoint 4901858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.03601
Policy Entropy: 3.86155
Value Function Loss: 3.36250

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.15745
Policy Update Magnitude: 0.38275
Value Function Update Magnitude: 0.24660

Collected Steps per Second: 21,767.08437
Overall Steps per Second: 9,984.17818

Timestep Collection Time: 2.29842
Timestep Consumption Time: 2.71250
PPO Batch Consumption Time: 0.30703
Total Iteration Time: 5.01093

Cumulative Model Updates: 588
Cumulative Timesteps: 4,951,888

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.90173
Policy Entropy: 3.85890
Value Function Loss: 3.29768

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.16409
Policy Update Magnitude: 0.37237
Value Function Update Magnitude: 0.25710

Collected Steps per Second: 19,411.23646
Overall Steps per Second: 9,407.06784

Timestep Collection Time: 2.57779
Timestep Consumption Time: 2.74141
PPO Batch Consumption Time: 0.30319
Total Iteration Time: 5.31919

Cumulative Model Updates: 594
Cumulative Timesteps: 5,001,926

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 5001926...
Checkpoint 5001926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.81750
Policy Entropy: 3.87084
Value Function Loss: 3.33895

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.16504
Policy Update Magnitude: 0.33827
Value Function Update Magnitude: 0.29298

Collected Steps per Second: 21,647.97586
Overall Steps per Second: 10,334.40468

Timestep Collection Time: 2.31015
Timestep Consumption Time: 2.52903
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.83918

Cumulative Model Updates: 600
Cumulative Timesteps: 5,051,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.35069
Policy Entropy: 3.86097
Value Function Loss: 3.31627

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10926
Policy Update Magnitude: 0.38021
Value Function Update Magnitude: 0.30898

Collected Steps per Second: 22,382.87142
Overall Steps per Second: 10,266.74699

Timestep Collection Time: 2.23466
Timestep Consumption Time: 2.63719
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.87185

Cumulative Model Updates: 606
Cumulative Timesteps: 5,101,954

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 5101954...
Checkpoint 5101954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.26761
Policy Entropy: 3.84103
Value Function Loss: 3.21244

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08667
Policy Update Magnitude: 0.48224
Value Function Update Magnitude: 0.27986

Collected Steps per Second: 21,726.43180
Overall Steps per Second: 10,259.67187

Timestep Collection Time: 2.30254
Timestep Consumption Time: 2.57344
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.87598

Cumulative Model Updates: 612
Cumulative Timesteps: 5,151,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.21325
Policy Entropy: 3.82506
Value Function Loss: 3.29210

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09320
Policy Update Magnitude: 0.48416
Value Function Update Magnitude: 0.25012

Collected Steps per Second: 22,608.75284
Overall Steps per Second: 10,243.65763

Timestep Collection Time: 2.21374
Timestep Consumption Time: 2.67221
PPO Batch Consumption Time: 0.30264
Total Iteration Time: 4.88595

Cumulative Model Updates: 618
Cumulative Timesteps: 5,202,030

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 5202030...
Checkpoint 5202030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.05735
Policy Entropy: 3.83080
Value Function Loss: 3.21118

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.43398
Value Function Update Magnitude: 0.28628

Collected Steps per Second: 22,342.34376
Overall Steps per Second: 10,019.16168

Timestep Collection Time: 2.23799
Timestep Consumption Time: 2.75264
PPO Batch Consumption Time: 0.31755
Total Iteration Time: 4.99064

Cumulative Model Updates: 624
Cumulative Timesteps: 5,252,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.90516
Policy Entropy: 3.81764
Value Function Loss: 3.20427

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08993
Policy Update Magnitude: 0.45687
Value Function Update Magnitude: 0.41219

Collected Steps per Second: 22,198.03907
Overall Steps per Second: 10,371.02308

Timestep Collection Time: 2.25299
Timestep Consumption Time: 2.56929
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.82228

Cumulative Model Updates: 630
Cumulative Timesteps: 5,302,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 5302044...
Checkpoint 5302044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.70772
Policy Entropy: 3.80766
Value Function Loss: 3.02950

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.46877
Value Function Update Magnitude: 0.41899

Collected Steps per Second: 21,999.61714
Overall Steps per Second: 10,221.09771

Timestep Collection Time: 2.27340
Timestep Consumption Time: 2.61981
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.89321

Cumulative Model Updates: 636
Cumulative Timesteps: 5,352,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.13924
Policy Entropy: 3.81447
Value Function Loss: 3.10177

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.39657
Value Function Update Magnitude: 0.42822

Collected Steps per Second: 21,817.70494
Overall Steps per Second: 10,163.12558

Timestep Collection Time: 2.29218
Timestep Consumption Time: 2.62856
PPO Batch Consumption Time: 0.29996
Total Iteration Time: 4.92073

Cumulative Model Updates: 642
Cumulative Timesteps: 5,402,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 5402068...
Checkpoint 5402068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.54532
Policy Entropy: 3.79994
Value Function Loss: 2.78184

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.35532
Value Function Update Magnitude: 0.45098

Collected Steps per Second: 22,933.73780
Overall Steps per Second: 10,318.04044

Timestep Collection Time: 2.18124
Timestep Consumption Time: 2.66697
PPO Batch Consumption Time: 0.30356
Total Iteration Time: 4.84821

Cumulative Model Updates: 648
Cumulative Timesteps: 5,452,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.22092
Policy Entropy: 3.79844
Value Function Loss: 2.77582

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.38788
Value Function Update Magnitude: 0.37727

Collected Steps per Second: 22,203.68560
Overall Steps per Second: 10,299.12737

Timestep Collection Time: 2.25224
Timestep Consumption Time: 2.60332
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.85556

Cumulative Model Updates: 654
Cumulative Timesteps: 5,502,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 5502100...
Checkpoint 5502100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.71019
Policy Entropy: 3.78610
Value Function Loss: 2.67250

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.11045
Policy Update Magnitude: 0.38112
Value Function Update Magnitude: 0.33012

Collected Steps per Second: 21,824.86678
Overall Steps per Second: 10,205.91140

Timestep Collection Time: 2.29280
Timestep Consumption Time: 2.61024
PPO Batch Consumption Time: 0.30547
Total Iteration Time: 4.90304

Cumulative Model Updates: 660
Cumulative Timesteps: 5,552,140

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.54957
Policy Entropy: 3.77658
Value Function Loss: 2.69770

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.39789
Value Function Update Magnitude: 0.37988

Collected Steps per Second: 21,955.68230
Overall Steps per Second: 10,029.11599

Timestep Collection Time: 2.27841
Timestep Consumption Time: 2.70947
PPO Batch Consumption Time: 0.30796
Total Iteration Time: 4.98788

Cumulative Model Updates: 666
Cumulative Timesteps: 5,602,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 5602164...
Checkpoint 5602164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.09133
Policy Entropy: 3.77793
Value Function Loss: 2.75415

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.42708
Value Function Update Magnitude: 0.35630

Collected Steps per Second: 22,072.87543
Overall Steps per Second: 10,284.15181

Timestep Collection Time: 2.26649
Timestep Consumption Time: 2.59808
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.86457

Cumulative Model Updates: 672
Cumulative Timesteps: 5,652,192

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.55896
Policy Entropy: 3.77170
Value Function Loss: 2.78643

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.48871
Value Function Update Magnitude: 0.35014

Collected Steps per Second: 22,159.79102
Overall Steps per Second: 10,052.07855

Timestep Collection Time: 2.25841
Timestep Consumption Time: 2.72026
PPO Batch Consumption Time: 0.30727
Total Iteration Time: 4.97867

Cumulative Model Updates: 678
Cumulative Timesteps: 5,702,238

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 5702238...
Checkpoint 5702238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.46789
Policy Entropy: 3.77423
Value Function Loss: 2.78680

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.47956
Value Function Update Magnitude: 0.34880

Collected Steps per Second: 21,956.53847
Overall Steps per Second: 10,152.95054

Timestep Collection Time: 2.27795
Timestep Consumption Time: 2.64830
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 4.92625

Cumulative Model Updates: 684
Cumulative Timesteps: 5,752,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.97170
Policy Entropy: 3.77338
Value Function Loss: 2.92639

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.41569
Value Function Update Magnitude: 0.36175

Collected Steps per Second: 22,359.62635
Overall Steps per Second: 10,339.77455

Timestep Collection Time: 2.23689
Timestep Consumption Time: 2.60035
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.83724

Cumulative Model Updates: 690
Cumulative Timesteps: 5,802,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 5802270...
Checkpoint 5802270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.04670
Policy Entropy: 3.77461
Value Function Loss: 2.83841

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.17328
Policy Update Magnitude: 0.38952
Value Function Update Magnitude: 0.38468

Collected Steps per Second: 22,662.19829
Overall Steps per Second: 10,297.16865

Timestep Collection Time: 2.20817
Timestep Consumption Time: 2.65161
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.85978

Cumulative Model Updates: 696
Cumulative Timesteps: 5,852,312

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.11031
Policy Entropy: 3.77655
Value Function Loss: 2.83405

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.24582
Policy Update Magnitude: 0.34700
Value Function Update Magnitude: 0.38454

Collected Steps per Second: 21,957.78772
Overall Steps per Second: 9,993.33438

Timestep Collection Time: 2.27783
Timestep Consumption Time: 2.72711
PPO Batch Consumption Time: 0.31002
Total Iteration Time: 5.00494

Cumulative Model Updates: 702
Cumulative Timesteps: 5,902,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 5902328...
Checkpoint 5902328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.16776
Policy Entropy: 3.76494
Value Function Loss: 2.78013

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14802
Policy Update Magnitude: 0.28339
Value Function Update Magnitude: 0.33839

Collected Steps per Second: 21,767.24425
Overall Steps per Second: 10,264.66642

Timestep Collection Time: 2.29703
Timestep Consumption Time: 2.57405
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.87108

Cumulative Model Updates: 708
Cumulative Timesteps: 5,952,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.43938
Policy Entropy: 3.76732
Value Function Loss: 2.82755

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.33717
Value Function Update Magnitude: 0.35868

Collected Steps per Second: 22,340.95509
Overall Steps per Second: 10,181.82881

Timestep Collection Time: 2.23974
Timestep Consumption Time: 2.67470
PPO Batch Consumption Time: 0.30192
Total Iteration Time: 4.91444

Cumulative Model Updates: 714
Cumulative Timesteps: 6,002,366

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 6002366...
Checkpoint 6002366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.24216
Policy Entropy: 3.74153
Value Function Loss: 2.90652

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.38707
Value Function Update Magnitude: 0.35801

Collected Steps per Second: 21,010.66005
Overall Steps per Second: 9,928.25982

Timestep Collection Time: 2.38041
Timestep Consumption Time: 2.65713
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 5.03754

Cumulative Model Updates: 720
Cumulative Timesteps: 6,052,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.37348
Policy Entropy: 3.75129
Value Function Loss: 2.78152

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09201
Policy Update Magnitude: 0.42226
Value Function Update Magnitude: 0.34910

Collected Steps per Second: 20,657.44989
Overall Steps per Second: 9,768.38277

Timestep Collection Time: 2.42218
Timestep Consumption Time: 2.70006
PPO Batch Consumption Time: 0.30565
Total Iteration Time: 5.12224

Cumulative Model Updates: 726
Cumulative Timesteps: 6,102,416

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 6102416...
Checkpoint 6102416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.26328
Policy Entropy: 3.73556
Value Function Loss: 2.80548

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.45478
Value Function Update Magnitude: 0.43045

Collected Steps per Second: 20,036.65856
Overall Steps per Second: 9,692.84330

Timestep Collection Time: 2.49622
Timestep Consumption Time: 2.66387
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 5.16010

Cumulative Model Updates: 732
Cumulative Timesteps: 6,152,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.23553
Policy Entropy: 3.73743
Value Function Loss: 2.96517

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.40916
Value Function Update Magnitude: 0.42392

Collected Steps per Second: 21,081.46642
Overall Steps per Second: 10,032.98745

Timestep Collection Time: 2.37308
Timestep Consumption Time: 2.61327
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.98635

Cumulative Model Updates: 738
Cumulative Timesteps: 6,202,460

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 6202460...
Checkpoint 6202460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.98637
Policy Entropy: 3.71702
Value Function Loss: 2.79896

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11340
Policy Update Magnitude: 0.38719
Value Function Update Magnitude: 0.36530

Collected Steps per Second: 21,457.20239
Overall Steps per Second: 9,323.28989

Timestep Collection Time: 2.33022
Timestep Consumption Time: 3.03269
PPO Batch Consumption Time: 0.35904
Total Iteration Time: 5.36291

Cumulative Model Updates: 744
Cumulative Timesteps: 6,252,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.52375
Policy Entropy: 3.69948
Value Function Loss: 2.77432

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.40417
Value Function Update Magnitude: 0.38526

Collected Steps per Second: 22,002.94507
Overall Steps per Second: 10,234.29116

Timestep Collection Time: 2.27451
Timestep Consumption Time: 2.61552
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.89003

Cumulative Model Updates: 750
Cumulative Timesteps: 6,302,506

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 6302506...
Checkpoint 6302506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.53618
Policy Entropy: 3.67896
Value Function Loss: 2.59816

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.15351
Policy Update Magnitude: 0.38765
Value Function Update Magnitude: 0.33979

Collected Steps per Second: 20,540.89884
Overall Steps per Second: 9,845.82181

Timestep Collection Time: 2.43553
Timestep Consumption Time: 2.64561
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 5.08114

Cumulative Model Updates: 756
Cumulative Timesteps: 6,352,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.05421
Policy Entropy: 3.69574
Value Function Loss: 2.49963

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.16382
Policy Update Magnitude: 0.34602
Value Function Update Magnitude: 0.33767

Collected Steps per Second: 21,649.44852
Overall Steps per Second: 10,116.80504

Timestep Collection Time: 2.31027
Timestep Consumption Time: 2.63359
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 4.94385

Cumulative Model Updates: 762
Cumulative Timesteps: 6,402,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 6402550...
Checkpoint 6402550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.55875
Policy Entropy: 3.68271
Value Function Loss: 2.43539

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14983
Policy Update Magnitude: 0.29394
Value Function Update Magnitude: 0.36072

Collected Steps per Second: 20,809.38141
Overall Steps per Second: 10,132.43549

Timestep Collection Time: 2.40517
Timestep Consumption Time: 2.53442
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.93958

Cumulative Model Updates: 768
Cumulative Timesteps: 6,452,600

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.15572
Policy Entropy: 3.68505
Value Function Loss: 2.61407

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14698
Policy Update Magnitude: 0.28093
Value Function Update Magnitude: 0.34436

Collected Steps per Second: 21,788.09807
Overall Steps per Second: 9,550.09269

Timestep Collection Time: 2.29575
Timestep Consumption Time: 2.94190
PPO Batch Consumption Time: 0.33660
Total Iteration Time: 5.23765

Cumulative Model Updates: 774
Cumulative Timesteps: 6,502,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 6502620...
Checkpoint 6502620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.81439
Policy Entropy: 3.65667
Value Function Loss: 2.52018

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.31252
Value Function Update Magnitude: 0.32573

Collected Steps per Second: 21,958.38112
Overall Steps per Second: 10,038.67227

Timestep Collection Time: 2.27749
Timestep Consumption Time: 2.70424
PPO Batch Consumption Time: 0.30911
Total Iteration Time: 4.98173

Cumulative Model Updates: 780
Cumulative Timesteps: 6,552,630

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.23712
Policy Entropy: 3.65588
Value Function Loss: 2.58990

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.19126
Policy Update Magnitude: 0.33298
Value Function Update Magnitude: 0.37295

Collected Steps per Second: 21,715.60295
Overall Steps per Second: 9,963.16048

Timestep Collection Time: 2.30397
Timestep Consumption Time: 2.71773
PPO Batch Consumption Time: 0.31372
Total Iteration Time: 5.02170

Cumulative Model Updates: 786
Cumulative Timesteps: 6,602,662

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 6602662...
Checkpoint 6602662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.97510
Policy Entropy: 3.69295
Value Function Loss: 2.95124

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.19428
Policy Update Magnitude: 0.28927
Value Function Update Magnitude: 0.33407

Collected Steps per Second: 21,573.93209
Overall Steps per Second: 10,138.50664

Timestep Collection Time: 2.31928
Timestep Consumption Time: 2.61596
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.93524

Cumulative Model Updates: 792
Cumulative Timesteps: 6,652,698

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.76136
Policy Entropy: 3.71054
Value Function Loss: 3.03118

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10858
Policy Update Magnitude: 0.29714
Value Function Update Magnitude: 0.35123

Collected Steps per Second: 20,806.15105
Overall Steps per Second: 9,706.51579

Timestep Collection Time: 2.40544
Timestep Consumption Time: 2.75068
PPO Batch Consumption Time: 0.32730
Total Iteration Time: 5.15612

Cumulative Model Updates: 798
Cumulative Timesteps: 6,702,746

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 6702746...
Checkpoint 6702746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.75182
Policy Entropy: 3.67685
Value Function Loss: 2.98331

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.35119
Value Function Update Magnitude: 0.26582

Collected Steps per Second: 19,291.01284
Overall Steps per Second: 9,520.17920

Timestep Collection Time: 2.59230
Timestep Consumption Time: 2.66055
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 5.25284

Cumulative Model Updates: 804
Cumulative Timesteps: 6,752,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.87415
Policy Entropy: 3.67391
Value Function Loss: 2.80714

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.36911
Value Function Update Magnitude: 0.24092

Collected Steps per Second: 22,015.40303
Overall Steps per Second: 9,996.42411

Timestep Collection Time: 2.27141
Timestep Consumption Time: 2.73098
PPO Batch Consumption Time: 0.31657
Total Iteration Time: 5.00239

Cumulative Model Updates: 810
Cumulative Timesteps: 6,802,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 6802760...
Checkpoint 6802760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.72671
Policy Entropy: 3.66335
Value Function Loss: 2.82554

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.39208
Value Function Update Magnitude: 0.22427

Collected Steps per Second: 21,488.72014
Overall Steps per Second: 10,173.29261

Timestep Collection Time: 2.32727
Timestep Consumption Time: 2.58855
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.91581

Cumulative Model Updates: 816
Cumulative Timesteps: 6,852,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.12246
Policy Entropy: 3.65983
Value Function Loss: 2.73515

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12468
Policy Update Magnitude: 0.39573
Value Function Update Magnitude: 0.24351

Collected Steps per Second: 20,711.53791
Overall Steps per Second: 9,502.52005

Timestep Collection Time: 2.41450
Timestep Consumption Time: 2.84810
PPO Batch Consumption Time: 0.32372
Total Iteration Time: 5.26260

Cumulative Model Updates: 822
Cumulative Timesteps: 6,902,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 6902778...
Checkpoint 6902778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.29435
Policy Entropy: 3.66094
Value Function Loss: 2.77419

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.38012
Value Function Update Magnitude: 0.27215

Collected Steps per Second: 19,466.17393
Overall Steps per Second: 8,865.28074

Timestep Collection Time: 2.57010
Timestep Consumption Time: 3.07326
PPO Batch Consumption Time: 0.36034
Total Iteration Time: 5.64336

Cumulative Model Updates: 828
Cumulative Timesteps: 6,952,808

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.33006
Policy Entropy: 3.65168
Value Function Loss: 2.69381

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.45009
Value Function Update Magnitude: 0.28253

Collected Steps per Second: 20,877.38544
Overall Steps per Second: 10,045.48210

Timestep Collection Time: 2.39513
Timestep Consumption Time: 2.58263
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.97776

Cumulative Model Updates: 834
Cumulative Timesteps: 7,002,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 7002812...
Checkpoint 7002812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.52239
Policy Entropy: 3.62477
Value Function Loss: 2.56432

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.39461
Value Function Update Magnitude: 0.30842

Collected Steps per Second: 22,081.29522
Overall Steps per Second: 10,269.53346

Timestep Collection Time: 2.26445
Timestep Consumption Time: 2.60451
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.86897

Cumulative Model Updates: 840
Cumulative Timesteps: 7,052,814

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.84895
Policy Entropy: 3.65073
Value Function Loss: 2.58065

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.34944
Value Function Update Magnitude: 0.34509

Collected Steps per Second: 22,107.49521
Overall Steps per Second: 10,425.03268

Timestep Collection Time: 2.26358
Timestep Consumption Time: 2.53660
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.80018

Cumulative Model Updates: 846
Cumulative Timesteps: 7,102,856

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 7102856...
Checkpoint 7102856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.96255
Policy Entropy: 3.63617
Value Function Loss: 2.47386

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.33633
Value Function Update Magnitude: 0.31057

Collected Steps per Second: 21,917.69677
Overall Steps per Second: 10,141.70374

Timestep Collection Time: 2.28126
Timestep Consumption Time: 2.64888
PPO Batch Consumption Time: 0.29866
Total Iteration Time: 4.93014

Cumulative Model Updates: 852
Cumulative Timesteps: 7,152,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.42501
Policy Entropy: 3.60885
Value Function Loss: 2.47806

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.34867
Value Function Update Magnitude: 0.49843

Collected Steps per Second: 21,678.93390
Overall Steps per Second: 10,090.59013

Timestep Collection Time: 2.30676
Timestep Consumption Time: 2.64915
PPO Batch Consumption Time: 0.29752
Total Iteration Time: 4.95590

Cumulative Model Updates: 858
Cumulative Timesteps: 7,202,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 7202864...
Checkpoint 7202864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.18706
Policy Entropy: 3.59047
Value Function Loss: 2.60820

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12627
Policy Update Magnitude: 0.37746
Value Function Update Magnitude: 0.43079

Collected Steps per Second: 21,819.42973
Overall Steps per Second: 10,130.19345

Timestep Collection Time: 2.29154
Timestep Consumption Time: 2.64420
PPO Batch Consumption Time: 0.31115
Total Iteration Time: 4.93574

Cumulative Model Updates: 864
Cumulative Timesteps: 7,252,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.39944
Policy Entropy: 3.60056
Value Function Loss: 2.57430

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08679
Policy Update Magnitude: 0.42853
Value Function Update Magnitude: 0.37585

Collected Steps per Second: 22,379.39792
Overall Steps per Second: 10,075.10555

Timestep Collection Time: 2.23456
Timestep Consumption Time: 2.72897
PPO Batch Consumption Time: 0.31164
Total Iteration Time: 4.96352

Cumulative Model Updates: 870
Cumulative Timesteps: 7,302,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 7302872...
Checkpoint 7302872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.14085
Policy Entropy: 3.59362
Value Function Loss: 2.65328

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10260
Policy Update Magnitude: 0.46308
Value Function Update Magnitude: 0.40799

Collected Steps per Second: 22,026.10485
Overall Steps per Second: 10,288.95931

Timestep Collection Time: 2.27094
Timestep Consumption Time: 2.59058
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.86152

Cumulative Model Updates: 876
Cumulative Timesteps: 7,352,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.20076
Policy Entropy: 3.57920
Value Function Loss: 2.66714

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.39352
Value Function Update Magnitude: 0.44025

Collected Steps per Second: 22,759.04882
Overall Steps per Second: 10,444.74879

Timestep Collection Time: 2.19719
Timestep Consumption Time: 2.59048
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.78767

Cumulative Model Updates: 882
Cumulative Timesteps: 7,402,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 7402898...
Checkpoint 7402898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.24412
Policy Entropy: 3.59705
Value Function Loss: 2.63916

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11626
Policy Update Magnitude: 0.35649
Value Function Update Magnitude: 0.40502

Collected Steps per Second: 20,119.35073
Overall Steps per Second: 9,698.65726

Timestep Collection Time: 2.48577
Timestep Consumption Time: 2.67082
PPO Batch Consumption Time: 0.30627
Total Iteration Time: 5.15659

Cumulative Model Updates: 888
Cumulative Timesteps: 7,452,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.73744
Policy Entropy: 3.56835
Value Function Loss: 2.73730

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.33777
Value Function Update Magnitude: 0.40934

Collected Steps per Second: 21,710.64343
Overall Steps per Second: 10,163.29836

Timestep Collection Time: 2.30311
Timestep Consumption Time: 2.61675
PPO Batch Consumption Time: 0.30320
Total Iteration Time: 4.91986

Cumulative Model Updates: 894
Cumulative Timesteps: 7,502,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 7502912...
Checkpoint 7502912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.27251
Policy Entropy: 3.58123
Value Function Loss: 2.67160

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12338
Policy Update Magnitude: 0.33737
Value Function Update Magnitude: 0.37819

Collected Steps per Second: 21,775.85674
Overall Steps per Second: 10,204.70407

Timestep Collection Time: 2.29630
Timestep Consumption Time: 2.60379
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.90009

Cumulative Model Updates: 900
Cumulative Timesteps: 7,552,916

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.88378
Policy Entropy: 3.55856
Value Function Loss: 2.66536

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.36210
Value Function Update Magnitude: 0.42430

Collected Steps per Second: 22,214.98501
Overall Steps per Second: 10,343.40840

Timestep Collection Time: 2.25163
Timestep Consumption Time: 2.58430
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.83593

Cumulative Model Updates: 906
Cumulative Timesteps: 7,602,936

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 7602936...
Checkpoint 7602936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.71823
Policy Entropy: 3.55364
Value Function Loss: 2.59073

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.36666
Value Function Update Magnitude: 0.54497

Collected Steps per Second: 21,273.43976
Overall Steps per Second: 10,265.49472

Timestep Collection Time: 2.35082
Timestep Consumption Time: 2.52084
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.87166

Cumulative Model Updates: 912
Cumulative Timesteps: 7,652,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.30692
Policy Entropy: 3.55483
Value Function Loss: 2.62940

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.38857
Value Function Update Magnitude: 0.48291

Collected Steps per Second: 22,442.22858
Overall Steps per Second: 9,783.82057

Timestep Collection Time: 2.22830
Timestep Consumption Time: 2.88300
PPO Batch Consumption Time: 0.32921
Total Iteration Time: 5.11130

Cumulative Model Updates: 918
Cumulative Timesteps: 7,702,954

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 7702954...
Checkpoint 7702954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.50745
Policy Entropy: 3.54876
Value Function Loss: 2.58234

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.35342
Value Function Update Magnitude: 0.42751

Collected Steps per Second: 21,558.59019
Overall Steps per Second: 9,846.92160

Timestep Collection Time: 2.31963
Timestep Consumption Time: 2.75891
PPO Batch Consumption Time: 0.31769
Total Iteration Time: 5.07854

Cumulative Model Updates: 924
Cumulative Timesteps: 7,752,962

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.34660
Policy Entropy: 3.54898
Value Function Loss: 2.64088

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.11061
Policy Update Magnitude: 0.35797
Value Function Update Magnitude: 0.36732

Collected Steps per Second: 22,819.93023
Overall Steps per Second: 10,172.16893

Timestep Collection Time: 2.19133
Timestep Consumption Time: 2.72463
PPO Batch Consumption Time: 0.31002
Total Iteration Time: 4.91596

Cumulative Model Updates: 930
Cumulative Timesteps: 7,802,968

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 7802968...
Checkpoint 7802968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.74991
Policy Entropy: 3.53605
Value Function Loss: 2.56517

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.20717
Policy Update Magnitude: 0.37318
Value Function Update Magnitude: 0.34200

Collected Steps per Second: 21,839.55683
Overall Steps per Second: 10,230.43584

Timestep Collection Time: 2.28961
Timestep Consumption Time: 2.59816
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.88777

Cumulative Model Updates: 936
Cumulative Timesteps: 7,852,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.80821
Policy Entropy: 3.53520
Value Function Loss: 2.64635

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.23600
Policy Update Magnitude: 0.32297
Value Function Update Magnitude: 0.34253

Collected Steps per Second: 22,049.16697
Overall Steps per Second: 10,160.43155

Timestep Collection Time: 2.26956
Timestep Consumption Time: 2.65562
PPO Batch Consumption Time: 0.30468
Total Iteration Time: 4.92518

Cumulative Model Updates: 942
Cumulative Timesteps: 7,903,014

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 7903014...
Checkpoint 7903014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.29180
Policy Entropy: 3.53741
Value Function Loss: 2.52236

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.32413
Value Function Update Magnitude: 0.36404

Collected Steps per Second: 22,587.75904
Overall Steps per Second: 10,142.20893

Timestep Collection Time: 2.21412
Timestep Consumption Time: 2.71696
PPO Batch Consumption Time: 0.30869
Total Iteration Time: 4.93108

Cumulative Model Updates: 948
Cumulative Timesteps: 7,953,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.21405
Policy Entropy: 3.52174
Value Function Loss: 2.42751

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11371
Policy Update Magnitude: 0.37457
Value Function Update Magnitude: 0.41886

Collected Steps per Second: 22,380.92251
Overall Steps per Second: 10,302.96351

Timestep Collection Time: 2.23530
Timestep Consumption Time: 2.62039
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.85569

Cumulative Model Updates: 954
Cumulative Timesteps: 8,003,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 8003054...
Checkpoint 8003054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.85652
Policy Entropy: 3.51067
Value Function Loss: 2.40529

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.37068
Value Function Update Magnitude: 0.40343

Collected Steps per Second: 21,393.89522
Overall Steps per Second: 10,029.32375

Timestep Collection Time: 2.33777
Timestep Consumption Time: 2.64901
PPO Batch Consumption Time: 0.30591
Total Iteration Time: 4.98678

Cumulative Model Updates: 960
Cumulative Timesteps: 8,053,068

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.43316
Policy Entropy: 3.51766
Value Function Loss: 2.67194

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15599
Policy Update Magnitude: 0.35476
Value Function Update Magnitude: 0.32232

Collected Steps per Second: 22,605.17501
Overall Steps per Second: 10,353.99329

Timestep Collection Time: 2.21259
Timestep Consumption Time: 2.61801
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.83060

Cumulative Model Updates: 966
Cumulative Timesteps: 8,103,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 8103084...
Checkpoint 8103084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.67126
Policy Entropy: 3.52155
Value Function Loss: 2.63245

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.34025
Value Function Update Magnitude: 0.32052

Collected Steps per Second: 21,428.73688
Overall Steps per Second: 10,001.17041

Timestep Collection Time: 2.33556
Timestep Consumption Time: 2.66866
PPO Batch Consumption Time: 0.30071
Total Iteration Time: 5.00421

Cumulative Model Updates: 972
Cumulative Timesteps: 8,153,132

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.58068
Policy Entropy: 3.52108
Value Function Loss: 2.69039

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12165
Policy Update Magnitude: 0.32712
Value Function Update Magnitude: 0.30385

Collected Steps per Second: 22,091.40018
Overall Steps per Second: 10,123.70669

Timestep Collection Time: 2.26450
Timestep Consumption Time: 2.67697
PPO Batch Consumption Time: 0.31624
Total Iteration Time: 4.94147

Cumulative Model Updates: 978
Cumulative Timesteps: 8,203,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 8203158...
Checkpoint 8203158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.55353
Policy Entropy: 3.51377
Value Function Loss: 2.50398

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.34864
Value Function Update Magnitude: 0.30374

Collected Steps per Second: 21,773.50083
Overall Steps per Second: 10,162.29770

Timestep Collection Time: 2.29729
Timestep Consumption Time: 2.62483
PPO Batch Consumption Time: 0.29602
Total Iteration Time: 4.92212

Cumulative Model Updates: 984
Cumulative Timesteps: 8,253,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.52805
Policy Entropy: 3.51721
Value Function Loss: 2.65680

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13079
Policy Update Magnitude: 0.34368
Value Function Update Magnitude: 0.33351

Collected Steps per Second: 21,008.34513
Overall Steps per Second: 10,029.74073

Timestep Collection Time: 2.38096
Timestep Consumption Time: 2.60621
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.98717

Cumulative Model Updates: 990
Cumulative Timesteps: 8,303,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 8303198...
Checkpoint 8303198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.19348
Policy Entropy: 3.50521
Value Function Loss: 2.55058

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.17410
Policy Update Magnitude: 0.30808
Value Function Update Magnitude: 0.29166

Collected Steps per Second: 21,770.57446
Overall Steps per Second: 9,991.07821

Timestep Collection Time: 2.29787
Timestep Consumption Time: 2.70919
PPO Batch Consumption Time: 0.31692
Total Iteration Time: 5.00707

Cumulative Model Updates: 996
Cumulative Timesteps: 8,353,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.52335
Policy Entropy: 3.48957
Value Function Loss: 2.63561

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.30275
Value Function Update Magnitude: 0.28989

Collected Steps per Second: 21,447.79247
Overall Steps per Second: 9,997.90346

Timestep Collection Time: 2.33171
Timestep Consumption Time: 2.67034
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 5.00205

Cumulative Model Updates: 1,002
Cumulative Timesteps: 8,403,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 8403234...
Checkpoint 8403234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.82588
Policy Entropy: 3.45947
Value Function Loss: 2.50594

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.35828
Value Function Update Magnitude: 0.33714

Collected Steps per Second: 21,192.42928
Overall Steps per Second: 9,716.21476

Timestep Collection Time: 2.35971
Timestep Consumption Time: 2.78715
PPO Batch Consumption Time: 0.32636
Total Iteration Time: 5.14686

Cumulative Model Updates: 1,008
Cumulative Timesteps: 8,453,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.85082
Policy Entropy: 3.44823
Value Function Loss: 2.47112

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.35024
Value Function Update Magnitude: 0.44385

Collected Steps per Second: 22,655.55033
Overall Steps per Second: 10,151.41914

Timestep Collection Time: 2.20741
Timestep Consumption Time: 2.71900
PPO Batch Consumption Time: 0.30985
Total Iteration Time: 4.92640

Cumulative Model Updates: 1,014
Cumulative Timesteps: 8,503,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 8503252...
Checkpoint 8503252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.64902
Policy Entropy: 3.45626
Value Function Loss: 2.45033

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.12144
Policy Update Magnitude: 0.36341
Value Function Update Magnitude: 0.46166

Collected Steps per Second: 21,988.88807
Overall Steps per Second: 9,964.37529

Timestep Collection Time: 2.27424
Timestep Consumption Time: 2.74444
PPO Batch Consumption Time: 0.30955
Total Iteration Time: 5.01868

Cumulative Model Updates: 1,020
Cumulative Timesteps: 8,553,260

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.06492
Policy Entropy: 3.44783
Value Function Loss: 2.41532

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12318
Policy Update Magnitude: 0.33509
Value Function Update Magnitude: 0.45014

Collected Steps per Second: 21,504.01413
Overall Steps per Second: 10,177.13379

Timestep Collection Time: 2.32701
Timestep Consumption Time: 2.58990
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.91690

Cumulative Model Updates: 1,026
Cumulative Timesteps: 8,603,300

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 8603300...
Checkpoint 8603300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398.25946
Policy Entropy: 3.44842
Value Function Loss: 2.45745

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11976
Policy Update Magnitude: 0.34042
Value Function Update Magnitude: 0.43841

Collected Steps per Second: 21,625.06826
Overall Steps per Second: 9,953.88535

Timestep Collection Time: 2.31232
Timestep Consumption Time: 2.71125
PPO Batch Consumption Time: 0.30428
Total Iteration Time: 5.02357

Cumulative Model Updates: 1,032
Cumulative Timesteps: 8,653,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.55378
Policy Entropy: 3.44525
Value Function Loss: 2.41000

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10332
Policy Update Magnitude: 0.37428
Value Function Update Magnitude: 0.36577

Collected Steps per Second: 20,388.01473
Overall Steps per Second: 9,860.15861

Timestep Collection Time: 2.45311
Timestep Consumption Time: 2.61922
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 5.07233

Cumulative Model Updates: 1,038
Cumulative Timesteps: 8,703,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 8703318...
Checkpoint 8703318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.31615
Policy Entropy: 3.41294
Value Function Loss: 2.40861

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.39671
Value Function Update Magnitude: 0.34973

Collected Steps per Second: 21,621.48606
Overall Steps per Second: 10,332.93013

Timestep Collection Time: 2.31270
Timestep Consumption Time: 2.52659
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.83929

Cumulative Model Updates: 1,044
Cumulative Timesteps: 8,753,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.64580
Policy Entropy: 3.40781
Value Function Loss: 2.31357

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12088
Policy Update Magnitude: 0.37873
Value Function Update Magnitude: 0.35516

Collected Steps per Second: 22,217.04312
Overall Steps per Second: 10,258.77676

Timestep Collection Time: 2.25178
Timestep Consumption Time: 2.62482
PPO Batch Consumption Time: 0.29736
Total Iteration Time: 4.87660

Cumulative Model Updates: 1,050
Cumulative Timesteps: 8,803,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 8803350...
Checkpoint 8803350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.76275
Policy Entropy: 3.39853
Value Function Loss: 2.36419

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.34992
Value Function Update Magnitude: 0.39444

Collected Steps per Second: 19,467.09035
Overall Steps per Second: 9,423.77507

Timestep Collection Time: 2.56967
Timestep Consumption Time: 2.73861
PPO Batch Consumption Time: 0.30710
Total Iteration Time: 5.30828

Cumulative Model Updates: 1,056
Cumulative Timesteps: 8,853,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.30852
Policy Entropy: 3.41208
Value Function Loss: 2.33567

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11614
Policy Update Magnitude: 0.36037
Value Function Update Magnitude: 0.40542

Collected Steps per Second: 21,754.03744
Overall Steps per Second: 9,918.64986

Timestep Collection Time: 2.29962
Timestep Consumption Time: 2.74401
PPO Batch Consumption Time: 0.31331
Total Iteration Time: 5.04363

Cumulative Model Updates: 1,062
Cumulative Timesteps: 8,903,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 8903400...
Checkpoint 8903400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.62377
Policy Entropy: 3.41000
Value Function Loss: 2.32593

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.37298
Value Function Update Magnitude: 0.35291

Collected Steps per Second: 22,064.50115
Overall Steps per Second: 9,979.54252

Timestep Collection Time: 2.26690
Timestep Consumption Time: 2.74515
PPO Batch Consumption Time: 0.30651
Total Iteration Time: 5.01205

Cumulative Model Updates: 1,068
Cumulative Timesteps: 8,953,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.75520
Policy Entropy: 3.42062
Value Function Loss: 2.31699

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.32785
Value Function Update Magnitude: 0.35948

Collected Steps per Second: 20,245.04575
Overall Steps per Second: 9,630.71893

Timestep Collection Time: 2.47102
Timestep Consumption Time: 2.72340
PPO Batch Consumption Time: 0.30054
Total Iteration Time: 5.19442

Cumulative Model Updates: 1,074
Cumulative Timesteps: 9,003,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 9003444...
Checkpoint 9003444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.57702
Policy Entropy: 3.39899
Value Function Loss: 2.23332

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.30913
Value Function Update Magnitude: 0.36896

Collected Steps per Second: 20,750.92794
Overall Steps per Second: 9,979.19711

Timestep Collection Time: 2.41107
Timestep Consumption Time: 2.60256
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 5.01363

Cumulative Model Updates: 1,080
Cumulative Timesteps: 9,053,476

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.20847
Policy Entropy: 3.38638
Value Function Loss: 2.25205

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15182
Policy Update Magnitude: 0.33452
Value Function Update Magnitude: 0.34215

Collected Steps per Second: 20,625.92710
Overall Steps per Second: 9,877.58335

Timestep Collection Time: 2.42598
Timestep Consumption Time: 2.63984
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 5.06581

Cumulative Model Updates: 1,086
Cumulative Timesteps: 9,103,514

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 9103514...
Checkpoint 9103514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.12924
Policy Entropy: 3.37121
Value Function Loss: 2.20678

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13797
Policy Update Magnitude: 0.34873
Value Function Update Magnitude: 0.34191

Collected Steps per Second: 21,764.76325
Overall Steps per Second: 10,372.84261

Timestep Collection Time: 2.29775
Timestep Consumption Time: 2.52349
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.82124

Cumulative Model Updates: 1,092
Cumulative Timesteps: 9,153,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.44040
Policy Entropy: 3.36682
Value Function Loss: 2.18555

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11328
Policy Update Magnitude: 0.34270
Value Function Update Magnitude: 0.33372

Collected Steps per Second: 22,024.13519
Overall Steps per Second: 10,022.57304

Timestep Collection Time: 2.27024
Timestep Consumption Time: 2.71850
PPO Batch Consumption Time: 0.30905
Total Iteration Time: 4.98874

Cumulative Model Updates: 1,098
Cumulative Timesteps: 9,203,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 9203524...
Checkpoint 9203524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.52389
Policy Entropy: 3.35127
Value Function Loss: 2.23853

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12417
Policy Update Magnitude: 0.34201
Value Function Update Magnitude: 0.30733

Collected Steps per Second: 21,852.83167
Overall Steps per Second: 10,082.73489

Timestep Collection Time: 2.28803
Timestep Consumption Time: 2.67094
PPO Batch Consumption Time: 0.30494
Total Iteration Time: 4.95897

Cumulative Model Updates: 1,104
Cumulative Timesteps: 9,253,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.61304
Policy Entropy: 3.33534
Value Function Loss: 2.19391

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.32327
Value Function Update Magnitude: 0.28196

Collected Steps per Second: 19,251.73324
Overall Steps per Second: 9,741.48122

Timestep Collection Time: 2.59758
Timestep Consumption Time: 2.53593
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 5.13351

Cumulative Model Updates: 1,110
Cumulative Timesteps: 9,303,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 9303532...
Checkpoint 9303532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.64098
Policy Entropy: 3.33872
Value Function Loss: 2.27364

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11927
Policy Update Magnitude: 0.31777
Value Function Update Magnitude: 0.28826

Collected Steps per Second: 22,059.83475
Overall Steps per Second: 10,256.00644

Timestep Collection Time: 2.26720
Timestep Consumption Time: 2.60936
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.87656

Cumulative Model Updates: 1,116
Cumulative Timesteps: 9,353,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.48020
Policy Entropy: 3.33978
Value Function Loss: 2.23224

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.11713
Policy Update Magnitude: 0.32087
Value Function Update Magnitude: 0.28985

Collected Steps per Second: 22,243.14134
Overall Steps per Second: 10,240.42710

Timestep Collection Time: 2.24887
Timestep Consumption Time: 2.63588
PPO Batch Consumption Time: 0.30033
Total Iteration Time: 4.88476

Cumulative Model Updates: 1,122
Cumulative Timesteps: 9,403,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 9403568...
Checkpoint 9403568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.53946
Policy Entropy: 3.32353
Value Function Loss: 2.25329

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.40971
Value Function Update Magnitude: 0.31751

Collected Steps per Second: 22,653.67876
Overall Steps per Second: 10,267.54012

Timestep Collection Time: 2.20927
Timestep Consumption Time: 2.66512
PPO Batch Consumption Time: 0.30091
Total Iteration Time: 4.87439

Cumulative Model Updates: 1,128
Cumulative Timesteps: 9,453,616

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.56214
Policy Entropy: 3.30806
Value Function Loss: 2.22333

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.43508
Value Function Update Magnitude: 0.32119

Collected Steps per Second: 20,309.63504
Overall Steps per Second: 9,716.51104

Timestep Collection Time: 2.46267
Timestep Consumption Time: 2.68485
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 5.14753

Cumulative Model Updates: 1,134
Cumulative Timesteps: 9,503,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 9503632...
Checkpoint 9503632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.08966
Policy Entropy: 3.31854
Value Function Loss: 2.23201

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.44182
Value Function Update Magnitude: 0.31206

Collected Steps per Second: 20,717.24568
Overall Steps per Second: 9,967.49195

Timestep Collection Time: 2.41412
Timestep Consumption Time: 2.60359
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 5.01771

Cumulative Model Updates: 1,140
Cumulative Timesteps: 9,553,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.52097
Policy Entropy: 3.32473
Value Function Loss: 2.22821

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.36360
Value Function Update Magnitude: 0.31171

Collected Steps per Second: 21,769.32802
Overall Steps per Second: 10,223.89809

Timestep Collection Time: 2.29690
Timestep Consumption Time: 2.59380
PPO Batch Consumption Time: 0.30135
Total Iteration Time: 4.89070

Cumulative Model Updates: 1,146
Cumulative Timesteps: 9,603,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 9603648...
Checkpoint 9603648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.18840
Policy Entropy: 3.31772
Value Function Loss: 2.21789

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.31043
Value Function Update Magnitude: 0.30214

Collected Steps per Second: 20,461.59330
Overall Steps per Second: 9,803.66343

Timestep Collection Time: 2.44566
Timestep Consumption Time: 2.65876
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 5.10442

Cumulative Model Updates: 1,152
Cumulative Timesteps: 9,653,690

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.96922
Policy Entropy: 3.32962
Value Function Loss: 2.19834

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11974
Policy Update Magnitude: 0.33673
Value Function Update Magnitude: 0.30586

Collected Steps per Second: 21,413.02783
Overall Steps per Second: 10,018.75071

Timestep Collection Time: 2.33615
Timestep Consumption Time: 2.65689
PPO Batch Consumption Time: 0.30265
Total Iteration Time: 4.99304

Cumulative Model Updates: 1,158
Cumulative Timesteps: 9,703,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 9703714...
Checkpoint 9703714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.35996
Policy Entropy: 3.31926
Value Function Loss: 2.21469

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11418
Policy Update Magnitude: 0.34276
Value Function Update Magnitude: 0.32922

Collected Steps per Second: 21,536.27742
Overall Steps per Second: 10,142.82971

Timestep Collection Time: 2.32278
Timestep Consumption Time: 2.60918
PPO Batch Consumption Time: 0.30038
Total Iteration Time: 4.93196

Cumulative Model Updates: 1,164
Cumulative Timesteps: 9,753,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.01211
Policy Entropy: 3.31558
Value Function Loss: 2.15719

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.34595
Value Function Update Magnitude: 0.44564

Collected Steps per Second: 22,222.01887
Overall Steps per Second: 10,274.70848

Timestep Collection Time: 2.25119
Timestep Consumption Time: 2.61766
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.86885

Cumulative Model Updates: 1,170
Cumulative Timesteps: 9,803,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 9803764...
Checkpoint 9803764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.45529
Policy Entropy: 3.30401
Value Function Loss: 2.17154

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.33048
Value Function Update Magnitude: 0.44582

Collected Steps per Second: 21,789.79394
Overall Steps per Second: 10,262.36085

Timestep Collection Time: 2.29640
Timestep Consumption Time: 2.57948
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.87588

Cumulative Model Updates: 1,176
Cumulative Timesteps: 9,853,802

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.71377
Policy Entropy: 3.30368
Value Function Loss: 2.14017

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.31867
Value Function Update Magnitude: 0.36794

Collected Steps per Second: 21,922.75272
Overall Steps per Second: 10,374.06697

Timestep Collection Time: 2.28110
Timestep Consumption Time: 2.53938
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.82048

Cumulative Model Updates: 1,182
Cumulative Timesteps: 9,903,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 9903810...
Checkpoint 9903810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.45815
Policy Entropy: 3.30486
Value Function Loss: 2.07226

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.23061
Policy Update Magnitude: 0.28565
Value Function Update Magnitude: 0.35131

Collected Steps per Second: 21,945.24621
Overall Steps per Second: 10,201.79753

Timestep Collection Time: 2.27949
Timestep Consumption Time: 2.62396
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.90345

Cumulative Model Updates: 1,188
Cumulative Timesteps: 9,953,834

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.96605
Policy Entropy: 3.31750
Value Function Loss: 2.20830

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.17187
Policy Update Magnitude: 0.25530
Value Function Update Magnitude: 0.37117

Collected Steps per Second: 22,199.80768
Overall Steps per Second: 10,277.91238

Timestep Collection Time: 2.25290
Timestep Consumption Time: 2.61326
PPO Batch Consumption Time: 0.29861
Total Iteration Time: 4.86616

Cumulative Model Updates: 1,194
Cumulative Timesteps: 10,003,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 10003848...
Checkpoint 10003848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.16165
Policy Entropy: 3.30348
Value Function Loss: 2.24135

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.18010
Policy Update Magnitude: 0.26338
Value Function Update Magnitude: 0.33284

Collected Steps per Second: 21,861.65921
Overall Steps per Second: 10,405.91490

Timestep Collection Time: 2.28894
Timestep Consumption Time: 2.51986
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.80880

Cumulative Model Updates: 1,200
Cumulative Timesteps: 10,053,888

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.99908
Policy Entropy: 3.30048
Value Function Loss: 2.40532

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.15143
Policy Update Magnitude: 0.32637
Value Function Update Magnitude: 0.31992

Collected Steps per Second: 22,033.20156
Overall Steps per Second: 9,973.22157

Timestep Collection Time: 2.26939
Timestep Consumption Time: 2.74423
PPO Batch Consumption Time: 0.31409
Total Iteration Time: 5.01363

Cumulative Model Updates: 1,206
Cumulative Timesteps: 10,103,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 10103890...
Checkpoint 10103890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.10822
Policy Entropy: 3.28267
Value Function Loss: 2.34630

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.22861
Policy Update Magnitude: 0.34799
Value Function Update Magnitude: 0.32869

Collected Steps per Second: 20,695.64606
Overall Steps per Second: 9,572.52877

Timestep Collection Time: 2.41597
Timestep Consumption Time: 2.80731
PPO Batch Consumption Time: 0.32749
Total Iteration Time: 5.22328

Cumulative Model Updates: 1,212
Cumulative Timesteps: 10,153,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.42518
Policy Entropy: 3.28048
Value Function Loss: 2.40153

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.23945
Policy Update Magnitude: 0.31201
Value Function Update Magnitude: 0.35855

Collected Steps per Second: 21,761.95315
Overall Steps per Second: 10,381.43845

Timestep Collection Time: 2.29786
Timestep Consumption Time: 2.51900
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.81687

Cumulative Model Updates: 1,218
Cumulative Timesteps: 10,203,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 10203896...
Checkpoint 10203896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.91176
Policy Entropy: 3.26101
Value Function Loss: 2.40673

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.17077
Policy Update Magnitude: 0.28935
Value Function Update Magnitude: 0.38218

Collected Steps per Second: 21,690.60931
Overall Steps per Second: 9,976.14185

Timestep Collection Time: 2.30644
Timestep Consumption Time: 2.70833
PPO Batch Consumption Time: 0.30706
Total Iteration Time: 5.01476

Cumulative Model Updates: 1,224
Cumulative Timesteps: 10,253,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.85501
Policy Entropy: 3.23357
Value Function Loss: 2.34810

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.33937
Value Function Update Magnitude: 0.45391

Collected Steps per Second: 21,359.49195
Overall Steps per Second: 9,881.45416

Timestep Collection Time: 2.34182
Timestep Consumption Time: 2.72019
PPO Batch Consumption Time: 0.31153
Total Iteration Time: 5.06201

Cumulative Model Updates: 1,230
Cumulative Timesteps: 10,303,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 10303944...
Checkpoint 10303944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.60553
Policy Entropy: 3.24362
Value Function Loss: 2.30495

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.39156
Value Function Update Magnitude: 0.44115

Collected Steps per Second: 20,920.63772
Overall Steps per Second: 9,795.54109

Timestep Collection Time: 2.39094
Timestep Consumption Time: 2.71546
PPO Batch Consumption Time: 0.30982
Total Iteration Time: 5.10640

Cumulative Model Updates: 1,236
Cumulative Timesteps: 10,353,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.98399
Policy Entropy: 3.23734
Value Function Loss: 2.22527

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.19940
Policy Update Magnitude: 0.33157
Value Function Update Magnitude: 0.38934

Collected Steps per Second: 22,231.50498
Overall Steps per Second: 10,274.66964

Timestep Collection Time: 2.25005
Timestep Consumption Time: 2.61843
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.86848

Cumulative Model Updates: 1,242
Cumulative Timesteps: 10,403,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 10403986...
Checkpoint 10403986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.32278
Policy Entropy: 3.23880
Value Function Loss: 2.26979

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.27824
Value Function Update Magnitude: 0.42383

Collected Steps per Second: 21,715.82558
Overall Steps per Second: 10,052.41409

Timestep Collection Time: 2.30247
Timestep Consumption Time: 2.67146
PPO Batch Consumption Time: 0.30713
Total Iteration Time: 4.97393

Cumulative Model Updates: 1,248
Cumulative Timesteps: 10,453,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.20535
Policy Entropy: 3.23737
Value Function Loss: 2.19368

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.34442
Value Function Update Magnitude: 0.41804

Collected Steps per Second: 20,886.74128
Overall Steps per Second: 10,012.12390

Timestep Collection Time: 2.39520
Timestep Consumption Time: 2.60154
PPO Batch Consumption Time: 0.29854
Total Iteration Time: 4.99674

Cumulative Model Updates: 1,254
Cumulative Timesteps: 10,504,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 10504014...
Checkpoint 10504014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.74614
Policy Entropy: 3.21872
Value Function Loss: 2.17402

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.38315
Value Function Update Magnitude: 0.43511

Collected Steps per Second: 22,070.38244
Overall Steps per Second: 10,007.14261

Timestep Collection Time: 2.26620
Timestep Consumption Time: 2.73183
PPO Batch Consumption Time: 0.31238
Total Iteration Time: 4.99803

Cumulative Model Updates: 1,260
Cumulative Timesteps: 10,554,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.93830
Policy Entropy: 3.20900
Value Function Loss: 2.11005

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12226
Policy Update Magnitude: 0.42801
Value Function Update Magnitude: 0.44335

Collected Steps per Second: 21,843.83705
Overall Steps per Second: 9,935.29145

Timestep Collection Time: 2.28907
Timestep Consumption Time: 2.74370
PPO Batch Consumption Time: 0.31679
Total Iteration Time: 5.03277

Cumulative Model Updates: 1,266
Cumulative Timesteps: 10,604,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 10604032...
Checkpoint 10604032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.25538
Policy Entropy: 3.18838
Value Function Loss: 2.11505

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.16867
Policy Update Magnitude: 0.33012
Value Function Update Magnitude: 0.51381

Collected Steps per Second: 20,898.65469
Overall Steps per Second: 9,975.67959

Timestep Collection Time: 2.39288
Timestep Consumption Time: 2.62011
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 5.01299

Cumulative Model Updates: 1,272
Cumulative Timesteps: 10,654,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.29331
Policy Entropy: 3.18531
Value Function Loss: 2.08354

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13932
Policy Update Magnitude: 0.27068
Value Function Update Magnitude: 0.40095

Collected Steps per Second: 22,307.87734
Overall Steps per Second: 10,093.23050

Timestep Collection Time: 2.24199
Timestep Consumption Time: 2.71321
PPO Batch Consumption Time: 0.31033
Total Iteration Time: 4.95520

Cumulative Model Updates: 1,278
Cumulative Timesteps: 10,704,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 10704054...
Checkpoint 10704054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.88878
Policy Entropy: 3.19162
Value Function Loss: 1.99889

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.29429
Value Function Update Magnitude: 0.31440

Collected Steps per Second: 21,923.19876
Overall Steps per Second: 10,244.68358

Timestep Collection Time: 2.28142
Timestep Consumption Time: 2.60072
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.88214

Cumulative Model Updates: 1,284
Cumulative Timesteps: 10,754,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.95410
Policy Entropy: 3.20464
Value Function Loss: 1.97225

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.30674
Value Function Update Magnitude: 0.30748

Collected Steps per Second: 22,076.77259
Overall Steps per Second: 10,428.78644

Timestep Collection Time: 2.26482
Timestep Consumption Time: 2.52960
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.79442

Cumulative Model Updates: 1,290
Cumulative Timesteps: 10,804,070

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 10804070...
Checkpoint 10804070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454.80582
Policy Entropy: 3.21609
Value Function Loss: 1.91601

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15295
Policy Update Magnitude: 0.28709
Value Function Update Magnitude: 0.31611

Collected Steps per Second: 20,842.45635
Overall Steps per Second: 9,788.71056

Timestep Collection Time: 2.40029
Timestep Consumption Time: 2.71049
PPO Batch Consumption Time: 0.31103
Total Iteration Time: 5.11079

Cumulative Model Updates: 1,296
Cumulative Timesteps: 10,854,098

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.95709
Policy Entropy: 3.21752
Value Function Loss: 1.95223

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.29323
Value Function Update Magnitude: 0.29383

Collected Steps per Second: 20,917.74034
Overall Steps per Second: 10,002.61627

Timestep Collection Time: 2.39070
Timestep Consumption Time: 2.60879
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.99949

Cumulative Model Updates: 1,302
Cumulative Timesteps: 10,904,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 10904106...
Checkpoint 10904106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.88379
Policy Entropy: 3.18242
Value Function Loss: 1.96564

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.11162
Policy Update Magnitude: 0.35490
Value Function Update Magnitude: 0.30342

Collected Steps per Second: 21,966.50473
Overall Steps per Second: 10,195.25304

Timestep Collection Time: 2.27637
Timestep Consumption Time: 2.62826
PPO Batch Consumption Time: 0.30908
Total Iteration Time: 4.90464

Cumulative Model Updates: 1,308
Cumulative Timesteps: 10,954,110

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.72863
Policy Entropy: 3.14529
Value Function Loss: 2.01489

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.33491
Value Function Update Magnitude: 0.29349

Collected Steps per Second: 20,031.17366
Overall Steps per Second: 9,809.76547

Timestep Collection Time: 2.49711
Timestep Consumption Time: 2.60189
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 5.09900

Cumulative Model Updates: 1,314
Cumulative Timesteps: 11,004,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 11004130...
Checkpoint 11004130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.46767
Policy Entropy: 3.15285
Value Function Loss: 1.93032

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10382
Policy Update Magnitude: 0.33172
Value Function Update Magnitude: 0.29841

Collected Steps per Second: 19,315.15967
Overall Steps per Second: 9,530.36817

Timestep Collection Time: 2.58895
Timestep Consumption Time: 2.65807
PPO Batch Consumption Time: 0.30120
Total Iteration Time: 5.24702

Cumulative Model Updates: 1,320
Cumulative Timesteps: 11,054,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.33474
Policy Entropy: 3.15315
Value Function Loss: 2.00181

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.22406
Policy Update Magnitude: 0.29233
Value Function Update Magnitude: 0.30042

Collected Steps per Second: 21,527.83395
Overall Steps per Second: 10,073.30469

Timestep Collection Time: 2.32304
Timestep Consumption Time: 2.64157
PPO Batch Consumption Time: 0.30962
Total Iteration Time: 4.96461

Cumulative Model Updates: 1,326
Cumulative Timesteps: 11,104,146

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 11104146...
Checkpoint 11104146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.22286
Policy Entropy: 3.17558
Value Function Loss: 2.05931

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.19574
Policy Update Magnitude: 0.21545
Value Function Update Magnitude: 0.28300

Collected Steps per Second: 19,168.28889
Overall Steps per Second: 8,389.84669

Timestep Collection Time: 2.61014
Timestep Consumption Time: 3.35325
PPO Batch Consumption Time: 0.40181
Total Iteration Time: 5.96340

Cumulative Model Updates: 1,332
Cumulative Timesteps: 11,154,178

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.88324
Policy Entropy: 3.17159
Value Function Loss: 2.08021

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.21556
Value Function Update Magnitude: 0.30039

Collected Steps per Second: 18,947.57655
Overall Steps per Second: 8,481.10299

Timestep Collection Time: 2.64002
Timestep Consumption Time: 3.25803
PPO Batch Consumption Time: 0.38904
Total Iteration Time: 5.89805

Cumulative Model Updates: 1,338
Cumulative Timesteps: 11,204,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 11204200...
Checkpoint 11204200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.81921
Policy Entropy: 3.16948
Value Function Loss: 1.92807

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.25759
Value Function Update Magnitude: 0.30527

Collected Steps per Second: 18,904.13244
Overall Steps per Second: 8,476.04244

Timestep Collection Time: 2.64630
Timestep Consumption Time: 3.25575
PPO Batch Consumption Time: 0.39432
Total Iteration Time: 5.90205

Cumulative Model Updates: 1,344
Cumulative Timesteps: 11,254,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.26739
Policy Entropy: 3.15430
Value Function Loss: 1.89986

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.27658
Value Function Update Magnitude: 0.33512

Collected Steps per Second: 19,273.82054
Overall Steps per Second: 8,404.77917

Timestep Collection Time: 2.59440
Timestep Consumption Time: 3.35507
PPO Batch Consumption Time: 0.39113
Total Iteration Time: 5.94947

Cumulative Model Updates: 1,350
Cumulative Timesteps: 11,304,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 11304230...
Checkpoint 11304230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.90676
Policy Entropy: 3.16194
Value Function Loss: 1.85117

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.23741
Value Function Update Magnitude: 0.34594

Collected Steps per Second: 19,003.94101
Overall Steps per Second: 9,339.47698

Timestep Collection Time: 2.63303
Timestep Consumption Time: 2.72465
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 5.35769

Cumulative Model Updates: 1,356
Cumulative Timesteps: 11,354,268

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.44166
Policy Entropy: 3.15107
Value Function Loss: 1.86800

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.23932
Value Function Update Magnitude: 0.35220

Collected Steps per Second: 21,843.72347
Overall Steps per Second: 9,540.50922

Timestep Collection Time: 2.28954
Timestep Consumption Time: 2.95253
PPO Batch Consumption Time: 0.36268
Total Iteration Time: 5.24207

Cumulative Model Updates: 1,362
Cumulative Timesteps: 11,404,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 11404280...
Checkpoint 11404280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.17756
Policy Entropy: 3.14952
Value Function Loss: 1.78578

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12471
Policy Update Magnitude: 0.24712
Value Function Update Magnitude: 0.31839

Collected Steps per Second: 19,151.44660
Overall Steps per Second: 8,721.57747

Timestep Collection Time: 2.61234
Timestep Consumption Time: 3.12401
PPO Batch Consumption Time: 0.36589
Total Iteration Time: 5.73635

Cumulative Model Updates: 1,368
Cumulative Timesteps: 11,454,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.96999
Policy Entropy: 3.15958
Value Function Loss: 1.78050

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.27601
Value Function Update Magnitude: 0.33246

Collected Steps per Second: 19,070.04778
Overall Steps per Second: 8,777.69200

Timestep Collection Time: 2.62359
Timestep Consumption Time: 3.07631
PPO Batch Consumption Time: 0.36658
Total Iteration Time: 5.69990

Cumulative Model Updates: 1,374
Cumulative Timesteps: 11,504,342

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 11504342...
Checkpoint 11504342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.05622
Policy Entropy: 3.15766
Value Function Loss: 1.83153

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.27081
Value Function Update Magnitude: 0.31343

Collected Steps per Second: 18,854.10119
Overall Steps per Second: 8,844.09180

Timestep Collection Time: 2.65343
Timestep Consumption Time: 3.00323
PPO Batch Consumption Time: 0.36367
Total Iteration Time: 5.65666

Cumulative Model Updates: 1,380
Cumulative Timesteps: 11,554,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.44051
Policy Entropy: 3.16147
Value Function Loss: 1.84934

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.16190
Policy Update Magnitude: 0.24840
Value Function Update Magnitude: 0.30674

Collected Steps per Second: 18,800.39218
Overall Steps per Second: 8,808.18590

Timestep Collection Time: 2.66111
Timestep Consumption Time: 3.01883
PPO Batch Consumption Time: 0.35090
Total Iteration Time: 5.67994

Cumulative Model Updates: 1,386
Cumulative Timesteps: 11,604,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 11604400...
Checkpoint 11604400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.72928
Policy Entropy: 3.17350
Value Function Loss: 1.87211

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.16913
Policy Update Magnitude: 0.23868
Value Function Update Magnitude: 0.31080

Collected Steps per Second: 18,983.69804
Overall Steps per Second: 8,836.78884

Timestep Collection Time: 2.63605
Timestep Consumption Time: 3.02687
PPO Batch Consumption Time: 0.34923
Total Iteration Time: 5.66292

Cumulative Model Updates: 1,392
Cumulative Timesteps: 11,654,442

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.12492
Policy Entropy: 3.17045
Value Function Loss: 1.76664

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.19686
Policy Update Magnitude: 0.23865
Value Function Update Magnitude: 0.33859

Collected Steps per Second: 19,134.94880
Overall Steps per Second: 8,933.49822

Timestep Collection Time: 2.61354
Timestep Consumption Time: 2.98449
PPO Batch Consumption Time: 0.34911
Total Iteration Time: 5.59803

Cumulative Model Updates: 1,398
Cumulative Timesteps: 11,704,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 11704452...
Checkpoint 11704452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.31423
Policy Entropy: 3.18180
Value Function Loss: 1.70938

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.21237
Value Function Update Magnitude: 0.30751

Collected Steps per Second: 19,503.79653
Overall Steps per Second: 8,896.03190

Timestep Collection Time: 2.56442
Timestep Consumption Time: 3.05786
PPO Batch Consumption Time: 0.35855
Total Iteration Time: 5.62228

Cumulative Model Updates: 1,404
Cumulative Timesteps: 11,754,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.27691
Policy Entropy: 3.14281
Value Function Loss: 1.59357

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.15339
Policy Update Magnitude: 0.23676
Value Function Update Magnitude: 0.36799

Collected Steps per Second: 19,566.70659
Overall Steps per Second: 8,929.63698

Timestep Collection Time: 2.55638
Timestep Consumption Time: 3.04519
PPO Batch Consumption Time: 0.36203
Total Iteration Time: 5.60157

Cumulative Model Updates: 1,410
Cumulative Timesteps: 11,804,488

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 11804488...
Checkpoint 11804488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.39178
Policy Entropy: 3.13209
Value Function Loss: 1.65616

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.25323
Value Function Update Magnitude: 0.32505

Collected Steps per Second: 19,042.98895
Overall Steps per Second: 8,993.95861

Timestep Collection Time: 2.62753
Timestep Consumption Time: 2.93576
PPO Batch Consumption Time: 0.34853
Total Iteration Time: 5.56329

Cumulative Model Updates: 1,416
Cumulative Timesteps: 11,854,524

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.12418
Policy Entropy: 3.12930
Value Function Loss: 1.70968

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13703
Policy Update Magnitude: 0.25139
Value Function Update Magnitude: 0.31219

Collected Steps per Second: 20,550.38723
Overall Steps per Second: 9,322.92104

Timestep Collection Time: 2.43314
Timestep Consumption Time: 2.93020
PPO Batch Consumption Time: 0.33331
Total Iteration Time: 5.36334

Cumulative Model Updates: 1,422
Cumulative Timesteps: 11,904,526

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 11904526...
Checkpoint 11904526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.79186
Policy Entropy: 3.13667
Value Function Loss: 1.70104

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.26163
Value Function Update Magnitude: 0.31260

Collected Steps per Second: 21,729.06488
Overall Steps per Second: 10,185.78258

Timestep Collection Time: 2.30143
Timestep Consumption Time: 2.60815
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.90959

Cumulative Model Updates: 1,428
Cumulative Timesteps: 11,954,534

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.87596
Policy Entropy: 3.14878
Value Function Loss: 1.68222

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.25170
Value Function Update Magnitude: 0.30039

Collected Steps per Second: 21,635.95156
Overall Steps per Second: 10,331.89311

Timestep Collection Time: 2.31125
Timestep Consumption Time: 2.52872
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.83996

Cumulative Model Updates: 1,434
Cumulative Timesteps: 12,004,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 12004540...
Checkpoint 12004540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.98319
Policy Entropy: 3.13570
Value Function Loss: 1.61769

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.24545
Value Function Update Magnitude: 0.29803

Collected Steps per Second: 21,842.88272
Overall Steps per Second: 10,230.14785

Timestep Collection Time: 2.28944
Timestep Consumption Time: 2.59886
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.88830

Cumulative Model Updates: 1,440
Cumulative Timesteps: 12,054,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.75690
Policy Entropy: 3.15295
Value Function Loss: 1.64024

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12966
Policy Update Magnitude: 0.24731
Value Function Update Magnitude: 0.32624

Collected Steps per Second: 21,854.89583
Overall Steps per Second: 10,031.84795

Timestep Collection Time: 2.28855
Timestep Consumption Time: 2.69717
PPO Batch Consumption Time: 0.30425
Total Iteration Time: 4.98572

Cumulative Model Updates: 1,446
Cumulative Timesteps: 12,104,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 12104564...
Checkpoint 12104564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.38736
Policy Entropy: 3.13338
Value Function Loss: 1.64600

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.26229
Value Function Update Magnitude: 0.32332

Collected Steps per Second: 21,430.90867
Overall Steps per Second: 10,269.47853

Timestep Collection Time: 2.33364
Timestep Consumption Time: 2.53633
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.86996

Cumulative Model Updates: 1,452
Cumulative Timesteps: 12,154,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.71378
Policy Entropy: 3.13490
Value Function Loss: 1.67479

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.30752
Value Function Update Magnitude: 0.32111

Collected Steps per Second: 22,288.45415
Overall Steps per Second: 10,063.92933

Timestep Collection Time: 2.24457
Timestep Consumption Time: 2.72645
PPO Batch Consumption Time: 0.31197
Total Iteration Time: 4.97102

Cumulative Model Updates: 1,458
Cumulative Timesteps: 12,204,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 12204604...
Checkpoint 12204604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.08644
Policy Entropy: 3.13730
Value Function Loss: 1.62128

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.35044
Value Function Update Magnitude: 0.32882

Collected Steps per Second: 21,817.04847
Overall Steps per Second: 10,091.62802

Timestep Collection Time: 2.29215
Timestep Consumption Time: 2.66324
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.95539

Cumulative Model Updates: 1,464
Cumulative Timesteps: 12,254,612

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.29032
Policy Entropy: 3.12594
Value Function Loss: 1.60133

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.36347
Value Function Update Magnitude: 0.32492

Collected Steps per Second: 20,394.67699
Overall Steps per Second: 9,762.63380

Timestep Collection Time: 2.45329
Timestep Consumption Time: 2.67176
PPO Batch Consumption Time: 0.30514
Total Iteration Time: 5.12505

Cumulative Model Updates: 1,470
Cumulative Timesteps: 12,304,646

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 12304646...
Checkpoint 12304646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.50971
Policy Entropy: 3.10153
Value Function Loss: 1.61374

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12408
Policy Update Magnitude: 0.32807
Value Function Update Magnitude: 0.30331

Collected Steps per Second: 22,020.45608
Overall Steps per Second: 10,178.77418

Timestep Collection Time: 2.27171
Timestep Consumption Time: 2.64283
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 4.91454

Cumulative Model Updates: 1,476
Cumulative Timesteps: 12,354,670

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.05100
Policy Entropy: 3.10136
Value Function Loss: 1.62540

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.11548
Policy Update Magnitude: 0.35699
Value Function Update Magnitude: 0.31998

Collected Steps per Second: 22,138.13994
Overall Steps per Second: 10,053.19696

Timestep Collection Time: 2.25927
Timestep Consumption Time: 2.71587
PPO Batch Consumption Time: 0.31024
Total Iteration Time: 4.97513

Cumulative Model Updates: 1,482
Cumulative Timesteps: 12,404,686

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 12404686...
Checkpoint 12404686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.05437
Policy Entropy: 3.10555
Value Function Loss: 1.60236

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15039
Policy Update Magnitude: 0.30937
Value Function Update Magnitude: 0.28912

Collected Steps per Second: 20,821.98320
Overall Steps per Second: 9,769.72411

Timestep Collection Time: 2.40140
Timestep Consumption Time: 2.71665
PPO Batch Consumption Time: 0.31502
Total Iteration Time: 5.11806

Cumulative Model Updates: 1,488
Cumulative Timesteps: 12,454,688

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.24705
Policy Entropy: 3.10665
Value Function Loss: 1.62281

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14650
Policy Update Magnitude: 0.28379
Value Function Update Magnitude: 0.29136

Collected Steps per Second: 21,905.48275
Overall Steps per Second: 10,339.72084

Timestep Collection Time: 2.28381
Timestep Consumption Time: 2.55462
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.83843

Cumulative Model Updates: 1,494
Cumulative Timesteps: 12,504,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 12504716...
Checkpoint 12504716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.40064
Policy Entropy: 3.10090
Value Function Loss: 1.62802

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.25767
Value Function Update Magnitude: 0.29063

Collected Steps per Second: 21,313.80111
Overall Steps per Second: 9,878.76609

Timestep Collection Time: 2.34684
Timestep Consumption Time: 2.71655
PPO Batch Consumption Time: 0.30922
Total Iteration Time: 5.06339

Cumulative Model Updates: 1,500
Cumulative Timesteps: 12,554,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.96344
Policy Entropy: 3.08124
Value Function Loss: 1.63922

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.27192
Value Function Update Magnitude: 0.31174

Collected Steps per Second: 20,287.14152
Overall Steps per Second: 9,649.33792

Timestep Collection Time: 2.46481
Timestep Consumption Time: 2.71730
PPO Batch Consumption Time: 0.30160
Total Iteration Time: 5.18212

Cumulative Model Updates: 1,506
Cumulative Timesteps: 12,604,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 12604740...
Checkpoint 12604740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.06345
Policy Entropy: 3.08877
Value Function Loss: 1.63070

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.29304
Value Function Update Magnitude: 0.32382

Collected Steps per Second: 20,348.77310
Overall Steps per Second: 9,904.77404

Timestep Collection Time: 2.45784
Timestep Consumption Time: 2.59165
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 5.04948

Cumulative Model Updates: 1,512
Cumulative Timesteps: 12,654,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.43592
Policy Entropy: 3.08506
Value Function Loss: 1.63997

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.31104
Value Function Update Magnitude: 0.46589

Collected Steps per Second: 22,842.27229
Overall Steps per Second: 10,424.27274

Timestep Collection Time: 2.18910
Timestep Consumption Time: 2.60778
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.79688

Cumulative Model Updates: 1,518
Cumulative Timesteps: 12,704,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 12704758...
Checkpoint 12704758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.13195
Policy Entropy: 3.07637
Value Function Loss: 1.63917

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.11012
Policy Update Magnitude: 0.32793
Value Function Update Magnitude: 0.39376

Collected Steps per Second: 21,875.26793
Overall Steps per Second: 10,215.42665

Timestep Collection Time: 2.28605
Timestep Consumption Time: 2.60929
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.89534

Cumulative Model Updates: 1,524
Cumulative Timesteps: 12,754,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.73807
Policy Entropy: 3.06303
Value Function Loss: 1.61595

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.29615
Value Function Update Magnitude: 0.37997

Collected Steps per Second: 22,018.71300
Overall Steps per Second: 10,116.99111

Timestep Collection Time: 2.27207
Timestep Consumption Time: 2.67288
PPO Batch Consumption Time: 0.30943
Total Iteration Time: 4.94495

Cumulative Model Updates: 1,530
Cumulative Timesteps: 12,804,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 12804794...
Checkpoint 12804794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.26895
Policy Entropy: 3.04202
Value Function Loss: 1.54969

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.32994
Value Function Update Magnitude: 0.35610

Collected Steps per Second: 20,046.75010
Overall Steps per Second: 9,086.63429

Timestep Collection Time: 2.49497
Timestep Consumption Time: 3.00938
PPO Batch Consumption Time: 0.36830
Total Iteration Time: 5.50435

Cumulative Model Updates: 1,536
Cumulative Timesteps: 12,854,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.73145
Policy Entropy: 3.05357
Value Function Loss: 1.54059

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11916
Policy Update Magnitude: 0.36123
Value Function Update Magnitude: 0.42017

Collected Steps per Second: 19,289.23201
Overall Steps per Second: 8,745.71261

Timestep Collection Time: 2.59409
Timestep Consumption Time: 3.12734
PPO Batch Consumption Time: 0.36642
Total Iteration Time: 5.72143

Cumulative Model Updates: 1,542
Cumulative Timesteps: 12,904,848

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 12904848...
Checkpoint 12904848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.15353
Policy Entropy: 3.05249
Value Function Loss: 1.57774

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.15550
Policy Update Magnitude: 0.35552
Value Function Update Magnitude: 0.41824

Collected Steps per Second: 20,550.16717
Overall Steps per Second: 9,938.33822

Timestep Collection Time: 2.43336
Timestep Consumption Time: 2.59826
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 5.03163

Cumulative Model Updates: 1,548
Cumulative Timesteps: 12,954,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.52783
Policy Entropy: 3.06155
Value Function Loss: 1.58570

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.15970
Policy Update Magnitude: 0.30193
Value Function Update Magnitude: 0.49425

Collected Steps per Second: 19,853.69922
Overall Steps per Second: 9,673.52379

Timestep Collection Time: 2.51963
Timestep Consumption Time: 2.65160
PPO Batch Consumption Time: 0.30422
Total Iteration Time: 5.17123

Cumulative Model Updates: 1,554
Cumulative Timesteps: 13,004,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 13004878...
Checkpoint 13004878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.50446
Policy Entropy: 3.07929
Value Function Loss: 1.53714

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15423
Policy Update Magnitude: 0.27871
Value Function Update Magnitude: 0.55749

Collected Steps per Second: 21,550.24588
Overall Steps per Second: 10,309.92329

Timestep Collection Time: 2.32099
Timestep Consumption Time: 2.53045
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.85144

Cumulative Model Updates: 1,560
Cumulative Timesteps: 13,054,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.45206
Policy Entropy: 3.03090
Value Function Loss: 1.60239

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.29736
Value Function Update Magnitude: 0.44201

Collected Steps per Second: 21,538.85385
Overall Steps per Second: 9,797.07166

Timestep Collection Time: 2.32157
Timestep Consumption Time: 2.78240
PPO Batch Consumption Time: 0.31958
Total Iteration Time: 5.10397

Cumulative Model Updates: 1,566
Cumulative Timesteps: 13,104,900

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 13104900...
Checkpoint 13104900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.62827
Policy Entropy: 3.02138
Value Function Loss: 1.61095

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.28128
Value Function Update Magnitude: 0.43131

Collected Steps per Second: 20,192.11326
Overall Steps per Second: 9,548.22403

Timestep Collection Time: 2.47760
Timestep Consumption Time: 2.76191
PPO Batch Consumption Time: 0.30853
Total Iteration Time: 5.23951

Cumulative Model Updates: 1,572
Cumulative Timesteps: 13,154,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.87584
Policy Entropy: 2.99714
Value Function Loss: 1.72842

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.23125
Value Function Update Magnitude: 0.35693

Collected Steps per Second: 21,591.13753
Overall Steps per Second: 10,095.94477

Timestep Collection Time: 2.31706
Timestep Consumption Time: 2.63820
PPO Batch Consumption Time: 0.29995
Total Iteration Time: 4.95526

Cumulative Model Updates: 1,578
Cumulative Timesteps: 13,204,956

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 13204956...
Checkpoint 13204956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.11816
Policy Entropy: 3.01370
Value Function Loss: 1.61717

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11415
Policy Update Magnitude: 0.26497
Value Function Update Magnitude: 0.32200

Collected Steps per Second: 22,541.02370
Overall Steps per Second: 10,177.99523

Timestep Collection Time: 2.21827
Timestep Consumption Time: 2.69449
PPO Batch Consumption Time: 0.30782
Total Iteration Time: 4.91276

Cumulative Model Updates: 1,584
Cumulative Timesteps: 13,254,958

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.68661
Policy Entropy: 3.02087
Value Function Loss: 1.62178

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.26689
Value Function Update Magnitude: 0.31012

Collected Steps per Second: 21,978.17940
Overall Steps per Second: 9,998.33135

Timestep Collection Time: 2.27562
Timestep Consumption Time: 2.72661
PPO Batch Consumption Time: 0.31076
Total Iteration Time: 5.00223

Cumulative Model Updates: 1,590
Cumulative Timesteps: 13,304,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 13304972...
Checkpoint 13304972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.19326
Policy Entropy: 3.00564
Value Function Loss: 1.59304

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.26612
Value Function Update Magnitude: 0.32374

Collected Steps per Second: 21,402.99183
Overall Steps per Second: 10,006.37777

Timestep Collection Time: 2.33696
Timestep Consumption Time: 2.66165
PPO Batch Consumption Time: 0.30323
Total Iteration Time: 4.99861

Cumulative Model Updates: 1,596
Cumulative Timesteps: 13,354,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.67952
Policy Entropy: 3.01319
Value Function Loss: 1.67789

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.27057
Value Function Update Magnitude: 0.34789

Collected Steps per Second: 21,655.60764
Overall Steps per Second: 10,122.52843

Timestep Collection Time: 2.31090
Timestep Consumption Time: 2.63292
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 4.94382

Cumulative Model Updates: 1,602
Cumulative Timesteps: 13,405,034

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 13405034...
Checkpoint 13405034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.37295
Policy Entropy: 3.02944
Value Function Loss: 1.70632

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.28852
Value Function Update Magnitude: 0.34010

Collected Steps per Second: 19,637.98103
Overall Steps per Second: 8,680.93120

Timestep Collection Time: 2.54660
Timestep Consumption Time: 3.21431
PPO Batch Consumption Time: 0.37459
Total Iteration Time: 5.76090

Cumulative Model Updates: 1,608
Cumulative Timesteps: 13,455,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.03403
Policy Entropy: 3.02359
Value Function Loss: 1.66970

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.15014
Policy Update Magnitude: 0.27016
Value Function Update Magnitude: 0.33728

Collected Steps per Second: 18,572.32407
Overall Steps per Second: 8,540.96737

Timestep Collection Time: 2.69282
Timestep Consumption Time: 3.16272
PPO Batch Consumption Time: 0.36992
Total Iteration Time: 5.85554

Cumulative Model Updates: 1,614
Cumulative Timesteps: 13,505,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 13505056...
Checkpoint 13505056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.18304
Policy Entropy: 3.01920
Value Function Loss: 1.67066

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.16492
Policy Update Magnitude: 0.25007
Value Function Update Magnitude: 0.30959

Collected Steps per Second: 19,270.66099
Overall Steps per Second: 8,754.43221

Timestep Collection Time: 2.59597
Timestep Consumption Time: 3.11840
PPO Batch Consumption Time: 0.36226
Total Iteration Time: 5.71436

Cumulative Model Updates: 1,620
Cumulative Timesteps: 13,555,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728.16296
Policy Entropy: 3.02209
Value Function Loss: 1.69242

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.25394
Value Function Update Magnitude: 0.29529

Collected Steps per Second: 18,597.61288
Overall Steps per Second: 8,735.46437

Timestep Collection Time: 2.69067
Timestep Consumption Time: 3.03771
PPO Batch Consumption Time: 0.36241
Total Iteration Time: 5.72837

Cumulative Model Updates: 1,626
Cumulative Timesteps: 13,605,122

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 13605122...
Checkpoint 13605122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.27269
Policy Entropy: 3.02038
Value Function Loss: 1.65810

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11611
Policy Update Magnitude: 0.28186
Value Function Update Magnitude: 0.28533

Collected Steps per Second: 19,248.08197
Overall Steps per Second: 8,650.72667

Timestep Collection Time: 2.59891
Timestep Consumption Time: 3.18373
PPO Batch Consumption Time: 0.36835
Total Iteration Time: 5.78264

Cumulative Model Updates: 1,632
Cumulative Timesteps: 13,655,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.99937
Policy Entropy: 3.02028
Value Function Loss: 1.63317

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12360
Policy Update Magnitude: 0.30306
Value Function Update Magnitude: 0.26218

Collected Steps per Second: 18,939.42048
Overall Steps per Second: 8,645.05154

Timestep Collection Time: 2.64042
Timestep Consumption Time: 3.14416
PPO Batch Consumption Time: 0.36317
Total Iteration Time: 5.78458

Cumulative Model Updates: 1,638
Cumulative Timesteps: 13,705,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 13705154...
Checkpoint 13705154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.87299
Policy Entropy: 2.99388
Value Function Loss: 1.63221

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.27721
Value Function Update Magnitude: 0.25200

Collected Steps per Second: 18,908.57998
Overall Steps per Second: 8,847.88213

Timestep Collection Time: 2.64589
Timestep Consumption Time: 3.00857
PPO Batch Consumption Time: 0.35567
Total Iteration Time: 5.65446

Cumulative Model Updates: 1,644
Cumulative Timesteps: 13,755,184

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.68410
Policy Entropy: 3.01101
Value Function Loss: 1.62272

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.16988
Policy Update Magnitude: 0.23550
Value Function Update Magnitude: 0.24512

Collected Steps per Second: 19,772.64892
Overall Steps per Second: 8,899.10845

Timestep Collection Time: 2.53006
Timestep Consumption Time: 3.09140
PPO Batch Consumption Time: 0.36291
Total Iteration Time: 5.62146

Cumulative Model Updates: 1,650
Cumulative Timesteps: 13,805,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 13805210...
Checkpoint 13805210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638.86820
Policy Entropy: 2.99785
Value Function Loss: 1.67110

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.16283
Policy Update Magnitude: 0.22225
Value Function Update Magnitude: 0.26191

Collected Steps per Second: 19,117.16287
Overall Steps per Second: 8,744.35344

Timestep Collection Time: 2.61629
Timestep Consumption Time: 3.10352
PPO Batch Consumption Time: 0.36806
Total Iteration Time: 5.71981

Cumulative Model Updates: 1,656
Cumulative Timesteps: 13,855,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.59002
Policy Entropy: 3.01621
Value Function Loss: 1.70696

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14604
Policy Update Magnitude: 0.21037
Value Function Update Magnitude: 0.28741

Collected Steps per Second: 18,912.21206
Overall Steps per Second: 8,700.93130

Timestep Collection Time: 2.64485
Timestep Consumption Time: 3.10396
PPO Batch Consumption Time: 0.36744
Total Iteration Time: 5.74881

Cumulative Model Updates: 1,662
Cumulative Timesteps: 13,905,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 13905246...
Checkpoint 13905246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.30597
Policy Entropy: 3.02710
Value Function Loss: 1.79616

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.17914
Policy Update Magnitude: 0.19170
Value Function Update Magnitude: 0.31908

Collected Steps per Second: 18,844.32332
Overall Steps per Second: 8,813.37214

Timestep Collection Time: 2.65480
Timestep Consumption Time: 3.02157
PPO Batch Consumption Time: 0.36420
Total Iteration Time: 5.67637

Cumulative Model Updates: 1,668
Cumulative Timesteps: 13,955,274

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.51131
Policy Entropy: 3.01654
Value Function Loss: 1.84593

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.15651
Policy Update Magnitude: 0.19015
Value Function Update Magnitude: 0.31325

Collected Steps per Second: 19,319.74133
Overall Steps per Second: 9,659.83000

Timestep Collection Time: 2.58917
Timestep Consumption Time: 2.58919
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 5.17835

Cumulative Model Updates: 1,674
Cumulative Timesteps: 14,005,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 14005296...
Checkpoint 14005296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.27874
Policy Entropy: 3.00503
Value Function Loss: 1.86310

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.14937
Policy Update Magnitude: 0.22823
Value Function Update Magnitude: 0.34899

Collected Steps per Second: 21,185.22891
Overall Steps per Second: 9,826.90872

Timestep Collection Time: 2.36032
Timestep Consumption Time: 2.72815
PPO Batch Consumption Time: 0.31387
Total Iteration Time: 5.08848

Cumulative Model Updates: 1,680
Cumulative Timesteps: 14,055,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.58788
Policy Entropy: 2.98608
Value Function Loss: 1.89612

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15714
Policy Update Magnitude: 0.20971
Value Function Update Magnitude: 0.37332

Collected Steps per Second: 21,775.29409
Overall Steps per Second: 10,047.31202

Timestep Collection Time: 2.29747
Timestep Consumption Time: 2.68178
PPO Batch Consumption Time: 0.30573
Total Iteration Time: 4.97924

Cumulative Model Updates: 1,686
Cumulative Timesteps: 14,105,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 14105328...
Checkpoint 14105328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.47412
Policy Entropy: 2.98317
Value Function Loss: 1.84286

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.15827
Policy Update Magnitude: 0.18025
Value Function Update Magnitude: 0.35720

Collected Steps per Second: 21,806.29857
Overall Steps per Second: 10,222.03236

Timestep Collection Time: 2.29292
Timestep Consumption Time: 2.59848
PPO Batch Consumption Time: 0.30310
Total Iteration Time: 4.89140

Cumulative Model Updates: 1,692
Cumulative Timesteps: 14,155,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.05556
Policy Entropy: 2.97411
Value Function Loss: 1.78862

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.17875
Value Function Update Magnitude: 0.40384

Collected Steps per Second: 21,211.00286
Overall Steps per Second: 9,764.19264

Timestep Collection Time: 2.35764
Timestep Consumption Time: 2.76393
PPO Batch Consumption Time: 0.31317
Total Iteration Time: 5.12157

Cumulative Model Updates: 1,698
Cumulative Timesteps: 14,205,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 14205336...
Checkpoint 14205336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.11132
Policy Entropy: 2.99355
Value Function Loss: 1.84884

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.20244
Value Function Update Magnitude: 0.45282

Collected Steps per Second: 21,026.14730
Overall Steps per Second: 10,060.44293

Timestep Collection Time: 2.37837
Timestep Consumption Time: 2.59238
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.97076

Cumulative Model Updates: 1,704
Cumulative Timesteps: 14,255,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.87652
Policy Entropy: 2.98931
Value Function Loss: 1.90697

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.21264
Value Function Update Magnitude: 0.36535

Collected Steps per Second: 21,302.14968
Overall Steps per Second: 9,806.93104

Timestep Collection Time: 2.34831
Timestep Consumption Time: 2.75257
PPO Batch Consumption Time: 0.30814
Total Iteration Time: 5.10088

Cumulative Model Updates: 1,710
Cumulative Timesteps: 14,305,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 14305368...
Checkpoint 14305368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 774.70346
Policy Entropy: 3.00658
Value Function Loss: 1.89767

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.20023
Value Function Update Magnitude: 0.33646

Collected Steps per Second: 21,345.22009
Overall Steps per Second: 10,143.32353

Timestep Collection Time: 2.34282
Timestep Consumption Time: 2.58732
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.93014

Cumulative Model Updates: 1,716
Cumulative Timesteps: 14,355,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.68580
Policy Entropy: 2.99032
Value Function Loss: 1.86333

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13161
Policy Update Magnitude: 0.20609
Value Function Update Magnitude: 0.34736

Collected Steps per Second: 21,697.93333
Overall Steps per Second: 10,019.03107

Timestep Collection Time: 2.30557
Timestep Consumption Time: 2.68753
PPO Batch Consumption Time: 0.31708
Total Iteration Time: 4.99310

Cumulative Model Updates: 1,722
Cumulative Timesteps: 14,405,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 14405402...
Checkpoint 14405402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.16302
Policy Entropy: 2.99001
Value Function Loss: 1.87837

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.21924
Value Function Update Magnitude: 0.34882

Collected Steps per Second: 20,811.99210
Overall Steps per Second: 9,621.34989

Timestep Collection Time: 2.40438
Timestep Consumption Time: 2.79655
PPO Batch Consumption Time: 0.32513
Total Iteration Time: 5.20093

Cumulative Model Updates: 1,728
Cumulative Timesteps: 14,455,442

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.59525
Policy Entropy: 2.96027
Value Function Loss: 1.85761

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.23225
Value Function Update Magnitude: 0.28987

Collected Steps per Second: 20,786.07620
Overall Steps per Second: 9,752.02869

Timestep Collection Time: 2.40757
Timestep Consumption Time: 2.72408
PPO Batch Consumption Time: 0.31080
Total Iteration Time: 5.13165

Cumulative Model Updates: 1,734
Cumulative Timesteps: 14,505,486

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 14505486...
Checkpoint 14505486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.99435
Policy Entropy: 2.96723
Value Function Loss: 1.88957

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.23959
Value Function Update Magnitude: 0.26921

Collected Steps per Second: 20,921.09180
Overall Steps per Second: 9,796.83840

Timestep Collection Time: 2.39108
Timestep Consumption Time: 2.71506
PPO Batch Consumption Time: 0.31107
Total Iteration Time: 5.10614

Cumulative Model Updates: 1,740
Cumulative Timesteps: 14,555,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.62281
Policy Entropy: 2.97315
Value Function Loss: 1.85985

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.23345
Value Function Update Magnitude: 0.25657

Collected Steps per Second: 21,755.07048
Overall Steps per Second: 9,791.48628

Timestep Collection Time: 2.29979
Timestep Consumption Time: 2.80996
PPO Batch Consumption Time: 0.33244
Total Iteration Time: 5.10975

Cumulative Model Updates: 1,746
Cumulative Timesteps: 14,605,542

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 14605542...
Checkpoint 14605542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.99751
Policy Entropy: 2.96554
Value Function Loss: 1.83113

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.21577
Value Function Update Magnitude: 0.35854

Collected Steps per Second: 21,133.13899
Overall Steps per Second: 9,791.27560

Timestep Collection Time: 2.36680
Timestep Consumption Time: 2.74162
PPO Batch Consumption Time: 0.31343
Total Iteration Time: 5.10843

Cumulative Model Updates: 1,752
Cumulative Timesteps: 14,655,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.33549
Policy Entropy: 2.95486
Value Function Loss: 1.81088

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12578
Policy Update Magnitude: 0.21705
Value Function Update Magnitude: 0.33752

Collected Steps per Second: 21,083.50087
Overall Steps per Second: 10,003.12408

Timestep Collection Time: 2.37190
Timestep Consumption Time: 2.62734
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.99924

Cumulative Model Updates: 1,758
Cumulative Timesteps: 14,705,568

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 14705568...
Checkpoint 14705568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666.20189
Policy Entropy: 2.93250
Value Function Loss: 1.81774

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.22764
Value Function Update Magnitude: 0.30565

Collected Steps per Second: 21,644.47830
Overall Steps per Second: 10,106.17485

Timestep Collection Time: 2.31052
Timestep Consumption Time: 2.63794
PPO Batch Consumption Time: 0.30869
Total Iteration Time: 4.94846

Cumulative Model Updates: 1,764
Cumulative Timesteps: 14,755,578

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.21484
Policy Entropy: 2.93930
Value Function Loss: 1.75445

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 0.24218
Value Function Update Magnitude: 0.32592

Collected Steps per Second: 21,988.82230
Overall Steps per Second: 10,078.50926

Timestep Collection Time: 2.27507
Timestep Consumption Time: 2.68857
PPO Batch Consumption Time: 0.30452
Total Iteration Time: 4.96363

Cumulative Model Updates: 1,770
Cumulative Timesteps: 14,805,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 14805604...
Checkpoint 14805604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.46975
Policy Entropy: 2.93765
Value Function Loss: 1.79175

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.25340
Value Function Update Magnitude: 0.32646

Collected Steps per Second: 20,674.81163
Overall Steps per Second: 9,793.20975

Timestep Collection Time: 2.41889
Timestep Consumption Time: 2.68771
PPO Batch Consumption Time: 0.30522
Total Iteration Time: 5.10660

Cumulative Model Updates: 1,776
Cumulative Timesteps: 14,855,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.78259
Policy Entropy: 2.94874
Value Function Loss: 1.80388

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.15279
Policy Update Magnitude: 0.25188
Value Function Update Magnitude: 0.30058

Collected Steps per Second: 21,321.15826
Overall Steps per Second: 10,053.90104

Timestep Collection Time: 2.34621
Timestep Consumption Time: 2.62937
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.97558

Cumulative Model Updates: 1,782
Cumulative Timesteps: 14,905,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 14905638...
Checkpoint 14905638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.48609
Policy Entropy: 2.92089
Value Function Loss: 1.75506

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.26011
Policy Update Magnitude: 0.20497
Value Function Update Magnitude: 0.32544

Collected Steps per Second: 21,244.22655
Overall Steps per Second: 9,891.93836

Timestep Collection Time: 2.35462
Timestep Consumption Time: 2.70223
PPO Batch Consumption Time: 0.30776
Total Iteration Time: 5.05685

Cumulative Model Updates: 1,788
Cumulative Timesteps: 14,955,660

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.92735
Policy Entropy: 2.90601
Value Function Loss: 1.68953

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.20182
Value Function Update Magnitude: 0.33492

Collected Steps per Second: 22,239.56018
Overall Steps per Second: 10,380.76393

Timestep Collection Time: 2.24825
Timestep Consumption Time: 2.56836
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 4.81660

Cumulative Model Updates: 1,794
Cumulative Timesteps: 15,005,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 15005660...
Checkpoint 15005660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459.48029
Policy Entropy: 2.89670
Value Function Loss: 1.67824

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.15893
Policy Update Magnitude: 0.25451
Value Function Update Magnitude: 0.32581

Collected Steps per Second: 21,616.31100
Overall Steps per Second: 10,178.01930

Timestep Collection Time: 2.31418
Timestep Consumption Time: 2.60073
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.91491

Cumulative Model Updates: 1,800
Cumulative Timesteps: 15,055,684

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713.87809
Policy Entropy: 2.92087
Value Function Loss: 1.73933

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.16608
Policy Update Magnitude: 0.21851
Value Function Update Magnitude: 0.32929

Collected Steps per Second: 21,811.52132
Overall Steps per Second: 10,024.35511

Timestep Collection Time: 2.29347
Timestep Consumption Time: 2.69678
PPO Batch Consumption Time: 0.30575
Total Iteration Time: 4.99025

Cumulative Model Updates: 1,806
Cumulative Timesteps: 15,105,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 15105708...
Checkpoint 15105708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.42107
Policy Entropy: 2.93595
Value Function Loss: 1.74476

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14844
Policy Update Magnitude: 0.21943
Value Function Update Magnitude: 0.34107

Collected Steps per Second: 21,369.68530
Overall Steps per Second: 10,118.89899

Timestep Collection Time: 2.34023
Timestep Consumption Time: 2.60201
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.94224

Cumulative Model Updates: 1,812
Cumulative Timesteps: 15,155,718

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.49779
Policy Entropy: 2.92590
Value Function Loss: 1.81740

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.22808
Value Function Update Magnitude: 0.34516

Collected Steps per Second: 21,806.78961
Overall Steps per Second: 10,089.61091

Timestep Collection Time: 2.29369
Timestep Consumption Time: 2.66369
PPO Batch Consumption Time: 0.31375
Total Iteration Time: 4.95738

Cumulative Model Updates: 1,818
Cumulative Timesteps: 15,205,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 15205736...
Checkpoint 15205736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.32854
Policy Entropy: 2.91913
Value Function Loss: 1.85929

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.22716
Value Function Update Magnitude: 0.32139

Collected Steps per Second: 21,489.19992
Overall Steps per Second: 10,035.05909

Timestep Collection Time: 2.32703
Timestep Consumption Time: 2.65610
PPO Batch Consumption Time: 0.30195
Total Iteration Time: 4.98313

Cumulative Model Updates: 1,824
Cumulative Timesteps: 15,255,742

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.13278
Policy Entropy: 2.91690
Value Function Loss: 1.86077

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.23383
Value Function Update Magnitude: 0.33551

Collected Steps per Second: 21,602.66609
Overall Steps per Second: 10,105.04568

Timestep Collection Time: 2.31518
Timestep Consumption Time: 2.63423
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 4.94941

Cumulative Model Updates: 1,830
Cumulative Timesteps: 15,305,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 15305756...
Checkpoint 15305756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459.75529
Policy Entropy: 2.90595
Value Function Loss: 1.82509

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.24677
Value Function Update Magnitude: 0.28637

Collected Steps per Second: 21,422.37315
Overall Steps per Second: 9,962.14017

Timestep Collection Time: 2.33625
Timestep Consumption Time: 2.68757
PPO Batch Consumption Time: 0.31042
Total Iteration Time: 5.02382

Cumulative Model Updates: 1,836
Cumulative Timesteps: 15,355,804

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.83736
Policy Entropy: 2.88961
Value Function Loss: 1.78708

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.26543
Value Function Update Magnitude: 0.26889

Collected Steps per Second: 21,333.69690
Overall Steps per Second: 9,730.45322

Timestep Collection Time: 2.34418
Timestep Consumption Time: 2.79536
PPO Batch Consumption Time: 0.32017
Total Iteration Time: 5.13953

Cumulative Model Updates: 1,842
Cumulative Timesteps: 15,405,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 15405814...
Checkpoint 15405814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642.16843
Policy Entropy: 2.86599
Value Function Loss: 1.86167

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.27602
Value Function Update Magnitude: 0.29034

Collected Steps per Second: 21,669.35729
Overall Steps per Second: 10,134.70041

Timestep Collection Time: 2.30907
Timestep Consumption Time: 2.62803
PPO Batch Consumption Time: 0.30976
Total Iteration Time: 4.93710

Cumulative Model Updates: 1,848
Cumulative Timesteps: 15,455,850

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.67748
Policy Entropy: 2.84360
Value Function Loss: 1.87250

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.11098
Policy Update Magnitude: 0.30136
Value Function Update Magnitude: 0.31415

Collected Steps per Second: 21,857.29035
Overall Steps per Second: 9,957.62892

Timestep Collection Time: 2.28885
Timestep Consumption Time: 2.73524
PPO Batch Consumption Time: 0.31238
Total Iteration Time: 5.02409

Cumulative Model Updates: 1,854
Cumulative Timesteps: 15,505,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 15505878...
Checkpoint 15505878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 901.65584
Policy Entropy: 2.86076
Value Function Loss: 1.89598

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.30805
Value Function Update Magnitude: 0.28068

Collected Steps per Second: 20,856.07950
Overall Steps per Second: 9,824.60776

Timestep Collection Time: 2.39738
Timestep Consumption Time: 2.69188
PPO Batch Consumption Time: 0.30029
Total Iteration Time: 5.08926

Cumulative Model Updates: 1,860
Cumulative Timesteps: 15,555,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.07536
Policy Entropy: 2.86020
Value Function Loss: 1.90149

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.31544
Value Function Update Magnitude: 0.27605

Collected Steps per Second: 21,803.07176
Overall Steps per Second: 10,031.87260

Timestep Collection Time: 2.29463
Timestep Consumption Time: 2.69247
PPO Batch Consumption Time: 0.30993
Total Iteration Time: 4.98710

Cumulative Model Updates: 1,866
Cumulative Timesteps: 15,605,908

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 15605908...
Checkpoint 15605908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.88328
Policy Entropy: 2.82669
Value Function Loss: 1.88824

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15648
Policy Update Magnitude: 0.23535
Value Function Update Magnitude: 0.26578

Collected Steps per Second: 21,688.52359
Overall Steps per Second: 10,233.20323

Timestep Collection Time: 2.30601
Timestep Consumption Time: 2.58141
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.88742

Cumulative Model Updates: 1,872
Cumulative Timesteps: 15,655,922

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.37741
Policy Entropy: 2.81846
Value Function Loss: 1.91161

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.19242
Value Function Update Magnitude: 0.29312

Collected Steps per Second: 21,840.63655
Overall Steps per Second: 10,288.32722

Timestep Collection Time: 2.28986
Timestep Consumption Time: 2.57118
PPO Batch Consumption Time: 0.29911
Total Iteration Time: 4.86104

Cumulative Model Updates: 1,878
Cumulative Timesteps: 15,705,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 15705934...
Checkpoint 15705934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440.88999
Policy Entropy: 2.80632
Value Function Loss: 1.88649

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.18779
Value Function Update Magnitude: 0.28406

Collected Steps per Second: 21,968.82620
Overall Steps per Second: 10,219.27491

Timestep Collection Time: 2.27768
Timestep Consumption Time: 2.61875
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.89643

Cumulative Model Updates: 1,884
Cumulative Timesteps: 15,755,972

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.35411
Policy Entropy: 2.81039
Value Function Loss: 1.93168

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.20339
Value Function Update Magnitude: 0.28306

Collected Steps per Second: 21,557.83619
Overall Steps per Second: 10,177.77926

Timestep Collection Time: 2.32018
Timestep Consumption Time: 2.59425
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.91443

Cumulative Model Updates: 1,890
Cumulative Timesteps: 15,805,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 15805990...
Checkpoint 15805990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 916.07488
Policy Entropy: 2.83277
Value Function Loss: 1.86956

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.21140
Value Function Update Magnitude: 0.27886

Collected Steps per Second: 21,737.04485
Overall Steps per Second: 10,076.72109

Timestep Collection Time: 2.30151
Timestep Consumption Time: 2.66320
PPO Batch Consumption Time: 0.30178
Total Iteration Time: 4.96471

Cumulative Model Updates: 1,896
Cumulative Timesteps: 15,856,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.10134
Policy Entropy: 2.83445
Value Function Loss: 1.87655

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.20050
Value Function Update Magnitude: 0.32870

Collected Steps per Second: 21,818.95356
Overall Steps per Second: 10,198.27140

Timestep Collection Time: 2.29186
Timestep Consumption Time: 2.61152
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.90338

Cumulative Model Updates: 1,902
Cumulative Timesteps: 15,906,024

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 15906024...
Checkpoint 15906024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648.37247
Policy Entropy: 2.83838
Value Function Loss: 1.86324

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14535
Policy Update Magnitude: 0.20625
Value Function Update Magnitude: 0.34455

Collected Steps per Second: 21,585.26670
Overall Steps per Second: 10,158.96887

Timestep Collection Time: 2.31686
Timestep Consumption Time: 2.60589
PPO Batch Consumption Time: 0.30591
Total Iteration Time: 4.92274

Cumulative Model Updates: 1,908
Cumulative Timesteps: 15,956,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.83068
Policy Entropy: 2.86056
Value Function Loss: 1.95536

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.20523
Value Function Update Magnitude: 0.42050

Collected Steps per Second: 21,873.63842
Overall Steps per Second: 10,003.90237

Timestep Collection Time: 2.28595
Timestep Consumption Time: 2.71230
PPO Batch Consumption Time: 0.30840
Total Iteration Time: 4.99825

Cumulative Model Updates: 1,914
Cumulative Timesteps: 16,006,036

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 16006036...
Checkpoint 16006036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830.45742
Policy Entropy: 2.87461
Value Function Loss: 1.87021

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.20427
Value Function Update Magnitude: 0.34127

Collected Steps per Second: 21,334.46212
Overall Steps per Second: 9,826.82041

Timestep Collection Time: 2.34447
Timestep Consumption Time: 2.74548
PPO Batch Consumption Time: 0.31666
Total Iteration Time: 5.08995

Cumulative Model Updates: 1,920
Cumulative Timesteps: 16,056,054

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.20271
Policy Entropy: 2.85163
Value Function Loss: 1.91924

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.14508
Policy Update Magnitude: 0.21473
Value Function Update Magnitude: 0.33084

Collected Steps per Second: 19,922.07406
Overall Steps per Second: 9,602.22500

Timestep Collection Time: 2.51028
Timestep Consumption Time: 2.69789
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 5.20817

Cumulative Model Updates: 1,926
Cumulative Timesteps: 16,106,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 16106064...
Checkpoint 16106064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.57589
Policy Entropy: 2.83103
Value Function Loss: 1.90799

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.21369
Value Function Update Magnitude: 0.34203

Collected Steps per Second: 21,601.78170
Overall Steps per Second: 10,052.24042

Timestep Collection Time: 2.31518
Timestep Consumption Time: 2.66003
PPO Batch Consumption Time: 0.30147
Total Iteration Time: 4.97521

Cumulative Model Updates: 1,932
Cumulative Timesteps: 16,156,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712.84865
Policy Entropy: 2.82385
Value Function Loss: 1.96263

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.20222
Value Function Update Magnitude: 0.40452

Collected Steps per Second: 20,201.10107
Overall Steps per Second: 9,849.50356

Timestep Collection Time: 2.47709
Timestep Consumption Time: 2.60337
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 5.08046

Cumulative Model Updates: 1,938
Cumulative Timesteps: 16,206,116

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 16206116...
Checkpoint 16206116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.65719
Policy Entropy: 2.82704
Value Function Loss: 2.02182

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.24328
Value Function Update Magnitude: 0.38118

Collected Steps per Second: 21,288.17097
Overall Steps per Second: 10,028.98843

Timestep Collection Time: 2.34966
Timestep Consumption Time: 2.63788
PPO Batch Consumption Time: 0.30024
Total Iteration Time: 4.98754

Cumulative Model Updates: 1,944
Cumulative Timesteps: 16,256,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665.54458
Policy Entropy: 2.82074
Value Function Loss: 2.04707

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.16530
Policy Update Magnitude: 0.21391
Value Function Update Magnitude: 0.33085

Collected Steps per Second: 21,571.65999
Overall Steps per Second: 10,327.79611

Timestep Collection Time: 2.31832
Timestep Consumption Time: 2.52395
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.84227

Cumulative Model Updates: 1,950
Cumulative Timesteps: 16,306,146

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 16306146...
Checkpoint 16306146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.57562
Policy Entropy: 2.80183
Value Function Loss: 2.03244

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.15437
Policy Update Magnitude: 0.19304
Value Function Update Magnitude: 0.31475

Collected Steps per Second: 20,372.10608
Overall Steps per Second: 9,686.68208

Timestep Collection Time: 2.45443
Timestep Consumption Time: 2.70750
PPO Batch Consumption Time: 0.30690
Total Iteration Time: 5.16193

Cumulative Model Updates: 1,956
Cumulative Timesteps: 16,356,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.71997
Policy Entropy: 2.80100
Value Function Loss: 1.92529

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.15962
Policy Update Magnitude: 0.19150
Value Function Update Magnitude: 0.31466

Collected Steps per Second: 21,104.06301
Overall Steps per Second: 10,049.75152

Timestep Collection Time: 2.36931
Timestep Consumption Time: 2.60614
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.97545

Cumulative Model Updates: 1,962
Cumulative Timesteps: 16,406,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 16406150...
Checkpoint 16406150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.31191
Policy Entropy: 2.81560
Value Function Loss: 1.96605

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.17027
Policy Update Magnitude: 0.20768
Value Function Update Magnitude: 0.34499

Collected Steps per Second: 21,309.39112
Overall Steps per Second: 9,991.56046

Timestep Collection Time: 2.34770
Timestep Consumption Time: 2.65933
PPO Batch Consumption Time: 0.30035
Total Iteration Time: 5.00703

Cumulative Model Updates: 1,968
Cumulative Timesteps: 16,456,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.68605
Policy Entropy: 2.82757
Value Function Loss: 2.01737

Mean KL Divergence: 0.02489
SB3 Clip Fraction: 0.24986
Policy Update Magnitude: 0.20526
Value Function Update Magnitude: 0.32269

Collected Steps per Second: 21,693.20627
Overall Steps per Second: 10,059.20117

Timestep Collection Time: 2.30598
Timestep Consumption Time: 2.66698
PPO Batch Consumption Time: 0.30223
Total Iteration Time: 4.97296

Cumulative Model Updates: 1,974
Cumulative Timesteps: 16,506,202

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 16506202...
Checkpoint 16506202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630.05026
Policy Entropy: 2.77869
Value Function Loss: 1.97146

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.19347
Policy Update Magnitude: 0.16839
Value Function Update Magnitude: 0.37089

Collected Steps per Second: 21,363.24968
Overall Steps per Second: 9,953.29916

Timestep Collection Time: 2.34150
Timestep Consumption Time: 2.68417
PPO Batch Consumption Time: 0.30854
Total Iteration Time: 5.02567

Cumulative Model Updates: 1,980
Cumulative Timesteps: 16,556,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.44889
Policy Entropy: 2.75968
Value Function Loss: 1.97303

Mean KL Divergence: 0.02680
SB3 Clip Fraction: 0.25782
Policy Update Magnitude: 0.18463
Value Function Update Magnitude: 0.37886

Collected Steps per Second: 21,754.23902
Overall Steps per Second: 10,077.33070

Timestep Collection Time: 2.29987
Timestep Consumption Time: 2.66493
PPO Batch Consumption Time: 0.30474
Total Iteration Time: 4.96481

Cumulative Model Updates: 1,986
Cumulative Timesteps: 16,606,256

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 16606256...
Checkpoint 16606256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.06211
Policy Entropy: 2.74348
Value Function Loss: 1.98609

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.14404
Policy Update Magnitude: 0.16166
Value Function Update Magnitude: 0.31675

Collected Steps per Second: 21,692.46893
Overall Steps per Second: 10,219.34479

Timestep Collection Time: 2.30522
Timestep Consumption Time: 2.58804
PPO Batch Consumption Time: 0.30089
Total Iteration Time: 4.89327

Cumulative Model Updates: 1,992
Cumulative Timesteps: 16,656,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.50543
Policy Entropy: 2.76341
Value Function Loss: 1.93389

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.21481
Value Function Update Magnitude: 0.26124

Collected Steps per Second: 21,836.57688
Overall Steps per Second: 10,002.04765

Timestep Collection Time: 2.29038
Timestep Consumption Time: 2.71000
PPO Batch Consumption Time: 0.30875
Total Iteration Time: 5.00038

Cumulative Model Updates: 1,998
Cumulative Timesteps: 16,706,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 16706276...
Checkpoint 16706276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614.31489
Policy Entropy: 2.76337
Value Function Loss: 1.86538

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.21943
Policy Update Magnitude: 0.24788
Value Function Update Magnitude: 0.23620

Collected Steps per Second: 21,362.16917
Overall Steps per Second: 10,055.02594

Timestep Collection Time: 2.34068
Timestep Consumption Time: 2.63216
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.97284

Cumulative Model Updates: 2,004
Cumulative Timesteps: 16,756,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.34487
Policy Entropy: 2.75062
Value Function Loss: 1.78526

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.21177
Policy Update Magnitude: 0.23121
Value Function Update Magnitude: 0.23487

Collected Steps per Second: 21,455.78303
Overall Steps per Second: 10,082.04227

Timestep Collection Time: 2.33131
Timestep Consumption Time: 2.62999
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.96130

Cumulative Model Updates: 2,010
Cumulative Timesteps: 16,806,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 16806298...
Checkpoint 16806298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.07079
Policy Entropy: 2.76739
Value Function Loss: 1.79309

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.21056
Policy Update Magnitude: 0.19124
Value Function Update Magnitude: 0.32879

Collected Steps per Second: 19,403.62194
Overall Steps per Second: 9,546.88295

Timestep Collection Time: 2.57838
Timestep Consumption Time: 2.66207
PPO Batch Consumption Time: 0.30117
Total Iteration Time: 5.24045

Cumulative Model Updates: 2,016
Cumulative Timesteps: 16,856,328

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.59994
Policy Entropy: 2.78134
Value Function Loss: 1.84778

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.19681
Policy Update Magnitude: 0.18321
Value Function Update Magnitude: 0.32300

Collected Steps per Second: 21,440.49949
Overall Steps per Second: 9,998.27513

Timestep Collection Time: 2.33315
Timestep Consumption Time: 2.67011
PPO Batch Consumption Time: 0.30438
Total Iteration Time: 5.00326

Cumulative Model Updates: 2,022
Cumulative Timesteps: 16,906,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 16906352...
Checkpoint 16906352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.55083
Policy Entropy: 2.80190
Value Function Loss: 1.91254

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.18005
Value Function Update Magnitude: 0.28295

Collected Steps per Second: 21,285.64278
Overall Steps per Second: 10,259.93616

Timestep Collection Time: 2.34966
Timestep Consumption Time: 2.52503
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.87469

Cumulative Model Updates: 2,028
Cumulative Timesteps: 16,956,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.22485
Policy Entropy: 2.76226
Value Function Loss: 1.87988

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.24930
Value Function Update Magnitude: 0.26264

Collected Steps per Second: 21,623.23550
Overall Steps per Second: 10,023.05302

Timestep Collection Time: 2.31371
Timestep Consumption Time: 2.67778
PPO Batch Consumption Time: 0.30245
Total Iteration Time: 4.99149

Cumulative Model Updates: 2,034
Cumulative Timesteps: 17,006,396

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 17006396...
Checkpoint 17006396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.20440
Policy Entropy: 2.76138
Value Function Loss: 1.81171

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.16115
Policy Update Magnitude: 0.26182
Value Function Update Magnitude: 0.27881

Collected Steps per Second: 21,480.24389
Overall Steps per Second: 9,977.62634

Timestep Collection Time: 2.32865
Timestep Consumption Time: 2.68456
PPO Batch Consumption Time: 0.30411
Total Iteration Time: 5.01322

Cumulative Model Updates: 2,040
Cumulative Timesteps: 17,056,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.06305
Policy Entropy: 2.74397
Value Function Loss: 1.73922

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.18839
Policy Update Magnitude: 0.24776
Value Function Update Magnitude: 0.26092

Collected Steps per Second: 22,046.63337
Overall Steps per Second: 10,125.57978

Timestep Collection Time: 2.26865
Timestep Consumption Time: 2.67092
PPO Batch Consumption Time: 0.30058
Total Iteration Time: 4.93957

Cumulative Model Updates: 2,046
Cumulative Timesteps: 17,106,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 17106432...
Checkpoint 17106432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.44689
Policy Entropy: 2.78058
Value Function Loss: 1.76247

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.24264
Policy Update Magnitude: 0.21206
Value Function Update Magnitude: 0.37589

Collected Steps per Second: 21,237.47040
Overall Steps per Second: 9,935.79661

Timestep Collection Time: 2.35593
Timestep Consumption Time: 2.67980
PPO Batch Consumption Time: 0.30859
Total Iteration Time: 5.03573

Cumulative Model Updates: 2,052
Cumulative Timesteps: 17,156,466

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.98926
Policy Entropy: 2.77766
Value Function Loss: 1.86238

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.21193
Policy Update Magnitude: 0.19002
Value Function Update Magnitude: 0.36631

Collected Steps per Second: 21,581.27613
Overall Steps per Second: 10,056.45128

Timestep Collection Time: 2.31766
Timestep Consumption Time: 2.65607
PPO Batch Consumption Time: 0.30097
Total Iteration Time: 4.97372

Cumulative Model Updates: 2,058
Cumulative Timesteps: 17,206,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 17206484...
Checkpoint 17206484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 784.09515
Policy Entropy: 2.78292
Value Function Loss: 1.96800

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.19406
Policy Update Magnitude: 0.22831
Value Function Update Magnitude: 0.30427

Collected Steps per Second: 21,732.88306
Overall Steps per Second: 10,240.90659

Timestep Collection Time: 2.30149
Timestep Consumption Time: 2.58265
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.88414

Cumulative Model Updates: 2,064
Cumulative Timesteps: 17,256,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 865.94001
Policy Entropy: 2.79420
Value Function Loss: 1.90718

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.15573
Policy Update Magnitude: 0.21354
Value Function Update Magnitude: 0.28892

Collected Steps per Second: 21,773.08064
Overall Steps per Second: 10,292.60451

Timestep Collection Time: 2.29825
Timestep Consumption Time: 2.56349
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.86174

Cumulative Model Updates: 2,070
Cumulative Timesteps: 17,306,542

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 17306542...
Checkpoint 17306542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704.43911
Policy Entropy: 2.79647
Value Function Loss: 1.92153

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14079
Policy Update Magnitude: 0.20433
Value Function Update Magnitude: 0.27555

Collected Steps per Second: 20,881.96722
Overall Steps per Second: 9,913.35522

Timestep Collection Time: 2.39613
Timestep Consumption Time: 2.65120
PPO Batch Consumption Time: 0.31184
Total Iteration Time: 5.04733

Cumulative Model Updates: 2,076
Cumulative Timesteps: 17,356,578

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.10308
Policy Entropy: 2.79479
Value Function Loss: 1.81972

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.16484
Policy Update Magnitude: 0.17999
Value Function Update Magnitude: 0.35711

Collected Steps per Second: 21,639.76440
Overall Steps per Second: 10,054.36132

Timestep Collection Time: 2.31056
Timestep Consumption Time: 2.66241
PPO Batch Consumption Time: 0.29929
Total Iteration Time: 4.97297

Cumulative Model Updates: 2,082
Cumulative Timesteps: 17,406,578

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 17406578...
Checkpoint 17406578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.98329
Policy Entropy: 2.79136
Value Function Loss: 1.84111

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.14489
Policy Update Magnitude: 0.16084
Value Function Update Magnitude: 0.34909

Collected Steps per Second: 21,590.32149
Overall Steps per Second: 10,173.23886

Timestep Collection Time: 2.31585
Timestep Consumption Time: 2.59900
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.91486

Cumulative Model Updates: 2,088
Cumulative Timesteps: 17,456,578

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.50534
Policy Entropy: 2.78433
Value Function Loss: 1.79907

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.14432
Policy Update Magnitude: 0.19095
Value Function Update Magnitude: 0.38521

Collected Steps per Second: 20,453.14418
Overall Steps per Second: 9,605.73699

Timestep Collection Time: 2.44598
Timestep Consumption Time: 2.76216
PPO Batch Consumption Time: 0.30758
Total Iteration Time: 5.20814

Cumulative Model Updates: 2,094
Cumulative Timesteps: 17,506,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 17506606...
Checkpoint 17506606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.47357
Policy Entropy: 2.79375
Value Function Loss: 1.87435

Mean KL Divergence: 0.03769
SB3 Clip Fraction: 0.33175
Policy Update Magnitude: 0.19662
Value Function Update Magnitude: 0.34162

Collected Steps per Second: 19,627.04380
Overall Steps per Second: 9,439.83536

Timestep Collection Time: 2.54893
Timestep Consumption Time: 2.75074
PPO Batch Consumption Time: 0.30206
Total Iteration Time: 5.29967

Cumulative Model Updates: 2,100
Cumulative Timesteps: 17,556,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.28228
Policy Entropy: 2.75608
Value Function Loss: 1.99508

Mean KL Divergence: 0.04743
SB3 Clip Fraction: 0.35326
Policy Update Magnitude: 0.16177
Value Function Update Magnitude: 0.30967

Collected Steps per Second: 20,657.20696
Overall Steps per Second: 9,846.45604

Timestep Collection Time: 2.42124
Timestep Consumption Time: 2.65836
PPO Batch Consumption Time: 0.30434
Total Iteration Time: 5.07959

Cumulative Model Updates: 2,106
Cumulative Timesteps: 17,606,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 17606650...
Checkpoint 17606650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737.70209
Policy Entropy: 2.75030
Value Function Loss: 1.93634

Mean KL Divergence: 0.02942
SB3 Clip Fraction: 0.30409
Policy Update Magnitude: 0.15985
Value Function Update Magnitude: 0.27697

Collected Steps per Second: 21,540.27250
Overall Steps per Second: 10,051.34278

Timestep Collection Time: 2.32142
Timestep Consumption Time: 2.65344
PPO Batch Consumption Time: 0.30377
Total Iteration Time: 4.97486

Cumulative Model Updates: 2,112
Cumulative Timesteps: 17,656,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.78077
Policy Entropy: 2.74823
Value Function Loss: 1.83934

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.17666
Policy Update Magnitude: 0.21509
Value Function Update Magnitude: 0.26693

Collected Steps per Second: 21,606.72486
Overall Steps per Second: 10,135.73462

Timestep Collection Time: 2.31474
Timestep Consumption Time: 2.61968
PPO Batch Consumption Time: 0.30649
Total Iteration Time: 4.93442

Cumulative Model Updates: 2,118
Cumulative Timesteps: 17,706,668

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 17706668...
Checkpoint 17706668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.16962
Policy Entropy: 2.76935
Value Function Loss: 1.75342

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.17894
Policy Update Magnitude: 0.21990
Value Function Update Magnitude: 0.28930

Collected Steps per Second: 21,717.22153
Overall Steps per Second: 10,040.36114

Timestep Collection Time: 2.30361
Timestep Consumption Time: 2.67908
PPO Batch Consumption Time: 0.30228
Total Iteration Time: 4.98269

Cumulative Model Updates: 2,124
Cumulative Timesteps: 17,756,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.65052
Policy Entropy: 2.78638
Value Function Loss: 1.82584

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.17538
Policy Update Magnitude: 0.19265
Value Function Update Magnitude: 0.27813

Collected Steps per Second: 21,342.10787
Overall Steps per Second: 10,069.38409

Timestep Collection Time: 2.34363
Timestep Consumption Time: 2.62370
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.96733

Cumulative Model Updates: 2,130
Cumulative Timesteps: 17,806,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 17806714...
Checkpoint 17806714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.10200
Policy Entropy: 2.79676
Value Function Loss: 1.80936

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.19500
Value Function Update Magnitude: 0.27903

Collected Steps per Second: 21,453.08225
Overall Steps per Second: 9,934.86850

Timestep Collection Time: 2.33197
Timestep Consumption Time: 2.70363
PPO Batch Consumption Time: 0.30744
Total Iteration Time: 5.03560

Cumulative Model Updates: 2,136
Cumulative Timesteps: 17,856,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.15640
Policy Entropy: 2.81450
Value Function Loss: 1.84032

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.20107
Value Function Update Magnitude: 0.27434

Collected Steps per Second: 21,269.22988
Overall Steps per Second: 9,986.17583

Timestep Collection Time: 2.35185
Timestep Consumption Time: 2.65728
PPO Batch Consumption Time: 0.30109
Total Iteration Time: 5.00912

Cumulative Model Updates: 2,142
Cumulative Timesteps: 17,906,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 17906764...
Checkpoint 17906764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 941.10288
Policy Entropy: 2.81098
Value Function Loss: 1.76213

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.19022
Value Function Update Magnitude: 0.27865

Collected Steps per Second: 21,386.53483
Overall Steps per Second: 10,056.96689

Timestep Collection Time: 2.33876
Timestep Consumption Time: 2.63471
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.97347

Cumulative Model Updates: 2,148
Cumulative Timesteps: 17,956,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935.57083
Policy Entropy: 2.80317
Value Function Loss: 1.73723

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11682
Policy Update Magnitude: 0.18624
Value Function Update Magnitude: 0.26959

Collected Steps per Second: 19,914.02434
Overall Steps per Second: 9,794.34595

Timestep Collection Time: 2.51220
Timestep Consumption Time: 2.59565
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 5.10784

Cumulative Model Updates: 2,154
Cumulative Timesteps: 18,006,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 18006810...
Checkpoint 18006810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.07060
Policy Entropy: 2.78733
Value Function Loss: 1.72376

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.18418
Value Function Update Magnitude: 0.33463

Collected Steps per Second: 21,506.66689
Overall Steps per Second: 10,178.48481

Timestep Collection Time: 2.32626
Timestep Consumption Time: 2.58901
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.91527

Cumulative Model Updates: 2,160
Cumulative Timesteps: 18,056,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.73270
Policy Entropy: 2.74726
Value Function Loss: 1.80934

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.19591
Value Function Update Magnitude: 0.33756

Collected Steps per Second: 21,374.86532
Overall Steps per Second: 10,017.22561

Timestep Collection Time: 2.33985
Timestep Consumption Time: 2.65295
PPO Batch Consumption Time: 0.31214
Total Iteration Time: 4.99280

Cumulative Model Updates: 2,166
Cumulative Timesteps: 18,106,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 18106854...
Checkpoint 18106854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 997.63010
Policy Entropy: 2.72133
Value Function Loss: 1.84507

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.25294
Value Function Update Magnitude: 0.29205

Collected Steps per Second: 20,882.73201
Overall Steps per Second: 10,179.27752

Timestep Collection Time: 2.39586
Timestep Consumption Time: 2.51923
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.91508

Cumulative Model Updates: 2,172
Cumulative Timesteps: 18,156,886

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.79931
Policy Entropy: 2.71428
Value Function Loss: 1.84080

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.16733
Policy Update Magnitude: 0.25132
Value Function Update Magnitude: 0.29952

Collected Steps per Second: 21,591.58176
Overall Steps per Second: 10,161.70757

Timestep Collection Time: 2.31692
Timestep Consumption Time: 2.60607
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.92299

Cumulative Model Updates: 2,178
Cumulative Timesteps: 18,206,912

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 18206912...
Checkpoint 18206912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.42729
Policy Entropy: 2.72128
Value Function Loss: 1.85850

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.21544
Value Function Update Magnitude: 0.30877

Collected Steps per Second: 21,633.09360
Overall Steps per Second: 10,196.34964

Timestep Collection Time: 2.31257
Timestep Consumption Time: 2.59389
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.90646

Cumulative Model Updates: 2,184
Cumulative Timesteps: 18,256,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,839.84238
Policy Entropy: 2.72211
Value Function Loss: 1.89222

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12047
Policy Update Magnitude: 0.25932
Value Function Update Magnitude: 0.29392

Collected Steps per Second: 21,718.72137
Overall Steps per Second: 9,930.23383

Timestep Collection Time: 2.30290
Timestep Consumption Time: 2.73384
PPO Batch Consumption Time: 0.31086
Total Iteration Time: 5.03674

Cumulative Model Updates: 2,190
Cumulative Timesteps: 18,306,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 18306956...
Checkpoint 18306956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.90378
Policy Entropy: 2.71647
Value Function Loss: 1.84193

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.16852
Policy Update Magnitude: 0.27089
Value Function Update Magnitude: 0.34120

Collected Steps per Second: 21,222.45534
Overall Steps per Second: 9,770.49778

Timestep Collection Time: 2.35750
Timestep Consumption Time: 2.76322
PPO Batch Consumption Time: 0.31154
Total Iteration Time: 5.12072

Cumulative Model Updates: 2,196
Cumulative Timesteps: 18,356,988

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,785.40615
Policy Entropy: 2.75639
Value Function Loss: 1.71710

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.17257
Policy Update Magnitude: 0.23957
Value Function Update Magnitude: 0.30834

Collected Steps per Second: 21,026.87739
Overall Steps per Second: 9,993.28713

Timestep Collection Time: 2.37877
Timestep Consumption Time: 2.62639
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 5.00516

Cumulative Model Updates: 2,202
Cumulative Timesteps: 18,407,006

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 18407006...
Checkpoint 18407006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.91588
Policy Entropy: 2.75581
Value Function Loss: 1.66716

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.21701
Value Function Update Magnitude: 0.28138

Collected Steps per Second: 21,142.15497
Overall Steps per Second: 9,904.83507

Timestep Collection Time: 2.36523
Timestep Consumption Time: 2.68342
PPO Batch Consumption Time: 0.30241
Total Iteration Time: 5.04865

Cumulative Model Updates: 2,208
Cumulative Timesteps: 18,457,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,189.36321
Policy Entropy: 2.76557
Value Function Loss: 1.70272

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.19848
Policy Update Magnitude: 0.18743
Value Function Update Magnitude: 0.26865

Collected Steps per Second: 21,188.89666
Overall Steps per Second: 10,028.43898

Timestep Collection Time: 2.36020
Timestep Consumption Time: 2.62662
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.98682

Cumulative Model Updates: 2,214
Cumulative Timesteps: 18,507,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 18507022...
Checkpoint 18507022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.55287
Policy Entropy: 2.74937
Value Function Loss: 1.68373

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.17044
Value Function Update Magnitude: 0.33576

Collected Steps per Second: 21,376.52755
Overall Steps per Second: 10,192.04670

Timestep Collection Time: 2.34051
Timestep Consumption Time: 2.56841
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.90893

Cumulative Model Updates: 2,220
Cumulative Timesteps: 18,557,054

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.12751
Policy Entropy: 2.74798
Value Function Loss: 1.81681

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.16620
Value Function Update Magnitude: 0.32588

Collected Steps per Second: 21,333.33788
Overall Steps per Second: 10,011.57293

Timestep Collection Time: 2.34412
Timestep Consumption Time: 2.65089
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.99502

Cumulative Model Updates: 2,226
Cumulative Timesteps: 18,607,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 18607062...
Checkpoint 18607062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.62678
Policy Entropy: 2.73984
Value Function Loss: 1.83750

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.16522
Value Function Update Magnitude: 0.28060

Collected Steps per Second: 21,510.63953
Overall Steps per Second: 10,240.30747

Timestep Collection Time: 2.32452
Timestep Consumption Time: 2.55834
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.88286

Cumulative Model Updates: 2,232
Cumulative Timesteps: 18,657,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,534.09515
Policy Entropy: 2.71888
Value Function Loss: 1.95644

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.17370
Policy Update Magnitude: 0.20402
Value Function Update Magnitude: 0.29681

Collected Steps per Second: 21,605.32994
Overall Steps per Second: 10,028.01201

Timestep Collection Time: 2.31443
Timestep Consumption Time: 2.67200
PPO Batch Consumption Time: 0.30360
Total Iteration Time: 4.98643

Cumulative Model Updates: 2,238
Cumulative Timesteps: 18,707,068

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 18707068...
Checkpoint 18707068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 807.37441
Policy Entropy: 2.72071
Value Function Loss: 2.23996

Mean KL Divergence: 0.02666
SB3 Clip Fraction: 0.26944
Policy Update Magnitude: 0.15659
Value Function Update Magnitude: 0.29935

Collected Steps per Second: 21,305.47888
Overall Steps per Second: 10,048.43427

Timestep Collection Time: 2.34710
Timestep Consumption Time: 2.62940
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.97650

Cumulative Model Updates: 2,244
Cumulative Timesteps: 18,757,074

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.77720
Policy Entropy: 2.70708
Value Function Loss: 2.18935

Mean KL Divergence: 0.02857
SB3 Clip Fraction: 0.25706
Policy Update Magnitude: 0.14524
Value Function Update Magnitude: 0.24566

Collected Steps per Second: 21,651.72243
Overall Steps per Second: 10,232.00121

Timestep Collection Time: 2.30929
Timestep Consumption Time: 2.57734
PPO Batch Consumption Time: 0.30032
Total Iteration Time: 4.88663

Cumulative Model Updates: 2,250
Cumulative Timesteps: 18,807,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 18807074...
Checkpoint 18807074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.06508
Policy Entropy: 2.70030
Value Function Loss: 2.11893

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.17386
Policy Update Magnitude: 0.13995
Value Function Update Magnitude: 0.18980

Collected Steps per Second: 20,840.61771
Overall Steps per Second: 10,168.07605

Timestep Collection Time: 2.39926
Timestep Consumption Time: 2.51829
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.91755

Cumulative Model Updates: 2,256
Cumulative Timesteps: 18,857,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.01575
Policy Entropy: 2.71508
Value Function Loss: 2.10756

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.22160
Policy Update Magnitude: 0.13380
Value Function Update Magnitude: 0.17067

Collected Steps per Second: 21,283.96577
Overall Steps per Second: 9,995.61460

Timestep Collection Time: 2.34966
Timestep Consumption Time: 2.65354
PPO Batch Consumption Time: 0.31104
Total Iteration Time: 5.00319

Cumulative Model Updates: 2,262
Cumulative Timesteps: 18,907,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 18907086...
Checkpoint 18907086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.39557
Policy Entropy: 2.69782
Value Function Loss: 2.11289

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.17485
Policy Update Magnitude: 0.13659
Value Function Update Magnitude: 0.16460

Collected Steps per Second: 21,459.75324
Overall Steps per Second: 10,086.99234

Timestep Collection Time: 2.33050
Timestep Consumption Time: 2.62757
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.95807

Cumulative Model Updates: 2,268
Cumulative Timesteps: 18,957,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.63284
Policy Entropy: 2.68122
Value Function Loss: 2.02785

Mean KL Divergence: 0.02690
SB3 Clip Fraction: 0.26399
Policy Update Magnitude: 0.15837
Value Function Update Magnitude: 0.16160

Collected Steps per Second: 21,434.08344
Overall Steps per Second: 9,978.28473

Timestep Collection Time: 2.33283
Timestep Consumption Time: 2.67826
PPO Batch Consumption Time: 0.30569
Total Iteration Time: 5.01108

Cumulative Model Updates: 2,274
Cumulative Timesteps: 19,007,100

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 19007100...
Checkpoint 19007100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.79398
Policy Entropy: 2.68628
Value Function Loss: 2.03711

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.19483
Policy Update Magnitude: 0.14814
Value Function Update Magnitude: 0.16063

Collected Steps per Second: 21,410.58592
Overall Steps per Second: 10,030.93078

Timestep Collection Time: 2.33529
Timestep Consumption Time: 2.64929
PPO Batch Consumption Time: 0.29808
Total Iteration Time: 4.98458

Cumulative Model Updates: 2,280
Cumulative Timesteps: 19,057,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.48901
Policy Entropy: 2.66599
Value Function Loss: 1.94281

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.20576
Policy Update Magnitude: 0.14535
Value Function Update Magnitude: 0.16351

Collected Steps per Second: 21,720.96234
Overall Steps per Second: 9,973.42692

Timestep Collection Time: 2.30349
Timestep Consumption Time: 2.71324
PPO Batch Consumption Time: 0.31208
Total Iteration Time: 5.01673

Cumulative Model Updates: 2,286
Cumulative Timesteps: 19,107,134

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 19107134...
Checkpoint 19107134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703.05622
Policy Entropy: 2.63398
Value Function Loss: 1.95231

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.21001
Policy Update Magnitude: 0.13673
Value Function Update Magnitude: 0.18381

Collected Steps per Second: 21,411.08120
Overall Steps per Second: 10,168.27639

Timestep Collection Time: 2.33543
Timestep Consumption Time: 2.58222
PPO Batch Consumption Time: 0.29832
Total Iteration Time: 4.91765

Cumulative Model Updates: 2,292
Cumulative Timesteps: 19,157,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.32920
Policy Entropy: 2.62929
Value Function Loss: 1.93647

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.17611
Policy Update Magnitude: 0.17162
Value Function Update Magnitude: 0.20730

Collected Steps per Second: 19,875.05067
Overall Steps per Second: 8,988.93143

Timestep Collection Time: 2.51622
Timestep Consumption Time: 3.04729
PPO Batch Consumption Time: 0.35216
Total Iteration Time: 5.56351

Cumulative Model Updates: 2,298
Cumulative Timesteps: 19,207,148

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 19207148...
Checkpoint 19207148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.52951
Policy Entropy: 2.65194
Value Function Loss: 1.91992

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.16498
Policy Update Magnitude: 0.16236
Value Function Update Magnitude: 0.20239

Collected Steps per Second: 20,579.91039
Overall Steps per Second: 9,073.87411

Timestep Collection Time: 2.43023
Timestep Consumption Time: 3.08163
PPO Batch Consumption Time: 0.36721
Total Iteration Time: 5.51187

Cumulative Model Updates: 2,304
Cumulative Timesteps: 19,257,162

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.91629
Policy Entropy: 2.65558
Value Function Loss: 1.88102

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.18563
Policy Update Magnitude: 0.16638
Value Function Update Magnitude: 0.19369

Collected Steps per Second: 20,285.58292
Overall Steps per Second: 9,723.60237

Timestep Collection Time: 2.46599
Timestep Consumption Time: 2.67861
PPO Batch Consumption Time: 0.29960
Total Iteration Time: 5.14460

Cumulative Model Updates: 2,310
Cumulative Timesteps: 19,307,186

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 19307186...
Checkpoint 19307186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.85650
Policy Entropy: 2.65979
Value Function Loss: 1.86988

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.18541
Policy Update Magnitude: 0.18548
Value Function Update Magnitude: 0.18641

Collected Steps per Second: 21,948.37427
Overall Steps per Second: 10,159.40146

Timestep Collection Time: 2.27826
Timestep Consumption Time: 2.64369
PPO Batch Consumption Time: 0.31046
Total Iteration Time: 4.92194

Cumulative Model Updates: 2,316
Cumulative Timesteps: 19,357,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.34279
Policy Entropy: 2.66703
Value Function Loss: 1.84448

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.18574
Value Function Update Magnitude: 0.19513

Collected Steps per Second: 21,854.73750
Overall Steps per Second: 10,075.07141

Timestep Collection Time: 2.28802
Timestep Consumption Time: 2.67512
PPO Batch Consumption Time: 0.30156
Total Iteration Time: 4.96314

Cumulative Model Updates: 2,322
Cumulative Timesteps: 19,407,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 19407194...
Checkpoint 19407194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.06018
Policy Entropy: 2.66669
Value Function Loss: 1.84807

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.19099
Policy Update Magnitude: 0.17416
Value Function Update Magnitude: 0.20539

Collected Steps per Second: 21,959.77492
Overall Steps per Second: 10,037.52141

Timestep Collection Time: 2.27789
Timestep Consumption Time: 2.70561
PPO Batch Consumption Time: 0.30550
Total Iteration Time: 4.98350

Cumulative Model Updates: 2,328
Cumulative Timesteps: 19,457,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.35665
Policy Entropy: 2.67527
Value Function Loss: 1.79246

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.17373
Policy Update Magnitude: 0.17457
Value Function Update Magnitude: 0.21348

Collected Steps per Second: 19,910.61447
Overall Steps per Second: 9,552.71269

Timestep Collection Time: 2.51132
Timestep Consumption Time: 2.72300
PPO Batch Consumption Time: 0.32421
Total Iteration Time: 5.23432

Cumulative Model Updates: 2,334
Cumulative Timesteps: 19,507,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 19507218...
Checkpoint 19507218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.73739
Policy Entropy: 2.66258
Value Function Loss: 1.75224

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11934
Policy Update Magnitude: 0.19805
Value Function Update Magnitude: 0.21710

Collected Steps per Second: 18,934.88544
Overall Steps per Second: 8,590.72782

Timestep Collection Time: 2.64147
Timestep Consumption Time: 3.18062
PPO Batch Consumption Time: 0.35632
Total Iteration Time: 5.82209

Cumulative Model Updates: 2,340
Cumulative Timesteps: 19,557,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.41662
Policy Entropy: 2.68493
Value Function Loss: 1.70654

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.26236
Value Function Update Magnitude: 0.21219

Collected Steps per Second: 20,296.11366
Overall Steps per Second: 9,775.05221

Timestep Collection Time: 2.46372
Timestep Consumption Time: 2.65175
PPO Batch Consumption Time: 0.29956
Total Iteration Time: 5.11547

Cumulative Model Updates: 2,346
Cumulative Timesteps: 19,607,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 19607238...
Checkpoint 19607238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548.12281
Policy Entropy: 2.69268
Value Function Loss: 1.68942

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.14884
Policy Update Magnitude: 0.28660
Value Function Update Magnitude: 0.19334

Collected Steps per Second: 21,644.59082
Overall Steps per Second: 10,254.33842

Timestep Collection Time: 2.31106
Timestep Consumption Time: 2.56707
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.87813

Cumulative Model Updates: 2,352
Cumulative Timesteps: 19,657,260

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.38992
Policy Entropy: 2.69583
Value Function Loss: 1.67009

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.23534
Value Function Update Magnitude: 0.19493

Collected Steps per Second: 21,943.84063
Overall Steps per Second: 10,380.81467

Timestep Collection Time: 2.27918
Timestep Consumption Time: 2.53874
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.81793

Cumulative Model Updates: 2,358
Cumulative Timesteps: 19,707,274

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 19707274...
Checkpoint 19707274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.15521
Policy Entropy: 2.71864
Value Function Loss: 1.63076

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.21771
Value Function Update Magnitude: 0.22286

Collected Steps per Second: 20,735.96983
Overall Steps per Second: 9,667.64546

Timestep Collection Time: 2.41252
Timestep Consumption Time: 2.76206
PPO Batch Consumption Time: 0.31739
Total Iteration Time: 5.17458

Cumulative Model Updates: 2,364
Cumulative Timesteps: 19,757,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.34386
Policy Entropy: 2.72382
Value Function Loss: 1.62856

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.23662
Value Function Update Magnitude: 0.22430

Collected Steps per Second: 21,477.71929
Overall Steps per Second: 10,145.14402

Timestep Collection Time: 2.32930
Timestep Consumption Time: 2.60193
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.93123

Cumulative Model Updates: 2,370
Cumulative Timesteps: 19,807,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 19807328...
Checkpoint 19807328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.77050
Policy Entropy: 2.73221
Value Function Loss: 1.66958

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.23760
Value Function Update Magnitude: 0.21005

Collected Steps per Second: 21,310.42219
Overall Steps per Second: 10,101.83743

Timestep Collection Time: 2.34627
Timestep Consumption Time: 2.60332
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.94959

Cumulative Model Updates: 2,376
Cumulative Timesteps: 19,857,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.76956
Policy Entropy: 2.75088
Value Function Loss: 1.65532

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.15293
Policy Update Magnitude: 0.21419
Value Function Update Magnitude: 0.22432

Collected Steps per Second: 20,789.49193
Overall Steps per Second: 9,779.06041

Timestep Collection Time: 2.40583
Timestep Consumption Time: 2.70877
PPO Batch Consumption Time: 0.31149
Total Iteration Time: 5.11460

Cumulative Model Updates: 2,382
Cumulative Timesteps: 19,907,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 19907344...
Checkpoint 19907344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.67046
Policy Entropy: 2.73860
Value Function Loss: 1.62197

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.14983
Policy Update Magnitude: 0.20045
Value Function Update Magnitude: 0.21322

Collected Steps per Second: 21,137.57527
Overall Steps per Second: 10,231.23277

Timestep Collection Time: 2.36650
Timestep Consumption Time: 2.52265
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.88915

Cumulative Model Updates: 2,388
Cumulative Timesteps: 19,957,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.12717
Policy Entropy: 2.74040
Value Function Loss: 1.58090

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13442
Policy Update Magnitude: 0.23234
Value Function Update Magnitude: 0.23752

Collected Steps per Second: 21,248.05434
Overall Steps per Second: 10,018.30782

Timestep Collection Time: 2.35447
Timestep Consumption Time: 2.63918
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.99366

Cumulative Model Updates: 2,394
Cumulative Timesteps: 20,007,394

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 20007394...
Checkpoint 20007394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.64081
Policy Entropy: 2.73631
Value Function Loss: 1.57769

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.22988
Value Function Update Magnitude: 0.21446

Collected Steps per Second: 20,841.49593
Overall Steps per Second: 9,850.91163

Timestep Collection Time: 2.39916
Timestep Consumption Time: 2.67672
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 5.07588

Cumulative Model Updates: 2,400
Cumulative Timesteps: 20,057,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740.03142
Policy Entropy: 2.74572
Value Function Loss: 1.52940

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14456
Policy Update Magnitude: 0.21551
Value Function Update Magnitude: 0.20285

Collected Steps per Second: 21,550.67780
Overall Steps per Second: 10,022.21632

Timestep Collection Time: 2.32132
Timestep Consumption Time: 2.67019
PPO Batch Consumption Time: 0.29994
Total Iteration Time: 4.99151

Cumulative Model Updates: 2,406
Cumulative Timesteps: 20,107,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 20107422...
Checkpoint 20107422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 999.84541
Policy Entropy: 2.72075
Value Function Loss: 1.54786

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.20666
Value Function Update Magnitude: 0.19850

Collected Steps per Second: 20,876.69691
Overall Steps per Second: 9,756.70014

Timestep Collection Time: 2.39636
Timestep Consumption Time: 2.73120
PPO Batch Consumption Time: 0.31015
Total Iteration Time: 5.12755

Cumulative Model Updates: 2,412
Cumulative Timesteps: 20,157,450

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.81220
Policy Entropy: 2.73356
Value Function Loss: 1.58013

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.21070
Value Function Update Magnitude: 0.20718

Collected Steps per Second: 20,753.95178
Overall Steps per Second: 10,032.75101

Timestep Collection Time: 2.40928
Timestep Consumption Time: 2.57460
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.98388

Cumulative Model Updates: 2,418
Cumulative Timesteps: 20,207,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 20207452...
Checkpoint 20207452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 964.56338
Policy Entropy: 2.72856
Value Function Loss: 1.63580

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.22477
Value Function Update Magnitude: 0.20954

Collected Steps per Second: 20,445.13923
Overall Steps per Second: 9,923.24840

Timestep Collection Time: 2.44616
Timestep Consumption Time: 2.59373
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 5.03988

Cumulative Model Updates: 2,424
Cumulative Timesteps: 20,257,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.39928
Policy Entropy: 2.73655
Value Function Loss: 1.64357

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.26648
Policy Update Magnitude: 0.22106
Value Function Update Magnitude: 0.19861

Collected Steps per Second: 21,692.27697
Overall Steps per Second: 9,932.01162

Timestep Collection Time: 2.30524
Timestep Consumption Time: 2.72959
PPO Batch Consumption Time: 0.31252
Total Iteration Time: 5.03483

Cumulative Model Updates: 2,430
Cumulative Timesteps: 20,307,470

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 20307470...
Checkpoint 20307470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.51607
Policy Entropy: 2.72784
Value Function Loss: 1.73755

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.22958
Policy Update Magnitude: 0.15781
Value Function Update Magnitude: 0.19597

Collected Steps per Second: 21,213.76976
Overall Steps per Second: 10,249.97872

Timestep Collection Time: 2.35819
Timestep Consumption Time: 2.52241
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.88060

Cumulative Model Updates: 2,436
Cumulative Timesteps: 20,357,496

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.67208
Policy Entropy: 2.70672
Value Function Loss: 1.79418

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.21353
Policy Update Magnitude: 0.13987
Value Function Update Magnitude: 0.18758

Collected Steps per Second: 20,893.39014
Overall Steps per Second: 9,930.89476

Timestep Collection Time: 2.39492
Timestep Consumption Time: 2.64370
PPO Batch Consumption Time: 0.30850
Total Iteration Time: 5.03862

Cumulative Model Updates: 2,442
Cumulative Timesteps: 20,407,534

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 20407534...
Checkpoint 20407534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 852.42735
Policy Entropy: 2.70414
Value Function Loss: 1.82615

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13198
Policy Update Magnitude: 0.15107
Value Function Update Magnitude: 0.22432

Collected Steps per Second: 21,195.18977
Overall Steps per Second: 9,967.26175

Timestep Collection Time: 2.36054
Timestep Consumption Time: 2.65910
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 5.01963

Cumulative Model Updates: 2,448
Cumulative Timesteps: 20,457,566

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.26896
Policy Entropy: 2.66950
Value Function Loss: 1.83698

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.16596
Value Function Update Magnitude: 0.18350

Collected Steps per Second: 20,506.35232
Overall Steps per Second: 9,735.15625

Timestep Collection Time: 2.43876
Timestep Consumption Time: 2.69830
PPO Batch Consumption Time: 0.30309
Total Iteration Time: 5.13705

Cumulative Model Updates: 2,454
Cumulative Timesteps: 20,507,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 20507576...
Checkpoint 20507576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.52791
Policy Entropy: 2.69629
Value Function Loss: 1.82407

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.14940
Policy Update Magnitude: 0.17065
Value Function Update Magnitude: 0.18113

Collected Steps per Second: 21,239.97301
Overall Steps per Second: 9,982.28137

Timestep Collection Time: 2.35518
Timestep Consumption Time: 2.65610
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 5.01128

Cumulative Model Updates: 2,460
Cumulative Timesteps: 20,557,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.26003
Policy Entropy: 2.67922
Value Function Loss: 1.81275

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.13571
Policy Update Magnitude: 0.18133
Value Function Update Magnitude: 0.18744

Collected Steps per Second: 20,828.53573
Overall Steps per Second: 9,752.61496

Timestep Collection Time: 2.40094
Timestep Consumption Time: 2.72671
PPO Batch Consumption Time: 0.30952
Total Iteration Time: 5.12765

Cumulative Model Updates: 2,466
Cumulative Timesteps: 20,607,608

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 20607608...
Checkpoint 20607608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584.00888
Policy Entropy: 2.69489
Value Function Loss: 1.78683

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.18317
Value Function Update Magnitude: 0.22206

Collected Steps per Second: 21,338.72877
Overall Steps per Second: 10,042.63865

Timestep Collection Time: 2.34391
Timestep Consumption Time: 2.63646
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.98036

Cumulative Model Updates: 2,472
Cumulative Timesteps: 20,657,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715.68882
Policy Entropy: 2.67479
Value Function Loss: 1.84167

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.18375
Value Function Update Magnitude: 0.19609

Collected Steps per Second: 21,437.63946
Overall Steps per Second: 10,148.97240

Timestep Collection Time: 2.33300
Timestep Consumption Time: 2.59499
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.92799

Cumulative Model Updates: 2,478
Cumulative Timesteps: 20,707,638

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 20707638...
Checkpoint 20707638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.85700
Policy Entropy: 2.69462
Value Function Loss: 1.86463

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13489
Policy Update Magnitude: 0.17829
Value Function Update Magnitude: 0.18963

Collected Steps per Second: 21,201.39216
Overall Steps per Second: 9,935.11743

Timestep Collection Time: 2.35918
Timestep Consumption Time: 2.67528
PPO Batch Consumption Time: 0.30371
Total Iteration Time: 5.03446

Cumulative Model Updates: 2,484
Cumulative Timesteps: 20,757,656

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.59328
Policy Entropy: 2.70562
Value Function Loss: 1.87376

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.18435
Value Function Update Magnitude: 0.19285

Collected Steps per Second: 21,244.82783
Overall Steps per Second: 9,880.36686

Timestep Collection Time: 2.35464
Timestep Consumption Time: 2.70833
PPO Batch Consumption Time: 0.30534
Total Iteration Time: 5.06297

Cumulative Model Updates: 2,490
Cumulative Timesteps: 20,807,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 20807680...
Checkpoint 20807680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798.96239
Policy Entropy: 2.70322
Value Function Loss: 1.78497

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.19709
Value Function Update Magnitude: 0.18156

Collected Steps per Second: 21,454.58702
Overall Steps per Second: 10,103.92674

Timestep Collection Time: 2.33069
Timestep Consumption Time: 2.61828
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.94897

Cumulative Model Updates: 2,496
Cumulative Timesteps: 20,857,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.07162
Policy Entropy: 2.69130
Value Function Loss: 1.75952

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.20346
Value Function Update Magnitude: 0.17465

Collected Steps per Second: 21,308.48520
Overall Steps per Second: 10,151.56907

Timestep Collection Time: 2.34667
Timestep Consumption Time: 2.57907
PPO Batch Consumption Time: 0.29826
Total Iteration Time: 4.92574

Cumulative Model Updates: 2,502
Cumulative Timesteps: 20,907,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 20907688...
Checkpoint 20907688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.63330
Policy Entropy: 2.66966
Value Function Loss: 1.78315

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.23481
Value Function Update Magnitude: 0.20231

Collected Steps per Second: 20,308.38337
Overall Steps per Second: 9,553.60242

Timestep Collection Time: 2.46273
Timestep Consumption Time: 2.77237
PPO Batch Consumption Time: 0.32967
Total Iteration Time: 5.23509

Cumulative Model Updates: 2,508
Cumulative Timesteps: 20,957,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,712.18358
Policy Entropy: 2.66162
Value Function Loss: 1.80909

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.28025
Value Function Update Magnitude: 0.19224

Collected Steps per Second: 20,531.88629
Overall Steps per Second: 10,018.49485

Timestep Collection Time: 2.43572
Timestep Consumption Time: 2.55604
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.99177

Cumulative Model Updates: 2,514
Cumulative Timesteps: 21,007,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 21007712...
Checkpoint 21007712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.02801
Policy Entropy: 2.66279
Value Function Loss: 1.84328

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.14728
Policy Update Magnitude: 0.20817
Value Function Update Magnitude: 0.19269

Collected Steps per Second: 20,162.34137
Overall Steps per Second: 9,565.55071

Timestep Collection Time: 2.48215
Timestep Consumption Time: 2.74975
PPO Batch Consumption Time: 0.32481
Total Iteration Time: 5.23190

Cumulative Model Updates: 2,520
Cumulative Timesteps: 21,057,758

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 999.54663
Policy Entropy: 2.64800
Value Function Loss: 1.80401

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.17251
Value Function Update Magnitude: 0.18841

Collected Steps per Second: 19,524.84370
Overall Steps per Second: 9,488.38747

Timestep Collection Time: 2.56279
Timestep Consumption Time: 2.71082
PPO Batch Consumption Time: 0.30922
Total Iteration Time: 5.27360

Cumulative Model Updates: 2,526
Cumulative Timesteps: 21,107,796

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 21107796...
Checkpoint 21107796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,736.67871
Policy Entropy: 2.61859
Value Function Loss: 1.81278

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.15475
Policy Update Magnitude: 0.17854
Value Function Update Magnitude: 0.20720

Collected Steps per Second: 21,630.17717
Overall Steps per Second: 9,978.16702

Timestep Collection Time: 2.31214
Timestep Consumption Time: 2.70000
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 5.01214

Cumulative Model Updates: 2,532
Cumulative Timesteps: 21,157,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,129.71592
Policy Entropy: 2.62464
Value Function Loss: 1.79759

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.20063
Policy Update Magnitude: 0.20601
Value Function Update Magnitude: 0.21089

Collected Steps per Second: 21,173.64061
Overall Steps per Second: 9,609.98046

Timestep Collection Time: 2.36360
Timestep Consumption Time: 2.84411
PPO Batch Consumption Time: 0.32598
Total Iteration Time: 5.20771

Cumulative Model Updates: 2,538
Cumulative Timesteps: 21,207,854

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 21207854...
Checkpoint 21207854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.02168
Policy Entropy: 2.62603
Value Function Loss: 1.77125

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.16693
Policy Update Magnitude: 0.18154
Value Function Update Magnitude: 0.21624

Collected Steps per Second: 21,125.83991
Overall Steps per Second: 9,871.41716

Timestep Collection Time: 2.36743
Timestep Consumption Time: 2.69911
PPO Batch Consumption Time: 0.30095
Total Iteration Time: 5.06655

Cumulative Model Updates: 2,544
Cumulative Timesteps: 21,257,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.88304
Policy Entropy: 2.62122
Value Function Loss: 1.81034

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.20973
Value Function Update Magnitude: 0.21203

Collected Steps per Second: 21,491.42956
Overall Steps per Second: 9,781.53681

Timestep Collection Time: 2.32651
Timestep Consumption Time: 2.78516
PPO Batch Consumption Time: 0.31692
Total Iteration Time: 5.11167

Cumulative Model Updates: 2,550
Cumulative Timesteps: 21,307,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 21307868...
Checkpoint 21307868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,828.26803
Policy Entropy: 2.59966
Value Function Loss: 1.76180

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.26997
Value Function Update Magnitude: 0.22046

Collected Steps per Second: 20,571.10939
Overall Steps per Second: 9,768.24283

Timestep Collection Time: 2.43195
Timestep Consumption Time: 2.68954
PPO Batch Consumption Time: 0.29885
Total Iteration Time: 5.12149

Cumulative Model Updates: 2,556
Cumulative Timesteps: 21,357,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.74232
Policy Entropy: 2.59486
Value Function Loss: 1.76067

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.16394
Policy Update Magnitude: 0.24278
Value Function Update Magnitude: 0.21798

Collected Steps per Second: 20,289.96881
Overall Steps per Second: 9,853.71587

Timestep Collection Time: 2.46427
Timestep Consumption Time: 2.60996
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 5.07423

Cumulative Model Updates: 2,562
Cumulative Timesteps: 21,407,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 21407896...
Checkpoint 21407896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,640.72739
Policy Entropy: 2.58894
Value Function Loss: 1.71934

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15766
Policy Update Magnitude: 0.20424
Value Function Update Magnitude: 0.22377

Collected Steps per Second: 21,559.91412
Overall Steps per Second: 10,176.78425

Timestep Collection Time: 2.32070
Timestep Consumption Time: 2.59579
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.91648

Cumulative Model Updates: 2,568
Cumulative Timesteps: 21,457,930

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,139.79723
Policy Entropy: 2.58654
Value Function Loss: 1.77345

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.19495
Value Function Update Magnitude: 0.21890

Collected Steps per Second: 18,976.00810
Overall Steps per Second: 9,372.43583

Timestep Collection Time: 2.63564
Timestep Consumption Time: 2.70064
PPO Batch Consumption Time: 0.30500
Total Iteration Time: 5.33629

Cumulative Model Updates: 2,574
Cumulative Timesteps: 21,507,944

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 21507944...
Checkpoint 21507944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,349.09148
Policy Entropy: 2.58946
Value Function Loss: 1.78559

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.17960
Policy Update Magnitude: 0.19863
Value Function Update Magnitude: 0.23390

Collected Steps per Second: 18,761.94842
Overall Steps per Second: 9,251.96320

Timestep Collection Time: 2.66646
Timestep Consumption Time: 2.74082
PPO Batch Consumption Time: 0.30033
Total Iteration Time: 5.40728

Cumulative Model Updates: 2,580
Cumulative Timesteps: 21,557,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,919.93846
Policy Entropy: 2.58670
Value Function Loss: 1.76804

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.19873
Policy Update Magnitude: 0.16736
Value Function Update Magnitude: 0.23049

Collected Steps per Second: 19,722.38503
Overall Steps per Second: 9,616.45632

Timestep Collection Time: 2.53600
Timestep Consumption Time: 2.66508
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 5.20108

Cumulative Model Updates: 2,586
Cumulative Timesteps: 21,607,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 21607988...
Checkpoint 21607988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,960.47827
Policy Entropy: 2.57506
Value Function Loss: 1.74984

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.20801
Policy Update Magnitude: 0.16095
Value Function Update Magnitude: 0.19623

Collected Steps per Second: 21,126.80131
Overall Steps per Second: 9,816.41032

Timestep Collection Time: 2.36780
Timestep Consumption Time: 2.72816
PPO Batch Consumption Time: 0.31310
Total Iteration Time: 5.09596

Cumulative Model Updates: 2,592
Cumulative Timesteps: 21,658,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,189.28153
Policy Entropy: 2.57221
Value Function Loss: 1.73022

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.20129
Policy Update Magnitude: 0.16265
Value Function Update Magnitude: 0.19072

Collected Steps per Second: 20,982.88646
Overall Steps per Second: 9,995.67206

Timestep Collection Time: 2.38366
Timestep Consumption Time: 2.62011
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 5.00377

Cumulative Model Updates: 2,598
Cumulative Timesteps: 21,708,028

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 21708028...
Checkpoint 21708028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,979.70140
Policy Entropy: 2.57708
Value Function Loss: 1.69771

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.19983
Policy Update Magnitude: 0.16142
Value Function Update Magnitude: 0.20200

Collected Steps per Second: 21,413.09291
Overall Steps per Second: 9,888.15673

Timestep Collection Time: 2.33614
Timestep Consumption Time: 2.72284
PPO Batch Consumption Time: 0.30757
Total Iteration Time: 5.05898

Cumulative Model Updates: 2,604
Cumulative Timesteps: 21,758,052

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,934.23982
Policy Entropy: 2.57656
Value Function Loss: 1.64513

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.16850
Policy Update Magnitude: 0.16435
Value Function Update Magnitude: 0.18037

Collected Steps per Second: 21,565.13978
Overall Steps per Second: 10,071.30227

Timestep Collection Time: 2.31893
Timestep Consumption Time: 2.64647
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.96540

Cumulative Model Updates: 2,610
Cumulative Timesteps: 21,808,060

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 21808060...
Checkpoint 21808060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733.62210
Policy Entropy: 2.56704
Value Function Loss: 1.67710

Mean KL Divergence: 0.02736
SB3 Clip Fraction: 0.26489
Policy Update Magnitude: 0.17091
Value Function Update Magnitude: 0.18280

Collected Steps per Second: 20,636.66433
Overall Steps per Second: 9,672.03219

Timestep Collection Time: 2.42297
Timestep Consumption Time: 2.74678
PPO Batch Consumption Time: 0.31630
Total Iteration Time: 5.16975

Cumulative Model Updates: 2,616
Cumulative Timesteps: 21,858,062

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,075.60809
Policy Entropy: 2.55565
Value Function Loss: 1.73301

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.24209
Policy Update Magnitude: 0.16166
Value Function Update Magnitude: 0.21306

Collected Steps per Second: 21,013.98685
Overall Steps per Second: 10,074.99080

Timestep Collection Time: 2.37946
Timestep Consumption Time: 2.58352
PPO Batch Consumption Time: 0.30499
Total Iteration Time: 4.96298

Cumulative Model Updates: 2,622
Cumulative Timesteps: 21,908,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 21908064...
Checkpoint 21908064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,801.89795
Policy Entropy: 2.58391
Value Function Loss: 1.79599

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.23835
Policy Update Magnitude: 0.13625
Value Function Update Magnitude: 0.22337

Collected Steps per Second: 20,394.29126
Overall Steps per Second: 9,901.14278

Timestep Collection Time: 2.45245
Timestep Consumption Time: 2.59909
PPO Batch Consumption Time: 0.30501
Total Iteration Time: 5.05154

Cumulative Model Updates: 2,628
Cumulative Timesteps: 21,958,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,886.25530
Policy Entropy: 2.57247
Value Function Loss: 1.72631

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.17429
Policy Update Magnitude: 0.14280
Value Function Update Magnitude: 0.20970

Collected Steps per Second: 20,078.29741
Overall Steps per Second: 9,921.34682

Timestep Collection Time: 2.49135
Timestep Consumption Time: 2.55051
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 5.04186

Cumulative Model Updates: 2,634
Cumulative Timesteps: 22,008,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 22008102...
Checkpoint 22008102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,262.95624
Policy Entropy: 2.56815
Value Function Loss: 1.68758

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.18857
Value Function Update Magnitude: 0.19075

Collected Steps per Second: 21,232.56662
Overall Steps per Second: 10,178.60585

Timestep Collection Time: 2.35676
Timestep Consumption Time: 2.55944
PPO Batch Consumption Time: 0.29851
Total Iteration Time: 4.91619

Cumulative Model Updates: 2,640
Cumulative Timesteps: 22,058,142

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,398.47371
Policy Entropy: 2.55884
Value Function Loss: 1.63069

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.11842
Policy Update Magnitude: 0.19846
Value Function Update Magnitude: 0.19595

Collected Steps per Second: 21,392.89806
Overall Steps per Second: 10,360.69978

Timestep Collection Time: 2.33760
Timestep Consumption Time: 2.48910
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.82670

Cumulative Model Updates: 2,646
Cumulative Timesteps: 22,108,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 22108150...
Checkpoint 22108150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,246.43993
Policy Entropy: 2.55525
Value Function Loss: 1.57347

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11384
Policy Update Magnitude: 0.18389
Value Function Update Magnitude: 0.19312

Collected Steps per Second: 21,310.19384
Overall Steps per Second: 10,359.30614

Timestep Collection Time: 2.34676
Timestep Consumption Time: 2.48078
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.82754

Cumulative Model Updates: 2,652
Cumulative Timesteps: 22,158,160

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,958.79379
Policy Entropy: 2.57046
Value Function Loss: 1.52002

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11493
Policy Update Magnitude: 0.17911
Value Function Update Magnitude: 0.18824

Collected Steps per Second: 21,469.76966
Overall Steps per Second: 10,379.01198

Timestep Collection Time: 2.32969
Timestep Consumption Time: 2.48945
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.81915

Cumulative Model Updates: 2,658
Cumulative Timesteps: 22,208,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 22208178...
Checkpoint 22208178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,232.72512
Policy Entropy: 2.58004
Value Function Loss: 1.49071

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.17356
Value Function Update Magnitude: 0.20663

Collected Steps per Second: 19,919.66740
Overall Steps per Second: 9,665.45315

Timestep Collection Time: 2.51099
Timestep Consumption Time: 2.66394
PPO Batch Consumption Time: 0.32338
Total Iteration Time: 5.17493

Cumulative Model Updates: 2,664
Cumulative Timesteps: 22,258,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.55687
Policy Entropy: 2.56188
Value Function Loss: 1.52835

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.18059
Value Function Update Magnitude: 0.21971

Collected Steps per Second: 21,506.09596
Overall Steps per Second: 10,219.06155

Timestep Collection Time: 2.32502
Timestep Consumption Time: 2.56800
PPO Batch Consumption Time: 0.30526
Total Iteration Time: 4.89301

Cumulative Model Updates: 2,670
Cumulative Timesteps: 22,308,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 22308198...
Checkpoint 22308198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,359.48720
Policy Entropy: 2.55851
Value Function Loss: 1.54488

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.20853
Policy Update Magnitude: 0.17837
Value Function Update Magnitude: 0.20836

Collected Steps per Second: 21,205.93066
Overall Steps per Second: 10,097.15045

Timestep Collection Time: 2.35877
Timestep Consumption Time: 2.59510
PPO Batch Consumption Time: 0.30752
Total Iteration Time: 4.95387

Cumulative Model Updates: 2,676
Cumulative Timesteps: 22,358,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,523.67361
Policy Entropy: 2.54202
Value Function Loss: 1.61305

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.21150
Policy Update Magnitude: 0.15333
Value Function Update Magnitude: 0.19225

Collected Steps per Second: 20,423.41560
Overall Steps per Second: 10,122.07860

Timestep Collection Time: 2.44954
Timestep Consumption Time: 2.49292
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.94246

Cumulative Model Updates: 2,682
Cumulative Timesteps: 22,408,246

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 22408246...
Checkpoint 22408246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,100.55616
Policy Entropy: 2.55410
Value Function Loss: 1.58924

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.20329
Policy Update Magnitude: 0.14307
Value Function Update Magnitude: 0.18304

Collected Steps per Second: 21,222.54828
Overall Steps per Second: 10,240.46356

Timestep Collection Time: 2.35683
Timestep Consumption Time: 2.52752
PPO Batch Consumption Time: 0.29859
Total Iteration Time: 4.88435

Cumulative Model Updates: 2,688
Cumulative Timesteps: 22,458,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,733.62347
Policy Entropy: 2.55541
Value Function Loss: 1.58974

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.16826
Value Function Update Magnitude: 0.18705

Collected Steps per Second: 21,321.34251
Overall Steps per Second: 10,326.70689

Timestep Collection Time: 2.34535
Timestep Consumption Time: 2.49705
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.84240

Cumulative Model Updates: 2,694
Cumulative Timesteps: 22,508,270

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 22508270...
Checkpoint 22508270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,245.90969
Policy Entropy: 2.55455
Value Function Loss: 1.45498

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10568
Policy Update Magnitude: 0.26633
Value Function Update Magnitude: 0.18504

Collected Steps per Second: 21,108.59534
Overall Steps per Second: 10,277.76551

Timestep Collection Time: 2.37003
Timestep Consumption Time: 2.49757
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.86760

Cumulative Model Updates: 2,700
Cumulative Timesteps: 22,558,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,779.34967
Policy Entropy: 2.56750
Value Function Loss: 1.49582

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.16323
Policy Update Magnitude: 0.21181
Value Function Update Magnitude: 0.17518

Collected Steps per Second: 21,308.52878
Overall Steps per Second: 10,032.00837

Timestep Collection Time: 2.34667
Timestep Consumption Time: 2.63778
PPO Batch Consumption Time: 0.31763
Total Iteration Time: 4.98445

Cumulative Model Updates: 2,706
Cumulative Timesteps: 22,608,302

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 22608302...
Checkpoint 22608302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889.66097
Policy Entropy: 2.55073
Value Function Loss: 1.45770

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.15784
Policy Update Magnitude: 0.16693
Value Function Update Magnitude: 0.17055

Collected Steps per Second: 19,713.83757
Overall Steps per Second: 9,921.42743

Timestep Collection Time: 2.53700
Timestep Consumption Time: 2.50401
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 5.04101

Cumulative Model Updates: 2,712
Cumulative Timesteps: 22,658,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,141.59644
Policy Entropy: 2.51811
Value Function Loss: 1.46900

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.14617
Policy Update Magnitude: 0.16468
Value Function Update Magnitude: 0.18345

Collected Steps per Second: 19,666.48152
Overall Steps per Second: 9,793.79449

Timestep Collection Time: 2.54280
Timestep Consumption Time: 2.56329
PPO Batch Consumption Time: 0.29932
Total Iteration Time: 5.10609

Cumulative Model Updates: 2,718
Cumulative Timesteps: 22,708,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 22708324...
Checkpoint 22708324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,598.48864
Policy Entropy: 2.50194
Value Function Loss: 1.45542

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.19615
Value Function Update Magnitude: 0.19858

Collected Steps per Second: 19,950.06300
Overall Steps per Second: 9,752.39294

Timestep Collection Time: 2.50636
Timestep Consumption Time: 2.62079
PPO Batch Consumption Time: 0.31265
Total Iteration Time: 5.12715

Cumulative Model Updates: 2,724
Cumulative Timesteps: 22,758,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793.73391
Policy Entropy: 2.49917
Value Function Loss: 1.45007

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.13705
Policy Update Magnitude: 0.18048
Value Function Update Magnitude: 0.19930

Collected Steps per Second: 20,098.67793
Overall Steps per Second: 9,741.44828

Timestep Collection Time: 2.48862
Timestep Consumption Time: 2.64593
PPO Batch Consumption Time: 0.31596
Total Iteration Time: 5.13455

Cumulative Model Updates: 2,730
Cumulative Timesteps: 22,808,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 22808344...
Checkpoint 22808344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,488.90177
Policy Entropy: 2.49168
Value Function Loss: 1.45933

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.13476
Policy Update Magnitude: 0.16892
Value Function Update Magnitude: 0.19495

Collected Steps per Second: 20,840.32216
Overall Steps per Second: 10,049.46815

Timestep Collection Time: 2.39996
Timestep Consumption Time: 2.57702
PPO Batch Consumption Time: 0.30629
Total Iteration Time: 4.97698

Cumulative Model Updates: 2,736
Cumulative Timesteps: 22,858,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,764.44535
Policy Entropy: 2.51249
Value Function Loss: 1.40729

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.20947
Value Function Update Magnitude: 0.19386

Collected Steps per Second: 21,050.29741
Overall Steps per Second: 10,266.74977

Timestep Collection Time: 2.37659
Timestep Consumption Time: 2.49622
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.87282

Cumulative Model Updates: 2,742
Cumulative Timesteps: 22,908,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 22908388...
Checkpoint 22908388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,146.93410
Policy Entropy: 2.50748
Value Function Loss: 1.42100

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.19159
Policy Update Magnitude: 0.19293
Value Function Update Magnitude: 0.19690

Collected Steps per Second: 21,269.01282
Overall Steps per Second: 10,318.35970

Timestep Collection Time: 2.35103
Timestep Consumption Time: 2.49509
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.84612

Cumulative Model Updates: 2,748
Cumulative Timesteps: 22,958,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633.00047
Policy Entropy: 2.49246
Value Function Loss: 1.43780

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.15824
Policy Update Magnitude: 0.16004
Value Function Update Magnitude: 0.20472

Collected Steps per Second: 21,033.66168
Overall Steps per Second: 10,160.27517

Timestep Collection Time: 2.37828
Timestep Consumption Time: 2.54521
PPO Batch Consumption Time: 0.30241
Total Iteration Time: 4.92349

Cumulative Model Updates: 2,754
Cumulative Timesteps: 23,008,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 23008416...
Checkpoint 23008416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.70482
Policy Entropy: 2.48513
Value Function Loss: 1.39602

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.20428
Value Function Update Magnitude: 0.21989

Collected Steps per Second: 21,336.67544
Overall Steps per Second: 10,253.18067

Timestep Collection Time: 2.34423
Timestep Consumption Time: 2.53406
PPO Batch Consumption Time: 0.30014
Total Iteration Time: 4.87829

Cumulative Model Updates: 2,760
Cumulative Timesteps: 23,058,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,802.93504
Policy Entropy: 2.46734
Value Function Loss: 1.39226

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.17961
Value Function Update Magnitude: 0.20531

Collected Steps per Second: 21,074.05359
Overall Steps per Second: 10,206.02630

Timestep Collection Time: 2.37297
Timestep Consumption Time: 2.52688
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.89985

Cumulative Model Updates: 2,766
Cumulative Timesteps: 23,108,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 23108442...
Checkpoint 23108442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.86201
Policy Entropy: 2.46984
Value Function Loss: 1.26757

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.15113
Policy Update Magnitude: 0.16622
Value Function Update Magnitude: 0.18850

Collected Steps per Second: 20,995.43559
Overall Steps per Second: 10,253.47030

Timestep Collection Time: 2.38147
Timestep Consumption Time: 2.49493
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.87640

Cumulative Model Updates: 2,772
Cumulative Timesteps: 23,158,442

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.28611
Policy Entropy: 2.45713
Value Function Loss: 1.25411

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.15009
Policy Update Magnitude: 0.17786
Value Function Update Magnitude: 0.19480

Collected Steps per Second: 21,285.21357
Overall Steps per Second: 10,213.82129

Timestep Collection Time: 2.35065
Timestep Consumption Time: 2.54801
PPO Batch Consumption Time: 0.30180
Total Iteration Time: 4.89866

Cumulative Model Updates: 2,778
Cumulative Timesteps: 23,208,476

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 23208476...
Checkpoint 23208476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,207.27062
Policy Entropy: 2.46396
Value Function Loss: 1.16759

Mean KL Divergence: 0.02416
SB3 Clip Fraction: 0.25518
Policy Update Magnitude: 0.16236
Value Function Update Magnitude: 0.19746

Collected Steps per Second: 20,365.30878
Overall Steps per Second: 10,057.13288

Timestep Collection Time: 2.45663
Timestep Consumption Time: 2.51795
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.97458

Cumulative Model Updates: 2,784
Cumulative Timesteps: 23,258,506

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,166.94423
Policy Entropy: 2.47564
Value Function Loss: 1.23283

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.18125
Policy Update Magnitude: 0.13781
Value Function Update Magnitude: 0.20514

Collected Steps per Second: 20,963.37370
Overall Steps per Second: 10,092.63020

Timestep Collection Time: 2.38559
Timestep Consumption Time: 2.56951
PPO Batch Consumption Time: 0.30548
Total Iteration Time: 4.95510

Cumulative Model Updates: 2,790
Cumulative Timesteps: 23,308,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 23308516...
Checkpoint 23308516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,032.56317
Policy Entropy: 2.48966
Value Function Loss: 1.24194

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.14306
Value Function Update Magnitude: 0.19831

Collected Steps per Second: 20,975.40365
Overall Steps per Second: 10,178.50741

Timestep Collection Time: 2.38498
Timestep Consumption Time: 2.52988
PPO Batch Consumption Time: 0.30016
Total Iteration Time: 4.91487

Cumulative Model Updates: 2,796
Cumulative Timesteps: 23,358,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,429.59048
Policy Entropy: 2.51129
Value Function Loss: 1.22460

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.15852
Policy Update Magnitude: 0.15118
Value Function Update Magnitude: 0.20366

Collected Steps per Second: 21,098.10128
Overall Steps per Second: 10,160.11147

Timestep Collection Time: 2.36998
Timestep Consumption Time: 2.55143
PPO Batch Consumption Time: 0.30212
Total Iteration Time: 4.92140

Cumulative Model Updates: 2,802
Cumulative Timesteps: 23,408,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 23408544...
Checkpoint 23408544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,964.92234
Policy Entropy: 2.50127
Value Function Loss: 1.17997

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.16026
Policy Update Magnitude: 0.14660
Value Function Update Magnitude: 0.22774

Collected Steps per Second: 21,007.96299
Overall Steps per Second: 9,925.06388

Timestep Collection Time: 2.38053
Timestep Consumption Time: 2.65823
PPO Batch Consumption Time: 0.32259
Total Iteration Time: 5.03876

Cumulative Model Updates: 2,808
Cumulative Timesteps: 23,458,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,470.84178
Policy Entropy: 2.50767
Value Function Loss: 1.10737

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.15243
Policy Update Magnitude: 0.18274
Value Function Update Magnitude: 0.22669

Collected Steps per Second: 20,800.11318
Overall Steps per Second: 10,108.44039

Timestep Collection Time: 2.40460
Timestep Consumption Time: 2.54334
PPO Batch Consumption Time: 0.30100
Total Iteration Time: 4.94794

Cumulative Model Updates: 2,814
Cumulative Timesteps: 23,508,570

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 23508570...
Checkpoint 23508570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.82511
Policy Entropy: 2.47928
Value Function Loss: 1.11418

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.14632
Policy Update Magnitude: 0.17152
Value Function Update Magnitude: 0.24111

Collected Steps per Second: 20,874.04785
Overall Steps per Second: 10,161.49441

Timestep Collection Time: 2.39580
Timestep Consumption Time: 2.52572
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.92152

Cumulative Model Updates: 2,820
Cumulative Timesteps: 23,558,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,532.13355
Policy Entropy: 2.48307
Value Function Loss: 1.12228

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.18019
Value Function Update Magnitude: 0.24321

Collected Steps per Second: 20,829.19556
Overall Steps per Second: 10,103.33873

Timestep Collection Time: 2.40115
Timestep Consumption Time: 2.54910
PPO Batch Consumption Time: 0.31083
Total Iteration Time: 4.95024

Cumulative Model Updates: 2,826
Cumulative Timesteps: 23,608,594

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 23608594...
Checkpoint 23608594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,286.26408
Policy Entropy: 2.48125
Value Function Loss: 1.09003

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.15989
Policy Update Magnitude: 0.16605
Value Function Update Magnitude: 0.24679

Collected Steps per Second: 20,404.03132
Overall Steps per Second: 10,226.44335

Timestep Collection Time: 2.45079
Timestep Consumption Time: 2.43908
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.88987

Cumulative Model Updates: 2,832
Cumulative Timesteps: 23,658,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,465.85128
Policy Entropy: 2.50282
Value Function Loss: 1.06485

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.15085
Value Function Update Magnitude: 0.25837

Collected Steps per Second: 20,058.13427
Overall Steps per Second: 10,015.55711

Timestep Collection Time: 2.49395
Timestep Consumption Time: 2.50068
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.99463

Cumulative Model Updates: 2,838
Cumulative Timesteps: 23,708,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 23708624...
Checkpoint 23708624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,182.22357
Policy Entropy: 2.49011
Value Function Loss: 1.04565

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.15045
Value Function Update Magnitude: 0.25900

Collected Steps per Second: 19,301.67034
Overall Steps per Second: 9,600.82850

Timestep Collection Time: 2.59055
Timestep Consumption Time: 2.61754
PPO Batch Consumption Time: 0.32075
Total Iteration Time: 5.20809

Cumulative Model Updates: 2,844
Cumulative Timesteps: 23,758,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,866.83110
Policy Entropy: 2.48662
Value Function Loss: 1.03053

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12134
Policy Update Magnitude: 0.15158
Value Function Update Magnitude: 0.23283

Collected Steps per Second: 19,980.09740
Overall Steps per Second: 9,887.41379

Timestep Collection Time: 2.50339
Timestep Consumption Time: 2.55536
PPO Batch Consumption Time: 0.31379
Total Iteration Time: 5.05875

Cumulative Model Updates: 2,850
Cumulative Timesteps: 23,808,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 23808644...
Checkpoint 23808644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,666.17954
Policy Entropy: 2.46394
Value Function Loss: 0.99789

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12361
Policy Update Magnitude: 0.15252
Value Function Update Magnitude: 0.23389

Collected Steps per Second: 20,250.32108
Overall Steps per Second: 10,223.03275

Timestep Collection Time: 2.46979
Timestep Consumption Time: 2.42250
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.89229

Cumulative Model Updates: 2,856
Cumulative Timesteps: 23,858,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213.23756
Policy Entropy: 2.46619
Value Function Loss: 0.97018

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.17345
Value Function Update Magnitude: 0.21936

Collected Steps per Second: 19,197.58001
Overall Steps per Second: 9,557.70645

Timestep Collection Time: 2.60470
Timestep Consumption Time: 2.62710
PPO Batch Consumption Time: 0.30931
Total Iteration Time: 5.23180

Cumulative Model Updates: 2,862
Cumulative Timesteps: 23,908,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 23908662...
Checkpoint 23908662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.95047
Policy Entropy: 2.44496
Value Function Loss: 0.96194

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.11971
Policy Update Magnitude: 0.22039
Value Function Update Magnitude: 0.22324

Collected Steps per Second: 19,485.46788
Overall Steps per Second: 9,739.32423

Timestep Collection Time: 2.56714
Timestep Consumption Time: 2.56894
PPO Batch Consumption Time: 0.30550
Total Iteration Time: 5.13609

Cumulative Model Updates: 2,868
Cumulative Timesteps: 23,958,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,707.97023
Policy Entropy: 2.46613
Value Function Loss: 0.97672

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.16685
Policy Update Magnitude: 0.21052
Value Function Update Magnitude: 0.22790

Collected Steps per Second: 20,074.30971
Overall Steps per Second: 10,105.82375

Timestep Collection Time: 2.49085
Timestep Consumption Time: 2.45699
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.94784

Cumulative Model Updates: 2,874
Cumulative Timesteps: 24,008,686

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 24008686...
Checkpoint 24008686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.08272
Policy Entropy: 2.45574
Value Function Loss: 0.96818

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.15744
Policy Update Magnitude: 0.17594
Value Function Update Magnitude: 0.22335

Collected Steps per Second: 20,655.77374
Overall Steps per Second: 9,866.19291

Timestep Collection Time: 2.42141
Timestep Consumption Time: 2.64803
PPO Batch Consumption Time: 0.31708
Total Iteration Time: 5.06943

Cumulative Model Updates: 2,880
Cumulative Timesteps: 24,058,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,420.24258
Policy Entropy: 2.47204
Value Function Loss: 0.97255

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.18551
Value Function Update Magnitude: 0.20826

Collected Steps per Second: 21,096.19657
Overall Steps per Second: 9,999.39441

Timestep Collection Time: 2.37076
Timestep Consumption Time: 2.63094
PPO Batch Consumption Time: 0.30981
Total Iteration Time: 5.00170

Cumulative Model Updates: 2,886
Cumulative Timesteps: 24,108,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 24108716...
Checkpoint 24108716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,547.58328
Policy Entropy: 2.46999
Value Function Loss: 0.94406

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.15420
Policy Update Magnitude: 0.17856
Value Function Update Magnitude: 0.20232

Collected Steps per Second: 20,789.22588
Overall Steps per Second: 10,005.75498

Timestep Collection Time: 2.40615
Timestep Consumption Time: 2.59317
PPO Batch Consumption Time: 0.30649
Total Iteration Time: 4.99932

Cumulative Model Updates: 2,892
Cumulative Timesteps: 24,158,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,781.72988
Policy Entropy: 2.45604
Value Function Loss: 0.95488

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.18303
Value Function Update Magnitude: 0.20806

Collected Steps per Second: 20,509.00501
Overall Steps per Second: 9,988.27286

Timestep Collection Time: 2.43864
Timestep Consumption Time: 2.56864
PPO Batch Consumption Time: 0.31116
Total Iteration Time: 5.00727

Cumulative Model Updates: 2,898
Cumulative Timesteps: 24,208,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 24208752...
Checkpoint 24208752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,226.49377
Policy Entropy: 2.43085
Value Function Loss: 0.90565

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.17320
Policy Update Magnitude: 0.21314
Value Function Update Magnitude: 0.21802

Collected Steps per Second: 20,323.97488
Overall Steps per Second: 10,044.77392

Timestep Collection Time: 2.46212
Timestep Consumption Time: 2.51958
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.98169

Cumulative Model Updates: 2,904
Cumulative Timesteps: 24,258,792

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,745.85496
Policy Entropy: 2.45330
Value Function Loss: 0.88166

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.21767
Policy Update Magnitude: 0.19019
Value Function Update Magnitude: 0.23127

Collected Steps per Second: 20,694.29710
Overall Steps per Second: 10,165.05584

Timestep Collection Time: 2.41680
Timestep Consumption Time: 2.50339
PPO Batch Consumption Time: 0.30407
Total Iteration Time: 4.92019

Cumulative Model Updates: 2,910
Cumulative Timesteps: 24,308,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 24308806...
Checkpoint 24308806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,947.25249
Policy Entropy: 2.47690
Value Function Loss: 0.84330

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.15510
Policy Update Magnitude: 0.14660
Value Function Update Magnitude: 0.22395

Collected Steps per Second: 18,512.51149
Overall Steps per Second: 9,693.74016

Timestep Collection Time: 2.70239
Timestep Consumption Time: 2.45847
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 5.16086

Cumulative Model Updates: 2,916
Cumulative Timesteps: 24,358,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,801.02379
Policy Entropy: 2.47706
Value Function Loss: 0.84852

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.18178
Policy Update Magnitude: 0.14233
Value Function Update Magnitude: 0.22302

Collected Steps per Second: 19,356.51750
Overall Steps per Second: 9,558.58296

Timestep Collection Time: 2.58404
Timestep Consumption Time: 2.64874
PPO Batch Consumption Time: 0.32292
Total Iteration Time: 5.23278

Cumulative Model Updates: 2,922
Cumulative Timesteps: 24,408,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 24408852...
Checkpoint 24408852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,796.95657
Policy Entropy: 2.45639
Value Function Loss: 0.86774

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.15634
Policy Update Magnitude: 0.12880
Value Function Update Magnitude: 0.22078

Collected Steps per Second: 19,010.21779
Overall Steps per Second: 9,693.34522

Timestep Collection Time: 2.63174
Timestep Consumption Time: 2.52953
PPO Batch Consumption Time: 0.31047
Total Iteration Time: 5.16127

Cumulative Model Updates: 2,928
Cumulative Timesteps: 24,458,882

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,501.66184
Policy Entropy: 2.43420
Value Function Loss: 0.86484

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.15332
Value Function Update Magnitude: 0.24456

Collected Steps per Second: 19,122.37648
Overall Steps per Second: 9,661.99173

Timestep Collection Time: 2.61641
Timestep Consumption Time: 2.56182
PPO Batch Consumption Time: 0.30925
Total Iteration Time: 5.17823

Cumulative Model Updates: 2,934
Cumulative Timesteps: 24,508,914

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 24508914...
Checkpoint 24508914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,979.71757
Policy Entropy: 2.41266
Value Function Loss: 0.84999

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.15290
Policy Update Magnitude: 0.18739
Value Function Update Magnitude: 0.25692

Collected Steps per Second: 19,288.84132
Overall Steps per Second: 9,551.44111

Timestep Collection Time: 2.59290
Timestep Consumption Time: 2.64338
PPO Batch Consumption Time: 0.32171
Total Iteration Time: 5.23628

Cumulative Model Updates: 2,940
Cumulative Timesteps: 24,558,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,958.78145
Policy Entropy: 2.44350
Value Function Loss: 0.81660

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.24931
Policy Update Magnitude: 0.17356
Value Function Update Magnitude: 0.24227

Collected Steps per Second: 20,066.85796
Overall Steps per Second: 9,914.85313

Timestep Collection Time: 2.49197
Timestep Consumption Time: 2.55157
PPO Batch Consumption Time: 0.30587
Total Iteration Time: 5.04354

Cumulative Model Updates: 2,946
Cumulative Timesteps: 24,608,934

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 24608934...
Checkpoint 24608934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,781.32230
Policy Entropy: 2.45279
Value Function Loss: 0.80430

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.17235
Policy Update Magnitude: 0.16385
Value Function Update Magnitude: 0.25057

Collected Steps per Second: 20,268.43706
Overall Steps per Second: 10,104.16897

Timestep Collection Time: 2.46798
Timestep Consumption Time: 2.48265
PPO Batch Consumption Time: 0.29873
Total Iteration Time: 4.95063

Cumulative Model Updates: 2,952
Cumulative Timesteps: 24,658,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,744.91289
Policy Entropy: 2.46762
Value Function Loss: 0.77856

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.19938
Value Function Update Magnitude: 0.25080

Collected Steps per Second: 21,372.93320
Overall Steps per Second: 10,113.49494

Timestep Collection Time: 2.34016
Timestep Consumption Time: 2.60532
PPO Batch Consumption Time: 0.30689
Total Iteration Time: 4.94547

Cumulative Model Updates: 2,958
Cumulative Timesteps: 24,708,972

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 24708972...
Checkpoint 24708972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,432.79620
Policy Entropy: 2.45435
Value Function Loss: 0.76486

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.19327
Policy Update Magnitude: 0.19193
Value Function Update Magnitude: 0.25601

Collected Steps per Second: 19,240.93015
Overall Steps per Second: 9,739.69048

Timestep Collection Time: 2.60008
Timestep Consumption Time: 2.53643
PPO Batch Consumption Time: 0.30845
Total Iteration Time: 5.13651

Cumulative Model Updates: 2,964
Cumulative Timesteps: 24,759,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,910.15246
Policy Entropy: 2.44801
Value Function Loss: 0.73965

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.16058
Value Function Update Magnitude: 0.25193

Collected Steps per Second: 21,014.78520
Overall Steps per Second: 10,033.45937

Timestep Collection Time: 2.38070
Timestep Consumption Time: 2.60561
PPO Batch Consumption Time: 0.30067
Total Iteration Time: 4.98632

Cumulative Model Updates: 2,970
Cumulative Timesteps: 24,809,030

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 24809030...
Checkpoint 24809030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,019.61293
Policy Entropy: 2.43887
Value Function Loss: 0.75311

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.18427
Value Function Update Magnitude: 0.25212

Collected Steps per Second: 20,510.50108
Overall Steps per Second: 10,175.54307

Timestep Collection Time: 2.43826
Timestep Consumption Time: 2.47646
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.91473

Cumulative Model Updates: 2,976
Cumulative Timesteps: 24,859,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,414.78298
Policy Entropy: 2.42718
Value Function Loss: 0.78463

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.18107
Policy Update Magnitude: 0.17236
Value Function Update Magnitude: 0.26743

Collected Steps per Second: 21,041.02322
Overall Steps per Second: 10,061.03557

Timestep Collection Time: 2.37669
Timestep Consumption Time: 2.59377
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.97046

Cumulative Model Updates: 2,982
Cumulative Timesteps: 24,909,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 24909048...
Checkpoint 24909048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,699.12795
Policy Entropy: 2.43731
Value Function Loss: 0.80490

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.16400
Policy Update Magnitude: 0.13952
Value Function Update Magnitude: 0.24753

Collected Steps per Second: 20,561.52823
Overall Steps per Second: 10,127.21056

Timestep Collection Time: 2.43318
Timestep Consumption Time: 2.50697
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.94016

Cumulative Model Updates: 2,988
Cumulative Timesteps: 24,959,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,208.05662
Policy Entropy: 2.44279
Value Function Loss: 0.80962

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.16216
Policy Update Magnitude: 0.13936
Value Function Update Magnitude: 0.25614

Collected Steps per Second: 20,263.73076
Overall Steps per Second: 10,058.12908

Timestep Collection Time: 2.46805
Timestep Consumption Time: 2.50424
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.97230

Cumulative Model Updates: 2,994
Cumulative Timesteps: 25,009,090

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 25009090...
Checkpoint 25009090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,968.23858
Policy Entropy: 2.44248
Value Function Loss: 0.78226

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.14060
Value Function Update Magnitude: 0.26717

Collected Steps per Second: 21,456.75751
Overall Steps per Second: 10,303.27484

Timestep Collection Time: 2.33101
Timestep Consumption Time: 2.52337
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.85438

Cumulative Model Updates: 3,000
Cumulative Timesteps: 25,059,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,073.89420
Policy Entropy: 2.43112
Value Function Loss: 0.76458

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.17869
Policy Update Magnitude: 0.14255
Value Function Update Magnitude: 0.22572

Collected Steps per Second: 20,090.10507
Overall Steps per Second: 9,994.15582

Timestep Collection Time: 2.48998
Timestep Consumption Time: 2.51534
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 5.00533

Cumulative Model Updates: 3,006
Cumulative Timesteps: 25,109,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 25109130...
Checkpoint 25109130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,187.13689
Policy Entropy: 2.46255
Value Function Loss: 0.73798

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.16265
Policy Update Magnitude: 0.15680
Value Function Update Magnitude: 0.21194

Collected Steps per Second: 21,109.34281
Overall Steps per Second: 10,259.94837

Timestep Collection Time: 2.36957
Timestep Consumption Time: 2.50570
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.87527

Cumulative Model Updates: 3,012
Cumulative Timesteps: 25,159,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.66711
Policy Entropy: 2.46127
Value Function Loss: 0.73352

Mean KL Divergence: 0.02562
SB3 Clip Fraction: 0.26464
Policy Update Magnitude: 0.17106
Value Function Update Magnitude: 0.22609

Collected Steps per Second: 20,856.58875
Overall Steps per Second: 10,004.76375

Timestep Collection Time: 2.39819
Timestep Consumption Time: 2.60123
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.99942

Cumulative Model Updates: 3,018
Cumulative Timesteps: 25,209,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 25209168...
Checkpoint 25209168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.02235
Policy Entropy: 2.47350
Value Function Loss: 0.70849

Mean KL Divergence: 0.03231
SB3 Clip Fraction: 0.29962
Policy Update Magnitude: 0.12808
Value Function Update Magnitude: 0.23860

Collected Steps per Second: 20,957.00851
Overall Steps per Second: 10,235.00565

Timestep Collection Time: 2.38641
Timestep Consumption Time: 2.49996
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.88637

Cumulative Model Updates: 3,024
Cumulative Timesteps: 25,259,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,414.32007
Policy Entropy: 2.46329
Value Function Loss: 0.73184

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.17729
Policy Update Magnitude: 0.11990
Value Function Update Magnitude: 0.23851

Collected Steps per Second: 21,233.03189
Overall Steps per Second: 10,191.77413

Timestep Collection Time: 2.35482
Timestep Consumption Time: 2.55110
PPO Batch Consumption Time: 0.30034
Total Iteration Time: 4.90592

Cumulative Model Updates: 3,030
Cumulative Timesteps: 25,309,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 25309180...
Checkpoint 25309180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,127.03089
Policy Entropy: 2.46491
Value Function Loss: 0.73553

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.16260
Policy Update Magnitude: 0.14530
Value Function Update Magnitude: 0.21997

Collected Steps per Second: 21,068.84909
Overall Steps per Second: 9,887.82735

Timestep Collection Time: 2.37469
Timestep Consumption Time: 2.68527
PPO Batch Consumption Time: 0.32055
Total Iteration Time: 5.05996

Cumulative Model Updates: 3,036
Cumulative Timesteps: 25,359,212

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,223.08207
Policy Entropy: 2.45026
Value Function Loss: 0.71659

Mean KL Divergence: 0.02395
SB3 Clip Fraction: 0.23607
Policy Update Magnitude: 0.16955
Value Function Update Magnitude: 0.22107

Collected Steps per Second: 19,066.74160
Overall Steps per Second: 9,507.70396

Timestep Collection Time: 2.62268
Timestep Consumption Time: 2.63684
PPO Batch Consumption Time: 0.31160
Total Iteration Time: 5.25952

Cumulative Model Updates: 3,042
Cumulative Timesteps: 25,409,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 25409218...
Checkpoint 25409218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,370.88636
Policy Entropy: 2.46708
Value Function Loss: 0.73192

Mean KL Divergence: 0.02446
SB3 Clip Fraction: 0.25222
Policy Update Magnitude: 0.15985
Value Function Update Magnitude: 0.22290

Collected Steps per Second: 20,548.33780
Overall Steps per Second: 10,123.96400

Timestep Collection Time: 2.43377
Timestep Consumption Time: 2.50599
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.93976

Cumulative Model Updates: 3,048
Cumulative Timesteps: 25,459,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,315.95182
Policy Entropy: 2.47940
Value Function Loss: 0.73442

Mean KL Divergence: 0.02590
SB3 Clip Fraction: 0.26564
Policy Update Magnitude: 0.13616
Value Function Update Magnitude: 0.23581

Collected Steps per Second: 19,919.68798
Overall Steps per Second: 9,928.42399

Timestep Collection Time: 2.51078
Timestep Consumption Time: 2.52667
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 5.03746

Cumulative Model Updates: 3,054
Cumulative Timesteps: 25,509,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 25509242...
Checkpoint 25509242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,116.62546
Policy Entropy: 2.49013
Value Function Loss: 0.73476

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.20149
Policy Update Magnitude: 0.13087
Value Function Update Magnitude: 0.21914

Collected Steps per Second: 20,803.23212
Overall Steps per Second: 9,798.22131

Timestep Collection Time: 2.40501
Timestep Consumption Time: 2.70122
PPO Batch Consumption Time: 0.32238
Total Iteration Time: 5.10623

Cumulative Model Updates: 3,060
Cumulative Timesteps: 25,559,274

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,676.00149
Policy Entropy: 2.48530
Value Function Loss: 0.68150

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.17056
Value Function Update Magnitude: 0.27547

Collected Steps per Second: 20,687.50367
Overall Steps per Second: 10,159.11449

Timestep Collection Time: 2.41692
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.92169

Cumulative Model Updates: 3,066
Cumulative Timesteps: 25,609,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 25609274...
Checkpoint 25609274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,929.97809
Policy Entropy: 2.47363
Value Function Loss: 0.67831

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.16370
Policy Update Magnitude: 0.16604
Value Function Update Magnitude: 0.31983

Collected Steps per Second: 21,220.74488
Overall Steps per Second: 10,186.17688

Timestep Collection Time: 2.35666
Timestep Consumption Time: 2.55294
PPO Batch Consumption Time: 0.29843
Total Iteration Time: 4.90959

Cumulative Model Updates: 3,072
Cumulative Timesteps: 25,659,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,559.27018
Policy Entropy: 2.46970
Value Function Loss: 0.64589

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14298
Policy Update Magnitude: 0.14945
Value Function Update Magnitude: 0.36934

Collected Steps per Second: 19,661.40423
Overall Steps per Second: 9,695.08489

Timestep Collection Time: 2.54326
Timestep Consumption Time: 2.61441
PPO Batch Consumption Time: 0.30420
Total Iteration Time: 5.15767

Cumulative Model Updates: 3,078
Cumulative Timesteps: 25,709,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 25709288...
Checkpoint 25709288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,594.84008
Policy Entropy: 2.46215
Value Function Loss: 0.63347

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.16943
Value Function Update Magnitude: 0.39809

Collected Steps per Second: 19,889.08372
Overall Steps per Second: 9,823.73475

Timestep Collection Time: 2.51455
Timestep Consumption Time: 2.57639
PPO Batch Consumption Time: 0.30358
Total Iteration Time: 5.09094

Cumulative Model Updates: 3,084
Cumulative Timesteps: 25,759,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,096.03159
Policy Entropy: 2.43322
Value Function Loss: 0.61561

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.16167
Value Function Update Magnitude: 0.48427

Collected Steps per Second: 20,880.53317
Overall Steps per Second: 9,900.12041

Timestep Collection Time: 2.39553
Timestep Consumption Time: 2.65693
PPO Batch Consumption Time: 0.31562
Total Iteration Time: 5.05246

Cumulative Model Updates: 3,090
Cumulative Timesteps: 25,809,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 25809320...
Checkpoint 25809320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,720.86775
Policy Entropy: 2.42651
Value Function Loss: 0.61336

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.19705
Value Function Update Magnitude: 0.50959

Collected Steps per Second: 20,986.92852
Overall Steps per Second: 10,084.18391

Timestep Collection Time: 2.38358
Timestep Consumption Time: 2.57706
PPO Batch Consumption Time: 0.30049
Total Iteration Time: 4.96064

Cumulative Model Updates: 3,096
Cumulative Timesteps: 25,859,344

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,575.95073
Policy Entropy: 2.45308
Value Function Loss: 0.64710

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.20024
Policy Update Magnitude: 0.17405
Value Function Update Magnitude: 0.44907

Collected Steps per Second: 21,036.86244
Overall Steps per Second: 10,027.07937

Timestep Collection Time: 2.37840
Timestep Consumption Time: 2.61149
PPO Batch Consumption Time: 0.30571
Total Iteration Time: 4.98989

Cumulative Model Updates: 3,102
Cumulative Timesteps: 25,909,378

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 25909378...
Checkpoint 25909378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,146.42114
Policy Entropy: 2.47580
Value Function Loss: 0.62096

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.23221
Policy Update Magnitude: 0.15069
Value Function Update Magnitude: 0.39046

Collected Steps per Second: 20,622.15034
Overall Steps per Second: 9,685.92194

Timestep Collection Time: 2.42467
Timestep Consumption Time: 2.73766
PPO Batch Consumption Time: 0.32066
Total Iteration Time: 5.16234

Cumulative Model Updates: 3,108
Cumulative Timesteps: 25,959,380

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,633.58887
Policy Entropy: 2.49037
Value Function Loss: 0.63731

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.20561
Policy Update Magnitude: 0.15667
Value Function Update Magnitude: 0.36550

Collected Steps per Second: 21,199.03660
Overall Steps per Second: 10,233.33690

Timestep Collection Time: 2.35935
Timestep Consumption Time: 2.52820
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.88756

Cumulative Model Updates: 3,114
Cumulative Timesteps: 26,009,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 26009396...
Checkpoint 26009396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,200.24085
Policy Entropy: 2.45069
Value Function Loss: 0.62507

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.20918
Policy Update Magnitude: 0.15655
Value Function Update Magnitude: 0.35727

Collected Steps per Second: 21,222.46310
Overall Steps per Second: 10,300.30104

Timestep Collection Time: 2.35647
Timestep Consumption Time: 2.49873
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.85520

Cumulative Model Updates: 3,120
Cumulative Timesteps: 26,059,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,947.46584
Policy Entropy: 2.45327
Value Function Loss: 0.58878

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.15270
Policy Update Magnitude: 0.15498
Value Function Update Magnitude: 0.38881

Collected Steps per Second: 20,883.52743
Overall Steps per Second: 9,830.92178

Timestep Collection Time: 2.39529
Timestep Consumption Time: 2.69295
PPO Batch Consumption Time: 0.31932
Total Iteration Time: 5.08823

Cumulative Model Updates: 3,126
Cumulative Timesteps: 26,109,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 26109428...
Checkpoint 26109428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,075.00580
Policy Entropy: 2.43122
Value Function Loss: 0.61376

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.15056
Policy Update Magnitude: 0.18107
Value Function Update Magnitude: 0.36646

Collected Steps per Second: 20,674.45202
Overall Steps per Second: 9,727.76720

Timestep Collection Time: 2.41951
Timestep Consumption Time: 2.72268
PPO Batch Consumption Time: 0.32725
Total Iteration Time: 5.14219

Cumulative Model Updates: 3,132
Cumulative Timesteps: 26,159,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,752.88625
Policy Entropy: 2.41785
Value Function Loss: 0.61895

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.21508
Policy Update Magnitude: 0.19000
Value Function Update Magnitude: 0.33582

Collected Steps per Second: 20,094.69033
Overall Steps per Second: 9,752.82072

Timestep Collection Time: 2.48931
Timestep Consumption Time: 2.63966
PPO Batch Consumption Time: 0.30188
Total Iteration Time: 5.12898

Cumulative Model Updates: 3,138
Cumulative Timesteps: 26,209,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 26209472...
Checkpoint 26209472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,985.95031
Policy Entropy: 2.41206
Value Function Loss: 0.62240

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14705
Policy Update Magnitude: 0.20804
Value Function Update Magnitude: 0.47438

Collected Steps per Second: 19,644.48499
Overall Steps per Second: 9,757.05559

Timestep Collection Time: 2.54718
Timestep Consumption Time: 2.58121
PPO Batch Consumption Time: 0.30357
Total Iteration Time: 5.12839

Cumulative Model Updates: 3,144
Cumulative Timesteps: 26,259,510

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,333.53940
Policy Entropy: 2.40926
Value Function Loss: 0.63836

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.16718
Policy Update Magnitude: 0.22771
Value Function Update Magnitude: 0.46131

Collected Steps per Second: 20,051.90196
Overall Steps per Second: 9,927.24052

Timestep Collection Time: 2.49463
Timestep Consumption Time: 2.54424
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 5.03886

Cumulative Model Updates: 3,150
Cumulative Timesteps: 26,309,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 26309532...
Checkpoint 26309532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,972.17080
Policy Entropy: 2.39465
Value Function Loss: 0.70376

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.20561
Policy Update Magnitude: 0.18369
Value Function Update Magnitude: 0.38204

Collected Steps per Second: 19,703.55765
Overall Steps per Second: 9,609.65139

Timestep Collection Time: 2.53771
Timestep Consumption Time: 2.66560
PPO Batch Consumption Time: 0.31360
Total Iteration Time: 5.20331

Cumulative Model Updates: 3,156
Cumulative Timesteps: 26,359,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,342.62075
Policy Entropy: 2.39279
Value Function Loss: 0.72901

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.15693
Policy Update Magnitude: 0.15391
Value Function Update Magnitude: 0.35770

Collected Steps per Second: 20,318.59584
Overall Steps per Second: 9,867.70132

Timestep Collection Time: 2.46090
Timestep Consumption Time: 2.60634
PPO Batch Consumption Time: 0.30872
Total Iteration Time: 5.06724

Cumulative Model Updates: 3,162
Cumulative Timesteps: 26,409,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 26409536...
Checkpoint 26409536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,741.99029
Policy Entropy: 2.37960
Value Function Loss: 0.73206

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.15602
Policy Update Magnitude: 0.15058
Value Function Update Magnitude: 0.31647

Collected Steps per Second: 20,468.14635
Overall Steps per Second: 10,118.03429

Timestep Collection Time: 2.44409
Timestep Consumption Time: 2.50015
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.94424

Cumulative Model Updates: 3,168
Cumulative Timesteps: 26,459,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,223.50492
Policy Entropy: 2.38091
Value Function Loss: 0.67399

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.16174
Value Function Update Magnitude: 0.36717

Collected Steps per Second: 21,539.18208
Overall Steps per Second: 10,290.08100

Timestep Collection Time: 2.32219
Timestep Consumption Time: 2.53861
PPO Batch Consumption Time: 0.30059
Total Iteration Time: 4.86080

Cumulative Model Updates: 3,174
Cumulative Timesteps: 26,509,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 26509580...
Checkpoint 26509580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,961.09467
Policy Entropy: 2.35820
Value Function Loss: 0.64973

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.14780
Policy Update Magnitude: 0.17472
Value Function Update Magnitude: 0.36843

Collected Steps per Second: 21,163.54017
Overall Steps per Second: 10,209.58873

Timestep Collection Time: 2.36284
Timestep Consumption Time: 2.53511
PPO Batch Consumption Time: 0.30038
Total Iteration Time: 4.89794

Cumulative Model Updates: 3,180
Cumulative Timesteps: 26,559,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,167.43485
Policy Entropy: 2.34789
Value Function Loss: 0.66155

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.17091
Value Function Update Magnitude: 0.44107

Collected Steps per Second: 20,985.49062
Overall Steps per Second: 10,234.48521

Timestep Collection Time: 2.38327
Timestep Consumption Time: 2.50355
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.88681

Cumulative Model Updates: 3,186
Cumulative Timesteps: 26,609,600

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 26609600...
Checkpoint 26609600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,061.09333
Policy Entropy: 2.35364
Value Function Loss: 0.65865

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.18224
Value Function Update Magnitude: 0.41030

Collected Steps per Second: 20,815.01610
Overall Steps per Second: 10,039.31318

Timestep Collection Time: 2.40336
Timestep Consumption Time: 2.57965
PPO Batch Consumption Time: 0.29736
Total Iteration Time: 4.98301

Cumulative Model Updates: 3,192
Cumulative Timesteps: 26,659,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,410.42973
Policy Entropy: 2.36885
Value Function Loss: 0.69294

Mean KL Divergence: 0.03066
SB3 Clip Fraction: 0.26293
Policy Update Magnitude: 0.15316
Value Function Update Magnitude: 0.42644

Collected Steps per Second: 21,219.61101
Overall Steps per Second: 10,237.55746

Timestep Collection Time: 2.35763
Timestep Consumption Time: 2.52908
PPO Batch Consumption Time: 0.30104
Total Iteration Time: 4.88671

Cumulative Model Updates: 3,198
Cumulative Timesteps: 26,709,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 26709654...
Checkpoint 26709654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,225.04928
Policy Entropy: 2.39128
Value Function Loss: 0.71998

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.22270
Policy Update Magnitude: 0.11636
Value Function Update Magnitude: 0.36324

Collected Steps per Second: 20,350.08394
Overall Steps per Second: 10,109.08951

Timestep Collection Time: 2.45758
Timestep Consumption Time: 2.48965
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.94723

Cumulative Model Updates: 3,204
Cumulative Timesteps: 26,759,666

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,262.09687
Policy Entropy: 2.40870
Value Function Loss: 0.69662

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.24664
Policy Update Magnitude: 0.11239
Value Function Update Magnitude: 0.27238

Collected Steps per Second: 21,528.25940
Overall Steps per Second: 10,270.63849

Timestep Collection Time: 2.32374
Timestep Consumption Time: 2.54704
PPO Batch Consumption Time: 0.30158
Total Iteration Time: 4.87078

Cumulative Model Updates: 3,210
Cumulative Timesteps: 26,809,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 26809692...
Checkpoint 26809692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,924.19683
Policy Entropy: 2.41458
Value Function Loss: 0.66453

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.18249
Policy Update Magnitude: 0.12435
Value Function Update Magnitude: 0.24317

Collected Steps per Second: 21,270.24954
Overall Steps per Second: 10,201.37092

Timestep Collection Time: 2.35155
Timestep Consumption Time: 2.55152
PPO Batch Consumption Time: 0.30177
Total Iteration Time: 4.90307

Cumulative Model Updates: 3,216
Cumulative Timesteps: 26,859,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,157.13164
Policy Entropy: 2.40953
Value Function Loss: 0.68917

Mean KL Divergence: 0.02359
SB3 Clip Fraction: 0.23345
Policy Update Magnitude: 0.14082
Value Function Update Magnitude: 0.23540

Collected Steps per Second: 20,839.52329
Overall Steps per Second: 10,159.87922

Timestep Collection Time: 2.39938
Timestep Consumption Time: 2.52213
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.92152

Cumulative Model Updates: 3,222
Cumulative Timesteps: 26,909,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 26909712...
Checkpoint 26909712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,421.46160
Policy Entropy: 2.39293
Value Function Loss: 0.65969

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.20380
Policy Update Magnitude: 0.15743
Value Function Update Magnitude: 0.24961

Collected Steps per Second: 21,392.62068
Overall Steps per Second: 10,342.60729

Timestep Collection Time: 2.33772
Timestep Consumption Time: 2.49762
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.83534

Cumulative Model Updates: 3,228
Cumulative Timesteps: 26,959,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,710.44992
Policy Entropy: 2.37546
Value Function Loss: 0.65177

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.19030
Policy Update Magnitude: 0.16260
Value Function Update Magnitude: 0.31302

Collected Steps per Second: 21,300.15876
Overall Steps per Second: 10,218.05503

Timestep Collection Time: 2.34843
Timestep Consumption Time: 2.54702
PPO Batch Consumption Time: 0.30087
Total Iteration Time: 4.89545

Cumulative Model Updates: 3,234
Cumulative Timesteps: 27,009,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 27009744...
Checkpoint 27009744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,112.30575
Policy Entropy: 2.35230
Value Function Loss: 0.62071

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.15015
Policy Update Magnitude: 0.13704
Value Function Update Magnitude: 0.44838

Collected Steps per Second: 21,046.21749
Overall Steps per Second: 10,159.69550

Timestep Collection Time: 2.37667
Timestep Consumption Time: 2.54670
PPO Batch Consumption Time: 0.30232
Total Iteration Time: 4.92338

Cumulative Model Updates: 3,240
Cumulative Timesteps: 27,059,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,264.99930
Policy Entropy: 2.35591
Value Function Loss: 0.61727

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11457
Policy Update Magnitude: 0.16837
Value Function Update Magnitude: 0.39566

Collected Steps per Second: 21,292.64504
Overall Steps per Second: 10,312.60820

Timestep Collection Time: 2.34954
Timestep Consumption Time: 2.50161
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.85115

Cumulative Model Updates: 3,246
Cumulative Timesteps: 27,109,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 27109792...
Checkpoint 27109792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,378.87417
Policy Entropy: 2.32978
Value Function Loss: 0.60389

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.19914
Policy Update Magnitude: 0.21147
Value Function Update Magnitude: 0.36563

Collected Steps per Second: 19,260.83189
Overall Steps per Second: 9,359.87618

Timestep Collection Time: 2.59740
Timestep Consumption Time: 2.74755
PPO Batch Consumption Time: 0.32673
Total Iteration Time: 5.34494

Cumulative Model Updates: 3,252
Cumulative Timesteps: 27,159,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,682.99384
Policy Entropy: 2.35460
Value Function Loss: 0.60071

Mean KL Divergence: 0.03875
SB3 Clip Fraction: 0.32274
Policy Update Magnitude: 0.16879
Value Function Update Magnitude: 0.35370

Collected Steps per Second: 18,221.63754
Overall Steps per Second: 9,249.46818

Timestep Collection Time: 2.74476
Timestep Consumption Time: 2.66247
PPO Batch Consumption Time: 0.31908
Total Iteration Time: 5.40723

Cumulative Model Updates: 3,258
Cumulative Timesteps: 27,209,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 27209834...
Checkpoint 27209834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,175.81342
Policy Entropy: 2.33636
Value Function Loss: 0.59731

Mean KL Divergence: 0.02372
SB3 Clip Fraction: 0.23795
Policy Update Magnitude: 0.13238
Value Function Update Magnitude: 0.32202

Collected Steps per Second: 20,982.28903
Overall Steps per Second: 10,267.54497

Timestep Collection Time: 2.38439
Timestep Consumption Time: 2.48824
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.87264

Cumulative Model Updates: 3,264
Cumulative Timesteps: 27,259,864

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,207.64770
Policy Entropy: 2.37754
Value Function Loss: 0.58841

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.22253
Policy Update Magnitude: 0.12468
Value Function Update Magnitude: 0.36030

Collected Steps per Second: 20,184.55267
Overall Steps per Second: 9,893.80517

Timestep Collection Time: 2.47813
Timestep Consumption Time: 2.57756
PPO Batch Consumption Time: 0.30086
Total Iteration Time: 5.05569

Cumulative Model Updates: 3,270
Cumulative Timesteps: 27,309,884

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 27309884...
Checkpoint 27309884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,276.83306
Policy Entropy: 2.40584
Value Function Loss: 0.64632

Mean KL Divergence: 0.02431
SB3 Clip Fraction: 0.22697
Policy Update Magnitude: 0.11334
Value Function Update Magnitude: 0.32087

Collected Steps per Second: 20,815.23406
Overall Steps per Second: 10,049.23938

Timestep Collection Time: 2.40238
Timestep Consumption Time: 2.57372
PPO Batch Consumption Time: 0.30513
Total Iteration Time: 4.97610

Cumulative Model Updates: 3,276
Cumulative Timesteps: 27,359,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,843.46411
Policy Entropy: 2.43372
Value Function Loss: 0.79131

Mean KL Divergence: 0.02621
SB3 Clip Fraction: 0.24291
Policy Update Magnitude: 0.10288
Value Function Update Magnitude: 0.33344

Collected Steps per Second: 21,033.81185
Overall Steps per Second: 9,966.59596

Timestep Collection Time: 2.37712
Timestep Consumption Time: 2.63963
PPO Batch Consumption Time: 0.31864
Total Iteration Time: 5.01676

Cumulative Model Updates: 3,282
Cumulative Timesteps: 27,409,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 27409890...
Checkpoint 27409890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,096.28007
Policy Entropy: 2.46537
Value Function Loss: 0.70595

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.19140
Policy Update Magnitude: 0.10452
Value Function Update Magnitude: 0.26378

Collected Steps per Second: 20,627.38522
Overall Steps per Second: 10,198.15796

Timestep Collection Time: 2.42396
Timestep Consumption Time: 2.47888
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.90285

Cumulative Model Updates: 3,288
Cumulative Timesteps: 27,459,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.05205
Policy Entropy: 2.50759
Value Function Loss: 0.71238

Mean KL Divergence: 0.02646
SB3 Clip Fraction: 0.26432
Policy Update Magnitude: 0.09747
Value Function Update Magnitude: 0.23497

Collected Steps per Second: 21,398.79470
Overall Steps per Second: 10,225.28428

Timestep Collection Time: 2.33658
Timestep Consumption Time: 2.55326
PPO Batch Consumption Time: 0.30334
Total Iteration Time: 4.88984

Cumulative Model Updates: 3,294
Cumulative Timesteps: 27,509,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 27509890...
Checkpoint 27509890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,694.42398
Policy Entropy: 2.52423
Value Function Loss: 0.68899

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.14745
Policy Update Magnitude: 0.12363
Value Function Update Magnitude: 0.17189

Collected Steps per Second: 21,058.78917
Overall Steps per Second: 10,132.17713

Timestep Collection Time: 2.37516
Timestep Consumption Time: 2.56139
PPO Batch Consumption Time: 0.30476
Total Iteration Time: 4.93655

Cumulative Model Updates: 3,300
Cumulative Timesteps: 27,559,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,842.24945
Policy Entropy: 2.51232
Value Function Loss: 0.66560

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.21767
Policy Update Magnitude: 0.13077
Value Function Update Magnitude: 0.17383

Collected Steps per Second: 21,112.87235
Overall Steps per Second: 10,306.27045

Timestep Collection Time: 2.36993
Timestep Consumption Time: 2.48498
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.85491

Cumulative Model Updates: 3,306
Cumulative Timesteps: 27,609,944

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 27609944...
Checkpoint 27609944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,509.38961
Policy Entropy: 2.45880
Value Function Loss: 0.58926

Mean KL Divergence: 0.02663
SB3 Clip Fraction: 0.27631
Policy Update Magnitude: 0.12803
Value Function Update Magnitude: 0.26001

Collected Steps per Second: 21,007.08163
Overall Steps per Second: 10,260.36334

Timestep Collection Time: 2.38101
Timestep Consumption Time: 2.49387
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.87488

Cumulative Model Updates: 3,312
Cumulative Timesteps: 27,659,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,879.78885
Policy Entropy: 2.48878
Value Function Loss: 0.61867

Mean KL Divergence: 0.02173
SB3 Clip Fraction: 0.22977
Policy Update Magnitude: 0.11112
Value Function Update Magnitude: 0.26591

Collected Steps per Second: 21,576.04960
Overall Steps per Second: 10,525.87129

Timestep Collection Time: 2.31868
Timestep Consumption Time: 2.43418
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.75286

Cumulative Model Updates: 3,318
Cumulative Timesteps: 27,709,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 27709990...
Checkpoint 27709990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,624.68831
Policy Entropy: 2.50822
Value Function Loss: 0.62522

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.16985
Policy Update Magnitude: 0.14047
Value Function Update Magnitude: 0.25416

Collected Steps per Second: 20,625.61366
Overall Steps per Second: 10,151.66386

Timestep Collection Time: 2.42592
Timestep Consumption Time: 2.50293
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.92885

Cumulative Model Updates: 3,324
Cumulative Timesteps: 27,760,026

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,201.60108
Policy Entropy: 2.48745
Value Function Loss: 0.60957

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.22758
Policy Update Magnitude: 0.16149
Value Function Update Magnitude: 0.29282

Collected Steps per Second: 21,160.24144
Overall Steps per Second: 10,140.70070

Timestep Collection Time: 2.36349
Timestep Consumption Time: 2.56832
PPO Batch Consumption Time: 0.30488
Total Iteration Time: 4.93181

Cumulative Model Updates: 3,330
Cumulative Timesteps: 27,810,038

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 27810038...
Checkpoint 27810038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,069.47810
Policy Entropy: 2.43706
Value Function Loss: 0.58000

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.20852
Policy Update Magnitude: 0.17023
Value Function Update Magnitude: 0.27885

Collected Steps per Second: 20,768.04129
Overall Steps per Second: 10,146.59857

Timestep Collection Time: 2.40803
Timestep Consumption Time: 2.52072
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.92875

Cumulative Model Updates: 3,336
Cumulative Timesteps: 27,860,048

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.32979
Policy Entropy: 2.41734
Value Function Loss: 0.58418

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.17961
Policy Update Magnitude: 0.15792
Value Function Update Magnitude: 0.28411

Collected Steps per Second: 21,186.46581
Overall Steps per Second: 10,420.74791

Timestep Collection Time: 2.36037
Timestep Consumption Time: 2.43851
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.79889

Cumulative Model Updates: 3,342
Cumulative Timesteps: 27,910,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 27910056...
Checkpoint 27910056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,754.14104
Policy Entropy: 2.44098
Value Function Loss: 0.56432

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.19280
Policy Update Magnitude: 0.14219
Value Function Update Magnitude: 0.32052

Collected Steps per Second: 20,564.94477
Overall Steps per Second: 10,208.83872

Timestep Collection Time: 2.43229
Timestep Consumption Time: 2.46738
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.89968

Cumulative Model Updates: 3,348
Cumulative Timesteps: 27,960,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,737.45450
Policy Entropy: 2.44978
Value Function Loss: 0.58949

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.16695
Policy Update Magnitude: 0.10860
Value Function Update Magnitude: 0.28111

Collected Steps per Second: 20,720.99468
Overall Steps per Second: 10,212.88898

Timestep Collection Time: 2.41407
Timestep Consumption Time: 2.48386
PPO Batch Consumption Time: 0.30068
Total Iteration Time: 4.89793

Cumulative Model Updates: 3,354
Cumulative Timesteps: 28,010,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 28010098...
Checkpoint 28010098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,067.09534
Policy Entropy: 2.41701
Value Function Loss: 0.56641

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.17472
Policy Update Magnitude: 0.11205
Value Function Update Magnitude: 0.27493

Collected Steps per Second: 20,449.16870
Overall Steps per Second: 9,958.02709

Timestep Collection Time: 2.44597
Timestep Consumption Time: 2.57692
PPO Batch Consumption Time: 0.31740
Total Iteration Time: 5.02288

Cumulative Model Updates: 3,360
Cumulative Timesteps: 28,060,116

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,508.82299
Policy Entropy: 2.39412
Value Function Loss: 0.55687

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.20123
Policy Update Magnitude: 0.11643
Value Function Update Magnitude: 0.27902

Collected Steps per Second: 20,766.23074
Overall Steps per Second: 10,174.49938

Timestep Collection Time: 2.40872
Timestep Consumption Time: 2.50749
PPO Batch Consumption Time: 0.30439
Total Iteration Time: 4.91621

Cumulative Model Updates: 3,366
Cumulative Timesteps: 28,110,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 28110136...
Checkpoint 28110136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,279.92424
Policy Entropy: 2.39412
Value Function Loss: 0.54556

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.19254
Policy Update Magnitude: 0.11557
Value Function Update Magnitude: 0.29594

Collected Steps per Second: 20,518.10617
Overall Steps per Second: 10,152.61081

Timestep Collection Time: 2.43833
Timestep Consumption Time: 2.48946
PPO Batch Consumption Time: 0.30106
Total Iteration Time: 4.92780

Cumulative Model Updates: 3,372
Cumulative Timesteps: 28,160,166

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,988.63926
Policy Entropy: 2.39494
Value Function Loss: 0.51027

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.15059
Policy Update Magnitude: 0.12561
Value Function Update Magnitude: 0.27944

Collected Steps per Second: 19,997.16428
Overall Steps per Second: 10,030.12144

Timestep Collection Time: 2.50165
Timestep Consumption Time: 2.48592
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.98758

Cumulative Model Updates: 3,378
Cumulative Timesteps: 28,210,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 28210192...
Checkpoint 28210192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,994.08701
Policy Entropy: 2.38309
Value Function Loss: 0.51230

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.18844
Policy Update Magnitude: 0.11553
Value Function Update Magnitude: 0.27704

Collected Steps per Second: 20,526.80460
Overall Steps per Second: 10,248.43934

Timestep Collection Time: 2.43750
Timestep Consumption Time: 2.44461
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.88211

Cumulative Model Updates: 3,384
Cumulative Timesteps: 28,260,226

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,885.78104
Policy Entropy: 2.35612
Value Function Loss: 0.47955

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.16238
Policy Update Magnitude: 0.11588
Value Function Update Magnitude: 0.33572

Collected Steps per Second: 19,615.67000
Overall Steps per Second: 9,894.72837

Timestep Collection Time: 2.54929
Timestep Consumption Time: 2.50451
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 5.05380

Cumulative Model Updates: 3,390
Cumulative Timesteps: 28,310,232

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 28310232...
Checkpoint 28310232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,364.34410
Policy Entropy: 2.33537
Value Function Loss: 0.51653

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.11890
Value Function Update Magnitude: 0.40918

Collected Steps per Second: 20,277.03954
Overall Steps per Second: 9,789.35564

Timestep Collection Time: 2.46673
Timestep Consumption Time: 2.64270
PPO Batch Consumption Time: 0.32631
Total Iteration Time: 5.10943

Cumulative Model Updates: 3,396
Cumulative Timesteps: 28,360,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,720.32387
Policy Entropy: 2.31749
Value Function Loss: 0.50893

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.13248
Value Function Update Magnitude: 0.29805

Collected Steps per Second: 20,569.96616
Overall Steps per Second: 10,179.04266

Timestep Collection Time: 2.43121
Timestep Consumption Time: 2.48182
PPO Batch Consumption Time: 0.29883
Total Iteration Time: 4.91304

Cumulative Model Updates: 3,402
Cumulative Timesteps: 28,410,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 28410260...
Checkpoint 28410260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,862.21339
Policy Entropy: 2.29026
Value Function Loss: 0.49673

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.14487
Policy Update Magnitude: 0.14142
Value Function Update Magnitude: 0.37119

Collected Steps per Second: 20,338.56572
Overall Steps per Second: 10,230.04911

Timestep Collection Time: 2.45956
Timestep Consumption Time: 2.43034
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.88991

Cumulative Model Updates: 3,408
Cumulative Timesteps: 28,460,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,307.60898
Policy Entropy: 2.26917
Value Function Loss: 0.49969

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.15493
Value Function Update Magnitude: 0.36242

Collected Steps per Second: 20,582.54393
Overall Steps per Second: 10,096.65574

Timestep Collection Time: 2.43041
Timestep Consumption Time: 2.52410
PPO Batch Consumption Time: 0.30460
Total Iteration Time: 4.95451

Cumulative Model Updates: 3,414
Cumulative Timesteps: 28,510,308

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 28510308...
Checkpoint 28510308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,046.96698
Policy Entropy: 2.25457
Value Function Loss: 0.52177

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.20082
Value Function Update Magnitude: 0.30767

Collected Steps per Second: 20,791.94494
Overall Steps per Second: 10,164.77728

Timestep Collection Time: 2.40622
Timestep Consumption Time: 2.51568
PPO Batch Consumption Time: 0.30516
Total Iteration Time: 4.92190

Cumulative Model Updates: 3,420
Cumulative Timesteps: 28,560,338

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,944.08747
Policy Entropy: 2.27418
Value Function Loss: 0.49351

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.18085
Policy Update Magnitude: 0.17825
Value Function Update Magnitude: 0.27297

Collected Steps per Second: 19,412.02271
Overall Steps per Second: 9,953.65828

Timestep Collection Time: 2.57593
Timestep Consumption Time: 2.44775
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 5.02368

Cumulative Model Updates: 3,426
Cumulative Timesteps: 28,610,342

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 28610342...
Checkpoint 28610342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,231.87939
Policy Entropy: 2.29572
Value Function Loss: 0.45184

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.21389
Policy Update Magnitude: 0.15372
Value Function Update Magnitude: 0.27918

Collected Steps per Second: 20,535.08450
Overall Steps per Second: 10,122.27931

Timestep Collection Time: 2.43622
Timestep Consumption Time: 2.50614
PPO Batch Consumption Time: 0.29831
Total Iteration Time: 4.94237

Cumulative Model Updates: 3,432
Cumulative Timesteps: 28,660,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,053.43630
Policy Entropy: 2.28282
Value Function Loss: 0.45822

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.19944
Policy Update Magnitude: 0.13826
Value Function Update Magnitude: 0.24587

Collected Steps per Second: 20,642.36610
Overall Steps per Second: 10,159.47334

Timestep Collection Time: 2.42259
Timestep Consumption Time: 2.49971
PPO Batch Consumption Time: 0.30383
Total Iteration Time: 4.92230

Cumulative Model Updates: 3,438
Cumulative Timesteps: 28,710,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 28710378...
Checkpoint 28710378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,619.85911
Policy Entropy: 2.26688
Value Function Loss: 0.45271

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.17442
Policy Update Magnitude: 0.15457
Value Function Update Magnitude: 0.26818

Collected Steps per Second: 21,125.10395
Overall Steps per Second: 10,252.20191

Timestep Collection Time: 2.36780
Timestep Consumption Time: 2.51115
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.87895

Cumulative Model Updates: 3,444
Cumulative Timesteps: 28,760,398

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,363.75288
Policy Entropy: 2.24416
Value Function Loss: 0.46891

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.18118
Policy Update Magnitude: 0.13686
Value Function Update Magnitude: 0.29610

Collected Steps per Second: 20,821.24461
Overall Steps per Second: 10,032.30256

Timestep Collection Time: 2.40341
Timestep Consumption Time: 2.58468
PPO Batch Consumption Time: 0.30239
Total Iteration Time: 4.98809

Cumulative Model Updates: 3,450
Cumulative Timesteps: 28,810,440

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 28810440...
Checkpoint 28810440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,814.33062
Policy Entropy: 2.22110
Value Function Loss: 0.46999

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.20341
Policy Update Magnitude: 0.14271
Value Function Update Magnitude: 0.29600

Collected Steps per Second: 21,235.20830
Overall Steps per Second: 10,215.06653

Timestep Collection Time: 2.35656
Timestep Consumption Time: 2.54228
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.89884

Cumulative Model Updates: 3,456
Cumulative Timesteps: 28,860,482

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,041.45868
Policy Entropy: 2.23858
Value Function Loss: 0.50112

Mean KL Divergence: 0.02416
SB3 Clip Fraction: 0.23765
Policy Update Magnitude: 0.13434
Value Function Update Magnitude: 0.28466

Collected Steps per Second: 21,038.27981
Overall Steps per Second: 10,105.14097

Timestep Collection Time: 2.37814
Timestep Consumption Time: 2.57300
PPO Batch Consumption Time: 0.30453
Total Iteration Time: 4.95114

Cumulative Model Updates: 3,462
Cumulative Timesteps: 28,910,514

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 28910514...
Checkpoint 28910514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,950.51552
Policy Entropy: 2.25725
Value Function Loss: 0.47317

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.21187
Policy Update Magnitude: 0.13174
Value Function Update Magnitude: 0.26548

Collected Steps per Second: 21,281.08093
Overall Steps per Second: 10,158.49873

Timestep Collection Time: 2.35148
Timestep Consumption Time: 2.57464
PPO Batch Consumption Time: 0.30027
Total Iteration Time: 4.92612

Cumulative Model Updates: 3,468
Cumulative Timesteps: 28,960,556

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,987.68880
Policy Entropy: 2.23749
Value Function Loss: 0.48573

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.19632
Policy Update Magnitude: 0.13706
Value Function Update Magnitude: 0.26463

Collected Steps per Second: 21,158.65459
Overall Steps per Second: 10,052.68839

Timestep Collection Time: 2.36423
Timestep Consumption Time: 2.61195
PPO Batch Consumption Time: 0.29814
Total Iteration Time: 4.97618

Cumulative Model Updates: 3,474
Cumulative Timesteps: 29,010,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 29010580...
Checkpoint 29010580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,998.65073
Policy Entropy: 2.22808
Value Function Loss: 0.47844

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.16938
Policy Update Magnitude: 0.12706
Value Function Update Magnitude: 0.28697

Collected Steps per Second: 21,232.27052
Overall Steps per Second: 10,215.09053

Timestep Collection Time: 2.35594
Timestep Consumption Time: 2.54093
PPO Batch Consumption Time: 0.29825
Total Iteration Time: 4.89687

Cumulative Model Updates: 3,480
Cumulative Timesteps: 29,060,602

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,540.25353
Policy Entropy: 2.22680
Value Function Loss: 0.45477

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.14890
Policy Update Magnitude: 0.12534
Value Function Update Magnitude: 0.41738

Collected Steps per Second: 21,107.99146
Overall Steps per Second: 10,094.27703

Timestep Collection Time: 2.36953
Timestep Consumption Time: 2.58536
PPO Batch Consumption Time: 0.30496
Total Iteration Time: 4.95489

Cumulative Model Updates: 3,486
Cumulative Timesteps: 29,110,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 29110618...
Checkpoint 29110618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,451.35277
Policy Entropy: 2.23393
Value Function Loss: 0.44390

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.20242
Policy Update Magnitude: 0.13506
Value Function Update Magnitude: 0.42540

Collected Steps per Second: 20,085.73864
Overall Steps per Second: 9,769.70048

Timestep Collection Time: 2.49162
Timestep Consumption Time: 2.63095
PPO Batch Consumption Time: 0.30918
Total Iteration Time: 5.12257

Cumulative Model Updates: 3,492
Cumulative Timesteps: 29,160,664

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,924.30877
Policy Entropy: 2.20146
Value Function Loss: 0.41023

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.18383
Policy Update Magnitude: 0.13120
Value Function Update Magnitude: 0.44193

Collected Steps per Second: 20,813.02350
Overall Steps per Second: 9,964.05717

Timestep Collection Time: 2.40350
Timestep Consumption Time: 2.61695
PPO Batch Consumption Time: 0.31065
Total Iteration Time: 5.02044

Cumulative Model Updates: 3,498
Cumulative Timesteps: 29,210,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 29210688...
Checkpoint 29210688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,492.04768
Policy Entropy: 2.17692
Value Function Loss: 0.40806

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12055
Policy Update Magnitude: 0.15943
Value Function Update Magnitude: 0.42230

Collected Steps per Second: 21,024.70815
Overall Steps per Second: 10,215.73801

Timestep Collection Time: 2.37853
Timestep Consumption Time: 2.51666
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.89519

Cumulative Model Updates: 3,504
Cumulative Timesteps: 29,260,696

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,070.03110
Policy Entropy: 2.16339
Value Function Loss: 0.41464

Mean KL Divergence: 0.02556
SB3 Clip Fraction: 0.24558
Policy Update Magnitude: 0.18345
Value Function Update Magnitude: 0.37443

Collected Steps per Second: 21,030.84618
Overall Steps per Second: 9,978.69387

Timestep Collection Time: 2.37813
Timestep Consumption Time: 2.63395
PPO Batch Consumption Time: 0.31186
Total Iteration Time: 5.01208

Cumulative Model Updates: 3,510
Cumulative Timesteps: 29,310,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 29310710...
Checkpoint 29310710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,666.70212
Policy Entropy: 2.19359
Value Function Loss: 0.40197

Mean KL Divergence: 0.03427
SB3 Clip Fraction: 0.29294
Policy Update Magnitude: 0.13913
Value Function Update Magnitude: 0.34903

Collected Steps per Second: 21,269.01193
Overall Steps per Second: 10,283.17476

Timestep Collection Time: 2.35215
Timestep Consumption Time: 2.51288
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.86503

Cumulative Model Updates: 3,516
Cumulative Timesteps: 29,360,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,261.58951
Policy Entropy: 2.22391
Value Function Loss: 0.42466

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.22219
Policy Update Magnitude: 0.10072
Value Function Update Magnitude: 0.33267

Collected Steps per Second: 20,912.86854
Overall Steps per Second: 10,062.72786

Timestep Collection Time: 2.39145
Timestep Consumption Time: 2.57858
PPO Batch Consumption Time: 0.30187
Total Iteration Time: 4.97002

Cumulative Model Updates: 3,522
Cumulative Timesteps: 29,410,750

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 29410750...
Checkpoint 29410750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,226.35604
Policy Entropy: 2.21562
Value Function Loss: 0.45993

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.17851
Policy Update Magnitude: 0.10709
Value Function Update Magnitude: 0.29543

Collected Steps per Second: 20,687.81761
Overall Steps per Second: 10,117.26484

Timestep Collection Time: 2.41775
Timestep Consumption Time: 2.52607
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.94383

Cumulative Model Updates: 3,528
Cumulative Timesteps: 29,460,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,449.30331
Policy Entropy: 2.19680
Value Function Loss: 0.44158

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.15795
Policy Update Magnitude: 0.11002
Value Function Update Magnitude: 0.31117

Collected Steps per Second: 20,782.20632
Overall Steps per Second: 9,477.28651

Timestep Collection Time: 2.40744
Timestep Consumption Time: 2.87170
PPO Batch Consumption Time: 0.35230
Total Iteration Time: 5.27915

Cumulative Model Updates: 3,534
Cumulative Timesteps: 29,510,800

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 29510800...
Checkpoint 29510800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,604.69900
Policy Entropy: 2.19271
Value Function Loss: 0.41351

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.12744
Value Function Update Magnitude: 0.35067

Collected Steps per Second: 17,374.65158
Overall Steps per Second: 8,402.91107

Timestep Collection Time: 2.87833
Timestep Consumption Time: 3.07318
PPO Batch Consumption Time: 0.37362
Total Iteration Time: 5.95151

Cumulative Model Updates: 3,540
Cumulative Timesteps: 29,560,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,062.86433
Policy Entropy: 2.17756
Value Function Loss: 0.39959

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.16438
Policy Update Magnitude: 0.13665
Value Function Update Magnitude: 0.38660

Collected Steps per Second: 18,245.36526
Overall Steps per Second: 8,381.23695

Timestep Collection Time: 2.74185
Timestep Consumption Time: 3.22696
PPO Batch Consumption Time: 0.39244
Total Iteration Time: 5.96881

Cumulative Model Updates: 3,546
Cumulative Timesteps: 29,610,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 29610836...
Checkpoint 29610836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,371.38982
Policy Entropy: 2.14870
Value Function Loss: 0.42398

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.16010
Policy Update Magnitude: 0.14642
Value Function Update Magnitude: 0.33397

Collected Steps per Second: 18,041.29458
Overall Steps per Second: 8,414.28236

Timestep Collection Time: 2.77153
Timestep Consumption Time: 3.17098
PPO Batch Consumption Time: 0.38400
Total Iteration Time: 5.94252

Cumulative Model Updates: 3,552
Cumulative Timesteps: 29,660,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,974.73281
Policy Entropy: 2.13623
Value Function Loss: 0.43416

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.16779
Value Function Update Magnitude: 0.33176

Collected Steps per Second: 17,985.23843
Overall Steps per Second: 8,199.41203

Timestep Collection Time: 2.78161
Timestep Consumption Time: 3.31980
PPO Batch Consumption Time: 0.40189
Total Iteration Time: 6.10141

Cumulative Model Updates: 3,558
Cumulative Timesteps: 29,710,866

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 29710866...
Checkpoint 29710866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,049.86455
Policy Entropy: 2.13729
Value Function Loss: 0.42876

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.17937
Policy Update Magnitude: 0.15838
Value Function Update Magnitude: 0.36365

Collected Steps per Second: 18,333.83175
Overall Steps per Second: 8,455.98933

Timestep Collection Time: 2.72796
Timestep Consumption Time: 3.18666
PPO Batch Consumption Time: 0.38951
Total Iteration Time: 5.91462

Cumulative Model Updates: 3,564
Cumulative Timesteps: 29,760,880

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,029.51923
Policy Entropy: 2.13684
Value Function Loss: 0.42072

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.14360
Policy Update Magnitude: 0.14786
Value Function Update Magnitude: 0.36393

Collected Steps per Second: 18,337.38836
Overall Steps per Second: 8,474.92110

Timestep Collection Time: 2.72711
Timestep Consumption Time: 3.17360
PPO Batch Consumption Time: 0.38935
Total Iteration Time: 5.90070

Cumulative Model Updates: 3,570
Cumulative Timesteps: 29,810,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 29810888...
Checkpoint 29810888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,593.41073
Policy Entropy: 2.13219
Value Function Loss: 0.41479

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.15972
Policy Update Magnitude: 0.13647
Value Function Update Magnitude: 0.33792

Collected Steps per Second: 18,168.89715
Overall Steps per Second: 8,863.87655

Timestep Collection Time: 2.75295
Timestep Consumption Time: 2.88996
PPO Batch Consumption Time: 0.35132
Total Iteration Time: 5.64290

Cumulative Model Updates: 3,576
Cumulative Timesteps: 29,860,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,461.32325
Policy Entropy: 2.11611
Value Function Loss: 0.41264

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.14307
Policy Update Magnitude: 0.13561
Value Function Update Magnitude: 0.32490

Collected Steps per Second: 18,070.72397
Overall Steps per Second: 8,746.38241

Timestep Collection Time: 2.76691
Timestep Consumption Time: 2.94974
PPO Batch Consumption Time: 0.35386
Total Iteration Time: 5.71665

Cumulative Model Updates: 3,582
Cumulative Timesteps: 29,910,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 29910906...
Checkpoint 29910906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,241.00989
Policy Entropy: 2.11316
Value Function Loss: 0.42416

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.16832
Policy Update Magnitude: 0.14442
Value Function Update Magnitude: 0.32344

Collected Steps per Second: 20,795.50086
Overall Steps per Second: 10,202.66045

Timestep Collection Time: 2.40562
Timestep Consumption Time: 2.49761
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.90323

Cumulative Model Updates: 3,588
Cumulative Timesteps: 29,960,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,300.55644
Policy Entropy: 2.10628
Value Function Loss: 0.41755

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.15644
Policy Update Magnitude: 0.13605
Value Function Update Magnitude: 0.34378

Collected Steps per Second: 20,386.30279
Overall Steps per Second: 9,994.72346

Timestep Collection Time: 2.45331
Timestep Consumption Time: 2.55073
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 5.00404

Cumulative Model Updates: 3,594
Cumulative Timesteps: 30,010,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 30010946...
Checkpoint 30010946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,834.76889
Policy Entropy: 2.10651
Value Function Loss: 0.43146

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.16658
Policy Update Magnitude: 0.11674
Value Function Update Magnitude: 0.37782

Collected Steps per Second: 20,984.88019
Overall Steps per Second: 10,196.13044

Timestep Collection Time: 2.38295
Timestep Consumption Time: 2.52146
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.90441

Cumulative Model Updates: 3,600
Cumulative Timesteps: 30,060,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,263.45968
Policy Entropy: 2.10303
Value Function Loss: 0.42682

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.14426
Policy Update Magnitude: 0.13197
Value Function Update Magnitude: 0.32921

Collected Steps per Second: 19,846.64519
Overall Steps per Second: 9,897.57161

Timestep Collection Time: 2.52033
Timestep Consumption Time: 2.53344
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 5.05376

Cumulative Model Updates: 3,606
Cumulative Timesteps: 30,110,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 30110972...
Checkpoint 30110972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,480.21554
Policy Entropy: 2.07513
Value Function Loss: 0.43368

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.15258
Value Function Update Magnitude: 0.33397

Collected Steps per Second: 20,910.11672
Overall Steps per Second: 10,103.31930

Timestep Collection Time: 2.39253
Timestep Consumption Time: 2.55911
PPO Batch Consumption Time: 0.30195
Total Iteration Time: 4.95164

Cumulative Model Updates: 3,612
Cumulative Timesteps: 30,161,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,278.94443
Policy Entropy: 2.07656
Value Function Loss: 0.43965

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14136
Policy Update Magnitude: 0.14511
Value Function Update Magnitude: 0.35843

Collected Steps per Second: 20,844.52828
Overall Steps per Second: 9,294.60376

Timestep Collection Time: 2.40082
Timestep Consumption Time: 2.98338
PPO Batch Consumption Time: 0.37190
Total Iteration Time: 5.38420

Cumulative Model Updates: 3,618
Cumulative Timesteps: 30,211,044

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 30211044...
Checkpoint 30211044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,635.01062
Policy Entropy: 2.05995
Value Function Loss: 0.42959

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.14824
Value Function Update Magnitude: 0.33623

Collected Steps per Second: 18,130.11219
Overall Steps per Second: 8,626.27635

Timestep Collection Time: 2.75917
Timestep Consumption Time: 3.03986
PPO Batch Consumption Time: 0.37609
Total Iteration Time: 5.79903

Cumulative Model Updates: 3,624
Cumulative Timesteps: 30,261,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,919.85689
Policy Entropy: 2.06159
Value Function Loss: 0.41521

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.15032
Policy Update Magnitude: 0.13501
Value Function Update Magnitude: 0.31403

Collected Steps per Second: 17,785.23028
Overall Steps per Second: 8,460.97193

Timestep Collection Time: 2.81391
Timestep Consumption Time: 3.10102
PPO Batch Consumption Time: 0.37351
Total Iteration Time: 5.91492

Cumulative Model Updates: 3,630
Cumulative Timesteps: 30,311,114

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 30311114...
Checkpoint 30311114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,497.94227
Policy Entropy: 2.06287
Value Function Loss: 0.41867

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.18100
Policy Update Magnitude: 0.11589
Value Function Update Magnitude: 0.41100

Collected Steps per Second: 17,812.05653
Overall Steps per Second: 8,595.11764

Timestep Collection Time: 2.80866
Timestep Consumption Time: 3.01185
PPO Batch Consumption Time: 0.36330
Total Iteration Time: 5.82051

Cumulative Model Updates: 3,636
Cumulative Timesteps: 30,361,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,116.97663
Policy Entropy: 2.06259
Value Function Loss: 0.41143

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.14880
Policy Update Magnitude: 0.11281
Value Function Update Magnitude: 0.38400

Collected Steps per Second: 18,235.69122
Overall Steps per Second: 8,645.24009

Timestep Collection Time: 2.74220
Timestep Consumption Time: 3.04202
PPO Batch Consumption Time: 0.36689
Total Iteration Time: 5.78422

Cumulative Model Updates: 3,642
Cumulative Timesteps: 30,411,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 30411148...
Checkpoint 30411148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,002.54727
Policy Entropy: 2.05939
Value Function Loss: 0.41083

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.10909
Value Function Update Magnitude: 0.33092

Collected Steps per Second: 18,344.09337
Overall Steps per Second: 8,711.32134

Timestep Collection Time: 2.72567
Timestep Consumption Time: 3.01398
PPO Batch Consumption Time: 0.36843
Total Iteration Time: 5.73966

Cumulative Model Updates: 3,648
Cumulative Timesteps: 30,461,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,809.21026
Policy Entropy: 2.04267
Value Function Loss: 0.43053

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.12627
Policy Update Magnitude: 0.11253
Value Function Update Magnitude: 0.34704

Collected Steps per Second: 18,215.08815
Overall Steps per Second: 8,812.36674

Timestep Collection Time: 2.74608
Timestep Consumption Time: 2.93004
PPO Batch Consumption Time: 0.35209
Total Iteration Time: 5.67611

Cumulative Model Updates: 3,654
Cumulative Timesteps: 30,511,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 30511168...
Checkpoint 30511168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,386.29361
Policy Entropy: 2.01410
Value Function Loss: 0.42801

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.13497
Value Function Update Magnitude: 0.30149

Collected Steps per Second: 18,210.14800
Overall Steps per Second: 9,423.94223

Timestep Collection Time: 2.74770
Timestep Consumption Time: 2.56176
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 5.30946

Cumulative Model Updates: 3,660
Cumulative Timesteps: 30,561,204

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,719.10677
Policy Entropy: 2.00599
Value Function Loss: 0.43948

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.19309
Value Function Update Magnitude: 0.36560

Collected Steps per Second: 21,029.94427
Overall Steps per Second: 10,134.46820

Timestep Collection Time: 2.37861
Timestep Consumption Time: 2.55722
PPO Batch Consumption Time: 0.30264
Total Iteration Time: 4.93583

Cumulative Model Updates: 3,666
Cumulative Timesteps: 30,611,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 30611226...
Checkpoint 30611226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,401.24846
Policy Entropy: 2.00621
Value Function Loss: 0.45133

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.17454
Policy Update Magnitude: 0.16171
Value Function Update Magnitude: 0.33169

Collected Steps per Second: 17,856.95416
Overall Steps per Second: 8,449.32176

Timestep Collection Time: 2.80115
Timestep Consumption Time: 3.11885
PPO Batch Consumption Time: 0.39587
Total Iteration Time: 5.92000

Cumulative Model Updates: 3,672
Cumulative Timesteps: 30,661,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,584.27399
Policy Entropy: 2.00605
Value Function Loss: 0.44090

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.17340
Policy Update Magnitude: 0.12768
Value Function Update Magnitude: 0.29572

Collected Steps per Second: 17,865.07433
Overall Steps per Second: 8,548.58420

Timestep Collection Time: 2.79965
Timestep Consumption Time: 3.05114
PPO Batch Consumption Time: 0.36496
Total Iteration Time: 5.85079

Cumulative Model Updates: 3,678
Cumulative Timesteps: 30,711,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 30711262...
Checkpoint 30711262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,230.93236
Policy Entropy: 2.00917
Value Function Loss: 0.40877

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.16297
Policy Update Magnitude: 0.12061
Value Function Update Magnitude: 0.29499

Collected Steps per Second: 18,266.06921
Overall Steps per Second: 8,701.70908

Timestep Collection Time: 2.73743
Timestep Consumption Time: 3.00880
PPO Batch Consumption Time: 0.36698
Total Iteration Time: 5.74623

Cumulative Model Updates: 3,684
Cumulative Timesteps: 30,761,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,395.25287
Policy Entropy: 1.97533
Value Function Loss: 0.39289

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.12581
Value Function Update Magnitude: 0.30821

Collected Steps per Second: 17,568.15052
Overall Steps per Second: 8,682.47933

Timestep Collection Time: 2.84686
Timestep Consumption Time: 2.91348
PPO Batch Consumption Time: 0.34659
Total Iteration Time: 5.76034

Cumulative Model Updates: 3,690
Cumulative Timesteps: 30,811,278

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 30811278...
Checkpoint 30811278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,007.91091
Policy Entropy: 1.98411
Value Function Loss: 0.44208

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.21338
Policy Update Magnitude: 0.12716
Value Function Update Magnitude: 0.37271

Collected Steps per Second: 18,543.29037
Overall Steps per Second: 9,504.61120

Timestep Collection Time: 2.69661
Timestep Consumption Time: 2.56442
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 5.26103

Cumulative Model Updates: 3,696
Cumulative Timesteps: 30,861,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,746.77361
Policy Entropy: 1.97778
Value Function Loss: 0.40689

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.15711
Policy Update Magnitude: 0.12443
Value Function Update Magnitude: 0.31788

Collected Steps per Second: 19,881.12270
Overall Steps per Second: 9,142.24772

Timestep Collection Time: 2.51565
Timestep Consumption Time: 2.95499
PPO Batch Consumption Time: 0.35896
Total Iteration Time: 5.47065

Cumulative Model Updates: 3,702
Cumulative Timesteps: 30,911,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 30911296...
Checkpoint 30911296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,443.16702
Policy Entropy: 1.98067
Value Function Loss: 0.39562

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.15716
Policy Update Magnitude: 0.12878
Value Function Update Magnitude: 0.35533

Collected Steps per Second: 18,204.64827
Overall Steps per Second: 8,620.29075

Timestep Collection Time: 2.74765
Timestep Consumption Time: 3.05494
PPO Batch Consumption Time: 0.36861
Total Iteration Time: 5.80259

Cumulative Model Updates: 3,708
Cumulative Timesteps: 30,961,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,657.86164
Policy Entropy: 1.97362
Value Function Loss: 0.38207

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.19586
Policy Update Magnitude: 0.15733
Value Function Update Magnitude: 0.37643

Collected Steps per Second: 18,064.51277
Overall Steps per Second: 8,538.10753

Timestep Collection Time: 2.76974
Timestep Consumption Time: 3.09034
PPO Batch Consumption Time: 0.37353
Total Iteration Time: 5.86008

Cumulative Model Updates: 3,714
Cumulative Timesteps: 31,011,350

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 31011350...
Checkpoint 31011350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,233.62182
Policy Entropy: 1.97111
Value Function Loss: 0.40437

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.15785
Policy Update Magnitude: 0.16066
Value Function Update Magnitude: 0.33723

Collected Steps per Second: 19,912.15138
Overall Steps per Second: 9,826.24045

Timestep Collection Time: 2.51244
Timestep Consumption Time: 2.57883
PPO Batch Consumption Time: 0.30448
Total Iteration Time: 5.09127

Cumulative Model Updates: 3,720
Cumulative Timesteps: 31,061,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,888.98292
Policy Entropy: 1.94758
Value Function Loss: 0.40753

Mean KL Divergence: 0.03515
SB3 Clip Fraction: 0.26627
Policy Update Magnitude: 0.14689
Value Function Update Magnitude: 0.28221

Collected Steps per Second: 20,936.46038
Overall Steps per Second: 10,013.61456

Timestep Collection Time: 2.38894
Timestep Consumption Time: 2.60586
PPO Batch Consumption Time: 0.31010
Total Iteration Time: 4.99480

Cumulative Model Updates: 3,726
Cumulative Timesteps: 31,111,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 31111394...
Checkpoint 31111394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,366.65510
Policy Entropy: 1.96793
Value Function Loss: 0.42111

Mean KL Divergence: 0.04006
SB3 Clip Fraction: 0.28891
Policy Update Magnitude: 0.12299
Value Function Update Magnitude: 0.27361

Collected Steps per Second: 17,712.06179
Overall Steps per Second: 8,524.41529

Timestep Collection Time: 2.82327
Timestep Consumption Time: 3.04293
PPO Batch Consumption Time: 0.37082
Total Iteration Time: 5.86621

Cumulative Model Updates: 3,732
Cumulative Timesteps: 31,161,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,485.77994
Policy Entropy: 1.99073
Value Function Loss: 0.41627

Mean KL Divergence: 0.04125
SB3 Clip Fraction: 0.29429
Policy Update Magnitude: 0.09771
Value Function Update Magnitude: 0.27723

Collected Steps per Second: 17,822.12366
Overall Steps per Second: 8,597.04126

Timestep Collection Time: 2.80606
Timestep Consumption Time: 3.01105
PPO Batch Consumption Time: 0.37076
Total Iteration Time: 5.81712

Cumulative Model Updates: 3,738
Cumulative Timesteps: 31,211,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 31211410...
Checkpoint 31211410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,370.54773
Policy Entropy: 1.99222
Value Function Loss: 0.48406

Mean KL Divergence: 0.03191
SB3 Clip Fraction: 0.26508
Policy Update Magnitude: 0.09078
Value Function Update Magnitude: 0.26286

Collected Steps per Second: 17,905.97409
Overall Steps per Second: 8,567.05505

Timestep Collection Time: 2.79326
Timestep Consumption Time: 3.04492
PPO Batch Consumption Time: 0.36628
Total Iteration Time: 5.83818

Cumulative Model Updates: 3,744
Cumulative Timesteps: 31,261,426

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,913.42154
Policy Entropy: 2.00428
Value Function Loss: 0.44265

Mean KL Divergence: 0.02734
SB3 Clip Fraction: 0.24319
Policy Update Magnitude: 0.08740
Value Function Update Magnitude: 0.24062

Collected Steps per Second: 17,834.82653
Overall Steps per Second: 8,612.88584

Timestep Collection Time: 2.80496
Timestep Consumption Time: 3.00331
PPO Batch Consumption Time: 0.36497
Total Iteration Time: 5.80827

Cumulative Model Updates: 3,750
Cumulative Timesteps: 31,311,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 31311452...
Checkpoint 31311452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,683.82630
Policy Entropy: 2.00292
Value Function Loss: 0.47153

Mean KL Divergence: 0.02593
SB3 Clip Fraction: 0.23720
Policy Update Magnitude: 0.08927
Value Function Update Magnitude: 0.22989

Collected Steps per Second: 18,240.13740
Overall Steps per Second: 8,768.61488

Timestep Collection Time: 2.74252
Timestep Consumption Time: 2.96237
PPO Batch Consumption Time: 0.36442
Total Iteration Time: 5.70489

Cumulative Model Updates: 3,756
Cumulative Timesteps: 31,361,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,099.82363
Policy Entropy: 1.99517
Value Function Loss: 0.43854

Mean KL Divergence: 0.04327
SB3 Clip Fraction: 0.29756
Policy Update Magnitude: 0.10269
Value Function Update Magnitude: 0.18764

Collected Steps per Second: 17,989.54226
Overall Steps per Second: 9,470.93175

Timestep Collection Time: 2.78106
Timestep Consumption Time: 2.50142
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 5.28248

Cumulative Model Updates: 3,762
Cumulative Timesteps: 31,411,506

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 31411506...
Checkpoint 31411506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,972.10431
Policy Entropy: 2.00382
Value Function Loss: 0.46329

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.17744
Policy Update Magnitude: 0.10159
Value Function Update Magnitude: 0.17480

Collected Steps per Second: 21,104.58111
Overall Steps per Second: 10,084.82282

Timestep Collection Time: 2.36963
Timestep Consumption Time: 2.58931
PPO Batch Consumption Time: 0.30773
Total Iteration Time: 4.95894

Cumulative Model Updates: 3,768
Cumulative Timesteps: 31,461,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,674.47894
Policy Entropy: 2.01067
Value Function Loss: 0.45568

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.15650
Value Function Update Magnitude: 0.18347

Collected Steps per Second: 20,856.22605
Overall Steps per Second: 10,157.19261

Timestep Collection Time: 2.39832
Timestep Consumption Time: 2.52626
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.92459

Cumulative Model Updates: 3,774
Cumulative Timesteps: 31,511,536

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 31511536...
Checkpoint 31511536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,335.11064
Policy Entropy: 1.99591
Value Function Loss: 0.45188

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.19764
Policy Update Magnitude: 0.17429
Value Function Update Magnitude: 0.26858

Collected Steps per Second: 21,199.02578
Overall Steps per Second: 10,102.03777

Timestep Collection Time: 2.36020
Timestep Consumption Time: 2.59266
PPO Batch Consumption Time: 0.30578
Total Iteration Time: 4.95286

Cumulative Model Updates: 3,780
Cumulative Timesteps: 31,561,570

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,709.55463
Policy Entropy: 1.95476
Value Function Loss: 0.53721

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.19335
Policy Update Magnitude: 0.15124
Value Function Update Magnitude: 0.23860

Collected Steps per Second: 20,653.32578
Overall Steps per Second: 10,208.79784

Timestep Collection Time: 2.42169
Timestep Consumption Time: 2.47761
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.89930

Cumulative Model Updates: 3,786
Cumulative Timesteps: 31,611,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 31611586...
Checkpoint 31611586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,010.55175
Policy Entropy: 1.93690
Value Function Loss: 0.43724

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.17360
Policy Update Magnitude: 0.14732
Value Function Update Magnitude: 0.23178

Collected Steps per Second: 20,766.03159
Overall Steps per Second: 10,211.29626

Timestep Collection Time: 2.40874
Timestep Consumption Time: 2.48976
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.89850

Cumulative Model Updates: 3,792
Cumulative Timesteps: 31,661,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,190.58732
Policy Entropy: 1.96099
Value Function Loss: 0.39987

Mean KL Divergence: 0.02595
SB3 Clip Fraction: 0.23229
Policy Update Magnitude: 0.16039
Value Function Update Magnitude: 0.24988

Collected Steps per Second: 21,083.33487
Overall Steps per Second: 10,100.52564

Timestep Collection Time: 2.37334
Timestep Consumption Time: 2.58066
PPO Batch Consumption Time: 0.30532
Total Iteration Time: 4.95400

Cumulative Model Updates: 3,798
Cumulative Timesteps: 31,711,644

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 31711644...
Checkpoint 31711644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,241.34831
Policy Entropy: 1.94660
Value Function Loss: 0.36676

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.15413
Policy Update Magnitude: 0.12772
Value Function Update Magnitude: 0.26090

Collected Steps per Second: 17,554.23815
Overall Steps per Second: 8,485.43270

Timestep Collection Time: 2.84968
Timestep Consumption Time: 3.04560
PPO Batch Consumption Time: 0.37392
Total Iteration Time: 5.89528

Cumulative Model Updates: 3,804
Cumulative Timesteps: 31,761,668

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,976.65418
Policy Entropy: 1.96302
Value Function Loss: 0.37596

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.15417
Policy Update Magnitude: 0.12705
Value Function Update Magnitude: 0.27294

Collected Steps per Second: 17,533.00695
Overall Steps per Second: 8,459.14826

Timestep Collection Time: 2.85336
Timestep Consumption Time: 3.06071
PPO Batch Consumption Time: 0.36580
Total Iteration Time: 5.91407

Cumulative Model Updates: 3,810
Cumulative Timesteps: 31,811,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 31811696...
Checkpoint 31811696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,401.20378
Policy Entropy: 1.94464
Value Function Loss: 0.37587

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.11839
Policy Update Magnitude: 0.15394
Value Function Update Magnitude: 0.36325

Collected Steps per Second: 18,026.39777
Overall Steps per Second: 8,765.60938

Timestep Collection Time: 2.77460
Timestep Consumption Time: 2.93134
PPO Batch Consumption Time: 0.35938
Total Iteration Time: 5.70594

Cumulative Model Updates: 3,816
Cumulative Timesteps: 31,861,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,835.84965
Policy Entropy: 1.94828
Value Function Loss: 0.38863

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.18671
Value Function Update Magnitude: 0.34035

Collected Steps per Second: 18,390.40302
Overall Steps per Second: 8,881.28508

Timestep Collection Time: 2.72033
Timestep Consumption Time: 2.91264
PPO Batch Consumption Time: 0.34758
Total Iteration Time: 5.63297

Cumulative Model Updates: 3,822
Cumulative Timesteps: 31,911,740

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 31911740...
Checkpoint 31911740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,133.47472
Policy Entropy: 1.95205
Value Function Loss: 0.41664

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.17343
Policy Update Magnitude: 0.15130
Value Function Update Magnitude: 0.26542

Collected Steps per Second: 18,419.84153
Overall Steps per Second: 8,917.49624

Timestep Collection Time: 2.71588
Timestep Consumption Time: 2.89399
PPO Batch Consumption Time: 0.34957
Total Iteration Time: 5.60987

Cumulative Model Updates: 3,828
Cumulative Timesteps: 31,961,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,723.18385
Policy Entropy: 1.94786
Value Function Loss: 0.36548

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.19610
Policy Update Magnitude: 0.14845
Value Function Update Magnitude: 0.32566

Collected Steps per Second: 18,386.38400
Overall Steps per Second: 9,240.32475

Timestep Collection Time: 2.72060
Timestep Consumption Time: 2.69285
PPO Batch Consumption Time: 0.32712
Total Iteration Time: 5.41345

Cumulative Model Updates: 3,834
Cumulative Timesteps: 32,011,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 32011788...
Checkpoint 32011788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,518.24056
Policy Entropy: 1.93270
Value Function Loss: 0.36687

Mean KL Divergence: 0.03532
SB3 Clip Fraction: 0.27538
Policy Update Magnitude: 0.13845
Value Function Update Magnitude: 0.38230

Collected Steps per Second: 19,735.44457
Overall Steps per Second: 9,957.83162

Timestep Collection Time: 2.53594
Timestep Consumption Time: 2.49005
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 5.02599

Cumulative Model Updates: 3,840
Cumulative Timesteps: 32,061,836

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,033.42070
Policy Entropy: 1.90193
Value Function Loss: 0.36167

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.17350
Policy Update Magnitude: 0.12424
Value Function Update Magnitude: 0.37045

Collected Steps per Second: 19,666.23787
Overall Steps per Second: 9,881.93821

Timestep Collection Time: 2.54294
Timestep Consumption Time: 2.51781
PPO Batch Consumption Time: 0.29959
Total Iteration Time: 5.06075

Cumulative Model Updates: 3,846
Cumulative Timesteps: 32,111,846

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 32111846...
Checkpoint 32111846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,134.43401
Policy Entropy: 1.91835
Value Function Loss: 0.37042

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.12887
Value Function Update Magnitude: 0.37371

Collected Steps per Second: 19,673.02942
Overall Steps per Second: 9,770.36439

Timestep Collection Time: 2.54186
Timestep Consumption Time: 2.57627
PPO Batch Consumption Time: 0.30547
Total Iteration Time: 5.11813

Cumulative Model Updates: 3,852
Cumulative Timesteps: 32,161,852

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,332.50094
Policy Entropy: 1.91633
Value Function Loss: 0.37705

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.18915
Policy Update Magnitude: 0.13990
Value Function Update Magnitude: 0.36392

Collected Steps per Second: 20,625.73011
Overall Steps per Second: 9,778.65684

Timestep Collection Time: 2.42677
Timestep Consumption Time: 2.69192
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 5.11870

Cumulative Model Updates: 3,858
Cumulative Timesteps: 32,211,906

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 32211906...
Checkpoint 32211906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377.76303
Policy Entropy: 1.92028
Value Function Loss: 0.39877

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.15390
Value Function Update Magnitude: 0.31740

Collected Steps per Second: 20,847.27340
Overall Steps per Second: 9,625.92306

Timestep Collection Time: 2.39926
Timestep Consumption Time: 2.79692
PPO Batch Consumption Time: 0.34292
Total Iteration Time: 5.19618

Cumulative Model Updates: 3,864
Cumulative Timesteps: 32,261,924

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,444.69420
Policy Entropy: 1.90232
Value Function Loss: 0.38402

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.16949
Policy Update Magnitude: 0.17178
Value Function Update Magnitude: 0.28722

Collected Steps per Second: 20,486.15550
Overall Steps per Second: 9,501.87994

Timestep Collection Time: 2.44184
Timestep Consumption Time: 2.82280
PPO Batch Consumption Time: 0.34481
Total Iteration Time: 5.26464

Cumulative Model Updates: 3,870
Cumulative Timesteps: 32,311,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 32311948...
Checkpoint 32311948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,282.29268
Policy Entropy: 1.89954
Value Function Loss: 0.39853

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.15809
Policy Update Magnitude: 0.15258
Value Function Update Magnitude: 0.25964

Collected Steps per Second: 21,080.63583
Overall Steps per Second: 10,192.92060

Timestep Collection Time: 2.37317
Timestep Consumption Time: 2.53494
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.90811

Cumulative Model Updates: 3,876
Cumulative Timesteps: 32,361,976

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,316.14922
Policy Entropy: 1.90729
Value Function Loss: 0.39218

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.16743
Value Function Update Magnitude: 0.33234

Collected Steps per Second: 19,721.80439
Overall Steps per Second: 9,795.57794

Timestep Collection Time: 2.53547
Timestep Consumption Time: 2.56928
PPO Batch Consumption Time: 0.30641
Total Iteration Time: 5.10475

Cumulative Model Updates: 3,882
Cumulative Timesteps: 32,411,980

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 32411980...
Checkpoint 32411980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,764.90800
Policy Entropy: 1.90100
Value Function Loss: 0.41144

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.17790
Policy Update Magnitude: 0.16428
Value Function Update Magnitude: 0.34928

Collected Steps per Second: 19,427.75176
Overall Steps per Second: 9,813.25504

Timestep Collection Time: 2.57456
Timestep Consumption Time: 2.52242
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 5.09698

Cumulative Model Updates: 3,888
Cumulative Timesteps: 32,461,998

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,879.12976
Policy Entropy: 1.88854
Value Function Loss: 0.41921

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.14720
Value Function Update Magnitude: 0.28476

Collected Steps per Second: 18,930.12937
Overall Steps per Second: 9,653.73541

Timestep Collection Time: 2.64203
Timestep Consumption Time: 2.53876
PPO Batch Consumption Time: 0.30105
Total Iteration Time: 5.18079

Cumulative Model Updates: 3,894
Cumulative Timesteps: 32,512,012

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 32512012...
Checkpoint 32512012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,436.99890
Policy Entropy: 1.88705
Value Function Loss: 0.41333

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.15045
Policy Update Magnitude: 0.13959
Value Function Update Magnitude: 0.26157

Collected Steps per Second: 20,367.38409
Overall Steps per Second: 9,873.06123

Timestep Collection Time: 2.45599
Timestep Consumption Time: 2.61053
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 5.06651

Cumulative Model Updates: 3,900
Cumulative Timesteps: 32,562,034

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,326.57055
Policy Entropy: 1.87974
Value Function Loss: 0.38323

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.13732
Value Function Update Magnitude: 0.33143

Collected Steps per Second: 20,375.84263
Overall Steps per Second: 9,522.67854

Timestep Collection Time: 2.45575
Timestep Consumption Time: 2.79886
PPO Batch Consumption Time: 0.34069
Total Iteration Time: 5.25461

Cumulative Model Updates: 3,906
Cumulative Timesteps: 32,612,072

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 32612072...
Checkpoint 32612072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,980.78598
Policy Entropy: 1.87589
Value Function Loss: 0.37626

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.14045
Policy Update Magnitude: 0.14952
Value Function Update Magnitude: 0.37572

Collected Steps per Second: 20,408.11747
Overall Steps per Second: 9,486.67432

Timestep Collection Time: 2.45128
Timestep Consumption Time: 2.82201
PPO Batch Consumption Time: 0.34572
Total Iteration Time: 5.27329

Cumulative Model Updates: 3,912
Cumulative Timesteps: 32,662,098

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,809.26250
Policy Entropy: 1.87629
Value Function Loss: 0.37190

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.18277
Policy Update Magnitude: 0.14118
Value Function Update Magnitude: 0.38609

Collected Steps per Second: 20,655.75921
Overall Steps per Second: 9,773.83521

Timestep Collection Time: 2.42063
Timestep Consumption Time: 2.69507
PPO Batch Consumption Time: 0.32187
Total Iteration Time: 5.11570

Cumulative Model Updates: 3,918
Cumulative Timesteps: 32,712,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 32712098...
Checkpoint 32712098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,999.70486
Policy Entropy: 1.89024
Value Function Loss: 0.38813

Mean KL Divergence: 0.03013
SB3 Clip Fraction: 0.23605
Policy Update Magnitude: 0.12025
Value Function Update Magnitude: 0.34501

Collected Steps per Second: 20,321.35954
Overall Steps per Second: 10,087.31336

Timestep Collection Time: 2.46047
Timestep Consumption Time: 2.49626
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.95672

Cumulative Model Updates: 3,924
Cumulative Timesteps: 32,762,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,906.41207
Policy Entropy: 1.93141
Value Function Loss: 0.38774

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.18758
Policy Update Magnitude: 0.11937
Value Function Update Magnitude: 0.32823

Collected Steps per Second: 19,485.24201
Overall Steps per Second: 9,823.24656

Timestep Collection Time: 2.56728
Timestep Consumption Time: 2.52513
PPO Batch Consumption Time: 0.29804
Total Iteration Time: 5.09241

Cumulative Model Updates: 3,930
Cumulative Timesteps: 32,812,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 32812122...
Checkpoint 32812122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,383.10420
Policy Entropy: 1.94074
Value Function Loss: 0.38814

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.16361
Policy Update Magnitude: 0.12858
Value Function Update Magnitude: 0.29883

Collected Steps per Second: 19,748.81266
Overall Steps per Second: 9,900.66213

Timestep Collection Time: 2.53352
Timestep Consumption Time: 2.52008
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 5.05360

Cumulative Model Updates: 3,936
Cumulative Timesteps: 32,862,156

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,786.44153
Policy Entropy: 1.91943
Value Function Loss: 0.38383

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.19952
Policy Update Magnitude: 0.14095
Value Function Update Magnitude: 0.26110

Collected Steps per Second: 21,041.85056
Overall Steps per Second: 10,140.14878

Timestep Collection Time: 2.37669
Timestep Consumption Time: 2.55519
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 4.93188

Cumulative Model Updates: 3,942
Cumulative Timesteps: 32,912,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 32912166...
Checkpoint 32912166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,995.30324
Policy Entropy: 1.88203
Value Function Loss: 0.40406

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.17005
Value Function Update Magnitude: 0.26162

Collected Steps per Second: 20,990.61679
Overall Steps per Second: 10,186.38901

Timestep Collection Time: 2.38306
Timestep Consumption Time: 2.52761
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.91067

Cumulative Model Updates: 3,948
Cumulative Timesteps: 32,962,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,736.26782
Policy Entropy: 1.85585
Value Function Loss: 0.38256

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.17352
Value Function Update Magnitude: 0.26490

Collected Steps per Second: 20,922.92365
Overall Steps per Second: 10,091.25203

Timestep Collection Time: 2.39049
Timestep Consumption Time: 2.56588
PPO Batch Consumption Time: 0.30582
Total Iteration Time: 4.95637

Cumulative Model Updates: 3,954
Cumulative Timesteps: 33,012,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 33012204...
Checkpoint 33012204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,004.54249
Policy Entropy: 1.86318
Value Function Loss: 0.35757

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.14792
Policy Update Magnitude: 0.14665
Value Function Update Magnitude: 0.28896

Collected Steps per Second: 20,814.53400
Overall Steps per Second: 10,189.02457

Timestep Collection Time: 2.40390
Timestep Consumption Time: 2.50688
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.91077

Cumulative Model Updates: 3,960
Cumulative Timesteps: 33,062,240

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,026.92499
Policy Entropy: 1.87512
Value Function Loss: 0.38590

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.17622
Policy Update Magnitude: 0.14246
Value Function Update Magnitude: 0.31825

Collected Steps per Second: 19,452.23669
Overall Steps per Second: 9,804.97628

Timestep Collection Time: 2.57040
Timestep Consumption Time: 2.52905
PPO Batch Consumption Time: 0.30042
Total Iteration Time: 5.09945

Cumulative Model Updates: 3,966
Cumulative Timesteps: 33,112,240

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 33112240...
Checkpoint 33112240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,390.11637
Policy Entropy: 1.87554
Value Function Loss: 0.42000

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.19386
Policy Update Magnitude: 0.12604
Value Function Update Magnitude: 0.27953

Collected Steps per Second: 19,425.32645
Overall Steps per Second: 9,810.14756

Timestep Collection Time: 2.57499
Timestep Consumption Time: 2.52381
PPO Batch Consumption Time: 0.29952
Total Iteration Time: 5.09880

Cumulative Model Updates: 3,972
Cumulative Timesteps: 33,162,260

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,051.37437
Policy Entropy: 1.87495
Value Function Loss: 0.36751

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.17755
Policy Update Magnitude: 0.14801
Value Function Update Magnitude: 0.30859

Collected Steps per Second: 19,492.10387
Overall Steps per Second: 9,884.86070

Timestep Collection Time: 2.56576
Timestep Consumption Time: 2.49370
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 5.05945

Cumulative Model Updates: 3,978
Cumulative Timesteps: 33,212,272

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 33212272...
Checkpoint 33212272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,674.78642
Policy Entropy: 1.87066
Value Function Loss: 0.36052

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.18054
Policy Update Magnitude: 0.14359
Value Function Update Magnitude: 0.37500

Collected Steps per Second: 19,652.93390
Overall Steps per Second: 9,804.68595

Timestep Collection Time: 2.54415
Timestep Consumption Time: 2.55545
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 5.09960

Cumulative Model Updates: 3,984
Cumulative Timesteps: 33,262,272

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,061.21609
Policy Entropy: 1.86950
Value Function Loss: 0.35884

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.15746
Policy Update Magnitude: 0.12083
Value Function Update Magnitude: 0.38634

Collected Steps per Second: 20,915.77675
Overall Steps per Second: 9,808.35076

Timestep Collection Time: 2.39207
Timestep Consumption Time: 2.70889
PPO Batch Consumption Time: 0.30910
Total Iteration Time: 5.10096

Cumulative Model Updates: 3,990
Cumulative Timesteps: 33,312,304

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 33312304...
Checkpoint 33312304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,741.51110
Policy Entropy: 1.87371
Value Function Loss: 0.37624

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.15906
Policy Update Magnitude: 0.11301
Value Function Update Magnitude: 0.30405

Collected Steps per Second: 20,556.15509
Overall Steps per Second: 9,554.40608

Timestep Collection Time: 2.43392
Timestep Consumption Time: 2.80262
PPO Batch Consumption Time: 0.34168
Total Iteration Time: 5.23654

Cumulative Model Updates: 3,996
Cumulative Timesteps: 33,362,336

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,130.59867
Policy Entropy: 1.86545
Value Function Loss: 0.36523

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.14906
Policy Update Magnitude: 0.12968
Value Function Update Magnitude: 0.29424

Collected Steps per Second: 20,488.30221
Overall Steps per Second: 9,706.03528

Timestep Collection Time: 2.44130
Timestep Consumption Time: 2.71199
PPO Batch Consumption Time: 0.32428
Total Iteration Time: 5.15329

Cumulative Model Updates: 4,002
Cumulative Timesteps: 33,412,354

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 33412354...
Checkpoint 33412354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,016.37819
Policy Entropy: 1.87521
Value Function Loss: 0.36735

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.20689
Policy Update Magnitude: 0.13651
Value Function Update Magnitude: 0.30888

Collected Steps per Second: 20,282.47744
Overall Steps per Second: 9,786.50506

Timestep Collection Time: 2.46676
Timestep Consumption Time: 2.64559
PPO Batch Consumption Time: 0.31728
Total Iteration Time: 5.11235

Cumulative Model Updates: 4,008
Cumulative Timesteps: 33,462,386

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,095.06353
Policy Entropy: 1.91430
Value Function Loss: 0.37870

Mean KL Divergence: 0.03063
SB3 Clip Fraction: 0.22468
Policy Update Magnitude: 0.11412
Value Function Update Magnitude: 0.26025

Collected Steps per Second: 21,341.01437
Overall Steps per Second: 10,236.55983

Timestep Collection Time: 2.34441
Timestep Consumption Time: 2.54317
PPO Batch Consumption Time: 0.30223
Total Iteration Time: 4.88758

Cumulative Model Updates: 4,014
Cumulative Timesteps: 33,512,418

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 33512418...
Checkpoint 33512418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,823.44364
Policy Entropy: 1.98280
Value Function Loss: 0.41763

Mean KL Divergence: 0.03516
SB3 Clip Fraction: 0.24120
Policy Update Magnitude: 0.11635
Value Function Update Magnitude: 0.24347

Collected Steps per Second: 20,735.53161
Overall Steps per Second: 10,090.88680

Timestep Collection Time: 2.41132
Timestep Consumption Time: 2.54365
PPO Batch Consumption Time: 0.30082
Total Iteration Time: 4.95497

Cumulative Model Updates: 4,020
Cumulative Timesteps: 33,562,418

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,347.65062
Policy Entropy: 2.04335
Value Function Loss: 0.45273

Mean KL Divergence: 0.02395
SB3 Clip Fraction: 0.21769
Policy Update Magnitude: 0.11293
Value Function Update Magnitude: 0.22163

Collected Steps per Second: 21,071.24316
Overall Steps per Second: 10,160.02094

Timestep Collection Time: 2.37328
Timestep Consumption Time: 2.54876
PPO Batch Consumption Time: 0.30189
Total Iteration Time: 4.92204

Cumulative Model Updates: 4,026
Cumulative Timesteps: 33,612,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 33612426...
Checkpoint 33612426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,083.55760
Policy Entropy: 2.10769
Value Function Loss: 0.51124

Mean KL Divergence: 0.02851
SB3 Clip Fraction: 0.25548
Policy Update Magnitude: 0.10360
Value Function Update Magnitude: 0.22028

Collected Steps per Second: 21,381.73382
Overall Steps per Second: 10,502.57378

Timestep Collection Time: 2.33844
Timestep Consumption Time: 2.42229
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.76074

Cumulative Model Updates: 4,032
Cumulative Timesteps: 33,662,426

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.46082
Policy Entropy: 2.16553
Value Function Loss: 0.56683

Mean KL Divergence: 0.02932
SB3 Clip Fraction: 0.24712
Policy Update Magnitude: 0.11304
Value Function Update Magnitude: 0.21361

Collected Steps per Second: 21,671.83723
Overall Steps per Second: 10,406.54603

Timestep Collection Time: 2.30733
Timestep Consumption Time: 2.49773
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.80505

Cumulative Model Updates: 4,038
Cumulative Timesteps: 33,712,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 33712430...
Checkpoint 33712430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.42615
Policy Entropy: 2.22847
Value Function Loss: 0.71422

Mean KL Divergence: 0.03634
SB3 Clip Fraction: 0.27634
Policy Update Magnitude: 0.13271
Value Function Update Magnitude: 0.23743

Collected Steps per Second: 20,349.51962
Overall Steps per Second: 9,975.47833

Timestep Collection Time: 2.45794
Timestep Consumption Time: 2.55615
PPO Batch Consumption Time: 0.30135
Total Iteration Time: 5.01410

Cumulative Model Updates: 4,044
Cumulative Timesteps: 33,762,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.13886
Policy Entropy: 2.26616
Value Function Loss: 0.55364

Mean KL Divergence: 0.02850
SB3 Clip Fraction: 0.26121
Policy Update Magnitude: 0.14508
Value Function Update Magnitude: 0.23331

Collected Steps per Second: 20,377.55975
Overall Steps per Second: 10,063.16571

Timestep Collection Time: 2.45437
Timestep Consumption Time: 2.51564
PPO Batch Consumption Time: 0.29960
Total Iteration Time: 4.97001

Cumulative Model Updates: 4,050
Cumulative Timesteps: 33,812,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 33812462...
Checkpoint 33812462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.87385
Policy Entropy: 2.30426
Value Function Loss: 0.54788

Mean KL Divergence: 0.02714
SB3 Clip Fraction: 0.25583
Policy Update Magnitude: 0.12556
Value Function Update Magnitude: 0.26537

Collected Steps per Second: 21,960.40093
Overall Steps per Second: 10,277.12333

Timestep Collection Time: 2.27737
Timestep Consumption Time: 2.58897
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.86634

Cumulative Model Updates: 4,056
Cumulative Timesteps: 33,862,474

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.37086
Policy Entropy: 2.33391
Value Function Loss: 0.47777

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.21344
Policy Update Magnitude: 0.12128
Value Function Update Magnitude: 0.27221

Collected Steps per Second: 21,829.65421
Overall Steps per Second: 9,729.30789

Timestep Collection Time: 2.29046
Timestep Consumption Time: 2.84865
PPO Batch Consumption Time: 0.34746
Total Iteration Time: 5.13911

Cumulative Model Updates: 4,062
Cumulative Timesteps: 33,912,474

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 33912474...
Checkpoint 33912474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.12951
Policy Entropy: 2.33484
Value Function Loss: 0.51192

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.15999
Policy Update Magnitude: 0.12164
Value Function Update Magnitude: 0.29987

Collected Steps per Second: 21,577.94657
Overall Steps per Second: 9,772.10702

Timestep Collection Time: 2.31746
Timestep Consumption Time: 2.79976
PPO Batch Consumption Time: 0.34217
Total Iteration Time: 5.11722

Cumulative Model Updates: 4,068
Cumulative Timesteps: 33,962,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.27162
Policy Entropy: 2.33808
Value Function Loss: 0.41031

Mean KL Divergence: 0.04020
SB3 Clip Fraction: 0.33040
Policy Update Magnitude: 0.13129
Value Function Update Magnitude: 0.30314

Collected Steps per Second: 20,937.90616
Overall Steps per Second: 10,138.79066

Timestep Collection Time: 2.38859
Timestep Consumption Time: 2.54415
PPO Batch Consumption Time: 0.31143
Total Iteration Time: 4.93274

Cumulative Model Updates: 4,074
Cumulative Timesteps: 34,012,492

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 34012492...
Checkpoint 34012492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.48884
Policy Entropy: 2.38924
Value Function Loss: 0.38489

Mean KL Divergence: 0.04576
SB3 Clip Fraction: 0.37075
Policy Update Magnitude: 0.13402
Value Function Update Magnitude: 0.26205

Collected Steps per Second: 20,551.66474
Overall Steps per Second: 10,169.29493

Timestep Collection Time: 2.43328
Timestep Consumption Time: 2.48427
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.91755

Cumulative Model Updates: 4,080
Cumulative Timesteps: 34,062,500

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.61362
Policy Entropy: 2.39834
Value Function Loss: 0.32107

Mean KL Divergence: 0.04245
SB3 Clip Fraction: 0.33234
Policy Update Magnitude: 0.13395
Value Function Update Magnitude: 0.27007

Collected Steps per Second: 20,435.08872
Overall Steps per Second: 10,138.14798

Timestep Collection Time: 2.44697
Timestep Consumption Time: 2.48529
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.93226

Cumulative Model Updates: 4,086
Cumulative Timesteps: 34,112,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 34112504...
Checkpoint 34112504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.72146
Policy Entropy: 2.41242
Value Function Loss: 0.31969

Mean KL Divergence: 0.02263
SB3 Clip Fraction: 0.24966
Policy Update Magnitude: 0.11464
Value Function Update Magnitude: 0.24061

Collected Steps per Second: 20,303.53332
Overall Steps per Second: 10,198.20480

Timestep Collection Time: 2.46351
Timestep Consumption Time: 2.44108
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.90459

Cumulative Model Updates: 4,092
Cumulative Timesteps: 34,162,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.38260
Policy Entropy: 2.43546
Value Function Loss: 0.28043

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.22093
Policy Update Magnitude: 0.11686
Value Function Update Magnitude: 0.22890

Collected Steps per Second: 21,603.14264
Overall Steps per Second: 9,895.69100

Timestep Collection Time: 2.31614
Timestep Consumption Time: 2.74020
PPO Batch Consumption Time: 0.32006
Total Iteration Time: 5.05634

Cumulative Model Updates: 4,098
Cumulative Timesteps: 34,212,558

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 34212558...
Checkpoint 34212558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.75113
Policy Entropy: 2.46245
Value Function Loss: 0.27383

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.21140
Policy Update Magnitude: 0.11654
Value Function Update Magnitude: 0.22278

Collected Steps per Second: 21,440.03251
Overall Steps per Second: 9,855.05742

Timestep Collection Time: 2.33218
Timestep Consumption Time: 2.74156
PPO Batch Consumption Time: 0.32943
Total Iteration Time: 5.07374

Cumulative Model Updates: 4,104
Cumulative Timesteps: 34,262,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.43054
Policy Entropy: 2.45649
Value Function Loss: 0.29882

Mean KL Divergence: 0.02872
SB3 Clip Fraction: 0.29033
Policy Update Magnitude: 0.11309
Value Function Update Magnitude: 0.24243

Collected Steps per Second: 19,684.61177
Overall Steps per Second: 9,740.22579

Timestep Collection Time: 2.54117
Timestep Consumption Time: 2.59444
PPO Batch Consumption Time: 0.30576
Total Iteration Time: 5.13561

Cumulative Model Updates: 4,110
Cumulative Timesteps: 34,312,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 34312582...
Checkpoint 34312582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.53037
Policy Entropy: 2.45745
Value Function Loss: 0.29002

Mean KL Divergence: 0.02421
SB3 Clip Fraction: 0.25917
Policy Update Magnitude: 0.09809
Value Function Update Magnitude: 0.23252

Collected Steps per Second: 21,464.02928
Overall Steps per Second: 10,264.55182

Timestep Collection Time: 2.33013
Timestep Consumption Time: 2.54237
PPO Batch Consumption Time: 0.30359
Total Iteration Time: 4.87250

Cumulative Model Updates: 4,116
Cumulative Timesteps: 34,362,596

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.92110
Policy Entropy: 2.46149
Value Function Loss: 0.28138

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.25071
Policy Update Magnitude: 0.11503
Value Function Update Magnitude: 0.23526

Collected Steps per Second: 21,164.31138
Overall Steps per Second: 10,389.18192

Timestep Collection Time: 2.36275
Timestep Consumption Time: 2.45052
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.81328

Cumulative Model Updates: 4,122
Cumulative Timesteps: 34,412,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 34412602...
Checkpoint 34412602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.00343
Policy Entropy: 2.47977
Value Function Loss: 0.26844

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.21305
Policy Update Magnitude: 0.13538
Value Function Update Magnitude: 0.25975

Collected Steps per Second: 21,452.29737
Overall Steps per Second: 10,104.61774

Timestep Collection Time: 2.33169
Timestep Consumption Time: 2.61853
PPO Batch Consumption Time: 0.31077
Total Iteration Time: 4.95021

Cumulative Model Updates: 4,128
Cumulative Timesteps: 34,462,622

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.04535
Policy Entropy: 2.46896
Value Function Loss: 0.26650

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.19019
Policy Update Magnitude: 0.14684
Value Function Update Magnitude: 0.25716

Collected Steps per Second: 21,782.95655
Overall Steps per Second: 10,428.81555

Timestep Collection Time: 2.29583
Timestep Consumption Time: 2.49954
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.79537

Cumulative Model Updates: 4,134
Cumulative Timesteps: 34,512,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 34512632...
Checkpoint 34512632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.71707
Policy Entropy: 2.45361
Value Function Loss: 0.27222

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.20368
Policy Update Magnitude: 0.14473
Value Function Update Magnitude: 0.26976

Collected Steps per Second: 21,688.67328
Overall Steps per Second: 10,329.76390

Timestep Collection Time: 2.30544
Timestep Consumption Time: 2.53513
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.84058

Cumulative Model Updates: 4,140
Cumulative Timesteps: 34,562,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 914.65896
Policy Entropy: 2.46171
Value Function Loss: 0.29458

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.20700
Policy Update Magnitude: 0.13809
Value Function Update Magnitude: 0.27287

Collected Steps per Second: 21,279.03839
Overall Steps per Second: 10,220.43333

Timestep Collection Time: 2.35095
Timestep Consumption Time: 2.54375
PPO Batch Consumption Time: 0.29964
Total Iteration Time: 4.89470

Cumulative Model Updates: 4,146
Cumulative Timesteps: 34,612,660

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 34612660...
Checkpoint 34612660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 863.93385
Policy Entropy: 2.43305
Value Function Loss: 0.30088

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.19722
Policy Update Magnitude: 0.14159
Value Function Update Magnitude: 0.29336

Collected Steps per Second: 21,586.39637
Overall Steps per Second: 10,273.24797

Timestep Collection Time: 2.31646
Timestep Consumption Time: 2.55094
PPO Batch Consumption Time: 0.29856
Total Iteration Time: 4.86740

Cumulative Model Updates: 4,152
Cumulative Timesteps: 34,662,664

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,204.74736
Policy Entropy: 2.43443
Value Function Loss: 0.28135

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.17883
Policy Update Magnitude: 0.14626
Value Function Update Magnitude: 0.31103

Collected Steps per Second: 21,361.31372
Overall Steps per Second: 10,212.80176

Timestep Collection Time: 2.34134
Timestep Consumption Time: 2.55585
PPO Batch Consumption Time: 0.30513
Total Iteration Time: 4.89719

Cumulative Model Updates: 4,158
Cumulative Timesteps: 34,712,678

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 34712678...
Checkpoint 34712678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.09505
Policy Entropy: 2.39979
Value Function Loss: 0.26655

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.18685
Policy Update Magnitude: 0.16694
Value Function Update Magnitude: 0.35238

Collected Steps per Second: 20,934.55722
Overall Steps per Second: 10,178.67248

Timestep Collection Time: 2.38868
Timestep Consumption Time: 2.52414
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.91282

Cumulative Model Updates: 4,164
Cumulative Timesteps: 34,762,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,752.85434
Policy Entropy: 2.36949
Value Function Loss: 0.26278

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.16758
Policy Update Magnitude: 0.17089
Value Function Update Magnitude: 0.38982

Collected Steps per Second: 20,821.23650
Overall Steps per Second: 10,057.38068

Timestep Collection Time: 2.40197
Timestep Consumption Time: 2.57070
PPO Batch Consumption Time: 0.30506
Total Iteration Time: 4.97267

Cumulative Model Updates: 4,170
Cumulative Timesteps: 34,812,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 34812696...
Checkpoint 34812696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,386.65380
Policy Entropy: 2.31279
Value Function Loss: 0.26766

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.17353
Policy Update Magnitude: 0.16351
Value Function Update Magnitude: 0.51224

Collected Steps per Second: 21,149.75320
Overall Steps per Second: 10,177.54954

Timestep Collection Time: 2.36561
Timestep Consumption Time: 2.55031
PPO Batch Consumption Time: 0.30209
Total Iteration Time: 4.91592

Cumulative Model Updates: 4,176
Cumulative Timesteps: 34,862,728

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,635.61144
Policy Entropy: 2.28709
Value Function Loss: 0.28406

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.16510
Policy Update Magnitude: 0.16833
Value Function Update Magnitude: 0.43526

Collected Steps per Second: 20,944.73918
Overall Steps per Second: 10,123.93017

Timestep Collection Time: 2.38733
Timestep Consumption Time: 2.55166
PPO Batch Consumption Time: 0.30469
Total Iteration Time: 4.93899

Cumulative Model Updates: 4,182
Cumulative Timesteps: 34,912,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 34912730...
Checkpoint 34912730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,904.19697
Policy Entropy: 2.25602
Value Function Loss: 0.25701

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.15324
Policy Update Magnitude: 0.17156
Value Function Update Magnitude: 0.35201

Collected Steps per Second: 21,182.12327
Overall Steps per Second: 10,071.97389

Timestep Collection Time: 2.36086
Timestep Consumption Time: 2.60421
PPO Batch Consumption Time: 0.31176
Total Iteration Time: 4.96506

Cumulative Model Updates: 4,188
Cumulative Timesteps: 34,962,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,074.35719
Policy Entropy: 2.23412
Value Function Loss: 0.24389

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.18683
Value Function Update Magnitude: 0.44524

Collected Steps per Second: 19,800.95703
Overall Steps per Second: 9,953.44174

Timestep Collection Time: 2.52564
Timestep Consumption Time: 2.49876
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 5.02439

Cumulative Model Updates: 4,194
Cumulative Timesteps: 35,012,748

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 35012748...
Checkpoint 35012748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216.23962
Policy Entropy: 2.17763
Value Function Loss: 0.23837

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10781
Policy Update Magnitude: 0.21008
Value Function Update Magnitude: 0.48892

Collected Steps per Second: 20,990.88666
Overall Steps per Second: 10,254.92659

Timestep Collection Time: 2.38332
Timestep Consumption Time: 2.49512
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.87844

Cumulative Model Updates: 4,200
Cumulative Timesteps: 35,062,776

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,280.32409
Policy Entropy: 2.16450
Value Function Loss: 0.25872

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.22079
Value Function Update Magnitude: 0.45079

Collected Steps per Second: 19,675.34849
Overall Steps per Second: 9,873.76459

Timestep Collection Time: 2.54257
Timestep Consumption Time: 2.52399
PPO Batch Consumption Time: 0.30063
Total Iteration Time: 5.06656

Cumulative Model Updates: 4,206
Cumulative Timesteps: 35,112,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 35112802...
Checkpoint 35112802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,817.44799
Policy Entropy: 2.12902
Value Function Loss: 0.25155

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.21917
Value Function Update Magnitude: 0.38375

Collected Steps per Second: 20,842.14155
Overall Steps per Second: 9,753.01617

Timestep Collection Time: 2.39927
Timestep Consumption Time: 2.72796
PPO Batch Consumption Time: 0.33275
Total Iteration Time: 5.12723

Cumulative Model Updates: 4,212
Cumulative Timesteps: 35,162,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,052.58882
Policy Entropy: 2.12753
Value Function Loss: 0.24721

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.15855
Policy Update Magnitude: 0.19910
Value Function Update Magnitude: 0.42955

Collected Steps per Second: 18,549.62165
Overall Steps per Second: 9,277.66391

Timestep Collection Time: 2.69623
Timestep Consumption Time: 2.69457
PPO Batch Consumption Time: 0.32785
Total Iteration Time: 5.39080

Cumulative Model Updates: 4,218
Cumulative Timesteps: 35,212,822

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 35212822...
Checkpoint 35212822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,806.57105
Policy Entropy: 2.11640
Value Function Loss: 0.24564

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.19292
Value Function Update Magnitude: 0.39508

Collected Steps per Second: 15,594.86413
Overall Steps per Second: 8,102.23891

Timestep Collection Time: 3.20631
Timestep Consumption Time: 2.96507
PPO Batch Consumption Time: 0.36266
Total Iteration Time: 6.17138

Cumulative Model Updates: 4,224
Cumulative Timesteps: 35,262,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.53506
Policy Entropy: 2.10804
Value Function Loss: 0.24821

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.21492
Value Function Update Magnitude: 0.42076

Collected Steps per Second: 18,721.03067
Overall Steps per Second: 9,233.51747

Timestep Collection Time: 2.67240
Timestep Consumption Time: 2.74591
PPO Batch Consumption Time: 0.32764
Total Iteration Time: 5.41830

Cumulative Model Updates: 4,230
Cumulative Timesteps: 35,312,854

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 35312854...
Checkpoint 35312854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,128.34350
Policy Entropy: 2.08935
Value Function Loss: 0.25632

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.21315
Value Function Update Magnitude: 0.38246

Collected Steps per Second: 19,722.61067
Overall Steps per Second: 9,440.23466

Timestep Collection Time: 2.53618
Timestep Consumption Time: 2.76242
PPO Batch Consumption Time: 0.32595
Total Iteration Time: 5.29860

Cumulative Model Updates: 4,236
Cumulative Timesteps: 35,362,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,891.88316
Policy Entropy: 2.07548
Value Function Loss: 0.26415

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.14385
Policy Update Magnitude: 0.19913
Value Function Update Magnitude: 0.36414

Collected Steps per Second: 19,902.05391
Overall Steps per Second: 9,832.24504

Timestep Collection Time: 2.51250
Timestep Consumption Time: 2.57321
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 5.08572

Cumulative Model Updates: 4,242
Cumulative Timesteps: 35,412,878

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 35412878...
Checkpoint 35412878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,208.62874
Policy Entropy: 2.05981
Value Function Loss: 0.26304

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.15434
Policy Update Magnitude: 0.19000
Value Function Update Magnitude: 0.39493

Collected Steps per Second: 19,650.55668
Overall Steps per Second: 9,459.51223

Timestep Collection Time: 2.54670
Timestep Consumption Time: 2.74364
PPO Batch Consumption Time: 0.30914
Total Iteration Time: 5.29034

Cumulative Model Updates: 4,248
Cumulative Timesteps: 35,462,922

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,303.64486
Policy Entropy: 2.03623
Value Function Loss: 0.27404

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.15779
Policy Update Magnitude: 0.18120
Value Function Update Magnitude: 0.33007

Collected Steps per Second: 18,446.24419
Overall Steps per Second: 9,123.95991

Timestep Collection Time: 2.71112
Timestep Consumption Time: 2.77005
PPO Batch Consumption Time: 0.33500
Total Iteration Time: 5.48117

Cumulative Model Updates: 4,254
Cumulative Timesteps: 35,512,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 35512932...
Checkpoint 35512932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,770.07807
Policy Entropy: 2.01211
Value Function Loss: 0.26132

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.16586
Value Function Update Magnitude: 0.29037

Collected Steps per Second: 17,644.70074
Overall Steps per Second: 9,306.65720

Timestep Collection Time: 2.83655
Timestep Consumption Time: 2.54133
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 5.37787

Cumulative Model Updates: 4,260
Cumulative Timesteps: 35,562,982

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,353.61161
Policy Entropy: 1.98472
Value Function Loss: 0.26190

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.15772
Value Function Update Magnitude: 0.37307

Collected Steps per Second: 18,739.66062
Overall Steps per Second: 9,409.28726

Timestep Collection Time: 2.66953
Timestep Consumption Time: 2.64714
PPO Batch Consumption Time: 0.30022
Total Iteration Time: 5.31666

Cumulative Model Updates: 4,266
Cumulative Timesteps: 35,613,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 35613008...
Checkpoint 35613008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,726.45134
Policy Entropy: 1.98042
Value Function Loss: 0.27210

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.14262
Policy Update Magnitude: 0.15688
Value Function Update Magnitude: 0.34666

Collected Steps per Second: 20,031.57775
Overall Steps per Second: 9,840.87800

Timestep Collection Time: 2.49676
Timestep Consumption Time: 2.58551
PPO Batch Consumption Time: 0.29957
Total Iteration Time: 5.08227

Cumulative Model Updates: 4,272
Cumulative Timesteps: 35,663,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,142.38995
Policy Entropy: 1.97076
Value Function Loss: 0.28812

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.15346
Policy Update Magnitude: 0.15514
Value Function Update Magnitude: 0.35074

Collected Steps per Second: 17,720.64517
Overall Steps per Second: 9,151.03494

Timestep Collection Time: 2.82247
Timestep Consumption Time: 2.64314
PPO Batch Consumption Time: 0.31032
Total Iteration Time: 5.46561

Cumulative Model Updates: 4,278
Cumulative Timesteps: 35,713,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 35713038...
Checkpoint 35713038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,090.41736
Policy Entropy: 1.96744
Value Function Loss: 0.30092

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.14471
Value Function Update Magnitude: 0.34039

Collected Steps per Second: 13,293.29673
Overall Steps per Second: 6,820.39889

Timestep Collection Time: 3.76475
Timestep Consumption Time: 3.57294
PPO Batch Consumption Time: 0.46688
Total Iteration Time: 7.33769

Cumulative Model Updates: 4,284
Cumulative Timesteps: 35,763,084

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,372.61093
Policy Entropy: 1.97242
Value Function Loss: 0.32186

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.14040
Policy Update Magnitude: 0.12453
Value Function Update Magnitude: 0.30714

Collected Steps per Second: 13,678.24571
Overall Steps per Second: 6,663.50898

Timestep Collection Time: 3.65690
Timestep Consumption Time: 3.84965
PPO Batch Consumption Time: 0.50517
Total Iteration Time: 7.50656

Cumulative Model Updates: 4,290
Cumulative Timesteps: 35,813,104

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 35813104...
Checkpoint 35813104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,039.05617
Policy Entropy: 1.96142
Value Function Loss: 0.31811

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.12646
Policy Update Magnitude: 0.12735
Value Function Update Magnitude: 0.28376

Collected Steps per Second: 15,227.39867
Overall Steps per Second: 7,356.32617

Timestep Collection Time: 3.28408
Timestep Consumption Time: 3.51388
PPO Batch Consumption Time: 0.46130
Total Iteration Time: 6.79796

Cumulative Model Updates: 4,296
Cumulative Timesteps: 35,863,112

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,300.81741
Policy Entropy: 1.95179
Value Function Loss: 0.29856

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.13457
Value Function Update Magnitude: 0.30234

Collected Steps per Second: 15,365.01780
Overall Steps per Second: 7,097.35275

Timestep Collection Time: 3.25480
Timestep Consumption Time: 3.79149
PPO Batch Consumption Time: 0.50719
Total Iteration Time: 7.04629

Cumulative Model Updates: 4,302
Cumulative Timesteps: 35,913,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 35913122...
Checkpoint 35913122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,425.16448
Policy Entropy: 1.94915
Value Function Loss: 0.30825

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12100
Policy Update Magnitude: 0.13969
Value Function Update Magnitude: 0.34133

Collected Steps per Second: 14,386.72935
Overall Steps per Second: 6,759.29629

Timestep Collection Time: 3.47723
Timestep Consumption Time: 3.92383
PPO Batch Consumption Time: 0.52820
Total Iteration Time: 7.40107

Cumulative Model Updates: 4,308
Cumulative Timesteps: 35,963,148

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,648.44453
Policy Entropy: 1.93195
Value Function Loss: 0.33158

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.15406
Value Function Update Magnitude: 0.31813

Collected Steps per Second: 15,307.43185
Overall Steps per Second: 7,289.10908

Timestep Collection Time: 3.26913
Timestep Consumption Time: 3.59618
PPO Batch Consumption Time: 0.47055
Total Iteration Time: 6.86531

Cumulative Model Updates: 4,314
Cumulative Timesteps: 36,013,190

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 36013190...
Checkpoint 36013190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,587.75158
Policy Entropy: 1.93544
Value Function Loss: 0.33801

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.12415
Policy Update Magnitude: 0.15539
Value Function Update Magnitude: 0.28137

Collected Steps per Second: 13,005.51808
Overall Steps per Second: 6,236.49661

Timestep Collection Time: 3.84591
Timestep Consumption Time: 4.17430
PPO Batch Consumption Time: 0.56331
Total Iteration Time: 8.02021

Cumulative Model Updates: 4,320
Cumulative Timesteps: 36,063,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,768.72074
Policy Entropy: 1.92809
Value Function Loss: 0.34090

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.14963
Value Function Update Magnitude: 0.35781

Collected Steps per Second: 14,356.57929
Overall Steps per Second: 6,821.05918

Timestep Collection Time: 3.48314
Timestep Consumption Time: 3.84798
PPO Batch Consumption Time: 0.51746
Total Iteration Time: 7.33112

Cumulative Model Updates: 4,326
Cumulative Timesteps: 36,113,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 36113214...
Checkpoint 36113214 saved!
