Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,473.58984
Policy Entropy: 0.59958
Value Function Loss: 0.05094

Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.00883
Value Function Update Magnitude: 0.02071

Collected Steps per Second: 15,693.11033
Overall Steps per Second: 12,586.91663

Timestep Collection Time: 3.18713
Timestep Consumption Time: 0.78652
PPO Batch Consumption Time: 0.13451
Total Iteration Time: 3.97365

Cumulative Model Updates: 18,247
Cumulative Timesteps: 304,654,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,847.75916
Policy Entropy: 0.61379
Value Function Loss: 0.04900

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02685
Policy Update Magnitude: 0.01629
Value Function Update Magnitude: 0.04352

Collected Steps per Second: 22,916.99509
Overall Steps per Second: 17,859.99474

Timestep Collection Time: 2.18275
Timestep Consumption Time: 0.61804
PPO Batch Consumption Time: 0.03355
Total Iteration Time: 2.80078

Cumulative Model Updates: 18,249
Cumulative Timesteps: 304,704,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 304704178...
Checkpoint 304704178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,531.49318
Policy Entropy: 0.62265
Value Function Loss: 0.04789

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03694
Policy Update Magnitude: 0.01530
Value Function Update Magnitude: 0.04967

Collected Steps per Second: 20,211.04590
Overall Steps per Second: 14,726.89034

Timestep Collection Time: 2.47419
Timestep Consumption Time: 0.92137
PPO Batch Consumption Time: 0.17952
Total Iteration Time: 3.39556

Cumulative Model Updates: 18,251
Cumulative Timesteps: 304,754,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,261.99133
Policy Entropy: 0.63565
Value Function Loss: 0.04461

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02736
Policy Update Magnitude: 0.02586
Value Function Update Magnitude: 0.07619

Collected Steps per Second: 22,267.70872
Overall Steps per Second: 15,577.13342

Timestep Collection Time: 2.24540
Timestep Consumption Time: 0.96443
PPO Batch Consumption Time: 0.11930
Total Iteration Time: 3.20983

Cumulative Model Updates: 18,254
Cumulative Timesteps: 304,804,184

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 304804184...
Checkpoint 304804184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,796.52047
Policy Entropy: 0.63642
Value Function Loss: 0.04751

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01997
Policy Update Magnitude: 0.02617
Value Function Update Magnitude: 0.07483

Collected Steps per Second: 23,128.52153
Overall Steps per Second: 16,897.31458

Timestep Collection Time: 2.16201
Timestep Consumption Time: 0.79728
PPO Batch Consumption Time: 0.06084
Total Iteration Time: 2.95929

Cumulative Model Updates: 18,257
Cumulative Timesteps: 304,854,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,655.57433
Policy Entropy: 0.63411
Value Function Loss: 0.04896

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.03097
Policy Update Magnitude: 0.02570
Value Function Update Magnitude: 0.06532

Collected Steps per Second: 23,136.63754
Overall Steps per Second: 16,968.02731

Timestep Collection Time: 2.16246
Timestep Consumption Time: 0.78615
PPO Batch Consumption Time: 0.06527
Total Iteration Time: 2.94860

Cumulative Model Updates: 18,260
Cumulative Timesteps: 304,904,220

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 304904220...
Checkpoint 304904220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,965.53175
Policy Entropy: 0.62759
Value Function Loss: 0.05315

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.02056
Policy Update Magnitude: 0.02546
Value Function Update Magnitude: 0.06075

Collected Steps per Second: 23,445.31490
Overall Steps per Second: 17,080.40019

Timestep Collection Time: 2.13365
Timestep Consumption Time: 0.79509
PPO Batch Consumption Time: 0.06440
Total Iteration Time: 2.92874

Cumulative Model Updates: 18,263
Cumulative Timesteps: 304,954,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,366.63854
Policy Entropy: 0.62526
Value Function Loss: 0.05509

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02094
Policy Update Magnitude: 0.02381
Value Function Update Magnitude: 0.06277

Collected Steps per Second: 19,794.19827
Overall Steps per Second: 14,283.80574

Timestep Collection Time: 2.52731
Timestep Consumption Time: 0.97498
PPO Batch Consumption Time: 0.11215
Total Iteration Time: 3.50229

Cumulative Model Updates: 18,266
Cumulative Timesteps: 305,004,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 305004270...
Checkpoint 305004270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,873.46157
Policy Entropy: 0.62920
Value Function Loss: 0.05070

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.03060
Policy Update Magnitude: 0.02457
Value Function Update Magnitude: 0.06037

Collected Steps per Second: 23,004.37316
Overall Steps per Second: 15,747.58097

Timestep Collection Time: 2.17506
Timestep Consumption Time: 1.00231
PPO Batch Consumption Time: 0.11865
Total Iteration Time: 3.17738

Cumulative Model Updates: 18,269
Cumulative Timesteps: 305,054,306

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,056.55285
Policy Entropy: 0.63211
Value Function Loss: 0.05034

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02963
Policy Update Magnitude: 0.02548
Value Function Update Magnitude: 0.05489

Collected Steps per Second: 23,508.61416
Overall Steps per Second: 16,892.49857

Timestep Collection Time: 2.12875
Timestep Consumption Time: 0.83375
PPO Batch Consumption Time: 0.06444
Total Iteration Time: 2.96250

Cumulative Model Updates: 18,272
Cumulative Timesteps: 305,104,350

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 305104350...
Checkpoint 305104350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,562.47756
Policy Entropy: 0.63715
Value Function Loss: 0.04526

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.03161
Policy Update Magnitude: 0.02679
Value Function Update Magnitude: 0.05034

Collected Steps per Second: 22,995.05776
Overall Steps per Second: 16,649.25364

Timestep Collection Time: 2.17464
Timestep Consumption Time: 0.82886
PPO Batch Consumption Time: 0.06485
Total Iteration Time: 3.00350

Cumulative Model Updates: 18,275
Cumulative Timesteps: 305,154,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,018.28177
Policy Entropy: 0.63302
Value Function Loss: 0.05047

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03323
Policy Update Magnitude: 0.02930
Value Function Update Magnitude: 0.04836

Collected Steps per Second: 20,801.15495
Overall Steps per Second: 14,702.15489

Timestep Collection Time: 2.40592
Timestep Consumption Time: 0.99807
PPO Batch Consumption Time: 0.11930
Total Iteration Time: 3.40399

Cumulative Model Updates: 18,278
Cumulative Timesteps: 305,204,402

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 305204402...
Checkpoint 305204402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,796.85484
Policy Entropy: 0.63154
Value Function Loss: 0.05297

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03913
Policy Update Magnitude: 0.02807
Value Function Update Magnitude: 0.04568

Collected Steps per Second: 23,076.76974
Overall Steps per Second: 15,776.69612

Timestep Collection Time: 2.16711
Timestep Consumption Time: 1.00275
PPO Batch Consumption Time: 0.12441
Total Iteration Time: 3.16987

Cumulative Model Updates: 18,281
Cumulative Timesteps: 305,254,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,337.86128
Policy Entropy: 0.62944
Value Function Loss: 0.05573

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03605
Policy Update Magnitude: 0.02655
Value Function Update Magnitude: 0.04129

Collected Steps per Second: 23,414.63890
Overall Steps per Second: 16,929.31399

Timestep Collection Time: 2.13576
Timestep Consumption Time: 0.81817
PPO Batch Consumption Time: 0.06419
Total Iteration Time: 2.95393

Cumulative Model Updates: 18,284
Cumulative Timesteps: 305,304,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 305304420...
Checkpoint 305304420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,460.65378
Policy Entropy: 0.64078
Value Function Loss: 0.04902

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.03092
Policy Update Magnitude: 0.02634
Value Function Update Magnitude: 0.03670

Collected Steps per Second: 23,445.90905
Overall Steps per Second: 16,855.34459

Timestep Collection Time: 2.13265
Timestep Consumption Time: 0.83388
PPO Batch Consumption Time: 0.06897
Total Iteration Time: 2.96654

Cumulative Model Updates: 18,287
Cumulative Timesteps: 305,354,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,429.53618
Policy Entropy: 0.64227
Value Function Loss: 0.04867

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.04146
Policy Update Magnitude: 0.02693
Value Function Update Magnitude: 0.04002

Collected Steps per Second: 23,578.92682
Overall Steps per Second: 16,822.66820

Timestep Collection Time: 2.12266
Timestep Consumption Time: 0.85249
PPO Batch Consumption Time: 0.06715
Total Iteration Time: 2.97515

Cumulative Model Updates: 18,290
Cumulative Timesteps: 305,404,472

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 305404472...
Checkpoint 305404472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,326.14531
Policy Entropy: 0.64501
Value Function Loss: 0.05043

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04223
Policy Update Magnitude: 0.02397
Value Function Update Magnitude: 0.04093

Collected Steps per Second: 23,708.87654
Overall Steps per Second: 17,127.95723

Timestep Collection Time: 2.10925
Timestep Consumption Time: 0.81042
PPO Batch Consumption Time: 0.06314
Total Iteration Time: 2.91967

Cumulative Model Updates: 18,293
Cumulative Timesteps: 305,454,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,406.91961
Policy Entropy: 0.64053
Value Function Loss: 0.04849

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03681
Policy Update Magnitude: 0.02398
Value Function Update Magnitude: 0.04049

Collected Steps per Second: 20,572.64645
Overall Steps per Second: 14,816.28508

Timestep Collection Time: 2.43177
Timestep Consumption Time: 0.94478
PPO Batch Consumption Time: 0.08883
Total Iteration Time: 3.37655

Cumulative Model Updates: 18,296
Cumulative Timesteps: 305,504,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 305504508...
Checkpoint 305504508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,347.54761
Policy Entropy: 0.63852
Value Function Loss: 0.05182

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02276
Policy Update Magnitude: 0.02385
Value Function Update Magnitude: 0.03690

Collected Steps per Second: 23,808.10683
Overall Steps per Second: 17,034.43053

Timestep Collection Time: 2.10038
Timestep Consumption Time: 0.83521
PPO Batch Consumption Time: 0.06037
Total Iteration Time: 2.93558

Cumulative Model Updates: 18,299
Cumulative Timesteps: 305,554,514

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,794.91509
Policy Entropy: 0.64524
Value Function Loss: 0.04515

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02608
Policy Update Magnitude: 0.02454
Value Function Update Magnitude: 0.03512

Collected Steps per Second: 20,975.12881
Overall Steps per Second: 14,756.73613

Timestep Collection Time: 2.38492
Timestep Consumption Time: 1.00499
PPO Batch Consumption Time: 0.12305
Total Iteration Time: 3.38991

Cumulative Model Updates: 18,302
Cumulative Timesteps: 305,604,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 305604538...
Checkpoint 305604538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,538.66240
Policy Entropy: 0.64528
Value Function Loss: 0.04770

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03498
Policy Update Magnitude: 0.02539
Value Function Update Magnitude: 0.02977

Collected Steps per Second: 23,150.98087
Overall Steps per Second: 16,890.13568

Timestep Collection Time: 2.16060
Timestep Consumption Time: 0.80089
PPO Batch Consumption Time: 0.06346
Total Iteration Time: 2.96149

Cumulative Model Updates: 18,305
Cumulative Timesteps: 305,654,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,572.37274
Policy Entropy: 0.64848
Value Function Loss: 0.04280

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.02649
Value Function Update Magnitude: 0.03214

Collected Steps per Second: 23,623.33692
Overall Steps per Second: 17,096.23309

Timestep Collection Time: 2.11858
Timestep Consumption Time: 0.80885
PPO Batch Consumption Time: 0.06213
Total Iteration Time: 2.92743

Cumulative Model Updates: 18,308
Cumulative Timesteps: 305,704,606

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 305704606...
Checkpoint 305704606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,917.35892
Policy Entropy: 0.63783
Value Function Loss: 0.05375

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.04501
Policy Update Magnitude: 0.03421
Value Function Update Magnitude: 0.03263

Collected Steps per Second: 20,818.23698
Overall Steps per Second: 15,313.50234

Timestep Collection Time: 2.40193
Timestep Consumption Time: 0.86342
PPO Batch Consumption Time: 0.02882
Total Iteration Time: 3.26535

Cumulative Model Updates: 18,311
Cumulative Timesteps: 305,754,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,780.34111
Policy Entropy: 0.64120
Value Function Loss: 0.05277

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03903
Policy Update Magnitude: 0.03084
Value Function Update Magnitude: 0.03282

Collected Steps per Second: 23,358.18834
Overall Steps per Second: 16,934.83370

Timestep Collection Time: 2.14143
Timestep Consumption Time: 0.81224
PPO Batch Consumption Time: 0.06609
Total Iteration Time: 2.95368

Cumulative Model Updates: 18,314
Cumulative Timesteps: 305,804,630

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 305804630...
Checkpoint 305804630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,300.24373
Policy Entropy: 0.64052
Value Function Loss: 0.05399

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03608
Policy Update Magnitude: 0.03018
Value Function Update Magnitude: 0.03236

Collected Steps per Second: 23,759.27029
Overall Steps per Second: 16,484.42639

Timestep Collection Time: 2.10570
Timestep Consumption Time: 0.92928
PPO Batch Consumption Time: 0.10194
Total Iteration Time: 3.03499

Cumulative Model Updates: 18,317
Cumulative Timesteps: 305,854,660

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,061.70232
Policy Entropy: 0.64820
Value Function Loss: 0.05035

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03828
Policy Update Magnitude: 0.02744
Value Function Update Magnitude: 0.03112

Collected Steps per Second: 23,095.94591
Overall Steps per Second: 16,704.80779

Timestep Collection Time: 2.16497
Timestep Consumption Time: 0.82830
PPO Batch Consumption Time: 0.05909
Total Iteration Time: 2.99327

Cumulative Model Updates: 18,320
Cumulative Timesteps: 305,904,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 305904662...
Checkpoint 305904662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,197.87948
Policy Entropy: 0.64101
Value Function Loss: 0.05350

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03351
Policy Update Magnitude: 0.02793
Value Function Update Magnitude: 0.03555

Collected Steps per Second: 19,937.14137
Overall Steps per Second: 14,616.88515

Timestep Collection Time: 2.50919
Timestep Consumption Time: 0.91329
PPO Batch Consumption Time: 0.09606
Total Iteration Time: 3.42248

Cumulative Model Updates: 18,323
Cumulative Timesteps: 305,954,688

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,053.43708
Policy Entropy: 0.64542
Value Function Loss: 0.05282

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03961
Policy Update Magnitude: 0.02721
Value Function Update Magnitude: 0.03603

Collected Steps per Second: 23,352.55251
Overall Steps per Second: 16,982.97627

Timestep Collection Time: 2.14135
Timestep Consumption Time: 0.80313
PPO Batch Consumption Time: 0.06149
Total Iteration Time: 2.94448

Cumulative Model Updates: 18,326
Cumulative Timesteps: 306,004,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 306004694...
Checkpoint 306004694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,548.03131
Policy Entropy: 0.64816
Value Function Loss: 0.04666

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03465
Policy Update Magnitude: 0.02509
Value Function Update Magnitude: 0.03337

Collected Steps per Second: 20,778.28567
Overall Steps per Second: 14,763.90507

Timestep Collection Time: 2.40655
Timestep Consumption Time: 0.98036
PPO Batch Consumption Time: 0.11379
Total Iteration Time: 3.38691

Cumulative Model Updates: 18,329
Cumulative Timesteps: 306,054,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,945.87743
Policy Entropy: 0.65737
Value Function Loss: 0.04471

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02750
Policy Update Magnitude: 0.02322
Value Function Update Magnitude: 0.03156

Collected Steps per Second: 23,669.81927
Overall Steps per Second: 16,670.98669

Timestep Collection Time: 2.11375
Timestep Consumption Time: 0.88740
PPO Batch Consumption Time: 0.08751
Total Iteration Time: 3.00114

Cumulative Model Updates: 18,332
Cumulative Timesteps: 306,104,730

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 306104730...
Checkpoint 306104730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,358.14657
Policy Entropy: 0.65300
Value Function Loss: 0.04148

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.02826
Value Function Update Magnitude: 0.02674

Collected Steps per Second: 23,634.93239
Overall Steps per Second: 16,535.35050

Timestep Collection Time: 2.11627
Timestep Consumption Time: 0.90864
PPO Batch Consumption Time: 0.08405
Total Iteration Time: 3.02491

Cumulative Model Updates: 18,335
Cumulative Timesteps: 306,154,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,434.15376
Policy Entropy: 0.65471
Value Function Loss: 0.04636

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03366
Policy Update Magnitude: 0.02746
Value Function Update Magnitude: 0.02496

Collected Steps per Second: 19,937.54084
Overall Steps per Second: 14,288.55768

Timestep Collection Time: 2.50894
Timestep Consumption Time: 0.99191
PPO Batch Consumption Time: 0.09854
Total Iteration Time: 3.50084

Cumulative Model Updates: 18,338
Cumulative Timesteps: 306,204,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 306204770...
Checkpoint 306204770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,494.11071
Policy Entropy: 0.64941
Value Function Loss: 0.04482

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02462
Policy Update Magnitude: 0.02802
Value Function Update Magnitude: 0.02566

Collected Steps per Second: 20,614.90201
Overall Steps per Second: 15,714.74566

Timestep Collection Time: 2.42592
Timestep Consumption Time: 0.75645
PPO Batch Consumption Time: 0.03380
Total Iteration Time: 3.18236

Cumulative Model Updates: 18,341
Cumulative Timesteps: 306,254,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,086.66950
Policy Entropy: 0.64696
Value Function Loss: 0.04651

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03235
Policy Update Magnitude: 0.02704
Value Function Update Magnitude: 0.03083

Collected Steps per Second: 19,449.09830
Overall Steps per Second: 14,306.69599

Timestep Collection Time: 2.57122
Timestep Consumption Time: 0.92420
PPO Batch Consumption Time: 0.08486
Total Iteration Time: 3.49543

Cumulative Model Updates: 18,344
Cumulative Timesteps: 306,304,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 306304788...
Checkpoint 306304788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,867.20815
Policy Entropy: 0.64135
Value Function Loss: 0.04838

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.02534
Value Function Update Magnitude: 0.02916

Collected Steps per Second: 21,093.34484
Overall Steps per Second: 15,017.52816

Timestep Collection Time: 2.37098
Timestep Consumption Time: 0.95926
PPO Batch Consumption Time: 0.09670
Total Iteration Time: 3.33024

Cumulative Model Updates: 18,347
Cumulative Timesteps: 306,354,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,629.49714
Policy Entropy: 0.63982
Value Function Loss: 0.05102

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01725
Policy Update Magnitude: 0.02599
Value Function Update Magnitude: 0.02929

Collected Steps per Second: 21,689.15282
Overall Steps per Second: 16,255.13945

Timestep Collection Time: 2.30595
Timestep Consumption Time: 0.77087
PPO Batch Consumption Time: 0.06557
Total Iteration Time: 3.07681

Cumulative Model Updates: 18,350
Cumulative Timesteps: 306,404,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 306404814...
Checkpoint 306404814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,388.52311
Policy Entropy: 0.62959
Value Function Loss: 0.05759

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01823
Policy Update Magnitude: 0.02670
Value Function Update Magnitude: 0.03007

Collected Steps per Second: 19,954.52321
Overall Steps per Second: 15,830.78325

Timestep Collection Time: 2.50730
Timestep Consumption Time: 0.65312
PPO Batch Consumption Time: 0.03038
Total Iteration Time: 3.16042

Cumulative Model Updates: 18,353
Cumulative Timesteps: 306,454,846

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,686.94183
Policy Entropy: 0.63809
Value Function Loss: 0.05415

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02857
Policy Update Magnitude: 0.02732
Value Function Update Magnitude: 0.03099

Collected Steps per Second: 22,276.23403
Overall Steps per Second: 15,920.37584

Timestep Collection Time: 2.24535
Timestep Consumption Time: 0.89641
PPO Batch Consumption Time: 0.10489
Total Iteration Time: 3.14176

Cumulative Model Updates: 18,356
Cumulative Timesteps: 306,504,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 306504864...
Checkpoint 306504864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,859.22503
Policy Entropy: 0.63872
Value Function Loss: 0.05070

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.03065
Policy Update Magnitude: 0.03035
Value Function Update Magnitude: 0.03147

Collected Steps per Second: 21,736.99960
Overall Steps per Second: 16,489.46996

Timestep Collection Time: 2.30161
Timestep Consumption Time: 0.73245
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 3.03406

Cumulative Model Updates: 18,359
Cumulative Timesteps: 306,554,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,795.89772
Policy Entropy: 0.65042
Value Function Loss: 0.04818

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.03134
Value Function Update Magnitude: 0.03305

Collected Steps per Second: 22,541.92644
Overall Steps per Second: 17,112.06838

Timestep Collection Time: 2.21907
Timestep Consumption Time: 0.70414
PPO Batch Consumption Time: 0.03081
Total Iteration Time: 2.92320

Cumulative Model Updates: 18,362
Cumulative Timesteps: 306,604,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 306604916...
Checkpoint 306604916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,514.00197
Policy Entropy: 0.65129
Value Function Loss: 0.04408

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02067
Policy Update Magnitude: 0.02922
Value Function Update Magnitude: 0.03155

Collected Steps per Second: 21,258.52238
Overall Steps per Second: 15,598.59986

Timestep Collection Time: 2.35200
Timestep Consumption Time: 0.85342
PPO Batch Consumption Time: 0.07860
Total Iteration Time: 3.20542

Cumulative Model Updates: 18,365
Cumulative Timesteps: 306,654,916

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,413.85315
Policy Entropy: 0.65207
Value Function Loss: 0.04320

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02046
Policy Update Magnitude: 0.02858
Value Function Update Magnitude: 0.02938

Collected Steps per Second: 22,356.00851
Overall Steps per Second: 16,574.99165

Timestep Collection Time: 2.23770
Timestep Consumption Time: 0.78046
PPO Batch Consumption Time: 0.05959
Total Iteration Time: 3.01816

Cumulative Model Updates: 18,368
Cumulative Timesteps: 306,704,942

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 306704942...
Checkpoint 306704942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,359.13591
Policy Entropy: 0.65509
Value Function Loss: 0.04218

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01403
Policy Update Magnitude: 0.02763
Value Function Update Magnitude: 0.02767

Collected Steps per Second: 21,297.38146
Overall Steps per Second: 16,305.45726

Timestep Collection Time: 2.34818
Timestep Consumption Time: 0.71890
PPO Batch Consumption Time: 0.03065
Total Iteration Time: 3.06707

Cumulative Model Updates: 18,371
Cumulative Timesteps: 306,754,952

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,208.57198
Policy Entropy: 0.65242
Value Function Loss: 0.04433

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01303
Policy Update Magnitude: 0.03014
Value Function Update Magnitude: 0.02575

Collected Steps per Second: 22,968.00829
Overall Steps per Second: 16,237.98309

Timestep Collection Time: 2.17790
Timestep Consumption Time: 0.90266
PPO Batch Consumption Time: 0.07966
Total Iteration Time: 3.08056

Cumulative Model Updates: 18,374
Cumulative Timesteps: 306,804,974

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 306804974...
Checkpoint 306804974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,386.45117
Policy Entropy: 0.65505
Value Function Loss: 0.04553

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02956
Policy Update Magnitude: 0.02515
Value Function Update Magnitude: 0.02609

Collected Steps per Second: 22,684.68528
Overall Steps per Second: 16,515.18118

Timestep Collection Time: 2.20439
Timestep Consumption Time: 0.82349
PPO Batch Consumption Time: 0.06426
Total Iteration Time: 3.02788

Cumulative Model Updates: 18,377
Cumulative Timesteps: 306,854,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,549.44640
Policy Entropy: 0.64940
Value Function Loss: 0.05139

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02395
Policy Update Magnitude: 0.02620
Value Function Update Magnitude: 0.02587

Collected Steps per Second: 21,133.48398
Overall Steps per Second: 16,210.08740

Timestep Collection Time: 2.36686
Timestep Consumption Time: 0.71887
PPO Batch Consumption Time: 0.02993
Total Iteration Time: 3.08573

Cumulative Model Updates: 18,380
Cumulative Timesteps: 306,905,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 306905000...
Checkpoint 306905000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,815.01187
Policy Entropy: 0.65418
Value Function Loss: 0.05018

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02473
Policy Update Magnitude: 0.02800
Value Function Update Magnitude: 0.03102

Collected Steps per Second: 22,356.96804
Overall Steps per Second: 16,041.87967

Timestep Collection Time: 2.23689
Timestep Consumption Time: 0.88058
PPO Batch Consumption Time: 0.08503
Total Iteration Time: 3.11747

Cumulative Model Updates: 18,383
Cumulative Timesteps: 306,955,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,419.66184
Policy Entropy: 0.65184
Value Function Loss: 0.04953

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03256
Policy Update Magnitude: 0.02855
Value Function Update Magnitude: 0.03292

Collected Steps per Second: 23,374.03067
Overall Steps per Second: 17,447.89688

Timestep Collection Time: 2.13947
Timestep Consumption Time: 0.72667
PPO Batch Consumption Time: 0.03066
Total Iteration Time: 2.86613

Cumulative Model Updates: 18,386
Cumulative Timesteps: 307,005,018

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 307005018...
Checkpoint 307005018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,520.79168
Policy Entropy: 0.65376
Value Function Loss: 0.04119

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03153
Policy Update Magnitude: 0.02507
Value Function Update Magnitude: 0.03121

Collected Steps per Second: 21,515.83463
Overall Steps per Second: 15,503.45558

Timestep Collection Time: 2.32526
Timestep Consumption Time: 0.90176
PPO Batch Consumption Time: 0.08125
Total Iteration Time: 3.22702

Cumulative Model Updates: 18,389
Cumulative Timesteps: 307,055,048

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,439.75979
Policy Entropy: 0.64732
Value Function Loss: 0.04126

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.03040
Policy Update Magnitude: 0.02389
Value Function Update Magnitude: 0.03258

Collected Steps per Second: 22,830.40204
Overall Steps per Second: 17,141.35943

Timestep Collection Time: 2.19085
Timestep Consumption Time: 0.72712
PPO Batch Consumption Time: 0.02986
Total Iteration Time: 2.91797

Cumulative Model Updates: 18,392
Cumulative Timesteps: 307,105,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 307105066...
Checkpoint 307105066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,772.61499
Policy Entropy: 0.65967
Value Function Loss: 0.04128

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04350
Policy Update Magnitude: 0.02092
Value Function Update Magnitude: 0.03037

Collected Steps per Second: 22,871.19331
Overall Steps per Second: 16,199.79903

Timestep Collection Time: 2.18624
Timestep Consumption Time: 0.90034
PPO Batch Consumption Time: 0.07732
Total Iteration Time: 3.08658

Cumulative Model Updates: 18,395
Cumulative Timesteps: 307,155,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,583.39171
Policy Entropy: 0.65751
Value Function Loss: 0.04339

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03239
Policy Update Magnitude: 0.02190
Value Function Update Magnitude: 0.02874

Collected Steps per Second: 22,030.98604
Overall Steps per Second: 15,600.66783

Timestep Collection Time: 2.26971
Timestep Consumption Time: 0.93554
PPO Batch Consumption Time: 0.08533
Total Iteration Time: 3.20525

Cumulative Model Updates: 18,398
Cumulative Timesteps: 307,205,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 307205072...
Checkpoint 307205072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,033.56410
Policy Entropy: 0.66066
Value Function Loss: 0.04701

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03266
Policy Update Magnitude: 0.02477
Value Function Update Magnitude: 0.02905

Collected Steps per Second: 19,891.47890
Overall Steps per Second: 14,872.29495

Timestep Collection Time: 2.51464
Timestep Consumption Time: 0.84866
PPO Batch Consumption Time: 0.05044
Total Iteration Time: 3.36330

Cumulative Model Updates: 18,401
Cumulative Timesteps: 307,255,092

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,783.78425
Policy Entropy: 0.66370
Value Function Loss: 0.04378

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03725
Policy Update Magnitude: 0.02628
Value Function Update Magnitude: 0.03116

Collected Steps per Second: 18,491.77350
Overall Steps per Second: 13,344.05191

Timestep Collection Time: 2.70455
Timestep Consumption Time: 1.04333
PPO Batch Consumption Time: 0.11295
Total Iteration Time: 3.74789

Cumulative Model Updates: 18,404
Cumulative Timesteps: 307,305,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 307305104...
Checkpoint 307305104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,757.89089
Policy Entropy: 0.65982
Value Function Loss: 0.04488

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03527
Policy Update Magnitude: 0.02719
Value Function Update Magnitude: 0.03294

Collected Steps per Second: 22,406.87822
Overall Steps per Second: 15,691.05430

Timestep Collection Time: 2.23244
Timestep Consumption Time: 0.95549
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 3.18793

Cumulative Model Updates: 18,407
Cumulative Timesteps: 307,355,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,170.24446
Policy Entropy: 0.65809
Value Function Loss: 0.04672

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.02757
Value Function Update Magnitude: 0.03283

Collected Steps per Second: 20,120.87322
Overall Steps per Second: 14,923.08785

Timestep Collection Time: 2.48687
Timestep Consumption Time: 0.86619
PPO Batch Consumption Time: 0.07327
Total Iteration Time: 3.35306

Cumulative Model Updates: 18,410
Cumulative Timesteps: 307,405,164

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 307405164...
Checkpoint 307405164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,021.40378
Policy Entropy: 0.65653
Value Function Loss: 0.04998

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02933
Policy Update Magnitude: 0.02955
Value Function Update Magnitude: 0.04198

Collected Steps per Second: 20,218.37037
Overall Steps per Second: 14,810.19828

Timestep Collection Time: 2.47339
Timestep Consumption Time: 0.90320
PPO Batch Consumption Time: 0.07933
Total Iteration Time: 3.37659

Cumulative Model Updates: 18,413
Cumulative Timesteps: 307,455,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,231.95650
Policy Entropy: 0.64898
Value Function Loss: 0.05578

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02211
Policy Update Magnitude: 0.02748
Value Function Update Magnitude: 0.04140

Collected Steps per Second: 20,379.78562
Overall Steps per Second: 14,999.09122

Timestep Collection Time: 2.45508
Timestep Consumption Time: 0.88072
PPO Batch Consumption Time: 0.07573
Total Iteration Time: 3.33580

Cumulative Model Updates: 18,416
Cumulative Timesteps: 307,505,206

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 307505206...
Checkpoint 307505206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,916.03489
Policy Entropy: 0.65332
Value Function Loss: 0.05445

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01562
Policy Update Magnitude: 0.02826
Value Function Update Magnitude: 0.03609

Collected Steps per Second: 20,226.82465
Overall Steps per Second: 14,995.66959

Timestep Collection Time: 2.47276
Timestep Consumption Time: 0.86261
PPO Batch Consumption Time: 0.06839
Total Iteration Time: 3.33536

Cumulative Model Updates: 18,419
Cumulative Timesteps: 307,555,222

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,577.67818
Policy Entropy: 0.65768
Value Function Loss: 0.05337

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01187
Policy Update Magnitude: 0.03154
Value Function Update Magnitude: 0.03885

Collected Steps per Second: 20,017.05972
Overall Steps per Second: 15,289.99733

Timestep Collection Time: 2.49887
Timestep Consumption Time: 0.77255
PPO Batch Consumption Time: 0.07490
Total Iteration Time: 3.27142

Cumulative Model Updates: 18,422
Cumulative Timesteps: 307,605,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 307605242...
Checkpoint 307605242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,804.74290
Policy Entropy: 0.66467
Value Function Loss: 0.04674

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.02704
Value Function Update Magnitude: 0.03749

Collected Steps per Second: 20,246.53621
Overall Steps per Second: 15,526.26363

Timestep Collection Time: 2.47025
Timestep Consumption Time: 0.75100
PPO Batch Consumption Time: 0.06629
Total Iteration Time: 3.22125

Cumulative Model Updates: 18,425
Cumulative Timesteps: 307,655,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,215.08746
Policy Entropy: 0.66329
Value Function Loss: 0.04426

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01679
Policy Update Magnitude: 0.02568
Value Function Update Magnitude: 0.03468

Collected Steps per Second: 19,913.83811
Overall Steps per Second: 15,200.45636

Timestep Collection Time: 2.51132
Timestep Consumption Time: 0.77871
PPO Batch Consumption Time: 0.07126
Total Iteration Time: 3.29003

Cumulative Model Updates: 18,428
Cumulative Timesteps: 307,705,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 307705266...
Checkpoint 307705266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,528.79409
Policy Entropy: 0.66460
Value Function Loss: 0.04267

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01655
Policy Update Magnitude: 0.02587
Value Function Update Magnitude: 0.03154

Collected Steps per Second: 19,929.37715
Overall Steps per Second: 15,059.80438

Timestep Collection Time: 2.51026
Timestep Consumption Time: 0.81169
PPO Batch Consumption Time: 0.06602
Total Iteration Time: 3.32196

Cumulative Model Updates: 18,431
Cumulative Timesteps: 307,755,294

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,627.23391
Policy Entropy: 0.66203
Value Function Loss: 0.04166

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02055
Policy Update Magnitude: 0.02475
Value Function Update Magnitude: 0.02936

Collected Steps per Second: 20,674.90271
Overall Steps per Second: 15,327.19173

Timestep Collection Time: 2.41984
Timestep Consumption Time: 0.84429
PPO Batch Consumption Time: 0.07353
Total Iteration Time: 3.26413

Cumulative Model Updates: 18,434
Cumulative Timesteps: 307,805,324

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 307805324...
Checkpoint 307805324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,672.51877
Policy Entropy: 0.67134
Value Function Loss: 0.03955

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04397
Policy Update Magnitude: 0.02386
Value Function Update Magnitude: 0.02579

Collected Steps per Second: 18,622.82479
Overall Steps per Second: 14,617.27810

Timestep Collection Time: 2.68541
Timestep Consumption Time: 0.73588
PPO Batch Consumption Time: 0.03103
Total Iteration Time: 3.42129

Cumulative Model Updates: 18,437
Cumulative Timesteps: 307,855,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,204.57259
Policy Entropy: 0.66965
Value Function Loss: 0.04346

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04401
Policy Update Magnitude: 0.02361
Value Function Update Magnitude: 0.02629

Collected Steps per Second: 21,107.92032
Overall Steps per Second: 15,297.51933

Timestep Collection Time: 2.37067
Timestep Consumption Time: 0.90044
PPO Batch Consumption Time: 0.08511
Total Iteration Time: 3.27112

Cumulative Model Updates: 18,440
Cumulative Timesteps: 307,905,374

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 307905374...
Checkpoint 307905374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,195.58257
Policy Entropy: 0.67225
Value Function Loss: 0.04462

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04971
Policy Update Magnitude: 0.02455
Value Function Update Magnitude: 0.02775

Collected Steps per Second: 22,256.85923
Overall Steps per Second: 16,202.62430

Timestep Collection Time: 2.24686
Timestep Consumption Time: 0.83956
PPO Batch Consumption Time: 0.06629
Total Iteration Time: 3.08641

Cumulative Model Updates: 18,443
Cumulative Timesteps: 307,955,382

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,477.97929
Policy Entropy: 0.66902
Value Function Loss: 0.04985

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04933
Policy Update Magnitude: 0.02451
Value Function Update Magnitude: 0.03150

Collected Steps per Second: 22,246.45826
Overall Steps per Second: 15,309.44225

Timestep Collection Time: 2.24872
Timestep Consumption Time: 1.01894
PPO Batch Consumption Time: 0.11698
Total Iteration Time: 3.26766

Cumulative Model Updates: 18,446
Cumulative Timesteps: 308,005,408

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 308005408...
Checkpoint 308005408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,343.80421
Policy Entropy: 0.66961
Value Function Loss: 0.04822

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.02568
Value Function Update Magnitude: 0.02860

Collected Steps per Second: 22,315.45807
Overall Steps per Second: 16,654.09165

Timestep Collection Time: 2.24167
Timestep Consumption Time: 0.76203
PPO Batch Consumption Time: 0.03110
Total Iteration Time: 3.00371

Cumulative Model Updates: 18,449
Cumulative Timesteps: 308,055,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,740.60878
Policy Entropy: 0.67489
Value Function Loss: 0.04654

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.04005
Policy Update Magnitude: 0.02729
Value Function Update Magnitude: 0.03022

Collected Steps per Second: 22,687.88964
Overall Steps per Second: 17,011.61458

Timestep Collection Time: 2.20382
Timestep Consumption Time: 0.73535
PPO Batch Consumption Time: 0.02986
Total Iteration Time: 2.93917

Cumulative Model Updates: 18,452
Cumulative Timesteps: 308,105,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 308105432...
Checkpoint 308105432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,358.02117
Policy Entropy: 0.67361
Value Function Loss: 0.04512

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03407
Policy Update Magnitude: 0.02732
Value Function Update Magnitude: 0.03155

Collected Steps per Second: 20,971.85856
Overall Steps per Second: 14,623.29174

Timestep Collection Time: 2.38443
Timestep Consumption Time: 1.03518
PPO Batch Consumption Time: 0.11945
Total Iteration Time: 3.41961

Cumulative Model Updates: 18,455
Cumulative Timesteps: 308,155,438

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,456.62780
Policy Entropy: 0.67604
Value Function Loss: 0.04390

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05475
Policy Update Magnitude: 0.02811
Value Function Update Magnitude: 0.02641

Collected Steps per Second: 22,488.11060
Overall Steps per Second: 16,991.77450

Timestep Collection Time: 2.22438
Timestep Consumption Time: 0.71952
PPO Batch Consumption Time: 0.03030
Total Iteration Time: 2.94389

Cumulative Model Updates: 18,458
Cumulative Timesteps: 308,205,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 308205460...
Checkpoint 308205460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,230.13438
Policy Entropy: 0.68225
Value Function Loss: 0.04572

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05368
Policy Update Magnitude: 0.02452
Value Function Update Magnitude: 0.02511

Collected Steps per Second: 22,658.96348
Overall Steps per Second: 16,971.03537

Timestep Collection Time: 2.20681
Timestep Consumption Time: 0.73962
PPO Batch Consumption Time: 0.02994
Total Iteration Time: 2.94643

Cumulative Model Updates: 18,461
Cumulative Timesteps: 308,255,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,099.00512
Policy Entropy: 0.67738
Value Function Loss: 0.04210

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03689
Policy Update Magnitude: 0.02456
Value Function Update Magnitude: 0.02368

Collected Steps per Second: 21,686.16457
Overall Steps per Second: 15,244.89704

Timestep Collection Time: 2.30571
Timestep Consumption Time: 0.97421
PPO Batch Consumption Time: 0.10031
Total Iteration Time: 3.27992

Cumulative Model Updates: 18,464
Cumulative Timesteps: 308,305,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 308305466...
Checkpoint 308305466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,960.33048
Policy Entropy: 0.67955
Value Function Loss: 0.03958

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02880
Policy Update Magnitude: 0.02494
Value Function Update Magnitude: 0.02085

Collected Steps per Second: 21,980.72632
Overall Steps per Second: 15,698.58861

Timestep Collection Time: 2.27554
Timestep Consumption Time: 0.91061
PPO Batch Consumption Time: 0.09027
Total Iteration Time: 3.18615

Cumulative Model Updates: 18,467
Cumulative Timesteps: 308,355,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,899.21351
Policy Entropy: 0.67995
Value Function Loss: 0.04217

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02462
Policy Update Magnitude: 0.02312
Value Function Update Magnitude: 0.02316

Collected Steps per Second: 22,341.32295
Overall Steps per Second: 16,258.04513

Timestep Collection Time: 2.23917
Timestep Consumption Time: 0.83783
PPO Batch Consumption Time: 0.06385
Total Iteration Time: 3.07700

Cumulative Model Updates: 18,470
Cumulative Timesteps: 308,405,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 308405510...
Checkpoint 308405510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,206.13048
Policy Entropy: 0.67988
Value Function Loss: 0.04687

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.02398
Value Function Update Magnitude: 0.02981

Collected Steps per Second: 22,583.99107
Overall Steps per Second: 17,015.94448

Timestep Collection Time: 2.21493
Timestep Consumption Time: 0.72478
PPO Batch Consumption Time: 0.03048
Total Iteration Time: 2.93971

Cumulative Model Updates: 18,473
Cumulative Timesteps: 308,455,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,551.00016
Policy Entropy: 0.68774
Value Function Loss: 0.05144

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01875
Policy Update Magnitude: 0.02552
Value Function Update Magnitude: 0.03336

Collected Steps per Second: 22,599.37343
Overall Steps per Second: 16,691.43854

Timestep Collection Time: 2.21334
Timestep Consumption Time: 0.78341
PPO Batch Consumption Time: 0.05139
Total Iteration Time: 2.99675

Cumulative Model Updates: 18,476
Cumulative Timesteps: 308,505,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 308505552...
Checkpoint 308505552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,137.70783
Policy Entropy: 0.69160
Value Function Loss: 0.04965

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03366
Policy Update Magnitude: 0.02569
Value Function Update Magnitude: 0.03085

Collected Steps per Second: 21,178.47649
Overall Steps per Second: 15,041.58434

Timestep Collection Time: 2.36174
Timestep Consumption Time: 0.96358
PPO Batch Consumption Time: 0.10029
Total Iteration Time: 3.32531

Cumulative Model Updates: 18,479
Cumulative Timesteps: 308,555,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,721.76749
Policy Entropy: 0.69600
Value Function Loss: 0.04645

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02156
Policy Update Magnitude: 0.02574
Value Function Update Magnitude: 0.02802

Collected Steps per Second: 22,250.29059
Overall Steps per Second: 16,129.80924

Timestep Collection Time: 2.24824
Timestep Consumption Time: 0.85310
PPO Batch Consumption Time: 0.03934
Total Iteration Time: 3.10134

Cumulative Model Updates: 18,482
Cumulative Timesteps: 308,605,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 308605594...
Checkpoint 308605594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,682.09876
Policy Entropy: 0.69739
Value Function Loss: 0.05007

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01929
Policy Update Magnitude: 0.02653
Value Function Update Magnitude: 0.02823

Collected Steps per Second: 20,067.90089
Overall Steps per Second: 14,608.47500

Timestep Collection Time: 2.49234
Timestep Consumption Time: 0.93143
PPO Batch Consumption Time: 0.06268
Total Iteration Time: 3.42377

Cumulative Model Updates: 18,485
Cumulative Timesteps: 308,655,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,525.66318
Policy Entropy: 0.69621
Value Function Loss: 0.05291

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.04055
Policy Update Magnitude: 0.02929
Value Function Update Magnitude: 0.03049

Collected Steps per Second: 22,313.44630
Overall Steps per Second: 15,522.72359

Timestep Collection Time: 2.24241
Timestep Consumption Time: 0.98099
PPO Batch Consumption Time: 0.10594
Total Iteration Time: 3.22340

Cumulative Model Updates: 18,488
Cumulative Timesteps: 308,705,646

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 308705646...
Checkpoint 308705646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,714.23157
Policy Entropy: 0.69396
Value Function Loss: 0.05190

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04967
Policy Update Magnitude: 0.03120
Value Function Update Magnitude: 0.03036

Collected Steps per Second: 22,837.16075
Overall Steps per Second: 17,230.54589

Timestep Collection Time: 2.18950
Timestep Consumption Time: 0.71244
PPO Batch Consumption Time: 0.03074
Total Iteration Time: 2.90194

Cumulative Model Updates: 18,491
Cumulative Timesteps: 308,755,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,590.88652
Policy Entropy: 0.69516
Value Function Loss: 0.04991

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07933
Policy Update Magnitude: 0.02732
Value Function Update Magnitude: 0.03134

Collected Steps per Second: 22,124.48703
Overall Steps per Second: 16,079.29787

Timestep Collection Time: 2.26003
Timestep Consumption Time: 0.84968
PPO Batch Consumption Time: 0.07784
Total Iteration Time: 3.10971

Cumulative Model Updates: 18,494
Cumulative Timesteps: 308,805,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 308805650...
Checkpoint 308805650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,025.42089
Policy Entropy: 0.69432
Value Function Loss: 0.04760

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05287
Policy Update Magnitude: 0.02463
Value Function Update Magnitude: 0.02845

Collected Steps per Second: 22,247.56348
Overall Steps per Second: 17,467.48072

Timestep Collection Time: 2.24816
Timestep Consumption Time: 0.61522
PPO Batch Consumption Time: 0.02997
Total Iteration Time: 2.86338

Cumulative Model Updates: 18,497
Cumulative Timesteps: 308,855,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,444.44000
Policy Entropy: 0.69560
Value Function Loss: 0.05141

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05610
Policy Update Magnitude: 0.02393
Value Function Update Magnitude: 0.02937

Collected Steps per Second: 21,499.42555
Overall Steps per Second: 15,965.83151

Timestep Collection Time: 2.32769
Timestep Consumption Time: 0.80675
PPO Batch Consumption Time: 0.08000
Total Iteration Time: 3.13444

Cumulative Model Updates: 18,500
Cumulative Timesteps: 308,905,710

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 308905710...
Checkpoint 308905710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,921.33129
Policy Entropy: 0.68984
Value Function Loss: 0.04579

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.03000
Policy Update Magnitude: 0.02665
Value Function Update Magnitude: 0.02931

Collected Steps per Second: 21,861.16374
Overall Steps per Second: 16,416.13588

Timestep Collection Time: 2.28817
Timestep Consumption Time: 0.75896
PPO Batch Consumption Time: 0.06928
Total Iteration Time: 3.04712

Cumulative Model Updates: 18,503
Cumulative Timesteps: 308,955,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,928.79441
Policy Entropy: 0.68250
Value Function Loss: 0.04480

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05961
Policy Update Magnitude: 0.02245
Value Function Update Magnitude: 0.03027

Collected Steps per Second: 21,658.15796
Overall Steps per Second: 16,619.93866

Timestep Collection Time: 2.30961
Timestep Consumption Time: 0.70014
PPO Batch Consumption Time: 0.02982
Total Iteration Time: 3.00976

Cumulative Model Updates: 18,506
Cumulative Timesteps: 309,005,754

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 309005754...
Checkpoint 309005754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,214.33750
Policy Entropy: 0.68750
Value Function Loss: 0.04435

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03466
Policy Update Magnitude: 0.02510
Value Function Update Magnitude: 0.03376

Collected Steps per Second: 22,648.53981
Overall Steps per Second: 16,779.80005

Timestep Collection Time: 2.20853
Timestep Consumption Time: 0.77243
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 2.98097

Cumulative Model Updates: 18,509
Cumulative Timesteps: 309,055,774

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,799.60490
Policy Entropy: 0.69459
Value Function Loss: 0.04948

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04674
Policy Update Magnitude: 0.02652
Value Function Update Magnitude: 0.03285

Collected Steps per Second: 22,180.59467
Overall Steps per Second: 16,984.24256

Timestep Collection Time: 2.25422
Timestep Consumption Time: 0.68968
PPO Batch Consumption Time: 0.03081
Total Iteration Time: 2.94391

Cumulative Model Updates: 18,512
Cumulative Timesteps: 309,105,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 309105774...
Checkpoint 309105774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,285.69856
Policy Entropy: 0.70195
Value Function Loss: 0.04395

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03786
Policy Update Magnitude: 0.02859
Value Function Update Magnitude: 0.03237

Collected Steps per Second: 22,593.88679
Overall Steps per Second: 16,354.64930

Timestep Collection Time: 2.21396
Timestep Consumption Time: 0.84462
PPO Batch Consumption Time: 0.06102
Total Iteration Time: 3.05858

Cumulative Model Updates: 18,515
Cumulative Timesteps: 309,155,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,951.75757
Policy Entropy: 0.70940
Value Function Loss: 0.04248

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04881
Policy Update Magnitude: 0.02787
Value Function Update Magnitude: 0.03602

Collected Steps per Second: 20,708.64488
Overall Steps per Second: 14,508.59046

Timestep Collection Time: 2.41532
Timestep Consumption Time: 1.03215
PPO Batch Consumption Time: 0.12020
Total Iteration Time: 3.44747

Cumulative Model Updates: 18,518
Cumulative Timesteps: 309,205,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 309205814...
Checkpoint 309205814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,870.24332
Policy Entropy: 0.71055
Value Function Loss: 0.03814

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03143
Policy Update Magnitude: 0.02484
Value Function Update Magnitude: 0.03296

Collected Steps per Second: 22,317.94793
Overall Steps per Second: 16,961.28338

Timestep Collection Time: 2.24071
Timestep Consumption Time: 0.70765
PPO Batch Consumption Time: 0.03033
Total Iteration Time: 2.94836

Cumulative Model Updates: 18,521
Cumulative Timesteps: 309,255,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,608.86634
Policy Entropy: 0.70561
Value Function Loss: 0.04199

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01725
Policy Update Magnitude: 0.02648
Value Function Update Magnitude: 0.02825

Collected Steps per Second: 22,955.13813
Overall Steps per Second: 17,207.55422

Timestep Collection Time: 2.17921
Timestep Consumption Time: 0.72789
PPO Batch Consumption Time: 0.03035
Total Iteration Time: 2.90710

Cumulative Model Updates: 18,524
Cumulative Timesteps: 309,305,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 309305846...
Checkpoint 309305846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,794.28425
Policy Entropy: 0.70208
Value Function Loss: 0.04391

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02944
Policy Update Magnitude: 0.02645
Value Function Update Magnitude: 0.03338

Collected Steps per Second: 22,548.95061
Overall Steps per Second: 17,041.16201

Timestep Collection Time: 2.21935
Timestep Consumption Time: 0.71730
PPO Batch Consumption Time: 0.03004
Total Iteration Time: 2.93665

Cumulative Model Updates: 18,527
Cumulative Timesteps: 309,355,890

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,109.58340
Policy Entropy: 0.69806
Value Function Loss: 0.04890

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02503
Policy Update Magnitude: 0.02674
Value Function Update Magnitude: 0.03326

Collected Steps per Second: 23,044.08671
Overall Steps per Second: 16,849.33138

Timestep Collection Time: 2.17001
Timestep Consumption Time: 0.79782
PPO Batch Consumption Time: 0.05123
Total Iteration Time: 2.96783

Cumulative Model Updates: 18,530
Cumulative Timesteps: 309,405,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 309405896...
Checkpoint 309405896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,958.74959
Policy Entropy: 0.70518
Value Function Loss: 0.05060

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02993
Policy Update Magnitude: 0.02752
Value Function Update Magnitude: 0.04156

Collected Steps per Second: 19,340.76836
Overall Steps per Second: 13,998.05074

Timestep Collection Time: 2.58521
Timestep Consumption Time: 0.98671
PPO Batch Consumption Time: 0.11035
Total Iteration Time: 3.57193

Cumulative Model Updates: 18,533
Cumulative Timesteps: 309,455,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,283.73820
Policy Entropy: 0.70799
Value Function Loss: 0.05652

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.07316
Policy Update Magnitude: 0.02764
Value Function Update Magnitude: 0.04179

Collected Steps per Second: 22,722.16891
Overall Steps per Second: 17,123.73860

Timestep Collection Time: 2.20067
Timestep Consumption Time: 0.71949
PPO Batch Consumption Time: 0.03023
Total Iteration Time: 2.92016

Cumulative Model Updates: 18,536
Cumulative Timesteps: 309,505,900

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 309505900...
Checkpoint 309505900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,214.55166
Policy Entropy: 0.70665
Value Function Loss: 0.05200

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.02820
Value Function Update Magnitude: 0.03665

Collected Steps per Second: 22,959.30573
Overall Steps per Second: 16,303.08026

Timestep Collection Time: 2.17777
Timestep Consumption Time: 0.88914
PPO Batch Consumption Time: 0.08795
Total Iteration Time: 3.06691

Cumulative Model Updates: 18,539
Cumulative Timesteps: 309,555,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,520.75993
Policy Entropy: 0.71302
Value Function Loss: 0.05235

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08468
Policy Update Magnitude: 0.02973
Value Function Update Magnitude: 0.03475

Collected Steps per Second: 22,952.02730
Overall Steps per Second: 16,581.51127

Timestep Collection Time: 2.17959
Timestep Consumption Time: 0.83739
PPO Batch Consumption Time: 0.06329
Total Iteration Time: 3.01697

Cumulative Model Updates: 18,542
Cumulative Timesteps: 309,605,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 309605926...
Checkpoint 309605926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,086.73493
Policy Entropy: 0.71185
Value Function Loss: 0.04751

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.06838
Policy Update Magnitude: 0.02970
Value Function Update Magnitude: 0.02971

Collected Steps per Second: 16,387.19807
Overall Steps per Second: 12,525.57058

Timestep Collection Time: 3.05263
Timestep Consumption Time: 0.94112
PPO Batch Consumption Time: 0.04624
Total Iteration Time: 3.99375

Cumulative Model Updates: 18,545
Cumulative Timesteps: 309,655,950

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,165.48599
Policy Entropy: 0.70718
Value Function Loss: 0.05215

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.07011
Policy Update Magnitude: 0.02839
Value Function Update Magnitude: 0.03275

Collected Steps per Second: 20,937.60558
Overall Steps per Second: 16,079.50583

Timestep Collection Time: 2.38910
Timestep Consumption Time: 0.72182
PPO Batch Consumption Time: 0.02929
Total Iteration Time: 3.11092

Cumulative Model Updates: 18,548
Cumulative Timesteps: 309,705,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 309705972...
Checkpoint 309705972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,406.25942
Policy Entropy: 0.69710
Value Function Loss: 0.05897

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.04125
Policy Update Magnitude: 0.02666
Value Function Update Magnitude: 0.03734

Collected Steps per Second: 22,279.93687
Overall Steps per Second: 15,593.97257

Timestep Collection Time: 2.24588
Timestep Consumption Time: 0.96293
PPO Batch Consumption Time: 0.11418
Total Iteration Time: 3.20880

Cumulative Model Updates: 18,551
Cumulative Timesteps: 309,756,010

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,055.72647
Policy Entropy: 0.68226
Value Function Loss: 0.06131

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.05197
Policy Update Magnitude: 0.02622
Value Function Update Magnitude: 0.03689

Collected Steps per Second: 22,207.71480
Overall Steps per Second: 16,116.75508

Timestep Collection Time: 2.25264
Timestep Consumption Time: 0.85133
PPO Batch Consumption Time: 0.06510
Total Iteration Time: 3.10397

Cumulative Model Updates: 18,554
Cumulative Timesteps: 309,806,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 309806036...
Checkpoint 309806036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,193.12929
Policy Entropy: 0.67411
Value Function Loss: 0.06296

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03967
Policy Update Magnitude: 0.02851
Value Function Update Magnitude: 0.03643

Collected Steps per Second: 21,770.10820
Overall Steps per Second: 16,852.42500

Timestep Collection Time: 2.29737
Timestep Consumption Time: 0.67039
PPO Batch Consumption Time: 0.02976
Total Iteration Time: 2.96776

Cumulative Model Updates: 18,557
Cumulative Timesteps: 309,856,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,608.18130
Policy Entropy: 0.68383
Value Function Loss: 0.05912

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.05253
Policy Update Magnitude: 0.02996
Value Function Update Magnitude: 0.03737

Collected Steps per Second: 22,432.77838
Overall Steps per Second: 16,054.76059

Timestep Collection Time: 2.22906
Timestep Consumption Time: 0.88553
PPO Batch Consumption Time: 0.07815
Total Iteration Time: 3.11459

Cumulative Model Updates: 18,560
Cumulative Timesteps: 309,906,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 309906054...
Checkpoint 309906054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,492.90484
Policy Entropy: 0.68315
Value Function Loss: 0.05761

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02771
Policy Update Magnitude: 0.02677
Value Function Update Magnitude: 0.03564

Collected Steps per Second: 22,807.75557
Overall Steps per Second: 17,264.26775

Timestep Collection Time: 2.19268
Timestep Consumption Time: 0.70406
PPO Batch Consumption Time: 0.02982
Total Iteration Time: 2.89673

Cumulative Model Updates: 18,563
Cumulative Timesteps: 309,956,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,876.95483
Policy Entropy: 0.68646
Value Function Loss: 0.05342

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.02796
Value Function Update Magnitude: 0.03323

Collected Steps per Second: 23,440.23336
Overall Steps per Second: 16,354.49215

Timestep Collection Time: 2.13394
Timestep Consumption Time: 0.92455
PPO Batch Consumption Time: 0.09543
Total Iteration Time: 3.05849

Cumulative Model Updates: 18,566
Cumulative Timesteps: 310,006,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 310006084...
Checkpoint 310006084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,163.89922
Policy Entropy: 0.68355
Value Function Loss: 0.05111

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01533
Policy Update Magnitude: 0.03098
Value Function Update Magnitude: 0.03728

Collected Steps per Second: 22,670.54834
Overall Steps per Second: 17,133.47717

Timestep Collection Time: 2.20568
Timestep Consumption Time: 0.71282
PPO Batch Consumption Time: 0.03021
Total Iteration Time: 2.91850

Cumulative Model Updates: 18,569
Cumulative Timesteps: 310,056,088

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,088.40601
Policy Entropy: 0.67755
Value Function Loss: 0.05219

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01697
Policy Update Magnitude: 0.03132
Value Function Update Magnitude: 0.03902

Collected Steps per Second: 23,068.19016
Overall Steps per Second: 17,366.76594

Timestep Collection Time: 2.16757
Timestep Consumption Time: 0.71160
PPO Batch Consumption Time: 0.02975
Total Iteration Time: 2.87918

Cumulative Model Updates: 18,572
Cumulative Timesteps: 310,106,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 310106090...
Checkpoint 310106090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,037.98800
Policy Entropy: 0.67487
Value Function Loss: 0.05056

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02628
Policy Update Magnitude: 0.02694
Value Function Update Magnitude: 0.03995

Collected Steps per Second: 22,090.69355
Overall Steps per Second: 16,697.82377

Timestep Collection Time: 2.26448
Timestep Consumption Time: 0.73136
PPO Batch Consumption Time: 0.03022
Total Iteration Time: 2.99584

Cumulative Model Updates: 18,575
Cumulative Timesteps: 310,156,114

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,627.19281
Policy Entropy: 0.68053
Value Function Loss: 0.05398

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.02518
Value Function Update Magnitude: 0.04089

Collected Steps per Second: 23,074.07004
Overall Steps per Second: 16,414.73617

Timestep Collection Time: 2.16719
Timestep Consumption Time: 0.87921
PPO Batch Consumption Time: 0.07247
Total Iteration Time: 3.04641

Cumulative Model Updates: 18,578
Cumulative Timesteps: 310,206,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 310206120...
Checkpoint 310206120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,026.28004
Policy Entropy: 0.68002
Value Function Loss: 0.05739

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03962
Policy Update Magnitude: 0.02793
Value Function Update Magnitude: 0.04778

Collected Steps per Second: 20,607.14958
Overall Steps per Second: 15,707.69247

Timestep Collection Time: 2.42731
Timestep Consumption Time: 0.75711
PPO Batch Consumption Time: 0.03088
Total Iteration Time: 3.18443

Cumulative Model Updates: 18,581
Cumulative Timesteps: 310,256,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,714.55678
Policy Entropy: 0.68611
Value Function Loss: 0.05983

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.02729
Value Function Update Magnitude: 0.05532

Collected Steps per Second: 22,154.99975
Overall Steps per Second: 16,673.77997

Timestep Collection Time: 2.25692
Timestep Consumption Time: 0.74192
PPO Batch Consumption Time: 0.03374
Total Iteration Time: 2.99884

Cumulative Model Updates: 18,584
Cumulative Timesteps: 310,306,142

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 310306142...
Checkpoint 310306142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,922.45674
Policy Entropy: 0.67945
Value Function Loss: 0.05867

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01769
Policy Update Magnitude: 0.02769
Value Function Update Magnitude: 0.05983

Collected Steps per Second: 19,643.64440
Overall Steps per Second: 15,378.13460

Timestep Collection Time: 2.54657
Timestep Consumption Time: 0.70636
PPO Batch Consumption Time: 0.02968
Total Iteration Time: 3.25293

Cumulative Model Updates: 18,587
Cumulative Timesteps: 310,356,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,096.49235
Policy Entropy: 0.68392
Value Function Loss: 0.04982

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01364
Policy Update Magnitude: 0.02875
Value Function Update Magnitude: 0.05264

Collected Steps per Second: 22,097.08515
Overall Steps per Second: 15,991.41854

Timestep Collection Time: 2.26292
Timestep Consumption Time: 0.86400
PPO Batch Consumption Time: 0.07361
Total Iteration Time: 3.12693

Cumulative Model Updates: 18,590
Cumulative Timesteps: 310,406,170

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 310406170...
Checkpoint 310406170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,036.53610
Policy Entropy: 0.68630
Value Function Loss: 0.04697

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01904
Policy Update Magnitude: 0.02822
Value Function Update Magnitude: 0.05038

Collected Steps per Second: 20,351.27285
Overall Steps per Second: 15,097.00828

Timestep Collection Time: 2.45793
Timestep Consumption Time: 0.85544
PPO Batch Consumption Time: 0.06608
Total Iteration Time: 3.31337

Cumulative Model Updates: 18,593
Cumulative Timesteps: 310,456,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,738.87986
Policy Entropy: 0.68372
Value Function Loss: 0.04514

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01154
Policy Update Magnitude: 0.02944
Value Function Update Magnitude: 0.04620

Collected Steps per Second: 20,600.36491
Overall Steps per Second: 15,197.41321

Timestep Collection Time: 2.42763
Timestep Consumption Time: 0.86306
PPO Batch Consumption Time: 0.07455
Total Iteration Time: 3.29069

Cumulative Model Updates: 18,596
Cumulative Timesteps: 310,506,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 310506202...
Checkpoint 310506202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,651.93303
Policy Entropy: 0.68388
Value Function Loss: 0.04310

Mean KL Divergence: 0.00128
SB3 Clip Fraction: 0.00971
Policy Update Magnitude: 0.02857
Value Function Update Magnitude: 0.04135

Collected Steps per Second: 20,713.60353
Overall Steps per Second: 15,344.70828

Timestep Collection Time: 2.41387
Timestep Consumption Time: 0.84458
PPO Batch Consumption Time: 0.06407
Total Iteration Time: 3.25845

Cumulative Model Updates: 18,599
Cumulative Timesteps: 310,556,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,302.07429
Policy Entropy: 0.68254
Value Function Loss: 0.04250

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01939
Policy Update Magnitude: 0.02984
Value Function Update Magnitude: 0.04492

Collected Steps per Second: 19,976.38552
Overall Steps per Second: 14,826.49954

Timestep Collection Time: 2.50406
Timestep Consumption Time: 0.86977
PPO Batch Consumption Time: 0.03349
Total Iteration Time: 3.37382

Cumulative Model Updates: 18,602
Cumulative Timesteps: 310,606,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 310606224...
Checkpoint 310606224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,746.42045
Policy Entropy: 0.69127
Value Function Loss: 0.04294

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02156
Policy Update Magnitude: 0.02734
Value Function Update Magnitude: 0.05330

Collected Steps per Second: 19,755.46548
Overall Steps per Second: 15,034.99954

Timestep Collection Time: 2.53155
Timestep Consumption Time: 0.79482
PPO Batch Consumption Time: 0.07695
Total Iteration Time: 3.32637

Cumulative Model Updates: 18,605
Cumulative Timesteps: 310,656,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,818.55137
Policy Entropy: 0.68814
Value Function Loss: 0.04624

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01926
Policy Update Magnitude: 0.02959
Value Function Update Magnitude: 0.05126

Collected Steps per Second: 20,499.74241
Overall Steps per Second: 15,532.82414

Timestep Collection Time: 2.43915
Timestep Consumption Time: 0.77997
PPO Batch Consumption Time: 0.07713
Total Iteration Time: 3.21912

Cumulative Model Updates: 18,608
Cumulative Timesteps: 310,706,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 310706238...
Checkpoint 310706238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,738.26652
Policy Entropy: 0.68955
Value Function Loss: 0.04960

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02903
Policy Update Magnitude: 0.03062
Value Function Update Magnitude: 0.04980

Collected Steps per Second: 18,036.27578
Overall Steps per Second: 14,096.13667

Timestep Collection Time: 2.77330
Timestep Consumption Time: 0.77519
PPO Batch Consumption Time: 0.07568
Total Iteration Time: 3.54849

Cumulative Model Updates: 18,611
Cumulative Timesteps: 310,756,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,317.77260
Policy Entropy: 0.68035
Value Function Loss: 0.04685

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02233
Policy Update Magnitude: 0.03009
Value Function Update Magnitude: 0.05329

Collected Steps per Second: 20,266.64246
Overall Steps per Second: 15,494.63319

Timestep Collection Time: 2.46780
Timestep Consumption Time: 0.76003
PPO Batch Consumption Time: 0.06676
Total Iteration Time: 3.22783

Cumulative Model Updates: 18,614
Cumulative Timesteps: 310,806,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 310806272...
Checkpoint 310806272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,640.38218
Policy Entropy: 0.68915
Value Function Loss: 0.04754

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02843
Policy Update Magnitude: 0.02918
Value Function Update Magnitude: 0.05162

Collected Steps per Second: 20,060.58288
Overall Steps per Second: 14,745.70079

Timestep Collection Time: 2.49295
Timestep Consumption Time: 0.89855
PPO Batch Consumption Time: 0.03148
Total Iteration Time: 3.39150

Cumulative Model Updates: 18,617
Cumulative Timesteps: 310,856,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,976.26253
Policy Entropy: 0.69035
Value Function Loss: 0.03900

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.01911
Policy Update Magnitude: 0.02641
Value Function Update Magnitude: 0.05417

Collected Steps per Second: 20,715.79098
Overall Steps per Second: 15,482.35458

Timestep Collection Time: 2.41381
Timestep Consumption Time: 0.81593
PPO Batch Consumption Time: 0.06424
Total Iteration Time: 3.22974

Cumulative Model Updates: 18,620
Cumulative Timesteps: 310,906,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 310906286...
Checkpoint 310906286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,929.04299
Policy Entropy: 0.70055
Value Function Loss: 0.03436

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03105
Policy Update Magnitude: 0.02576
Value Function Update Magnitude: 0.05217

Collected Steps per Second: 20,619.13881
Overall Steps per Second: 15,791.18416

Timestep Collection Time: 2.42629
Timestep Consumption Time: 0.74181
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 3.16810

Cumulative Model Updates: 18,623
Cumulative Timesteps: 310,956,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,245.37176
Policy Entropy: 0.70179
Value Function Loss: 0.03044

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02653
Policy Update Magnitude: 0.02489
Value Function Update Magnitude: 0.04343

Collected Steps per Second: 20,937.61358
Overall Steps per Second: 15,584.01675

Timestep Collection Time: 2.38872
Timestep Consumption Time: 0.82060
PPO Batch Consumption Time: 0.06300
Total Iteration Time: 3.20931

Cumulative Model Updates: 18,626
Cumulative Timesteps: 311,006,328

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 311006328...
Checkpoint 311006328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,281.73485
Policy Entropy: 0.70620
Value Function Loss: 0.03673

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04790
Policy Update Magnitude: 0.02322
Value Function Update Magnitude: 0.04172

Collected Steps per Second: 20,433.25577
Overall Steps per Second: 15,079.75397

Timestep Collection Time: 2.44817
Timestep Consumption Time: 0.86913
PPO Batch Consumption Time: 0.07019
Total Iteration Time: 3.31730

Cumulative Model Updates: 18,629
Cumulative Timesteps: 311,056,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,829.03544
Policy Entropy: 0.68858
Value Function Loss: 0.04553

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04551
Policy Update Magnitude: 0.02353
Value Function Update Magnitude: 0.04652

Collected Steps per Second: 20,799.37276
Overall Steps per Second: 15,385.41754

Timestep Collection Time: 2.40469
Timestep Consumption Time: 0.84618
PPO Batch Consumption Time: 0.06708
Total Iteration Time: 3.25087

Cumulative Model Updates: 18,632
Cumulative Timesteps: 311,106,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 311106368...
Checkpoint 311106368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,556.52239
Policy Entropy: 0.68910
Value Function Loss: 0.04566

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.05509
Policy Update Magnitude: 0.02511
Value Function Update Magnitude: 0.05219

Collected Steps per Second: 20,345.69379
Overall Steps per Second: 15,039.77975

Timestep Collection Time: 2.45890
Timestep Consumption Time: 0.86748
PPO Batch Consumption Time: 0.07084
Total Iteration Time: 3.32638

Cumulative Model Updates: 18,635
Cumulative Timesteps: 311,156,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,755.60903
Policy Entropy: 0.69067
Value Function Loss: 0.04398

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.04162
Policy Update Magnitude: 0.02498
Value Function Update Magnitude: 0.05212

Collected Steps per Second: 20,309.04758
Overall Steps per Second: 14,998.14165

Timestep Collection Time: 2.46245
Timestep Consumption Time: 0.87196
PPO Batch Consumption Time: 0.07612
Total Iteration Time: 3.33441

Cumulative Model Updates: 18,638
Cumulative Timesteps: 311,206,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 311206406...
Checkpoint 311206406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,529.03010
Policy Entropy: 0.70045
Value Function Loss: 0.04012

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03847
Policy Update Magnitude: 0.02594
Value Function Update Magnitude: 0.04760

Collected Steps per Second: 19,866.08505
Overall Steps per Second: 14,803.30394

Timestep Collection Time: 2.51766
Timestep Consumption Time: 0.86105
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 3.37871

Cumulative Model Updates: 18,641
Cumulative Timesteps: 311,256,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,015.38456
Policy Entropy: 0.69226
Value Function Loss: 0.04469

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.04003
Policy Update Magnitude: 0.02512
Value Function Update Magnitude: 0.04749

Collected Steps per Second: 20,865.42771
Overall Steps per Second: 15,587.63596

Timestep Collection Time: 2.39775
Timestep Consumption Time: 0.81185
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 3.20960

Cumulative Model Updates: 18,644
Cumulative Timesteps: 311,306,452

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 311306452...
Checkpoint 311306452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,008.58177
Policy Entropy: 0.68479
Value Function Loss: 0.05453

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.02552
Value Function Update Magnitude: 0.04943

Collected Steps per Second: 19,430.09985
Overall Steps per Second: 14,999.72691

Timestep Collection Time: 2.57528
Timestep Consumption Time: 0.76064
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 3.33593

Cumulative Model Updates: 18,647
Cumulative Timesteps: 311,356,490

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,143.72479
Policy Entropy: 0.67330
Value Function Loss: 0.05543

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.02819
Value Function Update Magnitude: 0.05799

Collected Steps per Second: 22,263.27806
Overall Steps per Second: 15,922.89263

Timestep Collection Time: 2.24648
Timestep Consumption Time: 0.89453
PPO Batch Consumption Time: 0.06290
Total Iteration Time: 3.14101

Cumulative Model Updates: 18,650
Cumulative Timesteps: 311,406,504

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 311406504...
Checkpoint 311406504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,448.80176
Policy Entropy: 0.67837
Value Function Loss: 0.05614

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01647
Policy Update Magnitude: 0.02783
Value Function Update Magnitude: 0.04927

Collected Steps per Second: 18,864.62213
Overall Steps per Second: 14,547.00622

Timestep Collection Time: 2.65216
Timestep Consumption Time: 0.78717
PPO Batch Consumption Time: 0.04666
Total Iteration Time: 3.43933

Cumulative Model Updates: 18,653
Cumulative Timesteps: 311,456,536

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,111.13110
Policy Entropy: 0.69314
Value Function Loss: 0.04844

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.02728
Value Function Update Magnitude: 0.04456

Collected Steps per Second: 22,225.35955
Overall Steps per Second: 15,203.27197

Timestep Collection Time: 2.25103
Timestep Consumption Time: 1.03971
PPO Batch Consumption Time: 0.11809
Total Iteration Time: 3.29074

Cumulative Model Updates: 18,656
Cumulative Timesteps: 311,506,566

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 311506566...
Checkpoint 311506566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,932.14310
Policy Entropy: 0.70124
Value Function Loss: 0.04838

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01907
Policy Update Magnitude: 0.02663
Value Function Update Magnitude: 0.03806

Collected Steps per Second: 22,403.19279
Overall Steps per Second: 15,669.31695

Timestep Collection Time: 2.23263
Timestep Consumption Time: 0.95947
PPO Batch Consumption Time: 0.10084
Total Iteration Time: 3.19210

Cumulative Model Updates: 18,659
Cumulative Timesteps: 311,556,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,272.50055
Policy Entropy: 0.69998
Value Function Loss: 0.04957

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02514
Policy Update Magnitude: 0.02747
Value Function Update Magnitude: 0.04167

Collected Steps per Second: 22,745.80391
Overall Steps per Second: 17,116.39184

Timestep Collection Time: 2.19838
Timestep Consumption Time: 0.72303
PPO Batch Consumption Time: 0.03038
Total Iteration Time: 2.92141

Cumulative Model Updates: 18,662
Cumulative Timesteps: 311,606,588

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 311606588...
Checkpoint 311606588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,387.64665
Policy Entropy: 0.69349
Value Function Loss: 0.05169

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01713
Policy Update Magnitude: 0.02562
Value Function Update Magnitude: 0.03636

Collected Steps per Second: 22,440.09714
Overall Steps per Second: 16,563.13712

Timestep Collection Time: 2.22833
Timestep Consumption Time: 0.79066
PPO Batch Consumption Time: 0.05114
Total Iteration Time: 3.01899

Cumulative Model Updates: 18,665
Cumulative Timesteps: 311,656,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,865.31746
Policy Entropy: 0.68854
Value Function Loss: 0.05166

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03750
Policy Update Magnitude: 0.02635
Value Function Update Magnitude: 0.03283

Collected Steps per Second: 21,678.50495
Overall Steps per Second: 16,546.27413

Timestep Collection Time: 2.30689
Timestep Consumption Time: 0.71554
PPO Batch Consumption Time: 0.03044
Total Iteration Time: 3.02243

Cumulative Model Updates: 18,668
Cumulative Timesteps: 311,706,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 311706602...
Checkpoint 311706602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,512.48175
Policy Entropy: 0.69787
Value Function Loss: 0.05100

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03049
Policy Update Magnitude: 0.02755
Value Function Update Magnitude: 0.03808

Collected Steps per Second: 22,863.44083
Overall Steps per Second: 16,776.80004

Timestep Collection Time: 2.18882
Timestep Consumption Time: 0.79411
PPO Batch Consumption Time: 0.05261
Total Iteration Time: 2.98293

Cumulative Model Updates: 18,671
Cumulative Timesteps: 311,756,646

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,577.43394
Policy Entropy: 0.68886
Value Function Loss: 0.05724

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03847
Policy Update Magnitude: 0.02567
Value Function Update Magnitude: 0.03952

Collected Steps per Second: 20,508.20751
Overall Steps per Second: 14,674.19039

Timestep Collection Time: 2.43815
Timestep Consumption Time: 0.96933
PPO Batch Consumption Time: 0.09346
Total Iteration Time: 3.40748

Cumulative Model Updates: 18,674
Cumulative Timesteps: 311,806,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 311806648...
Checkpoint 311806648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,289.50056
Policy Entropy: 0.69217
Value Function Loss: 0.05769

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03213
Policy Update Magnitude: 0.02970
Value Function Update Magnitude: 0.03695

Collected Steps per Second: 22,499.77301
Overall Steps per Second: 15,835.59005

Timestep Collection Time: 2.22260
Timestep Consumption Time: 0.93535
PPO Batch Consumption Time: 0.09728
Total Iteration Time: 3.15795

Cumulative Model Updates: 18,677
Cumulative Timesteps: 311,856,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,814.02195
Policy Entropy: 0.69077
Value Function Loss: 0.05378

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03854
Policy Update Magnitude: 0.03108
Value Function Update Magnitude: 0.03645

Collected Steps per Second: 23,101.35374
Overall Steps per Second: 16,811.51428

Timestep Collection Time: 2.16481
Timestep Consumption Time: 0.80994
PPO Batch Consumption Time: 0.06094
Total Iteration Time: 2.97475

Cumulative Model Updates: 18,680
Cumulative Timesteps: 311,906,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 311906666...
Checkpoint 311906666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,517.61482
Policy Entropy: 0.69552
Value Function Loss: 0.05202

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03599
Policy Update Magnitude: 0.02934
Value Function Update Magnitude: 0.03764

Collected Steps per Second: 22,313.23272
Overall Steps per Second: 16,948.78044

Timestep Collection Time: 2.24199
Timestep Consumption Time: 0.70961
PPO Batch Consumption Time: 0.02968
Total Iteration Time: 2.95160

Cumulative Model Updates: 18,683
Cumulative Timesteps: 311,956,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,593.64556
Policy Entropy: 0.70434
Value Function Loss: 0.04586

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03811
Policy Update Magnitude: 0.02917
Value Function Update Magnitude: 0.03316

Collected Steps per Second: 22,043.15506
Overall Steps per Second: 15,670.43414

Timestep Collection Time: 2.26964
Timestep Consumption Time: 0.92300
PPO Batch Consumption Time: 0.09643
Total Iteration Time: 3.19264

Cumulative Model Updates: 18,686
Cumulative Timesteps: 312,006,722

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 312006722...
Checkpoint 312006722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,496.22093
Policy Entropy: 0.69533
Value Function Loss: 0.05075

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03839
Policy Update Magnitude: 0.02807
Value Function Update Magnitude: 0.03089

Collected Steps per Second: 22,395.55088
Overall Steps per Second: 17,447.24069

Timestep Collection Time: 2.23268
Timestep Consumption Time: 0.63322
PPO Batch Consumption Time: 0.02969
Total Iteration Time: 2.86590

Cumulative Model Updates: 18,689
Cumulative Timesteps: 312,056,724

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,600.02130
Policy Entropy: 0.69937
Value Function Loss: 0.05408

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05423
Policy Update Magnitude: 0.02681
Value Function Update Magnitude: 0.02985

Collected Steps per Second: 21,848.97843
Overall Steps per Second: 15,818.18544

Timestep Collection Time: 2.28889
Timestep Consumption Time: 0.87266
PPO Batch Consumption Time: 0.11174
Total Iteration Time: 3.16155

Cumulative Model Updates: 18,692
Cumulative Timesteps: 312,106,734

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 312106734...
Checkpoint 312106734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,872.92085
Policy Entropy: 0.69479
Value Function Loss: 0.05981

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05583
Policy Update Magnitude: 0.02890
Value Function Update Magnitude: 0.03294

Collected Steps per Second: 20,923.41036
Overall Steps per Second: 16,462.53897

Timestep Collection Time: 2.39110
Timestep Consumption Time: 0.64792
PPO Batch Consumption Time: 0.03178
Total Iteration Time: 3.03902

Cumulative Model Updates: 18,695
Cumulative Timesteps: 312,156,764

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,445.50400
Policy Entropy: 0.69262
Value Function Loss: 0.05909

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06786
Policy Update Magnitude: 0.03330
Value Function Update Magnitude: 0.03928

Collected Steps per Second: 22,466.94032
Overall Steps per Second: 15,881.14770

Timestep Collection Time: 2.22558
Timestep Consumption Time: 0.92293
PPO Batch Consumption Time: 0.10877
Total Iteration Time: 3.14851

Cumulative Model Updates: 18,698
Cumulative Timesteps: 312,206,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 312206766...
Checkpoint 312206766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,693.79455
Policy Entropy: 0.69651
Value Function Loss: 0.05223

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06486
Policy Update Magnitude: 0.02789
Value Function Update Magnitude: 0.03692

Collected Steps per Second: 22,335.03943
Overall Steps per Second: 17,021.88764

Timestep Collection Time: 2.23971
Timestep Consumption Time: 0.69909
PPO Batch Consumption Time: 0.03094
Total Iteration Time: 2.93880

Cumulative Model Updates: 18,701
Cumulative Timesteps: 312,256,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,935.56609
Policy Entropy: 0.69874
Value Function Loss: 0.05161

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04475
Policy Update Magnitude: 0.02678
Value Function Update Magnitude: 0.03605

Collected Steps per Second: 21,681.22358
Overall Steps per Second: 15,450.76265

Timestep Collection Time: 2.30633
Timestep Consumption Time: 0.93002
PPO Batch Consumption Time: 0.10113
Total Iteration Time: 3.23635

Cumulative Model Updates: 18,704
Cumulative Timesteps: 312,306,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 312306794...
Checkpoint 312306794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,535.75297
Policy Entropy: 0.68883
Value Function Loss: 0.05053

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04531
Policy Update Magnitude: 0.02583
Value Function Update Magnitude: 0.03275

Collected Steps per Second: 22,525.00262
Overall Steps per Second: 16,412.30988

Timestep Collection Time: 2.22038
Timestep Consumption Time: 0.82697
PPO Batch Consumption Time: 0.06708
Total Iteration Time: 3.04735

Cumulative Model Updates: 18,707
Cumulative Timesteps: 312,356,808

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,653.59802
Policy Entropy: 0.69063
Value Function Loss: 0.04983

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04646
Policy Update Magnitude: 0.02451
Value Function Update Magnitude: 0.03143

Collected Steps per Second: 18,542.17051
Overall Steps per Second: 14,389.89419

Timestep Collection Time: 2.69666
Timestep Consumption Time: 0.77814
PPO Batch Consumption Time: 0.05827
Total Iteration Time: 3.47480

Cumulative Model Updates: 18,710
Cumulative Timesteps: 312,406,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 312406810...
Checkpoint 312406810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,464.47237
Policy Entropy: 0.69314
Value Function Loss: 0.04662

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04881
Policy Update Magnitude: 0.02275
Value Function Update Magnitude: 0.03131

Collected Steps per Second: 22,080.64192
Overall Steps per Second: 16,933.79788

Timestep Collection Time: 2.26569
Timestep Consumption Time: 0.68863
PPO Batch Consumption Time: 0.02900
Total Iteration Time: 2.95433

Cumulative Model Updates: 18,713
Cumulative Timesteps: 312,456,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,812.84583
Policy Entropy: 0.68854
Value Function Loss: 0.05086

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03789
Policy Update Magnitude: 0.02323
Value Function Update Magnitude: 0.03069

Collected Steps per Second: 24,110.22910
Overall Steps per Second: 17,605.40947

Timestep Collection Time: 2.07447
Timestep Consumption Time: 0.76647
PPO Batch Consumption Time: 0.05137
Total Iteration Time: 2.84094

Cumulative Model Updates: 18,716
Cumulative Timesteps: 312,506,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 312506854...
Checkpoint 312506854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,314.47916
Policy Entropy: 0.68555
Value Function Loss: 0.04876

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03326
Policy Update Magnitude: 0.02612
Value Function Update Magnitude: 0.03200

Collected Steps per Second: 21,414.89156
Overall Steps per Second: 16,127.79091

Timestep Collection Time: 2.33576
Timestep Consumption Time: 0.76572
PPO Batch Consumption Time: 0.03934
Total Iteration Time: 3.10148

Cumulative Model Updates: 18,719
Cumulative Timesteps: 312,556,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,136.52468
Policy Entropy: 0.69059
Value Function Loss: 0.05461

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03653
Policy Update Magnitude: 0.02438
Value Function Update Magnitude: 0.03514

Collected Steps per Second: 22,923.26610
Overall Steps per Second: 17,212.77430

Timestep Collection Time: 2.18311
Timestep Consumption Time: 0.72427
PPO Batch Consumption Time: 0.02907
Total Iteration Time: 2.90738

Cumulative Model Updates: 18,722
Cumulative Timesteps: 312,606,918

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 312606918...
Checkpoint 312606918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,061.26899
Policy Entropy: 0.68849
Value Function Loss: 0.06232

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03557
Policy Update Magnitude: 0.02564
Value Function Update Magnitude: 0.03506

Collected Steps per Second: 21,652.77106
Overall Steps per Second: 15,423.69470

Timestep Collection Time: 2.31047
Timestep Consumption Time: 0.93311
PPO Batch Consumption Time: 0.08833
Total Iteration Time: 3.24358

Cumulative Model Updates: 18,725
Cumulative Timesteps: 312,656,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,032.53241
Policy Entropy: 0.69510
Value Function Loss: 0.06974

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.04209
Policy Update Magnitude: 0.02863
Value Function Update Magnitude: 0.03637

Collected Steps per Second: 22,856.21778
Overall Steps per Second: 16,394.36649

Timestep Collection Time: 2.18916
Timestep Consumption Time: 0.86286
PPO Batch Consumption Time: 0.07545
Total Iteration Time: 3.05202

Cumulative Model Updates: 18,728
Cumulative Timesteps: 312,706,982

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 312706982...
Checkpoint 312706982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,529.97796
Policy Entropy: 0.68949
Value Function Loss: 0.06693

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03383
Policy Update Magnitude: 0.03053
Value Function Update Magnitude: 0.03622

Collected Steps per Second: 20,018.94134
Overall Steps per Second: 15,441.94771

Timestep Collection Time: 2.49813
Timestep Consumption Time: 0.74045
PPO Batch Consumption Time: 0.02975
Total Iteration Time: 3.23858

Cumulative Model Updates: 18,731
Cumulative Timesteps: 312,756,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,500.87442
Policy Entropy: 0.69498
Value Function Loss: 0.06363

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03783
Policy Update Magnitude: 0.03021
Value Function Update Magnitude: 0.03763

Collected Steps per Second: 22,948.28152
Overall Steps per Second: 16,323.70149

Timestep Collection Time: 2.17934
Timestep Consumption Time: 0.88443
PPO Batch Consumption Time: 0.07684
Total Iteration Time: 3.06377

Cumulative Model Updates: 18,734
Cumulative Timesteps: 312,807,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 312807004...
Checkpoint 312807004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,447.84778
Policy Entropy: 0.68703
Value Function Loss: 0.06277

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03715
Policy Update Magnitude: 0.03328
Value Function Update Magnitude: 0.04465

Collected Steps per Second: 22,573.60787
Overall Steps per Second: 17,102.87019

Timestep Collection Time: 2.21631
Timestep Consumption Time: 0.70893
PPO Batch Consumption Time: 0.02998
Total Iteration Time: 2.92524

Cumulative Model Updates: 18,737
Cumulative Timesteps: 312,857,034

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,119.20223
Policy Entropy: 0.69895
Value Function Loss: 0.06239

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02885
Policy Update Magnitude: 0.03165
Value Function Update Magnitude: 0.03958

Collected Steps per Second: 22,643.53236
Overall Steps per Second: 15,676.77437

Timestep Collection Time: 2.20902
Timestep Consumption Time: 0.98169
PPO Batch Consumption Time: 0.10711
Total Iteration Time: 3.19071

Cumulative Model Updates: 18,740
Cumulative Timesteps: 312,907,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 312907054...
Checkpoint 312907054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,616.16243
Policy Entropy: 0.70090
Value Function Loss: 0.05677

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.03227
Value Function Update Magnitude: 0.04228

Collected Steps per Second: 22,452.30647
Overall Steps per Second: 17,079.33532

Timestep Collection Time: 2.22774
Timestep Consumption Time: 0.70082
PPO Batch Consumption Time: 0.03003
Total Iteration Time: 2.92857

Cumulative Model Updates: 18,743
Cumulative Timesteps: 312,957,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,238.09050
Policy Entropy: 0.71311
Value Function Loss: 0.05623

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02849
Policy Update Magnitude: 0.03186
Value Function Update Magnitude: 0.04174

Collected Steps per Second: 23,283.39186
Overall Steps per Second: 16,650.87618

Timestep Collection Time: 2.14943
Timestep Consumption Time: 0.85618
PPO Batch Consumption Time: 0.07159
Total Iteration Time: 3.00561

Cumulative Model Updates: 18,746
Cumulative Timesteps: 313,007,118

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 313007118...
Checkpoint 313007118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,932.49743
Policy Entropy: 0.70556
Value Function Loss: 0.05713

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.03160
Value Function Update Magnitude: 0.05006

Collected Steps per Second: 22,343.64154
Overall Steps per Second: 16,356.88204

Timestep Collection Time: 2.23777
Timestep Consumption Time: 0.81904
PPO Batch Consumption Time: 0.06411
Total Iteration Time: 3.05682

Cumulative Model Updates: 18,749
Cumulative Timesteps: 313,057,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,185.96585
Policy Entropy: 0.70936
Value Function Loss: 0.05548

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03059
Policy Update Magnitude: 0.03016
Value Function Update Magnitude: 0.04375

Collected Steps per Second: 20,068.14148
Overall Steps per Second: 14,794.84459

Timestep Collection Time: 2.49211
Timestep Consumption Time: 0.88826
PPO Batch Consumption Time: 0.08010
Total Iteration Time: 3.38037

Cumulative Model Updates: 18,752
Cumulative Timesteps: 313,107,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 313107130...
Checkpoint 313107130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,719.04291
Policy Entropy: 0.70788
Value Function Loss: 0.04924

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02858
Policy Update Magnitude: 0.03185
Value Function Update Magnitude: 0.05438

Collected Steps per Second: 22,839.92405
Overall Steps per Second: 16,703.84013

Timestep Collection Time: 2.18950
Timestep Consumption Time: 0.80430
PPO Batch Consumption Time: 0.06014
Total Iteration Time: 2.99380

Cumulative Model Updates: 18,755
Cumulative Timesteps: 313,157,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,605.72016
Policy Entropy: 0.71974
Value Function Loss: 0.04412

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01687
Policy Update Magnitude: 0.03098
Value Function Update Magnitude: 0.04427

Collected Steps per Second: 19,551.86934
Overall Steps per Second: 14,034.48035

Timestep Collection Time: 2.55771
Timestep Consumption Time: 1.00551
PPO Batch Consumption Time: 0.11699
Total Iteration Time: 3.56322

Cumulative Model Updates: 18,758
Cumulative Timesteps: 313,207,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 313207146...
Checkpoint 313207146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,603.59025
Policy Entropy: 0.71802
Value Function Loss: 0.04686

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01675
Policy Update Magnitude: 0.02815
Value Function Update Magnitude: 0.03772

Collected Steps per Second: 23,282.84372
Overall Steps per Second: 17,485.71048

Timestep Collection Time: 2.14811
Timestep Consumption Time: 0.71217
PPO Batch Consumption Time: 0.03037
Total Iteration Time: 2.86028

Cumulative Model Updates: 18,761
Cumulative Timesteps: 313,257,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,226.92032
Policy Entropy: 0.71830
Value Function Loss: 0.04919

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.02159
Policy Update Magnitude: 0.02996
Value Function Update Magnitude: 0.03272

Collected Steps per Second: 21,614.43157
Overall Steps per Second: 15,951.05180

Timestep Collection Time: 2.31401
Timestep Consumption Time: 0.82158
PPO Batch Consumption Time: 0.07990
Total Iteration Time: 3.13559

Cumulative Model Updates: 18,764
Cumulative Timesteps: 313,307,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 313307176...
Checkpoint 313307176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,106.01043
Policy Entropy: 0.72024
Value Function Loss: 0.04818

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02558
Policy Update Magnitude: 0.02934
Value Function Update Magnitude: 0.03493

Collected Steps per Second: 21,823.40674
Overall Steps per Second: 15,860.87702

Timestep Collection Time: 2.29112
Timestep Consumption Time: 0.86129
PPO Batch Consumption Time: 0.10306
Total Iteration Time: 3.15241

Cumulative Model Updates: 18,767
Cumulative Timesteps: 313,357,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,972.10535
Policy Entropy: 0.71547
Value Function Loss: 0.04595

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02167
Policy Update Magnitude: 0.02730
Value Function Update Magnitude: 0.03219

Collected Steps per Second: 22,308.24913
Overall Steps per Second: 16,536.72229

Timestep Collection Time: 2.24240
Timestep Consumption Time: 0.78263
PPO Batch Consumption Time: 0.06138
Total Iteration Time: 3.02503

Cumulative Model Updates: 18,770
Cumulative Timesteps: 313,407,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 313407200...
Checkpoint 313407200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,692.76818
Policy Entropy: 0.71746
Value Function Loss: 0.05092

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01563
Policy Update Magnitude: 0.02806
Value Function Update Magnitude: 0.03343

Collected Steps per Second: 20,317.19731
Overall Steps per Second: 14,852.38726

Timestep Collection Time: 2.46235
Timestep Consumption Time: 0.90600
PPO Batch Consumption Time: 0.08749
Total Iteration Time: 3.36835

Cumulative Model Updates: 18,773
Cumulative Timesteps: 313,457,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,081.66975
Policy Entropy: 0.70460
Value Function Loss: 0.05039

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02971
Policy Update Magnitude: 0.02998
Value Function Update Magnitude: 0.03189

Collected Steps per Second: 22,550.19971
Overall Steps per Second: 16,718.46994

Timestep Collection Time: 2.21790
Timestep Consumption Time: 0.77365
PPO Batch Consumption Time: 0.05882
Total Iteration Time: 2.99154

Cumulative Model Updates: 18,776
Cumulative Timesteps: 313,507,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 313507242...
Checkpoint 313507242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,897.44840
Policy Entropy: 0.70415
Value Function Loss: 0.04803

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03689
Policy Update Magnitude: 0.02982
Value Function Update Magnitude: 0.03389

Collected Steps per Second: 23,084.55209
Overall Steps per Second: 17,600.49041

Timestep Collection Time: 2.16612
Timestep Consumption Time: 0.67493
PPO Batch Consumption Time: 0.03063
Total Iteration Time: 2.84106

Cumulative Model Updates: 18,779
Cumulative Timesteps: 313,557,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,778.28649
Policy Entropy: 0.70049
Value Function Loss: 0.04313

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.06515
Policy Update Magnitude: 0.02967
Value Function Update Magnitude: 0.03107

Collected Steps per Second: 22,336.81840
Overall Steps per Second: 15,949.21145

Timestep Collection Time: 2.23971
Timestep Consumption Time: 0.89700
PPO Batch Consumption Time: 0.08528
Total Iteration Time: 3.13671

Cumulative Model Updates: 18,782
Cumulative Timesteps: 313,607,274

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 313607274...
Checkpoint 313607274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,958.95991
Policy Entropy: 0.71238
Value Function Loss: 0.03949

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04867
Policy Update Magnitude: 0.02705
Value Function Update Magnitude: 0.02864

Collected Steps per Second: 21,413.85858
Overall Steps per Second: 16,418.58729

Timestep Collection Time: 2.33494
Timestep Consumption Time: 0.71039
PPO Batch Consumption Time: 0.03121
Total Iteration Time: 3.04533

Cumulative Model Updates: 18,785
Cumulative Timesteps: 313,657,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,602.08494
Policy Entropy: 0.70324
Value Function Loss: 0.04274

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06819
Policy Update Magnitude: 0.03005
Value Function Update Magnitude: 0.03015

Collected Steps per Second: 21,862.88161
Overall Steps per Second: 16,034.34828

Timestep Collection Time: 2.28890
Timestep Consumption Time: 0.83202
PPO Batch Consumption Time: 0.05434
Total Iteration Time: 3.12093

Cumulative Model Updates: 18,788
Cumulative Timesteps: 313,707,316

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 313707316...
Checkpoint 313707316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,571.27603
Policy Entropy: 0.71212
Value Function Loss: 0.04025

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.05155
Policy Update Magnitude: 0.03291
Value Function Update Magnitude: 0.03130

Collected Steps per Second: 18,387.46680
Overall Steps per Second: 13,275.87566

Timestep Collection Time: 2.72077
Timestep Consumption Time: 1.04757
PPO Batch Consumption Time: 0.12471
Total Iteration Time: 3.76834

Cumulative Model Updates: 18,791
Cumulative Timesteps: 313,757,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,228.76299
Policy Entropy: 0.70932
Value Function Loss: 0.04404

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05887
Policy Update Magnitude: 0.03262
Value Function Update Magnitude: 0.03201

Collected Steps per Second: 20,593.28852
Overall Steps per Second: 14,893.37791

Timestep Collection Time: 2.43002
Timestep Consumption Time: 0.93000
PPO Batch Consumption Time: 0.08852
Total Iteration Time: 3.36002

Cumulative Model Updates: 18,794
Cumulative Timesteps: 313,807,386

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 313807386...
Checkpoint 313807386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,247.47698
Policy Entropy: 0.71062
Value Function Loss: 0.04712

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03215
Policy Update Magnitude: 0.03337
Value Function Update Magnitude: 0.03112

Collected Steps per Second: 20,641.09417
Overall Steps per Second: 14,868.46964

Timestep Collection Time: 2.42410
Timestep Consumption Time: 0.94115
PPO Batch Consumption Time: 0.07437
Total Iteration Time: 3.36524

Cumulative Model Updates: 18,797
Cumulative Timesteps: 313,857,422

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,491.86761
Policy Entropy: 0.71068
Value Function Loss: 0.05350

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02979
Policy Update Magnitude: 0.02865
Value Function Update Magnitude: 0.03464

Collected Steps per Second: 18,526.53126
Overall Steps per Second: 13,734.80327

Timestep Collection Time: 2.70056
Timestep Consumption Time: 0.94216
PPO Batch Consumption Time: 0.08804
Total Iteration Time: 3.64272

Cumulative Model Updates: 18,800
Cumulative Timesteps: 313,907,454

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 313907454...
Checkpoint 313907454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,734.86750
Policy Entropy: 0.71056
Value Function Loss: 0.05345

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.03804
Value Function Update Magnitude: 0.03459

Collected Steps per Second: 22,294.79687
Overall Steps per Second: 15,723.30998

Timestep Collection Time: 2.24348
Timestep Consumption Time: 0.93765
PPO Batch Consumption Time: 0.09997
Total Iteration Time: 3.18114

Cumulative Model Updates: 18,803
Cumulative Timesteps: 313,957,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,651.99573
Policy Entropy: 0.69731
Value Function Loss: 0.05463

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02993
Policy Update Magnitude: 0.03530
Value Function Update Magnitude: 0.03785

Collected Steps per Second: 23,176.60595
Overall Steps per Second: 16,919.48670

Timestep Collection Time: 2.15743
Timestep Consumption Time: 0.79786
PPO Batch Consumption Time: 0.06113
Total Iteration Time: 2.95529

Cumulative Model Updates: 18,806
Cumulative Timesteps: 314,007,474

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 314007474...
Checkpoint 314007474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,051.42550
Policy Entropy: 0.69863
Value Function Loss: 0.04909

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04850
Policy Update Magnitude: 0.03221
Value Function Update Magnitude: 0.03658

Collected Steps per Second: 20,396.73967
Overall Steps per Second: 14,694.32847

Timestep Collection Time: 2.45196
Timestep Consumption Time: 0.95153
PPO Batch Consumption Time: 0.12719
Total Iteration Time: 3.40349

Cumulative Model Updates: 18,809
Cumulative Timesteps: 314,057,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,894.22625
Policy Entropy: 0.69346
Value Function Loss: 0.05004

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03604
Policy Update Magnitude: 0.03137
Value Function Update Magnitude: 0.03601

Collected Steps per Second: 22,553.73018
Overall Steps per Second: 16,552.81603

Timestep Collection Time: 2.21879
Timestep Consumption Time: 0.80438
PPO Batch Consumption Time: 0.07987
Total Iteration Time: 3.02317

Cumulative Model Updates: 18,812
Cumulative Timesteps: 314,107,528

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 314107528...
Checkpoint 314107528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,591.82937
Policy Entropy: 0.70987
Value Function Loss: 0.04615

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02004
Policy Update Magnitude: 0.03091
Value Function Update Magnitude: 0.03211

Collected Steps per Second: 22,129.38803
Overall Steps per Second: 16,033.91074

Timestep Collection Time: 2.26143
Timestep Consumption Time: 0.85971
PPO Batch Consumption Time: 0.10629
Total Iteration Time: 3.12113

Cumulative Model Updates: 18,815
Cumulative Timesteps: 314,157,572

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,396.31906
Policy Entropy: 0.71278
Value Function Loss: 0.04724

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.03026
Policy Update Magnitude: 0.02966
Value Function Update Magnitude: 0.03151

Collected Steps per Second: 22,515.08561
Overall Steps per Second: 16,853.72691

Timestep Collection Time: 2.22260
Timestep Consumption Time: 0.74660
PPO Batch Consumption Time: 0.06414
Total Iteration Time: 2.96919

Cumulative Model Updates: 18,818
Cumulative Timesteps: 314,207,614

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 314207614...
Checkpoint 314207614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,012.03643
Policy Entropy: 0.71913
Value Function Loss: 0.04914

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04350
Policy Update Magnitude: 0.02872
Value Function Update Magnitude: 0.02921

Collected Steps per Second: 22,155.41724
Overall Steps per Second: 16,183.18221

Timestep Collection Time: 2.25742
Timestep Consumption Time: 0.83308
PPO Batch Consumption Time: 0.06272
Total Iteration Time: 3.09049

Cumulative Model Updates: 18,821
Cumulative Timesteps: 314,257,628

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,289.93644
Policy Entropy: 0.71161
Value Function Loss: 0.04649

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03392
Policy Update Magnitude: 0.02799
Value Function Update Magnitude: 0.02795

Collected Steps per Second: 19,161.00995
Overall Steps per Second: 14,080.30231

Timestep Collection Time: 2.61041
Timestep Consumption Time: 0.94193
PPO Batch Consumption Time: 0.10657
Total Iteration Time: 3.55234

Cumulative Model Updates: 18,824
Cumulative Timesteps: 314,307,646

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 314307646...
Checkpoint 314307646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,394.91421
Policy Entropy: 0.71505
Value Function Loss: 0.04470

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03591
Policy Update Magnitude: 0.02643
Value Function Update Magnitude: 0.03100

Collected Steps per Second: 22,918.92559
Overall Steps per Second: 16,901.28132

Timestep Collection Time: 2.18291
Timestep Consumption Time: 0.77722
PPO Batch Consumption Time: 0.05869
Total Iteration Time: 2.96013

Cumulative Model Updates: 18,827
Cumulative Timesteps: 314,357,676

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,668.69064
Policy Entropy: 0.72011
Value Function Loss: 0.04766

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.02015
Policy Update Magnitude: 0.02548
Value Function Update Magnitude: 0.03445

Collected Steps per Second: 20,000.59762
Overall Steps per Second: 14,638.27805

Timestep Collection Time: 2.49993
Timestep Consumption Time: 0.91578
PPO Batch Consumption Time: 0.09661
Total Iteration Time: 3.41570

Cumulative Model Updates: 18,830
Cumulative Timesteps: 314,407,676

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 314407676...
Checkpoint 314407676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,440.20941
Policy Entropy: 0.72627
Value Function Loss: 0.04587

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01950
Policy Update Magnitude: 0.02688
Value Function Update Magnitude: 0.03082

Collected Steps per Second: 22,665.11265
Overall Steps per Second: 16,532.32541

Timestep Collection Time: 2.20753
Timestep Consumption Time: 0.81890
PPO Batch Consumption Time: 0.05872
Total Iteration Time: 3.02643

Cumulative Model Updates: 18,833
Cumulative Timesteps: 314,457,710

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,031.12202
Policy Entropy: 0.71747
Value Function Loss: 0.05066

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02190
Policy Update Magnitude: 0.02781
Value Function Update Magnitude: 0.02780

Collected Steps per Second: 19,796.09140
Overall Steps per Second: 14,100.27059

Timestep Collection Time: 2.52737
Timestep Consumption Time: 1.02093
PPO Batch Consumption Time: 0.12121
Total Iteration Time: 3.54830

Cumulative Model Updates: 18,836
Cumulative Timesteps: 314,507,742

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 314507742...
Checkpoint 314507742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,713.26002
Policy Entropy: 0.72134
Value Function Loss: 0.04377

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01935
Policy Update Magnitude: 0.02843
Value Function Update Magnitude: 0.02955

Collected Steps per Second: 22,583.63401
Overall Steps per Second: 15,714.17185

Timestep Collection Time: 2.21479
Timestep Consumption Time: 0.96820
PPO Batch Consumption Time: 0.09251
Total Iteration Time: 3.18299

Cumulative Model Updates: 18,839
Cumulative Timesteps: 314,557,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,525.51371
Policy Entropy: 0.70921
Value Function Loss: 0.05198

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.02660
Value Function Update Magnitude: 0.03330

Collected Steps per Second: 23,255.41387
Overall Steps per Second: 17,109.86834

Timestep Collection Time: 2.15072
Timestep Consumption Time: 0.77250
PPO Batch Consumption Time: 0.06181
Total Iteration Time: 2.92323

Cumulative Model Updates: 18,842
Cumulative Timesteps: 314,607,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 314607776...
Checkpoint 314607776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,587.50849
Policy Entropy: 0.71122
Value Function Loss: 0.05245

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02159
Policy Update Magnitude: 0.02721
Value Function Update Magnitude: 0.03616

Collected Steps per Second: 23,374.44563
Overall Steps per Second: 16,895.94701

Timestep Collection Time: 2.13994
Timestep Consumption Time: 0.82053
PPO Batch Consumption Time: 0.06431
Total Iteration Time: 2.96047

Cumulative Model Updates: 18,845
Cumulative Timesteps: 314,657,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,986.23331
Policy Entropy: 0.69971
Value Function Loss: 0.05423

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03165
Policy Update Magnitude: 0.02743
Value Function Update Magnitude: 0.04166

Collected Steps per Second: 23,106.92577
Overall Steps per Second: 16,224.89123

Timestep Collection Time: 2.16481
Timestep Consumption Time: 0.91824
PPO Batch Consumption Time: 0.09219
Total Iteration Time: 3.08304

Cumulative Model Updates: 18,848
Cumulative Timesteps: 314,707,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 314707818...
Checkpoint 314707818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,134.61537
Policy Entropy: 0.71594
Value Function Loss: 0.04917

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02054
Policy Update Magnitude: 0.02748
Value Function Update Magnitude: 0.04857

Collected Steps per Second: 23,034.57715
Overall Steps per Second: 16,745.37289

Timestep Collection Time: 2.17169
Timestep Consumption Time: 0.81564
PPO Batch Consumption Time: 0.05980
Total Iteration Time: 2.98733

Cumulative Model Updates: 18,851
Cumulative Timesteps: 314,757,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,094.07850
Policy Entropy: 0.71537
Value Function Loss: 0.04461

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02919
Policy Update Magnitude: 0.02713
Value Function Update Magnitude: 0.04928

Collected Steps per Second: 21,109.25841
Overall Steps per Second: 14,748.91512

Timestep Collection Time: 2.37005
Timestep Consumption Time: 1.02206
PPO Batch Consumption Time: 0.09477
Total Iteration Time: 3.39211

Cumulative Model Updates: 18,854
Cumulative Timesteps: 314,807,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 314807872...
Checkpoint 314807872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,445.38045
Policy Entropy: 0.72189
Value Function Loss: 0.04257

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02583
Policy Update Magnitude: 0.02734
Value Function Update Magnitude: 0.05776

Collected Steps per Second: 22,398.93468
Overall Steps per Second: 15,747.39298

Timestep Collection Time: 2.23332
Timestep Consumption Time: 0.94333
PPO Batch Consumption Time: 0.09735
Total Iteration Time: 3.17665

Cumulative Model Updates: 18,857
Cumulative Timesteps: 314,857,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,101.95349
Policy Entropy: 0.71302
Value Function Loss: 0.03942

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02647
Policy Update Magnitude: 0.02891
Value Function Update Magnitude: 0.05251

Collected Steps per Second: 22,880.02864
Overall Steps per Second: 16,771.27586

Timestep Collection Time: 2.18566
Timestep Consumption Time: 0.79610
PPO Batch Consumption Time: 0.05935
Total Iteration Time: 2.98176

Cumulative Model Updates: 18,860
Cumulative Timesteps: 314,907,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 314907904...
Checkpoint 314907904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,808.01322
Policy Entropy: 0.71735
Value Function Loss: 0.04545

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02881
Policy Update Magnitude: 0.02768
Value Function Update Magnitude: 0.05155

Collected Steps per Second: 20,429.73094
Overall Steps per Second: 14,745.93885

Timestep Collection Time: 2.44839
Timestep Consumption Time: 0.94373
PPO Batch Consumption Time: 0.10253
Total Iteration Time: 3.39212

Cumulative Model Updates: 18,863
Cumulative Timesteps: 314,957,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,317.65555
Policy Entropy: 0.70815
Value Function Loss: 0.04929

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.03075
Policy Update Magnitude: 0.02749
Value Function Update Magnitude: 0.04991

Collected Steps per Second: 23,181.44369
Overall Steps per Second: 15,716.72988

Timestep Collection Time: 2.15793
Timestep Consumption Time: 1.02492
PPO Batch Consumption Time: 0.11992
Total Iteration Time: 3.18285

Cumulative Model Updates: 18,866
Cumulative Timesteps: 315,007,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 315007948...
Checkpoint 315007948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,764.73765
Policy Entropy: 0.72324
Value Function Loss: 0.04587

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.04102
Policy Update Magnitude: 0.02717
Value Function Update Magnitude: 0.04821

Collected Steps per Second: 23,298.35272
Overall Steps per Second: 17,037.32775

Timestep Collection Time: 2.14633
Timestep Consumption Time: 0.78875
PPO Batch Consumption Time: 0.05935
Total Iteration Time: 2.93508

Cumulative Model Updates: 18,869
Cumulative Timesteps: 315,057,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,376.21241
Policy Entropy: 0.72016
Value Function Loss: 0.04032

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02649
Policy Update Magnitude: 0.02538
Value Function Update Magnitude: 0.04900

Collected Steps per Second: 23,679.43531
Overall Steps per Second: 17,132.28530

Timestep Collection Time: 2.11272
Timestep Consumption Time: 0.80738
PPO Batch Consumption Time: 0.06313
Total Iteration Time: 2.92010

Cumulative Model Updates: 18,872
Cumulative Timesteps: 315,107,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 315107982...
Checkpoint 315107982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,702.48369
Policy Entropy: 0.72702
Value Function Loss: 0.03528

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02161
Policy Update Magnitude: 0.02429
Value Function Update Magnitude: 0.04750

Collected Steps per Second: 20,073.94082
Overall Steps per Second: 15,111.85812

Timestep Collection Time: 2.49129
Timestep Consumption Time: 0.81803
PPO Batch Consumption Time: 0.08266
Total Iteration Time: 3.30932

Cumulative Model Updates: 18,875
Cumulative Timesteps: 315,157,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,873.88393
Policy Entropy: 0.71880
Value Function Loss: 0.04128

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01914
Policy Update Magnitude: 0.02586
Value Function Update Magnitude: 0.05024

Collected Steps per Second: 22,047.51542
Overall Steps per Second: 16,773.12059

Timestep Collection Time: 2.26828
Timestep Consumption Time: 0.71327
PPO Batch Consumption Time: 0.05977
Total Iteration Time: 2.98156

Cumulative Model Updates: 18,878
Cumulative Timesteps: 315,208,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 315208002...
Checkpoint 315208002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,601.27115
Policy Entropy: 0.70827
Value Function Loss: 0.05140

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03303
Policy Update Magnitude: 0.02719
Value Function Update Magnitude: 0.05261

Collected Steps per Second: 19,530.79548
Overall Steps per Second: 14,746.70398

Timestep Collection Time: 2.56108
Timestep Consumption Time: 0.83086
PPO Batch Consumption Time: 0.08755
Total Iteration Time: 3.39194

Cumulative Model Updates: 18,881
Cumulative Timesteps: 315,258,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,605.92468
Policy Entropy: 0.71522
Value Function Loss: 0.04950

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02072
Policy Update Magnitude: 0.02893
Value Function Update Magnitude: 0.05569

Collected Steps per Second: 22,594.59539
Overall Steps per Second: 16,616.85916

Timestep Collection Time: 2.21407
Timestep Consumption Time: 0.79649
PPO Batch Consumption Time: 0.06159
Total Iteration Time: 3.01056

Cumulative Model Updates: 18,884
Cumulative Timesteps: 315,308,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 315308048...
Checkpoint 315308048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,877.65112
Policy Entropy: 0.71739
Value Function Loss: 0.05054

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03601
Policy Update Magnitude: 0.02577
Value Function Update Magnitude: 0.06916

Collected Steps per Second: 19,402.47982
Overall Steps per Second: 14,073.26925

Timestep Collection Time: 2.57740
Timestep Consumption Time: 0.97600
PPO Batch Consumption Time: 0.11328
Total Iteration Time: 3.55340

Cumulative Model Updates: 18,887
Cumulative Timesteps: 315,358,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,038.77770
Policy Entropy: 0.71245
Value Function Loss: 0.04946

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02976
Policy Update Magnitude: 0.02610
Value Function Update Magnitude: 0.06084

Collected Steps per Second: 23,151.35225
Overall Steps per Second: 17,037.06005

Timestep Collection Time: 2.16013
Timestep Consumption Time: 0.77523
PPO Batch Consumption Time: 0.06365
Total Iteration Time: 2.93537

Cumulative Model Updates: 18,890
Cumulative Timesteps: 315,408,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 315408066...
Checkpoint 315408066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,751.25564
Policy Entropy: 0.71186
Value Function Loss: 0.05566

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.02527
Value Function Update Magnitude: 0.05813

Collected Steps per Second: 22,841.93839
Overall Steps per Second: 16,784.81955

Timestep Collection Time: 2.18913
Timestep Consumption Time: 0.78999
PPO Batch Consumption Time: 0.06639
Total Iteration Time: 2.97912

Cumulative Model Updates: 18,893
Cumulative Timesteps: 315,458,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,099.47383
Policy Entropy: 0.71026
Value Function Loss: 0.05234

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03471
Policy Update Magnitude: 0.02710
Value Function Update Magnitude: 0.06207

Collected Steps per Second: 22,801.51246
Overall Steps per Second: 16,785.69623

Timestep Collection Time: 2.19354
Timestep Consumption Time: 0.78614
PPO Batch Consumption Time: 0.06629
Total Iteration Time: 2.97968

Cumulative Model Updates: 18,896
Cumulative Timesteps: 315,508,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 315508086...
Checkpoint 315508086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,978.13883
Policy Entropy: 0.72698
Value Function Loss: 0.05038

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03799
Policy Update Magnitude: 0.02484
Value Function Update Magnitude: 0.05445

Collected Steps per Second: 22,824.99357
Overall Steps per Second: 16,581.02972

Timestep Collection Time: 2.19163
Timestep Consumption Time: 0.82531
PPO Batch Consumption Time: 0.06577
Total Iteration Time: 3.01694

Cumulative Model Updates: 18,899
Cumulative Timesteps: 315,558,110

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,211.78608
Policy Entropy: 0.72557
Value Function Loss: 0.05270

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.04009
Policy Update Magnitude: 0.02493
Value Function Update Magnitude: 0.05000

Collected Steps per Second: 23,339.71841
Overall Steps per Second: 16,955.77162

Timestep Collection Time: 2.14338
Timestep Consumption Time: 0.80700
PPO Batch Consumption Time: 0.06379
Total Iteration Time: 2.95038

Cumulative Model Updates: 18,902
Cumulative Timesteps: 315,608,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 315608136...
Checkpoint 315608136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,191.90059
Policy Entropy: 0.72572
Value Function Loss: 0.05566

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.05151
Policy Update Magnitude: 0.02980
Value Function Update Magnitude: 0.04132

Collected Steps per Second: 22,839.01463
Overall Steps per Second: 16,685.57053

Timestep Collection Time: 2.19011
Timestep Consumption Time: 0.80769
PPO Batch Consumption Time: 0.06558
Total Iteration Time: 2.99780

Cumulative Model Updates: 18,905
Cumulative Timesteps: 315,658,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,242.02627
Policy Entropy: 0.71154
Value Function Loss: 0.05413

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04469
Policy Update Magnitude: 0.02679
Value Function Update Magnitude: 0.03756

Collected Steps per Second: 23,119.78939
Overall Steps per Second: 16,724.04362

Timestep Collection Time: 2.16326
Timestep Consumption Time: 0.82729
PPO Batch Consumption Time: 0.06543
Total Iteration Time: 2.99054

Cumulative Model Updates: 18,908
Cumulative Timesteps: 315,708,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 315708170...
Checkpoint 315708170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,359.71414
Policy Entropy: 0.71460
Value Function Loss: 0.05682

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03496
Policy Update Magnitude: 0.02645
Value Function Update Magnitude: 0.03888

Collected Steps per Second: 23,278.40193
Overall Steps per Second: 16,903.72814

Timestep Collection Time: 2.14860
Timestep Consumption Time: 0.81027
PPO Batch Consumption Time: 0.06494
Total Iteration Time: 2.95887

Cumulative Model Updates: 18,911
Cumulative Timesteps: 315,758,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,081.98469
Policy Entropy: 0.71492
Value Function Loss: 0.05460

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05221
Policy Update Magnitude: 0.03008
Value Function Update Magnitude: 0.04512

Collected Steps per Second: 22,922.72542
Overall Steps per Second: 16,166.34865

Timestep Collection Time: 2.18159
Timestep Consumption Time: 0.91175
PPO Batch Consumption Time: 0.08835
Total Iteration Time: 3.09334

Cumulative Model Updates: 18,914
Cumulative Timesteps: 315,808,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 315808194...
Checkpoint 315808194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,813.85590
Policy Entropy: 0.72086
Value Function Loss: 0.05212

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05413
Policy Update Magnitude: 0.02846
Value Function Update Magnitude: 0.06356

Collected Steps per Second: 22,625.53741
Overall Steps per Second: 16,426.83233

Timestep Collection Time: 2.21113
Timestep Consumption Time: 0.83438
PPO Batch Consumption Time: 0.06331
Total Iteration Time: 3.04551

Cumulative Model Updates: 18,917
Cumulative Timesteps: 315,858,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,615.27564
Policy Entropy: 0.72431
Value Function Loss: 0.04836

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05561
Policy Update Magnitude: 0.02884
Value Function Update Magnitude: 0.06919

Collected Steps per Second: 20,385.88328
Overall Steps per Second: 14,957.79800

Timestep Collection Time: 2.45356
Timestep Consumption Time: 0.89038
PPO Batch Consumption Time: 0.07880
Total Iteration Time: 3.34394

Cumulative Model Updates: 18,920
Cumulative Timesteps: 315,908,240

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 315908240...
Checkpoint 315908240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,482.95368
Policy Entropy: 0.71455
Value Function Loss: 0.04837

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02741
Policy Update Magnitude: 0.02696
Value Function Update Magnitude: 0.07509

Collected Steps per Second: 22,973.06241
Overall Steps per Second: 16,820.54167

Timestep Collection Time: 2.17733
Timestep Consumption Time: 0.79641
PPO Batch Consumption Time: 0.05821
Total Iteration Time: 2.97374

Cumulative Model Updates: 18,923
Cumulative Timesteps: 315,958,260

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,089.32639
Policy Entropy: 0.71396
Value Function Loss: 0.04674

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01753
Policy Update Magnitude: 0.02536
Value Function Update Magnitude: 0.08369

Collected Steps per Second: 18,425.89806
Overall Steps per Second: 13,230.49497

Timestep Collection Time: 2.71422
Timestep Consumption Time: 1.06583
PPO Batch Consumption Time: 0.11234
Total Iteration Time: 3.78006

Cumulative Model Updates: 18,926
Cumulative Timesteps: 316,008,272

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 316008272...
Checkpoint 316008272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,105.66079
Policy Entropy: 0.71904
Value Function Loss: 0.04306

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02152
Policy Update Magnitude: 0.02476
Value Function Update Magnitude: 0.07922

Collected Steps per Second: 22,944.39596
Overall Steps per Second: 16,790.15654

Timestep Collection Time: 2.18014
Timestep Consumption Time: 0.79911
PPO Batch Consumption Time: 0.05908
Total Iteration Time: 2.97925

Cumulative Model Updates: 18,929
Cumulative Timesteps: 316,058,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,123.42742
Policy Entropy: 0.71770
Value Function Loss: 0.04393

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01910
Policy Update Magnitude: 0.02585
Value Function Update Magnitude: 0.07387

Collected Steps per Second: 20,372.91180
Overall Steps per Second: 14,704.49765

Timestep Collection Time: 2.45444
Timestep Consumption Time: 0.94616
PPO Batch Consumption Time: 0.09716
Total Iteration Time: 3.40059

Cumulative Model Updates: 18,932
Cumulative Timesteps: 316,108,298

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 316108298...
Checkpoint 316108298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,056.51561
Policy Entropy: 0.71636
Value Function Loss: 0.05175

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.02538
Value Function Update Magnitude: 0.07114

Collected Steps per Second: 22,618.21973
Overall Steps per Second: 15,724.68154

Timestep Collection Time: 2.21087
Timestep Consumption Time: 0.96922
PPO Batch Consumption Time: 0.10360
Total Iteration Time: 3.18010

Cumulative Model Updates: 18,935
Cumulative Timesteps: 316,158,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,612.08320
Policy Entropy: 0.71089
Value Function Loss: 0.05451

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.01938
Policy Update Magnitude: 0.02708
Value Function Update Magnitude: 0.07087

Collected Steps per Second: 23,129.63504
Overall Steps per Second: 16,864.34740

Timestep Collection Time: 2.16251
Timestep Consumption Time: 0.80339
PPO Batch Consumption Time: 0.06253
Total Iteration Time: 2.96590

Cumulative Model Updates: 18,938
Cumulative Timesteps: 316,208,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 316208322...
Checkpoint 316208322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,953.73377
Policy Entropy: 0.71118
Value Function Loss: 0.05672

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02973
Policy Update Magnitude: 0.02839
Value Function Update Magnitude: 0.06177

Collected Steps per Second: 20,894.19049
Overall Steps per Second: 14,728.49104

Timestep Collection Time: 2.39406
Timestep Consumption Time: 1.00221
PPO Batch Consumption Time: 0.12433
Total Iteration Time: 3.39627

Cumulative Model Updates: 18,941
Cumulative Timesteps: 316,258,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,003.73009
Policy Entropy: 0.71724
Value Function Loss: 0.04767

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03284
Policy Update Magnitude: 0.03008
Value Function Update Magnitude: 0.05449

Collected Steps per Second: 22,843.51852
Overall Steps per Second: 15,641.29986

Timestep Collection Time: 2.19003
Timestep Consumption Time: 1.00842
PPO Batch Consumption Time: 0.11874
Total Iteration Time: 3.19846

Cumulative Model Updates: 18,944
Cumulative Timesteps: 316,308,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 316308372...
Checkpoint 316308372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,400.84645
Policy Entropy: 0.71946
Value Function Loss: 0.04268

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.02853
Value Function Update Magnitude: 0.04782

Collected Steps per Second: 23,228.20058
Overall Steps per Second: 16,942.25499

Timestep Collection Time: 2.15290
Timestep Consumption Time: 0.79877
PPO Batch Consumption Time: 0.05954
Total Iteration Time: 2.95167

Cumulative Model Updates: 18,947
Cumulative Timesteps: 316,358,380

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,082.86610
Policy Entropy: 0.71765
Value Function Loss: 0.04459

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03683
Policy Update Magnitude: 0.02895
Value Function Update Magnitude: 0.04451

Collected Steps per Second: 23,488.01923
Overall Steps per Second: 16,943.82234

Timestep Collection Time: 2.12917
Timestep Consumption Time: 0.82235
PPO Batch Consumption Time: 0.06454
Total Iteration Time: 2.95152

Cumulative Model Updates: 18,950
Cumulative Timesteps: 316,408,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 316408390...
Checkpoint 316408390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,879.25349
Policy Entropy: 0.71754
Value Function Loss: 0.04414

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05879
Policy Update Magnitude: 0.02949
Value Function Update Magnitude: 0.05077

Collected Steps per Second: 22,944.46153
Overall Steps per Second: 16,743.08743

Timestep Collection Time: 2.17926
Timestep Consumption Time: 0.80716
PPO Batch Consumption Time: 0.06401
Total Iteration Time: 2.98643

Cumulative Model Updates: 18,953
Cumulative Timesteps: 316,458,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,126.24467
Policy Entropy: 0.71591
Value Function Loss: 0.04591

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06767
Policy Update Magnitude: 0.03050
Value Function Update Magnitude: 0.05418

Collected Steps per Second: 22,302.72614
Overall Steps per Second: 16,807.42097

Timestep Collection Time: 2.24188
Timestep Consumption Time: 0.73300
PPO Batch Consumption Time: 0.06399
Total Iteration Time: 2.97488

Cumulative Model Updates: 18,956
Cumulative Timesteps: 316,508,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 316508392...
Checkpoint 316508392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,557.13295
Policy Entropy: 0.71643
Value Function Loss: 0.03918

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.05536
Policy Update Magnitude: 0.03024
Value Function Update Magnitude: 0.04792

Collected Steps per Second: 22,520.40946
Overall Steps per Second: 16,875.93355

Timestep Collection Time: 2.22127
Timestep Consumption Time: 0.74295
PPO Batch Consumption Time: 0.06295
Total Iteration Time: 2.96422

Cumulative Model Updates: 18,959
Cumulative Timesteps: 316,558,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,087.78179
Policy Entropy: 0.70652
Value Function Loss: 0.05019

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.06050
Policy Update Magnitude: 0.02954
Value Function Update Magnitude: 0.04426

Collected Steps per Second: 20,991.54444
Overall Steps per Second: 15,134.14300

Timestep Collection Time: 2.38210
Timestep Consumption Time: 0.92195
PPO Batch Consumption Time: 0.09858
Total Iteration Time: 3.30405

Cumulative Model Updates: 18,962
Cumulative Timesteps: 316,608,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 316608420...
Checkpoint 316608420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,946.13558
Policy Entropy: 0.70573
Value Function Loss: 0.04998

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02832
Policy Update Magnitude: 0.02866
Value Function Update Magnitude: 0.04158

Collected Steps per Second: 22,081.19063
Overall Steps per Second: 16,771.73875

Timestep Collection Time: 2.26491
Timestep Consumption Time: 0.71701
PPO Batch Consumption Time: 0.05882
Total Iteration Time: 2.98192

Cumulative Model Updates: 18,965
Cumulative Timesteps: 316,658,432

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,783.05573
Policy Entropy: 0.69774
Value Function Loss: 0.05286

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02901
Policy Update Magnitude: 0.03075
Value Function Update Magnitude: 0.05223

Collected Steps per Second: 20,378.97194
Overall Steps per Second: 14,738.02561

Timestep Collection Time: 2.45390
Timestep Consumption Time: 0.93923
PPO Batch Consumption Time: 0.10163
Total Iteration Time: 3.39313

Cumulative Model Updates: 18,968
Cumulative Timesteps: 316,708,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 316708440...
Checkpoint 316708440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,780.85371
Policy Entropy: 0.70899
Value Function Loss: 0.04978

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01565
Policy Update Magnitude: 0.03320
Value Function Update Magnitude: 0.04926

Collected Steps per Second: 22,655.75035
Overall Steps per Second: 16,751.72405

Timestep Collection Time: 2.20703
Timestep Consumption Time: 0.77785
PPO Batch Consumption Time: 0.05895
Total Iteration Time: 2.98489

Cumulative Model Updates: 18,971
Cumulative Timesteps: 316,758,442

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,757.58215
Policy Entropy: 0.71169
Value Function Loss: 0.05101

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01921
Policy Update Magnitude: 0.03349
Value Function Update Magnitude: 0.05461

Collected Steps per Second: 19,803.10163
Overall Steps per Second: 14,739.24674

Timestep Collection Time: 2.52506
Timestep Consumption Time: 0.86752
PPO Batch Consumption Time: 0.08327
Total Iteration Time: 3.39258

Cumulative Model Updates: 18,974
Cumulative Timesteps: 316,808,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 316808446...
Checkpoint 316808446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,106.51692
Policy Entropy: 0.71799
Value Function Loss: 0.04688

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02612
Policy Update Magnitude: 0.03116
Value Function Update Magnitude: 0.05290

Collected Steps per Second: 22,970.47343
Overall Steps per Second: 15,746.38788

Timestep Collection Time: 2.17732
Timestep Consumption Time: 0.99890
PPO Batch Consumption Time: 0.10933
Total Iteration Time: 3.17622

Cumulative Model Updates: 18,977
Cumulative Timesteps: 316,858,460

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,413.72451
Policy Entropy: 0.72173
Value Function Loss: 0.04201

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04515
Policy Update Magnitude: 0.02920
Value Function Update Magnitude: 0.06037

Collected Steps per Second: 23,445.07026
Overall Steps per Second: 17,257.59723

Timestep Collection Time: 2.13273
Timestep Consumption Time: 0.76466
PPO Batch Consumption Time: 0.06219
Total Iteration Time: 2.89739

Cumulative Model Updates: 18,980
Cumulative Timesteps: 316,908,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 316908462...
Checkpoint 316908462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,360.20443
Policy Entropy: 0.70586
Value Function Loss: 0.04178

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04982
Policy Update Magnitude: 0.02737
Value Function Update Magnitude: 0.06021

Collected Steps per Second: 20,770.11853
Overall Steps per Second: 15,186.90521

Timestep Collection Time: 2.40865
Timestep Consumption Time: 0.88550
PPO Batch Consumption Time: 0.08077
Total Iteration Time: 3.29415

Cumulative Model Updates: 18,983
Cumulative Timesteps: 316,958,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,564.98806
Policy Entropy: 0.70946
Value Function Loss: 0.05054

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.06146
Policy Update Magnitude: 0.02801
Value Function Update Magnitude: 0.06497

Collected Steps per Second: 22,982.10396
Overall Steps per Second: 16,733.25512

Timestep Collection Time: 2.17648
Timestep Consumption Time: 0.81278
PPO Batch Consumption Time: 0.05926
Total Iteration Time: 2.98926

Cumulative Model Updates: 18,986
Cumulative Timesteps: 317,008,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 317008510...
Checkpoint 317008510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,632.94149
Policy Entropy: 0.70375
Value Function Loss: 0.05428

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04417
Policy Update Magnitude: 0.02884
Value Function Update Magnitude: 0.06470

Collected Steps per Second: 20,564.17973
Overall Steps per Second: 14,825.95859

Timestep Collection Time: 2.43258
Timestep Consumption Time: 0.94150
PPO Batch Consumption Time: 0.09493
Total Iteration Time: 3.37408

Cumulative Model Updates: 18,989
Cumulative Timesteps: 317,058,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,110.15253
Policy Entropy: 0.71624
Value Function Loss: 0.05602

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.05296
Policy Update Magnitude: 0.02652
Value Function Update Magnitude: 0.05959

Collected Steps per Second: 23,123.14589
Overall Steps per Second: 16,828.66344

Timestep Collection Time: 2.16277
Timestep Consumption Time: 0.80895
PPO Batch Consumption Time: 0.05954
Total Iteration Time: 2.97172

Cumulative Model Updates: 18,992
Cumulative Timesteps: 317,108,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 317108544...
Checkpoint 317108544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,865.91457
Policy Entropy: 0.71407
Value Function Loss: 0.05634

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03183
Policy Update Magnitude: 0.02894
Value Function Update Magnitude: 0.06044

Collected Steps per Second: 20,347.82030
Overall Steps per Second: 14,677.69973

Timestep Collection Time: 2.45786
Timestep Consumption Time: 0.94949
PPO Batch Consumption Time: 0.09734
Total Iteration Time: 3.40735

Cumulative Model Updates: 18,995
Cumulative Timesteps: 317,158,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,091.41391
Policy Entropy: 0.70966
Value Function Loss: 0.06838

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02635
Policy Update Magnitude: 0.03113
Value Function Update Magnitude: 0.06592

Collected Steps per Second: 22,795.49383
Overall Steps per Second: 15,751.24073

Timestep Collection Time: 2.19447
Timestep Consumption Time: 0.98141
PPO Batch Consumption Time: 0.11932
Total Iteration Time: 3.17588

Cumulative Model Updates: 18,998
Cumulative Timesteps: 317,208,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 317208580...
Checkpoint 317208580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,858.85128
Policy Entropy: 0.70926
Value Function Loss: 0.06691

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02637
Policy Update Magnitude: 0.03373
Value Function Update Magnitude: 0.06972

Collected Steps per Second: 23,492.96195
Overall Steps per Second: 17,006.69748

Timestep Collection Time: 2.12915
Timestep Consumption Time: 0.81205
PPO Batch Consumption Time: 0.06162
Total Iteration Time: 2.94119

Cumulative Model Updates: 19,001
Cumulative Timesteps: 317,258,600

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,671.64375
Policy Entropy: 0.72381
Value Function Loss: 0.06258

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03719
Policy Update Magnitude: 0.03589
Value Function Update Magnitude: 0.06521

Collected Steps per Second: 23,535.18241
Overall Steps per Second: 16,999.34679

Timestep Collection Time: 2.12516
Timestep Consumption Time: 0.81707
PPO Batch Consumption Time: 0.06333
Total Iteration Time: 2.94223

Cumulative Model Updates: 19,004
Cumulative Timesteps: 317,308,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 317308616...
Checkpoint 317308616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,601.30993
Policy Entropy: 0.72319
Value Function Loss: 0.05334

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03835
Policy Update Magnitude: 0.03399
Value Function Update Magnitude: 0.06644

Collected Steps per Second: 22,673.65280
Overall Steps per Second: 16,159.40482

Timestep Collection Time: 2.20538
Timestep Consumption Time: 0.88904
PPO Batch Consumption Time: 0.08406
Total Iteration Time: 3.09442

Cumulative Model Updates: 19,007
Cumulative Timesteps: 317,358,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,080.49414
Policy Entropy: 0.73433
Value Function Loss: 0.05249

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03758
Policy Update Magnitude: 0.03072
Value Function Update Magnitude: 0.06762

Collected Steps per Second: 22,704.91994
Overall Steps per Second: 16,455.79783

Timestep Collection Time: 2.20269
Timestep Consumption Time: 0.83648
PPO Batch Consumption Time: 0.06407
Total Iteration Time: 3.03917

Cumulative Model Updates: 19,010
Cumulative Timesteps: 317,408,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 317408632...
Checkpoint 317408632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,050.49954
Policy Entropy: 0.72164
Value Function Loss: 0.05945

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03107
Policy Update Magnitude: 0.02956
Value Function Update Magnitude: 0.06480

Collected Steps per Second: 19,603.45811
Overall Steps per Second: 14,215.00762

Timestep Collection Time: 2.55057
Timestep Consumption Time: 0.96684
PPO Batch Consumption Time: 0.10419
Total Iteration Time: 3.51741

Cumulative Model Updates: 19,013
Cumulative Timesteps: 317,458,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,856.73131
Policy Entropy: 0.72733
Value Function Loss: 0.06244

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03843
Policy Update Magnitude: 0.03143
Value Function Update Magnitude: 0.06634

Collected Steps per Second: 23,176.78865
Overall Steps per Second: 16,860.43920

Timestep Collection Time: 2.15733
Timestep Consumption Time: 0.80819
PPO Batch Consumption Time: 0.05940
Total Iteration Time: 2.96552

Cumulative Model Updates: 19,016
Cumulative Timesteps: 317,508,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 317508632...
Checkpoint 317508632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,355.50384
Policy Entropy: 0.71154
Value Function Loss: 0.06904

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.03331
Value Function Update Magnitude: 0.07047

Collected Steps per Second: 20,855.52709
Overall Steps per Second: 14,694.80420

Timestep Collection Time: 2.39745
Timestep Consumption Time: 1.00512
PPO Batch Consumption Time: 0.12081
Total Iteration Time: 3.40256

Cumulative Model Updates: 19,019
Cumulative Timesteps: 317,558,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,849.01716
Policy Entropy: 0.71935
Value Function Loss: 0.05817

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05491
Policy Update Magnitude: 0.03186
Value Function Update Magnitude: 0.07926

Collected Steps per Second: 23,409.87754
Overall Steps per Second: 16,581.50303

Timestep Collection Time: 2.13696
Timestep Consumption Time: 0.88002
PPO Batch Consumption Time: 0.07584
Total Iteration Time: 3.01698

Cumulative Model Updates: 19,022
Cumulative Timesteps: 317,608,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 317608658...
Checkpoint 317608658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,792.32538
Policy Entropy: 0.71430
Value Function Loss: 0.04894

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04357
Policy Update Magnitude: 0.03102
Value Function Update Magnitude: 0.08074

Collected Steps per Second: 23,081.54285
Overall Steps per Second: 15,844.05577

Timestep Collection Time: 2.16727
Timestep Consumption Time: 0.99000
PPO Batch Consumption Time: 0.11753
Total Iteration Time: 3.15727

Cumulative Model Updates: 19,025
Cumulative Timesteps: 317,658,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,617.61463
Policy Entropy: 0.72708
Value Function Loss: 0.04121

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05899
Policy Update Magnitude: 0.02995
Value Function Update Magnitude: 0.07209

Collected Steps per Second: 22,713.53577
Overall Steps per Second: 16,409.55058

Timestep Collection Time: 2.20292
Timestep Consumption Time: 0.84628
PPO Batch Consumption Time: 0.06166
Total Iteration Time: 3.04920

Cumulative Model Updates: 19,028
Cumulative Timesteps: 317,708,718

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 317708718...
Checkpoint 317708718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,480.39512
Policy Entropy: 0.72193
Value Function Loss: 0.04423

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.05126
Policy Update Magnitude: 0.02743
Value Function Update Magnitude: 0.05831

Collected Steps per Second: 18,287.46984
Overall Steps per Second: 14,084.12463

Timestep Collection Time: 2.73444
Timestep Consumption Time: 0.81608
PPO Batch Consumption Time: 0.07657
Total Iteration Time: 3.55052

Cumulative Model Updates: 19,031
Cumulative Timesteps: 317,758,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,091.23903
Policy Entropy: 0.73013
Value Function Loss: 0.04837

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04460
Policy Update Magnitude: 0.02607
Value Function Update Magnitude: 0.05477

Collected Steps per Second: 22,355.62795
Overall Steps per Second: 16,951.08711

Timestep Collection Time: 2.23675
Timestep Consumption Time: 0.71315
PPO Batch Consumption Time: 0.06013
Total Iteration Time: 2.94990

Cumulative Model Updates: 19,034
Cumulative Timesteps: 317,808,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 317808728...
Checkpoint 317808728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,888.03601
Policy Entropy: 0.72850
Value Function Loss: 0.04699

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01769
Policy Update Magnitude: 0.02735
Value Function Update Magnitude: 0.06058

Collected Steps per Second: 20,133.50020
Overall Steps per Second: 14,710.32062

Timestep Collection Time: 2.48362
Timestep Consumption Time: 0.91562
PPO Batch Consumption Time: 0.11167
Total Iteration Time: 3.39925

Cumulative Model Updates: 19,037
Cumulative Timesteps: 317,858,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,702.84118
Policy Entropy: 0.73549
Value Function Loss: 0.04329

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02923
Policy Update Magnitude: 0.02575
Value Function Update Magnitude: 0.05992

Collected Steps per Second: 22,385.66387
Overall Steps per Second: 16,419.46857

Timestep Collection Time: 2.23429
Timestep Consumption Time: 0.81185
PPO Batch Consumption Time: 0.08221
Total Iteration Time: 3.04614

Cumulative Model Updates: 19,040
Cumulative Timesteps: 317,908,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 317908748...
Checkpoint 317908748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,854.57075
Policy Entropy: 0.73247
Value Function Loss: 0.04392

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03838
Policy Update Magnitude: 0.02484
Value Function Update Magnitude: 0.05607

Collected Steps per Second: 21,318.47612
Overall Steps per Second: 15,040.74508

Timestep Collection Time: 2.34538
Timestep Consumption Time: 0.97892
PPO Batch Consumption Time: 0.11906
Total Iteration Time: 3.32430

Cumulative Model Updates: 19,043
Cumulative Timesteps: 317,958,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,010.42316
Policy Entropy: 0.73857
Value Function Loss: 0.04629

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02942
Policy Update Magnitude: 0.02465
Value Function Update Magnitude: 0.05354

Collected Steps per Second: 23,067.56571
Overall Steps per Second: 16,771.72772

Timestep Collection Time: 2.16867
Timestep Consumption Time: 0.81408
PPO Batch Consumption Time: 0.05900
Total Iteration Time: 2.98276

Cumulative Model Updates: 19,046
Cumulative Timesteps: 318,008,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 318008774...
Checkpoint 318008774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,683.87557
Policy Entropy: 0.72887
Value Function Loss: 0.04921

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02945
Policy Update Magnitude: 0.02602
Value Function Update Magnitude: 0.04909

Collected Steps per Second: 16,890.73070
Overall Steps per Second: 13,226.31171

Timestep Collection Time: 2.96032
Timestep Consumption Time: 0.82017
PPO Batch Consumption Time: 0.04801
Total Iteration Time: 3.78049

Cumulative Model Updates: 19,049
Cumulative Timesteps: 318,058,776

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,920.44974
Policy Entropy: 0.72758
Value Function Loss: 0.05405

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02599
Policy Update Magnitude: 0.02802
Value Function Update Magnitude: 0.05100

Collected Steps per Second: 18,577.56249
Overall Steps per Second: 13,855.60038

Timestep Collection Time: 2.69303
Timestep Consumption Time: 0.91778
PPO Batch Consumption Time: 0.09006
Total Iteration Time: 3.61081

Cumulative Model Updates: 19,052
Cumulative Timesteps: 318,108,806

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 318108806...
Checkpoint 318108806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,197.14331
Policy Entropy: 0.72824
Value Function Loss: 0.04804

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01809
Policy Update Magnitude: 0.02803
Value Function Update Magnitude: 0.04752

Collected Steps per Second: 20,982.72009
Overall Steps per Second: 14,769.02143

Timestep Collection Time: 2.38368
Timestep Consumption Time: 1.00287
PPO Batch Consumption Time: 0.10856
Total Iteration Time: 3.38655

Cumulative Model Updates: 19,055
Cumulative Timesteps: 318,158,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,582.39940
Policy Entropy: 0.72621
Value Function Loss: 0.04550

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.02735
Value Function Update Magnitude: 0.05066

Collected Steps per Second: 18,893.84403
Overall Steps per Second: 14,663.17223

Timestep Collection Time: 2.64753
Timestep Consumption Time: 0.76387
PPO Batch Consumption Time: 0.02996
Total Iteration Time: 3.41140

Cumulative Model Updates: 19,058
Cumulative Timesteps: 318,208,844

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 318208844...
Checkpoint 318208844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,251.88786
Policy Entropy: 0.72480
Value Function Loss: 0.04353

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03540
Policy Update Magnitude: 0.02731
Value Function Update Magnitude: 0.04664

Collected Steps per Second: 21,538.24677
Overall Steps per Second: 15,631.19724

Timestep Collection Time: 2.32238
Timestep Consumption Time: 0.87763
PPO Batch Consumption Time: 0.07913
Total Iteration Time: 3.20001

Cumulative Model Updates: 19,061
Cumulative Timesteps: 318,258,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,177.51510
Policy Entropy: 0.72521
Value Function Loss: 0.04219

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04788
Policy Update Magnitude: 0.02634
Value Function Update Magnitude: 0.04787

Collected Steps per Second: 21,981.43688
Overall Steps per Second: 15,676.28976

Timestep Collection Time: 2.27574
Timestep Consumption Time: 0.91532
PPO Batch Consumption Time: 0.03169
Total Iteration Time: 3.19106

Cumulative Model Updates: 19,064
Cumulative Timesteps: 318,308,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 318308888...
Checkpoint 318308888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,867.01189
Policy Entropy: 0.72277
Value Function Loss: 0.04464

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04295
Policy Update Magnitude: 0.02710
Value Function Update Magnitude: 0.04452

Collected Steps per Second: 22,554.54627
Overall Steps per Second: 16,886.67307

Timestep Collection Time: 2.21809
Timestep Consumption Time: 0.74448
PPO Batch Consumption Time: 0.03051
Total Iteration Time: 2.96257

Cumulative Model Updates: 19,067
Cumulative Timesteps: 318,358,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,515.93867
Policy Entropy: 0.73005
Value Function Loss: 0.03874

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02987
Policy Update Magnitude: 0.02876
Value Function Update Magnitude: 0.04991

Collected Steps per Second: 22,442.82568
Overall Steps per Second: 15,987.55218

Timestep Collection Time: 2.22815
Timestep Consumption Time: 0.89966
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 3.12781

Cumulative Model Updates: 19,070
Cumulative Timesteps: 318,408,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 318408922...
Checkpoint 318408922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,560.14169
Policy Entropy: 0.72830
Value Function Loss: 0.04029

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03731
Policy Update Magnitude: 0.02749
Value Function Update Magnitude: 0.05101

Collected Steps per Second: 19,427.56769
Overall Steps per Second: 14,547.21284

Timestep Collection Time: 2.57438
Timestep Consumption Time: 0.86366
PPO Batch Consumption Time: 0.03053
Total Iteration Time: 3.43805

Cumulative Model Updates: 19,073
Cumulative Timesteps: 318,458,936

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,935.54114
Policy Entropy: 0.73063
Value Function Loss: 0.04590

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01289
Policy Update Magnitude: 0.02566
Value Function Update Magnitude: 0.04779

Collected Steps per Second: 23,683.41685
Overall Steps per Second: 17,705.75344

Timestep Collection Time: 2.11144
Timestep Consumption Time: 0.71284
PPO Batch Consumption Time: 0.02980
Total Iteration Time: 2.82428

Cumulative Model Updates: 19,076
Cumulative Timesteps: 318,508,942

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 318508942...
Checkpoint 318508942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,169.07400
Policy Entropy: 0.72453
Value Function Loss: 0.04660

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01610
Policy Update Magnitude: 0.02813
Value Function Update Magnitude: 0.06021

Collected Steps per Second: 22,899.54211
Overall Steps per Second: 15,985.96743

Timestep Collection Time: 2.18397
Timestep Consumption Time: 0.94452
PPO Batch Consumption Time: 0.10405
Total Iteration Time: 3.12849

Cumulative Model Updates: 19,079
Cumulative Timesteps: 318,558,954

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,207.03919
Policy Entropy: 0.71762
Value Function Loss: 0.05607

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02209
Policy Update Magnitude: 0.03031
Value Function Update Magnitude: 0.05533

Collected Steps per Second: 22,965.74925
Overall Steps per Second: 15,711.40377

Timestep Collection Time: 2.17768
Timestep Consumption Time: 1.00549
PPO Batch Consumption Time: 0.11637
Total Iteration Time: 3.18317

Cumulative Model Updates: 19,082
Cumulative Timesteps: 318,608,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 318608966...
Checkpoint 318608966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,346.84614
Policy Entropy: 0.70457
Value Function Loss: 0.05426

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01932
Policy Update Magnitude: 0.02987
Value Function Update Magnitude: 0.04887

Collected Steps per Second: 23,576.75471
Overall Steps per Second: 17,717.17120

Timestep Collection Time: 2.12268
Timestep Consumption Time: 0.70203
PPO Batch Consumption Time: 0.03034
Total Iteration Time: 2.82472

Cumulative Model Updates: 19,085
Cumulative Timesteps: 318,659,012

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,422.41523
Policy Entropy: 0.70478
Value Function Loss: 0.05742

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04349
Policy Update Magnitude: 0.02857
Value Function Update Magnitude: 0.04774

Collected Steps per Second: 22,900.21078
Overall Steps per Second: 16,854.47213

Timestep Collection Time: 2.18408
Timestep Consumption Time: 0.78344
PPO Batch Consumption Time: 0.05075
Total Iteration Time: 2.96752

Cumulative Model Updates: 19,088
Cumulative Timesteps: 318,709,028

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 318709028...
Checkpoint 318709028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,308.73568
Policy Entropy: 0.71566
Value Function Loss: 0.05024

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02563
Policy Update Magnitude: 0.02694
Value Function Update Magnitude: 0.05484

Collected Steps per Second: 20,691.51712
Overall Steps per Second: 14,606.09651

Timestep Collection Time: 2.41645
Timestep Consumption Time: 1.00678
PPO Batch Consumption Time: 0.10530
Total Iteration Time: 3.42323

Cumulative Model Updates: 19,091
Cumulative Timesteps: 318,759,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,774.53811
Policy Entropy: 0.73661
Value Function Loss: 0.04731

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02169
Policy Update Magnitude: 0.02669
Value Function Update Magnitude: 0.04678

Collected Steps per Second: 23,910.16311
Overall Steps per Second: 17,209.42501

Timestep Collection Time: 2.09175
Timestep Consumption Time: 0.81445
PPO Batch Consumption Time: 0.06318
Total Iteration Time: 2.90620

Cumulative Model Updates: 19,094
Cumulative Timesteps: 318,809,042

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 318809042...
Checkpoint 318809042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,896.50074
Policy Entropy: 0.74074
Value Function Loss: 0.04488

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01967
Policy Update Magnitude: 0.02776
Value Function Update Magnitude: 0.04856

Collected Steps per Second: 22,614.03420
Overall Steps per Second: 16,484.50236

Timestep Collection Time: 2.21128
Timestep Consumption Time: 0.82223
PPO Batch Consumption Time: 0.08783
Total Iteration Time: 3.03352

Cumulative Model Updates: 19,097
Cumulative Timesteps: 318,859,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,928.69091
Policy Entropy: 0.74120
Value Function Loss: 0.04263

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02817
Policy Update Magnitude: 0.02634
Value Function Update Magnitude: 0.05030

Collected Steps per Second: 20,089.53377
Overall Steps per Second: 15,360.71516

Timestep Collection Time: 2.48985
Timestep Consumption Time: 0.76651
PPO Batch Consumption Time: 0.05802
Total Iteration Time: 3.25636

Cumulative Model Updates: 19,100
Cumulative Timesteps: 318,909,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 318909068...
Checkpoint 318909068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,436.18361
Policy Entropy: 0.73837
Value Function Loss: 0.04465

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02545
Policy Update Magnitude: 0.02665
Value Function Update Magnitude: 0.05427

Collected Steps per Second: 20,232.16015
Overall Steps per Second: 15,087.03050

Timestep Collection Time: 2.47210
Timestep Consumption Time: 0.84306
PPO Batch Consumption Time: 0.09161
Total Iteration Time: 3.31517

Cumulative Model Updates: 19,103
Cumulative Timesteps: 318,959,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,736.95327
Policy Entropy: 0.74086
Value Function Loss: 0.04887

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03432
Policy Update Magnitude: 0.02464
Value Function Update Magnitude: 0.04851

Collected Steps per Second: 22,358.17921
Overall Steps per Second: 16,621.63506

Timestep Collection Time: 2.23757
Timestep Consumption Time: 0.77224
PPO Batch Consumption Time: 0.06136
Total Iteration Time: 3.00981

Cumulative Model Updates: 19,106
Cumulative Timesteps: 319,009,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 319009112...
Checkpoint 319009112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,187.03222
Policy Entropy: 0.73354
Value Function Loss: 0.04879

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05047
Policy Update Magnitude: 0.02497
Value Function Update Magnitude: 0.05181

Collected Steps per Second: 20,723.95781
Overall Steps per Second: 14,909.53144

Timestep Collection Time: 2.41325
Timestep Consumption Time: 0.94112
PPO Batch Consumption Time: 0.11171
Total Iteration Time: 3.35436

Cumulative Model Updates: 19,109
Cumulative Timesteps: 319,059,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,870.29101
Policy Entropy: 0.73390
Value Function Loss: 0.05567

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.05007
Policy Update Magnitude: 0.02533
Value Function Update Magnitude: 0.05125

Collected Steps per Second: 23,044.74991
Overall Steps per Second: 16,835.11600

Timestep Collection Time: 2.17030
Timestep Consumption Time: 0.80052
PPO Batch Consumption Time: 0.06239
Total Iteration Time: 2.97081

Cumulative Model Updates: 19,112
Cumulative Timesteps: 319,109,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 319109138...
Checkpoint 319109138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,403.69038
Policy Entropy: 0.73554
Value Function Loss: 0.05304

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04758
Policy Update Magnitude: 0.02632
Value Function Update Magnitude: 0.05097

Collected Steps per Second: 20,758.45003
Overall Steps per Second: 14,700.47064

Timestep Collection Time: 2.40933
Timestep Consumption Time: 0.99287
PPO Batch Consumption Time: 0.11738
Total Iteration Time: 3.40220

Cumulative Model Updates: 19,115
Cumulative Timesteps: 319,159,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,773.49007
Policy Entropy: 0.73907
Value Function Loss: 0.05994

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03385
Policy Update Magnitude: 0.02707
Value Function Update Magnitude: 0.04560

Collected Steps per Second: 20,169.93938
Overall Steps per Second: 14,673.33612

Timestep Collection Time: 2.48023
Timestep Consumption Time: 0.92909
PPO Batch Consumption Time: 0.10001
Total Iteration Time: 3.40931

Cumulative Model Updates: 19,118
Cumulative Timesteps: 319,209,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 319209178...
Checkpoint 319209178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,902.58125
Policy Entropy: 0.73724
Value Function Loss: 0.05201

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04721
Policy Update Magnitude: 0.02731
Value Function Update Magnitude: 0.04757

Collected Steps per Second: 21,891.83797
Overall Steps per Second: 16,086.45953

Timestep Collection Time: 2.28514
Timestep Consumption Time: 0.82468
PPO Batch Consumption Time: 0.06393
Total Iteration Time: 3.10982

Cumulative Model Updates: 19,121
Cumulative Timesteps: 319,259,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,215.67711
Policy Entropy: 0.73307
Value Function Loss: 0.05398

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06197
Policy Update Magnitude: 0.02696
Value Function Update Magnitude: 0.04805

Collected Steps per Second: 23,022.95962
Overall Steps per Second: 16,213.98807

Timestep Collection Time: 2.17235
Timestep Consumption Time: 0.91227
PPO Batch Consumption Time: 0.08777
Total Iteration Time: 3.08462

Cumulative Model Updates: 19,124
Cumulative Timesteps: 319,309,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 319309218...
Checkpoint 319309218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,706.48731
Policy Entropy: 0.73174
Value Function Loss: 0.05000

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.06831
Policy Update Magnitude: 0.02586
Value Function Update Magnitude: 0.04823

Collected Steps per Second: 23,027.23230
Overall Steps per Second: 16,744.90354

Timestep Collection Time: 2.17143
Timestep Consumption Time: 0.81467
PPO Batch Consumption Time: 0.06461
Total Iteration Time: 2.98610

Cumulative Model Updates: 19,127
Cumulative Timesteps: 319,359,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,040.44707
Policy Entropy: 0.73214
Value Function Loss: 0.05201

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06875
Policy Update Magnitude: 0.02586
Value Function Update Magnitude: 0.05000

Collected Steps per Second: 20,661.01280
Overall Steps per Second: 14,883.59040

Timestep Collection Time: 2.42108
Timestep Consumption Time: 0.93980
PPO Batch Consumption Time: 0.09675
Total Iteration Time: 3.36088

Cumulative Model Updates: 19,130
Cumulative Timesteps: 319,409,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 319409242...
Checkpoint 319409242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,648.84673
Policy Entropy: 0.74027
Value Function Loss: 0.05640

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.05103
Policy Update Magnitude: 0.02908
Value Function Update Magnitude: 0.04941

Collected Steps per Second: 22,849.87442
Overall Steps per Second: 16,716.09321

Timestep Collection Time: 2.18872
Timestep Consumption Time: 0.80313
PPO Batch Consumption Time: 0.05999
Total Iteration Time: 2.99185

Cumulative Model Updates: 19,133
Cumulative Timesteps: 319,459,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,297.22404
Policy Entropy: 0.74570
Value Function Loss: 0.05654

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.06016
Policy Update Magnitude: 0.02948
Value Function Update Magnitude: 0.05246

Collected Steps per Second: 20,328.98950
Overall Steps per Second: 14,764.55895

Timestep Collection Time: 2.46023
Timestep Consumption Time: 0.92721
PPO Batch Consumption Time: 0.08885
Total Iteration Time: 3.38744

Cumulative Model Updates: 19,136
Cumulative Timesteps: 319,509,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 319509268...
Checkpoint 319509268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,001.42209
Policy Entropy: 0.74721
Value Function Loss: 0.05463

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.03491
Value Function Update Magnitude: 0.05019

Collected Steps per Second: 22,710.99936
Overall Steps per Second: 16,476.62335

Timestep Collection Time: 2.20299
Timestep Consumption Time: 0.83356
PPO Batch Consumption Time: 0.06288
Total Iteration Time: 3.03654

Cumulative Model Updates: 19,139
Cumulative Timesteps: 319,559,300

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,494.64258
Policy Entropy: 0.73991
Value Function Loss: 0.05175

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.05255
Policy Update Magnitude: 0.03267
Value Function Update Magnitude: 0.04688

Collected Steps per Second: 20,717.89382
Overall Steps per Second: 14,907.21433

Timestep Collection Time: 2.41550
Timestep Consumption Time: 0.94154
PPO Batch Consumption Time: 0.07585
Total Iteration Time: 3.35703

Cumulative Model Updates: 19,142
Cumulative Timesteps: 319,609,344

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 319609344...
Checkpoint 319609344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,451.34383
Policy Entropy: 0.73514
Value Function Loss: 0.04705

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03409
Policy Update Magnitude: 0.03106
Value Function Update Magnitude: 0.05733

Collected Steps per Second: 21,220.90757
Overall Steps per Second: 14,914.75797

Timestep Collection Time: 2.35758
Timestep Consumption Time: 0.99682
PPO Batch Consumption Time: 0.12604
Total Iteration Time: 3.35440

Cumulative Model Updates: 19,145
Cumulative Timesteps: 319,659,374

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,758.12617
Policy Entropy: 0.73555
Value Function Loss: 0.04880

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02203
Policy Update Magnitude: 0.02883
Value Function Update Magnitude: 0.05465

Collected Steps per Second: 23,481.78605
Overall Steps per Second: 16,978.08084

Timestep Collection Time: 2.12999
Timestep Consumption Time: 0.81592
PPO Batch Consumption Time: 0.06032
Total Iteration Time: 2.94592

Cumulative Model Updates: 19,148
Cumulative Timesteps: 319,709,390

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 319709390...
Checkpoint 319709390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,685.21380
Policy Entropy: 0.75053
Value Function Loss: 0.04876

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.03065
Value Function Update Magnitude: 0.04682

Collected Steps per Second: 22,951.35922
Overall Steps per Second: 16,119.23087

Timestep Collection Time: 2.17913
Timestep Consumption Time: 0.92362
PPO Batch Consumption Time: 0.07273
Total Iteration Time: 3.10275

Cumulative Model Updates: 19,151
Cumulative Timesteps: 319,759,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,064.83735
Policy Entropy: 0.75215
Value Function Loss: 0.04798

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04579
Policy Update Magnitude: 0.03034
Value Function Update Magnitude: 0.03956

Collected Steps per Second: 22,360.20249
Overall Steps per Second: 15,885.03249

Timestep Collection Time: 2.23790
Timestep Consumption Time: 0.91223
PPO Batch Consumption Time: 0.08964
Total Iteration Time: 3.15014

Cumulative Model Updates: 19,154
Cumulative Timesteps: 319,809,444

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 319809444...
Checkpoint 319809444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,717.75755
Policy Entropy: 0.75742
Value Function Loss: 0.04816

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 0.02963
Value Function Update Magnitude: 0.04232

Collected Steps per Second: 23,282.84371
Overall Steps per Second: 15,914.28085

Timestep Collection Time: 2.14750
Timestep Consumption Time: 0.99433
PPO Batch Consumption Time: 0.12054
Total Iteration Time: 3.14183

Cumulative Model Updates: 19,157
Cumulative Timesteps: 319,859,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,137.19744
Policy Entropy: 0.75027
Value Function Loss: 0.04956

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.06101
Policy Update Magnitude: 0.03030
Value Function Update Magnitude: 0.04049

Collected Steps per Second: 22,818.65968
Overall Steps per Second: 16,774.27066

Timestep Collection Time: 2.19198
Timestep Consumption Time: 0.78985
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 2.98183

Cumulative Model Updates: 19,160
Cumulative Timesteps: 319,909,462

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 319909462...
Checkpoint 319909462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,593.03052
Policy Entropy: 0.75369
Value Function Loss: 0.04631

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.06068
Policy Update Magnitude: 0.03012
Value Function Update Magnitude: 0.03486

Collected Steps per Second: 21,460.37772
Overall Steps per Second: 15,497.16422

Timestep Collection Time: 2.33015
Timestep Consumption Time: 0.89663
PPO Batch Consumption Time: 0.07793
Total Iteration Time: 3.22678

Cumulative Model Updates: 19,163
Cumulative Timesteps: 319,959,468

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,691.58972
Policy Entropy: 0.75121
Value Function Loss: 0.04560

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03676
Policy Update Magnitude: 0.03141
Value Function Update Magnitude: 0.03565

Collected Steps per Second: 23,046.56117
Overall Steps per Second: 16,704.69309

Timestep Collection Time: 2.17074
Timestep Consumption Time: 0.82411
PPO Batch Consumption Time: 0.05975
Total Iteration Time: 2.99485

Cumulative Model Updates: 19,166
Cumulative Timesteps: 320,009,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 320009496...
Checkpoint 320009496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,479.58236
Policy Entropy: 0.74930
Value Function Loss: 0.04660

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04967
Policy Update Magnitude: 0.02854
Value Function Update Magnitude: 0.03350

Collected Steps per Second: 20,148.27918
Overall Steps per Second: 14,700.61757

Timestep Collection Time: 2.48190
Timestep Consumption Time: 0.91973
PPO Batch Consumption Time: 0.09029
Total Iteration Time: 3.40163

Cumulative Model Updates: 19,169
Cumulative Timesteps: 320,059,502

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,470.10530
Policy Entropy: 0.74018
Value Function Loss: 0.04731

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05413
Policy Update Magnitude: 0.02647
Value Function Update Magnitude: 0.03059

Collected Steps per Second: 23,548.80512
Overall Steps per Second: 16,991.72379

Timestep Collection Time: 2.12444
Timestep Consumption Time: 0.81982
PPO Batch Consumption Time: 0.06455
Total Iteration Time: 2.94426

Cumulative Model Updates: 19,172
Cumulative Timesteps: 320,109,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 320109530...
Checkpoint 320109530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,356.95390
Policy Entropy: 0.74712
Value Function Loss: 0.05047

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05721
Policy Update Magnitude: 0.02659
Value Function Update Magnitude: 0.03471

Collected Steps per Second: 21,437.35199
Overall Steps per Second: 14,833.58432

Timestep Collection Time: 2.33275
Timestep Consumption Time: 1.03852
PPO Batch Consumption Time: 0.12366
Total Iteration Time: 3.37127

Cumulative Model Updates: 19,175
Cumulative Timesteps: 320,159,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,847.13614
Policy Entropy: 0.73562
Value Function Loss: 0.05125

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.04187
Policy Update Magnitude: 0.02561
Value Function Update Magnitude: 0.03269

Collected Steps per Second: 22,677.58290
Overall Steps per Second: 15,636.39802

Timestep Collection Time: 2.20500
Timestep Consumption Time: 0.99293
PPO Batch Consumption Time: 0.11681
Total Iteration Time: 3.19792

Cumulative Model Updates: 19,178
Cumulative Timesteps: 320,209,542

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 320209542...
Checkpoint 320209542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,842.91991
Policy Entropy: 0.74420
Value Function Loss: 0.04964

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.05293
Policy Update Magnitude: 0.02639
Value Function Update Magnitude: 0.03444

Collected Steps per Second: 22,872.54753
Overall Steps per Second: 16,809.58263

Timestep Collection Time: 2.18620
Timestep Consumption Time: 0.78853
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 2.97473

Cumulative Model Updates: 19,181
Cumulative Timesteps: 320,259,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,495.75973
Policy Entropy: 0.73616
Value Function Loss: 0.04382

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.06381
Policy Update Magnitude: 0.02519
Value Function Update Magnitude: 0.03419

Collected Steps per Second: 21,445.50214
Overall Steps per Second: 15,678.80076

Timestep Collection Time: 2.33224
Timestep Consumption Time: 0.85780
PPO Batch Consumption Time: 0.02913
Total Iteration Time: 3.19004

Cumulative Model Updates: 19,184
Cumulative Timesteps: 320,309,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 320309562...
Checkpoint 320309562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,119.06733
Policy Entropy: 0.73954
Value Function Loss: 0.04852

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.05489
Policy Update Magnitude: 0.03523
Value Function Update Magnitude: 0.03625

Collected Steps per Second: 22,862.93306
Overall Steps per Second: 16,685.11206

Timestep Collection Time: 2.18695
Timestep Consumption Time: 0.80974
PPO Batch Consumption Time: 0.06082
Total Iteration Time: 2.99668

Cumulative Model Updates: 19,187
Cumulative Timesteps: 320,359,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,904.48952
Policy Entropy: 0.73359
Value Function Loss: 0.05801

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.04360
Value Function Update Magnitude: 0.04549

Collected Steps per Second: 20,445.02935
Overall Steps per Second: 14,690.03348

Timestep Collection Time: 2.44597
Timestep Consumption Time: 0.95824
PPO Batch Consumption Time: 0.10674
Total Iteration Time: 3.40421

Cumulative Model Updates: 19,190
Cumulative Timesteps: 320,409,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 320409570...
Checkpoint 320409570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,250.15884
Policy Entropy: 0.73335
Value Function Loss: 0.06588

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05935
Policy Update Magnitude: 0.03796
Value Function Update Magnitude: 0.05450

Collected Steps per Second: 23,306.20149
Overall Steps per Second: 16,890.59563

Timestep Collection Time: 2.14569
Timestep Consumption Time: 0.81501
PPO Batch Consumption Time: 0.06114
Total Iteration Time: 2.96070

Cumulative Model Updates: 19,193
Cumulative Timesteps: 320,459,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,383.15567
Policy Entropy: 0.73111
Value Function Loss: 0.06309

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06784
Policy Update Magnitude: 0.03610
Value Function Update Magnitude: 0.05953

Collected Steps per Second: 20,708.23197
Overall Steps per Second: 14,604.53933

Timestep Collection Time: 2.41517
Timestep Consumption Time: 1.00938
PPO Batch Consumption Time: 0.12388
Total Iteration Time: 3.42455

Cumulative Model Updates: 19,196
Cumulative Timesteps: 320,509,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 320509592...
Checkpoint 320509592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,244.81641
Policy Entropy: 0.73600
Value Function Loss: 0.06364

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07465
Policy Update Magnitude: 0.03359
Value Function Update Magnitude: 0.04874

Collected Steps per Second: 23,122.65725
Overall Steps per Second: 15,747.29515

Timestep Collection Time: 2.16290
Timestep Consumption Time: 1.01301
PPO Batch Consumption Time: 0.12408
Total Iteration Time: 3.17591

Cumulative Model Updates: 19,199
Cumulative Timesteps: 320,559,604

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,133.04844
Policy Entropy: 0.72624
Value Function Loss: 0.06680

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.04392
Policy Update Magnitude: 0.03223
Value Function Update Magnitude: 0.04790

Collected Steps per Second: 23,012.28776
Overall Steps per Second: 17,462.49884

Timestep Collection Time: 2.17319
Timestep Consumption Time: 0.69066
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 2.86385

Cumulative Model Updates: 19,202
Cumulative Timesteps: 320,609,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 320609614...
Checkpoint 320609614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,661.96391
Policy Entropy: 0.72935
Value Function Loss: 0.06546

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04517
Policy Update Magnitude: 0.03808
Value Function Update Magnitude: 0.04120

Collected Steps per Second: 21,108.64134
Overall Steps per Second: 15,137.98833

Timestep Collection Time: 2.36936
Timestep Consumption Time: 0.93451
PPO Batch Consumption Time: 0.12138
Total Iteration Time: 3.30387

Cumulative Model Updates: 19,205
Cumulative Timesteps: 320,659,628

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,722.64616
Policy Entropy: 0.73315
Value Function Loss: 0.05836

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03847
Policy Update Magnitude: 0.03662
Value Function Update Magnitude: 0.04024

Collected Steps per Second: 22,415.65531
Overall Steps per Second: 16,795.17228

Timestep Collection Time: 2.23094
Timestep Consumption Time: 0.74658
PPO Batch Consumption Time: 0.06026
Total Iteration Time: 2.97752

Cumulative Model Updates: 19,208
Cumulative Timesteps: 320,709,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 320709636...
Checkpoint 320709636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,857.58230
Policy Entropy: 0.74362
Value Function Loss: 0.04638

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.04019
Policy Update Magnitude: 0.03563
Value Function Update Magnitude: 0.03578

Collected Steps per Second: 19,704.95895
Overall Steps per Second: 14,715.41039

Timestep Collection Time: 2.53875
Timestep Consumption Time: 0.86081
PPO Batch Consumption Time: 0.09340
Total Iteration Time: 3.39957

Cumulative Model Updates: 19,211
Cumulative Timesteps: 320,759,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,421.84915
Policy Entropy: 0.74758
Value Function Loss: 0.04211

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02008
Policy Update Magnitude: 0.03195
Value Function Update Magnitude: 0.03672

Collected Steps per Second: 22,528.53560
Overall Steps per Second: 16,940.11968

Timestep Collection Time: 2.22038
Timestep Consumption Time: 0.73249
PPO Batch Consumption Time: 0.06062
Total Iteration Time: 2.95287

Cumulative Model Updates: 19,214
Cumulative Timesteps: 320,809,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 320809684...
Checkpoint 320809684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,878.21207
Policy Entropy: 0.74335
Value Function Loss: 0.04338

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04183
Policy Update Magnitude: 0.03338
Value Function Update Magnitude: 0.03281

Collected Steps per Second: 21,785.36434
Overall Steps per Second: 16,160.57829

Timestep Collection Time: 2.29640
Timestep Consumption Time: 0.79928
PPO Batch Consumption Time: 0.06985
Total Iteration Time: 3.09568

Cumulative Model Updates: 19,217
Cumulative Timesteps: 320,859,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,448.76993
Policy Entropy: 0.73859
Value Function Loss: 0.04703

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.04127
Policy Update Magnitude: 0.03146
Value Function Update Magnitude: 0.02993

Collected Steps per Second: 21,011.44527
Overall Steps per Second: 15,087.70050

Timestep Collection Time: 2.38061
Timestep Consumption Time: 0.93468
PPO Batch Consumption Time: 0.11039
Total Iteration Time: 3.31528

Cumulative Model Updates: 19,220
Cumulative Timesteps: 320,909,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 320909732...
Checkpoint 320909732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,529.60383
Policy Entropy: 0.74325
Value Function Loss: 0.05136

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.04125
Policy Update Magnitude: 0.03049
Value Function Update Magnitude: 0.03306

Collected Steps per Second: 22,645.30276
Overall Steps per Second: 15,788.54486

Timestep Collection Time: 2.20885
Timestep Consumption Time: 0.95927
PPO Batch Consumption Time: 0.12205
Total Iteration Time: 3.16812

Cumulative Model Updates: 19,223
Cumulative Timesteps: 320,959,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,634.60321
Policy Entropy: 0.74195
Value Function Loss: 0.05269

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03510
Policy Update Magnitude: 0.02954
Value Function Update Magnitude: 0.03149

Collected Steps per Second: 22,981.64929
Overall Steps per Second: 16,791.71513

Timestep Collection Time: 2.17565
Timestep Consumption Time: 0.80201
PPO Batch Consumption Time: 0.05855
Total Iteration Time: 2.97766

Cumulative Model Updates: 19,226
Cumulative Timesteps: 321,009,752

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 321009752...
Checkpoint 321009752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,199.19447
Policy Entropy: 0.73897
Value Function Loss: 0.05348

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03353
Policy Update Magnitude: 0.03087
Value Function Update Magnitude: 0.03162

Collected Steps per Second: 20,712.34905
Overall Steps per Second: 14,683.13731

Timestep Collection Time: 2.41402
Timestep Consumption Time: 0.99125
PPO Batch Consumption Time: 0.12066
Total Iteration Time: 3.40527

Cumulative Model Updates: 19,229
Cumulative Timesteps: 321,059,752

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,112.50301
Policy Entropy: 0.72890
Value Function Loss: 0.05348

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.04511
Policy Update Magnitude: 0.02997
Value Function Update Magnitude: 0.02990

Collected Steps per Second: 23,175.51349
Overall Steps per Second: 16,548.76609

Timestep Collection Time: 2.15745
Timestep Consumption Time: 0.86392
PPO Batch Consumption Time: 0.07790
Total Iteration Time: 3.02137

Cumulative Model Updates: 19,232
Cumulative Timesteps: 321,109,752

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 321109752...
Checkpoint 321109752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,518.70363
Policy Entropy: 0.73278
Value Function Loss: 0.05761

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04761
Policy Update Magnitude: 0.02863
Value Function Update Magnitude: 0.03201

Collected Steps per Second: 23,049.51382
Overall Steps per Second: 16,815.74713

Timestep Collection Time: 2.16968
Timestep Consumption Time: 0.80432
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 2.97400

Cumulative Model Updates: 19,235
Cumulative Timesteps: 321,159,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,747.63371
Policy Entropy: 0.73103
Value Function Loss: 0.06031

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01583
Policy Update Magnitude: 0.03042
Value Function Update Magnitude: 0.03449

Collected Steps per Second: 19,728.27724
Overall Steps per Second: 13,912.16631

Timestep Collection Time: 2.53514
Timestep Consumption Time: 1.05984
PPO Batch Consumption Time: 0.12738
Total Iteration Time: 3.59498

Cumulative Model Updates: 19,238
Cumulative Timesteps: 321,209,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 321209776...
Checkpoint 321209776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,991.30068
Policy Entropy: 0.73111
Value Function Loss: 0.05923

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02659
Policy Update Magnitude: 0.03519
Value Function Update Magnitude: 0.03432

Collected Steps per Second: 22,944.54436
Overall Steps per Second: 15,803.64162

Timestep Collection Time: 2.18039
Timestep Consumption Time: 0.98521
PPO Batch Consumption Time: 0.11594
Total Iteration Time: 3.16560

Cumulative Model Updates: 19,241
Cumulative Timesteps: 321,259,804

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,580.58154
Policy Entropy: 0.73013
Value Function Loss: 0.05810

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05309
Policy Update Magnitude: 0.03287
Value Function Update Magnitude: 0.03589

Collected Steps per Second: 23,506.50008
Overall Steps per Second: 16,992.67132

Timestep Collection Time: 2.12920
Timestep Consumption Time: 0.81619
PPO Batch Consumption Time: 0.06292
Total Iteration Time: 2.94539

Cumulative Model Updates: 19,244
Cumulative Timesteps: 321,309,854

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 321309854...
Checkpoint 321309854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,864.73610
Policy Entropy: 0.73600
Value Function Loss: 0.05954

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04160
Policy Update Magnitude: 0.03137
Value Function Update Magnitude: 0.03115

Collected Steps per Second: 23,146.16612
Overall Steps per Second: 16,619.62978

Timestep Collection Time: 2.16062
Timestep Consumption Time: 0.84848
PPO Batch Consumption Time: 0.06639
Total Iteration Time: 3.00909

Cumulative Model Updates: 19,247
Cumulative Timesteps: 321,359,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,833.76646
Policy Entropy: 0.74431
Value Function Loss: 0.05869

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04419
Policy Update Magnitude: 0.02999
Value Function Update Magnitude: 0.03286

Collected Steps per Second: 22,118.11812
Overall Steps per Second: 16,121.08021

Timestep Collection Time: 2.26231
Timestep Consumption Time: 0.84158
PPO Batch Consumption Time: 0.06777
Total Iteration Time: 3.10389

Cumulative Model Updates: 19,250
Cumulative Timesteps: 321,409,902

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 321409902...
Checkpoint 321409902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,730.70777
Policy Entropy: 0.74064
Value Function Loss: 0.05716

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04366
Policy Update Magnitude: 0.02896
Value Function Update Magnitude: 0.03330

Collected Steps per Second: 17,222.38297
Overall Steps per Second: 12,866.67536

Timestep Collection Time: 2.90482
Timestep Consumption Time: 0.98336
PPO Batch Consumption Time: 0.11145
Total Iteration Time: 3.88818

Cumulative Model Updates: 19,253
Cumulative Timesteps: 321,459,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,063.82242
Policy Entropy: 0.74722
Value Function Loss: 0.05752

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.06051
Policy Update Magnitude: 0.03103
Value Function Update Magnitude: 0.03462

Collected Steps per Second: 23,422.27113
Overall Steps per Second: 15,733.54425

Timestep Collection Time: 2.13472
Timestep Consumption Time: 1.04320
PPO Batch Consumption Time: 0.12568
Total Iteration Time: 3.17792

Cumulative Model Updates: 19,256
Cumulative Timesteps: 321,509,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 321509930...
Checkpoint 321509930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,209.19750
Policy Entropy: 0.74181
Value Function Loss: 0.05844

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07666
Policy Update Magnitude: 0.03041
Value Function Update Magnitude: 0.03109

Collected Steps per Second: 23,608.19444
Overall Steps per Second: 16,776.65843

Timestep Collection Time: 2.11799
Timestep Consumption Time: 0.86246
PPO Batch Consumption Time: 0.07633
Total Iteration Time: 2.98045

Cumulative Model Updates: 19,259
Cumulative Timesteps: 321,559,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,570.93476
Policy Entropy: 0.74727
Value Function Loss: 0.05718

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05935
Policy Update Magnitude: 0.03149
Value Function Update Magnitude: 0.03140

Collected Steps per Second: 21,801.18677
Overall Steps per Second: 15,780.70753

Timestep Collection Time: 2.29483
Timestep Consumption Time: 0.87550
PPO Batch Consumption Time: 0.06787
Total Iteration Time: 3.17033

Cumulative Model Updates: 19,262
Cumulative Timesteps: 321,609,962

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 321609962...
Checkpoint 321609962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,568.96697
Policy Entropy: 0.74609
Value Function Loss: 0.05745

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.06295
Policy Update Magnitude: 0.03074
Value Function Update Magnitude: 0.03654

Collected Steps per Second: 22,226.68580
Overall Steps per Second: 16,757.07015

Timestep Collection Time: 2.25081
Timestep Consumption Time: 0.73468
PPO Batch Consumption Time: 0.02933
Total Iteration Time: 2.98549

Cumulative Model Updates: 19,265
Cumulative Timesteps: 321,659,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,356.38387
Policy Entropy: 0.74263
Value Function Loss: 0.05334

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03365
Policy Update Magnitude: 0.03359
Value Function Update Magnitude: 0.04110

Collected Steps per Second: 20,169.87626
Overall Steps per Second: 15,314.28036

Timestep Collection Time: 2.47944
Timestep Consumption Time: 0.78614
PPO Batch Consumption Time: 0.04359
Total Iteration Time: 3.26558

Cumulative Model Updates: 19,268
Cumulative Timesteps: 321,710,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 321710000...
Checkpoint 321710000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,161.24166
Policy Entropy: 0.75295
Value Function Loss: 0.05125

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05385
Policy Update Magnitude: 0.03059
Value Function Update Magnitude: 0.04031

Collected Steps per Second: 19,519.13136
Overall Steps per Second: 15,271.00027

Timestep Collection Time: 2.56272
Timestep Consumption Time: 0.71290
PPO Batch Consumption Time: 0.02896
Total Iteration Time: 3.27562

Cumulative Model Updates: 19,271
Cumulative Timesteps: 321,760,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,486.70145
Policy Entropy: 0.74371
Value Function Loss: 0.05078

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03807
Policy Update Magnitude: 0.02864
Value Function Update Magnitude: 0.04261

Collected Steps per Second: 20,985.08211
Overall Steps per Second: 15,259.14554

Timestep Collection Time: 2.38341
Timestep Consumption Time: 0.89436
PPO Batch Consumption Time: 0.08226
Total Iteration Time: 3.27777

Cumulative Model Updates: 19,274
Cumulative Timesteps: 321,810,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 321810038...
Checkpoint 321810038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,110.55273
Policy Entropy: 0.73654
Value Function Loss: 0.05544

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04504
Policy Update Magnitude: 0.02818
Value Function Update Magnitude: 0.04288

Collected Steps per Second: 21,754.02675
Overall Steps per Second: 15,705.26102

Timestep Collection Time: 2.30054
Timestep Consumption Time: 0.88604
PPO Batch Consumption Time: 0.07858
Total Iteration Time: 3.18658

Cumulative Model Updates: 19,277
Cumulative Timesteps: 321,860,084

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,697.50841
Policy Entropy: 0.72707
Value Function Loss: 0.06152

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02736
Policy Update Magnitude: 0.02922
Value Function Update Magnitude: 0.06307

Collected Steps per Second: 21,994.51158
Overall Steps per Second: 16,267.26836

Timestep Collection Time: 2.27329
Timestep Consumption Time: 0.80036
PPO Batch Consumption Time: 0.06407
Total Iteration Time: 3.07366

Cumulative Model Updates: 19,280
Cumulative Timesteps: 321,910,084

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 321910084...
Checkpoint 321910084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,539.80116
Policy Entropy: 0.71933
Value Function Loss: 0.06673

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03407
Policy Update Magnitude: 0.02915
Value Function Update Magnitude: 0.07460

Collected Steps per Second: 20,501.77687
Overall Steps per Second: 15,178.84160

Timestep Collection Time: 2.44067
Timestep Consumption Time: 0.85590
PPO Batch Consumption Time: 0.03828
Total Iteration Time: 3.29656

Cumulative Model Updates: 19,283
Cumulative Timesteps: 321,960,122

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,077.05611
Policy Entropy: 0.71701
Value Function Loss: 0.06582

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03863
Policy Update Magnitude: 0.03332
Value Function Update Magnitude: 0.07565

Collected Steps per Second: 21,524.25627
Overall Steps per Second: 16,419.95265

Timestep Collection Time: 2.32380
Timestep Consumption Time: 0.72238
PPO Batch Consumption Time: 0.03106
Total Iteration Time: 3.04617

Cumulative Model Updates: 19,286
Cumulative Timesteps: 322,010,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 322010140...
Checkpoint 322010140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,672.58999
Policy Entropy: 0.71776
Value Function Loss: 0.06019

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.03035
Value Function Update Magnitude: 0.07135

Collected Steps per Second: 20,337.55625
Overall Steps per Second: 14,799.44313

Timestep Collection Time: 2.45851
Timestep Consumption Time: 0.92000
PPO Batch Consumption Time: 0.08017
Total Iteration Time: 3.37851

Cumulative Model Updates: 19,289
Cumulative Timesteps: 322,060,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,516.82509
Policy Entropy: 0.72614
Value Function Loss: 0.05681

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.05159
Policy Update Magnitude: 0.03389
Value Function Update Magnitude: 0.07511

Collected Steps per Second: 19,336.49617
Overall Steps per Second: 14,127.14510

Timestep Collection Time: 2.58620
Timestep Consumption Time: 0.95365
PPO Batch Consumption Time: 0.09025
Total Iteration Time: 3.53985

Cumulative Model Updates: 19,292
Cumulative Timesteps: 322,110,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 322110148...
Checkpoint 322110148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,756.60579
Policy Entropy: 0.72132
Value Function Loss: 0.04961

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.05182
Policy Update Magnitude: 0.03670
Value Function Update Magnitude: 0.07749

Collected Steps per Second: 21,836.98160
Overall Steps per Second: 15,846.64318

Timestep Collection Time: 2.28997
Timestep Consumption Time: 0.86565
PPO Batch Consumption Time: 0.06422
Total Iteration Time: 3.15562

Cumulative Model Updates: 19,295
Cumulative Timesteps: 322,160,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,784.08728
Policy Entropy: 0.72690
Value Function Loss: 0.04852

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05741
Policy Update Magnitude: 0.03396
Value Function Update Magnitude: 0.07052

Collected Steps per Second: 17,799.69229
Overall Steps per Second: 13,001.25204

Timestep Collection Time: 2.81027
Timestep Consumption Time: 1.03720
PPO Batch Consumption Time: 0.11197
Total Iteration Time: 3.84748

Cumulative Model Updates: 19,298
Cumulative Timesteps: 322,210,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 322210176...
Checkpoint 322210176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,847.33911
Policy Entropy: 0.72186
Value Function Loss: 0.05340

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.04194
Policy Update Magnitude: 0.02987
Value Function Update Magnitude: 0.06602

Collected Steps per Second: 22,678.39652
Overall Steps per Second: 16,090.16203

Timestep Collection Time: 2.20571
Timestep Consumption Time: 0.90314
PPO Batch Consumption Time: 0.08209
Total Iteration Time: 3.10886

Cumulative Model Updates: 19,301
Cumulative Timesteps: 322,260,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,579.18544
Policy Entropy: 0.72677
Value Function Loss: 0.06479

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04244
Policy Update Magnitude: 0.03191
Value Function Update Magnitude: 0.06900

Collected Steps per Second: 19,197.23159
Overall Steps per Second: 14,226.72048

Timestep Collection Time: 2.60517
Timestep Consumption Time: 0.91019
PPO Batch Consumption Time: 0.02945
Total Iteration Time: 3.51536

Cumulative Model Updates: 19,304
Cumulative Timesteps: 322,310,210

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 322310210...
Checkpoint 322310210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,036.15627
Policy Entropy: 0.71769
Value Function Loss: 0.06945

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.05276
Policy Update Magnitude: 0.03413
Value Function Update Magnitude: 0.06899

Collected Steps per Second: 19,577.53695
Overall Steps per Second: 13,350.09221

Timestep Collection Time: 2.55497
Timestep Consumption Time: 1.19182
PPO Batch Consumption Time: 0.03114
Total Iteration Time: 3.74679

Cumulative Model Updates: 19,307
Cumulative Timesteps: 322,360,230

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,280.40035
Policy Entropy: 0.72192
Value Function Loss: 0.06552

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04812
Policy Update Magnitude: 0.03327
Value Function Update Magnitude: 0.06352

Collected Steps per Second: 18,545.24274
Overall Steps per Second: 13,169.73961

Timestep Collection Time: 2.69751
Timestep Consumption Time: 1.10105
PPO Batch Consumption Time: 0.12234
Total Iteration Time: 3.79856

Cumulative Model Updates: 19,310
Cumulative Timesteps: 322,410,256

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 322410256...
Checkpoint 322410256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,063.48350
Policy Entropy: 0.71790
Value Function Loss: 0.06012

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04239
Policy Update Magnitude: 0.03394
Value Function Update Magnitude: 0.05615

Collected Steps per Second: 15,330.07428
Overall Steps per Second: 11,718.42190

Timestep Collection Time: 3.26261
Timestep Consumption Time: 1.00555
PPO Batch Consumption Time: 0.08061
Total Iteration Time: 4.26815

Cumulative Model Updates: 19,313
Cumulative Timesteps: 322,460,272

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,661.84511
Policy Entropy: 0.71843
Value Function Loss: 0.06086

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.05280
Policy Update Magnitude: 0.03165
Value Function Update Magnitude: 0.06163

Collected Steps per Second: 17,955.76599
Overall Steps per Second: 13,771.82891

Timestep Collection Time: 2.78484
Timestep Consumption Time: 0.84605
PPO Batch Consumption Time: 0.04976
Total Iteration Time: 3.63089

Cumulative Model Updates: 19,316
Cumulative Timesteps: 322,510,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 322510276...
Checkpoint 322510276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,675.50454
Policy Entropy: 0.71672
Value Function Loss: 0.06417

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02641
Policy Update Magnitude: 0.03217
Value Function Update Magnitude: 0.06837

Collected Steps per Second: 19,135.72197
Overall Steps per Second: 14,513.89972

Timestep Collection Time: 2.61344
Timestep Consumption Time: 0.83223
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 3.44566

Cumulative Model Updates: 19,319
Cumulative Timesteps: 322,560,286

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,021.94509
Policy Entropy: 0.72067
Value Function Loss: 0.06115

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.03286
Value Function Update Magnitude: 0.06496

Collected Steps per Second: 18,829.71287
Overall Steps per Second: 14,316.25378

Timestep Collection Time: 2.65665
Timestep Consumption Time: 0.83756
PPO Batch Consumption Time: 0.05961
Total Iteration Time: 3.49421

Cumulative Model Updates: 19,322
Cumulative Timesteps: 322,610,310

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 322610310...
Checkpoint 322610310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,440.95879
Policy Entropy: 0.72905
Value Function Loss: 0.05479

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03154
Policy Update Magnitude: 0.03123
Value Function Update Magnitude: 0.06082

Collected Steps per Second: 18,926.40073
Overall Steps per Second: 14,572.56231

Timestep Collection Time: 2.64255
Timestep Consumption Time: 0.78951
PPO Batch Consumption Time: 0.04801
Total Iteration Time: 3.43207

Cumulative Model Updates: 19,325
Cumulative Timesteps: 322,660,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,483.31890
Policy Entropy: 0.73413
Value Function Loss: 0.05768

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02881
Policy Update Magnitude: 0.03092
Value Function Update Magnitude: 0.05660

Collected Steps per Second: 18,594.73767
Overall Steps per Second: 14,127.57892

Timestep Collection Time: 2.68969
Timestep Consumption Time: 0.85048
PPO Batch Consumption Time: 0.06507
Total Iteration Time: 3.54017

Cumulative Model Updates: 19,328
Cumulative Timesteps: 322,710,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 322710338...
Checkpoint 322710338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,856.07127
Policy Entropy: 0.73239
Value Function Loss: 0.06013

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.03453
Value Function Update Magnitude: 0.05195

Collected Steps per Second: 19,267.51993
Overall Steps per Second: 14,686.21278

Timestep Collection Time: 2.59618
Timestep Consumption Time: 0.80987
PPO Batch Consumption Time: 0.05391
Total Iteration Time: 3.40605

Cumulative Model Updates: 19,331
Cumulative Timesteps: 322,760,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,289.21746
Policy Entropy: 0.73553
Value Function Loss: 0.05888

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.03387
Value Function Update Magnitude: 0.05688

Collected Steps per Second: 19,153.86624
Overall Steps per Second: 14,718.76354

Timestep Collection Time: 2.61086
Timestep Consumption Time: 0.78671
PPO Batch Consumption Time: 0.04925
Total Iteration Time: 3.39757

Cumulative Model Updates: 19,334
Cumulative Timesteps: 322,810,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 322810368...
Checkpoint 322810368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,439.46640
Policy Entropy: 0.74310
Value Function Loss: 0.05410

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.02983
Value Function Update Magnitude: 0.05946

Collected Steps per Second: 18,877.27492
Overall Steps per Second: 14,347.98572

Timestep Collection Time: 2.65028
Timestep Consumption Time: 0.83662
PPO Batch Consumption Time: 0.06066
Total Iteration Time: 3.48690

Cumulative Model Updates: 19,337
Cumulative Timesteps: 322,860,398

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,496.89867
Policy Entropy: 0.74605
Value Function Loss: 0.05445

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03452
Policy Update Magnitude: 0.02837
Value Function Update Magnitude: 0.05563

Collected Steps per Second: 19,694.00132
Overall Steps per Second: 14,835.55144

Timestep Collection Time: 2.54027
Timestep Consumption Time: 0.83190
PPO Batch Consumption Time: 0.06118
Total Iteration Time: 3.37217

Cumulative Model Updates: 19,340
Cumulative Timesteps: 322,910,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 322910426...
Checkpoint 322910426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,884.11764
Policy Entropy: 0.75301
Value Function Loss: 0.05498

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02931
Policy Update Magnitude: 0.02861
Value Function Update Magnitude: 0.05196

Collected Steps per Second: 18,767.84309
Overall Steps per Second: 14,316.34844

Timestep Collection Time: 2.66626
Timestep Consumption Time: 0.82904
PPO Batch Consumption Time: 0.05326
Total Iteration Time: 3.49530

Cumulative Model Updates: 19,343
Cumulative Timesteps: 322,960,466

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,182.38134
Policy Entropy: 0.75660
Value Function Loss: 0.05872

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.06039
Policy Update Magnitude: 0.02576
Value Function Update Magnitude: 0.05461

Collected Steps per Second: 18,944.15969
Overall Steps per Second: 14,460.70131

Timestep Collection Time: 2.63997
Timestep Consumption Time: 0.81851
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 3.45848

Cumulative Model Updates: 19,346
Cumulative Timesteps: 323,010,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 323010478...
Checkpoint 323010478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,137.67173
Policy Entropy: 0.75018
Value Function Loss: 0.05680

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04077
Policy Update Magnitude: 0.02715
Value Function Update Magnitude: 0.06456

Collected Steps per Second: 19,085.75502
Overall Steps per Second: 14,435.80375

Timestep Collection Time: 2.62070
Timestep Consumption Time: 0.84416
PPO Batch Consumption Time: 0.05842
Total Iteration Time: 3.46486

Cumulative Model Updates: 19,349
Cumulative Timesteps: 323,060,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,004.45123
Policy Entropy: 0.74496
Value Function Loss: 0.05818

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03856
Policy Update Magnitude: 0.02924
Value Function Update Magnitude: 0.07192

Collected Steps per Second: 19,386.55726
Overall Steps per Second: 14,619.73816

Timestep Collection Time: 2.57973
Timestep Consumption Time: 0.84113
PPO Batch Consumption Time: 0.05858
Total Iteration Time: 3.42085

Cumulative Model Updates: 19,352
Cumulative Timesteps: 323,110,508

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 323110508...
Checkpoint 323110508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,837.12711
Policy Entropy: 0.74394
Value Function Loss: 0.05424

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03575
Policy Update Magnitude: 0.03496
Value Function Update Magnitude: 0.07443

Collected Steps per Second: 19,011.45236
Overall Steps per Second: 14,442.12041

Timestep Collection Time: 2.63126
Timestep Consumption Time: 0.83250
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 3.46376

Cumulative Model Updates: 19,355
Cumulative Timesteps: 323,160,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,791.18782
Policy Entropy: 0.73973
Value Function Loss: 0.05812

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.03042
Policy Update Magnitude: 0.03336
Value Function Update Magnitude: 0.07806

Collected Steps per Second: 19,809.40222
Overall Steps per Second: 15,014.23943

Timestep Collection Time: 2.52527
Timestep Consumption Time: 0.80651
PPO Batch Consumption Time: 0.05172
Total Iteration Time: 3.33177

Cumulative Model Updates: 19,358
Cumulative Timesteps: 323,210,556

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 323210556...
Checkpoint 323210556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,465.96257
Policy Entropy: 0.73974
Value Function Loss: 0.05895

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02731
Policy Update Magnitude: 0.03402
Value Function Update Magnitude: 0.07683

Collected Steps per Second: 18,957.85081
Overall Steps per Second: 14,329.66428

Timestep Collection Time: 2.63986
Timestep Consumption Time: 0.85262
PPO Batch Consumption Time: 0.06398
Total Iteration Time: 3.49248

Cumulative Model Updates: 19,361
Cumulative Timesteps: 323,260,602

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,636.43446
Policy Entropy: 0.74060
Value Function Loss: 0.05843

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02069
Policy Update Magnitude: 0.03749
Value Function Update Magnitude: 0.07580

Collected Steps per Second: 19,510.59856
Overall Steps per Second: 14,702.17198

Timestep Collection Time: 2.56404
Timestep Consumption Time: 0.83858
PPO Batch Consumption Time: 0.06149
Total Iteration Time: 3.40263

Cumulative Model Updates: 19,364
Cumulative Timesteps: 323,310,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 323310628...
Checkpoint 323310628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,662.58360
Policy Entropy: 0.74554
Value Function Loss: 0.05576

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03755
Policy Update Magnitude: 0.03221
Value Function Update Magnitude: 0.07486

Collected Steps per Second: 19,453.18749
Overall Steps per Second: 14,682.96198

Timestep Collection Time: 2.57058
Timestep Consumption Time: 0.83513
PPO Batch Consumption Time: 0.06044
Total Iteration Time: 3.40572

Cumulative Model Updates: 19,367
Cumulative Timesteps: 323,360,634

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,543.12529
Policy Entropy: 0.73867
Value Function Loss: 0.06057

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03779
Policy Update Magnitude: 0.02896
Value Function Update Magnitude: 0.07198

Collected Steps per Second: 19,608.83933
Overall Steps per Second: 14,804.13817

Timestep Collection Time: 2.55089
Timestep Consumption Time: 0.82789
PPO Batch Consumption Time: 0.05879
Total Iteration Time: 3.37879

Cumulative Model Updates: 19,370
Cumulative Timesteps: 323,410,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 323410654...
Checkpoint 323410654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,159.40130
Policy Entropy: 0.73979
Value Function Loss: 0.05924

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03012
Policy Update Magnitude: 0.03474
Value Function Update Magnitude: 0.07076

Collected Steps per Second: 19,015.84613
Overall Steps per Second: 14,541.21490

Timestep Collection Time: 2.63033
Timestep Consumption Time: 0.80941
PPO Batch Consumption Time: 0.05356
Total Iteration Time: 3.43974

Cumulative Model Updates: 19,373
Cumulative Timesteps: 323,460,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,473.07108
Policy Entropy: 0.73813
Value Function Loss: 0.05896

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03065
Policy Update Magnitude: 0.03414
Value Function Update Magnitude: 0.07430

Collected Steps per Second: 18,941.35913
Overall Steps per Second: 14,440.98001

Timestep Collection Time: 2.64163
Timestep Consumption Time: 0.82324
PPO Batch Consumption Time: 0.05423
Total Iteration Time: 3.46486

Cumulative Model Updates: 19,376
Cumulative Timesteps: 323,510,708

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 323510708...
Checkpoint 323510708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,233.90708
Policy Entropy: 0.74270
Value Function Loss: 0.05686

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03229
Policy Update Magnitude: 0.03131
Value Function Update Magnitude: 0.07828

Collected Steps per Second: 19,224.36243
Overall Steps per Second: 14,632.65249

Timestep Collection Time: 2.60180
Timestep Consumption Time: 0.81644
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 3.41825

Cumulative Model Updates: 19,379
Cumulative Timesteps: 323,560,726

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,128.18337
Policy Entropy: 0.74480
Value Function Loss: 0.05288

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04893
Policy Update Magnitude: 0.03187
Value Function Update Magnitude: 0.07414

Collected Steps per Second: 19,205.83028
Overall Steps per Second: 14,577.82505

Timestep Collection Time: 2.60390
Timestep Consumption Time: 0.82666
PPO Batch Consumption Time: 0.05948
Total Iteration Time: 3.43055

Cumulative Model Updates: 19,382
Cumulative Timesteps: 323,610,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 323610736...
Checkpoint 323610736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,205.71538
Policy Entropy: 0.74111
Value Function Loss: 0.04825

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.04105
Policy Update Magnitude: 0.03146
Value Function Update Magnitude: 0.07092

Collected Steps per Second: 19,255.31414
Overall Steps per Second: 14,651.24347

Timestep Collection Time: 2.59783
Timestep Consumption Time: 0.81635
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 3.41418

Cumulative Model Updates: 19,385
Cumulative Timesteps: 323,660,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,479.02115
Policy Entropy: 0.74512
Value Function Loss: 0.03853

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02003
Policy Update Magnitude: 0.03035
Value Function Update Magnitude: 0.06619

Collected Steps per Second: 19,392.52346
Overall Steps per Second: 14,055.75619

Timestep Collection Time: 2.57914
Timestep Consumption Time: 0.97926
PPO Batch Consumption Time: 0.06045
Total Iteration Time: 3.55840

Cumulative Model Updates: 19,388
Cumulative Timesteps: 323,710,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 323710774...
Checkpoint 323710774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,488.28122
Policy Entropy: 0.73228
Value Function Loss: 0.04812

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01657
Policy Update Magnitude: 0.02925
Value Function Update Magnitude: 0.06712

Collected Steps per Second: 19,552.81402
Overall Steps per Second: 14,697.51154

Timestep Collection Time: 2.55779
Timestep Consumption Time: 0.84496
PPO Batch Consumption Time: 0.06660
Total Iteration Time: 3.40275

Cumulative Model Updates: 19,391
Cumulative Timesteps: 323,760,786

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,084.28700
Policy Entropy: 0.72838
Value Function Loss: 0.05850

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02634
Policy Update Magnitude: 0.02949
Value Function Update Magnitude: 0.07473

Collected Steps per Second: 20,137.26447
Overall Steps per Second: 15,117.44123

Timestep Collection Time: 2.48405
Timestep Consumption Time: 0.82484
PPO Batch Consumption Time: 0.05807
Total Iteration Time: 3.30889

Cumulative Model Updates: 19,394
Cumulative Timesteps: 323,810,808

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 323810808...
Checkpoint 323810808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,112.03366
Policy Entropy: 0.72592
Value Function Loss: 0.06597

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01585
Policy Update Magnitude: 0.03258
Value Function Update Magnitude: 0.08220

Collected Steps per Second: 19,262.48175
Overall Steps per Second: 14,603.08073

Timestep Collection Time: 2.59707
Timestep Consumption Time: 0.82865
PPO Batch Consumption Time: 0.05935
Total Iteration Time: 3.42572

Cumulative Model Updates: 19,397
Cumulative Timesteps: 323,860,834

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,300.16237
Policy Entropy: 0.72806
Value Function Loss: 0.05984

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02793
Policy Update Magnitude: 0.03426
Value Function Update Magnitude: 0.09048

Collected Steps per Second: 19,154.23594
Overall Steps per Second: 14,541.43827

Timestep Collection Time: 2.61143
Timestep Consumption Time: 0.82839
PPO Batch Consumption Time: 0.06102
Total Iteration Time: 3.43982

Cumulative Model Updates: 19,400
Cumulative Timesteps: 323,910,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 323910854...
Checkpoint 323910854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,903.18410
Policy Entropy: 0.73280
Value Function Loss: 0.05790

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03331
Policy Update Magnitude: 0.03322
Value Function Update Magnitude: 0.09210

Collected Steps per Second: 18,920.55300
Overall Steps per Second: 14,416.78914

Timestep Collection Time: 2.64485
Timestep Consumption Time: 0.82624
PPO Batch Consumption Time: 0.05921
Total Iteration Time: 3.47109

Cumulative Model Updates: 19,403
Cumulative Timesteps: 323,960,896

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,163.02731
Policy Entropy: 0.73137
Value Function Loss: 0.06114

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.05232
Policy Update Magnitude: 0.03134
Value Function Update Magnitude: 0.09136

Collected Steps per Second: 18,930.14948
Overall Steps per Second: 14,800.78064

Timestep Collection Time: 2.64245
Timestep Consumption Time: 0.73724
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 3.37969

Cumulative Model Updates: 19,406
Cumulative Timesteps: 324,010,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 324010918...
Checkpoint 324010918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,979.45414
Policy Entropy: 0.73506
Value Function Loss: 0.05657

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04404
Policy Update Magnitude: 0.03270
Value Function Update Magnitude: 0.07855

Collected Steps per Second: 18,985.57114
Overall Steps per Second: 14,812.59957

Timestep Collection Time: 2.63548
Timestep Consumption Time: 0.74246
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 3.37794

Cumulative Model Updates: 19,409
Cumulative Timesteps: 324,060,954

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,286.65431
Policy Entropy: 0.74725
Value Function Loss: 0.04787

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03863
Policy Update Magnitude: 0.03317
Value Function Update Magnitude: 0.08668

Collected Steps per Second: 19,106.65354
Overall Steps per Second: 14,972.02684

Timestep Collection Time: 2.61752
Timestep Consumption Time: 0.72285
PPO Batch Consumption Time: 0.05326
Total Iteration Time: 3.34036

Cumulative Model Updates: 19,412
Cumulative Timesteps: 324,110,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 324110966...
Checkpoint 324110966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,558.35960
Policy Entropy: 0.75743
Value Function Loss: 0.03852

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05288
Policy Update Magnitude: 0.03171
Value Function Update Magnitude: 0.08476

Collected Steps per Second: 18,162.84570
Overall Steps per Second: 14,070.03372

Timestep Collection Time: 2.75298
Timestep Consumption Time: 0.80081
PPO Batch Consumption Time: 0.06050
Total Iteration Time: 3.55379

Cumulative Model Updates: 19,415
Cumulative Timesteps: 324,160,968

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,000.38673
Policy Entropy: 0.74705
Value Function Loss: 0.04484

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05170
Policy Update Magnitude: 0.02991
Value Function Update Magnitude: 0.06817

Collected Steps per Second: 19,567.80833
Overall Steps per Second: 14,811.45987

Timestep Collection Time: 2.55665
Timestep Consumption Time: 0.82101
PPO Batch Consumption Time: 0.06542
Total Iteration Time: 3.37765

Cumulative Model Updates: 19,418
Cumulative Timesteps: 324,210,996

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 324210996...
Checkpoint 324210996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,193.29075
Policy Entropy: 0.74421
Value Function Loss: 0.05264

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05685
Policy Update Magnitude: 0.02708
Value Function Update Magnitude: 0.05676

Collected Steps per Second: 18,847.61472
Overall Steps per Second: 14,584.84840

Timestep Collection Time: 2.65519
Timestep Consumption Time: 0.77604
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 3.43123

Cumulative Model Updates: 19,421
Cumulative Timesteps: 324,261,040

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,402.19223
Policy Entropy: 0.74292
Value Function Loss: 0.05145

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03537
Policy Update Magnitude: 0.02775
Value Function Update Magnitude: 0.05992

Collected Steps per Second: 18,247.06167
Overall Steps per Second: 14,058.13054

Timestep Collection Time: 2.74170
Timestep Consumption Time: 0.81695
PPO Batch Consumption Time: 0.06219
Total Iteration Time: 3.55865

Cumulative Model Updates: 19,424
Cumulative Timesteps: 324,311,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 324311068...
Checkpoint 324311068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,241.16290
Policy Entropy: 0.75150
Value Function Loss: 0.05129

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.02816
Value Function Update Magnitude: 0.07146

Collected Steps per Second: 19,548.91655
Overall Steps per Second: 14,907.58806

Timestep Collection Time: 2.55902
Timestep Consumption Time: 0.79672
PPO Batch Consumption Time: 0.06293
Total Iteration Time: 3.35574

Cumulative Model Updates: 19,427
Cumulative Timesteps: 324,361,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,714.03186
Policy Entropy: 0.73948
Value Function Loss: 0.04762

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06679
Policy Update Magnitude: 0.02959
Value Function Update Magnitude: 0.06589

Collected Steps per Second: 19,535.17833
Overall Steps per Second: 14,645.99506

Timestep Collection Time: 2.56102
Timestep Consumption Time: 0.85493
PPO Batch Consumption Time: 0.06709
Total Iteration Time: 3.41595

Cumulative Model Updates: 19,430
Cumulative Timesteps: 324,411,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 324411124...
Checkpoint 324411124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,519.02690
Policy Entropy: 0.74006
Value Function Loss: 0.05163

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05638
Policy Update Magnitude: 0.02977
Value Function Update Magnitude: 0.05716

Collected Steps per Second: 19,330.10114
Overall Steps per Second: 14,630.22307

Timestep Collection Time: 2.58705
Timestep Consumption Time: 0.83108
PPO Batch Consumption Time: 0.05416
Total Iteration Time: 3.41813

Cumulative Model Updates: 19,433
Cumulative Timesteps: 324,461,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,648.69106
Policy Entropy: 0.73388
Value Function Loss: 0.04712

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04691
Policy Update Magnitude: 0.02713
Value Function Update Magnitude: 0.05621

Collected Steps per Second: 18,298.88471
Overall Steps per Second: 14,032.83887

Timestep Collection Time: 2.73427
Timestep Consumption Time: 0.83123
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 3.56549

Cumulative Model Updates: 19,436
Cumulative Timesteps: 324,511,166

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 324511166...
Checkpoint 324511166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,087.54916
Policy Entropy: 0.73189
Value Function Loss: 0.04408

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03881
Policy Update Magnitude: 0.02721
Value Function Update Magnitude: 0.05749

Collected Steps per Second: 19,053.66299
Overall Steps per Second: 14,489.64657

Timestep Collection Time: 2.62490
Timestep Consumption Time: 0.82680
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 3.45171

Cumulative Model Updates: 19,439
Cumulative Timesteps: 324,561,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,401.85897
Policy Entropy: 0.72646
Value Function Loss: 0.04608

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03999
Policy Update Magnitude: 0.02695
Value Function Update Magnitude: 0.06256

Collected Steps per Second: 19,040.67696
Overall Steps per Second: 14,446.45496

Timestep Collection Time: 2.62690
Timestep Consumption Time: 0.83540
PPO Batch Consumption Time: 0.06107
Total Iteration Time: 3.46230

Cumulative Model Updates: 19,442
Cumulative Timesteps: 324,611,198

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 324611198...
Checkpoint 324611198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,716.69521
Policy Entropy: 0.72303
Value Function Loss: 0.04918

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.03047
Policy Update Magnitude: 0.02577
Value Function Update Magnitude: 0.06259

Collected Steps per Second: 19,439.29360
Overall Steps per Second: 14,667.60740

Timestep Collection Time: 2.57293
Timestep Consumption Time: 0.83703
PPO Batch Consumption Time: 0.05795
Total Iteration Time: 3.40996

Cumulative Model Updates: 19,445
Cumulative Timesteps: 324,661,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,416.63072
Policy Entropy: 0.73283
Value Function Loss: 0.05733

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.02845
Value Function Update Magnitude: 0.07037

Collected Steps per Second: 19,325.23681
Overall Steps per Second: 14,609.63021

Timestep Collection Time: 2.58750
Timestep Consumption Time: 0.83518
PPO Batch Consumption Time: 0.05422
Total Iteration Time: 3.42267

Cumulative Model Updates: 19,448
Cumulative Timesteps: 324,711,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 324711218...
Checkpoint 324711218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,900.46782
Policy Entropy: 0.74018
Value Function Loss: 0.05267

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.04287
Policy Update Magnitude: 0.03027
Value Function Update Magnitude: 0.07204

Collected Steps per Second: 19,189.44067
Overall Steps per Second: 14,686.52541

Timestep Collection Time: 2.60622
Timestep Consumption Time: 0.79907
PPO Batch Consumption Time: 0.04694
Total Iteration Time: 3.40530

Cumulative Model Updates: 19,451
Cumulative Timesteps: 324,761,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,705.60728
Policy Entropy: 0.74166
Value Function Loss: 0.04736

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.05163
Policy Update Magnitude: 0.02846
Value Function Update Magnitude: 0.07487

Collected Steps per Second: 18,419.30697
Overall Steps per Second: 13,693.00527

Timestep Collection Time: 2.71606
Timestep Consumption Time: 0.93748
PPO Batch Consumption Time: 0.06831
Total Iteration Time: 3.65354

Cumulative Model Updates: 19,454
Cumulative Timesteps: 324,811,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 324811258...
Checkpoint 324811258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,178.31674
Policy Entropy: 0.73895
Value Function Loss: 0.04050

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05649
Policy Update Magnitude: 0.02682
Value Function Update Magnitude: 0.06952

Collected Steps per Second: 18,956.64883
Overall Steps per Second: 13,446.24283

Timestep Collection Time: 2.63770
Timestep Consumption Time: 1.08096
PPO Batch Consumption Time: 0.03253
Total Iteration Time: 3.71866

Cumulative Model Updates: 19,457
Cumulative Timesteps: 324,861,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,146.24052
Policy Entropy: 0.73758
Value Function Loss: 0.04817

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02175
Policy Update Magnitude: 0.02701
Value Function Update Magnitude: 0.06788

Collected Steps per Second: 17,086.42009
Overall Steps per Second: 12,557.06084

Timestep Collection Time: 2.92806
Timestep Consumption Time: 1.05616
PPO Batch Consumption Time: 0.11475
Total Iteration Time: 3.98421

Cumulative Model Updates: 19,460
Cumulative Timesteps: 324,911,290

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 324911290...
Checkpoint 324911290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,996.79695
Policy Entropy: 0.73807
Value Function Loss: 0.05219

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.02755
Value Function Update Magnitude: 0.07282

Collected Steps per Second: 20,096.52844
Overall Steps per Second: 14,740.69334

Timestep Collection Time: 2.48849
Timestep Consumption Time: 0.90416
PPO Batch Consumption Time: 0.08713
Total Iteration Time: 3.39265

Cumulative Model Updates: 19,463
Cumulative Timesteps: 324,961,300

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,418.81323
Policy Entropy: 0.73882
Value Function Loss: 0.05405

Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.00890
Policy Update Magnitude: 0.02969
Value Function Update Magnitude: 0.07248

Collected Steps per Second: 21,296.56633
Overall Steps per Second: 16,141.71818

Timestep Collection Time: 2.34845
Timestep Consumption Time: 0.74998
PPO Batch Consumption Time: 0.06509
Total Iteration Time: 3.09843

Cumulative Model Updates: 19,466
Cumulative Timesteps: 325,011,314

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 325011314...
Checkpoint 325011314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,649.87412
Policy Entropy: 0.74310
Value Function Loss: 0.04882

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02375
Policy Update Magnitude: 0.03061
Value Function Update Magnitude: 0.07054

Collected Steps per Second: 21,684.25193
Overall Steps per Second: 16,062.40644

Timestep Collection Time: 2.30711
Timestep Consumption Time: 0.80749
PPO Batch Consumption Time: 0.08304
Total Iteration Time: 3.11460

Cumulative Model Updates: 19,469
Cumulative Timesteps: 325,061,342

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,015.86626
Policy Entropy: 0.73782
Value Function Loss: 0.04140

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02855
Policy Update Magnitude: 0.03001
Value Function Update Magnitude: 0.07408

Collected Steps per Second: 20,704.07344
Overall Steps per Second: 14,964.80148

Timestep Collection Time: 2.41576
Timestep Consumption Time: 0.92649
PPO Batch Consumption Time: 0.11893
Total Iteration Time: 3.34224

Cumulative Model Updates: 19,472
Cumulative Timesteps: 325,111,358

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 325111358...
Checkpoint 325111358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,414.26728
Policy Entropy: 0.73301
Value Function Loss: 0.04130

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04614
Policy Update Magnitude: 0.02578
Value Function Update Magnitude: 0.07735

Collected Steps per Second: 21,662.03194
Overall Steps per Second: 16,444.22622

Timestep Collection Time: 2.30902
Timestep Consumption Time: 0.73266
PPO Batch Consumption Time: 0.06247
Total Iteration Time: 3.04168

Cumulative Model Updates: 19,475
Cumulative Timesteps: 325,161,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,329.41576
Policy Entropy: 0.73229
Value Function Loss: 0.03910

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04825
Policy Update Magnitude: 0.02708
Value Function Update Magnitude: 0.06911

Collected Steps per Second: 17,900.19617
Overall Steps per Second: 13,218.43068

Timestep Collection Time: 2.79371
Timestep Consumption Time: 0.98949
PPO Batch Consumption Time: 0.09266
Total Iteration Time: 3.78320

Cumulative Model Updates: 19,478
Cumulative Timesteps: 325,211,384

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 325211384...
Checkpoint 325211384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,915.38161
Policy Entropy: 0.72621
Value Function Loss: 0.04597

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04187
Policy Update Magnitude: 0.03196
Value Function Update Magnitude: 0.06142

Collected Steps per Second: 22,649.41472
Overall Steps per Second: 16,476.68204

Timestep Collection Time: 2.20889
Timestep Consumption Time: 0.82753
PPO Batch Consumption Time: 0.07324
Total Iteration Time: 3.03641

Cumulative Model Updates: 19,481
Cumulative Timesteps: 325,261,414

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,844.32191
Policy Entropy: 0.73505
Value Function Loss: 0.04462

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03825
Policy Update Magnitude: 0.03070
Value Function Update Magnitude: 0.05980

Collected Steps per Second: 22,760.34994
Overall Steps per Second: 16,194.58313

Timestep Collection Time: 2.19768
Timestep Consumption Time: 0.89101
PPO Batch Consumption Time: 0.09754
Total Iteration Time: 3.08869

Cumulative Model Updates: 19,484
Cumulative Timesteps: 325,311,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 325311434...
Checkpoint 325311434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,511.38704
Policy Entropy: 0.73582
Value Function Loss: 0.04417

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02925
Policy Update Magnitude: 0.02980
Value Function Update Magnitude: 0.05799

Collected Steps per Second: 19,242.62588
Overall Steps per Second: 14,710.67876

Timestep Collection Time: 2.59965
Timestep Consumption Time: 0.80088
PPO Batch Consumption Time: 0.05407
Total Iteration Time: 3.40052

Cumulative Model Updates: 19,487
Cumulative Timesteps: 325,361,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,482.87216
Policy Entropy: 0.74057
Value Function Loss: 0.04441

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04886
Policy Update Magnitude: 0.03096
Value Function Update Magnitude: 0.05410

Collected Steps per Second: 22,460.75946
Overall Steps per Second: 16,986.14484

Timestep Collection Time: 2.22691
Timestep Consumption Time: 0.71773
PPO Batch Consumption Time: 0.02898
Total Iteration Time: 2.94464

Cumulative Model Updates: 19,490
Cumulative Timesteps: 325,411,476

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 325411476...
Checkpoint 325411476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,645.84973
Policy Entropy: 0.74393
Value Function Loss: 0.04290

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03876
Policy Update Magnitude: 0.03224
Value Function Update Magnitude: 0.05244

Collected Steps per Second: 22,250.10146
Overall Steps per Second: 15,542.46175

Timestep Collection Time: 2.24763
Timestep Consumption Time: 0.97001
PPO Batch Consumption Time: 0.10528
Total Iteration Time: 3.21764

Cumulative Model Updates: 19,493
Cumulative Timesteps: 325,461,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,485.56770
Policy Entropy: 0.74484
Value Function Loss: 0.04943

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05520
Policy Update Magnitude: 0.03261
Value Function Update Magnitude: 0.05056

Collected Steps per Second: 22,940.91506
Overall Steps per Second: 16,798.59349

Timestep Collection Time: 2.18047
Timestep Consumption Time: 0.79728
PPO Batch Consumption Time: 0.06170
Total Iteration Time: 2.97775

Cumulative Model Updates: 19,496
Cumulative Timesteps: 325,511,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 325511508...
Checkpoint 325511508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,557.70077
Policy Entropy: 0.73909
Value Function Loss: 0.05551

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04193
Policy Update Magnitude: 0.03112
Value Function Update Magnitude: 0.04978

Collected Steps per Second: 20,714.21541
Overall Steps per Second: 14,728.44886

Timestep Collection Time: 2.41399
Timestep Consumption Time: 0.98107
PPO Batch Consumption Time: 0.11350
Total Iteration Time: 3.39506

Cumulative Model Updates: 19,499
Cumulative Timesteps: 325,561,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,392.38157
Policy Entropy: 0.72918
Value Function Loss: 0.05972

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.04059
Policy Update Magnitude: 0.03115
Value Function Update Magnitude: 0.05797

Collected Steps per Second: 23,551.56154
Overall Steps per Second: 16,645.70895

Timestep Collection Time: 2.12394
Timestep Consumption Time: 0.88116
PPO Batch Consumption Time: 0.08143
Total Iteration Time: 3.00510

Cumulative Model Updates: 19,502
Cumulative Timesteps: 325,611,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 325611534...
Checkpoint 325611534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,316.65625
Policy Entropy: 0.73107
Value Function Loss: 0.05742

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02694
Policy Update Magnitude: 0.03345
Value Function Update Magnitude: 0.05254

Collected Steps per Second: 21,340.42627
Overall Steps per Second: 15,733.81246

Timestep Collection Time: 2.34344
Timestep Consumption Time: 0.83507
PPO Batch Consumption Time: 0.07548
Total Iteration Time: 3.17850

Cumulative Model Updates: 19,505
Cumulative Timesteps: 325,661,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,582.54014
Policy Entropy: 0.73381
Value Function Loss: 0.05287

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03428
Policy Update Magnitude: 0.03427
Value Function Update Magnitude: 0.05381

Collected Steps per Second: 23,084.22618
Overall Steps per Second: 16,787.43651

Timestep Collection Time: 2.16641
Timestep Consumption Time: 0.81260
PPO Batch Consumption Time: 0.06169
Total Iteration Time: 2.97901

Cumulative Model Updates: 19,508
Cumulative Timesteps: 325,711,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 325711554...
Checkpoint 325711554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,803.41778
Policy Entropy: 0.73721
Value Function Loss: 0.05096

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02320
Policy Update Magnitude: 0.04067
Value Function Update Magnitude: 0.05007

Collected Steps per Second: 20,143.47738
Overall Steps per Second: 14,729.38899

Timestep Collection Time: 2.48358
Timestep Consumption Time: 0.91289
PPO Batch Consumption Time: 0.09238
Total Iteration Time: 3.39647

Cumulative Model Updates: 19,511
Cumulative Timesteps: 325,761,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,355.50324
Policy Entropy: 0.73067
Value Function Loss: 0.04765

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02941
Policy Update Magnitude: 0.03907
Value Function Update Magnitude: 0.05205

Collected Steps per Second: 23,318.21565
Overall Steps per Second: 15,699.97418

Timestep Collection Time: 2.14510
Timestep Consumption Time: 1.04089
PPO Batch Consumption Time: 0.12709
Total Iteration Time: 3.18599

Cumulative Model Updates: 19,514
Cumulative Timesteps: 325,811,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 325811602...
Checkpoint 325811602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,492.20518
Policy Entropy: 0.73184
Value Function Loss: 0.04281

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02661
Policy Update Magnitude: 0.03565
Value Function Update Magnitude: 0.04953

Collected Steps per Second: 22,074.98506
Overall Steps per Second: 15,854.63452

Timestep Collection Time: 2.26637
Timestep Consumption Time: 0.88918
PPO Batch Consumption Time: 0.07841
Total Iteration Time: 3.15554

Cumulative Model Updates: 19,517
Cumulative Timesteps: 325,861,632

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 325861632...
Checkpoint 325861632 saved!
