Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,293.51019
Policy Entropy: 0.58389
Value Function Loss: 5.74970

Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.00844
Value Function Update Magnitude: 0.01278

Collected Steps per Second: 21,332.67253
Overall Steps per Second: 16,284.05170

Timestep Collection Time: 2.34382
Timestep Consumption Time: 0.72667
PPO Batch Consumption Time: 0.14001
Total Iteration Time: 3.07049

Cumulative Model Updates: 9,628
Cumulative Timesteps: 160,751,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,926.36992
Policy Entropy: 0.61159
Value Function Loss: 5.48166

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00640
Policy Update Magnitude: 0.00904
Value Function Update Magnitude: 0.01708

Collected Steps per Second: 22,255.15130
Overall Steps per Second: 16,693.84405

Timestep Collection Time: 2.24793
Timestep Consumption Time: 0.74886
PPO Batch Consumption Time: 0.15439
Total Iteration Time: 2.99679

Cumulative Model Updates: 9,629
Cumulative Timesteps: 160,801,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 160801900...
Checkpoint 160801900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,097.22485
Policy Entropy: 0.61330
Value Function Loss: 4.56239

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03381
Policy Update Magnitude: 0.02228
Value Function Update Magnitude: 0.04991

Collected Steps per Second: 19,564.41579
Overall Steps per Second: 14,651.71893

Timestep Collection Time: 2.55658
Timestep Consumption Time: 0.85722
PPO Batch Consumption Time: 0.12269
Total Iteration Time: 3.41380

Cumulative Model Updates: 9,631
Cumulative Timesteps: 160,851,918

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,644.08758
Policy Entropy: 0.62480
Value Function Loss: 3.13375

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04906
Policy Update Magnitude: 0.02518
Value Function Update Magnitude: 0.10391

Collected Steps per Second: 22,709.27404
Overall Steps per Second: 16,778.84030

Timestep Collection Time: 2.20306
Timestep Consumption Time: 0.77867
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 2.98173

Cumulative Model Updates: 9,634
Cumulative Timesteps: 160,901,948

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 160901948...
Checkpoint 160901948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,157.79984
Policy Entropy: 0.63001
Value Function Loss: 2.85803

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04497
Policy Update Magnitude: 0.02336
Value Function Update Magnitude: 0.10084

Collected Steps per Second: 19,931.83826
Overall Steps per Second: 14,634.73385

Timestep Collection Time: 2.50985
Timestep Consumption Time: 0.90845
PPO Batch Consumption Time: 0.09802
Total Iteration Time: 3.41831

Cumulative Model Updates: 9,637
Cumulative Timesteps: 160,951,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,554.22979
Policy Entropy: 0.63032
Value Function Loss: 3.34308

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02603
Policy Update Magnitude: 0.02488
Value Function Update Magnitude: 0.09763

Collected Steps per Second: 22,972.24733
Overall Steps per Second: 17,013.33581

Timestep Collection Time: 2.17663
Timestep Consumption Time: 0.76236
PPO Batch Consumption Time: 0.05317
Total Iteration Time: 2.93899

Cumulative Model Updates: 9,640
Cumulative Timesteps: 161,001,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 161001976...
Checkpoint 161001976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,416.05601
Policy Entropy: 0.63161
Value Function Loss: 3.30040

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03477
Policy Update Magnitude: 0.02574
Value Function Update Magnitude: 0.11148

Collected Steps per Second: 20,332.05638
Overall Steps per Second: 14,711.32748

Timestep Collection Time: 2.45986
Timestep Consumption Time: 0.93983
PPO Batch Consumption Time: 0.10632
Total Iteration Time: 3.39969

Cumulative Model Updates: 9,643
Cumulative Timesteps: 161,051,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,482.63014
Policy Entropy: 0.62399
Value Function Loss: 3.56882

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03103
Policy Update Magnitude: 0.03012
Value Function Update Magnitude: 0.11792

Collected Steps per Second: 21,872.89567
Overall Steps per Second: 15,652.70196

Timestep Collection Time: 2.28621
Timestep Consumption Time: 0.90851
PPO Batch Consumption Time: 0.09935
Total Iteration Time: 3.19472

Cumulative Model Updates: 9,646
Cumulative Timesteps: 161,101,996

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 161101996...
Checkpoint 161101996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,482.64579
Policy Entropy: 0.62993
Value Function Loss: 3.94979

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03748
Policy Update Magnitude: 0.03057
Value Function Update Magnitude: 0.11169

Collected Steps per Second: 22,372.11433
Overall Steps per Second: 16,679.28242

Timestep Collection Time: 2.23510
Timestep Consumption Time: 0.76287
PPO Batch Consumption Time: 0.05187
Total Iteration Time: 2.99797

Cumulative Model Updates: 9,649
Cumulative Timesteps: 161,152,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,173.84709
Policy Entropy: 0.63958
Value Function Loss: 4.22786

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06908
Policy Update Magnitude: 0.02681
Value Function Update Magnitude: 0.09476

Collected Steps per Second: 19,772.00281
Overall Steps per Second: 14,774.18334

Timestep Collection Time: 2.52923
Timestep Consumption Time: 0.85559
PPO Batch Consumption Time: 0.07785
Total Iteration Time: 3.38482

Cumulative Model Updates: 9,652
Cumulative Timesteps: 161,202,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 161202008...
Checkpoint 161202008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,067.33388
Policy Entropy: 0.63960
Value Function Loss: 4.17754

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04016
Policy Update Magnitude: 0.02578
Value Function Update Magnitude: 0.08351

Collected Steps per Second: 22,613.83860
Overall Steps per Second: 15,827.66400

Timestep Collection Time: 2.21210
Timestep Consumption Time: 0.94845
PPO Batch Consumption Time: 0.11012
Total Iteration Time: 3.16054

Cumulative Model Updates: 9,655
Cumulative Timesteps: 161,252,032

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,574.56961
Policy Entropy: 0.64115
Value Function Loss: 4.10971

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.05197
Policy Update Magnitude: 0.02339
Value Function Update Magnitude: 0.09876

Collected Steps per Second: 22,871.11959
Overall Steps per Second: 16,831.39723

Timestep Collection Time: 2.18616
Timestep Consumption Time: 0.78448
PPO Batch Consumption Time: 0.05859
Total Iteration Time: 2.97064

Cumulative Model Updates: 9,658
Cumulative Timesteps: 161,302,032

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 161302032...
Checkpoint 161302032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,829.81760
Policy Entropy: 0.65012
Value Function Loss: 3.86333

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04561
Policy Update Magnitude: 0.02299
Value Function Update Magnitude: 0.10919

Collected Steps per Second: 20,964.37728
Overall Steps per Second: 14,736.38673

Timestep Collection Time: 2.38662
Timestep Consumption Time: 1.00865
PPO Batch Consumption Time: 0.12729
Total Iteration Time: 3.39527

Cumulative Model Updates: 9,661
Cumulative Timesteps: 161,352,066

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,850.53521
Policy Entropy: 0.64599
Value Function Loss: 3.91900

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03605
Policy Update Magnitude: 0.02326
Value Function Update Magnitude: 0.11333

Collected Steps per Second: 23,122.26064
Overall Steps per Second: 16,533.08495

Timestep Collection Time: 2.16294
Timestep Consumption Time: 0.86203
PPO Batch Consumption Time: 0.07918
Total Iteration Time: 3.02496

Cumulative Model Updates: 9,664
Cumulative Timesteps: 161,402,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 161402078...
Checkpoint 161402078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,169.38643
Policy Entropy: 0.65260
Value Function Loss: 3.91114

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 0.03032
Value Function Update Magnitude: 0.09717

Collected Steps per Second: 22,529.24775
Overall Steps per Second: 15,821.14688

Timestep Collection Time: 2.21969
Timestep Consumption Time: 0.94114
PPO Batch Consumption Time: 0.10830
Total Iteration Time: 3.16083

Cumulative Model Updates: 9,667
Cumulative Timesteps: 161,452,086

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,608.00323
Policy Entropy: 0.65428
Value Function Loss: 3.93244

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.05463
Policy Update Magnitude: 0.02978
Value Function Update Magnitude: 0.08717

Collected Steps per Second: 22,604.63489
Overall Steps per Second: 16,687.27194

Timestep Collection Time: 2.21291
Timestep Consumption Time: 0.78471
PPO Batch Consumption Time: 0.05346
Total Iteration Time: 2.99761

Cumulative Model Updates: 9,670
Cumulative Timesteps: 161,502,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 161502108...
Checkpoint 161502108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,160.64564
Policy Entropy: 0.66748
Value Function Loss: 3.76467

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.07355
Policy Update Magnitude: 0.02645
Value Function Update Magnitude: 0.07383

Collected Steps per Second: 19,976.65382
Overall Steps per Second: 14,736.60000

Timestep Collection Time: 2.50302
Timestep Consumption Time: 0.89003
PPO Batch Consumption Time: 0.08831
Total Iteration Time: 3.39305

Cumulative Model Updates: 9,673
Cumulative Timesteps: 161,552,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,469.90178
Policy Entropy: 0.68095
Value Function Loss: 3.43293

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.02165
Value Function Update Magnitude: 0.07203

Collected Steps per Second: 22,775.52898
Overall Steps per Second: 15,704.18313

Timestep Collection Time: 2.19604
Timestep Consumption Time: 0.98884
PPO Batch Consumption Time: 0.12217
Total Iteration Time: 3.18488

Cumulative Model Updates: 9,676
Cumulative Timesteps: 161,602,126

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 161602126...
Checkpoint 161602126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,807.78440
Policy Entropy: 0.68862
Value Function Loss: 3.43339

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.06766
Policy Update Magnitude: 0.02051
Value Function Update Magnitude: 0.06625

Collected Steps per Second: 22,768.44442
Overall Steps per Second: 16,702.13297

Timestep Collection Time: 2.19734
Timestep Consumption Time: 0.79809
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 2.99543

Cumulative Model Updates: 9,679
Cumulative Timesteps: 161,652,156

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,961.83688
Policy Entropy: 0.68944
Value Function Loss: 3.28299

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.05341
Policy Update Magnitude: 0.02421
Value Function Update Magnitude: 0.06990

Collected Steps per Second: 19,383.03963
Overall Steps per Second: 13,990.65859

Timestep Collection Time: 2.58061
Timestep Consumption Time: 0.99464
PPO Batch Consumption Time: 0.10838
Total Iteration Time: 3.57524

Cumulative Model Updates: 9,682
Cumulative Timesteps: 161,702,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 161702176...
Checkpoint 161702176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,830.31538
Policy Entropy: 0.68290
Value Function Loss: 3.18606

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.05321
Policy Update Magnitude: 0.02518
Value Function Update Magnitude: 0.05822

Collected Steps per Second: 20,190.40568
Overall Steps per Second: 15,363.37837

Timestep Collection Time: 2.47652
Timestep Consumption Time: 0.77810
PPO Batch Consumption Time: 0.05787
Total Iteration Time: 3.25462

Cumulative Model Updates: 9,685
Cumulative Timesteps: 161,752,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,323.21436
Policy Entropy: 0.67892
Value Function Loss: 2.98489

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.07825
Policy Update Magnitude: 0.02476
Value Function Update Magnitude: 0.05366

Collected Steps per Second: 17,500.40767
Overall Steps per Second: 13,571.81215

Timestep Collection Time: 2.85708
Timestep Consumption Time: 0.82703
PPO Batch Consumption Time: 0.03297
Total Iteration Time: 3.68411

Cumulative Model Updates: 9,688
Cumulative Timesteps: 161,802,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 161802178...
Checkpoint 161802178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,330.00199
Policy Entropy: 0.68859
Value Function Loss: 2.86623

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04874
Policy Update Magnitude: 0.02235
Value Function Update Magnitude: 0.05963

Collected Steps per Second: 19,561.18419
Overall Steps per Second: 14,609.21831

Timestep Collection Time: 2.55639
Timestep Consumption Time: 0.86652
PPO Batch Consumption Time: 0.03287
Total Iteration Time: 3.42291

Cumulative Model Updates: 9,691
Cumulative Timesteps: 161,852,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,500.99364
Policy Entropy: 0.68388
Value Function Loss: 2.86271

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03777
Policy Update Magnitude: 0.02196
Value Function Update Magnitude: 0.06501

Collected Steps per Second: 19,224.85380
Overall Steps per Second: 14,483.81298

Timestep Collection Time: 2.60174
Timestep Consumption Time: 0.85164
PPO Batch Consumption Time: 0.06958
Total Iteration Time: 3.45337

Cumulative Model Updates: 9,694
Cumulative Timesteps: 161,902,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 161902202...
Checkpoint 161902202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,492.91030
Policy Entropy: 0.68032
Value Function Loss: 2.97761

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.06113
Policy Update Magnitude: 0.02675
Value Function Update Magnitude: 0.06045

Collected Steps per Second: 18,639.14560
Overall Steps per Second: 13,803.61334

Timestep Collection Time: 2.68328
Timestep Consumption Time: 0.93998
PPO Batch Consumption Time: 0.08120
Total Iteration Time: 3.62325

Cumulative Model Updates: 9,697
Cumulative Timesteps: 161,952,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,718.06375
Policy Entropy: 0.67429
Value Function Loss: 2.99535

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07929
Policy Update Magnitude: 0.02510
Value Function Update Magnitude: 0.05033

Collected Steps per Second: 20,254.27023
Overall Steps per Second: 15,129.05435

Timestep Collection Time: 2.46921
Timestep Consumption Time: 0.83648
PPO Batch Consumption Time: 0.07020
Total Iteration Time: 3.30569

Cumulative Model Updates: 9,700
Cumulative Timesteps: 162,002,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 162002228...
Checkpoint 162002228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,250.33591
Policy Entropy: 0.66722
Value Function Loss: 3.21634

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.06329
Policy Update Magnitude: 0.02023
Value Function Update Magnitude: 0.06943

Collected Steps per Second: 21,866.93027
Overall Steps per Second: 15,708.34488

Timestep Collection Time: 2.28729
Timestep Consumption Time: 0.89675
PPO Batch Consumption Time: 0.08092
Total Iteration Time: 3.18404

Cumulative Model Updates: 9,703
Cumulative Timesteps: 162,052,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,507.40310
Policy Entropy: 0.66573
Value Function Loss: 3.14653

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03887
Policy Update Magnitude: 0.02623
Value Function Update Magnitude: 0.06029

Collected Steps per Second: 22,079.34376
Overall Steps per Second: 16,141.24366

Timestep Collection Time: 2.26538
Timestep Consumption Time: 0.83339
PPO Batch Consumption Time: 0.06816
Total Iteration Time: 3.09877

Cumulative Model Updates: 9,706
Cumulative Timesteps: 162,102,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 162102262...
Checkpoint 162102262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,942.56892
Policy Entropy: 0.66158
Value Function Loss: 3.45507

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05769
Policy Update Magnitude: 0.02937
Value Function Update Magnitude: 0.05637

Collected Steps per Second: 21,105.96613
Overall Steps per Second: 15,331.65043

Timestep Collection Time: 2.36900
Timestep Consumption Time: 0.89223
PPO Batch Consumption Time: 0.11183
Total Iteration Time: 3.26123

Cumulative Model Updates: 9,709
Cumulative Timesteps: 162,152,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,520.94414
Policy Entropy: 0.65050
Value Function Loss: 3.41593

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03575
Policy Update Magnitude: 0.02480
Value Function Update Magnitude: 0.05178

Collected Steps per Second: 23,184.77872
Overall Steps per Second: 16,757.57900

Timestep Collection Time: 2.15736
Timestep Consumption Time: 0.82743
PPO Batch Consumption Time: 0.09508
Total Iteration Time: 2.98480

Cumulative Model Updates: 9,712
Cumulative Timesteps: 162,202,280

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 162202280...
Checkpoint 162202280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,633.32990
Policy Entropy: 0.64210
Value Function Loss: 3.65879

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05841
Policy Update Magnitude: 0.02080
Value Function Update Magnitude: 0.06325

Collected Steps per Second: 23,114.28721
Overall Steps per Second: 16,762.39577

Timestep Collection Time: 2.16394
Timestep Consumption Time: 0.82000
PPO Batch Consumption Time: 0.09039
Total Iteration Time: 2.98394

Cumulative Model Updates: 9,715
Cumulative Timesteps: 162,252,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,501.60733
Policy Entropy: 0.64490
Value Function Loss: 3.49347

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.04108
Policy Update Magnitude: 0.02135
Value Function Update Magnitude: 0.05803

Collected Steps per Second: 23,310.30576
Overall Steps per Second: 16,683.06021

Timestep Collection Time: 2.14575
Timestep Consumption Time: 0.85238
PPO Batch Consumption Time: 0.07908
Total Iteration Time: 2.99813

Cumulative Model Updates: 9,718
Cumulative Timesteps: 162,302,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 162302316...
Checkpoint 162302316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,189.97944
Policy Entropy: 0.64876
Value Function Loss: 3.50804

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.05060
Policy Update Magnitude: 0.02611
Value Function Update Magnitude: 0.05456

Collected Steps per Second: 22,971.31561
Overall Steps per Second: 16,770.34146

Timestep Collection Time: 2.17767
Timestep Consumption Time: 0.80521
PPO Batch Consumption Time: 0.08366
Total Iteration Time: 2.98288

Cumulative Model Updates: 9,721
Cumulative Timesteps: 162,352,340

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,462.46687
Policy Entropy: 0.65639
Value Function Loss: 3.52096

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.02261
Value Function Update Magnitude: 0.05388

Collected Steps per Second: 23,389.48196
Overall Steps per Second: 16,689.20310

Timestep Collection Time: 2.13857
Timestep Consumption Time: 0.85858
PPO Batch Consumption Time: 0.07978
Total Iteration Time: 2.99715

Cumulative Model Updates: 9,724
Cumulative Timesteps: 162,402,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 162402360...
Checkpoint 162402360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,796.52979
Policy Entropy: 0.64797
Value Function Loss: 3.60109

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.01964
Value Function Update Magnitude: 0.05047

Collected Steps per Second: 23,079.75101
Overall Steps per Second: 16,954.52584

Timestep Collection Time: 2.16657
Timestep Consumption Time: 0.78273
PPO Batch Consumption Time: 0.05889
Total Iteration Time: 2.94930

Cumulative Model Updates: 9,727
Cumulative Timesteps: 162,452,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,169.82812
Policy Entropy: 0.64557
Value Function Loss: 3.75194

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.06369
Policy Update Magnitude: 0.02547
Value Function Update Magnitude: 0.04909

Collected Steps per Second: 21,101.99801
Overall Steps per Second: 15,361.29684

Timestep Collection Time: 2.37020
Timestep Consumption Time: 0.88577
PPO Batch Consumption Time: 0.09087
Total Iteration Time: 3.25598

Cumulative Model Updates: 9,730
Cumulative Timesteps: 162,502,380

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 162502380...
Checkpoint 162502380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,392.77581
Policy Entropy: 0.64068
Value Function Loss: 3.77515

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.05574
Policy Update Magnitude: 0.02198
Value Function Update Magnitude: 0.04648

Collected Steps per Second: 23,638.27205
Overall Steps per Second: 17,253.15469

Timestep Collection Time: 2.11589
Timestep Consumption Time: 0.78306
PPO Batch Consumption Time: 0.06214
Total Iteration Time: 2.89895

Cumulative Model Updates: 9,733
Cumulative Timesteps: 162,552,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,520.17011
Policy Entropy: 0.64109
Value Function Loss: 3.92797

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12327
Policy Update Magnitude: 0.02818
Value Function Update Magnitude: 0.05032

Collected Steps per Second: 23,946.95274
Overall Steps per Second: 17,498.45660

Timestep Collection Time: 2.08920
Timestep Consumption Time: 0.76991
PPO Batch Consumption Time: 0.06031
Total Iteration Time: 2.85911

Cumulative Model Updates: 9,736
Cumulative Timesteps: 162,602,426

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 162602426...
Checkpoint 162602426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,210.30194
Policy Entropy: 0.61774
Value Function Loss: 4.55703

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.02373
Value Function Update Magnitude: 0.04349

Collected Steps per Second: 20,349.84691
Overall Steps per Second: 14,746.53237

Timestep Collection Time: 2.45928
Timestep Consumption Time: 0.93447
PPO Batch Consumption Time: 0.10525
Total Iteration Time: 3.39375

Cumulative Model Updates: 9,739
Cumulative Timesteps: 162,652,472

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,431.68320
Policy Entropy: 0.62321
Value Function Loss: 4.40453

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.01867
Value Function Update Magnitude: 0.04634

Collected Steps per Second: 23,604.99676
Overall Steps per Second: 17,715.40057

Timestep Collection Time: 2.11853
Timestep Consumption Time: 0.70432
PPO Batch Consumption Time: 0.05981
Total Iteration Time: 2.82285

Cumulative Model Updates: 9,742
Cumulative Timesteps: 162,702,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 162702480...
Checkpoint 162702480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,358.38661
Policy Entropy: 0.60664
Value Function Loss: 4.81152

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.06633
Policy Update Magnitude: 0.01867
Value Function Update Magnitude: 0.05049

Collected Steps per Second: 20,966.22644
Overall Steps per Second: 15,085.96408

Timestep Collection Time: 2.38536
Timestep Consumption Time: 0.92977
PPO Batch Consumption Time: 0.10845
Total Iteration Time: 3.31513

Cumulative Model Updates: 9,745
Cumulative Timesteps: 162,752,492

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,561.30460
Policy Entropy: 0.62211
Value Function Loss: 4.37342

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05909
Policy Update Magnitude: 0.02071
Value Function Update Magnitude: 0.05138

Collected Steps per Second: 23,452.75688
Overall Steps per Second: 16,653.02386

Timestep Collection Time: 2.13280
Timestep Consumption Time: 0.87086
PPO Batch Consumption Time: 0.08631
Total Iteration Time: 3.00366

Cumulative Model Updates: 9,748
Cumulative Timesteps: 162,802,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 162802512...
Checkpoint 162802512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,919.00271
Policy Entropy: 0.62104
Value Function Loss: 4.41339

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03022
Policy Update Magnitude: 0.02860
Value Function Update Magnitude: 0.04579

Collected Steps per Second: 23,389.08813
Overall Steps per Second: 16,781.77618

Timestep Collection Time: 2.13852
Timestep Consumption Time: 0.84198
PPO Batch Consumption Time: 0.08048
Total Iteration Time: 2.98049

Cumulative Model Updates: 9,751
Cumulative Timesteps: 162,852,530

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,802.10917
Policy Entropy: 0.62637
Value Function Loss: 4.19251

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02789
Policy Update Magnitude: 0.02813
Value Function Update Magnitude: 0.04977

Collected Steps per Second: 23,627.07752
Overall Steps per Second: 16,549.66754

Timestep Collection Time: 2.11757
Timestep Consumption Time: 0.90557
PPO Batch Consumption Time: 0.09285
Total Iteration Time: 3.02314

Cumulative Model Updates: 9,754
Cumulative Timesteps: 162,902,562

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 162902562...
Checkpoint 162902562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,115.50086
Policy Entropy: 0.62198
Value Function Loss: 4.32027

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05645
Policy Update Magnitude: 0.02589
Value Function Update Magnitude: 0.05650

Collected Steps per Second: 23,173.54628
Overall Steps per Second: 16,965.11464

Timestep Collection Time: 2.15850
Timestep Consumption Time: 0.78991
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 2.94840

Cumulative Model Updates: 9,757
Cumulative Timesteps: 162,952,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,421.64941
Policy Entropy: 0.61792
Value Function Loss: 4.28586

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.06359
Policy Update Magnitude: 0.02629
Value Function Update Magnitude: 0.05558

Collected Steps per Second: 21,511.51050
Overall Steps per Second: 15,517.73631

Timestep Collection Time: 2.32648
Timestep Consumption Time: 0.89861
PPO Batch Consumption Time: 0.09254
Total Iteration Time: 3.22508

Cumulative Model Updates: 9,760
Cumulative Timesteps: 163,002,628

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 163002628...
Checkpoint 163002628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,917.48034
Policy Entropy: 0.61948
Value Function Loss: 4.38407

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.05047
Policy Update Magnitude: 0.02399
Value Function Update Magnitude: 0.04560

Collected Steps per Second: 23,394.60083
Overall Steps per Second: 17,515.50108

Timestep Collection Time: 2.13784
Timestep Consumption Time: 0.71757
PPO Batch Consumption Time: 0.05917
Total Iteration Time: 2.85541

Cumulative Model Updates: 9,763
Cumulative Timesteps: 163,052,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,218.26320
Policy Entropy: 0.61442
Value Function Loss: 4.46500

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.05385
Policy Update Magnitude: 0.02509
Value Function Update Magnitude: 0.04898

Collected Steps per Second: 20,868.28958
Overall Steps per Second: 15,224.66796

Timestep Collection Time: 2.39675
Timestep Consumption Time: 0.88845
PPO Batch Consumption Time: 0.09402
Total Iteration Time: 3.28519

Cumulative Model Updates: 9,766
Cumulative Timesteps: 163,102,658

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 163102658...
Checkpoint 163102658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,358.37832
Policy Entropy: 0.60838
Value Function Loss: 4.65016

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04771
Policy Update Magnitude: 0.02111
Value Function Update Magnitude: 0.04988

Collected Steps per Second: 23,517.27382
Overall Steps per Second: 17,108.19576

Timestep Collection Time: 2.12712
Timestep Consumption Time: 0.79686
PPO Batch Consumption Time: 0.06048
Total Iteration Time: 2.92398

Cumulative Model Updates: 9,769
Cumulative Timesteps: 163,152,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,240.17623
Policy Entropy: 0.60731
Value Function Loss: 4.38935

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03220
Policy Update Magnitude: 0.02703
Value Function Update Magnitude: 0.04845

Collected Steps per Second: 20,357.17221
Overall Steps per Second: 14,561.07496

Timestep Collection Time: 2.45741
Timestep Consumption Time: 0.97818
PPO Batch Consumption Time: 0.11407
Total Iteration Time: 3.43560

Cumulative Model Updates: 9,772
Cumulative Timesteps: 163,202,708

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 163202708...
Checkpoint 163202708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,801.53419
Policy Entropy: 0.59774
Value Function Loss: 4.58446

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03484
Policy Update Magnitude: 0.02481
Value Function Update Magnitude: 0.04554

Collected Steps per Second: 22,540.80592
Overall Steps per Second: 16,741.55803

Timestep Collection Time: 2.21882
Timestep Consumption Time: 0.76860
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 2.98742

Cumulative Model Updates: 9,775
Cumulative Timesteps: 163,252,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,109.24360
Policy Entropy: 0.59863
Value Function Loss: 4.68448

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03831
Policy Update Magnitude: 0.03056
Value Function Update Magnitude: 0.04725

Collected Steps per Second: 18,715.74997
Overall Steps per Second: 13,938.73149

Timestep Collection Time: 2.67294
Timestep Consumption Time: 0.91606
PPO Batch Consumption Time: 0.09443
Total Iteration Time: 3.58899

Cumulative Model Updates: 9,778
Cumulative Timesteps: 163,302,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 163302748...
Checkpoint 163302748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,451.58426
Policy Entropy: 0.60345
Value Function Loss: 4.54424

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05961
Policy Update Magnitude: 0.02639
Value Function Update Magnitude: 0.04533

Collected Steps per Second: 21,629.56501
Overall Steps per Second: 16,499.22936

Timestep Collection Time: 2.31285
Timestep Consumption Time: 0.71917
PPO Batch Consumption Time: 0.05814
Total Iteration Time: 3.03202

Cumulative Model Updates: 9,781
Cumulative Timesteps: 163,352,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,801.57566
Policy Entropy: 0.60609
Value Function Loss: 4.38454

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05619
Policy Update Magnitude: 0.02080
Value Function Update Magnitude: 0.05271

Collected Steps per Second: 18,627.12606
Overall Steps per Second: 13,399.73881

Timestep Collection Time: 2.68479
Timestep Consumption Time: 1.04737
PPO Batch Consumption Time: 0.12054
Total Iteration Time: 3.73216

Cumulative Model Updates: 9,784
Cumulative Timesteps: 163,402,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 163402784...
Checkpoint 163402784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,269.10092
Policy Entropy: 0.60496
Value Function Loss: 4.27766

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.02488
Value Function Update Magnitude: 0.05601

Collected Steps per Second: 21,496.05955
Overall Steps per Second: 15,850.43679

Timestep Collection Time: 2.32647
Timestep Consumption Time: 0.82865
PPO Batch Consumption Time: 0.07262
Total Iteration Time: 3.15512

Cumulative Model Updates: 9,787
Cumulative Timesteps: 163,452,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,127.74604
Policy Entropy: 0.59542
Value Function Loss: 4.83906

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.01883
Value Function Update Magnitude: 0.05002

Collected Steps per Second: 21,692.22783
Overall Steps per Second: 15,478.94301

Timestep Collection Time: 2.30709
Timestep Consumption Time: 0.92607
PPO Batch Consumption Time: 0.09457
Total Iteration Time: 3.23317

Cumulative Model Updates: 9,790
Cumulative Timesteps: 163,502,840

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 163502840...
Checkpoint 163502840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,342.23639
Policy Entropy: 0.59416
Value Function Loss: 4.58801

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08699
Policy Update Magnitude: 0.02377
Value Function Update Magnitude: 0.05531

Collected Steps per Second: 22,172.29936
Overall Steps per Second: 16,119.02519

Timestep Collection Time: 2.25606
Timestep Consumption Time: 0.84723
PPO Batch Consumption Time: 0.07593
Total Iteration Time: 3.10329

Cumulative Model Updates: 9,793
Cumulative Timesteps: 163,552,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,400.34948
Policy Entropy: 0.57864
Value Function Loss: 5.20385

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07151
Policy Update Magnitude: 0.02047
Value Function Update Magnitude: 0.06048

Collected Steps per Second: 22,458.02702
Overall Steps per Second: 16,279.61306

Timestep Collection Time: 2.22727
Timestep Consumption Time: 0.84529
PPO Batch Consumption Time: 0.10453
Total Iteration Time: 3.07255

Cumulative Model Updates: 9,796
Cumulative Timesteps: 163,602,882

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 163602882...
Checkpoint 163602882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,248.19573
Policy Entropy: 0.57212
Value Function Loss: 5.08251

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07345
Policy Update Magnitude: 0.02286
Value Function Update Magnitude: 0.05329

Collected Steps per Second: 21,012.33202
Overall Steps per Second: 15,960.27416

Timestep Collection Time: 2.38070
Timestep Consumption Time: 0.75358
PPO Batch Consumption Time: 0.07290
Total Iteration Time: 3.13428

Cumulative Model Updates: 9,799
Cumulative Timesteps: 163,652,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,549.98807
Policy Entropy: 0.55876
Value Function Loss: 5.41754

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06814
Policy Update Magnitude: 0.02110
Value Function Update Magnitude: 0.04898

Collected Steps per Second: 22,880.83338
Overall Steps per Second: 16,376.72239

Timestep Collection Time: 2.18532
Timestep Consumption Time: 0.86791
PPO Batch Consumption Time: 0.07718
Total Iteration Time: 3.05324

Cumulative Model Updates: 9,802
Cumulative Timesteps: 163,702,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 163702908...
Checkpoint 163702908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,736.29999
Policy Entropy: 0.56262
Value Function Loss: 5.18903

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.06932
Policy Update Magnitude: 0.02181
Value Function Update Magnitude: 0.04659

Collected Steps per Second: 21,930.05047
Overall Steps per Second: 15,766.93875

Timestep Collection Time: 2.28125
Timestep Consumption Time: 0.89172
PPO Batch Consumption Time: 0.09103
Total Iteration Time: 3.17297

Cumulative Model Updates: 9,805
Cumulative Timesteps: 163,752,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,320.97136
Policy Entropy: 0.56158
Value Function Loss: 5.18443

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03531
Policy Update Magnitude: 0.02438
Value Function Update Magnitude: 0.06158

Collected Steps per Second: 21,465.75972
Overall Steps per Second: 16,147.36326

Timestep Collection Time: 2.32948
Timestep Consumption Time: 0.76725
PPO Batch Consumption Time: 0.05853
Total Iteration Time: 3.09673

Cumulative Model Updates: 9,808
Cumulative Timesteps: 163,802,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 163802940...
Checkpoint 163802940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,476.75351
Policy Entropy: 0.56168
Value Function Loss: 5.08839

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.02599
Value Function Update Magnitude: 0.05957

Collected Steps per Second: 19,814.38216
Overall Steps per Second: 15,861.84079

Timestep Collection Time: 2.52483
Timestep Consumption Time: 0.62915
PPO Batch Consumption Time: 0.02932
Total Iteration Time: 3.15398

Cumulative Model Updates: 9,811
Cumulative Timesteps: 163,852,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,515.41120
Policy Entropy: 0.56088
Value Function Loss: 4.98571

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03930
Policy Update Magnitude: 0.02792
Value Function Update Magnitude: 0.06683

Collected Steps per Second: 20,822.38642
Overall Steps per Second: 15,806.54483

Timestep Collection Time: 2.40174
Timestep Consumption Time: 0.76214
PPO Batch Consumption Time: 0.03349
Total Iteration Time: 3.16388

Cumulative Model Updates: 9,814
Cumulative Timesteps: 163,902,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 163902978...
Checkpoint 163902978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,074.53193
Policy Entropy: 0.56377
Value Function Loss: 4.97316

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.05312
Policy Update Magnitude: 0.03303
Value Function Update Magnitude: 0.06445

Collected Steps per Second: 21,135.52816
Overall Steps per Second: 16,085.23147

Timestep Collection Time: 2.36635
Timestep Consumption Time: 0.74296
PPO Batch Consumption Time: 0.02918
Total Iteration Time: 3.10931

Cumulative Model Updates: 9,817
Cumulative Timesteps: 163,952,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,523.36017
Policy Entropy: 0.55439
Value Function Loss: 5.07123

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.06656
Policy Update Magnitude: 0.02995
Value Function Update Magnitude: 0.05344

Collected Steps per Second: 18,413.96321
Overall Steps per Second: 13,811.97732

Timestep Collection Time: 2.71598
Timestep Consumption Time: 0.90493
PPO Batch Consumption Time: 0.10405
Total Iteration Time: 3.62092

Cumulative Model Updates: 9,820
Cumulative Timesteps: 164,003,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 164003004...
Checkpoint 164003004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,119.22346
Policy Entropy: 0.56468
Value Function Loss: 4.69520

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05925
Policy Update Magnitude: 0.02746
Value Function Update Magnitude: 0.04445

Collected Steps per Second: 21,522.12712
Overall Steps per Second: 15,980.52309

Timestep Collection Time: 2.32440
Timestep Consumption Time: 0.80604
PPO Batch Consumption Time: 0.06404
Total Iteration Time: 3.13044

Cumulative Model Updates: 9,823
Cumulative Timesteps: 164,053,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,244.46089
Policy Entropy: 0.55298
Value Function Loss: 4.69409

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.06301
Policy Update Magnitude: 0.02572
Value Function Update Magnitude: 0.05423

Collected Steps per Second: 21,682.17051
Overall Steps per Second: 16,362.64195

Timestep Collection Time: 2.30650
Timestep Consumption Time: 0.74985
PPO Batch Consumption Time: 0.02972
Total Iteration Time: 3.05635

Cumulative Model Updates: 9,826
Cumulative Timesteps: 164,103,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 164103040...
Checkpoint 164103040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,996.98353
Policy Entropy: 0.55890
Value Function Loss: 4.63166

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08308
Policy Update Magnitude: 0.02478
Value Function Update Magnitude: 0.05397

Collected Steps per Second: 21,202.07686
Overall Steps per Second: 15,450.40317

Timestep Collection Time: 2.35845
Timestep Consumption Time: 0.87797
PPO Batch Consumption Time: 0.08947
Total Iteration Time: 3.23642

Cumulative Model Updates: 9,829
Cumulative Timesteps: 164,153,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,521.70157
Policy Entropy: 0.54896
Value Function Loss: 4.76411

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.05316
Policy Update Magnitude: 0.02219
Value Function Update Magnitude: 0.05049

Collected Steps per Second: 18,954.13090
Overall Steps per Second: 14,478.53543

Timestep Collection Time: 2.63805
Timestep Consumption Time: 0.81547
PPO Batch Consumption Time: 0.03013
Total Iteration Time: 3.45353

Cumulative Model Updates: 9,832
Cumulative Timesteps: 164,203,046

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 164203046...
Checkpoint 164203046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,513.25643
Policy Entropy: 0.55322
Value Function Loss: 4.80749

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06587
Policy Update Magnitude: 0.02191
Value Function Update Magnitude: 0.04731

Collected Steps per Second: 22,388.84078
Overall Steps per Second: 16,629.74087

Timestep Collection Time: 2.23379
Timestep Consumption Time: 0.77359
PPO Batch Consumption Time: 0.03883
Total Iteration Time: 3.00738

Cumulative Model Updates: 9,835
Cumulative Timesteps: 164,253,058

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,182.94928
Policy Entropy: 0.55088
Value Function Loss: 4.71195

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07807
Policy Update Magnitude: 0.02331
Value Function Update Magnitude: 0.03789

Collected Steps per Second: 20,798.71558
Overall Steps per Second: 14,500.22243

Timestep Collection Time: 2.40544
Timestep Consumption Time: 1.04485
PPO Batch Consumption Time: 0.11578
Total Iteration Time: 3.45029

Cumulative Model Updates: 9,838
Cumulative Timesteps: 164,303,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 164303088...
Checkpoint 164303088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,315.25640
Policy Entropy: 0.55813
Value Function Loss: 4.57938

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05952
Policy Update Magnitude: 0.02200
Value Function Update Magnitude: 0.03800

Collected Steps per Second: 22,902.26835
Overall Steps per Second: 16,668.29634

Timestep Collection Time: 2.18459
Timestep Consumption Time: 0.81704
PPO Batch Consumption Time: 0.06440
Total Iteration Time: 3.00163

Cumulative Model Updates: 9,841
Cumulative Timesteps: 164,353,120

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,391.17917
Policy Entropy: 0.55469
Value Function Loss: 4.40394

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.07543
Policy Update Magnitude: 0.02103
Value Function Update Magnitude: 0.03941

Collected Steps per Second: 17,508.27301
Overall Steps per Second: 13,238.97054

Timestep Collection Time: 2.85579
Timestep Consumption Time: 0.92094
PPO Batch Consumption Time: 0.09915
Total Iteration Time: 3.77673

Cumulative Model Updates: 9,844
Cumulative Timesteps: 164,403,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 164403120...
Checkpoint 164403120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,970.72075
Policy Entropy: 0.55891
Value Function Loss: 4.35427

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.06658
Policy Update Magnitude: 0.02100
Value Function Update Magnitude: 0.03663

Collected Steps per Second: 21,793.28838
Overall Steps per Second: 15,579.85091

Timestep Collection Time: 2.29438
Timestep Consumption Time: 0.91503
PPO Batch Consumption Time: 0.09851
Total Iteration Time: 3.20940

Cumulative Model Updates: 9,847
Cumulative Timesteps: 164,453,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,088.95232
Policy Entropy: 0.54797
Value Function Loss: 4.44462

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.07166
Policy Update Magnitude: 0.01988
Value Function Update Magnitude: 0.03720

Collected Steps per Second: 22,987.50790
Overall Steps per Second: 17,329.99689

Timestep Collection Time: 2.17710
Timestep Consumption Time: 0.71073
PPO Batch Consumption Time: 0.06291
Total Iteration Time: 2.88783

Cumulative Model Updates: 9,850
Cumulative Timesteps: 164,503,168

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 164503168...
Checkpoint 164503168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,838.46093
Policy Entropy: 0.54830
Value Function Loss: 4.46403

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05983
Policy Update Magnitude: 0.02310
Value Function Update Magnitude: 0.03238

Collected Steps per Second: 21,041.13484
Overall Steps per Second: 15,938.70736

Timestep Collection Time: 2.37706
Timestep Consumption Time: 0.76096
PPO Batch Consumption Time: 0.07155
Total Iteration Time: 3.13802

Cumulative Model Updates: 9,853
Cumulative Timesteps: 164,553,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,421.08147
Policy Entropy: 0.53883
Value Function Loss: 4.34769

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.07032
Policy Update Magnitude: 0.02517
Value Function Update Magnitude: 0.03112

Collected Steps per Second: 21,131.05015
Overall Steps per Second: 15,190.75068

Timestep Collection Time: 2.36751
Timestep Consumption Time: 0.92581
PPO Batch Consumption Time: 0.10214
Total Iteration Time: 3.29332

Cumulative Model Updates: 9,856
Cumulative Timesteps: 164,603,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 164603212...
Checkpoint 164603212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,204.54922
Policy Entropy: 0.55350
Value Function Loss: 4.18829

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05968
Policy Update Magnitude: 0.02160
Value Function Update Magnitude: 0.03228

Collected Steps per Second: 21,076.63928
Overall Steps per Second: 14,761.32318

Timestep Collection Time: 2.37248
Timestep Consumption Time: 1.01502
PPO Batch Consumption Time: 0.12622
Total Iteration Time: 3.38750

Cumulative Model Updates: 9,859
Cumulative Timesteps: 164,653,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,561.29270
Policy Entropy: 0.54459
Value Function Loss: 4.27668

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06852
Policy Update Magnitude: 0.02386
Value Function Update Magnitude: 0.03411

Collected Steps per Second: 23,230.07457
Overall Steps per Second: 16,485.59528

Timestep Collection Time: 2.15316
Timestep Consumption Time: 0.88089
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 3.03404

Cumulative Model Updates: 9,862
Cumulative Timesteps: 164,703,234

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 164703234...
Checkpoint 164703234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,290.22686
Policy Entropy: 0.56390
Value Function Loss: 4.19993

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.02056
Value Function Update Magnitude: 0.03134

Collected Steps per Second: 19,260.42346
Overall Steps per Second: 14,191.86422

Timestep Collection Time: 2.59672
Timestep Consumption Time: 0.92741
PPO Batch Consumption Time: 0.10950
Total Iteration Time: 3.52413

Cumulative Model Updates: 9,865
Cumulative Timesteps: 164,753,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,035.78414
Policy Entropy: 0.55343
Value Function Loss: 4.27291

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.06106
Policy Update Magnitude: 0.02029
Value Function Update Magnitude: 0.03087

Collected Steps per Second: 21,949.93423
Overall Steps per Second: 16,576.82665

Timestep Collection Time: 2.27928
Timestep Consumption Time: 0.73879
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 3.01807

Cumulative Model Updates: 9,868
Cumulative Timesteps: 164,803,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 164803278...
Checkpoint 164803278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,754.30905
Policy Entropy: 0.56152
Value Function Loss: 4.16910

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.02237
Value Function Update Magnitude: 0.03196

Collected Steps per Second: 19,258.23630
Overall Steps per Second: 14,060.75364

Timestep Collection Time: 2.59640
Timestep Consumption Time: 0.95974
PPO Batch Consumption Time: 0.11280
Total Iteration Time: 3.55614

Cumulative Model Updates: 9,871
Cumulative Timesteps: 164,853,280

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,523.25441
Policy Entropy: 0.54404
Value Function Loss: 4.31223

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.07290
Policy Update Magnitude: 0.02096
Value Function Update Magnitude: 0.03209

Collected Steps per Second: 21,966.82675
Overall Steps per Second: 16,318.67415

Timestep Collection Time: 2.27707
Timestep Consumption Time: 0.78813
PPO Batch Consumption Time: 0.06046
Total Iteration Time: 3.06520

Cumulative Model Updates: 9,874
Cumulative Timesteps: 164,903,300

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 164903300...
Checkpoint 164903300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,692.94033
Policy Entropy: 0.55478
Value Function Loss: 4.12231

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.06496
Policy Update Magnitude: 0.01785
Value Function Update Magnitude: 0.03265

Collected Steps per Second: 19,051.50312
Overall Steps per Second: 14,054.89631

Timestep Collection Time: 2.62562
Timestep Consumption Time: 0.93342
PPO Batch Consumption Time: 0.09463
Total Iteration Time: 3.55904

Cumulative Model Updates: 9,877
Cumulative Timesteps: 164,953,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,375.95498
Policy Entropy: 0.54173
Value Function Loss: 4.30197

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05545
Policy Update Magnitude: 0.02022
Value Function Update Magnitude: 0.03256

Collected Steps per Second: 23,134.23598
Overall Steps per Second: 17,110.67421

Timestep Collection Time: 2.16337
Timestep Consumption Time: 0.76158
PPO Batch Consumption Time: 0.05926
Total Iteration Time: 2.92496

Cumulative Model Updates: 9,880
Cumulative Timesteps: 165,003,370

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 165003370...
Checkpoint 165003370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,560.81276
Policy Entropy: 0.55014
Value Function Loss: 4.29121

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.07101
Policy Update Magnitude: 0.02238
Value Function Update Magnitude: 0.03056

Collected Steps per Second: 18,613.44358
Overall Steps per Second: 13,804.58656

Timestep Collection Time: 2.68730
Timestep Consumption Time: 0.93613
PPO Batch Consumption Time: 0.08363
Total Iteration Time: 3.62343

Cumulative Model Updates: 9,883
Cumulative Timesteps: 165,053,390

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,209.78640
Policy Entropy: 0.52973
Value Function Loss: 4.55332

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.06288
Policy Update Magnitude: 0.02153
Value Function Update Magnitude: 0.03844

Collected Steps per Second: 22,139.48959
Overall Steps per Second: 16,435.37024

Timestep Collection Time: 2.25895
Timestep Consumption Time: 0.78400
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 3.04295

Cumulative Model Updates: 9,886
Cumulative Timesteps: 165,103,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 165103402...
Checkpoint 165103402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,772.04617
Policy Entropy: 0.53684
Value Function Loss: 4.50514

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05625
Policy Update Magnitude: 0.02242
Value Function Update Magnitude: 0.04445

Collected Steps per Second: 18,035.21155
Overall Steps per Second: 13,796.12287

Timestep Collection Time: 2.77247
Timestep Consumption Time: 0.85189
PPO Batch Consumption Time: 0.07571
Total Iteration Time: 3.62435

Cumulative Model Updates: 9,889
Cumulative Timesteps: 165,153,404

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,466.88694
Policy Entropy: 0.52223
Value Function Loss: 4.75389

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05813
Policy Update Magnitude: 0.02279
Value Function Update Magnitude: 0.04176

Collected Steps per Second: 20,972.13178
Overall Steps per Second: 15,933.78062

Timestep Collection Time: 2.38450
Timestep Consumption Time: 0.75399
PPO Batch Consumption Time: 0.03294
Total Iteration Time: 3.13849

Cumulative Model Updates: 9,892
Cumulative Timesteps: 165,203,412

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 165203412...
Checkpoint 165203412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,994.67761
Policy Entropy: 0.52841
Value Function Loss: 4.55232

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.06393
Policy Update Magnitude: 0.02899
Value Function Update Magnitude: 0.03801

Collected Steps per Second: 21,000.84492
Overall Steps per Second: 14,993.60245

Timestep Collection Time: 2.38200
Timestep Consumption Time: 0.95436
PPO Batch Consumption Time: 0.09950
Total Iteration Time: 3.33636

Cumulative Model Updates: 9,895
Cumulative Timesteps: 165,253,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,426.27558
Policy Entropy: 0.52114
Value Function Loss: 4.50108

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.05721
Policy Update Magnitude: 0.02710
Value Function Update Magnitude: 0.03382

Collected Steps per Second: 22,612.85309
Overall Steps per Second: 17,099.39589

Timestep Collection Time: 2.21140
Timestep Consumption Time: 0.71303
PPO Batch Consumption Time: 0.06100
Total Iteration Time: 2.92443

Cumulative Model Updates: 9,898
Cumulative Timesteps: 165,303,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 165303442...
Checkpoint 165303442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,209.53964
Policy Entropy: 0.53387
Value Function Loss: 4.16945

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.07541
Policy Update Magnitude: 0.02344
Value Function Update Magnitude: 0.03912

Collected Steps per Second: 22,389.08255
Overall Steps per Second: 15,534.76457

Timestep Collection Time: 2.23475
Timestep Consumption Time: 0.98603
PPO Batch Consumption Time: 0.12248
Total Iteration Time: 3.22078

Cumulative Model Updates: 9,901
Cumulative Timesteps: 165,353,476

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,672.05766
Policy Entropy: 0.52624
Value Function Loss: 4.37738

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.04139
Policy Update Magnitude: 0.02015
Value Function Update Magnitude: 0.04831

Collected Steps per Second: 23,163.61427
Overall Steps per Second: 16,435.58311

Timestep Collection Time: 2.15899
Timestep Consumption Time: 0.88380
PPO Batch Consumption Time: 0.08143
Total Iteration Time: 3.04279

Cumulative Model Updates: 9,904
Cumulative Timesteps: 165,403,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 165403486...
Checkpoint 165403486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,855.19399
Policy Entropy: 0.52910
Value Function Loss: 4.27576

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02676
Policy Update Magnitude: 0.02541
Value Function Update Magnitude: 0.04833

Collected Steps per Second: 22,293.97417
Overall Steps per Second: 17,140.26912

Timestep Collection Time: 2.24366
Timestep Consumption Time: 0.67462
PPO Batch Consumption Time: 0.03332
Total Iteration Time: 2.91827

Cumulative Model Updates: 9,907
Cumulative Timesteps: 165,453,506

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,824.25227
Policy Entropy: 0.52571
Value Function Loss: 4.32969

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02319
Policy Update Magnitude: 0.02550
Value Function Update Magnitude: 0.05197

Collected Steps per Second: 21,883.12857
Overall Steps per Second: 15,554.50804

Timestep Collection Time: 2.28569
Timestep Consumption Time: 0.92997
PPO Batch Consumption Time: 0.10778
Total Iteration Time: 3.21566

Cumulative Model Updates: 9,910
Cumulative Timesteps: 165,503,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 165503524...
Checkpoint 165503524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,324.15064
Policy Entropy: 0.53626
Value Function Loss: 4.06159

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03271
Policy Update Magnitude: 0.03340
Value Function Update Magnitude: 0.04893

Collected Steps per Second: 22,588.71109
Overall Steps per Second: 16,892.92849

Timestep Collection Time: 2.21429
Timestep Consumption Time: 0.74659
PPO Batch Consumption Time: 0.06456
Total Iteration Time: 2.96088

Cumulative Model Updates: 9,913
Cumulative Timesteps: 165,553,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,725.57851
Policy Entropy: 0.53005
Value Function Loss: 4.28081

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.05709
Policy Update Magnitude: 0.03375
Value Function Update Magnitude: 0.04138

Collected Steps per Second: 22,104.26175
Overall Steps per Second: 16,225.14959

Timestep Collection Time: 2.26355
Timestep Consumption Time: 0.82019
PPO Batch Consumption Time: 0.06538
Total Iteration Time: 3.08373

Cumulative Model Updates: 9,916
Cumulative Timesteps: 165,603,576

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 165603576...
Checkpoint 165603576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,680.46868
Policy Entropy: 0.52749
Value Function Loss: 4.32456

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04577
Policy Update Magnitude: 0.03310
Value Function Update Magnitude: 0.03930

Collected Steps per Second: 18,180.29483
Overall Steps per Second: 13,277.50812

Timestep Collection Time: 2.75111
Timestep Consumption Time: 1.01586
PPO Batch Consumption Time: 0.10840
Total Iteration Time: 3.76697

Cumulative Model Updates: 9,919
Cumulative Timesteps: 165,653,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,837.54583
Policy Entropy: 0.52203
Value Function Loss: 4.21516

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03706
Policy Update Magnitude: 0.02649
Value Function Update Magnitude: 0.03502

Collected Steps per Second: 21,733.59625
Overall Steps per Second: 16,033.28718

Timestep Collection Time: 2.30151
Timestep Consumption Time: 0.81825
PPO Batch Consumption Time: 0.06537
Total Iteration Time: 3.11976

Cumulative Model Updates: 9,922
Cumulative Timesteps: 165,703,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 165703612...
Checkpoint 165703612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,452.76431
Policy Entropy: 0.52986
Value Function Loss: 3.91466

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02943
Policy Update Magnitude: 0.02998
Value Function Update Magnitude: 0.03383

Collected Steps per Second: 22,801.79937
Overall Steps per Second: 16,347.47032

Timestep Collection Time: 2.19281
Timestep Consumption Time: 0.86577
PPO Batch Consumption Time: 0.07921
Total Iteration Time: 3.05858

Cumulative Model Updates: 9,925
Cumulative Timesteps: 165,753,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,438.69821
Policy Entropy: 0.52649
Value Function Loss: 4.05671

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03503
Policy Update Magnitude: 0.02814
Value Function Update Magnitude: 0.03045

Collected Steps per Second: 22,787.04186
Overall Steps per Second: 15,894.85191

Timestep Collection Time: 2.19458
Timestep Consumption Time: 0.95160
PPO Batch Consumption Time: 0.10426
Total Iteration Time: 3.14618

Cumulative Model Updates: 9,928
Cumulative Timesteps: 165,803,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 165803620...
Checkpoint 165803620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,842.95268
Policy Entropy: 0.52591
Value Function Loss: 4.22590

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02735
Policy Update Magnitude: 0.02307
Value Function Update Magnitude: 0.03286

Collected Steps per Second: 22,074.27951
Overall Steps per Second: 16,430.09673

Timestep Collection Time: 2.26535
Timestep Consumption Time: 0.77821
PPO Batch Consumption Time: 0.05816
Total Iteration Time: 3.04356

Cumulative Model Updates: 9,931
Cumulative Timesteps: 165,853,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,655.98269
Policy Entropy: 0.52512
Value Function Loss: 4.18394

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03269
Policy Update Magnitude: 0.02573
Value Function Update Magnitude: 0.03272

Collected Steps per Second: 19,670.24682
Overall Steps per Second: 15,198.43911

Timestep Collection Time: 2.54211
Timestep Consumption Time: 0.74796
PPO Batch Consumption Time: 0.02902
Total Iteration Time: 3.29007

Cumulative Model Updates: 9,934
Cumulative Timesteps: 165,903,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 165903630...
Checkpoint 165903630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,226.48649
Policy Entropy: 0.53540
Value Function Loss: 3.81711

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03814
Policy Update Magnitude: 0.02158
Value Function Update Magnitude: 0.03578

Collected Steps per Second: 21,074.87775
Overall Steps per Second: 15,477.62011

Timestep Collection Time: 2.37344
Timestep Consumption Time: 0.85832
PPO Batch Consumption Time: 0.08662
Total Iteration Time: 3.23176

Cumulative Model Updates: 9,937
Cumulative Timesteps: 165,953,650

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,512.55582
Policy Entropy: 0.54046
Value Function Loss: 3.81780

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02476
Policy Update Magnitude: 0.03181
Value Function Update Magnitude: 0.03366

Collected Steps per Second: 23,734.85428
Overall Steps per Second: 17,316.86105

Timestep Collection Time: 2.10678
Timestep Consumption Time: 0.78082
PPO Batch Consumption Time: 0.06511
Total Iteration Time: 2.88759

Cumulative Model Updates: 9,940
Cumulative Timesteps: 166,003,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 166003654...
Checkpoint 166003654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,441.41251
Policy Entropy: 0.53328
Value Function Loss: 3.97414

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.05019
Policy Update Magnitude: 0.02941
Value Function Update Magnitude: 0.03486

Collected Steps per Second: 21,410.47097
Overall Steps per Second: 15,344.11690

Timestep Collection Time: 2.33577
Timestep Consumption Time: 0.92346
PPO Batch Consumption Time: 0.12326
Total Iteration Time: 3.25923

Cumulative Model Updates: 9,943
Cumulative Timesteps: 166,053,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,234.94226
Policy Entropy: 0.52487
Value Function Loss: 4.08973

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.05945
Policy Update Magnitude: 0.02588
Value Function Update Magnitude: 0.03375

Collected Steps per Second: 20,935.86805
Overall Steps per Second: 15,406.24047

Timestep Collection Time: 2.38872
Timestep Consumption Time: 0.85736
PPO Batch Consumption Time: 0.06029
Total Iteration Time: 3.24609

Cumulative Model Updates: 9,946
Cumulative Timesteps: 166,103,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 166103674...
Checkpoint 166103674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,584.34264
Policy Entropy: 0.51870
Value Function Loss: 4.01571

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04545
Policy Update Magnitude: 0.03479
Value Function Update Magnitude: 0.03659

Collected Steps per Second: 18,200.69314
Overall Steps per Second: 14,447.84289

Timestep Collection Time: 2.74968
Timestep Consumption Time: 0.71423
PPO Batch Consumption Time: 0.02891
Total Iteration Time: 3.46391

Cumulative Model Updates: 9,949
Cumulative Timesteps: 166,153,720

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,495.15769
Policy Entropy: 0.52476
Value Function Loss: 3.88624

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03466
Policy Update Magnitude: 0.02934
Value Function Update Magnitude: 0.03393

Collected Steps per Second: 23,527.72328
Overall Steps per Second: 16,955.99551

Timestep Collection Time: 2.12651
Timestep Consumption Time: 0.82418
PPO Batch Consumption Time: 0.04430
Total Iteration Time: 2.95070

Cumulative Model Updates: 9,952
Cumulative Timesteps: 166,203,752

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 166203752...
Checkpoint 166203752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,803.07661
Policy Entropy: 0.52437
Value Function Loss: 4.04502

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.04221
Policy Update Magnitude: 0.02719
Value Function Update Magnitude: 0.03626

Collected Steps per Second: 20,533.21065
Overall Steps per Second: 15,239.22521

Timestep Collection Time: 2.43557
Timestep Consumption Time: 0.84610
PPO Batch Consumption Time: 0.08599
Total Iteration Time: 3.28166

Cumulative Model Updates: 9,955
Cumulative Timesteps: 166,253,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,251.77137
Policy Entropy: 0.52241
Value Function Loss: 4.03621

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.06853
Policy Update Magnitude: 0.02453
Value Function Update Magnitude: 0.03378

Collected Steps per Second: 21,151.27104
Overall Steps per Second: 15,703.26271

Timestep Collection Time: 2.36487
Timestep Consumption Time: 0.82046
PPO Batch Consumption Time: 0.07440
Total Iteration Time: 3.18533

Cumulative Model Updates: 9,958
Cumulative Timesteps: 166,303,782

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 166303782...
Checkpoint 166303782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,347.36838
Policy Entropy: 0.52273
Value Function Loss: 4.02282

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03201
Policy Update Magnitude: 0.02305
Value Function Update Magnitude: 0.03993

Collected Steps per Second: 23,074.82813
Overall Steps per Second: 16,533.28278

Timestep Collection Time: 2.16712
Timestep Consumption Time: 0.85744
PPO Batch Consumption Time: 0.07495
Total Iteration Time: 3.02457

Cumulative Model Updates: 9,961
Cumulative Timesteps: 166,353,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,691.02357
Policy Entropy: 0.52073
Value Function Loss: 3.81743

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02974
Policy Update Magnitude: 0.02258
Value Function Update Magnitude: 0.03812

Collected Steps per Second: 23,023.50445
Overall Steps per Second: 16,848.51302

Timestep Collection Time: 2.17282
Timestep Consumption Time: 0.79634
PPO Batch Consumption Time: 0.06375
Total Iteration Time: 2.96916

Cumulative Model Updates: 9,964
Cumulative Timesteps: 166,403,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 166403814...
Checkpoint 166403814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,104.66847
Policy Entropy: 0.51531
Value Function Loss: 3.91988

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02969
Policy Update Magnitude: 0.02348
Value Function Update Magnitude: 0.03604

Collected Steps per Second: 17,790.47468
Overall Steps per Second: 13,243.07205

Timestep Collection Time: 2.81195
Timestep Consumption Time: 0.96557
PPO Batch Consumption Time: 0.11759
Total Iteration Time: 3.77752

Cumulative Model Updates: 9,967
Cumulative Timesteps: 166,453,840

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,729.08186
Policy Entropy: 0.51026
Value Function Loss: 3.98982

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03089
Policy Update Magnitude: 0.02155
Value Function Update Magnitude: 0.03254

Collected Steps per Second: 21,289.89759
Overall Steps per Second: 15,345.44430

Timestep Collection Time: 2.34938
Timestep Consumption Time: 0.91009
PPO Batch Consumption Time: 0.07236
Total Iteration Time: 3.25947

Cumulative Model Updates: 9,970
Cumulative Timesteps: 166,503,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 166503858...
Checkpoint 166503858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,360.30195
Policy Entropy: 0.51592
Value Function Loss: 3.90066

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02659
Policy Update Magnitude: 0.02222
Value Function Update Magnitude: 0.03523

Collected Steps per Second: 20,362.63092
Overall Steps per Second: 14,265.31489

Timestep Collection Time: 2.45558
Timestep Consumption Time: 1.04957
PPO Batch Consumption Time: 0.12343
Total Iteration Time: 3.50515

Cumulative Model Updates: 9,973
Cumulative Timesteps: 166,553,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997.22514
Policy Entropy: 0.51538
Value Function Loss: 3.90545

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03149
Policy Update Magnitude: 0.02390
Value Function Update Magnitude: 0.03312

Collected Steps per Second: 21,703.81685
Overall Steps per Second: 15,747.33721

Timestep Collection Time: 2.30568
Timestep Consumption Time: 0.87213
PPO Batch Consumption Time: 0.06967
Total Iteration Time: 3.17781

Cumulative Model Updates: 9,976
Cumulative Timesteps: 166,603,902

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 166603902...
Checkpoint 166603902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,532.19138
Policy Entropy: 0.52040
Value Function Loss: 3.86187

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03694
Policy Update Magnitude: 0.02128
Value Function Update Magnitude: 0.04463

Collected Steps per Second: 21,011.10877
Overall Steps per Second: 15,487.41488

Timestep Collection Time: 2.38007
Timestep Consumption Time: 0.84887
PPO Batch Consumption Time: 0.07854
Total Iteration Time: 3.22894

Cumulative Model Updates: 9,979
Cumulative Timesteps: 166,653,910

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,807.95842
Policy Entropy: 0.51608
Value Function Loss: 3.98136

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04142
Policy Update Magnitude: 0.02199
Value Function Update Magnitude: 0.04109

Collected Steps per Second: 23,154.84215
Overall Steps per Second: 16,749.89832

Timestep Collection Time: 2.16058
Timestep Consumption Time: 0.82618
PPO Batch Consumption Time: 0.09193
Total Iteration Time: 2.98676

Cumulative Model Updates: 9,982
Cumulative Timesteps: 166,703,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 166703938...
Checkpoint 166703938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,121.36705
Policy Entropy: 0.50840
Value Function Loss: 3.96474

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.08127
Policy Update Magnitude: 0.02331
Value Function Update Magnitude: 0.04358

Collected Steps per Second: 23,043.12909
Overall Steps per Second: 15,817.37337

Timestep Collection Time: 2.16984
Timestep Consumption Time: 0.99124
PPO Batch Consumption Time: 0.12635
Total Iteration Time: 3.16108

Cumulative Model Updates: 9,985
Cumulative Timesteps: 166,753,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,548.32983
Policy Entropy: 0.51336
Value Function Loss: 3.85578

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.05130
Policy Update Magnitude: 0.02346
Value Function Update Magnitude: 0.04404

Collected Steps per Second: 23,417.28555
Overall Steps per Second: 16,769.56768

Timestep Collection Time: 2.13535
Timestep Consumption Time: 0.84648
PPO Batch Consumption Time: 0.06825
Total Iteration Time: 2.98183

Cumulative Model Updates: 9,988
Cumulative Timesteps: 166,803,942

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 166803942...
Checkpoint 166803942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,197.55998
Policy Entropy: 0.51248
Value Function Loss: 3.84113

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.07218
Policy Update Magnitude: 0.02047
Value Function Update Magnitude: 0.04538

Collected Steps per Second: 20,604.45616
Overall Steps per Second: 15,115.27315

Timestep Collection Time: 2.42705
Timestep Consumption Time: 0.88139
PPO Batch Consumption Time: 0.05952
Total Iteration Time: 3.30844

Cumulative Model Updates: 9,991
Cumulative Timesteps: 166,853,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,886.46751
Policy Entropy: 0.51773
Value Function Loss: 3.82909

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.01989
Value Function Update Magnitude: 0.03571

Collected Steps per Second: 20,653.93618
Overall Steps per Second: 14,288.19599

Timestep Collection Time: 2.42240
Timestep Consumption Time: 1.07924
PPO Batch Consumption Time: 0.11315
Total Iteration Time: 3.50163

Cumulative Model Updates: 9,994
Cumulative Timesteps: 166,903,982

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 166903982...
Checkpoint 166903982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,121.16017
Policy Entropy: 0.50573
Value Function Loss: 3.92100

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05901
Policy Update Magnitude: 0.01854
Value Function Update Magnitude: 0.02842

Collected Steps per Second: 21,186.65519
Overall Steps per Second: 16,922.97754

Timestep Collection Time: 2.36054
Timestep Consumption Time: 0.59473
PPO Batch Consumption Time: 0.02844
Total Iteration Time: 2.95527

Cumulative Model Updates: 9,997
Cumulative Timesteps: 166,953,994

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,975.78842
Policy Entropy: 0.50555
Value Function Loss: 3.99330

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07305
Policy Update Magnitude: 0.01866
Value Function Update Magnitude: 0.02964

Collected Steps per Second: 22,799.00167
Overall Steps per Second: 15,559.69194

Timestep Collection Time: 2.19466
Timestep Consumption Time: 1.02109
PPO Batch Consumption Time: 0.09555
Total Iteration Time: 3.21574

Cumulative Model Updates: 10,000
Cumulative Timesteps: 167,004,030

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 167004030...
Checkpoint 167004030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,520.93989
Policy Entropy: 0.50173
Value Function Loss: 3.88233

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06587
Policy Update Magnitude: 0.01710
Value Function Update Magnitude: 0.02435

Collected Steps per Second: 19,682.89500
Overall Steps per Second: 14,006.16644

Timestep Collection Time: 2.54190
Timestep Consumption Time: 1.03024
PPO Batch Consumption Time: 0.11694
Total Iteration Time: 3.57214

Cumulative Model Updates: 10,003
Cumulative Timesteps: 167,054,062

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,184.23057
Policy Entropy: 0.49871
Value Function Loss: 3.99801

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.06153
Policy Update Magnitude: 0.01881
Value Function Update Magnitude: 0.02428

Collected Steps per Second: 19,057.44144
Overall Steps per Second: 13,981.24427

Timestep Collection Time: 2.62491
Timestep Consumption Time: 0.95303
PPO Batch Consumption Time: 0.11194
Total Iteration Time: 3.57794

Cumulative Model Updates: 10,006
Cumulative Timesteps: 167,104,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 167104086...
Checkpoint 167104086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,253.41240
Policy Entropy: 0.48895
Value Function Loss: 4.03548

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.06455
Policy Update Magnitude: 0.01617
Value Function Update Magnitude: 0.02208

Collected Steps per Second: 23,089.43766
Overall Steps per Second: 15,734.33541

Timestep Collection Time: 2.16627
Timestep Consumption Time: 1.01264
PPO Batch Consumption Time: 0.11932
Total Iteration Time: 3.17891

Cumulative Model Updates: 10,009
Cumulative Timesteps: 167,154,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,176.61981
Policy Entropy: 0.48520
Value Function Loss: 4.02499

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.06335
Policy Update Magnitude: 0.01803
Value Function Update Magnitude: 0.02229

Collected Steps per Second: 23,841.39880
Overall Steps per Second: 17,851.72110

Timestep Collection Time: 2.09845
Timestep Consumption Time: 0.70408
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 2.80253

Cumulative Model Updates: 10,012
Cumulative Timesteps: 167,204,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 167204134...
Checkpoint 167204134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,358.68256
Policy Entropy: 0.47787
Value Function Loss: 4.07761

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06630
Policy Update Magnitude: 0.02175
Value Function Update Magnitude: 0.02469

Collected Steps per Second: 20,706.51727
Overall Steps per Second: 14,832.60940

Timestep Collection Time: 2.41537
Timestep Consumption Time: 0.95652
PPO Batch Consumption Time: 0.11661
Total Iteration Time: 3.37189

Cumulative Model Updates: 10,015
Cumulative Timesteps: 167,254,148

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,373.74821
Policy Entropy: 0.48947
Value Function Loss: 3.92918

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05219
Policy Update Magnitude: 0.02042
Value Function Update Magnitude: 0.02284

Collected Steps per Second: 23,653.42866
Overall Steps per Second: 16,534.47745

Timestep Collection Time: 2.11487
Timestep Consumption Time: 0.91056
PPO Batch Consumption Time: 0.07597
Total Iteration Time: 3.02544

Cumulative Model Updates: 10,018
Cumulative Timesteps: 167,304,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 167304172...
Checkpoint 167304172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,923.53115
Policy Entropy: 0.48603
Value Function Loss: 3.80434

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06139
Policy Update Magnitude: 0.01980
Value Function Update Magnitude: 0.02124

Collected Steps per Second: 20,933.46981
Overall Steps per Second: 14,687.53619

Timestep Collection Time: 2.38862
Timestep Consumption Time: 1.01577
PPO Batch Consumption Time: 0.10178
Total Iteration Time: 3.40438

Cumulative Model Updates: 10,021
Cumulative Timesteps: 167,354,174

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,535.15496
Policy Entropy: 0.49492
Value Function Loss: 3.63150

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05649
Policy Update Magnitude: 0.01806
Value Function Update Magnitude: 0.02069

Collected Steps per Second: 22,745.94744
Overall Steps per Second: 16,644.20510

Timestep Collection Time: 2.19828
Timestep Consumption Time: 0.80589
PPO Batch Consumption Time: 0.05996
Total Iteration Time: 3.00417

Cumulative Model Updates: 10,024
Cumulative Timesteps: 167,404,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 167404176...
Checkpoint 167404176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,311.94524
Policy Entropy: 0.48344
Value Function Loss: 3.70370

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05879
Policy Update Magnitude: 0.02104
Value Function Update Magnitude: 0.02070

Collected Steps per Second: 18,847.15947
Overall Steps per Second: 14,928.69079

Timestep Collection Time: 2.65441
Timestep Consumption Time: 0.69673
PPO Batch Consumption Time: 0.03012
Total Iteration Time: 3.35113

Cumulative Model Updates: 10,027
Cumulative Timesteps: 167,454,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,470.38107
Policy Entropy: 0.48781
Value Function Loss: 3.78698

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05621
Policy Update Magnitude: 0.02220
Value Function Update Magnitude: 0.01798

Collected Steps per Second: 21,476.65946
Overall Steps per Second: 14,884.04603

Timestep Collection Time: 2.32885
Timestep Consumption Time: 1.03152
PPO Batch Consumption Time: 0.11168
Total Iteration Time: 3.36038

Cumulative Model Updates: 10,030
Cumulative Timesteps: 167,504,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 167504220...
Checkpoint 167504220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,044.79740
Policy Entropy: 0.47921
Value Function Loss: 3.82946

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06421
Policy Update Magnitude: 0.02340
Value Function Update Magnitude: 0.01917

Collected Steps per Second: 21,908.44516
Overall Steps per Second: 15,999.12038

Timestep Collection Time: 2.28341
Timestep Consumption Time: 0.84339
PPO Batch Consumption Time: 0.05961
Total Iteration Time: 3.12680

Cumulative Model Updates: 10,033
Cumulative Timesteps: 167,554,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,773.92881
Policy Entropy: 0.48042
Value Function Loss: 3.73208

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05530
Policy Update Magnitude: 0.01997
Value Function Update Magnitude: 0.02014

Collected Steps per Second: 20,208.35263
Overall Steps per Second: 14,507.19896

Timestep Collection Time: 2.47531
Timestep Consumption Time: 0.97277
PPO Batch Consumption Time: 0.11976
Total Iteration Time: 3.44808

Cumulative Model Updates: 10,036
Cumulative Timesteps: 167,604,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 167604268...
Checkpoint 167604268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,389.68495
Policy Entropy: 0.48575
Value Function Loss: 3.47826

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04463
Policy Update Magnitude: 0.02887
Value Function Update Magnitude: 0.01984

Collected Steps per Second: 21,557.94614
Overall Steps per Second: 16,066.34674

Timestep Collection Time: 2.31970
Timestep Consumption Time: 0.79289
PPO Batch Consumption Time: 0.06986
Total Iteration Time: 3.11259

Cumulative Model Updates: 10,039
Cumulative Timesteps: 167,654,276

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,039.91454
Policy Entropy: 0.48832
Value Function Loss: 3.53976

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.03066
Value Function Update Magnitude: 0.02082

Collected Steps per Second: 20,528.88519
Overall Steps per Second: 14,924.34115

Timestep Collection Time: 2.43618
Timestep Consumption Time: 0.91486
PPO Batch Consumption Time: 0.08283
Total Iteration Time: 3.35104

Cumulative Model Updates: 10,042
Cumulative Timesteps: 167,704,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 167704288...
Checkpoint 167704288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,072.86798
Policy Entropy: 0.48514
Value Function Loss: 3.59038

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04967
Policy Update Magnitude: 0.02428
Value Function Update Magnitude: 0.02054

Collected Steps per Second: 20,729.29207
Overall Steps per Second: 15,669.01447

Timestep Collection Time: 2.41262
Timestep Consumption Time: 0.77915
PPO Batch Consumption Time: 0.05310
Total Iteration Time: 3.19178

Cumulative Model Updates: 10,045
Cumulative Timesteps: 167,754,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,367.80215
Policy Entropy: 0.48008
Value Function Loss: 3.83146

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.06431
Policy Update Magnitude: 0.02485
Value Function Update Magnitude: 0.01970

Collected Steps per Second: 19,808.59663
Overall Steps per Second: 14,966.36846

Timestep Collection Time: 2.52507
Timestep Consumption Time: 0.81696
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 3.34203

Cumulative Model Updates: 10,048
Cumulative Timesteps: 167,804,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 167804318...
Checkpoint 167804318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,535.44100
Policy Entropy: 0.47595
Value Function Loss: 3.84577

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04782
Policy Update Magnitude: 0.02066
Value Function Update Magnitude: 0.02253

Collected Steps per Second: 22,693.72676
Overall Steps per Second: 17,383.57791

Timestep Collection Time: 2.20369
Timestep Consumption Time: 0.67316
PPO Batch Consumption Time: 0.02897
Total Iteration Time: 2.87685

Cumulative Model Updates: 10,051
Cumulative Timesteps: 167,854,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,541.78583
Policy Entropy: 0.47051
Value Function Loss: 3.90812

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03867
Policy Update Magnitude: 0.02584
Value Function Update Magnitude: 0.02188

Collected Steps per Second: 22,518.42726
Overall Steps per Second: 16,328.01416

Timestep Collection Time: 2.22076
Timestep Consumption Time: 0.84195
PPO Batch Consumption Time: 0.09945
Total Iteration Time: 3.06271

Cumulative Model Updates: 10,054
Cumulative Timesteps: 167,904,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 167904336...
Checkpoint 167904336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,674.75574
Policy Entropy: 0.47560
Value Function Loss: 3.85840

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.04148
Policy Update Magnitude: 0.03192
Value Function Update Magnitude: 0.02637

Collected Steps per Second: 22,798.04410
Overall Steps per Second: 16,814.34702

Timestep Collection Time: 2.19449
Timestep Consumption Time: 0.78095
PPO Batch Consumption Time: 0.06011
Total Iteration Time: 2.97544

Cumulative Model Updates: 10,057
Cumulative Timesteps: 167,954,366

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,076.38056
Policy Entropy: 0.48312
Value Function Loss: 3.82621

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02133
Policy Update Magnitude: 0.03304
Value Function Update Magnitude: 0.02245

Collected Steps per Second: 19,963.14116
Overall Steps per Second: 14,799.90985

Timestep Collection Time: 2.50502
Timestep Consumption Time: 0.87392
PPO Batch Consumption Time: 0.02853
Total Iteration Time: 3.37894

Cumulative Model Updates: 10,060
Cumulative Timesteps: 168,004,374

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 168004374...
Checkpoint 168004374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,839.16028
Policy Entropy: 0.48059
Value Function Loss: 3.82549

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02893
Policy Update Magnitude: 0.03005
Value Function Update Magnitude: 0.02421

Collected Steps per Second: 19,830.93537
Overall Steps per Second: 15,052.50435

Timestep Collection Time: 2.52353
Timestep Consumption Time: 0.80110
PPO Batch Consumption Time: 0.05845
Total Iteration Time: 3.32463

Cumulative Model Updates: 10,063
Cumulative Timesteps: 168,054,418

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,396.93680
Policy Entropy: 0.47539
Value Function Loss: 3.95821

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.04113
Policy Update Magnitude: 0.02769
Value Function Update Magnitude: 0.02426

Collected Steps per Second: 22,361.33099
Overall Steps per Second: 16,034.76575

Timestep Collection Time: 2.23743
Timestep Consumption Time: 0.88279
PPO Batch Consumption Time: 0.07069
Total Iteration Time: 3.12022

Cumulative Model Updates: 10,066
Cumulative Timesteps: 168,104,450

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 168104450...
Checkpoint 168104450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,499.44196
Policy Entropy: 0.46956
Value Function Loss: 4.03785

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03381
Policy Update Magnitude: 0.02408
Value Function Update Magnitude: 0.02328

Collected Steps per Second: 23,061.54982
Overall Steps per Second: 17,040.99292

Timestep Collection Time: 2.16915
Timestep Consumption Time: 0.76636
PPO Batch Consumption Time: 0.07336
Total Iteration Time: 2.93551

Cumulative Model Updates: 10,069
Cumulative Timesteps: 168,154,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,579.87808
Policy Entropy: 0.47377
Value Function Loss: 3.94482

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03237
Policy Update Magnitude: 0.02302
Value Function Update Magnitude: 0.02331

Collected Steps per Second: 22,628.88618
Overall Steps per Second: 16,521.54474

Timestep Collection Time: 2.21071
Timestep Consumption Time: 0.81721
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 3.02793

Cumulative Model Updates: 10,072
Cumulative Timesteps: 168,204,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 168204500...
Checkpoint 168204500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,109.26178
Policy Entropy: 0.48019
Value Function Loss: 3.67697

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01645
Policy Update Magnitude: 0.02695
Value Function Update Magnitude: 0.02036

Collected Steps per Second: 19,520.83797
Overall Steps per Second: 14,846.17455

Timestep Collection Time: 2.56239
Timestep Consumption Time: 0.80683
PPO Batch Consumption Time: 0.05287
Total Iteration Time: 3.36922

Cumulative Model Updates: 10,075
Cumulative Timesteps: 168,254,520

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,890.64400
Policy Entropy: 0.47842
Value Function Loss: 3.61734

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02886
Policy Update Magnitude: 0.03167
Value Function Update Magnitude: 0.02319

Collected Steps per Second: 19,093.55951
Overall Steps per Second: 14,028.82375

Timestep Collection Time: 2.61921
Timestep Consumption Time: 0.94560
PPO Batch Consumption Time: 0.09154
Total Iteration Time: 3.56480

Cumulative Model Updates: 10,078
Cumulative Timesteps: 168,304,530

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 168304530...
Checkpoint 168304530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,137.00907
Policy Entropy: 0.47823
Value Function Loss: 3.52948

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04836
Policy Update Magnitude: 0.02920
Value Function Update Magnitude: 0.02113

Collected Steps per Second: 22,372.57053
Overall Steps per Second: 16,900.57613

Timestep Collection Time: 2.23551
Timestep Consumption Time: 0.72380
PPO Batch Consumption Time: 0.05769
Total Iteration Time: 2.95931

Cumulative Model Updates: 10,081
Cumulative Timesteps: 168,354,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,967.99472
Policy Entropy: 0.47264
Value Function Loss: 3.71324

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03399
Policy Update Magnitude: 0.02669
Value Function Update Magnitude: 0.02016

Collected Steps per Second: 20,032.17996
Overall Steps per Second: 14,651.10057

Timestep Collection Time: 2.49708
Timestep Consumption Time: 0.91713
PPO Batch Consumption Time: 0.09375
Total Iteration Time: 3.41421

Cumulative Model Updates: 10,084
Cumulative Timesteps: 168,404,566

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 168404566...
Checkpoint 168404566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,975.35073
Policy Entropy: 0.47287
Value Function Loss: 3.84197

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03265
Policy Update Magnitude: 0.02921
Value Function Update Magnitude: 0.02044

Collected Steps per Second: 22,962.06930
Overall Steps per Second: 15,756.71079

Timestep Collection Time: 2.17864
Timestep Consumption Time: 0.99626
PPO Batch Consumption Time: 0.10834
Total Iteration Time: 3.17490

Cumulative Model Updates: 10,087
Cumulative Timesteps: 168,454,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,858.50780
Policy Entropy: 0.47046
Value Function Loss: 3.82472

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02742
Policy Update Magnitude: 0.03270
Value Function Update Magnitude: 0.01924

Collected Steps per Second: 22,471.21050
Overall Steps per Second: 16,799.10544

Timestep Collection Time: 2.22596
Timestep Consumption Time: 0.75158
PPO Batch Consumption Time: 0.03253
Total Iteration Time: 2.97754

Cumulative Model Updates: 10,090
Cumulative Timesteps: 168,504,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 168504612...
Checkpoint 168504612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,850.06489
Policy Entropy: 0.46908
Value Function Loss: 3.79501

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.05725
Policy Update Magnitude: 0.02992
Value Function Update Magnitude: 0.02234

Collected Steps per Second: 19,475.93315
Overall Steps per Second: 14,466.68120

Timestep Collection Time: 2.56932
Timestep Consumption Time: 0.88966
PPO Batch Consumption Time: 0.08236
Total Iteration Time: 3.45898

Cumulative Model Updates: 10,093
Cumulative Timesteps: 168,554,652

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,661.82201
Policy Entropy: 0.46496
Value Function Loss: 3.62731

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02954
Policy Update Magnitude: 0.02617
Value Function Update Magnitude: 0.02108

Collected Steps per Second: 20,371.87077
Overall Steps per Second: 15,006.08093

Timestep Collection Time: 2.45466
Timestep Consumption Time: 0.87772
PPO Batch Consumption Time: 0.10548
Total Iteration Time: 3.33238

Cumulative Model Updates: 10,096
Cumulative Timesteps: 168,604,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 168604658...
Checkpoint 168604658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,195.66221
Policy Entropy: 0.47184
Value Function Loss: 3.66927

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02808
Policy Update Magnitude: 0.02975
Value Function Update Magnitude: 0.02166

Collected Steps per Second: 22,671.12944
Overall Steps per Second: 16,669.71062

Timestep Collection Time: 2.20580
Timestep Consumption Time: 0.79413
PPO Batch Consumption Time: 0.05902
Total Iteration Time: 2.99993

Cumulative Model Updates: 10,099
Cumulative Timesteps: 168,654,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,064.53215
Policy Entropy: 0.46759
Value Function Loss: 3.76873

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03207
Policy Update Magnitude: 0.03219
Value Function Update Magnitude: 0.02020

Collected Steps per Second: 19,965.59179
Overall Steps per Second: 14,720.63467

Timestep Collection Time: 2.50481
Timestep Consumption Time: 0.89246
PPO Batch Consumption Time: 0.08300
Total Iteration Time: 3.39727

Cumulative Model Updates: 10,102
Cumulative Timesteps: 168,704,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 168704676...
Checkpoint 168704676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,407.28254
Policy Entropy: 0.46598
Value Function Loss: 3.86073

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02479
Policy Update Magnitude: 0.03126
Value Function Update Magnitude: 0.02122

Collected Steps per Second: 22,475.24931
Overall Steps per Second: 16,721.15488

Timestep Collection Time: 2.22485
Timestep Consumption Time: 0.76562
PPO Batch Consumption Time: 0.05903
Total Iteration Time: 2.99046

Cumulative Model Updates: 10,105
Cumulative Timesteps: 168,754,680

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,682.96222
Policy Entropy: 0.47026
Value Function Loss: 3.84048

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02989
Policy Update Magnitude: 0.02903
Value Function Update Magnitude: 0.02259

Collected Steps per Second: 20,988.74151
Overall Steps per Second: 15,715.50600

Timestep Collection Time: 2.38433
Timestep Consumption Time: 0.80004
PPO Batch Consumption Time: 0.07956
Total Iteration Time: 3.18437

Cumulative Model Updates: 10,108
Cumulative Timesteps: 168,804,724

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 168804724...
Checkpoint 168804724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,617.85623
Policy Entropy: 0.46700
Value Function Loss: 3.66591

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05734
Policy Update Magnitude: 0.03144
Value Function Update Magnitude: 0.02253

Collected Steps per Second: 22,134.65094
Overall Steps per Second: 16,750.10973

Timestep Collection Time: 2.26008
Timestep Consumption Time: 0.72653
PPO Batch Consumption Time: 0.05850
Total Iteration Time: 2.98661

Cumulative Model Updates: 10,111
Cumulative Timesteps: 168,854,750

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,512.79199
Policy Entropy: 0.46504
Value Function Loss: 3.74968

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08239
Policy Update Magnitude: 0.02919
Value Function Update Magnitude: 0.02182

Collected Steps per Second: 19,976.71074
Overall Steps per Second: 13,939.98001

Timestep Collection Time: 2.50442
Timestep Consumption Time: 1.08454
PPO Batch Consumption Time: 0.09581
Total Iteration Time: 3.58896

Cumulative Model Updates: 10,114
Cumulative Timesteps: 168,904,780

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 168904780...
Checkpoint 168904780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,448.03796
Policy Entropy: 0.47263
Value Function Loss: 3.54516

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07885
Policy Update Magnitude: 0.02453
Value Function Update Magnitude: 0.02007

Collected Steps per Second: 21,398.47417
Overall Steps per Second: 15,781.60929

Timestep Collection Time: 2.33662
Timestep Consumption Time: 0.83163
PPO Batch Consumption Time: 0.06044
Total Iteration Time: 3.16824

Cumulative Model Updates: 10,117
Cumulative Timesteps: 168,954,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,817.97601
Policy Entropy: 0.46862
Value Function Loss: 3.57451

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07379
Policy Update Magnitude: 0.02054
Value Function Update Magnitude: 0.02257

Collected Steps per Second: 19,487.28920
Overall Steps per Second: 13,829.69318

Timestep Collection Time: 2.56701
Timestep Consumption Time: 1.05014
PPO Batch Consumption Time: 0.12430
Total Iteration Time: 3.61714

Cumulative Model Updates: 10,120
Cumulative Timesteps: 169,004,804

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 169004804...
Checkpoint 169004804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,672.87858
Policy Entropy: 0.47238
Value Function Loss: 3.33843

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.06012
Policy Update Magnitude: 0.02287
Value Function Update Magnitude: 0.02004

Collected Steps per Second: 23,044.68633
Overall Steps per Second: 16,986.03967

Timestep Collection Time: 2.17022
Timestep Consumption Time: 0.77408
PPO Batch Consumption Time: 0.05762
Total Iteration Time: 2.94430

Cumulative Model Updates: 10,123
Cumulative Timesteps: 169,054,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,026.72073
Policy Entropy: 0.47505
Value Function Loss: 3.53109

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.04205
Policy Update Magnitude: 0.02294
Value Function Update Magnitude: 0.02018

Collected Steps per Second: 20,381.94185
Overall Steps per Second: 14,694.44836

Timestep Collection Time: 2.45492
Timestep Consumption Time: 0.95018
PPO Batch Consumption Time: 0.12111
Total Iteration Time: 3.40510

Cumulative Model Updates: 10,126
Cumulative Timesteps: 169,104,852

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 169104852...
Checkpoint 169104852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,411.58815
Policy Entropy: 0.47274
Value Function Loss: 3.48081

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03592
Policy Update Magnitude: 0.02162
Value Function Update Magnitude: 0.01928

Collected Steps per Second: 22,301.18944
Overall Steps per Second: 16,477.12647

Timestep Collection Time: 2.24338
Timestep Consumption Time: 0.79295
PPO Batch Consumption Time: 0.06182
Total Iteration Time: 3.03633

Cumulative Model Updates: 10,129
Cumulative Timesteps: 169,154,882

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,135.99494
Policy Entropy: 0.47107
Value Function Loss: 3.53695

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01799
Policy Update Magnitude: 0.02305
Value Function Update Magnitude: 0.01951

Collected Steps per Second: 19,397.77242
Overall Steps per Second: 15,029.52028

Timestep Collection Time: 2.57854
Timestep Consumption Time: 0.74944
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 3.32798

Cumulative Model Updates: 10,132
Cumulative Timesteps: 169,204,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 169204900...
Checkpoint 169204900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,207.32513
Policy Entropy: 0.46220
Value Function Loss: 3.69348

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03623
Policy Update Magnitude: 0.02383
Value Function Update Magnitude: 0.02049

Collected Steps per Second: 20,793.00953
Overall Steps per Second: 14,724.52587

Timestep Collection Time: 2.40542
Timestep Consumption Time: 0.99136
PPO Batch Consumption Time: 0.12167
Total Iteration Time: 3.39678

Cumulative Model Updates: 10,135
Cumulative Timesteps: 169,254,916

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,416.58028
Policy Entropy: 0.45875
Value Function Loss: 3.76807

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.02174
Policy Update Magnitude: 0.02172
Value Function Update Magnitude: 0.02110

Collected Steps per Second: 23,342.08253
Overall Steps per Second: 16,600.71710

Timestep Collection Time: 2.14420
Timestep Consumption Time: 0.87073
PPO Batch Consumption Time: 0.09342
Total Iteration Time: 3.01493

Cumulative Model Updates: 10,138
Cumulative Timesteps: 169,304,966

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 169304966...
Checkpoint 169304966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,650.20886
Policy Entropy: 0.45466
Value Function Loss: 3.66287

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02989
Policy Update Magnitude: 0.02118
Value Function Update Magnitude: 0.02117

Collected Steps per Second: 22,700.81828
Overall Steps per Second: 17,212.14342

Timestep Collection Time: 2.20344
Timestep Consumption Time: 0.70264
PPO Batch Consumption Time: 0.05816
Total Iteration Time: 2.90609

Cumulative Model Updates: 10,141
Cumulative Timesteps: 169,354,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,383.70510
Policy Entropy: 0.46254
Value Function Loss: 3.50020

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04346
Policy Update Magnitude: 0.02286
Value Function Update Magnitude: 0.02264

Collected Steps per Second: 23,694.86353
Overall Steps per Second: 16,456.07955

Timestep Collection Time: 2.11050
Timestep Consumption Time: 0.92838
PPO Batch Consumption Time: 0.10585
Total Iteration Time: 3.03888

Cumulative Model Updates: 10,144
Cumulative Timesteps: 169,404,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 169404994...
Checkpoint 169404994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,479.58745
Policy Entropy: 0.46792
Value Function Loss: 3.41208

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01415
Policy Update Magnitude: 0.02853
Value Function Update Magnitude: 0.02134

Collected Steps per Second: 21,910.27085
Overall Steps per Second: 15,658.68476

Timestep Collection Time: 2.28240
Timestep Consumption Time: 0.91123
PPO Batch Consumption Time: 0.08381
Total Iteration Time: 3.19363

Cumulative Model Updates: 10,147
Cumulative Timesteps: 169,455,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,849.62818
Policy Entropy: 0.46671
Value Function Loss: 3.48966

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01847
Policy Update Magnitude: 0.03404
Value Function Update Magnitude: 0.02024

Collected Steps per Second: 22,455.40611
Overall Steps per Second: 16,107.81510

Timestep Collection Time: 2.22690
Timestep Consumption Time: 0.87755
PPO Batch Consumption Time: 0.08074
Total Iteration Time: 3.10446

Cumulative Model Updates: 10,150
Cumulative Timesteps: 169,505,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 169505008...
Checkpoint 169505008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,525.23439
Policy Entropy: 0.47006
Value Function Loss: 3.44450

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03953
Policy Update Magnitude: 0.02868
Value Function Update Magnitude: 0.01953

Collected Steps per Second: 20,558.64004
Overall Steps per Second: 15,486.22616

Timestep Collection Time: 2.43255
Timestep Consumption Time: 0.79677
PPO Batch Consumption Time: 0.06381
Total Iteration Time: 3.22932

Cumulative Model Updates: 10,153
Cumulative Timesteps: 169,555,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,554.55487
Policy Entropy: 0.46263
Value Function Loss: 3.55472

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03931
Policy Update Magnitude: 0.02556
Value Function Update Magnitude: 0.01888

Collected Steps per Second: 20,574.39350
Overall Steps per Second: 15,187.43685

Timestep Collection Time: 2.43147
Timestep Consumption Time: 0.86244
PPO Batch Consumption Time: 0.08607
Total Iteration Time: 3.29391

Cumulative Model Updates: 10,156
Cumulative Timesteps: 169,605,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 169605044...
Checkpoint 169605044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,448.43589
Policy Entropy: 0.46814
Value Function Loss: 3.35487

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03743
Policy Update Magnitude: 0.02689
Value Function Update Magnitude: 0.02110

Collected Steps per Second: 21,041.93650
Overall Steps per Second: 16,060.66887

Timestep Collection Time: 2.37630
Timestep Consumption Time: 0.73702
PPO Batch Consumption Time: 0.06155
Total Iteration Time: 3.11332

Cumulative Model Updates: 10,159
Cumulative Timesteps: 169,655,046

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,866.25937
Policy Entropy: 0.47012
Value Function Loss: 3.39872

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.03183
Policy Update Magnitude: 0.02386
Value Function Update Magnitude: 0.02258

Collected Steps per Second: 18,934.65994
Overall Steps per Second: 14,220.61832

Timestep Collection Time: 2.64087
Timestep Consumption Time: 0.87543
PPO Batch Consumption Time: 0.08110
Total Iteration Time: 3.51630

Cumulative Model Updates: 10,162
Cumulative Timesteps: 169,705,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 169705050...
Checkpoint 169705050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,874.40742
Policy Entropy: 0.47299
Value Function Loss: 3.28777

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02642
Policy Update Magnitude: 0.02781
Value Function Update Magnitude: 0.02363

Collected Steps per Second: 21,291.11675
Overall Steps per Second: 15,537.65718

Timestep Collection Time: 2.34905
Timestep Consumption Time: 0.86983
PPO Batch Consumption Time: 0.07281
Total Iteration Time: 3.21889

Cumulative Model Updates: 10,165
Cumulative Timesteps: 169,755,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,094.82753
Policy Entropy: 0.46910
Value Function Loss: 3.36349

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03829
Policy Update Magnitude: 0.02368
Value Function Update Magnitude: 0.02311

Collected Steps per Second: 21,324.45318
Overall Steps per Second: 15,509.52783

Timestep Collection Time: 2.34566
Timestep Consumption Time: 0.87945
PPO Batch Consumption Time: 0.09329
Total Iteration Time: 3.22511

Cumulative Model Updates: 10,168
Cumulative Timesteps: 169,805,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 169805084...
Checkpoint 169805084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,495.53236
Policy Entropy: 0.46607
Value Function Loss: 3.33866

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.03209
Policy Update Magnitude: 0.02302
Value Function Update Magnitude: 0.02276

Collected Steps per Second: 22,423.64727
Overall Steps per Second: 16,941.03942

Timestep Collection Time: 2.23095
Timestep Consumption Time: 0.72200
PPO Batch Consumption Time: 0.06123
Total Iteration Time: 2.95295

Cumulative Model Updates: 10,171
Cumulative Timesteps: 169,855,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,791.28325
Policy Entropy: 0.45778
Value Function Loss: 3.39265

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.04449
Policy Update Magnitude: 0.02782
Value Function Update Magnitude: 0.02129

Collected Steps per Second: 23,286.99204
Overall Steps per Second: 16,513.84006

Timestep Collection Time: 2.14738
Timestep Consumption Time: 0.88075
PPO Batch Consumption Time: 0.08804
Total Iteration Time: 3.02813

Cumulative Model Updates: 10,174
Cumulative Timesteps: 169,905,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 169905116...
Checkpoint 169905116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,885.94985
Policy Entropy: 0.45996
Value Function Loss: 3.44431

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.04026
Policy Update Magnitude: 0.02350
Value Function Update Magnitude: 0.02259

Collected Steps per Second: 20,790.01042
Overall Steps per Second: 15,536.55684

Timestep Collection Time: 2.40644
Timestep Consumption Time: 0.81370
PPO Batch Consumption Time: 0.06021
Total Iteration Time: 3.22015

Cumulative Model Updates: 10,177
Cumulative Timesteps: 169,955,146

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,755.38222
Policy Entropy: 0.45934
Value Function Loss: 3.46989

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.05150
Policy Update Magnitude: 0.02089
Value Function Update Magnitude: 0.02159

Collected Steps per Second: 20,153.90615
Overall Steps per Second: 14,832.20516

Timestep Collection Time: 2.48160
Timestep Consumption Time: 0.89038
PPO Batch Consumption Time: 0.08035
Total Iteration Time: 3.37199

Cumulative Model Updates: 10,180
Cumulative Timesteps: 170,005,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 170005160...
Checkpoint 170005160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,014.97066
Policy Entropy: 0.45445
Value Function Loss: 3.45321

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.03210
Policy Update Magnitude: 0.02961
Value Function Update Magnitude: 0.02226

Collected Steps per Second: 22,681.82167
Overall Steps per Second: 16,705.70575

Timestep Collection Time: 2.20582
Timestep Consumption Time: 0.78909
PPO Batch Consumption Time: 0.06013
Total Iteration Time: 2.99490

Cumulative Model Updates: 10,183
Cumulative Timesteps: 170,055,192

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,932.16890
Policy Entropy: 0.44706
Value Function Loss: 3.58049

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.05633
Policy Update Magnitude: 0.02409
Value Function Update Magnitude: 0.02107

Collected Steps per Second: 20,348.16415
Overall Steps per Second: 14,879.04648

Timestep Collection Time: 2.45840
Timestep Consumption Time: 0.90364
PPO Batch Consumption Time: 0.09817
Total Iteration Time: 3.36204

Cumulative Model Updates: 10,186
Cumulative Timesteps: 170,105,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 170105216...
Checkpoint 170105216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,785.94038
Policy Entropy: 0.45351
Value Function Loss: 3.39704

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.05261
Policy Update Magnitude: 0.02543
Value Function Update Magnitude: 0.01976

Collected Steps per Second: 22,175.12067
Overall Steps per Second: 15,781.04017

Timestep Collection Time: 2.25541
Timestep Consumption Time: 0.91384
PPO Batch Consumption Time: 0.11864
Total Iteration Time: 3.16925

Cumulative Model Updates: 10,189
Cumulative Timesteps: 170,155,230

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,828.07897
Policy Entropy: 0.45865
Value Function Loss: 3.34612

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06597
Policy Update Magnitude: 0.02368
Value Function Update Magnitude: 0.02326

Collected Steps per Second: 23,554.34945
Overall Steps per Second: 16,978.93763

Timestep Collection Time: 2.12275
Timestep Consumption Time: 0.82207
PPO Batch Consumption Time: 0.06270
Total Iteration Time: 2.94483

Cumulative Model Updates: 10,192
Cumulative Timesteps: 170,205,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 170205230...
Checkpoint 170205230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,616.79932
Policy Entropy: 0.45745
Value Function Loss: 3.19582

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.06190
Policy Update Magnitude: 0.02119
Value Function Update Magnitude: 0.02269

Collected Steps per Second: 22,959.11659
Overall Steps per Second: 16,621.37220

Timestep Collection Time: 2.17900
Timestep Consumption Time: 0.83086
PPO Batch Consumption Time: 0.06833
Total Iteration Time: 3.00986

Cumulative Model Updates: 10,195
Cumulative Timesteps: 170,255,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,788.03427
Policy Entropy: 0.45217
Value Function Loss: 3.46090

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06595
Policy Update Magnitude: 0.02087
Value Function Update Magnitude: 0.02097

Collected Steps per Second: 23,250.19934
Overall Steps per Second: 16,711.10989

Timestep Collection Time: 2.15095
Timestep Consumption Time: 0.84167
PPO Batch Consumption Time: 0.06870
Total Iteration Time: 2.99262

Cumulative Model Updates: 10,198
Cumulative Timesteps: 170,305,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 170305268...
Checkpoint 170305268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,873.34620
Policy Entropy: 0.44738
Value Function Loss: 3.55842

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05923
Policy Update Magnitude: 0.01898
Value Function Update Magnitude: 0.02164

Collected Steps per Second: 22,409.56261
Overall Steps per Second: 16,693.26141

Timestep Collection Time: 2.23146
Timestep Consumption Time: 0.76412
PPO Batch Consumption Time: 0.05822
Total Iteration Time: 2.99558

Cumulative Model Updates: 10,201
Cumulative Timesteps: 170,355,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,271.91723
Policy Entropy: 0.44505
Value Function Loss: 3.64521

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.06735
Policy Update Magnitude: 0.02325
Value Function Update Magnitude: 0.02083

Collected Steps per Second: 20,371.37398
Overall Steps per Second: 14,690.84753

Timestep Collection Time: 2.45541
Timestep Consumption Time: 0.94943
PPO Batch Consumption Time: 0.11227
Total Iteration Time: 3.40484

Cumulative Model Updates: 10,204
Cumulative Timesteps: 170,405,294

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 170405294...
Checkpoint 170405294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,303.68500
Policy Entropy: 0.44366
Value Function Loss: 3.52494

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06753
Policy Update Magnitude: 0.02341
Value Function Update Magnitude: 0.02147

Collected Steps per Second: 21,305.91808
Overall Steps per Second: 15,674.19634

Timestep Collection Time: 2.34742
Timestep Consumption Time: 0.84343
PPO Batch Consumption Time: 0.09129
Total Iteration Time: 3.19085

Cumulative Model Updates: 10,207
Cumulative Timesteps: 170,455,308

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,302.53473
Policy Entropy: 0.44402
Value Function Loss: 3.45043

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06536
Policy Update Magnitude: 0.02162
Value Function Update Magnitude: 0.02134

Collected Steps per Second: 23,395.34280
Overall Steps per Second: 16,759.92069

Timestep Collection Time: 2.13778
Timestep Consumption Time: 0.84637
PPO Batch Consumption Time: 0.07237
Total Iteration Time: 2.98414

Cumulative Model Updates: 10,210
Cumulative Timesteps: 170,505,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 170505322...
Checkpoint 170505322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,806.76003
Policy Entropy: 0.44088
Value Function Loss: 3.26472

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05958
Policy Update Magnitude: 0.02302
Value Function Update Magnitude: 0.02223

Collected Steps per Second: 21,675.71815
Overall Steps per Second: 16,054.95097

Timestep Collection Time: 2.30747
Timestep Consumption Time: 0.80783
PPO Batch Consumption Time: 0.06442
Total Iteration Time: 3.11530

Cumulative Model Updates: 10,213
Cumulative Timesteps: 170,555,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,456.35142
Policy Entropy: 0.43989
Value Function Loss: 3.21087

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04701
Policy Update Magnitude: 0.02353
Value Function Update Magnitude: 0.02053

Collected Steps per Second: 23,351.62276
Overall Steps per Second: 16,354.44796

Timestep Collection Time: 2.14169
Timestep Consumption Time: 0.91631
PPO Batch Consumption Time: 0.10293
Total Iteration Time: 3.05801

Cumulative Model Updates: 10,216
Cumulative Timesteps: 170,605,350

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 170605350...
Checkpoint 170605350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,763.00218
Policy Entropy: 0.44137
Value Function Loss: 3.23177

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.05155
Policy Update Magnitude: 0.02562
Value Function Update Magnitude: 0.02281

Collected Steps per Second: 23,132.37430
Overall Steps per Second: 16,931.99690

Timestep Collection Time: 2.16251
Timestep Consumption Time: 0.79190
PPO Batch Consumption Time: 0.06233
Total Iteration Time: 2.95441

Cumulative Model Updates: 10,219
Cumulative Timesteps: 170,655,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,400.66687
Policy Entropy: 0.43838
Value Function Loss: 3.16130

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06318
Policy Update Magnitude: 0.02164
Value Function Update Magnitude: 0.02030

Collected Steps per Second: 23,218.01201
Overall Steps per Second: 16,518.46809

Timestep Collection Time: 2.15376
Timestep Consumption Time: 0.87352
PPO Batch Consumption Time: 0.09058
Total Iteration Time: 3.02728

Cumulative Model Updates: 10,222
Cumulative Timesteps: 170,705,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 170705380...
Checkpoint 170705380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,864.79779
Policy Entropy: 0.43900
Value Function Loss: 3.22839

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.05582
Policy Update Magnitude: 0.01949
Value Function Update Magnitude: 0.02394

Collected Steps per Second: 23,079.47738
Overall Steps per Second: 17,281.61651

Timestep Collection Time: 2.16799
Timestep Consumption Time: 0.72734
PPO Batch Consumption Time: 0.06263
Total Iteration Time: 2.89533

Cumulative Model Updates: 10,225
Cumulative Timesteps: 170,755,416

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,079.95265
Policy Entropy: 0.43281
Value Function Loss: 3.30703

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03938
Policy Update Magnitude: 0.02593
Value Function Update Magnitude: 0.02143

Collected Steps per Second: 23,234.22858
Overall Steps per Second: 16,272.80285

Timestep Collection Time: 2.15337
Timestep Consumption Time: 0.92120
PPO Batch Consumption Time: 0.10394
Total Iteration Time: 3.07458

Cumulative Model Updates: 10,228
Cumulative Timesteps: 170,805,448

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 170805448...
Checkpoint 170805448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,031.06710
Policy Entropy: 0.43507
Value Function Loss: 3.31149

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03403
Policy Update Magnitude: 0.02665
Value Function Update Magnitude: 0.02168

Collected Steps per Second: 23,215.80123
Overall Steps per Second: 16,913.50088

Timestep Collection Time: 2.15379
Timestep Consumption Time: 0.80254
PPO Batch Consumption Time: 0.06123
Total Iteration Time: 2.95634

Cumulative Model Updates: 10,231
Cumulative Timesteps: 170,855,450

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,091.49074
Policy Entropy: 0.43337
Value Function Loss: 3.29481

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03889
Policy Update Magnitude: 0.02766
Value Function Update Magnitude: 0.02215

Collected Steps per Second: 23,270.07596
Overall Steps per Second: 16,491.86355

Timestep Collection Time: 2.14980
Timestep Consumption Time: 0.88358
PPO Batch Consumption Time: 0.08226
Total Iteration Time: 3.03337

Cumulative Model Updates: 10,234
Cumulative Timesteps: 170,905,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 170905476...
Checkpoint 170905476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,796.95484
Policy Entropy: 0.43425
Value Function Loss: 3.24636

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.05830
Policy Update Magnitude: 0.02822
Value Function Update Magnitude: 0.01925

Collected Steps per Second: 20,506.86212
Overall Steps per Second: 15,251.55335

Timestep Collection Time: 2.43879
Timestep Consumption Time: 0.84035
PPO Batch Consumption Time: 0.06438
Total Iteration Time: 3.27914

Cumulative Model Updates: 10,237
Cumulative Timesteps: 170,955,488

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,950.62299
Policy Entropy: 0.43248
Value Function Loss: 3.39408

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.06871
Policy Update Magnitude: 0.02592
Value Function Update Magnitude: 0.02051

Collected Steps per Second: 19,959.14523
Overall Steps per Second: 15,448.55768

Timestep Collection Time: 2.50512
Timestep Consumption Time: 0.73143
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 3.23655

Cumulative Model Updates: 10,240
Cumulative Timesteps: 171,005,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 171005488...
Checkpoint 171005488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,384.69386
Policy Entropy: 0.43224
Value Function Loss: 3.38208

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04477
Policy Update Magnitude: 0.02255
Value Function Update Magnitude: 0.01965

Collected Steps per Second: 18,616.71826
Overall Steps per Second: 13,635.27988

Timestep Collection Time: 2.68576
Timestep Consumption Time: 0.98120
PPO Batch Consumption Time: 0.09269
Total Iteration Time: 3.66696

Cumulative Model Updates: 10,243
Cumulative Timesteps: 171,055,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,111.72146
Policy Entropy: 0.42808
Value Function Loss: 3.35944

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04977
Policy Update Magnitude: 0.02722
Value Function Update Magnitude: 0.01870

Collected Steps per Second: 21,834.98679
Overall Steps per Second: 16,671.21366

Timestep Collection Time: 2.29036
Timestep Consumption Time: 0.70942
PPO Batch Consumption Time: 0.02935
Total Iteration Time: 2.99978

Cumulative Model Updates: 10,246
Cumulative Timesteps: 171,105,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 171105498...
Checkpoint 171105498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,094.81149
Policy Entropy: 0.42776
Value Function Loss: 3.26396

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04989
Policy Update Magnitude: 0.02414
Value Function Update Magnitude: 0.01758

Collected Steps per Second: 23,108.78600
Overall Steps per Second: 15,935.48823

Timestep Collection Time: 2.16420
Timestep Consumption Time: 0.97421
PPO Batch Consumption Time: 0.10938
Total Iteration Time: 3.13840

Cumulative Model Updates: 10,249
Cumulative Timesteps: 171,155,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,636.21894
Policy Entropy: 0.42265
Value Function Loss: 3.32130

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03485
Policy Update Magnitude: 0.02159
Value Function Update Magnitude: 0.01925

Collected Steps per Second: 23,097.91023
Overall Steps per Second: 16,565.33964

Timestep Collection Time: 2.16539
Timestep Consumption Time: 0.85393
PPO Batch Consumption Time: 0.07837
Total Iteration Time: 3.01932

Cumulative Model Updates: 10,252
Cumulative Timesteps: 171,205,526

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 171205526...
Checkpoint 171205526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,338.77444
Policy Entropy: 0.42774
Value Function Loss: 3.27665

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02727
Policy Update Magnitude: 0.02630
Value Function Update Magnitude: 0.01951

Collected Steps per Second: 23,014.91313
Overall Steps per Second: 17,547.98791

Timestep Collection Time: 2.17355
Timestep Consumption Time: 0.67715
PPO Batch Consumption Time: 0.03108
Total Iteration Time: 2.85070

Cumulative Model Updates: 10,255
Cumulative Timesteps: 171,255,550

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,956.18523
Policy Entropy: 0.42520
Value Function Loss: 3.41024

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.03109
Policy Update Magnitude: 0.02516
Value Function Update Magnitude: 0.01971

Collected Steps per Second: 22,301.84093
Overall Steps per Second: 16,104.54739

Timestep Collection Time: 2.24233
Timestep Consumption Time: 0.86288
PPO Batch Consumption Time: 0.09954
Total Iteration Time: 3.10521

Cumulative Model Updates: 10,258
Cumulative Timesteps: 171,305,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 171305558...
Checkpoint 171305558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,593.16836
Policy Entropy: 0.42253
Value Function Loss: 3.34854

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03953
Policy Update Magnitude: 0.02707
Value Function Update Magnitude: 0.02028

Collected Steps per Second: 21,955.24819
Overall Steps per Second: 15,730.98066

Timestep Collection Time: 2.27763
Timestep Consumption Time: 0.90119
PPO Batch Consumption Time: 0.09192
Total Iteration Time: 3.17882

Cumulative Model Updates: 10,261
Cumulative Timesteps: 171,355,564

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,444.14307
Policy Entropy: 0.42495
Value Function Loss: 3.15718

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04603
Policy Update Magnitude: 0.02261
Value Function Update Magnitude: 0.02039

Collected Steps per Second: 22,868.22475
Overall Steps per Second: 16,685.82456

Timestep Collection Time: 2.18653
Timestep Consumption Time: 0.81015
PPO Batch Consumption Time: 0.06039
Total Iteration Time: 2.99668

Cumulative Model Updates: 10,264
Cumulative Timesteps: 171,405,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 171405566...
Checkpoint 171405566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,897.78264
Policy Entropy: 0.41784
Value Function Loss: 3.21616

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.03067
Policy Update Magnitude: 0.02286
Value Function Update Magnitude: 0.01987

Collected Steps per Second: 20,187.81458
Overall Steps per Second: 14,786.73216

Timestep Collection Time: 2.47704
Timestep Consumption Time: 0.90478
PPO Batch Consumption Time: 0.09038
Total Iteration Time: 3.38182

Cumulative Model Updates: 10,267
Cumulative Timesteps: 171,455,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,154.59183
Policy Entropy: 0.41849
Value Function Loss: 3.28706

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.02047
Policy Update Magnitude: 0.02963
Value Function Update Magnitude: 0.02038

Collected Steps per Second: 22,803.10453
Overall Steps per Second: 17,242.96144

Timestep Collection Time: 2.19277
Timestep Consumption Time: 0.70708
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 2.89985

Cumulative Model Updates: 10,270
Cumulative Timesteps: 171,505,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 171505574...
Checkpoint 171505574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,510.63957
Policy Entropy: 0.41814
Value Function Loss: 3.29410

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.03310
Value Function Update Magnitude: 0.02180

Collected Steps per Second: 22,277.42920
Overall Steps per Second: 17,483.91597

Timestep Collection Time: 2.24577
Timestep Consumption Time: 0.61572
PPO Batch Consumption Time: 0.03005
Total Iteration Time: 2.86149

Cumulative Model Updates: 10,273
Cumulative Timesteps: 171,555,604

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,317.04442
Policy Entropy: 0.41981
Value Function Loss: 3.27093

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03563
Policy Update Magnitude: 0.02828
Value Function Update Magnitude: 0.02095

Collected Steps per Second: 21,486.19709
Overall Steps per Second: 15,582.99157

Timestep Collection Time: 2.32745
Timestep Consumption Time: 0.88169
PPO Batch Consumption Time: 0.08400
Total Iteration Time: 3.20914

Cumulative Model Updates: 10,276
Cumulative Timesteps: 171,605,612

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 171605612...
Checkpoint 171605612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,248.92538
Policy Entropy: 0.42758
Value Function Loss: 3.04583

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01975
Policy Update Magnitude: 0.02862
Value Function Update Magnitude: 0.02065

Collected Steps per Second: 22,355.91574
Overall Steps per Second: 15,752.14625

Timestep Collection Time: 2.23744
Timestep Consumption Time: 0.93800
PPO Batch Consumption Time: 0.09785
Total Iteration Time: 3.17544

Cumulative Model Updates: 10,279
Cumulative Timesteps: 171,655,632

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,979.06735
Policy Entropy: 0.42840
Value Function Loss: 3.14769

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02901
Policy Update Magnitude: 0.02756
Value Function Update Magnitude: 0.01991

Collected Steps per Second: 22,702.66182
Overall Steps per Second: 16,673.15093

Timestep Collection Time: 2.20274
Timestep Consumption Time: 0.79658
PPO Batch Consumption Time: 0.06094
Total Iteration Time: 2.99931

Cumulative Model Updates: 10,282
Cumulative Timesteps: 171,705,640

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 171705640...
Checkpoint 171705640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,452.35618
Policy Entropy: 0.43964
Value Function Loss: 2.74220

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02171
Policy Update Magnitude: 0.02786
Value Function Update Magnitude: 0.01920

Collected Steps per Second: 20,441.23036
Overall Steps per Second: 15,933.34684

Timestep Collection Time: 2.44623
Timestep Consumption Time: 0.69209
PPO Batch Consumption Time: 0.02900
Total Iteration Time: 3.13832

Cumulative Model Updates: 10,285
Cumulative Timesteps: 171,755,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,059.07222
Policy Entropy: 0.43164
Value Function Loss: 2.84373

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.03277
Policy Update Magnitude: 0.02789
Value Function Update Magnitude: 0.01918

Collected Steps per Second: 22,851.67148
Overall Steps per Second: 17,177.15945

Timestep Collection Time: 2.18864
Timestep Consumption Time: 0.72302
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 2.91166

Cumulative Model Updates: 10,288
Cumulative Timesteps: 171,805,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 171805658...
Checkpoint 171805658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,729.97257
Policy Entropy: 0.43186
Value Function Loss: 2.75707

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03913
Policy Update Magnitude: 0.02252
Value Function Update Magnitude: 0.02193

Collected Steps per Second: 22,327.84008
Overall Steps per Second: 17,558.19589

Timestep Collection Time: 2.23963
Timestep Consumption Time: 0.60839
PPO Batch Consumption Time: 0.02996
Total Iteration Time: 2.84801

Cumulative Model Updates: 10,291
Cumulative Timesteps: 171,855,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,611.16725
Policy Entropy: 0.43019
Value Function Loss: 2.93841

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03697
Policy Update Magnitude: 0.02023
Value Function Update Magnitude: 0.02341

Collected Steps per Second: 23,320.30802
Overall Steps per Second: 16,543.46736

Timestep Collection Time: 2.14431
Timestep Consumption Time: 0.87839
PPO Batch Consumption Time: 0.08720
Total Iteration Time: 3.02270

Cumulative Model Updates: 10,294
Cumulative Timesteps: 171,905,670

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 171905670...
Checkpoint 171905670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,222.82602
Policy Entropy: 0.42974
Value Function Loss: 2.93302

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02792
Policy Update Magnitude: 0.01742
Value Function Update Magnitude: 0.02353

Collected Steps per Second: 22,701.21084
Overall Steps per Second: 16,643.64107

Timestep Collection Time: 2.20367
Timestep Consumption Time: 0.80204
PPO Batch Consumption Time: 0.05946
Total Iteration Time: 3.00571

Cumulative Model Updates: 10,297
Cumulative Timesteps: 171,955,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,705.30199
Policy Entropy: 0.42620
Value Function Loss: 3.01830

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.01197
Policy Update Magnitude: 0.02753
Value Function Update Magnitude: 0.02177

Collected Steps per Second: 19,980.97491
Overall Steps per Second: 14,770.08094

Timestep Collection Time: 2.50238
Timestep Consumption Time: 0.88284
PPO Batch Consumption Time: 0.07949
Total Iteration Time: 3.38522

Cumulative Model Updates: 10,300
Cumulative Timesteps: 172,005,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 172005696...
Checkpoint 172005696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,035.86636
Policy Entropy: 0.42096
Value Function Loss: 3.09214

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02847
Policy Update Magnitude: 0.03358
Value Function Update Magnitude: 0.02106

Collected Steps per Second: 22,726.12214
Overall Steps per Second: 15,943.06812

Timestep Collection Time: 2.20046
Timestep Consumption Time: 0.93620
PPO Batch Consumption Time: 0.10518
Total Iteration Time: 3.13666

Cumulative Model Updates: 10,303
Cumulative Timesteps: 172,055,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,381.27289
Policy Entropy: 0.41658
Value Function Loss: 3.17212

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02963
Policy Update Magnitude: 0.02898
Value Function Update Magnitude: 0.01972

Collected Steps per Second: 22,787.10949
Overall Steps per Second: 16,787.80828

Timestep Collection Time: 2.19510
Timestep Consumption Time: 0.78444
PPO Batch Consumption Time: 0.06583
Total Iteration Time: 2.97954

Cumulative Model Updates: 10,306
Cumulative Timesteps: 172,105,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 172105724...
Checkpoint 172105724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,125.75462
Policy Entropy: 0.41745
Value Function Loss: 3.19075

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03484
Policy Update Magnitude: 0.02676
Value Function Update Magnitude: 0.02136

Collected Steps per Second: 22,681.18001
Overall Steps per Second: 16,951.69279

Timestep Collection Time: 2.20465
Timestep Consumption Time: 0.74515
PPO Batch Consumption Time: 0.06278
Total Iteration Time: 2.94979

Cumulative Model Updates: 10,309
Cumulative Timesteps: 172,155,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,334.33561
Policy Entropy: 0.41692
Value Function Loss: 3.28026

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04505
Policy Update Magnitude: 0.02223
Value Function Update Magnitude: 0.02449

Collected Steps per Second: 22,519.18399
Overall Steps per Second: 16,509.97344

Timestep Collection Time: 2.22086
Timestep Consumption Time: 0.80834
PPO Batch Consumption Time: 0.06406
Total Iteration Time: 3.02920

Cumulative Model Updates: 10,312
Cumulative Timesteps: 172,205,740

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 172205740...
Checkpoint 172205740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,238.78275
Policy Entropy: 0.41800
Value Function Loss: 3.08251

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.04130
Policy Update Magnitude: 0.02182
Value Function Update Magnitude: 0.02529

Collected Steps per Second: 22,861.96338
Overall Steps per Second: 17,190.58232

Timestep Collection Time: 2.18826
Timestep Consumption Time: 0.72193
PPO Batch Consumption Time: 0.03231
Total Iteration Time: 2.91020

Cumulative Model Updates: 10,315
Cumulative Timesteps: 172,255,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,588.56542
Policy Entropy: 0.41169
Value Function Loss: 3.14183

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03688
Policy Update Magnitude: 0.02100
Value Function Update Magnitude: 0.02497

Collected Steps per Second: 23,282.98356
Overall Steps per Second: 17,498.77528

Timestep Collection Time: 2.14783
Timestep Consumption Time: 0.70997
PPO Batch Consumption Time: 0.02990
Total Iteration Time: 2.85780

Cumulative Model Updates: 10,318
Cumulative Timesteps: 172,305,776

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 172305776...
Checkpoint 172305776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,868.92456
Policy Entropy: 0.41446
Value Function Loss: 3.07131

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03995
Policy Update Magnitude: 0.02195
Value Function Update Magnitude: 0.02056

Collected Steps per Second: 21,568.16526
Overall Steps per Second: 15,383.75981

Timestep Collection Time: 2.31888
Timestep Consumption Time: 0.93221
PPO Batch Consumption Time: 0.09108
Total Iteration Time: 3.25109

Cumulative Model Updates: 10,321
Cumulative Timesteps: 172,355,790

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,834.72823
Policy Entropy: 0.41048
Value Function Loss: 3.15443

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02815
Policy Update Magnitude: 0.02272
Value Function Update Magnitude: 0.02101

Collected Steps per Second: 21,888.33388
Overall Steps per Second: 16,237.32064

Timestep Collection Time: 2.28560
Timestep Consumption Time: 0.79545
PPO Batch Consumption Time: 0.06205
Total Iteration Time: 3.08105

Cumulative Model Updates: 10,324
Cumulative Timesteps: 172,405,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 172405818...
Checkpoint 172405818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,774.01829
Policy Entropy: 0.40980
Value Function Loss: 3.11097

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03368
Policy Update Magnitude: 0.01929
Value Function Update Magnitude: 0.02273

Collected Steps per Second: 22,560.28009
Overall Steps per Second: 16,312.74069

Timestep Collection Time: 2.21691
Timestep Consumption Time: 0.84904
PPO Batch Consumption Time: 0.10531
Total Iteration Time: 3.06595

Cumulative Model Updates: 10,327
Cumulative Timesteps: 172,455,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,398.30338
Policy Entropy: 0.41448
Value Function Loss: 2.98244

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01623
Policy Update Magnitude: 0.02805
Value Function Update Magnitude: 0.02324

Collected Steps per Second: 22,724.37858
Overall Steps per Second: 16,728.75071

Timestep Collection Time: 2.20037
Timestep Consumption Time: 0.78862
PPO Batch Consumption Time: 0.06181
Total Iteration Time: 2.98899

Cumulative Model Updates: 10,330
Cumulative Timesteps: 172,505,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 172505834...
Checkpoint 172505834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,798.19409
Policy Entropy: 0.41481
Value Function Loss: 3.03292

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.03065
Value Function Update Magnitude: 0.02126

Collected Steps per Second: 20,187.03353
Overall Steps per Second: 14,748.53460

Timestep Collection Time: 2.47803
Timestep Consumption Time: 0.91377
PPO Batch Consumption Time: 0.09223
Total Iteration Time: 3.39179

Cumulative Model Updates: 10,333
Cumulative Timesteps: 172,555,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,776.94529
Policy Entropy: 0.41417
Value Function Loss: 2.91875

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.04071
Policy Update Magnitude: 0.02958
Value Function Update Magnitude: 0.02633

Collected Steps per Second: 22,764.19953
Overall Steps per Second: 16,677.54125

Timestep Collection Time: 2.19784
Timestep Consumption Time: 0.80213
PPO Batch Consumption Time: 0.05987
Total Iteration Time: 2.99996

Cumulative Model Updates: 10,336
Cumulative Timesteps: 172,605,890

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 172605890...
Checkpoint 172605890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,234.27667
Policy Entropy: 0.40915
Value Function Loss: 3.14205

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.02029
Policy Update Magnitude: 0.02607
Value Function Update Magnitude: 0.02467

Collected Steps per Second: 19,889.83370
Overall Steps per Second: 14,768.85851

Timestep Collection Time: 2.51485
Timestep Consumption Time: 0.87200
PPO Batch Consumption Time: 0.08511
Total Iteration Time: 3.38686

Cumulative Model Updates: 10,339
Cumulative Timesteps: 172,655,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,190.52306
Policy Entropy: 0.40952
Value Function Loss: 3.09093

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.02411
Value Function Update Magnitude: 0.02172

Collected Steps per Second: 23,056.15093
Overall Steps per Second: 17,284.87923

Timestep Collection Time: 2.16940
Timestep Consumption Time: 0.72434
PPO Batch Consumption Time: 0.06109
Total Iteration Time: 2.89374

Cumulative Model Updates: 10,342
Cumulative Timesteps: 172,705,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 172705928...
Checkpoint 172705928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,729.14622
Policy Entropy: 0.41155
Value Function Loss: 3.09824

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01807
Policy Update Magnitude: 0.02683
Value Function Update Magnitude: 0.02368

Collected Steps per Second: 22,031.70502
Overall Steps per Second: 16,612.60495

Timestep Collection Time: 2.27018
Timestep Consumption Time: 0.74054
PPO Batch Consumption Time: 0.05868
Total Iteration Time: 3.01073

Cumulative Model Updates: 10,345
Cumulative Timesteps: 172,755,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,817.81245
Policy Entropy: 0.41695
Value Function Loss: 2.91950

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.03077
Policy Update Magnitude: 0.02692
Value Function Update Magnitude: 0.02351

Collected Steps per Second: 23,397.88872
Overall Steps per Second: 17,587.45948

Timestep Collection Time: 2.13712
Timestep Consumption Time: 0.70605
PPO Batch Consumption Time: 0.02865
Total Iteration Time: 2.84316

Cumulative Model Updates: 10,348
Cumulative Timesteps: 172,805,948

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 172805948...
Checkpoint 172805948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,532.15995
Policy Entropy: 0.42186
Value Function Loss: 2.93578

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 0.02853
Value Function Update Magnitude: 0.02156

Collected Steps per Second: 21,662.04277
Overall Steps per Second: 15,682.33586

Timestep Collection Time: 2.30920
Timestep Consumption Time: 0.88050
PPO Batch Consumption Time: 0.08237
Total Iteration Time: 3.18970

Cumulative Model Updates: 10,351
Cumulative Timesteps: 172,855,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,733.30645
Policy Entropy: 0.42484
Value Function Loss: 3.08633

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.03051
Policy Update Magnitude: 0.03012
Value Function Update Magnitude: 0.02203

Collected Steps per Second: 22,979.85048
Overall Steps per Second: 15,895.65525

Timestep Collection Time: 2.17660
Timestep Consumption Time: 0.97004
PPO Batch Consumption Time: 0.10711
Total Iteration Time: 3.14665

Cumulative Model Updates: 10,354
Cumulative Timesteps: 172,905,988

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 172905988...
Checkpoint 172905988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,030.14529
Policy Entropy: 0.42732
Value Function Loss: 3.05009

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.02643
Value Function Update Magnitude: 0.02301

Collected Steps per Second: 23,265.35536
Overall Steps per Second: 17,551.53215

Timestep Collection Time: 2.15024
Timestep Consumption Time: 0.70000
PPO Batch Consumption Time: 0.03012
Total Iteration Time: 2.85024

Cumulative Model Updates: 10,357
Cumulative Timesteps: 172,956,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,442.96751
Policy Entropy: 0.42669
Value Function Loss: 3.00289

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04220
Policy Update Magnitude: 0.02406
Value Function Update Magnitude: 0.02588

Collected Steps per Second: 21,554.20062
Overall Steps per Second: 15,773.94879

Timestep Collection Time: 2.32010
Timestep Consumption Time: 0.85019
PPO Batch Consumption Time: 0.09918
Total Iteration Time: 3.17029

Cumulative Model Updates: 10,360
Cumulative Timesteps: 173,006,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 173006022...
Checkpoint 173006022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,287.65870
Policy Entropy: 0.42337
Value Function Loss: 2.87513

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02269
Policy Update Magnitude: 0.02304
Value Function Update Magnitude: 0.02374

Collected Steps per Second: 19,886.18791
Overall Steps per Second: 14,873.19239

Timestep Collection Time: 2.51551
Timestep Consumption Time: 0.84785
PPO Batch Consumption Time: 0.05932
Total Iteration Time: 3.36337

Cumulative Model Updates: 10,363
Cumulative Timesteps: 173,056,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,317.27840
Policy Entropy: 0.42511
Value Function Loss: 2.99799

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01817
Policy Update Magnitude: 0.02690
Value Function Update Magnitude: 0.02182

Collected Steps per Second: 19,596.02558
Overall Steps per Second: 14,583.30436

Timestep Collection Time: 2.55286
Timestep Consumption Time: 0.87750
PPO Batch Consumption Time: 0.07753
Total Iteration Time: 3.43036

Cumulative Model Updates: 10,366
Cumulative Timesteps: 173,106,072

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 173106072...
Checkpoint 173106072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,441.87723
Policy Entropy: 0.42199
Value Function Loss: 3.17692

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02534
Policy Update Magnitude: 0.02811
Value Function Update Magnitude: 0.02459

Collected Steps per Second: 20,983.73601
Overall Steps per Second: 15,556.17123

Timestep Collection Time: 2.38280
Timestep Consumption Time: 0.83136
PPO Batch Consumption Time: 0.06183
Total Iteration Time: 3.21416

Cumulative Model Updates: 10,369
Cumulative Timesteps: 173,156,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,513.39799
Policy Entropy: 0.41976
Value Function Loss: 3.32872

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05444
Policy Update Magnitude: 0.02546
Value Function Update Magnitude: 0.02169

Collected Steps per Second: 17,764.60650
Overall Steps per Second: 13,236.71745

Timestep Collection Time: 2.81582
Timestep Consumption Time: 0.96321
PPO Batch Consumption Time: 0.09171
Total Iteration Time: 3.77903

Cumulative Model Updates: 10,372
Cumulative Timesteps: 173,206,094

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 173206094...
Checkpoint 173206094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,394.12499
Policy Entropy: 0.41538
Value Function Loss: 3.29221

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04300
Policy Update Magnitude: 0.02688
Value Function Update Magnitude: 0.02369

Collected Steps per Second: 21,817.18846
Overall Steps per Second: 16,649.42585

Timestep Collection Time: 2.29305
Timestep Consumption Time: 0.71173
PPO Batch Consumption Time: 0.06011
Total Iteration Time: 3.00479

Cumulative Model Updates: 10,375
Cumulative Timesteps: 173,256,122

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,836.03664
Policy Entropy: 0.41670
Value Function Loss: 3.24606

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03517
Policy Update Magnitude: 0.02616
Value Function Update Magnitude: 0.02168

Collected Steps per Second: 20,752.99827
Overall Steps per Second: 15,028.88309

Timestep Collection Time: 2.41141
Timestep Consumption Time: 0.91844
PPO Batch Consumption Time: 0.09529
Total Iteration Time: 3.32985

Cumulative Model Updates: 10,378
Cumulative Timesteps: 173,306,166

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 173306166...
Checkpoint 173306166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,809.30112
Policy Entropy: 0.41229
Value Function Loss: 3.06402

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01938
Policy Update Magnitude: 0.02608
Value Function Update Magnitude: 0.02119

Collected Steps per Second: 22,822.87374
Overall Steps per Second: 15,788.39436

Timestep Collection Time: 2.19166
Timestep Consumption Time: 0.97649
PPO Batch Consumption Time: 0.10998
Total Iteration Time: 3.16815

Cumulative Model Updates: 10,381
Cumulative Timesteps: 173,356,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,205.72490
Policy Entropy: 0.41022
Value Function Loss: 3.05812

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.03048
Policy Update Magnitude: 0.02542
Value Function Update Magnitude: 0.02124

Collected Steps per Second: 20,840.15685
Overall Steps per Second: 15,121.78827

Timestep Collection Time: 2.39979
Timestep Consumption Time: 0.90749
PPO Batch Consumption Time: 0.07504
Total Iteration Time: 3.30728

Cumulative Model Updates: 10,384
Cumulative Timesteps: 173,406,198

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 173406198...
Checkpoint 173406198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,657.93787
Policy Entropy: 0.40865
Value Function Loss: 2.87005

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.02208
Policy Update Magnitude: 0.02635
Value Function Update Magnitude: 0.02137

Collected Steps per Second: 19,732.46514
Overall Steps per Second: 15,402.57190

Timestep Collection Time: 2.53450
Timestep Consumption Time: 0.71249
PPO Batch Consumption Time: 0.03013
Total Iteration Time: 3.24699

Cumulative Model Updates: 10,387
Cumulative Timesteps: 173,456,210

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,626.65109
Policy Entropy: 0.40608
Value Function Loss: 2.90854

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.03058
Policy Update Magnitude: 0.02555
Value Function Update Magnitude: 0.02053

Collected Steps per Second: 23,097.57873
Overall Steps per Second: 16,517.18622

Timestep Collection Time: 2.16525
Timestep Consumption Time: 0.86263
PPO Batch Consumption Time: 0.08893
Total Iteration Time: 3.02788

Cumulative Model Updates: 10,390
Cumulative Timesteps: 173,506,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 173506222...
Checkpoint 173506222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,073.80385
Policy Entropy: 0.41336
Value Function Loss: 2.70492

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02535
Policy Update Magnitude: 0.02499
Value Function Update Magnitude: 0.01997

Collected Steps per Second: 22,328.72817
Overall Steps per Second: 16,916.17243

Timestep Collection Time: 2.24052
Timestep Consumption Time: 0.71688
PPO Batch Consumption Time: 0.06032
Total Iteration Time: 2.95741

Cumulative Model Updates: 10,393
Cumulative Timesteps: 173,556,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,736.70953
Policy Entropy: 0.41695
Value Function Loss: 2.64426

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02779
Policy Update Magnitude: 0.02815
Value Function Update Magnitude: 0.03098

Collected Steps per Second: 20,782.37191
Overall Steps per Second: 14,703.10813

Timestep Collection Time: 2.40656
Timestep Consumption Time: 0.99503
PPO Batch Consumption Time: 0.12042
Total Iteration Time: 3.40159

Cumulative Model Updates: 10,396
Cumulative Timesteps: 173,606,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 173606264...
Checkpoint 173606264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,295.58707
Policy Entropy: 0.41383
Value Function Loss: 2.79757

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.03155
Policy Update Magnitude: 0.02418
Value Function Update Magnitude: 0.02883

Collected Steps per Second: 23,001.52262
Overall Steps per Second: 17,481.88888

Timestep Collection Time: 2.17507
Timestep Consumption Time: 0.68675
PPO Batch Consumption Time: 0.02917
Total Iteration Time: 2.86182

Cumulative Model Updates: 10,399
Cumulative Timesteps: 173,656,294

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,756.92755
Policy Entropy: 0.40262
Value Function Loss: 3.07023

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02881
Policy Update Magnitude: 0.02207
Value Function Update Magnitude: 0.02262

Collected Steps per Second: 23,106.13242
Overall Steps per Second: 16,001.21336

Timestep Collection Time: 2.16514
Timestep Consumption Time: 0.96137
PPO Batch Consumption Time: 0.10649
Total Iteration Time: 3.12651

Cumulative Model Updates: 10,402
Cumulative Timesteps: 173,706,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 173706322...
Checkpoint 173706322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,837.88639
Policy Entropy: 0.40268
Value Function Loss: 3.07547

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02167
Policy Update Magnitude: 0.03079
Value Function Update Magnitude: 0.03822

Collected Steps per Second: 22,910.07402
Overall Steps per Second: 17,557.56029

Timestep Collection Time: 2.18349
Timestep Consumption Time: 0.66565
PPO Batch Consumption Time: 0.02917
Total Iteration Time: 2.84914

Cumulative Model Updates: 10,405
Cumulative Timesteps: 173,756,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,663.37925
Policy Entropy: 0.40813
Value Function Loss: 2.89151

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03457
Policy Update Magnitude: 0.02888
Value Function Update Magnitude: 0.03853

Collected Steps per Second: 22,915.45779
Overall Steps per Second: 17,858.11199

Timestep Collection Time: 2.18263
Timestep Consumption Time: 0.61811
PPO Batch Consumption Time: 0.02900
Total Iteration Time: 2.80074

Cumulative Model Updates: 10,408
Cumulative Timesteps: 173,806,362

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 173806362...
Checkpoint 173806362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,613.98073
Policy Entropy: 0.41241
Value Function Loss: 2.77584

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03882
Policy Update Magnitude: 0.02419
Value Function Update Magnitude: 0.03194

Collected Steps per Second: 22,144.99295
Overall Steps per Second: 15,788.54859

Timestep Collection Time: 2.25893
Timestep Consumption Time: 0.90944
PPO Batch Consumption Time: 0.07788
Total Iteration Time: 3.16837

Cumulative Model Updates: 10,411
Cumulative Timesteps: 173,856,386

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,986.03936
Policy Entropy: 0.40594
Value Function Loss: 2.88666

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03817
Policy Update Magnitude: 0.02131
Value Function Update Magnitude: 0.03924

Collected Steps per Second: 20,866.52097
Overall Steps per Second: 16,101.62089

Timestep Collection Time: 2.39848
Timestep Consumption Time: 0.70978
PPO Batch Consumption Time: 0.03064
Total Iteration Time: 3.10826

Cumulative Model Updates: 10,414
Cumulative Timesteps: 173,906,434

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 173906434...
Checkpoint 173906434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,817.98940
Policy Entropy: 0.39992
Value Function Loss: 3.01527

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02932
Policy Update Magnitude: 0.01913
Value Function Update Magnitude: 0.03979

Collected Steps per Second: 21,465.25156
Overall Steps per Second: 15,474.72974

Timestep Collection Time: 2.32935
Timestep Consumption Time: 0.90173
PPO Batch Consumption Time: 0.08007
Total Iteration Time: 3.23107

Cumulative Model Updates: 10,417
Cumulative Timesteps: 173,956,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,953.29400
Policy Entropy: 0.39227
Value Function Loss: 3.29807

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02605
Policy Update Magnitude: 0.02082
Value Function Update Magnitude: 0.03688

Collected Steps per Second: 22,986.95339
Overall Steps per Second: 16,952.58227

Timestep Collection Time: 2.17689
Timestep Consumption Time: 0.77488
PPO Batch Consumption Time: 0.06154
Total Iteration Time: 2.95176

Cumulative Model Updates: 10,420
Cumulative Timesteps: 174,006,474

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 174006474...
Checkpoint 174006474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,536.93930
Policy Entropy: 0.39721
Value Function Loss: 3.18449

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.02206
Policy Update Magnitude: 0.02624
Value Function Update Magnitude: 0.03167

Collected Steps per Second: 21,849.09096
Overall Steps per Second: 17,255.47948

Timestep Collection Time: 2.28861
Timestep Consumption Time: 0.60925
PPO Batch Consumption Time: 0.02917
Total Iteration Time: 2.89786

Cumulative Model Updates: 10,423
Cumulative Timesteps: 174,056,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,751.33265
Policy Entropy: 0.39830
Value Function Loss: 3.15051

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.01420
Policy Update Magnitude: 0.02825
Value Function Update Magnitude: 0.03106

Collected Steps per Second: 23,197.17001
Overall Steps per Second: 16,258.97733

Timestep Collection Time: 2.15673
Timestep Consumption Time: 0.92034
PPO Batch Consumption Time: 0.10104
Total Iteration Time: 3.07707

Cumulative Model Updates: 10,426
Cumulative Timesteps: 174,106,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 174106508...
Checkpoint 174106508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,998.63633
Policy Entropy: 0.40363
Value Function Loss: 2.93122

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01917
Policy Update Magnitude: 0.02845
Value Function Update Magnitude: 0.02644

Collected Steps per Second: 22,986.84079
Overall Steps per Second: 17,452.77058

Timestep Collection Time: 2.17603
Timestep Consumption Time: 0.68999
PPO Batch Consumption Time: 0.02882
Total Iteration Time: 2.86602

Cumulative Model Updates: 10,429
Cumulative Timesteps: 174,156,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,734.87930
Policy Entropy: 0.39961
Value Function Loss: 3.05505

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02445
Policy Update Magnitude: 0.02632
Value Function Update Magnitude: 0.02917

Collected Steps per Second: 22,943.25818
Overall Steps per Second: 16,829.29114

Timestep Collection Time: 2.17938
Timestep Consumption Time: 0.79175
PPO Batch Consumption Time: 0.05316
Total Iteration Time: 2.97113

Cumulative Model Updates: 10,432
Cumulative Timesteps: 174,206,530

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 174206530...
Checkpoint 174206530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,322.47816
Policy Entropy: 0.39535
Value Function Loss: 3.05979

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.02338
Value Function Update Magnitude: 0.02880

Collected Steps per Second: 20,256.01674
Overall Steps per Second: 15,847.43419

Timestep Collection Time: 2.46899
Timestep Consumption Time: 0.68685
PPO Batch Consumption Time: 0.02963
Total Iteration Time: 3.15584

Cumulative Model Updates: 10,435
Cumulative Timesteps: 174,256,542

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,984.47949
Policy Entropy: 0.39373
Value Function Loss: 3.14751

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.04132
Policy Update Magnitude: 0.02272
Value Function Update Magnitude: 0.02684

Collected Steps per Second: 23,759.40878
Overall Steps per Second: 16,754.68634

Timestep Collection Time: 2.10468
Timestep Consumption Time: 0.87992
PPO Batch Consumption Time: 0.08909
Total Iteration Time: 2.98460

Cumulative Model Updates: 10,438
Cumulative Timesteps: 174,306,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 174306548...
Checkpoint 174306548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,055.86628
Policy Entropy: 0.40040
Value Function Loss: 3.10321

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.02839
Value Function Update Magnitude: 0.02338

Collected Steps per Second: 22,739.22464
Overall Steps per Second: 16,641.99867

Timestep Collection Time: 2.19972
Timestep Consumption Time: 0.80593
PPO Batch Consumption Time: 0.05872
Total Iteration Time: 3.00565

Cumulative Model Updates: 10,441
Cumulative Timesteps: 174,356,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,207.22483
Policy Entropy: 0.40069
Value Function Loss: 3.15456

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02892
Policy Update Magnitude: 0.02318
Value Function Update Magnitude: 0.02245

Collected Steps per Second: 21,459.75050
Overall Steps per Second: 16,503.71626

Timestep Collection Time: 2.33041
Timestep Consumption Time: 0.69982
PPO Batch Consumption Time: 0.02905
Total Iteration Time: 3.03023

Cumulative Model Updates: 10,444
Cumulative Timesteps: 174,406,578

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 174406578...
Checkpoint 174406578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,989.55234
Policy Entropy: 0.40183
Value Function Loss: 2.99430

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02620
Policy Update Magnitude: 0.02757
Value Function Update Magnitude: 0.02124

Collected Steps per Second: 22,956.61984
Overall Steps per Second: 16,930.48110

Timestep Collection Time: 2.17846
Timestep Consumption Time: 0.77539
PPO Batch Consumption Time: 0.04926
Total Iteration Time: 2.95384

Cumulative Model Updates: 10,447
Cumulative Timesteps: 174,456,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,626.21235
Policy Entropy: 0.39942
Value Function Loss: 3.01572

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03732
Policy Update Magnitude: 0.03593
Value Function Update Magnitude: 0.02026

Collected Steps per Second: 21,128.10960
Overall Steps per Second: 14,914.06789

Timestep Collection Time: 2.36737
Timestep Consumption Time: 0.98638
PPO Batch Consumption Time: 0.11757
Total Iteration Time: 3.35375

Cumulative Model Updates: 10,450
Cumulative Timesteps: 174,506,606

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 174506606...
Checkpoint 174506606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,712.07842
Policy Entropy: 0.40576
Value Function Loss: 2.88064

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04360
Policy Update Magnitude: 0.03520
Value Function Update Magnitude: 0.02121

Collected Steps per Second: 22,582.48140
Overall Steps per Second: 16,638.91186

Timestep Collection Time: 2.21526
Timestep Consumption Time: 0.79131
PPO Batch Consumption Time: 0.07865
Total Iteration Time: 3.00657

Cumulative Model Updates: 10,453
Cumulative Timesteps: 174,556,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,608.99520
Policy Entropy: 0.40273
Value Function Loss: 2.93594

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.05077
Policy Update Magnitude: 0.03143
Value Function Update Magnitude: 0.02202

Collected Steps per Second: 22,964.31825
Overall Steps per Second: 16,813.33906

Timestep Collection Time: 2.17781
Timestep Consumption Time: 0.79673
PPO Batch Consumption Time: 0.05989
Total Iteration Time: 2.97454

Cumulative Model Updates: 10,456
Cumulative Timesteps: 174,606,644

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 174606644...
Checkpoint 174606644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,280.00981
Policy Entropy: 0.40242
Value Function Loss: 2.84165

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02409
Policy Update Magnitude: 0.02982
Value Function Update Magnitude: 0.02095

Collected Steps per Second: 21,286.04749
Overall Steps per Second: 16,452.81254

Timestep Collection Time: 2.35102
Timestep Consumption Time: 0.69064
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 3.04167

Cumulative Model Updates: 10,459
Cumulative Timesteps: 174,656,688

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,878.79851
Policy Entropy: 0.40226
Value Function Loss: 2.91298

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.04115
Policy Update Magnitude: 0.03302
Value Function Update Magnitude: 0.02053

Collected Steps per Second: 22,662.16377
Overall Steps per Second: 16,001.57099

Timestep Collection Time: 2.20773
Timestep Consumption Time: 0.91896
PPO Batch Consumption Time: 0.10268
Total Iteration Time: 3.12669

Cumulative Model Updates: 10,462
Cumulative Timesteps: 174,706,720

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 174706720...
Checkpoint 174706720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,477.52791
Policy Entropy: 0.40063
Value Function Loss: 3.01805

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02584
Policy Update Magnitude: 0.03443
Value Function Update Magnitude: 0.02265

Collected Steps per Second: 22,169.81565
Overall Steps per Second: 16,451.84778

Timestep Collection Time: 2.25667
Timestep Consumption Time: 0.78432
PPO Batch Consumption Time: 0.06150
Total Iteration Time: 3.04100

Cumulative Model Updates: 10,465
Cumulative Timesteps: 174,756,750

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,960.67769
Policy Entropy: 0.40013
Value Function Loss: 3.05302

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03689
Policy Update Magnitude: 0.04024
Value Function Update Magnitude: 0.02274

Collected Steps per Second: 21,278.96088
Overall Steps per Second: 16,535.94615

Timestep Collection Time: 2.34974
Timestep Consumption Time: 0.67398
PPO Batch Consumption Time: 0.03825
Total Iteration Time: 3.02372

Cumulative Model Updates: 10,468
Cumulative Timesteps: 174,806,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 174806750...
Checkpoint 174806750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,060.08924
Policy Entropy: 0.39858
Value Function Loss: 3.11734

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03204
Policy Update Magnitude: 0.03329
Value Function Update Magnitude: 0.02875

Collected Steps per Second: 23,345.90327
Overall Steps per Second: 16,174.83933

Timestep Collection Time: 2.14273
Timestep Consumption Time: 0.94997
PPO Batch Consumption Time: 0.10550
Total Iteration Time: 3.09270

Cumulative Model Updates: 10,471
Cumulative Timesteps: 174,856,774

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,086.60668
Policy Entropy: 0.39559
Value Function Loss: 3.11914

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03735
Policy Update Magnitude: 0.03121
Value Function Update Magnitude: 0.02670

Collected Steps per Second: 22,331.37940
Overall Steps per Second: 16,935.00403

Timestep Collection Time: 2.23936
Timestep Consumption Time: 0.71358
PPO Batch Consumption Time: 0.02918
Total Iteration Time: 2.95294

Cumulative Model Updates: 10,474
Cumulative Timesteps: 174,906,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 174906782...
Checkpoint 174906782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,731.83298
Policy Entropy: 0.38872
Value Function Loss: 3.04250

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.04810
Policy Update Magnitude: 0.02882
Value Function Update Magnitude: 0.02375

Collected Steps per Second: 22,721.37706
Overall Steps per Second: 17,355.46343

Timestep Collection Time: 2.20154
Timestep Consumption Time: 0.68067
PPO Batch Consumption Time: 0.02964
Total Iteration Time: 2.88220

Cumulative Model Updates: 10,477
Cumulative Timesteps: 174,956,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,162.58418
Policy Entropy: 0.39035
Value Function Loss: 3.08787

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04833
Policy Update Magnitude: 0.02532
Value Function Update Magnitude: 0.02240

Collected Steps per Second: 21,840.51160
Overall Steps per Second: 15,913.39185

Timestep Collection Time: 2.28987
Timestep Consumption Time: 0.85289
PPO Batch Consumption Time: 0.07842
Total Iteration Time: 3.14276

Cumulative Model Updates: 10,480
Cumulative Timesteps: 175,006,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 175006816...
Checkpoint 175006816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,214.25545
Policy Entropy: 0.39367
Value Function Loss: 3.01918

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.04008
Policy Update Magnitude: 0.02365
Value Function Update Magnitude: 0.02101

Collected Steps per Second: 22,617.08934
Overall Steps per Second: 17,009.71496

Timestep Collection Time: 2.21222
Timestep Consumption Time: 0.72927
PPO Batch Consumption Time: 0.06258
Total Iteration Time: 2.94150

Cumulative Model Updates: 10,483
Cumulative Timesteps: 175,056,850

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,983.72058
Policy Entropy: 0.39897
Value Function Loss: 3.00847

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03391
Policy Update Magnitude: 0.03844
Value Function Update Magnitude: 0.02498

Collected Steps per Second: 22,961.51933
Overall Steps per Second: 17,368.09651

Timestep Collection Time: 2.17939
Timestep Consumption Time: 0.70187
PPO Batch Consumption Time: 0.02971
Total Iteration Time: 2.88126

Cumulative Model Updates: 10,486
Cumulative Timesteps: 175,106,892

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 175106892...
Checkpoint 175106892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,000.72282
Policy Entropy: 0.39561
Value Function Loss: 2.98425

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.04525
Policy Update Magnitude: 0.03346
Value Function Update Magnitude: 0.02521

Collected Steps per Second: 22,567.39713
Overall Steps per Second: 15,950.42938

Timestep Collection Time: 2.21674
Timestep Consumption Time: 0.91960
PPO Batch Consumption Time: 0.09988
Total Iteration Time: 3.13634

Cumulative Model Updates: 10,489
Cumulative Timesteps: 175,156,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,086.69361
Policy Entropy: 0.39357
Value Function Loss: 3.02886

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01417
Policy Update Magnitude: 0.03667
Value Function Update Magnitude: 0.02431

Collected Steps per Second: 22,837.34860
Overall Steps per Second: 17,457.81044

Timestep Collection Time: 2.19053
Timestep Consumption Time: 0.67500
PPO Batch Consumption Time: 0.02939
Total Iteration Time: 2.86554

Cumulative Model Updates: 10,492
Cumulative Timesteps: 175,206,944

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 175206944...
Checkpoint 175206944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,839.46167
Policy Entropy: 0.38458
Value Function Loss: 3.24299

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03015
Policy Update Magnitude: 0.03436
Value Function Update Magnitude: 0.02996

Collected Steps per Second: 23,023.02021
Overall Steps per Second: 17,610.40969

Timestep Collection Time: 2.17287
Timestep Consumption Time: 0.66784
PPO Batch Consumption Time: 0.02944
Total Iteration Time: 2.84071

Cumulative Model Updates: 10,495
Cumulative Timesteps: 175,256,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,925.16677
Policy Entropy: 0.38614
Value Function Loss: 3.17281

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03279
Policy Update Magnitude: 0.03511
Value Function Update Magnitude: 0.03110

Collected Steps per Second: 21,601.82742
Overall Steps per Second: 16,091.02918

Timestep Collection Time: 2.31517
Timestep Consumption Time: 0.79289
PPO Batch Consumption Time: 0.07616
Total Iteration Time: 3.10807

Cumulative Model Updates: 10,498
Cumulative Timesteps: 175,306,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 175306982...
Checkpoint 175306982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,214.02387
Policy Entropy: 0.38444
Value Function Loss: 3.01698

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02960
Policy Update Magnitude: 0.03247
Value Function Update Magnitude: 0.02826

Collected Steps per Second: 20,840.04676
Overall Steps per Second: 15,917.69909

Timestep Collection Time: 2.39942
Timestep Consumption Time: 0.74199
PPO Batch Consumption Time: 0.02877
Total Iteration Time: 3.14141

Cumulative Model Updates: 10,501
Cumulative Timesteps: 175,356,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,597.31034
Policy Entropy: 0.38430
Value Function Loss: 2.98431

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03654
Policy Update Magnitude: 0.03538
Value Function Update Magnitude: 0.02634

Collected Steps per Second: 19,743.60708
Overall Steps per Second: 15,078.82388

Timestep Collection Time: 2.53307
Timestep Consumption Time: 0.78363
PPO Batch Consumption Time: 0.03036
Total Iteration Time: 3.31670

Cumulative Model Updates: 10,504
Cumulative Timesteps: 175,406,998

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 175406998...
Checkpoint 175406998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,047.52182
Policy Entropy: 0.38681
Value Function Loss: 2.85591

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04855
Policy Update Magnitude: 0.03290
Value Function Update Magnitude: 0.02464

Collected Steps per Second: 20,941.53377
Overall Steps per Second: 16,207.55306

Timestep Collection Time: 2.38970
Timestep Consumption Time: 0.69800
PPO Batch Consumption Time: 0.03015
Total Iteration Time: 3.08770

Cumulative Model Updates: 10,507
Cumulative Timesteps: 175,457,042

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,962.61687
Policy Entropy: 0.38367
Value Function Loss: 2.96296

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04907
Policy Update Magnitude: 0.02778
Value Function Update Magnitude: 0.02297

Collected Steps per Second: 22,292.46429
Overall Steps per Second: 16,743.88612

Timestep Collection Time: 2.24291
Timestep Consumption Time: 0.74325
PPO Batch Consumption Time: 0.04148
Total Iteration Time: 2.98616

Cumulative Model Updates: 10,510
Cumulative Timesteps: 175,507,042

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 175507042...
Checkpoint 175507042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,898.16605
Policy Entropy: 0.39093
Value Function Loss: 2.78437

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.04127
Policy Update Magnitude: 0.02499
Value Function Update Magnitude: 0.02447

Collected Steps per Second: 20,774.43166
Overall Steps per Second: 14,966.13929

Timestep Collection Time: 2.40719
Timestep Consumption Time: 0.93422
PPO Batch Consumption Time: 0.10295
Total Iteration Time: 3.34141

Cumulative Model Updates: 10,513
Cumulative Timesteps: 175,557,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,972.36862
Policy Entropy: 0.38798
Value Function Loss: 2.91813

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03564
Policy Update Magnitude: 0.02463
Value Function Update Magnitude: 0.02762

Collected Steps per Second: 23,237.75877
Overall Steps per Second: 15,901.93537

Timestep Collection Time: 2.15245
Timestep Consumption Time: 0.99296
PPO Batch Consumption Time: 0.03068
Total Iteration Time: 3.14540

Cumulative Model Updates: 10,516
Cumulative Timesteps: 175,607,068

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 175607068...
Checkpoint 175607068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,963.61991
Policy Entropy: 0.39604
Value Function Loss: 2.79902

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03444
Policy Update Magnitude: 0.03129
Value Function Update Magnitude: 0.02625

Collected Steps per Second: 21,583.83200
Overall Steps per Second: 15,468.04423

Timestep Collection Time: 2.31775
Timestep Consumption Time: 0.91640
PPO Batch Consumption Time: 0.09306
Total Iteration Time: 3.23415

Cumulative Model Updates: 10,519
Cumulative Timesteps: 175,657,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,609.85974
Policy Entropy: 0.39591
Value Function Loss: 2.85643

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03801
Policy Update Magnitude: 0.02927
Value Function Update Magnitude: 0.03058

Collected Steps per Second: 21,715.27863
Overall Steps per Second: 16,020.85921

Timestep Collection Time: 2.30317
Timestep Consumption Time: 0.81863
PPO Batch Consumption Time: 0.06830
Total Iteration Time: 3.12181

Cumulative Model Updates: 10,522
Cumulative Timesteps: 175,707,108

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 175707108...
Checkpoint 175707108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,753.13535
Policy Entropy: 0.39041
Value Function Loss: 2.86092

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03892
Policy Update Magnitude: 0.02919
Value Function Update Magnitude: 0.03139

Collected Steps per Second: 23,057.48566
Overall Steps per Second: 17,481.29066

Timestep Collection Time: 2.16945
Timestep Consumption Time: 0.69201
PPO Batch Consumption Time: 0.02952
Total Iteration Time: 2.86146

Cumulative Model Updates: 10,525
Cumulative Timesteps: 175,757,130

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,164.16941
Policy Entropy: 0.39205
Value Function Loss: 2.93496

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03365
Policy Update Magnitude: 0.02923
Value Function Update Magnitude: 0.03204

Collected Steps per Second: 22,920.05708
Overall Steps per Second: 16,787.85051

Timestep Collection Time: 2.18158
Timestep Consumption Time: 0.79688
PPO Batch Consumption Time: 0.03231
Total Iteration Time: 2.97846

Cumulative Model Updates: 10,528
Cumulative Timesteps: 175,807,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 175807132...
Checkpoint 175807132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,607.13492
Policy Entropy: 0.38904
Value Function Loss: 2.87195

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03701
Policy Update Magnitude: 0.02464
Value Function Update Magnitude: 0.03026

Collected Steps per Second: 20,127.62898
Overall Steps per Second: 15,442.41274

Timestep Collection Time: 2.48484
Timestep Consumption Time: 0.75390
PPO Batch Consumption Time: 0.02892
Total Iteration Time: 3.23874

Cumulative Model Updates: 10,531
Cumulative Timesteps: 175,857,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,740.95704
Policy Entropy: 0.39195
Value Function Loss: 2.86595

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.04382
Policy Update Magnitude: 0.02839
Value Function Update Magnitude: 0.03083

Collected Steps per Second: 21,808.11640
Overall Steps per Second: 14,786.40511

Timestep Collection Time: 2.29300
Timestep Consumption Time: 1.08889
PPO Batch Consumption Time: 0.12397
Total Iteration Time: 3.38189

Cumulative Model Updates: 10,534
Cumulative Timesteps: 175,907,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 175907152...
Checkpoint 175907152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,371.87522
Policy Entropy: 0.39497
Value Function Loss: 2.84775

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.04030
Policy Update Magnitude: 0.02432
Value Function Update Magnitude: 0.02762

Collected Steps per Second: 21,776.64393
Overall Steps per Second: 16,949.91249

Timestep Collection Time: 2.29668
Timestep Consumption Time: 0.65401
PPO Batch Consumption Time: 0.03036
Total Iteration Time: 2.95069

Cumulative Model Updates: 10,537
Cumulative Timesteps: 175,957,166

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,411.23965
Policy Entropy: 0.39265
Value Function Loss: 2.99015

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03299
Policy Update Magnitude: 0.02100
Value Function Update Magnitude: 0.02434

Collected Steps per Second: 22,375.37380
Overall Steps per Second: 15,810.93172

Timestep Collection Time: 2.23594
Timestep Consumption Time: 0.92833
PPO Batch Consumption Time: 0.11362
Total Iteration Time: 3.16427

Cumulative Model Updates: 10,540
Cumulative Timesteps: 176,007,196

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 176007196...
Checkpoint 176007196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,561.39349
Policy Entropy: 0.38686
Value Function Loss: 2.96367

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.02431
Policy Update Magnitude: 0.02164
Value Function Update Magnitude: 0.02551

Collected Steps per Second: 23,782.68723
Overall Steps per Second: 16,767.56806

Timestep Collection Time: 2.10329
Timestep Consumption Time: 0.87996
PPO Batch Consumption Time: 0.11435
Total Iteration Time: 2.98326

Cumulative Model Updates: 10,543
Cumulative Timesteps: 176,057,218

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,081.50176
Policy Entropy: 0.38427
Value Function Loss: 3.08814

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03627
Policy Update Magnitude: 0.02161
Value Function Update Magnitude: 0.02474

Collected Steps per Second: 23,231.86637
Overall Steps per Second: 16,397.89910

Timestep Collection Time: 2.15325
Timestep Consumption Time: 0.89739
PPO Batch Consumption Time: 0.08015
Total Iteration Time: 3.05063

Cumulative Model Updates: 10,546
Cumulative Timesteps: 176,107,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 176107242...
Checkpoint 176107242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,536.72428
Policy Entropy: 0.37838
Value Function Loss: 3.11858

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03549
Policy Update Magnitude: 0.01955
Value Function Update Magnitude: 0.02921

Collected Steps per Second: 20,523.06405
Overall Steps per Second: 15,000.76818

Timestep Collection Time: 2.43726
Timestep Consumption Time: 0.89724
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 3.33450

Cumulative Model Updates: 10,549
Cumulative Timesteps: 176,157,262

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,930.97428
Policy Entropy: 0.38041
Value Function Loss: 3.13820

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03509
Policy Update Magnitude: 0.01953
Value Function Update Magnitude: 0.02822

Collected Steps per Second: 23,598.13626
Overall Steps per Second: 17,806.60222

Timestep Collection Time: 2.11898
Timestep Consumption Time: 0.68919
PPO Batch Consumption Time: 0.02844
Total Iteration Time: 2.80817

Cumulative Model Updates: 10,552
Cumulative Timesteps: 176,207,266

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 176207266...
Checkpoint 176207266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,143.38731
Policy Entropy: 0.38639
Value Function Loss: 3.03065

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.03152
Policy Update Magnitude: 0.01992
Value Function Update Magnitude: 0.02753

Collected Steps per Second: 21,221.13939
Overall Steps per Second: 14,700.33047

Timestep Collection Time: 2.35746
Timestep Consumption Time: 1.04573
PPO Batch Consumption Time: 0.10602
Total Iteration Time: 3.40319

Cumulative Model Updates: 10,555
Cumulative Timesteps: 176,257,294

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,966.81163
Policy Entropy: 0.38613
Value Function Loss: 2.86092

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04851
Policy Update Magnitude: 0.02139
Value Function Update Magnitude: 0.02694

Collected Steps per Second: 20,504.60396
Overall Steps per Second: 16,267.92926

Timestep Collection Time: 2.43935
Timestep Consumption Time: 0.63528
PPO Batch Consumption Time: 0.03004
Total Iteration Time: 3.07464

Cumulative Model Updates: 10,558
Cumulative Timesteps: 176,307,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 176307312...
Checkpoint 176307312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,118.32930
Policy Entropy: 0.38219
Value Function Loss: 2.99734

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04876
Policy Update Magnitude: 0.01835
Value Function Update Magnitude: 0.03333

Collected Steps per Second: 20,152.09133
Overall Steps per Second: 14,412.40331

Timestep Collection Time: 2.48252
Timestep Consumption Time: 0.98866
PPO Batch Consumption Time: 0.11170
Total Iteration Time: 3.47118

Cumulative Model Updates: 10,561
Cumulative Timesteps: 176,357,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,166.12421
Policy Entropy: 0.37496
Value Function Loss: 3.18216

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.04351
Policy Update Magnitude: 0.01826
Value Function Update Magnitude: 0.02603

Collected Steps per Second: 21,060.07043
Overall Steps per Second: 15,520.96225

Timestep Collection Time: 2.37473
Timestep Consumption Time: 0.84749
PPO Batch Consumption Time: 0.07530
Total Iteration Time: 3.22222

Cumulative Model Updates: 10,564
Cumulative Timesteps: 176,407,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 176407352...
Checkpoint 176407352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,200.48802
Policy Entropy: 0.37367
Value Function Loss: 3.18150

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03935
Policy Update Magnitude: 0.01720
Value Function Update Magnitude: 0.02944

Collected Steps per Second: 22,585.65005
Overall Steps per Second: 15,935.89040

Timestep Collection Time: 2.21441
Timestep Consumption Time: 0.92404
PPO Batch Consumption Time: 0.11226
Total Iteration Time: 3.13845

Cumulative Model Updates: 10,567
Cumulative Timesteps: 176,457,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,835.73864
Policy Entropy: 0.37309
Value Function Loss: 3.09529

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04689
Policy Update Magnitude: 0.01892
Value Function Update Magnitude: 0.02563

Collected Steps per Second: 23,571.89518
Overall Steps per Second: 17,632.29820

Timestep Collection Time: 2.12202
Timestep Consumption Time: 0.71482
PPO Batch Consumption Time: 0.05952
Total Iteration Time: 2.83684

Cumulative Model Updates: 10,570
Cumulative Timesteps: 176,507,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 176507386...
Checkpoint 176507386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,675.22925
Policy Entropy: 0.37867
Value Function Loss: 2.88603

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03811
Policy Update Magnitude: 0.02114
Value Function Update Magnitude: 0.02509

Collected Steps per Second: 20,337.68559
Overall Steps per Second: 14,883.06254

Timestep Collection Time: 2.45957
Timestep Consumption Time: 0.90143
PPO Batch Consumption Time: 0.09561
Total Iteration Time: 3.36100

Cumulative Model Updates: 10,573
Cumulative Timesteps: 176,557,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,663.09123
Policy Entropy: 0.37935
Value Function Loss: 2.97969

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.05081
Policy Update Magnitude: 0.02402
Value Function Update Magnitude: 0.02726

Collected Steps per Second: 23,690.47902
Overall Steps per Second: 16,738.35394

Timestep Collection Time: 2.11089
Timestep Consumption Time: 0.87674
PPO Batch Consumption Time: 0.09144
Total Iteration Time: 2.98763

Cumulative Model Updates: 10,576
Cumulative Timesteps: 176,607,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 176607416...
Checkpoint 176607416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,535.14530
Policy Entropy: 0.38435
Value Function Loss: 2.86147

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02955
Policy Update Magnitude: 0.02197
Value Function Update Magnitude: 0.02383

Collected Steps per Second: 23,572.17488
Overall Steps per Second: 16,746.37207

Timestep Collection Time: 2.12140
Timestep Consumption Time: 0.86468
PPO Batch Consumption Time: 0.08107
Total Iteration Time: 2.98608

Cumulative Model Updates: 10,579
Cumulative Timesteps: 176,657,422

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,707.65873
Policy Entropy: 0.38538
Value Function Loss: 2.87747

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03687
Policy Update Magnitude: 0.02835
Value Function Update Magnitude: 0.02498

Collected Steps per Second: 23,686.38776
Overall Steps per Second: 16,749.03854

Timestep Collection Time: 2.11193
Timestep Consumption Time: 0.87475
PPO Batch Consumption Time: 0.09993
Total Iteration Time: 2.98668

Cumulative Model Updates: 10,582
Cumulative Timesteps: 176,707,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 176707446...
Checkpoint 176707446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,276.18896
Policy Entropy: 0.38222
Value Function Loss: 2.96045

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03651
Policy Update Magnitude: 0.02411
Value Function Update Magnitude: 0.02417

Collected Steps per Second: 23,532.79748
Overall Steps per Second: 16,779.48411

Timestep Collection Time: 2.12588
Timestep Consumption Time: 0.85561
PPO Batch Consumption Time: 0.10486
Total Iteration Time: 2.98150

Cumulative Model Updates: 10,585
Cumulative Timesteps: 176,757,474

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,103.20647
Policy Entropy: 0.37964
Value Function Loss: 2.98123

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03327
Policy Update Magnitude: 0.02165
Value Function Update Magnitude: 0.02293

Collected Steps per Second: 22,765.24778
Overall Steps per Second: 15,726.77618

Timestep Collection Time: 2.19642
Timestep Consumption Time: 0.98300
PPO Batch Consumption Time: 0.12172
Total Iteration Time: 3.17942

Cumulative Model Updates: 10,588
Cumulative Timesteps: 176,807,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 176807476...
Checkpoint 176807476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,065.05476
Policy Entropy: 0.37531
Value Function Loss: 2.96111

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.02518
Value Function Update Magnitude: 0.02274

Collected Steps per Second: 23,447.73382
Overall Steps per Second: 17,034.12106

Timestep Collection Time: 2.13317
Timestep Consumption Time: 0.80317
PPO Batch Consumption Time: 0.06406
Total Iteration Time: 2.93634

Cumulative Model Updates: 10,591
Cumulative Timesteps: 176,857,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,528.56131
Policy Entropy: 0.37706
Value Function Loss: 2.90955

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.02335
Policy Update Magnitude: 0.02647
Value Function Update Magnitude: 0.02312

Collected Steps per Second: 23,290.90253
Overall Steps per Second: 16,338.62544

Timestep Collection Time: 2.14719
Timestep Consumption Time: 0.91365
PPO Batch Consumption Time: 0.09117
Total Iteration Time: 3.06084

Cumulative Model Updates: 10,594
Cumulative Timesteps: 176,907,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 176907504...
Checkpoint 176907504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,553.96675
Policy Entropy: 0.37347
Value Function Loss: 2.75138

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03337
Policy Update Magnitude: 0.02496
Value Function Update Magnitude: 0.02329

Collected Steps per Second: 23,197.97393
Overall Steps per Second: 17,162.43174

Timestep Collection Time: 2.15571
Timestep Consumption Time: 0.75810
PPO Batch Consumption Time: 0.05895
Total Iteration Time: 2.91381

Cumulative Model Updates: 10,597
Cumulative Timesteps: 176,957,512

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,435.66801
Policy Entropy: 0.38031
Value Function Loss: 2.73011

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03580
Policy Update Magnitude: 0.02387
Value Function Update Magnitude: 0.02373

Collected Steps per Second: 22,844.94629
Overall Steps per Second: 16,983.80708

Timestep Collection Time: 2.18928
Timestep Consumption Time: 0.75552
PPO Batch Consumption Time: 0.05862
Total Iteration Time: 2.94480

Cumulative Model Updates: 10,600
Cumulative Timesteps: 177,007,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 177007526...
Checkpoint 177007526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,172.40520
Policy Entropy: 0.37953
Value Function Loss: 2.60406

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03357
Policy Update Magnitude: 0.02341
Value Function Update Magnitude: 0.02417

Collected Steps per Second: 21,234.26184
Overall Steps per Second: 15,281.58237

Timestep Collection Time: 2.35619
Timestep Consumption Time: 0.91781
PPO Batch Consumption Time: 0.12270
Total Iteration Time: 3.27401

Cumulative Model Updates: 10,603
Cumulative Timesteps: 177,057,558

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,714.96142
Policy Entropy: 0.37969
Value Function Loss: 2.62400

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03530
Policy Update Magnitude: 0.02845
Value Function Update Magnitude: 0.02553

Collected Steps per Second: 24,070.92895
Overall Steps per Second: 17,507.64428

Timestep Collection Time: 2.07753
Timestep Consumption Time: 0.77883
PPO Batch Consumption Time: 0.06138
Total Iteration Time: 2.85635

Cumulative Model Updates: 10,606
Cumulative Timesteps: 177,107,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 177107566...
Checkpoint 177107566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,274.56338
Policy Entropy: 0.37839
Value Function Loss: 2.46986

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05437
Policy Update Magnitude: 0.02590
Value Function Update Magnitude: 0.02319

Collected Steps per Second: 20,436.08031
Overall Steps per Second: 14,971.38273

Timestep Collection Time: 2.44734
Timestep Consumption Time: 0.89330
PPO Batch Consumption Time: 0.08918
Total Iteration Time: 3.34064

Cumulative Model Updates: 10,609
Cumulative Timesteps: 177,157,580

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,137.50643
Policy Entropy: 0.37573
Value Function Loss: 2.50212

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06897
Policy Update Magnitude: 0.02502
Value Function Update Magnitude: 0.02928

Collected Steps per Second: 23,643.28003
Overall Steps per Second: 16,693.01715

Timestep Collection Time: 2.11477
Timestep Consumption Time: 0.88050
PPO Batch Consumption Time: 0.08254
Total Iteration Time: 2.99526

Cumulative Model Updates: 10,612
Cumulative Timesteps: 177,207,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 177207580...
Checkpoint 177207580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,520.18762
Policy Entropy: 0.37494
Value Function Loss: 2.70966

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06791
Policy Update Magnitude: 0.02424
Value Function Update Magnitude: 0.02543

Collected Steps per Second: 23,075.15658
Overall Steps per Second: 15,842.53189

Timestep Collection Time: 2.16727
Timestep Consumption Time: 0.98943
PPO Batch Consumption Time: 0.11939
Total Iteration Time: 3.15669

Cumulative Model Updates: 10,615
Cumulative Timesteps: 177,257,590

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,819.81698
Policy Entropy: 0.37014
Value Function Loss: 2.80043

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05272
Policy Update Magnitude: 0.02187
Value Function Update Magnitude: 0.02719

Collected Steps per Second: 24,128.41983
Overall Steps per Second: 17,283.55068

Timestep Collection Time: 2.07233
Timestep Consumption Time: 0.82071
PPO Batch Consumption Time: 0.07797
Total Iteration Time: 2.89304

Cumulative Model Updates: 10,618
Cumulative Timesteps: 177,307,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 177307592...
Checkpoint 177307592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,484.47754
Policy Entropy: 0.37534
Value Function Loss: 2.91398

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03631
Policy Update Magnitude: 0.02359
Value Function Update Magnitude: 0.02598

Collected Steps per Second: 19,137.61569
Overall Steps per Second: 14,151.45387

Timestep Collection Time: 2.61495
Timestep Consumption Time: 0.92136
PPO Batch Consumption Time: 0.11660
Total Iteration Time: 3.53632

Cumulative Model Updates: 10,621
Cumulative Timesteps: 177,357,636

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,990.17232
Policy Entropy: 0.37059
Value Function Loss: 2.73550

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04227
Policy Update Magnitude: 0.02545
Value Function Update Magnitude: 0.02660

Collected Steps per Second: 19,955.49568
Overall Steps per Second: 14,770.17514

Timestep Collection Time: 2.50668
Timestep Consumption Time: 0.88001
PPO Batch Consumption Time: 0.10876
Total Iteration Time: 3.38669

Cumulative Model Updates: 10,624
Cumulative Timesteps: 177,407,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 177407658...
Checkpoint 177407658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,476.28520
Policy Entropy: 0.36959
Value Function Loss: 2.72049

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03917
Policy Update Magnitude: 0.02482
Value Function Update Magnitude: 0.02637

Collected Steps per Second: 22,724.26765
Overall Steps per Second: 16,434.81610

Timestep Collection Time: 2.20082
Timestep Consumption Time: 0.84223
PPO Batch Consumption Time: 0.06164
Total Iteration Time: 3.04305

Cumulative Model Updates: 10,627
Cumulative Timesteps: 177,457,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,295.10561
Policy Entropy: 0.37365
Value Function Loss: 2.56988

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03544
Policy Update Magnitude: 0.02755
Value Function Update Magnitude: 0.02627

Collected Steps per Second: 18,544.77894
Overall Steps per Second: 13,479.05950

Timestep Collection Time: 2.69628
Timestep Consumption Time: 1.01332
PPO Batch Consumption Time: 0.10093
Total Iteration Time: 3.70961

Cumulative Model Updates: 10,630
Cumulative Timesteps: 177,507,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 177507672...
Checkpoint 177507672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,737.98590
Policy Entropy: 0.37453
Value Function Loss: 2.48792

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04625
Policy Update Magnitude: 0.02092
Value Function Update Magnitude: 0.02450

Collected Steps per Second: 20,576.70450
Overall Steps per Second: 14,845.01819

Timestep Collection Time: 2.43188
Timestep Consumption Time: 0.93895
PPO Batch Consumption Time: 0.09204
Total Iteration Time: 3.37083

Cumulative Model Updates: 10,633
Cumulative Timesteps: 177,557,712

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,902.12490
Policy Entropy: 0.37142
Value Function Loss: 2.51899

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02875
Policy Update Magnitude: 0.02177
Value Function Update Magnitude: 0.02688

Collected Steps per Second: 23,921.97013
Overall Steps per Second: 17,625.48698

Timestep Collection Time: 2.09088
Timestep Consumption Time: 0.74694
PPO Batch Consumption Time: 0.05988
Total Iteration Time: 2.83782

Cumulative Model Updates: 10,636
Cumulative Timesteps: 177,607,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 177607730...
Checkpoint 177607730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,183.06899
Policy Entropy: 0.37282
Value Function Loss: 2.48482

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.03043
Policy Update Magnitude: 0.02156
Value Function Update Magnitude: 0.02447

Collected Steps per Second: 17,640.37463
Overall Steps per Second: 13,218.22482

Timestep Collection Time: 2.83452
Timestep Consumption Time: 0.94829
PPO Batch Consumption Time: 0.08877
Total Iteration Time: 3.78281

Cumulative Model Updates: 10,639
Cumulative Timesteps: 177,657,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,949.23644
Policy Entropy: 0.36967
Value Function Loss: 2.51294

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03532
Policy Update Magnitude: 0.02443
Value Function Update Magnitude: 0.02592

Collected Steps per Second: 21,087.66183
Overall Steps per Second: 15,678.71229

Timestep Collection Time: 2.37305
Timestep Consumption Time: 0.81867
PPO Batch Consumption Time: 0.06844
Total Iteration Time: 3.19172

Cumulative Model Updates: 10,642
Cumulative Timesteps: 177,707,774

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 177707774...
Checkpoint 177707774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,936.13728
Policy Entropy: 0.37007
Value Function Loss: 2.52809

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.02083
Policy Update Magnitude: 0.02623
Value Function Update Magnitude: 0.02427

Collected Steps per Second: 18,027.74209
Overall Steps per Second: 13,946.49194

Timestep Collection Time: 2.77439
Timestep Consumption Time: 0.81189
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 3.58628

Cumulative Model Updates: 10,645
Cumulative Timesteps: 177,757,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,182.77261
Policy Entropy: 0.36871
Value Function Loss: 2.68979

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03396
Policy Update Magnitude: 0.02643
Value Function Update Magnitude: 0.02474

Collected Steps per Second: 19,053.39957
Overall Steps per Second: 13,944.45149

Timestep Collection Time: 2.62557
Timestep Consumption Time: 0.96195
PPO Batch Consumption Time: 0.09023
Total Iteration Time: 3.58752

Cumulative Model Updates: 10,648
Cumulative Timesteps: 177,807,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 177807816...
Checkpoint 177807816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,563.02184
Policy Entropy: 0.36787
Value Function Loss: 2.78642

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02886
Policy Update Magnitude: 0.02529
Value Function Update Magnitude: 0.03682

Collected Steps per Second: 20,655.55302
Overall Steps per Second: 14,788.92927

Timestep Collection Time: 2.42153
Timestep Consumption Time: 0.96060
PPO Batch Consumption Time: 0.11187
Total Iteration Time: 3.38212

Cumulative Model Updates: 10,651
Cumulative Timesteps: 177,857,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,336.42846
Policy Entropy: 0.37023
Value Function Loss: 2.69167

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05539
Policy Update Magnitude: 0.02652
Value Function Update Magnitude: 0.03252

Collected Steps per Second: 20,513.95103
Overall Steps per Second: 15,199.03348

Timestep Collection Time: 2.43863
Timestep Consumption Time: 0.85276
PPO Batch Consumption Time: 0.07183
Total Iteration Time: 3.29139

Cumulative Model Updates: 10,654
Cumulative Timesteps: 177,907,860

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 177907860...
Checkpoint 177907860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,774.56366
Policy Entropy: 0.37045
Value Function Loss: 2.58762

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03441
Policy Update Magnitude: 0.02635
Value Function Update Magnitude: 0.02785

Collected Steps per Second: 22,525.56725
Overall Steps per Second: 16,788.74615

Timestep Collection Time: 2.22139
Timestep Consumption Time: 0.75906
PPO Batch Consumption Time: 0.05854
Total Iteration Time: 2.98045

Cumulative Model Updates: 10,657
Cumulative Timesteps: 177,957,898

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,995.37204
Policy Entropy: 0.37336
Value Function Loss: 2.49524

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04157
Policy Update Magnitude: 0.02806
Value Function Update Magnitude: 0.03739

Collected Steps per Second: 24,060.61224
Overall Steps per Second: 17,579.48277

Timestep Collection Time: 2.07983
Timestep Consumption Time: 0.76678
PPO Batch Consumption Time: 0.06035
Total Iteration Time: 2.84661

Cumulative Model Updates: 10,660
Cumulative Timesteps: 178,007,940

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 178007940...
Checkpoint 178007940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,925.53339
Policy Entropy: 0.37206
Value Function Loss: 2.55069

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04352
Policy Update Magnitude: 0.02475
Value Function Update Magnitude: 0.04564

Collected Steps per Second: 20,663.77917
Overall Steps per Second: 15,458.39607

Timestep Collection Time: 2.41979
Timestep Consumption Time: 0.81483
PPO Batch Consumption Time: 0.08824
Total Iteration Time: 3.23462

Cumulative Model Updates: 10,663
Cumulative Timesteps: 178,057,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,840.53417
Policy Entropy: 0.37009
Value Function Loss: 2.69676

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03698
Policy Update Magnitude: 0.02509
Value Function Update Magnitude: 0.04097

Collected Steps per Second: 23,244.40418
Overall Steps per Second: 17,011.99447

Timestep Collection Time: 2.15217
Timestep Consumption Time: 0.78846
PPO Batch Consumption Time: 0.05990
Total Iteration Time: 2.94063

Cumulative Model Updates: 10,666
Cumulative Timesteps: 178,107,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 178107968...
Checkpoint 178107968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,652.51802
Policy Entropy: 0.36383
Value Function Loss: 2.83910

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.06079
Policy Update Magnitude: 0.02577
Value Function Update Magnitude: 0.04133

Collected Steps per Second: 21,114.95419
Overall Steps per Second: 14,825.12096

Timestep Collection Time: 2.36856
Timestep Consumption Time: 1.00490
PPO Batch Consumption Time: 0.12553
Total Iteration Time: 3.37346

Cumulative Model Updates: 10,669
Cumulative Timesteps: 178,157,980

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,856.20265
Policy Entropy: 0.36835
Value Function Loss: 2.70544

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03931
Policy Update Magnitude: 0.01956
Value Function Update Magnitude: 0.03360

Collected Steps per Second: 23,686.25961
Overall Steps per Second: 16,572.44267

Timestep Collection Time: 2.11211
Timestep Consumption Time: 0.90664
PPO Batch Consumption Time: 0.08773
Total Iteration Time: 3.01875

Cumulative Model Updates: 10,672
Cumulative Timesteps: 178,208,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 178208008...
Checkpoint 178208008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,599.70388
Policy Entropy: 0.36414
Value Function Loss: 2.69396

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03732
Policy Update Magnitude: 0.02412
Value Function Update Magnitude: 0.03510

Collected Steps per Second: 22,906.44491
Overall Steps per Second: 15,845.75640

Timestep Collection Time: 2.18358
Timestep Consumption Time: 0.97298
PPO Batch Consumption Time: 0.11963
Total Iteration Time: 3.15655

Cumulative Model Updates: 10,675
Cumulative Timesteps: 178,258,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,946.27278
Policy Entropy: 0.36738
Value Function Loss: 2.57025

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.01319
Policy Update Magnitude: 0.02723
Value Function Update Magnitude: 0.05809

Collected Steps per Second: 24,130.05279
Overall Steps per Second: 17,643.10208

Timestep Collection Time: 2.07302
Timestep Consumption Time: 0.76220
PPO Batch Consumption Time: 0.05984
Total Iteration Time: 2.83522

Cumulative Model Updates: 10,678
Cumulative Timesteps: 178,308,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 178308048...
Checkpoint 178308048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,458.99573
Policy Entropy: 0.35997
Value Function Loss: 2.63819

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03263
Policy Update Magnitude: 0.02574
Value Function Update Magnitude: 0.05948

Collected Steps per Second: 20,923.73728
Overall Steps per Second: 14,910.25945

Timestep Collection Time: 2.39068
Timestep Consumption Time: 0.96419
PPO Batch Consumption Time: 0.11880
Total Iteration Time: 3.35487

Cumulative Model Updates: 10,681
Cumulative Timesteps: 178,358,070

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,595.79816
Policy Entropy: 0.36260
Value Function Loss: 2.57619

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03347
Policy Update Magnitude: 0.02570
Value Function Update Magnitude: 0.05214

Collected Steps per Second: 23,111.98117
Overall Steps per Second: 17,340.23128

Timestep Collection Time: 2.16364
Timestep Consumption Time: 0.72017
PPO Batch Consumption Time: 0.06337
Total Iteration Time: 2.88381

Cumulative Model Updates: 10,684
Cumulative Timesteps: 178,408,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 178408076...
Checkpoint 178408076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,987.62063
Policy Entropy: 0.36268
Value Function Loss: 2.50089

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.03002
Policy Update Magnitude: 0.02089
Value Function Update Magnitude: 0.05942

Collected Steps per Second: 20,944.17626
Overall Steps per Second: 15,197.74894

Timestep Collection Time: 2.38816
Timestep Consumption Time: 0.90299
PPO Batch Consumption Time: 0.09916
Total Iteration Time: 3.29115

Cumulative Model Updates: 10,687
Cumulative Timesteps: 178,458,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,503.78114
Policy Entropy: 0.36261
Value Function Loss: 2.51975

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.03039
Policy Update Magnitude: 0.02397
Value Function Update Magnitude: 0.05339

Collected Steps per Second: 23,999.96047
Overall Steps per Second: 16,715.92405

Timestep Collection Time: 2.08442
Timestep Consumption Time: 0.90830
PPO Batch Consumption Time: 0.09354
Total Iteration Time: 2.99272

Cumulative Model Updates: 10,690
Cumulative Timesteps: 178,508,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 178508120...
Checkpoint 178508120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,932.57723
Policy Entropy: 0.36665
Value Function Loss: 2.47682

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04391
Policy Update Magnitude: 0.02299
Value Function Update Magnitude: 0.04370

Collected Steps per Second: 20,295.28577
Overall Steps per Second: 14,631.25087

Timestep Collection Time: 2.46382
Timestep Consumption Time: 0.95379
PPO Batch Consumption Time: 0.08415
Total Iteration Time: 3.41762

Cumulative Model Updates: 10,693
Cumulative Timesteps: 178,558,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,841.63010
Policy Entropy: 0.36467
Value Function Loss: 2.40291

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.04021
Policy Update Magnitude: 0.02356
Value Function Update Magnitude: 0.03520

Collected Steps per Second: 19,829.49960
Overall Steps per Second: 15,094.38198

Timestep Collection Time: 2.52250
Timestep Consumption Time: 0.79131
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 3.31382

Cumulative Model Updates: 10,696
Cumulative Timesteps: 178,608,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 178608144...
Checkpoint 178608144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,392.36871
Policy Entropy: 0.36332
Value Function Loss: 2.38935

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03647
Policy Update Magnitude: 0.02197
Value Function Update Magnitude: 0.03369

Collected Steps per Second: 19,747.59564
Overall Steps per Second: 14,405.14610

Timestep Collection Time: 2.53246
Timestep Consumption Time: 0.93922
PPO Batch Consumption Time: 0.08418
Total Iteration Time: 3.47168

Cumulative Model Updates: 10,699
Cumulative Timesteps: 178,658,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,785.75273
Policy Entropy: 0.36403
Value Function Loss: 2.49445

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03117
Policy Update Magnitude: 0.02004
Value Function Update Magnitude: 0.03167

Collected Steps per Second: 19,503.45317
Overall Steps per Second: 14,263.09283

Timestep Collection Time: 2.56437
Timestep Consumption Time: 0.94217
PPO Batch Consumption Time: 0.08232
Total Iteration Time: 3.50653

Cumulative Model Updates: 10,702
Cumulative Timesteps: 178,708,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 178708168...
Checkpoint 178708168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,862.95491
Policy Entropy: 0.35821
Value Function Loss: 2.59742

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01872
Policy Update Magnitude: 0.02416
Value Function Update Magnitude: 0.03148

Collected Steps per Second: 20,745.33957
Overall Steps per Second: 16,350.21463

Timestep Collection Time: 2.41047
Timestep Consumption Time: 0.64796
PPO Batch Consumption Time: 0.03227
Total Iteration Time: 3.05843

Cumulative Model Updates: 10,705
Cumulative Timesteps: 178,758,174

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,268.12894
Policy Entropy: 0.35736
Value Function Loss: 2.50826

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.02071
Policy Update Magnitude: 0.02505
Value Function Update Magnitude: 0.02658

Collected Steps per Second: 22,347.16444
Overall Steps per Second: 15,660.06347

Timestep Collection Time: 2.23823
Timestep Consumption Time: 0.95576
PPO Batch Consumption Time: 0.10767
Total Iteration Time: 3.19398

Cumulative Model Updates: 10,708
Cumulative Timesteps: 178,808,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 178808192...
Checkpoint 178808192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,542.48362
Policy Entropy: 0.35701
Value Function Loss: 2.53347

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03686
Policy Update Magnitude: 0.02731
Value Function Update Magnitude: 0.02627

Collected Steps per Second: 21,970.30280
Overall Steps per Second: 15,947.55881

Timestep Collection Time: 2.27662
Timestep Consumption Time: 0.85979
PPO Batch Consumption Time: 0.07718
Total Iteration Time: 3.13640

Cumulative Model Updates: 10,711
Cumulative Timesteps: 178,858,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,745.15860
Policy Entropy: 0.35665
Value Function Loss: 2.61829

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01937
Policy Update Magnitude: 0.02714
Value Function Update Magnitude: 0.02678

Collected Steps per Second: 20,301.17331
Overall Steps per Second: 14,858.74697

Timestep Collection Time: 2.46331
Timestep Consumption Time: 0.90225
PPO Batch Consumption Time: 0.09717
Total Iteration Time: 3.36556

Cumulative Model Updates: 10,714
Cumulative Timesteps: 178,908,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 178908218...
Checkpoint 178908218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,266.29189
Policy Entropy: 0.35677
Value Function Loss: 2.68237

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01433
Policy Update Magnitude: 0.02665
Value Function Update Magnitude: 0.02508

Collected Steps per Second: 23,169.35245
Overall Steps per Second: 16,996.99152

Timestep Collection Time: 2.15845
Timestep Consumption Time: 0.78383
PPO Batch Consumption Time: 0.05916
Total Iteration Time: 2.94229

Cumulative Model Updates: 10,717
Cumulative Timesteps: 178,958,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,682.73702
Policy Entropy: 0.35538
Value Function Loss: 2.58684

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.02824
Value Function Update Magnitude: 0.02704

Collected Steps per Second: 23,167.49409
Overall Steps per Second: 16,883.73197

Timestep Collection Time: 2.15975
Timestep Consumption Time: 0.80381
PPO Batch Consumption Time: 0.06373
Total Iteration Time: 2.96356

Cumulative Model Updates: 10,720
Cumulative Timesteps: 179,008,264

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 179008264...
Checkpoint 179008264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,636.79799
Policy Entropy: 0.35611
Value Function Loss: 2.58478

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.02037
Policy Update Magnitude: 0.02899
Value Function Update Magnitude: 0.02557

Collected Steps per Second: 20,767.81722
Overall Steps per Second: 15,052.66160

Timestep Collection Time: 2.40873
Timestep Consumption Time: 0.91454
PPO Batch Consumption Time: 0.12590
Total Iteration Time: 3.32327

Cumulative Model Updates: 10,723
Cumulative Timesteps: 179,058,288

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,370.72337
Policy Entropy: 0.35684
Value Function Loss: 2.52341

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02538
Policy Update Magnitude: 0.02673
Value Function Update Magnitude: 0.02734

Collected Steps per Second: 22,996.36926
Overall Steps per Second: 17,278.98271

Timestep Collection Time: 2.17504
Timestep Consumption Time: 0.71969
PPO Batch Consumption Time: 0.06292
Total Iteration Time: 2.89473

Cumulative Model Updates: 10,726
Cumulative Timesteps: 179,108,306

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 179108306...
Checkpoint 179108306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,441.13794
Policy Entropy: 0.36087
Value Function Loss: 2.49213

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02176
Policy Update Magnitude: 0.02894
Value Function Update Magnitude: 0.02433

Collected Steps per Second: 23,814.27494
Overall Steps per Second: 16,498.66883

Timestep Collection Time: 2.10025
Timestep Consumption Time: 0.93126
PPO Batch Consumption Time: 0.10712
Total Iteration Time: 3.03152

Cumulative Model Updates: 10,729
Cumulative Timesteps: 179,158,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,003.80331
Policy Entropy: 0.36543
Value Function Loss: 2.31992

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.04021
Policy Update Magnitude: 0.02756
Value Function Update Magnitude: 0.02204

Collected Steps per Second: 23,742.98952
Overall Steps per Second: 17,276.82140

Timestep Collection Time: 2.10715
Timestep Consumption Time: 0.78864
PPO Batch Consumption Time: 0.06469
Total Iteration Time: 2.89579

Cumulative Model Updates: 10,732
Cumulative Timesteps: 179,208,352

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 179208352...
Checkpoint 179208352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,536.41020
Policy Entropy: 0.36433
Value Function Loss: 2.31658

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05364
Policy Update Magnitude: 0.02481
Value Function Update Magnitude: 0.02394

Collected Steps per Second: 20,900.77408
Overall Steps per Second: 15,196.79300

Timestep Collection Time: 2.39417
Timestep Consumption Time: 0.89863
PPO Batch Consumption Time: 0.09642
Total Iteration Time: 3.29280

Cumulative Model Updates: 10,735
Cumulative Timesteps: 179,258,392

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,942.99523
Policy Entropy: 0.36226
Value Function Loss: 2.33923

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04585
Policy Update Magnitude: 0.02035
Value Function Update Magnitude: 0.02340

Collected Steps per Second: 20,988.45018
Overall Steps per Second: 15,367.87272

Timestep Collection Time: 2.38331
Timestep Consumption Time: 0.87166
PPO Batch Consumption Time: 0.06566
Total Iteration Time: 3.25497

Cumulative Model Updates: 10,738
Cumulative Timesteps: 179,308,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 179308414...
Checkpoint 179308414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,242.57048
Policy Entropy: 0.36049
Value Function Loss: 2.35688

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04430
Policy Update Magnitude: 0.01923
Value Function Update Magnitude: 0.02222

Collected Steps per Second: 19,640.37269
Overall Steps per Second: 15,073.08020

Timestep Collection Time: 2.54598
Timestep Consumption Time: 0.77146
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 3.31744

Cumulative Model Updates: 10,741
Cumulative Timesteps: 179,358,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,060.46127
Policy Entropy: 0.35862
Value Function Loss: 2.42199

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04235
Policy Update Magnitude: 0.01960
Value Function Update Magnitude: 0.02341

Collected Steps per Second: 19,937.90071
Overall Steps per Second: 15,696.72380

Timestep Collection Time: 2.50789
Timestep Consumption Time: 0.67762
PPO Batch Consumption Time: 0.02936
Total Iteration Time: 3.18551

Cumulative Model Updates: 10,744
Cumulative Timesteps: 179,408,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 179408420...
Checkpoint 179408420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,892.55803
Policy Entropy: 0.36395
Value Function Loss: 2.44022

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01425
Policy Update Magnitude: 0.02480
Value Function Update Magnitude: 0.02354

Collected Steps per Second: 22,764.82457
Overall Steps per Second: 16,421.67366

Timestep Collection Time: 2.19769
Timestep Consumption Time: 0.84889
PPO Batch Consumption Time: 0.08416
Total Iteration Time: 3.04658

Cumulative Model Updates: 10,747
Cumulative Timesteps: 179,458,450

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,415.05765
Policy Entropy: 0.36174
Value Function Loss: 2.49644

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01907
Policy Update Magnitude: 0.02851
Value Function Update Magnitude: 0.02519

Collected Steps per Second: 21,846.87353
Overall Steps per Second: 15,935.23109

Timestep Collection Time: 2.28985
Timestep Consumption Time: 0.84949
PPO Batch Consumption Time: 0.10369
Total Iteration Time: 3.13933

Cumulative Model Updates: 10,750
Cumulative Timesteps: 179,508,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 179508476...
Checkpoint 179508476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,301.90258
Policy Entropy: 0.36313
Value Function Loss: 2.44220

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01937
Policy Update Magnitude: 0.03164
Value Function Update Magnitude: 0.02378

Collected Steps per Second: 22,577.83022
Overall Steps per Second: 16,521.36249

Timestep Collection Time: 2.21651
Timestep Consumption Time: 0.81254
PPO Batch Consumption Time: 0.06253
Total Iteration Time: 3.02905

Cumulative Model Updates: 10,753
Cumulative Timesteps: 179,558,520

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,860.06198
Policy Entropy: 0.36084
Value Function Loss: 2.30091

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02948
Policy Update Magnitude: 0.03271
Value Function Update Magnitude: 0.02353

Collected Steps per Second: 19,766.56344
Overall Steps per Second: 15,311.23831

Timestep Collection Time: 2.53043
Timestep Consumption Time: 0.73632
PPO Batch Consumption Time: 0.02857
Total Iteration Time: 3.26675

Cumulative Model Updates: 10,756
Cumulative Timesteps: 179,608,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 179608538...
Checkpoint 179608538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,873.12759
Policy Entropy: 0.36742
Value Function Loss: 2.15359

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.03381
Value Function Update Magnitude: 0.02569

Collected Steps per Second: 22,649.73666
Overall Steps per Second: 17,191.76221

Timestep Collection Time: 2.20859
Timestep Consumption Time: 0.70117
PPO Batch Consumption Time: 0.02922
Total Iteration Time: 2.90977

Cumulative Model Updates: 10,759
Cumulative Timesteps: 179,658,562

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,586.64896
Policy Entropy: 0.35501
Value Function Loss: 2.35600

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.03205
Value Function Update Magnitude: 0.02653

Collected Steps per Second: 22,339.49175
Overall Steps per Second: 15,851.94019

Timestep Collection Time: 2.23855
Timestep Consumption Time: 0.91615
PPO Batch Consumption Time: 0.09153
Total Iteration Time: 3.15469

Cumulative Model Updates: 10,762
Cumulative Timesteps: 179,708,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 179708570...
Checkpoint 179708570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,869.35801
Policy Entropy: 0.35397
Value Function Loss: 2.40761

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04942
Policy Update Magnitude: 0.03075
Value Function Update Magnitude: 0.02388

Collected Steps per Second: 22,527.30424
Overall Steps per Second: 16,455.36369

Timestep Collection Time: 2.21988
Timestep Consumption Time: 0.81913
PPO Batch Consumption Time: 0.06130
Total Iteration Time: 3.03901

Cumulative Model Updates: 10,765
Cumulative Timesteps: 179,758,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,712.10631
Policy Entropy: 0.34548
Value Function Loss: 2.54879

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03846
Policy Update Magnitude: 0.02973
Value Function Update Magnitude: 0.04012

Collected Steps per Second: 19,829.19230
Overall Steps per Second: 14,190.28149

Timestep Collection Time: 2.52305
Timestep Consumption Time: 1.00260
PPO Batch Consumption Time: 0.11662
Total Iteration Time: 3.52565

Cumulative Model Updates: 10,768
Cumulative Timesteps: 179,808,608

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 179808608...
Checkpoint 179808608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,628.24938
Policy Entropy: 0.35628
Value Function Loss: 2.39814

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03457
Policy Update Magnitude: 0.02942
Value Function Update Magnitude: 0.04052

Collected Steps per Second: 22,545.27529
Overall Steps per Second: 16,918.01623

Timestep Collection Time: 2.21803
Timestep Consumption Time: 0.73776
PPO Batch Consumption Time: 0.06280
Total Iteration Time: 2.95578

Cumulative Model Updates: 10,771
Cumulative Timesteps: 179,858,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,947.74341
Policy Entropy: 0.35528
Value Function Loss: 2.37649

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.04306
Policy Update Magnitude: 0.02337
Value Function Update Magnitude: 0.03585

Collected Steps per Second: 21,974.86550
Overall Steps per Second: 16,693.81160

Timestep Collection Time: 2.27615
Timestep Consumption Time: 0.72005
PPO Batch Consumption Time: 0.05915
Total Iteration Time: 2.99620

Cumulative Model Updates: 10,774
Cumulative Timesteps: 179,908,632

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 179908632...
Checkpoint 179908632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,747.71463
Policy Entropy: 0.35911
Value Function Loss: 2.27927

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03453
Policy Update Magnitude: 0.02346
Value Function Update Magnitude: 0.04576

Collected Steps per Second: 19,239.22783
Overall Steps per Second: 14,594.69311

Timestep Collection Time: 2.59886
Timestep Consumption Time: 0.82705
PPO Batch Consumption Time: 0.08265
Total Iteration Time: 3.42590

Cumulative Model Updates: 10,777
Cumulative Timesteps: 179,958,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,254.84018
Policy Entropy: 0.35720
Value Function Loss: 2.35052

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03466
Policy Update Magnitude: 0.02198
Value Function Update Magnitude: 0.04150

Collected Steps per Second: 23,198.40994
Overall Steps per Second: 17,432.67680

Timestep Collection Time: 2.15644
Timestep Consumption Time: 0.71323
PPO Batch Consumption Time: 0.02964
Total Iteration Time: 2.86967

Cumulative Model Updates: 10,780
Cumulative Timesteps: 180,008,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 180008658...
Checkpoint 180008658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,692.77730
Policy Entropy: 0.35885
Value Function Loss: 2.36683

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03809
Policy Update Magnitude: 0.02249
Value Function Update Magnitude: 0.03855

Collected Steps per Second: 22,051.29894
Overall Steps per Second: 15,958.74744

Timestep Collection Time: 2.26835
Timestep Consumption Time: 0.86598
PPO Batch Consumption Time: 0.07788
Total Iteration Time: 3.13433

Cumulative Model Updates: 10,783
Cumulative Timesteps: 180,058,678

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,305.78763
Policy Entropy: 0.35692
Value Function Loss: 2.42306

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.02005
Policy Update Magnitude: 0.02515
Value Function Update Magnitude: 0.03786

Collected Steps per Second: 21,172.71874
Overall Steps per Second: 14,926.99733

Timestep Collection Time: 2.36276
Timestep Consumption Time: 0.98862
PPO Batch Consumption Time: 0.11737
Total Iteration Time: 3.35138

Cumulative Model Updates: 10,786
Cumulative Timesteps: 180,108,704

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 180108704...
Checkpoint 180108704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,738.23916
Policy Entropy: 0.35959
Value Function Loss: 2.31276

Mean KL Divergence: 0.00101
SB3 Clip Fraction: 0.01066
Policy Update Magnitude: 0.02698
Value Function Update Magnitude: 0.04478

Collected Steps per Second: 22,574.88925
Overall Steps per Second: 16,504.19726

Timestep Collection Time: 2.21618
Timestep Consumption Time: 0.81517
PPO Batch Consumption Time: 0.06289
Total Iteration Time: 3.03135

Cumulative Model Updates: 10,789
Cumulative Timesteps: 180,158,734

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,778.99293
Policy Entropy: 0.36226
Value Function Loss: 2.26501

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.01155
Policy Update Magnitude: 0.03014
Value Function Update Magnitude: 0.05282

Collected Steps per Second: 20,140.69413
Overall Steps per Second: 15,674.68654

Timestep Collection Time: 2.48343
Timestep Consumption Time: 0.70758
PPO Batch Consumption Time: 0.02915
Total Iteration Time: 3.19100

Cumulative Model Updates: 10,792
Cumulative Timesteps: 180,208,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 180208752...
Checkpoint 180208752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,058.06221
Policy Entropy: 0.36460
Value Function Loss: 2.28308

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01747
Policy Update Magnitude: 0.03051
Value Function Update Magnitude: 0.06330

Collected Steps per Second: 22,622.08128
Overall Steps per Second: 17,271.12437

Timestep Collection Time: 2.21138
Timestep Consumption Time: 0.68513
PPO Batch Consumption Time: 0.02928
Total Iteration Time: 2.89651

Cumulative Model Updates: 10,795
Cumulative Timesteps: 180,258,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,780.51136
Policy Entropy: 0.36169
Value Function Loss: 2.21534

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01843
Policy Update Magnitude: 0.02911
Value Function Update Magnitude: 0.06185

Collected Steps per Second: 21,336.57285
Overall Steps per Second: 15,442.01844

Timestep Collection Time: 2.34405
Timestep Consumption Time: 0.89477
PPO Batch Consumption Time: 0.09343
Total Iteration Time: 3.23883

Cumulative Model Updates: 10,798
Cumulative Timesteps: 180,308,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 180308792...
Checkpoint 180308792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,030.04381
Policy Entropy: 0.36514
Value Function Loss: 2.20239

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01829
Policy Update Magnitude: 0.03130
Value Function Update Magnitude: 0.05604

Collected Steps per Second: 21,307.26151
Overall Steps per Second: 16,737.14107

Timestep Collection Time: 2.34699
Timestep Consumption Time: 0.64085
PPO Batch Consumption Time: 0.03254
Total Iteration Time: 2.98785

Cumulative Model Updates: 10,801
Cumulative Timesteps: 180,358,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,959.74216
Policy Entropy: 0.36619
Value Function Loss: 2.16645

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.02724
Value Function Update Magnitude: 0.07147

Collected Steps per Second: 20,047.19060
Overall Steps per Second: 15,474.76448

Timestep Collection Time: 2.49541
Timestep Consumption Time: 0.73734
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 3.23275

Cumulative Model Updates: 10,804
Cumulative Timesteps: 180,408,826

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 180408826...
Checkpoint 180408826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,266.59735
Policy Entropy: 0.36339
Value Function Loss: 2.24133

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.04046
Policy Update Magnitude: 0.02480
Value Function Update Magnitude: 0.07130

Collected Steps per Second: 18,812.33462
Overall Steps per Second: 14,027.48140

Timestep Collection Time: 2.65804
Timestep Consumption Time: 0.90667
PPO Batch Consumption Time: 0.08845
Total Iteration Time: 3.56472

Cumulative Model Updates: 10,807
Cumulative Timesteps: 180,458,830

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,530.20994
Policy Entropy: 0.36676
Value Function Loss: 2.30289

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02999
Policy Update Magnitude: 0.02494
Value Function Update Magnitude: 0.06739

Collected Steps per Second: 23,619.41738
Overall Steps per Second: 17,114.79093

Timestep Collection Time: 2.11741
Timestep Consumption Time: 0.80474
PPO Batch Consumption Time: 0.06047
Total Iteration Time: 2.92215

Cumulative Model Updates: 10,810
Cumulative Timesteps: 180,508,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 180508842...
Checkpoint 180508842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,338.60997
Policy Entropy: 0.36791
Value Function Loss: 2.24969

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02435
Policy Update Magnitude: 0.02580
Value Function Update Magnitude: 0.06101

Collected Steps per Second: 22,656.14074
Overall Steps per Second: 17,284.10713

Timestep Collection Time: 2.20726
Timestep Consumption Time: 0.68603
PPO Batch Consumption Time: 0.02844
Total Iteration Time: 2.89329

Cumulative Model Updates: 10,813
Cumulative Timesteps: 180,558,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,732.67743
Policy Entropy: 0.37106
Value Function Loss: 2.24184

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03880
Policy Update Magnitude: 0.02618
Value Function Update Magnitude: 0.05070

Collected Steps per Second: 21,299.34431
Overall Steps per Second: 15,709.91696

Timestep Collection Time: 2.34852
Timestep Consumption Time: 0.83558
PPO Batch Consumption Time: 0.06120
Total Iteration Time: 3.18410

Cumulative Model Updates: 10,816
Cumulative Timesteps: 180,608,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 180608872...
Checkpoint 180608872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,693.65180
Policy Entropy: 0.37128
Value Function Loss: 2.25899

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02872
Policy Update Magnitude: 0.02459
Value Function Update Magnitude: 0.04431

Collected Steps per Second: 17,627.05570
Overall Steps per Second: 12,798.23817

Timestep Collection Time: 2.83712
Timestep Consumption Time: 1.07045
PPO Batch Consumption Time: 0.13015
Total Iteration Time: 3.90757

Cumulative Model Updates: 10,819
Cumulative Timesteps: 180,658,882

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,562.48281
Policy Entropy: 0.36614
Value Function Loss: 2.39428

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02749
Policy Update Magnitude: 0.02607
Value Function Update Magnitude: 0.04083

Collected Steps per Second: 20,087.99964
Overall Steps per Second: 15,410.12928

Timestep Collection Time: 2.49044
Timestep Consumption Time: 0.75599
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 3.24644

Cumulative Model Updates: 10,822
Cumulative Timesteps: 180,708,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 180708910...
Checkpoint 180708910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,839.86872
Policy Entropy: 0.36686
Value Function Loss: 2.39369

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.03090
Policy Update Magnitude: 0.02373
Value Function Update Magnitude: 0.05185

Collected Steps per Second: 20,811.94807
Overall Steps per Second: 15,093.72564

Timestep Collection Time: 2.40343
Timestep Consumption Time: 0.91053
PPO Batch Consumption Time: 0.12419
Total Iteration Time: 3.31396

Cumulative Model Updates: 10,825
Cumulative Timesteps: 180,758,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,381.61093
Policy Entropy: 0.37118
Value Function Loss: 2.26254

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.04030
Policy Update Magnitude: 0.02349
Value Function Update Magnitude: 0.04562

Collected Steps per Second: 23,811.16253
Overall Steps per Second: 17,827.46220

Timestep Collection Time: 2.10095
Timestep Consumption Time: 0.70517
PPO Batch Consumption Time: 0.05962
Total Iteration Time: 2.80612

Cumulative Model Updates: 10,828
Cumulative Timesteps: 180,808,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 180808956...
Checkpoint 180808956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,532.83552
Policy Entropy: 0.37540
Value Function Loss: 2.16924

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.05115
Policy Update Magnitude: 0.02186
Value Function Update Magnitude: 0.05325

Collected Steps per Second: 21,351.85182
Overall Steps per Second: 15,639.19045

Timestep Collection Time: 2.34190
Timestep Consumption Time: 0.85545
PPO Batch Consumption Time: 0.08127
Total Iteration Time: 3.19735

Cumulative Model Updates: 10,831
Cumulative Timesteps: 180,858,960

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,197.95950
Policy Entropy: 0.37800
Value Function Loss: 2.12473

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.02511
Policy Update Magnitude: 0.01810
Value Function Update Magnitude: 0.04797

Collected Steps per Second: 23,447.11383
Overall Steps per Second: 17,136.60910

Timestep Collection Time: 2.13348
Timestep Consumption Time: 0.78565
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 2.91913

Cumulative Model Updates: 10,834
Cumulative Timesteps: 180,908,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 180908984...
Checkpoint 180908984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,662.20020
Policy Entropy: 0.37371
Value Function Loss: 2.28663

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03057
Policy Update Magnitude: 0.02381
Value Function Update Magnitude: 0.04252

Collected Steps per Second: 22,943.22511
Overall Steps per Second: 16,404.09036

Timestep Collection Time: 2.17982
Timestep Consumption Time: 0.86894
PPO Batch Consumption Time: 0.08631
Total Iteration Time: 3.04875

Cumulative Model Updates: 10,837
Cumulative Timesteps: 180,958,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,000.15058
Policy Entropy: 0.37687
Value Function Loss: 2.30442

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03296
Policy Update Magnitude: 0.02259
Value Function Update Magnitude: 0.03511

Collected Steps per Second: 24,131.35959
Overall Steps per Second: 17,570.27566

Timestep Collection Time: 2.07266
Timestep Consumption Time: 0.77397
PPO Batch Consumption Time: 0.06396
Total Iteration Time: 2.84663

Cumulative Model Updates: 10,840
Cumulative Timesteps: 181,009,012

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 181009012...
Checkpoint 181009012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,913.36562
Policy Entropy: 0.37474
Value Function Loss: 2.29414

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03921
Policy Update Magnitude: 0.02458
Value Function Update Magnitude: 0.02826

Collected Steps per Second: 19,235.38832
Overall Steps per Second: 14,898.66628

Timestep Collection Time: 2.60042
Timestep Consumption Time: 0.75693
PPO Batch Consumption Time: 0.02963
Total Iteration Time: 3.35735

Cumulative Model Updates: 10,843
Cumulative Timesteps: 181,059,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,940.96852
Policy Entropy: 0.36931
Value Function Loss: 2.30697

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02329
Policy Update Magnitude: 0.02441
Value Function Update Magnitude: 0.03381

Collected Steps per Second: 21,341.51624
Overall Steps per Second: 16,887.01769

Timestep Collection Time: 2.34323
Timestep Consumption Time: 0.61810
PPO Batch Consumption Time: 0.02868
Total Iteration Time: 2.96133

Cumulative Model Updates: 10,846
Cumulative Timesteps: 181,109,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 181109040...
Checkpoint 181109040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,342.62574
Policy Entropy: 0.36995
Value Function Loss: 2.22872

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.04173
Policy Update Magnitude: 0.01969
Value Function Update Magnitude: 0.02906

Collected Steps per Second: 21,352.96983
Overall Steps per Second: 15,722.53347

Timestep Collection Time: 2.34225
Timestep Consumption Time: 0.83879
PPO Batch Consumption Time: 0.09797
Total Iteration Time: 3.18104

Cumulative Model Updates: 10,849
Cumulative Timesteps: 181,159,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,845.14543
Policy Entropy: 0.36945
Value Function Loss: 2.22904

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01573
Policy Update Magnitude: 0.02390
Value Function Update Magnitude: 0.02563

Collected Steps per Second: 24,308.44964
Overall Steps per Second: 18,220.70217

Timestep Collection Time: 2.05772
Timestep Consumption Time: 0.68751
PPO Batch Consumption Time: 0.02893
Total Iteration Time: 2.74523

Cumulative Model Updates: 10,852
Cumulative Timesteps: 181,209,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 181209074...
Checkpoint 181209074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,610.29722
Policy Entropy: 0.37026
Value Function Loss: 2.18293

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03288
Policy Update Magnitude: 0.02623
Value Function Update Magnitude: 0.02904

Collected Steps per Second: 23,040.36232
Overall Steps per Second: 17,117.63737

Timestep Collection Time: 2.17089
Timestep Consumption Time: 0.75113
PPO Batch Consumption Time: 0.02989
Total Iteration Time: 2.92202

Cumulative Model Updates: 10,855
Cumulative Timesteps: 181,259,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,465.94125
Policy Entropy: 0.37177
Value Function Loss: 2.23282

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.04013
Policy Update Magnitude: 0.02367
Value Function Update Magnitude: 0.02745

Collected Steps per Second: 22,527.20987
Overall Steps per Second: 16,523.61761

Timestep Collection Time: 2.21989
Timestep Consumption Time: 0.80656
PPO Batch Consumption Time: 0.04240
Total Iteration Time: 3.02646

Cumulative Model Updates: 10,858
Cumulative Timesteps: 181,309,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 181309100...
Checkpoint 181309100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,170.75744
Policy Entropy: 0.36850
Value Function Loss: 2.16892

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03852
Policy Update Magnitude: 0.02368
Value Function Update Magnitude: 0.02730

Collected Steps per Second: 21,557.40204
Overall Steps per Second: 15,451.32533

Timestep Collection Time: 2.31995
Timestep Consumption Time: 0.91680
PPO Batch Consumption Time: 0.08072
Total Iteration Time: 3.23674

Cumulative Model Updates: 10,861
Cumulative Timesteps: 181,359,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,859.16359
Policy Entropy: 0.36968
Value Function Loss: 2.19054

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.04041
Policy Update Magnitude: 0.01931
Value Function Update Magnitude: 0.02472

Collected Steps per Second: 22,165.32406
Overall Steps per Second: 15,634.43183

Timestep Collection Time: 2.25686
Timestep Consumption Time: 0.94275
PPO Batch Consumption Time: 0.10883
Total Iteration Time: 3.19960

Cumulative Model Updates: 10,864
Cumulative Timesteps: 181,409,136

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 181409136...
Checkpoint 181409136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,736.69011
Policy Entropy: 0.37406
Value Function Loss: 2.17026

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03223
Policy Update Magnitude: 0.02098
Value Function Update Magnitude: 0.02358

Collected Steps per Second: 24,042.39397
Overall Steps per Second: 17,433.81420

Timestep Collection Time: 2.08082
Timestep Consumption Time: 0.78877
PPO Batch Consumption Time: 0.06102
Total Iteration Time: 2.86960

Cumulative Model Updates: 10,867
Cumulative Timesteps: 181,459,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,194.95822
Policy Entropy: 0.37238
Value Function Loss: 2.18698

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05303
Policy Update Magnitude: 0.02257
Value Function Update Magnitude: 0.02220

Collected Steps per Second: 21,223.55595
Overall Steps per Second: 15,125.83889

Timestep Collection Time: 2.35672
Timestep Consumption Time: 0.95007
PPO Batch Consumption Time: 0.12088
Total Iteration Time: 3.30679

Cumulative Model Updates: 10,870
Cumulative Timesteps: 181,509,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 181509182...
Checkpoint 181509182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,769.65067
Policy Entropy: 0.37268
Value Function Loss: 2.14871

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04407
Policy Update Magnitude: 0.02069
Value Function Update Magnitude: 0.02328

Collected Steps per Second: 23,792.81820
Overall Steps per Second: 17,386.01002

Timestep Collection Time: 2.10223
Timestep Consumption Time: 0.77468
PPO Batch Consumption Time: 0.06298
Total Iteration Time: 2.87691

Cumulative Model Updates: 10,873
Cumulative Timesteps: 181,559,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,565.24357
Policy Entropy: 0.37017
Value Function Loss: 2.15301

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04003
Policy Update Magnitude: 0.01963
Value Function Update Magnitude: 0.02509

Collected Steps per Second: 20,608.86656
Overall Steps per Second: 15,160.73922

Timestep Collection Time: 2.42653
Timestep Consumption Time: 0.87199
PPO Batch Consumption Time: 0.11559
Total Iteration Time: 3.29852

Cumulative Model Updates: 10,876
Cumulative Timesteps: 181,609,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 181609208...
Checkpoint 181609208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,869.22901
Policy Entropy: 0.36920
Value Function Loss: 2.22559

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.03114
Policy Update Magnitude: 0.02190
Value Function Update Magnitude: 0.02461

Collected Steps per Second: 23,486.43509
Overall Steps per Second: 16,763.70934

Timestep Collection Time: 2.12991
Timestep Consumption Time: 0.85415
PPO Batch Consumption Time: 0.10377
Total Iteration Time: 2.98407

Cumulative Model Updates: 10,879
Cumulative Timesteps: 181,659,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,546.59902
Policy Entropy: 0.37020
Value Function Loss: 2.31676

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03491
Policy Update Magnitude: 0.02049
Value Function Update Magnitude: 0.02608

Collected Steps per Second: 24,536.66336
Overall Steps per Second: 16,722.13355

Timestep Collection Time: 2.03866
Timestep Consumption Time: 0.95270
PPO Batch Consumption Time: 0.11532
Total Iteration Time: 2.99136

Cumulative Model Updates: 10,882
Cumulative Timesteps: 181,709,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 181709254...
Checkpoint 181709254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,028.70578
Policy Entropy: 0.37204
Value Function Loss: 2.28222

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02641
Policy Update Magnitude: 0.01835
Value Function Update Magnitude: 0.02478

Collected Steps per Second: 24,388.72445
Overall Steps per Second: 16,754.00020

Timestep Collection Time: 2.05144
Timestep Consumption Time: 0.93483
PPO Batch Consumption Time: 0.10941
Total Iteration Time: 2.98627

Cumulative Model Updates: 10,885
Cumulative Timesteps: 181,759,286

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,879.28306
Policy Entropy: 0.37566
Value Function Loss: 2.19713

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02599
Policy Update Magnitude: 0.02199
Value Function Update Magnitude: 0.02604

Collected Steps per Second: 24,145.42767
Overall Steps per Second: 16,677.60853

Timestep Collection Time: 2.07095
Timestep Consumption Time: 0.92732
PPO Batch Consumption Time: 0.10308
Total Iteration Time: 2.99827

Cumulative Model Updates: 10,888
Cumulative Timesteps: 181,809,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 181809290...
Checkpoint 181809290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,380.44447
Policy Entropy: 0.37183
Value Function Loss: 2.23415

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.03205
Policy Update Magnitude: 0.02087
Value Function Update Magnitude: 0.02322

Collected Steps per Second: 22,629.08485
Overall Steps per Second: 15,737.36084

Timestep Collection Time: 2.21016
Timestep Consumption Time: 0.96788
PPO Batch Consumption Time: 0.11477
Total Iteration Time: 3.17804

Cumulative Model Updates: 10,891
Cumulative Timesteps: 181,859,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,304.65977
Policy Entropy: 0.37300
Value Function Loss: 2.19629

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03699
Policy Update Magnitude: 0.02439
Value Function Update Magnitude: 0.02311

Collected Steps per Second: 24,125.69081
Overall Steps per Second: 17,214.80856

Timestep Collection Time: 2.07405
Timestep Consumption Time: 0.83263
PPO Batch Consumption Time: 0.07294
Total Iteration Time: 2.90668

Cumulative Model Updates: 10,894
Cumulative Timesteps: 181,909,342

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 181909342...
Checkpoint 181909342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,047.73785
Policy Entropy: 0.36837
Value Function Loss: 2.14306

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.02342
Policy Update Magnitude: 0.02537
Value Function Update Magnitude: 0.02352

Collected Steps per Second: 22,051.76350
Overall Steps per Second: 15,217.00275

Timestep Collection Time: 2.26857
Timestep Consumption Time: 1.01894
PPO Batch Consumption Time: 0.13086
Total Iteration Time: 3.28751

Cumulative Model Updates: 10,897
Cumulative Timesteps: 181,959,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,439.50090
Policy Entropy: 0.36761
Value Function Loss: 2.17075

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.03156
Policy Update Magnitude: 0.02391
Value Function Update Magnitude: 0.02289

Collected Steps per Second: 24,427.34106
Overall Steps per Second: 17,959.82350

Timestep Collection Time: 2.04795
Timestep Consumption Time: 0.73749
PPO Batch Consumption Time: 0.05787
Total Iteration Time: 2.78544

Cumulative Model Updates: 10,900
Cumulative Timesteps: 182,009,394

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 182009394...
Checkpoint 182009394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,731.66657
Policy Entropy: 0.36981
Value Function Loss: 2.26970

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.04138
Policy Update Magnitude: 0.02090
Value Function Update Magnitude: 0.02413

Collected Steps per Second: 17,337.52750
Overall Steps per Second: 13,210.29016

Timestep Collection Time: 2.88461
Timestep Consumption Time: 0.90123
PPO Batch Consumption Time: 0.10936
Total Iteration Time: 3.78584

Cumulative Model Updates: 10,903
Cumulative Timesteps: 182,059,406

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,900.83182
Policy Entropy: 0.36911
Value Function Loss: 2.37273

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.03073
Policy Update Magnitude: 0.02414
Value Function Update Magnitude: 0.02439

Collected Steps per Second: 20,494.23347
Overall Steps per Second: 15,202.04310

Timestep Collection Time: 2.44196
Timestep Consumption Time: 0.85010
PPO Batch Consumption Time: 0.06024
Total Iteration Time: 3.29206

Cumulative Model Updates: 10,906
Cumulative Timesteps: 182,109,452

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 182109452...
Checkpoint 182109452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,151.07993
Policy Entropy: 0.37074
Value Function Loss: 2.21278

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03904
Policy Update Magnitude: 0.02252
Value Function Update Magnitude: 0.02073

Collected Steps per Second: 20,837.13505
Overall Steps per Second: 15,201.30668

Timestep Collection Time: 2.40023
Timestep Consumption Time: 0.88988
PPO Batch Consumption Time: 0.08399
Total Iteration Time: 3.29011

Cumulative Model Updates: 10,909
Cumulative Timesteps: 182,159,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,201.39133
Policy Entropy: 0.36809
Value Function Loss: 2.19613

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.04305
Policy Update Magnitude: 0.02033
Value Function Update Magnitude: 0.02194

Collected Steps per Second: 22,290.13244
Overall Steps per Second: 16,309.37397

Timestep Collection Time: 2.24440
Timestep Consumption Time: 0.82304
PPO Batch Consumption Time: 0.06523
Total Iteration Time: 3.06744

Cumulative Model Updates: 10,912
Cumulative Timesteps: 182,209,494

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 182209494...
Checkpoint 182209494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,705.88484
Policy Entropy: 0.36713
Value Function Loss: 2.12024

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.03017
Policy Update Magnitude: 0.02046
Value Function Update Magnitude: 0.02068

Collected Steps per Second: 20,699.03452
Overall Steps per Second: 15,716.74940

Timestep Collection Time: 2.41683
Timestep Consumption Time: 0.76615
PPO Batch Consumption Time: 0.03084
Total Iteration Time: 3.18297

Cumulative Model Updates: 10,915
Cumulative Timesteps: 182,259,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,273.47835
Policy Entropy: 0.36544
Value Function Loss: 2.17158

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.05037
Policy Update Magnitude: 0.02145
Value Function Update Magnitude: 0.02252

Collected Steps per Second: 20,655.24865
Overall Steps per Second: 15,445.90857

Timestep Collection Time: 2.42127
Timestep Consumption Time: 0.81661
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 3.23788

Cumulative Model Updates: 10,918
Cumulative Timesteps: 182,309,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 182309532...
Checkpoint 182309532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,078.70006
Policy Entropy: 0.37262
Value Function Loss: 2.04098

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.02100
Value Function Update Magnitude: 0.02082

Collected Steps per Second: 21,324.41015
Overall Steps per Second: 15,774.01107

Timestep Collection Time: 2.34595
Timestep Consumption Time: 0.82547
PPO Batch Consumption Time: 0.06664
Total Iteration Time: 3.17142

Cumulative Model Updates: 10,921
Cumulative Timesteps: 182,359,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,961.32853
Policy Entropy: 0.36615
Value Function Loss: 2.05826

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.05094
Policy Update Magnitude: 0.02110
Value Function Update Magnitude: 0.02061

Collected Steps per Second: 20,476.17570
Overall Steps per Second: 15,313.86675

Timestep Collection Time: 2.44235
Timestep Consumption Time: 0.82332
PPO Batch Consumption Time: 0.04457
Total Iteration Time: 3.26567

Cumulative Model Updates: 10,924
Cumulative Timesteps: 182,409,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 182409568...
Checkpoint 182409568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,419.63434
Policy Entropy: 0.36993
Value Function Loss: 1.95483

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03238
Policy Update Magnitude: 0.02114
Value Function Update Magnitude: 0.01987

Collected Steps per Second: 21,141.51055
Overall Steps per Second: 16,420.87764

Timestep Collection Time: 2.36606
Timestep Consumption Time: 0.68019
PPO Batch Consumption Time: 0.02969
Total Iteration Time: 3.04624

Cumulative Model Updates: 10,927
Cumulative Timesteps: 182,459,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,849.10885
Policy Entropy: 0.36705
Value Function Loss: 2.15156

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03505
Policy Update Magnitude: 0.01914
Value Function Update Magnitude: 0.02228

Collected Steps per Second: 22,474.08528
Overall Steps per Second: 17,586.75919

Timestep Collection Time: 2.22532
Timestep Consumption Time: 0.61841
PPO Batch Consumption Time: 0.02987
Total Iteration Time: 2.84373

Cumulative Model Updates: 10,930
Cumulative Timesteps: 182,509,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 182509602...
Checkpoint 182509602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,675.18590
Policy Entropy: 0.36700
Value Function Loss: 2.16928

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01981
Policy Update Magnitude: 0.01951
Value Function Update Magnitude: 0.02019

Collected Steps per Second: 22,451.36529
Overall Steps per Second: 16,531.37579

Timestep Collection Time: 2.22730
Timestep Consumption Time: 0.79761
PPO Batch Consumption Time: 0.08380
Total Iteration Time: 3.02491

Cumulative Model Updates: 10,933
Cumulative Timesteps: 182,559,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,753.35114
Policy Entropy: 0.36771
Value Function Loss: 2.12370

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01522
Policy Update Magnitude: 0.02267
Value Function Update Magnitude: 0.01980

Collected Steps per Second: 22,808.89874
Overall Steps per Second: 17,251.19469

Timestep Collection Time: 2.19318
Timestep Consumption Time: 0.70656
PPO Batch Consumption Time: 0.02928
Total Iteration Time: 2.89974

Cumulative Model Updates: 10,936
Cumulative Timesteps: 182,609,632

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 182609632...
Checkpoint 182609632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,659.94806
Policy Entropy: 0.37117
Value Function Loss: 2.02863

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.02147
Policy Update Magnitude: 0.02457
Value Function Update Magnitude: 0.02438

Collected Steps per Second: 22,788.35037
Overall Steps per Second: 16,003.82679

Timestep Collection Time: 2.19516
Timestep Consumption Time: 0.93060
PPO Batch Consumption Time: 0.09256
Total Iteration Time: 3.12575

Cumulative Model Updates: 10,939
Cumulative Timesteps: 182,659,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,217.74351
Policy Entropy: 0.37216
Value Function Loss: 1.97811

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.02348
Value Function Update Magnitude: 0.02243

Collected Steps per Second: 22,962.57627
Overall Steps per Second: 16,733.31539

Timestep Collection Time: 2.17859
Timestep Consumption Time: 0.81102
PPO Batch Consumption Time: 0.05913
Total Iteration Time: 2.98960

Cumulative Model Updates: 10,942
Cumulative Timesteps: 182,709,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 182709682...
Checkpoint 182709682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,001.35674
Policy Entropy: 0.36490
Value Function Loss: 2.05504

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03393
Policy Update Magnitude: 0.02355
Value Function Update Magnitude: 0.02419

Collected Steps per Second: 22,308.57191
Overall Steps per Second: 17,023.60488

Timestep Collection Time: 2.24210
Timestep Consumption Time: 0.69606
PPO Batch Consumption Time: 0.02922
Total Iteration Time: 2.93816

Cumulative Model Updates: 10,945
Cumulative Timesteps: 182,759,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,826.71227
Policy Entropy: 0.36938
Value Function Loss: 2.03051

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03815
Policy Update Magnitude: 0.02071
Value Function Update Magnitude: 0.02239

Collected Steps per Second: 22,074.57114
Overall Steps per Second: 15,455.18953

Timestep Collection Time: 2.26659
Timestep Consumption Time: 0.97077
PPO Batch Consumption Time: 0.10506
Total Iteration Time: 3.23736

Cumulative Model Updates: 10,948
Cumulative Timesteps: 182,809,734

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 182809734...
Checkpoint 182809734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,434.42256
Policy Entropy: 0.37031
Value Function Loss: 1.99051

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.03330
Policy Update Magnitude: 0.01822
Value Function Update Magnitude: 0.02197

Collected Steps per Second: 22,817.25422
Overall Steps per Second: 17,216.84410

Timestep Collection Time: 2.19159
Timestep Consumption Time: 0.71289
PPO Batch Consumption Time: 0.02911
Total Iteration Time: 2.90448

Cumulative Model Updates: 10,951
Cumulative Timesteps: 182,859,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,075.58767
Policy Entropy: 0.37438
Value Function Loss: 1.96594

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02985
Policy Update Magnitude: 0.02160
Value Function Update Magnitude: 0.02376

Collected Steps per Second: 20,842.15887
Overall Steps per Second: 14,987.83590

Timestep Collection Time: 2.40023
Timestep Consumption Time: 0.93754
PPO Batch Consumption Time: 0.09094
Total Iteration Time: 3.33777

Cumulative Model Updates: 10,954
Cumulative Timesteps: 182,909,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 182909766...
Checkpoint 182909766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,469.85618
Policy Entropy: 0.36903
Value Function Loss: 2.06355

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.04072
Policy Update Magnitude: 0.01996
Value Function Update Magnitude: 0.02446

Collected Steps per Second: 22,692.89025
Overall Steps per Second: 17,301.92936

Timestep Collection Time: 2.20369
Timestep Consumption Time: 0.68663
PPO Batch Consumption Time: 0.03085
Total Iteration Time: 2.89031

Cumulative Model Updates: 10,957
Cumulative Timesteps: 182,959,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,545.34478
Policy Entropy: 0.36578
Value Function Loss: 2.09903

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03520
Policy Update Magnitude: 0.01963
Value Function Update Magnitude: 0.02371

Collected Steps per Second: 22,897.05357
Overall Steps per Second: 17,428.71264

Timestep Collection Time: 2.18465
Timestep Consumption Time: 0.68544
PPO Batch Consumption Time: 0.02959
Total Iteration Time: 2.87009

Cumulative Model Updates: 10,960
Cumulative Timesteps: 183,009,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 183009796...
Checkpoint 183009796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,322.19838
Policy Entropy: 0.36526
Value Function Loss: 2.11669

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03313
Policy Update Magnitude: 0.01937
Value Function Update Magnitude: 0.02206

Collected Steps per Second: 21,873.88878
Overall Steps per Second: 15,981.66334

Timestep Collection Time: 2.28775
Timestep Consumption Time: 0.84346
PPO Batch Consumption Time: 0.09015
Total Iteration Time: 3.13121

Cumulative Model Updates: 10,963
Cumulative Timesteps: 183,059,838

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,296.79945
Policy Entropy: 0.36951
Value Function Loss: 2.01087

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.02097
Policy Update Magnitude: 0.02244
Value Function Update Magnitude: 0.02284

Collected Steps per Second: 22,453.53401
Overall Steps per Second: 16,424.82572

Timestep Collection Time: 2.22798
Timestep Consumption Time: 0.81778
PPO Batch Consumption Time: 0.08106
Total Iteration Time: 3.04576

Cumulative Model Updates: 10,966
Cumulative Timesteps: 183,109,864

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 183109864...
Checkpoint 183109864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,205.40305
Policy Entropy: 0.36491
Value Function Loss: 2.07121

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03995
Policy Update Magnitude: 0.02594
Value Function Update Magnitude: 0.02190

Collected Steps per Second: 21,833.13359
Overall Steps per Second: 15,159.88518

Timestep Collection Time: 2.29275
Timestep Consumption Time: 1.00925
PPO Batch Consumption Time: 0.12036
Total Iteration Time: 3.30200

Cumulative Model Updates: 10,969
Cumulative Timesteps: 183,159,922

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,664.73008
Policy Entropy: 0.36400
Value Function Loss: 2.12307

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04534
Policy Update Magnitude: 0.02471
Value Function Update Magnitude: 0.02131

Collected Steps per Second: 22,866.77900
Overall Steps per Second: 16,690.18927

Timestep Collection Time: 2.18772
Timestep Consumption Time: 0.80961
PPO Batch Consumption Time: 0.06161
Total Iteration Time: 2.99733

Cumulative Model Updates: 10,972
Cumulative Timesteps: 183,209,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 183209948...
Checkpoint 183209948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,094.99131
Policy Entropy: 0.36191
Value Function Loss: 2.08269

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05554
Policy Update Magnitude: 0.02136
Value Function Update Magnitude: 0.02507

Collected Steps per Second: 20,270.58252
Overall Steps per Second: 14,677.80466

Timestep Collection Time: 2.46683
Timestep Consumption Time: 0.93995
PPO Batch Consumption Time: 0.09065
Total Iteration Time: 3.40678

Cumulative Model Updates: 10,975
Cumulative Timesteps: 183,259,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,867.72054
Policy Entropy: 0.36717
Value Function Loss: 2.03328

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.04709
Policy Update Magnitude: 0.02020
Value Function Update Magnitude: 0.02433

Collected Steps per Second: 22,363.40965
Overall Steps per Second: 16,241.14731

Timestep Collection Time: 2.23714
Timestep Consumption Time: 0.84331
PPO Batch Consumption Time: 0.06629
Total Iteration Time: 3.08045

Cumulative Model Updates: 10,978
Cumulative Timesteps: 183,309,982

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 183309982...
Checkpoint 183309982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,279.29054
Policy Entropy: 0.36804
Value Function Loss: 1.90723

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03529
Policy Update Magnitude: 0.02092
Value Function Update Magnitude: 0.02301

Collected Steps per Second: 21,777.25705
Overall Steps per Second: 16,611.88772

Timestep Collection Time: 2.29652
Timestep Consumption Time: 0.71409
PPO Batch Consumption Time: 0.02911
Total Iteration Time: 3.01062

Cumulative Model Updates: 10,981
Cumulative Timesteps: 183,359,994

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,550.84867
Policy Entropy: 0.37367
Value Function Loss: 1.85345

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.02227
Policy Update Magnitude: 0.02282
Value Function Update Magnitude: 0.02578

Collected Steps per Second: 21,115.56219
Overall Steps per Second: 15,084.24141

Timestep Collection Time: 2.36849
Timestep Consumption Time: 0.94702
PPO Batch Consumption Time: 0.08206
Total Iteration Time: 3.31551

Cumulative Model Updates: 10,984
Cumulative Timesteps: 183,410,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 183410006...
Checkpoint 183410006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,409.84111
Policy Entropy: 0.36808
Value Function Loss: 1.85912

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01335
Policy Update Magnitude: 0.02645
Value Function Update Magnitude: 0.02396

Collected Steps per Second: 19,605.90908
Overall Steps per Second: 14,176.61374

Timestep Collection Time: 2.55178
Timestep Consumption Time: 0.97727
PPO Batch Consumption Time: 0.10916
Total Iteration Time: 3.52905

Cumulative Model Updates: 10,987
Cumulative Timesteps: 183,460,036

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,677.46710
Policy Entropy: 0.36660
Value Function Loss: 1.89838

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.04759
Policy Update Magnitude: 0.02729
Value Function Update Magnitude: 0.02356

Collected Steps per Second: 22,108.98453
Overall Steps per Second: 15,679.56614

Timestep Collection Time: 2.26161
Timestep Consumption Time: 0.92738
PPO Batch Consumption Time: 0.10786
Total Iteration Time: 3.18899

Cumulative Model Updates: 10,990
Cumulative Timesteps: 183,510,038

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 183510038...
Checkpoint 183510038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,384.23682
Policy Entropy: 0.35952
Value Function Loss: 1.97850

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04927
Policy Update Magnitude: 0.02552
Value Function Update Magnitude: 0.02175

Collected Steps per Second: 22,386.85965
Overall Steps per Second: 16,768.05283

Timestep Collection Time: 2.23497
Timestep Consumption Time: 0.74892
PPO Batch Consumption Time: 0.05774
Total Iteration Time: 2.98389

Cumulative Model Updates: 10,993
Cumulative Timesteps: 183,560,072

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,930.46544
Policy Entropy: 0.36446
Value Function Loss: 1.96544

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04803
Policy Update Magnitude: 0.02175
Value Function Update Magnitude: 0.02257

Collected Steps per Second: 20,952.19580
Overall Steps per Second: 15,627.13435

Timestep Collection Time: 2.38772
Timestep Consumption Time: 0.81363
PPO Batch Consumption Time: 0.08795
Total Iteration Time: 3.20135

Cumulative Model Updates: 10,996
Cumulative Timesteps: 183,610,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 183610100...
Checkpoint 183610100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,219.67849
Policy Entropy: 0.36327
Value Function Loss: 1.91360

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03198
Policy Update Magnitude: 0.01992
Value Function Update Magnitude: 0.02160

Collected Steps per Second: 22,067.55761
Overall Steps per Second: 16,792.57291

Timestep Collection Time: 2.26622
Timestep Consumption Time: 0.71188
PPO Batch Consumption Time: 0.06064
Total Iteration Time: 2.97810

Cumulative Model Updates: 10,999
Cumulative Timesteps: 183,660,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,004.45461
Policy Entropy: 0.36237
Value Function Loss: 1.90101

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01850
Policy Update Magnitude: 0.02266
Value Function Update Magnitude: 0.02257

Collected Steps per Second: 20,840.19208
Overall Steps per Second: 15,567.89933

Timestep Collection Time: 2.40113
Timestep Consumption Time: 0.81318
PPO Batch Consumption Time: 0.08551
Total Iteration Time: 3.21431

Cumulative Model Updates: 11,002
Cumulative Timesteps: 183,710,150

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 183710150...
Checkpoint 183710150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,026.97291
Policy Entropy: 0.36164
Value Function Loss: 1.92006

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01865
Policy Update Magnitude: 0.02370
Value Function Update Magnitude: 0.02472

Collected Steps per Second: 23,778.80689
Overall Steps per Second: 16,864.43217

Timestep Collection Time: 2.10339
Timestep Consumption Time: 0.86238
PPO Batch Consumption Time: 0.07827
Total Iteration Time: 2.96577

Cumulative Model Updates: 11,005
Cumulative Timesteps: 183,760,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,795.89111
Policy Entropy: 0.36098
Value Function Loss: 1.93891

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01947
Policy Update Magnitude: 0.02525
Value Function Update Magnitude: 0.02352

Collected Steps per Second: 24,277.05916
Overall Steps per Second: 16,803.04205

Timestep Collection Time: 2.06063
Timestep Consumption Time: 0.91657
PPO Batch Consumption Time: 0.10427
Total Iteration Time: 2.97720

Cumulative Model Updates: 11,008
Cumulative Timesteps: 183,810,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 183810192...
Checkpoint 183810192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,547.76169
Policy Entropy: 0.36136
Value Function Loss: 1.86690

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02317
Policy Update Magnitude: 0.02152
Value Function Update Magnitude: 0.02349

Collected Steps per Second: 23,417.16480
Overall Steps per Second: 16,687.53053

Timestep Collection Time: 2.13638
Timestep Consumption Time: 0.86155
PPO Batch Consumption Time: 0.08359
Total Iteration Time: 2.99793

Cumulative Model Updates: 11,011
Cumulative Timesteps: 183,860,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,266.67352
Policy Entropy: 0.36538
Value Function Loss: 1.85969

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01925
Policy Update Magnitude: 0.02431
Value Function Update Magnitude: 0.02632

Collected Steps per Second: 22,323.31212
Overall Steps per Second: 16,106.30405

Timestep Collection Time: 2.24098
Timestep Consumption Time: 0.86501
PPO Batch Consumption Time: 0.05871
Total Iteration Time: 3.10599

Cumulative Model Updates: 11,014
Cumulative Timesteps: 183,910,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 183910246...
Checkpoint 183910246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,824.17764
Policy Entropy: 0.36318
Value Function Loss: 1.89960

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.02243
Policy Update Magnitude: 0.02538
Value Function Update Magnitude: 0.02345

Collected Steps per Second: 20,650.90602
Overall Steps per Second: 16,157.99735

Timestep Collection Time: 2.42246
Timestep Consumption Time: 0.67359
PPO Batch Consumption Time: 0.02889
Total Iteration Time: 3.09605

Cumulative Model Updates: 11,017
Cumulative Timesteps: 183,960,272

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,370.31669
Policy Entropy: 0.35972
Value Function Loss: 2.03048

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03284
Policy Update Magnitude: 0.02592
Value Function Update Magnitude: 0.02518

Collected Steps per Second: 23,058.07860
Overall Steps per Second: 16,339.94938

Timestep Collection Time: 2.16844
Timestep Consumption Time: 0.89155
PPO Batch Consumption Time: 0.08608
Total Iteration Time: 3.05998

Cumulative Model Updates: 11,020
Cumulative Timesteps: 184,010,272

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 184010272...
Checkpoint 184010272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,996.63849
Policy Entropy: 0.35716
Value Function Loss: 2.00503

Mean KL Divergence: 0.00123
SB3 Clip Fraction: 0.01312
Policy Update Magnitude: 0.02511
Value Function Update Magnitude: 0.02376

Collected Steps per Second: 20,412.79285
Overall Steps per Second: 14,930.41205

Timestep Collection Time: 2.45052
Timestep Consumption Time: 0.89982
PPO Batch Consumption Time: 0.06384
Total Iteration Time: 3.35034

Cumulative Model Updates: 11,023
Cumulative Timesteps: 184,060,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,337.35696
Policy Entropy: 0.35923
Value Function Loss: 2.03235

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02835
Policy Update Magnitude: 0.02839
Value Function Update Magnitude: 0.02436

Collected Steps per Second: 20,689.34636
Overall Steps per Second: 15,042.96760

Timestep Collection Time: 2.41864
Timestep Consumption Time: 0.90784
PPO Batch Consumption Time: 0.09685
Total Iteration Time: 3.32647

Cumulative Model Updates: 11,026
Cumulative Timesteps: 184,110,334

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 184110334...
Checkpoint 184110334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,209.87000
Policy Entropy: 0.36190
Value Function Loss: 2.04300

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02987
Policy Update Magnitude: 0.02639
Value Function Update Magnitude: 0.02722

Collected Steps per Second: 22,826.63069
Overall Steps per Second: 17,442.48325

Timestep Collection Time: 2.19139
Timestep Consumption Time: 0.67644
PPO Batch Consumption Time: 0.02825
Total Iteration Time: 2.86783

Cumulative Model Updates: 11,029
Cumulative Timesteps: 184,160,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,834.11731
Policy Entropy: 0.36010
Value Function Loss: 2.10817

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.02854
Value Function Update Magnitude: 0.02448

Collected Steps per Second: 23,683.31147
Overall Steps per Second: 18,277.32368

Timestep Collection Time: 2.11128
Timestep Consumption Time: 0.62446
PPO Batch Consumption Time: 0.02960
Total Iteration Time: 2.73574

Cumulative Model Updates: 11,032
Cumulative Timesteps: 184,210,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 184210358...
Checkpoint 184210358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,464.98058
Policy Entropy: 0.37095
Value Function Loss: 2.04100

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02272
Policy Update Magnitude: 0.02921
Value Function Update Magnitude: 0.02254

Collected Steps per Second: 21,512.20261
Overall Steps per Second: 15,836.03744

Timestep Collection Time: 2.32436
Timestep Consumption Time: 0.83313
PPO Batch Consumption Time: 0.09493
Total Iteration Time: 3.15748

Cumulative Model Updates: 11,035
Cumulative Timesteps: 184,260,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,706.61401
Policy Entropy: 0.36940
Value Function Loss: 1.92311

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.02394
Value Function Update Magnitude: 0.02403

Collected Steps per Second: 23,367.22770
Overall Steps per Second: 17,564.46101

Timestep Collection Time: 2.13983
Timestep Consumption Time: 0.70694
PPO Batch Consumption Time: 0.02922
Total Iteration Time: 2.84677

Cumulative Model Updates: 11,038
Cumulative Timesteps: 184,310,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 184310362...
Checkpoint 184310362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,507.24727
Policy Entropy: 0.36776
Value Function Loss: 1.84863

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01623
Policy Update Magnitude: 0.02720
Value Function Update Magnitude: 0.02585

Collected Steps per Second: 22,766.31069
Overall Steps per Second: 16,091.55105

Timestep Collection Time: 2.19675
Timestep Consumption Time: 0.91121
PPO Batch Consumption Time: 0.10007
Total Iteration Time: 3.10797

Cumulative Model Updates: 11,041
Cumulative Timesteps: 184,360,374

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,641.78410
Policy Entropy: 0.36559
Value Function Loss: 1.87228

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02698
Policy Update Magnitude: 0.02538
Value Function Update Magnitude: 0.02123

Collected Steps per Second: 23,317.89667
Overall Steps per Second: 16,847.10433

Timestep Collection Time: 2.14556
Timestep Consumption Time: 0.82409
PPO Batch Consumption Time: 0.06870
Total Iteration Time: 2.96965

Cumulative Model Updates: 11,044
Cumulative Timesteps: 184,410,404

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 184410404...
Checkpoint 184410404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,346.53966
Policy Entropy: 0.36881
Value Function Loss: 1.85661

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.02060
Policy Update Magnitude: 0.02475
Value Function Update Magnitude: 0.02233

Collected Steps per Second: 22,880.33828
Overall Steps per Second: 16,683.61866

Timestep Collection Time: 2.18624
Timestep Consumption Time: 0.81203
PPO Batch Consumption Time: 0.06141
Total Iteration Time: 2.99827

Cumulative Model Updates: 11,047
Cumulative Timesteps: 184,460,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,204.59581
Policy Entropy: 0.36965
Value Function Loss: 1.83934

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03413
Policy Update Magnitude: 0.02277
Value Function Update Magnitude: 0.02299

Collected Steps per Second: 23,363.66640
Overall Steps per Second: 17,690.92101

Timestep Collection Time: 2.14093
Timestep Consumption Time: 0.68651
PPO Batch Consumption Time: 0.02958
Total Iteration Time: 2.82744

Cumulative Model Updates: 11,050
Cumulative Timesteps: 184,510,446

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 184510446...
Checkpoint 184510446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,048.72663
Policy Entropy: 0.36782
Value Function Loss: 1.84930

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.04095
Policy Update Magnitude: 0.02256
Value Function Update Magnitude: 0.02338

Collected Steps per Second: 22,662.67638
Overall Steps per Second: 15,774.43013

Timestep Collection Time: 2.20636
Timestep Consumption Time: 0.96345
PPO Batch Consumption Time: 0.10916
Total Iteration Time: 3.16981

Cumulative Model Updates: 11,053
Cumulative Timesteps: 184,560,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,016.19848
Policy Entropy: 0.36905
Value Function Loss: 1.97001

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05227
Policy Update Magnitude: 0.02226
Value Function Update Magnitude: 0.02560

Collected Steps per Second: 23,183.94336
Overall Steps per Second: 16,825.82129

Timestep Collection Time: 2.15727
Timestep Consumption Time: 0.81519
PPO Batch Consumption Time: 0.06391
Total Iteration Time: 2.97246

Cumulative Model Updates: 11,056
Cumulative Timesteps: 184,610,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 184610462...
Checkpoint 184610462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,598.59178
Policy Entropy: 0.36671
Value Function Loss: 2.00441

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05483
Policy Update Magnitude: 0.01824
Value Function Update Magnitude: 0.02790

Collected Steps per Second: 20,002.01204
Overall Steps per Second: 14,669.30732

Timestep Collection Time: 2.50095
Timestep Consumption Time: 0.90916
PPO Batch Consumption Time: 0.09298
Total Iteration Time: 3.41011

Cumulative Model Updates: 11,059
Cumulative Timesteps: 184,660,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,347.30100
Policy Entropy: 0.36947
Value Function Loss: 1.89206

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.05021
Policy Update Magnitude: 0.01942
Value Function Update Magnitude: 0.02425

Collected Steps per Second: 23,316.48666
Overall Steps per Second: 17,721.85695

Timestep Collection Time: 2.14586
Timestep Consumption Time: 0.67743
PPO Batch Consumption Time: 0.02917
Total Iteration Time: 2.82329

Cumulative Model Updates: 11,062
Cumulative Timesteps: 184,710,520

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 184710520...
Checkpoint 184710520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,140.81707
Policy Entropy: 0.36449
Value Function Loss: 1.83266

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03726
Policy Update Magnitude: 0.01990
Value Function Update Magnitude: 0.02330

Collected Steps per Second: 23,267.45850
Overall Steps per Second: 16,920.32948

Timestep Collection Time: 2.14892
Timestep Consumption Time: 0.80610
PPO Batch Consumption Time: 0.08563
Total Iteration Time: 2.95503

Cumulative Model Updates: 11,065
Cumulative Timesteps: 184,760,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,608.15180
Policy Entropy: 0.36893
Value Function Loss: 1.71448

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03414
Policy Update Magnitude: 0.01969
Value Function Update Magnitude: 0.03208

Collected Steps per Second: 22,797.32760
Overall Steps per Second: 17,217.18328

Timestep Collection Time: 2.19464
Timestep Consumption Time: 0.71129
PPO Batch Consumption Time: 0.06060
Total Iteration Time: 2.90593

Cumulative Model Updates: 11,068
Cumulative Timesteps: 184,810,552

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 184810552...
Checkpoint 184810552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,431.45153
Policy Entropy: 0.36502
Value Function Loss: 1.78708

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01591
Policy Update Magnitude: 0.02013
Value Function Update Magnitude: 0.02912

Collected Steps per Second: 23,183.42193
Overall Steps per Second: 16,306.94449

Timestep Collection Time: 2.15792
Timestep Consumption Time: 0.90997
PPO Batch Consumption Time: 0.08602
Total Iteration Time: 3.06790

Cumulative Model Updates: 11,071
Cumulative Timesteps: 184,860,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,094.15263
Policy Entropy: 0.36319
Value Function Loss: 1.73348

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.02478
Value Function Update Magnitude: 0.02512

Collected Steps per Second: 23,586.97607
Overall Steps per Second: 17,041.62906

Timestep Collection Time: 2.12109
Timestep Consumption Time: 0.81467
PPO Batch Consumption Time: 0.06566
Total Iteration Time: 2.93575

Cumulative Model Updates: 11,074
Cumulative Timesteps: 184,910,610

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 184910610...
Checkpoint 184910610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,140.35288
Policy Entropy: 0.35949
Value Function Loss: 1.72980

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03296
Policy Update Magnitude: 0.02363
Value Function Update Magnitude: 0.02323

Collected Steps per Second: 22,688.41884
Overall Steps per Second: 15,417.42506

Timestep Collection Time: 2.20412
Timestep Consumption Time: 1.03948
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 3.24360

Cumulative Model Updates: 11,077
Cumulative Timesteps: 184,960,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,227.61755
Policy Entropy: 0.36006
Value Function Loss: 1.67242

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03909
Policy Update Magnitude: 0.02091
Value Function Update Magnitude: 0.02402

Collected Steps per Second: 20,308.59366
Overall Steps per Second: 15,022.80304

Timestep Collection Time: 2.46270
Timestep Consumption Time: 0.86650
PPO Batch Consumption Time: 0.04414
Total Iteration Time: 3.32921

Cumulative Model Updates: 11,080
Cumulative Timesteps: 185,010,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 185010632...
Checkpoint 185010632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,311.37755
Policy Entropy: 0.36266
Value Function Loss: 1.54236

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.02082
Policy Update Magnitude: 0.02071
Value Function Update Magnitude: 0.02266

Collected Steps per Second: 21,042.37796
Overall Steps per Second: 15,602.57276

Timestep Collection Time: 2.37616
Timestep Consumption Time: 0.82844
PPO Batch Consumption Time: 0.06119
Total Iteration Time: 3.20460

Cumulative Model Updates: 11,083
Cumulative Timesteps: 185,060,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,240.21911
Policy Entropy: 0.36244
Value Function Loss: 1.57813

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01877
Policy Update Magnitude: 0.02130
Value Function Update Magnitude: 0.02188

Collected Steps per Second: 22,861.71528
Overall Steps per Second: 17,250.98567

Timestep Collection Time: 2.18802
Timestep Consumption Time: 0.71164
PPO Batch Consumption Time: 0.02933
Total Iteration Time: 2.89966

Cumulative Model Updates: 11,086
Cumulative Timesteps: 185,110,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 185110654...
Checkpoint 185110654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,327.18333
Policy Entropy: 0.36318
Value Function Loss: 1.50151

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02787
Policy Update Magnitude: 0.02338
Value Function Update Magnitude: 0.02099

Collected Steps per Second: 21,110.33256
Overall Steps per Second: 14,970.34808

Timestep Collection Time: 2.36851
Timestep Consumption Time: 0.97143
PPO Batch Consumption Time: 0.08110
Total Iteration Time: 3.33994

Cumulative Model Updates: 11,089
Cumulative Timesteps: 185,160,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,520.92079
Policy Entropy: 0.35742
Value Function Loss: 1.64835

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03912
Policy Update Magnitude: 0.02215
Value Function Update Magnitude: 0.02102

Collected Steps per Second: 21,325.45155
Overall Steps per Second: 16,401.67276

Timestep Collection Time: 2.34546
Timestep Consumption Time: 0.70411
PPO Batch Consumption Time: 0.02988
Total Iteration Time: 3.04957

Cumulative Model Updates: 11,092
Cumulative Timesteps: 185,210,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 185210672...
Checkpoint 185210672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,611.15339
Policy Entropy: 0.35796
Value Function Loss: 1.66230

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.03042
Policy Update Magnitude: 0.01988
Value Function Update Magnitude: 0.01914

Collected Steps per Second: 22,403.08770
Overall Steps per Second: 16,092.20535

Timestep Collection Time: 2.23255
Timestep Consumption Time: 0.87554
PPO Batch Consumption Time: 0.07993
Total Iteration Time: 3.10809

Cumulative Model Updates: 11,095
Cumulative Timesteps: 185,260,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,587.60728
Policy Entropy: 0.35624
Value Function Loss: 1.76362

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02992
Policy Update Magnitude: 0.01930
Value Function Update Magnitude: 0.02145

Collected Steps per Second: 23,118.60129
Overall Steps per Second: 17,468.50908

Timestep Collection Time: 2.16276
Timestep Consumption Time: 0.69953
PPO Batch Consumption Time: 0.02953
Total Iteration Time: 2.86229

Cumulative Model Updates: 11,098
Cumulative Timesteps: 185,310,688

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 185310688...
Checkpoint 185310688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,827.00984
Policy Entropy: 0.36156
Value Function Loss: 1.74352

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.01929
Value Function Update Magnitude: 0.02413

Collected Steps per Second: 23,427.11282
Overall Steps per Second: 17,178.10996

Timestep Collection Time: 2.13522
Timestep Consumption Time: 0.77674
PPO Batch Consumption Time: 0.05063
Total Iteration Time: 2.91196

Cumulative Model Updates: 11,101
Cumulative Timesteps: 185,360,710

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,822.57178
Policy Entropy: 0.35922
Value Function Loss: 1.77245

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.02160
Value Function Update Magnitude: 0.02246

Collected Steps per Second: 20,319.50473
Overall Steps per Second: 14,802.33810

Timestep Collection Time: 2.46177
Timestep Consumption Time: 0.91756
PPO Batch Consumption Time: 0.09807
Total Iteration Time: 3.37933

Cumulative Model Updates: 11,104
Cumulative Timesteps: 185,410,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 185410732...
Checkpoint 185410732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,394.50025
Policy Entropy: 0.36379
Value Function Loss: 1.73913

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.02052
Policy Update Magnitude: 0.02269
Value Function Update Magnitude: 0.02759

Collected Steps per Second: 23,077.96618
Overall Steps per Second: 17,586.32181

Timestep Collection Time: 2.16735
Timestep Consumption Time: 0.67679
PPO Batch Consumption Time: 0.02984
Total Iteration Time: 2.84414

Cumulative Model Updates: 11,107
Cumulative Timesteps: 185,460,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,234.73263
Policy Entropy: 0.36297
Value Function Loss: 1.70028

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.02209
Policy Update Magnitude: 0.02233
Value Function Update Magnitude: 0.02405

Collected Steps per Second: 23,144.38869
Overall Steps per Second: 17,132.01329

Timestep Collection Time: 2.16121
Timestep Consumption Time: 0.75847
PPO Batch Consumption Time: 0.05071
Total Iteration Time: 2.91968

Cumulative Model Updates: 11,110
Cumulative Timesteps: 185,510,770

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 185510770...
Checkpoint 185510770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,211.05701
Policy Entropy: 0.36847
Value Function Loss: 1.72165

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02489
Policy Update Magnitude: 0.02863
Value Function Update Magnitude: 0.02284

Collected Steps per Second: 21,359.09736
Overall Steps per Second: 15,579.48412

Timestep Collection Time: 2.34195
Timestep Consumption Time: 0.86881
PPO Batch Consumption Time: 0.07951
Total Iteration Time: 3.21076

Cumulative Model Updates: 11,113
Cumulative Timesteps: 185,560,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,857.09700
Policy Entropy: 0.37037
Value Function Loss: 1.77369

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02925
Policy Update Magnitude: 0.02219
Value Function Update Magnitude: 0.02215

Collected Steps per Second: 19,760.08646
Overall Steps per Second: 14,799.78770

Timestep Collection Time: 2.53106
Timestep Consumption Time: 0.84831
PPO Batch Consumption Time: 0.09132
Total Iteration Time: 3.37937

Cumulative Model Updates: 11,116
Cumulative Timesteps: 185,610,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 185610806...
Checkpoint 185610806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,207.70026
Policy Entropy: 0.36843
Value Function Loss: 1.69526

Mean KL Divergence: 0.00126
SB3 Clip Fraction: 0.01394
Policy Update Magnitude: 0.02370
Value Function Update Magnitude: 0.02024

Collected Steps per Second: 21,955.62538
Overall Steps per Second: 16,637.35912

Timestep Collection Time: 2.27850
Timestep Consumption Time: 0.72834
PPO Batch Consumption Time: 0.06124
Total Iteration Time: 3.00685

Cumulative Model Updates: 11,119
Cumulative Timesteps: 185,660,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,342.74672
Policy Entropy: 0.36622
Value Function Loss: 1.68737

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.01555
Policy Update Magnitude: 0.02724
Value Function Update Magnitude: 0.02091

Collected Steps per Second: 20,157.59782
Overall Steps per Second: 14,856.92618

Timestep Collection Time: 2.48105
Timestep Consumption Time: 0.88519
PPO Batch Consumption Time: 0.10457
Total Iteration Time: 3.36624

Cumulative Model Updates: 11,122
Cumulative Timesteps: 185,710,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 185710844...
Checkpoint 185710844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,304.63644
Policy Entropy: 0.36735
Value Function Loss: 1.61646

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.02307
Policy Update Magnitude: 0.02989
Value Function Update Magnitude: 0.02122

Collected Steps per Second: 22,848.04823
Overall Steps per Second: 17,335.82751

Timestep Collection Time: 2.18855
Timestep Consumption Time: 0.69589
PPO Batch Consumption Time: 0.03041
Total Iteration Time: 2.88443

Cumulative Model Updates: 11,125
Cumulative Timesteps: 185,760,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,116.04662
Policy Entropy: 0.37102
Value Function Loss: 1.67641

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02918
Policy Update Magnitude: 0.02638
Value Function Update Magnitude: 0.02210

Collected Steps per Second: 23,223.03344
Overall Steps per Second: 16,906.93555

Timestep Collection Time: 2.15329
Timestep Consumption Time: 0.80443
PPO Batch Consumption Time: 0.05320
Total Iteration Time: 2.95772

Cumulative Model Updates: 11,128
Cumulative Timesteps: 185,810,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 185810854...
Checkpoint 185810854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,406.15023
Policy Entropy: 0.36878
Value Function Loss: 1.66187

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.02248
Value Function Update Magnitude: 0.01893

Collected Steps per Second: 21,863.93453
Overall Steps per Second: 15,187.16864

Timestep Collection Time: 2.28687
Timestep Consumption Time: 1.00538
PPO Batch Consumption Time: 0.12508
Total Iteration Time: 3.29225

Cumulative Model Updates: 11,131
Cumulative Timesteps: 185,860,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,352.64383
Policy Entropy: 0.36964
Value Function Loss: 1.72441

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01757
Policy Update Magnitude: 0.02279
Value Function Update Magnitude: 0.02134

Collected Steps per Second: 23,459.73062
Overall Steps per Second: 17,671.23415

Timestep Collection Time: 2.13233
Timestep Consumption Time: 0.69848
PPO Batch Consumption Time: 0.02949
Total Iteration Time: 2.83082

Cumulative Model Updates: 11,134
Cumulative Timesteps: 185,910,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 185910878...
Checkpoint 185910878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,694.65101
Policy Entropy: 0.37304
Value Function Loss: 1.76761

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.03117
Policy Update Magnitude: 0.02509
Value Function Update Magnitude: 0.02102

Collected Steps per Second: 23,439.98600
Overall Steps per Second: 17,011.95066

Timestep Collection Time: 2.13319
Timestep Consumption Time: 0.80604
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 2.93923

Cumulative Model Updates: 11,137
Cumulative Timesteps: 185,960,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,643.81668
Policy Entropy: 0.36279
Value Function Loss: 1.91042

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02583
Policy Update Magnitude: 0.02413
Value Function Update Magnitude: 0.02061

Collected Steps per Second: 22,336.81992
Overall Steps per Second: 15,529.27031

Timestep Collection Time: 2.24007
Timestep Consumption Time: 0.98198
PPO Batch Consumption Time: 0.11204
Total Iteration Time: 3.22204

Cumulative Model Updates: 11,140
Cumulative Timesteps: 186,010,916

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 186010916...
Checkpoint 186010916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,883.62062
Policy Entropy: 0.36067
Value Function Loss: 1.83277

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.01373
Policy Update Magnitude: 0.02640
Value Function Update Magnitude: 0.02515

Collected Steps per Second: 22,584.08498
Overall Steps per Second: 16,753.72886

Timestep Collection Time: 2.21448
Timestep Consumption Time: 0.77065
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 2.98513

Cumulative Model Updates: 11,143
Cumulative Timesteps: 186,060,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,455.45144
Policy Entropy: 0.36132
Value Function Loss: 1.80456

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 0.02411
Value Function Update Magnitude: 0.02376

Collected Steps per Second: 18,971.78364
Overall Steps per Second: 13,954.88796

Timestep Collection Time: 2.63634
Timestep Consumption Time: 0.94778
PPO Batch Consumption Time: 0.11225
Total Iteration Time: 3.58412

Cumulative Model Updates: 11,146
Cumulative Timesteps: 186,110,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 186110944...
Checkpoint 186110944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,147.12959
Policy Entropy: 0.37115
Value Function Loss: 1.59530

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02712
Policy Update Magnitude: 0.02322
Value Function Update Magnitude: 0.02192

Collected Steps per Second: 21,313.26206
Overall Steps per Second: 15,802.87332

Timestep Collection Time: 2.34774
Timestep Consumption Time: 0.81865
PPO Batch Consumption Time: 0.05945
Total Iteration Time: 3.16639

Cumulative Model Updates: 11,149
Cumulative Timesteps: 186,160,982

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,190.18729
Policy Entropy: 0.37097
Value Function Loss: 1.62020

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.02448
Value Function Update Magnitude: 0.02515

Collected Steps per Second: 18,199.16180
Overall Steps per Second: 13,770.49290

Timestep Collection Time: 2.74914
Timestep Consumption Time: 0.88414
PPO Batch Consumption Time: 0.07581
Total Iteration Time: 3.63328

Cumulative Model Updates: 11,152
Cumulative Timesteps: 186,211,014

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 186211014...
Checkpoint 186211014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,859.83406
Policy Entropy: 0.37339
Value Function Loss: 1.56033

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03773
Policy Update Magnitude: 0.02020
Value Function Update Magnitude: 0.02391

Collected Steps per Second: 19,442.58372
Overall Steps per Second: 13,976.64315

Timestep Collection Time: 2.57188
Timestep Consumption Time: 1.00580
PPO Batch Consumption Time: 0.11320
Total Iteration Time: 3.57768

Cumulative Model Updates: 11,155
Cumulative Timesteps: 186,261,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,631.51108
Policy Entropy: 0.37391
Value Function Loss: 1.53021

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.03231
Policy Update Magnitude: 0.02245
Value Function Update Magnitude: 0.02228

Collected Steps per Second: 21,031.25829
Overall Steps per Second: 15,753.02145

Timestep Collection Time: 2.37808
Timestep Consumption Time: 0.79680
PPO Batch Consumption Time: 0.08470
Total Iteration Time: 3.17488

Cumulative Model Updates: 11,158
Cumulative Timesteps: 186,311,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 186311032...
Checkpoint 186311032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,777.44707
Policy Entropy: 0.37893
Value Function Loss: 1.49381

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.04099
Policy Update Magnitude: 0.02126
Value Function Update Magnitude: 0.02306

Collected Steps per Second: 20,619.49338
Overall Steps per Second: 16,266.71401

Timestep Collection Time: 2.42576
Timestep Consumption Time: 0.64911
PPO Batch Consumption Time: 0.02902
Total Iteration Time: 3.07487

Cumulative Model Updates: 11,161
Cumulative Timesteps: 186,361,050

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,558.38830
Policy Entropy: 0.37531
Value Function Loss: 1.48314

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.03264
Policy Update Magnitude: 0.02011
Value Function Update Magnitude: 0.02085

Collected Steps per Second: 23,166.26752
Overall Steps per Second: 17,214.32126

Timestep Collection Time: 2.15840
Timestep Consumption Time: 0.74628
PPO Batch Consumption Time: 0.07700
Total Iteration Time: 2.90467

Cumulative Model Updates: 11,164
Cumulative Timesteps: 186,411,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 186411052...
Checkpoint 186411052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,319.68801
Policy Entropy: 0.37549
Value Function Loss: 1.54804

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03565
Policy Update Magnitude: 0.02000
Value Function Update Magnitude: 0.02147

Collected Steps per Second: 22,959.34751
Overall Steps per Second: 17,160.44758

Timestep Collection Time: 2.17828
Timestep Consumption Time: 0.73609
PPO Batch Consumption Time: 0.06272
Total Iteration Time: 2.91438

Cumulative Model Updates: 11,167
Cumulative Timesteps: 186,461,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,456.08870
Policy Entropy: 0.37769
Value Function Loss: 1.68898

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.04425
Policy Update Magnitude: 0.02100
Value Function Update Magnitude: 0.02258

Collected Steps per Second: 24,557.54477
Overall Steps per Second: 17,688.33780

Timestep Collection Time: 2.03612
Timestep Consumption Time: 0.79072
PPO Batch Consumption Time: 0.06081
Total Iteration Time: 2.82683

Cumulative Model Updates: 11,170
Cumulative Timesteps: 186,511,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 186511066...
Checkpoint 186511066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,517.79625
Policy Entropy: 0.37174
Value Function Loss: 1.69286

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03467
Policy Update Magnitude: 0.01910
Value Function Update Magnitude: 0.02353

Collected Steps per Second: 21,058.97979
Overall Steps per Second: 15,421.59556

Timestep Collection Time: 2.37647
Timestep Consumption Time: 0.86872
PPO Batch Consumption Time: 0.08800
Total Iteration Time: 3.24519

Cumulative Model Updates: 11,173
Cumulative Timesteps: 186,561,112

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,898.50535
Policy Entropy: 0.37448
Value Function Loss: 1.65578

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03726
Policy Update Magnitude: 0.02241
Value Function Update Magnitude: 0.02286

Collected Steps per Second: 24,538.48569
Overall Steps per Second: 17,595.92067

Timestep Collection Time: 2.03851
Timestep Consumption Time: 0.80431
PPO Batch Consumption Time: 0.06073
Total Iteration Time: 2.84282

Cumulative Model Updates: 11,176
Cumulative Timesteps: 186,611,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 186611134...
Checkpoint 186611134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,628.48717
Policy Entropy: 0.37735
Value Function Loss: 1.54694

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01675
Policy Update Magnitude: 0.02425
Value Function Update Magnitude: 0.02437

Collected Steps per Second: 21,310.13903
Overall Steps per Second: 15,209.66051

Timestep Collection Time: 2.34743
Timestep Consumption Time: 0.94154
PPO Batch Consumption Time: 0.10730
Total Iteration Time: 3.28896

Cumulative Model Updates: 11,179
Cumulative Timesteps: 186,661,158

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,804.27508
Policy Entropy: 0.37748
Value Function Loss: 1.52053

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03723
Policy Update Magnitude: 0.02526
Value Function Update Magnitude: 0.02450

Collected Steps per Second: 24,134.84405
Overall Steps per Second: 17,344.76013

Timestep Collection Time: 2.07277
Timestep Consumption Time: 0.81144
PPO Batch Consumption Time: 0.06337
Total Iteration Time: 2.88421

Cumulative Model Updates: 11,182
Cumulative Timesteps: 186,711,184

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 186711184...
Checkpoint 186711184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,991.82786
Policy Entropy: 0.37087
Value Function Loss: 1.48446

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02853
Policy Update Magnitude: 0.02506
Value Function Update Magnitude: 0.02266

Collected Steps per Second: 21,115.48616
Overall Steps per Second: 15,194.07322

Timestep Collection Time: 2.36945
Timestep Consumption Time: 0.92342
PPO Batch Consumption Time: 0.10008
Total Iteration Time: 3.29286

Cumulative Model Updates: 11,185
Cumulative Timesteps: 186,761,216

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,115.68410
Policy Entropy: 0.37109
Value Function Loss: 1.45305

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.02577
Value Function Update Magnitude: 0.02194

Collected Steps per Second: 23,976.95190
Overall Steps per Second: 16,706.78319

Timestep Collection Time: 2.08559
Timestep Consumption Time: 0.90757
PPO Batch Consumption Time: 0.09361
Total Iteration Time: 2.99316

Cumulative Model Updates: 11,188
Cumulative Timesteps: 186,811,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 186811222...
Checkpoint 186811222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,815.84656
Policy Entropy: 0.37127
Value Function Loss: 1.49112

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04686
Policy Update Magnitude: 0.02382
Value Function Update Magnitude: 0.02255

Collected Steps per Second: 24,154.02493
Overall Steps per Second: 16,767.81946

Timestep Collection Time: 2.07121
Timestep Consumption Time: 0.91236
PPO Batch Consumption Time: 0.09573
Total Iteration Time: 2.98357

Cumulative Model Updates: 11,191
Cumulative Timesteps: 186,861,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,677.08887
Policy Entropy: 0.37445
Value Function Loss: 1.46239

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05771
Policy Update Magnitude: 0.02077
Value Function Update Magnitude: 0.02183

Collected Steps per Second: 24,033.41513
Overall Steps per Second: 16,708.94469

Timestep Collection Time: 2.08069
Timestep Consumption Time: 0.91208
PPO Batch Consumption Time: 0.09465
Total Iteration Time: 2.99277

Cumulative Model Updates: 11,194
Cumulative Timesteps: 186,911,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 186911256...
Checkpoint 186911256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,666.95904
Policy Entropy: 0.37072
Value Function Loss: 1.48066

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04461
Policy Update Magnitude: 0.01714
Value Function Update Magnitude: 0.02135

Collected Steps per Second: 24,105.32037
Overall Steps per Second: 16,581.93123

Timestep Collection Time: 2.07473
Timestep Consumption Time: 0.94133
PPO Batch Consumption Time: 0.10805
Total Iteration Time: 3.01605

Cumulative Model Updates: 11,197
Cumulative Timesteps: 186,961,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,546.23940
Policy Entropy: 0.37091
Value Function Loss: 1.47518

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.01907
Value Function Update Magnitude: 0.02333

Collected Steps per Second: 21,786.48478
Overall Steps per Second: 15,760.11642

Timestep Collection Time: 2.29509
Timestep Consumption Time: 0.87760
PPO Batch Consumption Time: 0.08118
Total Iteration Time: 3.17269

Cumulative Model Updates: 11,200
Cumulative Timesteps: 187,011,270

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 187011270...
Checkpoint 187011270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,436.63416
Policy Entropy: 0.36928
Value Function Loss: 1.45541

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.01352
Policy Update Magnitude: 0.02206
Value Function Update Magnitude: 0.02048

Collected Steps per Second: 20,728.81925
Overall Steps per Second: 15,525.37354

Timestep Collection Time: 2.41287
Timestep Consumption Time: 0.80869
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 3.22157

Cumulative Model Updates: 11,203
Cumulative Timesteps: 187,061,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,239.56408
Policy Entropy: 0.37355
Value Function Loss: 1.48100

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.03043
Policy Update Magnitude: 0.02504
Value Function Update Magnitude: 0.02324

Collected Steps per Second: 18,792.03257
Overall Steps per Second: 14,702.63104

Timestep Collection Time: 2.66081
Timestep Consumption Time: 0.74008
PPO Batch Consumption Time: 0.04735
Total Iteration Time: 3.40089

Cumulative Model Updates: 11,206
Cumulative Timesteps: 187,111,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 187111288...
Checkpoint 187111288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,084.26369
Policy Entropy: 0.37572
Value Function Loss: 1.47696

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03519
Policy Update Magnitude: 0.02234
Value Function Update Magnitude: 0.02402

Collected Steps per Second: 21,293.28906
Overall Steps per Second: 15,734.94957

Timestep Collection Time: 2.34863
Timestep Consumption Time: 0.82965
PPO Batch Consumption Time: 0.07573
Total Iteration Time: 3.17828

Cumulative Model Updates: 11,209
Cumulative Timesteps: 187,161,298

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,309.14619
Policy Entropy: 0.37114
Value Function Loss: 1.46166

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.03199
Policy Update Magnitude: 0.02027
Value Function Update Magnitude: 0.02626

Collected Steps per Second: 21,796.04710
Overall Steps per Second: 15,889.07360

Timestep Collection Time: 2.29454
Timestep Consumption Time: 0.85303
PPO Batch Consumption Time: 0.08473
Total Iteration Time: 3.14757

Cumulative Model Updates: 11,212
Cumulative Timesteps: 187,211,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 187211310...
Checkpoint 187211310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,760.01246
Policy Entropy: 0.37061
Value Function Loss: 1.44101

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02958
Policy Update Magnitude: 0.02030
Value Function Update Magnitude: 0.02479

Collected Steps per Second: 22,641.45647
Overall Steps per Second: 16,101.98741

Timestep Collection Time: 2.20887
Timestep Consumption Time: 0.89708
PPO Batch Consumption Time: 0.09634
Total Iteration Time: 3.10595

Cumulative Model Updates: 11,215
Cumulative Timesteps: 187,261,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,282.14279
Policy Entropy: 0.37357
Value Function Loss: 1.36993

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.02305
Value Function Update Magnitude: 0.02709

Collected Steps per Second: 20,659.78944
Overall Steps per Second: 15,684.61828

Timestep Collection Time: 2.42026
Timestep Consumption Time: 0.76771
PPO Batch Consumption Time: 0.06163
Total Iteration Time: 3.18796

Cumulative Model Updates: 11,218
Cumulative Timesteps: 187,311,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 187311324...
Checkpoint 187311324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,762.88263
Policy Entropy: 0.37533
Value Function Loss: 1.55034

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03187
Policy Update Magnitude: 0.02163
Value Function Update Magnitude: 0.02754

Collected Steps per Second: 20,614.95016
Overall Steps per Second: 15,247.01934

Timestep Collection Time: 2.42572
Timestep Consumption Time: 0.85401
PPO Batch Consumption Time: 0.08892
Total Iteration Time: 3.27972

Cumulative Model Updates: 11,221
Cumulative Timesteps: 187,361,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,355.55725
Policy Entropy: 0.36886
Value Function Loss: 1.66965

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.02012
Value Function Update Magnitude: 0.02562

Collected Steps per Second: 19,422.88978
Overall Steps per Second: 14,840.93646

Timestep Collection Time: 2.57439
Timestep Consumption Time: 0.79481
PPO Batch Consumption Time: 0.07313
Total Iteration Time: 3.36919

Cumulative Model Updates: 11,224
Cumulative Timesteps: 187,411,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 187411332...
Checkpoint 187411332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,109.29048
Policy Entropy: 0.36865
Value Function Loss: 1.69798

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02796
Policy Update Magnitude: 0.02252
Value Function Update Magnitude: 0.03387

Collected Steps per Second: 19,649.28945
Overall Steps per Second: 15,758.40366

Timestep Collection Time: 2.54513
Timestep Consumption Time: 0.62841
PPO Batch Consumption Time: 0.02958
Total Iteration Time: 3.17354

Cumulative Model Updates: 11,227
Cumulative Timesteps: 187,461,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,701.78153
Policy Entropy: 0.36967
Value Function Loss: 1.52998

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.04199
Policy Update Magnitude: 0.02183
Value Function Update Magnitude: 0.03525

Collected Steps per Second: 22,060.95525
Overall Steps per Second: 17,382.61218

Timestep Collection Time: 2.26654
Timestep Consumption Time: 0.61001
PPO Batch Consumption Time: 0.02907
Total Iteration Time: 2.87655

Cumulative Model Updates: 11,230
Cumulative Timesteps: 187,511,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 187511344...
Checkpoint 187511344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,512.30475
Policy Entropy: 0.38053
Value Function Loss: 1.33298

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04947
Policy Update Magnitude: 0.02062
Value Function Update Magnitude: 0.03241

Collected Steps per Second: 21,387.91412
Overall Steps per Second: 15,937.19158

Timestep Collection Time: 2.33796
Timestep Consumption Time: 0.79961
PPO Batch Consumption Time: 0.07815
Total Iteration Time: 3.13757

Cumulative Model Updates: 11,233
Cumulative Timesteps: 187,561,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,982.63190
Policy Entropy: 0.37758
Value Function Loss: 1.44336

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03891
Policy Update Magnitude: 0.01949
Value Function Update Magnitude: 0.02992

Collected Steps per Second: 23,216.57458
Overall Steps per Second: 17,550.40244

Timestep Collection Time: 2.15570
Timestep Consumption Time: 0.69597
PPO Batch Consumption Time: 0.02954
Total Iteration Time: 2.85167

Cumulative Model Updates: 11,236
Cumulative Timesteps: 187,611,396

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 187611396...
Checkpoint 187611396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,196.30701
Policy Entropy: 0.37823
Value Function Loss: 1.42414

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.04273
Policy Update Magnitude: 0.01878
Value Function Update Magnitude: 0.02518

Collected Steps per Second: 23,133.45792
Overall Steps per Second: 16,289.64117

Timestep Collection Time: 2.16146
Timestep Consumption Time: 0.90810
PPO Batch Consumption Time: 0.08658
Total Iteration Time: 3.06956

Cumulative Model Updates: 11,239
Cumulative Timesteps: 187,661,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,033.23928
Policy Entropy: 0.37358
Value Function Loss: 1.47950

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03493
Policy Update Magnitude: 0.01773
Value Function Update Magnitude: 0.03167

Collected Steps per Second: 23,353.60647
Overall Steps per Second: 17,563.20751

Timestep Collection Time: 2.14134
Timestep Consumption Time: 0.70598
PPO Batch Consumption Time: 0.02888
Total Iteration Time: 2.84732

Cumulative Model Updates: 11,242
Cumulative Timesteps: 187,711,406

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 187711406...
Checkpoint 187711406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,994.13477
Policy Entropy: 0.37183
Value Function Loss: 1.46378

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02913
Policy Update Magnitude: 0.02112
Value Function Update Magnitude: 0.03192

Collected Steps per Second: 23,521.64190
Overall Steps per Second: 17,248.60447

Timestep Collection Time: 2.12647
Timestep Consumption Time: 0.77336
PPO Batch Consumption Time: 0.05032
Total Iteration Time: 2.89983

Cumulative Model Updates: 11,245
Cumulative Timesteps: 187,761,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,440.44582
Policy Entropy: 0.38179
Value Function Loss: 1.41443

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.04499
Policy Update Magnitude: 0.02152
Value Function Update Magnitude: 0.03026

Collected Steps per Second: 22,417.77813
Overall Steps per Second: 15,571.81562

Timestep Collection Time: 2.23046
Timestep Consumption Time: 0.98060
PPO Batch Consumption Time: 0.11434
Total Iteration Time: 3.21106

Cumulative Model Updates: 11,248
Cumulative Timesteps: 187,811,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 187811426...
Checkpoint 187811426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,860.68081
Policy Entropy: 0.38304
Value Function Loss: 1.28260

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.04593
Policy Update Magnitude: 0.01846
Value Function Update Magnitude: 0.02829

Collected Steps per Second: 23,461.34501
Overall Steps per Second: 16,614.28025

Timestep Collection Time: 2.13151
Timestep Consumption Time: 0.87843
PPO Batch Consumption Time: 0.07997
Total Iteration Time: 3.00994

Cumulative Model Updates: 11,251
Cumulative Timesteps: 187,861,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,956.72699
Policy Entropy: 0.38142
Value Function Loss: 1.36236

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03419
Policy Update Magnitude: 0.01965
Value Function Update Magnitude: 0.03450

Collected Steps per Second: 23,367.71878
Overall Steps per Second: 17,519.68978

Timestep Collection Time: 2.14073
Timestep Consumption Time: 0.71457
PPO Batch Consumption Time: 0.02944
Total Iteration Time: 2.85530

Cumulative Model Updates: 11,254
Cumulative Timesteps: 187,911,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 187911458...
Checkpoint 187911458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,585.74700
Policy Entropy: 0.37529
Value Function Loss: 1.41285

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.03073
Policy Update Magnitude: 0.02240
Value Function Update Magnitude: 0.03660

Collected Steps per Second: 22,393.07909
Overall Steps per Second: 16,886.53833

Timestep Collection Time: 2.23328
Timestep Consumption Time: 0.72825
PPO Batch Consumption Time: 0.03016
Total Iteration Time: 2.96153

Cumulative Model Updates: 11,257
Cumulative Timesteps: 187,961,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,223.30174
Policy Entropy: 0.37818
Value Function Loss: 1.36638

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.02294
Value Function Update Magnitude: 0.03742

Collected Steps per Second: 22,303.04059
Overall Steps per Second: 15,944.39177

Timestep Collection Time: 2.24319
Timestep Consumption Time: 0.89459
PPO Batch Consumption Time: 0.08642
Total Iteration Time: 3.13778

Cumulative Model Updates: 11,260
Cumulative Timesteps: 188,011,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 188011498...
Checkpoint 188011498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,267.19901
Policy Entropy: 0.37459
Value Function Loss: 1.27662

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03557
Policy Update Magnitude: 0.02076
Value Function Update Magnitude: 0.03277

Collected Steps per Second: 22,848.89516
Overall Steps per Second: 17,211.39480

Timestep Collection Time: 2.18908
Timestep Consumption Time: 0.71702
PPO Batch Consumption Time: 0.03009
Total Iteration Time: 2.90610

Cumulative Model Updates: 11,263
Cumulative Timesteps: 188,061,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,401.17529
Policy Entropy: 0.37472
Value Function Loss: 1.24677

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02313
Policy Update Magnitude: 0.02231
Value Function Update Magnitude: 0.03611

Collected Steps per Second: 22,715.11250
Overall Steps per Second: 16,917.29533

Timestep Collection Time: 2.20241
Timestep Consumption Time: 0.75480
PPO Batch Consumption Time: 0.04304
Total Iteration Time: 2.95721

Cumulative Model Updates: 11,266
Cumulative Timesteps: 188,111,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 188111544...
Checkpoint 188111544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,300.82001
Policy Entropy: 0.37404
Value Function Loss: 1.40056

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02895
Policy Update Magnitude: 0.02159
Value Function Update Magnitude: 0.05650

Collected Steps per Second: 23,500.70683
Overall Steps per Second: 17,632.76545

Timestep Collection Time: 2.12802
Timestep Consumption Time: 0.70818
PPO Batch Consumption Time: 0.02963
Total Iteration Time: 2.83620

Cumulative Model Updates: 11,269
Cumulative Timesteps: 188,161,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,386.92635
Policy Entropy: 0.37602
Value Function Loss: 1.28967

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02801
Policy Update Magnitude: 0.01955
Value Function Update Magnitude: 0.06219

Collected Steps per Second: 22,688.76054
Overall Steps per Second: 17,207.12509

Timestep Collection Time: 2.20479
Timestep Consumption Time: 0.70238
PPO Batch Consumption Time: 0.02970
Total Iteration Time: 2.90717

Cumulative Model Updates: 11,272
Cumulative Timesteps: 188,211,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 188211578...
Checkpoint 188211578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,855.35522
Policy Entropy: 0.37445
Value Function Loss: 1.31582

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01915
Policy Update Magnitude: 0.02340
Value Function Update Magnitude: 0.06226

Collected Steps per Second: 23,407.32814
Overall Steps per Second: 17,426.63486

Timestep Collection Time: 2.13651
Timestep Consumption Time: 0.73323
PPO Batch Consumption Time: 0.05069
Total Iteration Time: 2.86975

Cumulative Model Updates: 11,275
Cumulative Timesteps: 188,261,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,128.30517
Policy Entropy: 0.37210
Value Function Loss: 1.27113

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.02426
Value Function Update Magnitude: 0.06008

Collected Steps per Second: 23,463.02481
Overall Steps per Second: 17,097.84739

Timestep Collection Time: 2.13178
Timestep Consumption Time: 0.79362
PPO Batch Consumption Time: 0.06522
Total Iteration Time: 2.92540

Cumulative Model Updates: 11,278
Cumulative Timesteps: 188,311,606

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 188311606...
Checkpoint 188311606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,337.05060
Policy Entropy: 0.37440
Value Function Loss: 1.31593

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01502
Policy Update Magnitude: 0.02384
Value Function Update Magnitude: 0.05411

Collected Steps per Second: 21,821.07235
Overall Steps per Second: 16,771.05803

Timestep Collection Time: 2.29237
Timestep Consumption Time: 0.69027
PPO Batch Consumption Time: 0.02892
Total Iteration Time: 2.98264

Cumulative Model Updates: 11,281
Cumulative Timesteps: 188,361,628

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,620.43253
Policy Entropy: 0.37359
Value Function Loss: 1.28639

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01403
Policy Update Magnitude: 0.02464
Value Function Update Magnitude: 0.04219

Collected Steps per Second: 23,407.77962
Overall Steps per Second: 17,378.32687

Timestep Collection Time: 2.13690
Timestep Consumption Time: 0.74140
PPO Batch Consumption Time: 0.05240
Total Iteration Time: 2.87830

Cumulative Model Updates: 11,284
Cumulative Timesteps: 188,411,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 188411648...
Checkpoint 188411648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,445.53924
Policy Entropy: 0.37786
Value Function Loss: 1.27496

Mean KL Divergence: 0.00124
SB3 Clip Fraction: 0.01251
Policy Update Magnitude: 0.02702
Value Function Update Magnitude: 0.03294

Collected Steps per Second: 20,304.36323
Overall Steps per Second: 14,507.61808

Timestep Collection Time: 2.46262
Timestep Consumption Time: 0.98398
PPO Batch Consumption Time: 0.10987
Total Iteration Time: 3.44660

Cumulative Model Updates: 11,287
Cumulative Timesteps: 188,461,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,935.53362
Policy Entropy: 0.37596
Value Function Loss: 1.39692

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.02222
Policy Update Magnitude: 0.02722
Value Function Update Magnitude: 0.03308

Collected Steps per Second: 20,786.84851
Overall Steps per Second: 16,036.21356

Timestep Collection Time: 2.40585
Timestep Consumption Time: 0.71272
PPO Batch Consumption Time: 0.03126
Total Iteration Time: 3.11857

Cumulative Model Updates: 11,290
Cumulative Timesteps: 188,511,660

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 188511660...
Checkpoint 188511660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,531.66536
Policy Entropy: 0.36892
Value Function Loss: 1.46503

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02914
Policy Update Magnitude: 0.02481
Value Function Update Magnitude: 0.02730

Collected Steps per Second: 21,376.59896
Overall Steps per Second: 15,510.91787

Timestep Collection Time: 2.34022
Timestep Consumption Time: 0.88499
PPO Batch Consumption Time: 0.08937
Total Iteration Time: 3.22521

Cumulative Model Updates: 11,293
Cumulative Timesteps: 188,561,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,473.33764
Policy Entropy: 0.37382
Value Function Loss: 1.48150

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02859
Policy Update Magnitude: 0.02437
Value Function Update Magnitude: 0.02861

Collected Steps per Second: 22,507.60780
Overall Steps per Second: 16,742.68452

Timestep Collection Time: 2.22209
Timestep Consumption Time: 0.76512
PPO Batch Consumption Time: 0.05887
Total Iteration Time: 2.98722

Cumulative Model Updates: 11,296
Cumulative Timesteps: 188,611,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 188611700...
Checkpoint 188611700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,922.72344
Policy Entropy: 0.37599
Value Function Loss: 1.35021

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02935
Policy Update Magnitude: 0.02629
Value Function Update Magnitude: 0.02788

Collected Steps per Second: 20,279.92376
Overall Steps per Second: 14,755.97056

Timestep Collection Time: 2.46648
Timestep Consumption Time: 0.92334
PPO Batch Consumption Time: 0.10111
Total Iteration Time: 3.38981

Cumulative Model Updates: 11,299
Cumulative Timesteps: 188,661,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,315.69578
Policy Entropy: 0.37509
Value Function Loss: 1.33873

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03973
Policy Update Magnitude: 0.02355
Value Function Update Magnitude: 0.02377

Collected Steps per Second: 23,041.61587
Overall Steps per Second: 17,574.80734

Timestep Collection Time: 2.17007
Timestep Consumption Time: 0.67502
PPO Batch Consumption Time: 0.02921
Total Iteration Time: 2.84510

Cumulative Model Updates: 11,302
Cumulative Timesteps: 188,711,722

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 188711722...
Checkpoint 188711722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,209.33351
Policy Entropy: 0.37536
Value Function Loss: 1.38973

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02942
Policy Update Magnitude: 0.02205
Value Function Update Magnitude: 0.02396

Collected Steps per Second: 23,063.78999
Overall Steps per Second: 17,614.14457

Timestep Collection Time: 2.16833
Timestep Consumption Time: 0.67086
PPO Batch Consumption Time: 0.02951
Total Iteration Time: 2.83920

Cumulative Model Updates: 11,305
Cumulative Timesteps: 188,761,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,003.70491
Policy Entropy: 0.37747
Value Function Loss: 1.41591

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01573
Policy Update Magnitude: 0.02552
Value Function Update Magnitude: 0.02351

Collected Steps per Second: 22,270.12323
Overall Steps per Second: 17,084.61238

Timestep Collection Time: 2.24579
Timestep Consumption Time: 0.68164
PPO Batch Consumption Time: 0.02923
Total Iteration Time: 2.92743

Cumulative Model Updates: 11,308
Cumulative Timesteps: 188,811,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 188811746...
Checkpoint 188811746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,226.70861
Policy Entropy: 0.37303
Value Function Loss: 1.43067

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02197
Policy Update Magnitude: 0.02667
Value Function Update Magnitude: 0.02108

Collected Steps per Second: 23,188.61921
Overall Steps per Second: 18,031.49661

Timestep Collection Time: 2.15683
Timestep Consumption Time: 0.61687
PPO Batch Consumption Time: 0.02969
Total Iteration Time: 2.77370

Cumulative Model Updates: 11,311
Cumulative Timesteps: 188,861,760

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,946.47998
Policy Entropy: 0.37444
Value Function Loss: 1.49376

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03870
Policy Update Magnitude: 0.02335
Value Function Update Magnitude: 0.02192

Collected Steps per Second: 22,447.72350
Overall Steps per Second: 16,617.24254

Timestep Collection Time: 2.22864
Timestep Consumption Time: 0.78196
PPO Batch Consumption Time: 0.07273
Total Iteration Time: 3.01061

Cumulative Model Updates: 11,314
Cumulative Timesteps: 188,911,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 188911788...
Checkpoint 188911788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,932.05174
Policy Entropy: 0.36988
Value Function Loss: 1.57460

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03608
Policy Update Magnitude: 0.02452
Value Function Update Magnitude: 0.02037

Collected Steps per Second: 21,415.08820
Overall Steps per Second: 16,862.38914

Timestep Collection Time: 2.33518
Timestep Consumption Time: 0.63048
PPO Batch Consumption Time: 0.02982
Total Iteration Time: 2.96565

Cumulative Model Updates: 11,317
Cumulative Timesteps: 188,961,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,663.13018
Policy Entropy: 0.37032
Value Function Loss: 1.60961

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02741
Policy Update Magnitude: 0.02477
Value Function Update Magnitude: 0.03321

Collected Steps per Second: 23,719.18892
Overall Steps per Second: 17,325.87671

Timestep Collection Time: 2.10935
Timestep Consumption Time: 0.77836
PPO Batch Consumption Time: 0.05069
Total Iteration Time: 2.88770

Cumulative Model Updates: 11,320
Cumulative Timesteps: 189,011,828

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 189011828...
Checkpoint 189011828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,014.50926
Policy Entropy: 0.37125
Value Function Loss: 1.54239

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.02372
Policy Update Magnitude: 0.02508
Value Function Update Magnitude: 0.03353

Collected Steps per Second: 18,049.87426
Overall Steps per Second: 14,103.46011

Timestep Collection Time: 2.77010
Timestep Consumption Time: 0.77513
PPO Batch Consumption Time: 0.04486
Total Iteration Time: 3.54523

Cumulative Model Updates: 11,323
Cumulative Timesteps: 189,061,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,447.25804
Policy Entropy: 0.37171
Value Function Loss: 1.39788

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03914
Policy Update Magnitude: 0.02349
Value Function Update Magnitude: 0.02765

Collected Steps per Second: 21,006.37006
Overall Steps per Second: 16,021.69481

Timestep Collection Time: 2.38156
Timestep Consumption Time: 0.74095
PPO Batch Consumption Time: 0.03370
Total Iteration Time: 3.12252

Cumulative Model Updates: 11,326
Cumulative Timesteps: 189,111,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 189111856...
Checkpoint 189111856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,354.98274
Policy Entropy: 0.37092
Value Function Loss: 1.41969

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.04023
Policy Update Magnitude: 0.02063
Value Function Update Magnitude: 0.02615

Collected Steps per Second: 22,569.67645
Overall Steps per Second: 16,002.23279

Timestep Collection Time: 2.21572
Timestep Consumption Time: 0.90935
PPO Batch Consumption Time: 0.09858
Total Iteration Time: 3.12506

Cumulative Model Updates: 11,329
Cumulative Timesteps: 189,161,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,482.59419
Policy Entropy: 0.37106
Value Function Loss: 1.40089

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02457
Policy Update Magnitude: 0.02375
Value Function Update Magnitude: 0.02483

Collected Steps per Second: 23,639.50045
Overall Steps per Second: 17,041.90473

Timestep Collection Time: 2.11680
Timestep Consumption Time: 0.81950
PPO Batch Consumption Time: 0.06247
Total Iteration Time: 2.93629

Cumulative Model Updates: 11,332
Cumulative Timesteps: 189,211,904

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 189211904...
Checkpoint 189211904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,243.99940
Policy Entropy: 0.37856
Value Function Loss: 1.47914

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03447
Policy Update Magnitude: 0.02822
Value Function Update Magnitude: 0.02429

Collected Steps per Second: 21,821.95808
Overall Steps per Second: 16,198.10875

Timestep Collection Time: 2.29164
Timestep Consumption Time: 0.79564
PPO Batch Consumption Time: 0.05152
Total Iteration Time: 3.08727

Cumulative Model Updates: 11,335
Cumulative Timesteps: 189,261,912

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,647.07921
Policy Entropy: 0.38085
Value Function Loss: 1.27324

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04545
Policy Update Magnitude: 0.02248
Value Function Update Magnitude: 0.02265

Collected Steps per Second: 18,605.45117
Overall Steps per Second: 14,023.65876

Timestep Collection Time: 2.68835
Timestep Consumption Time: 0.87833
PPO Batch Consumption Time: 0.09253
Total Iteration Time: 3.56669

Cumulative Model Updates: 11,338
Cumulative Timesteps: 189,311,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 189311930...
Checkpoint 189311930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,652.50939
Policy Entropy: 0.38901
Value Function Loss: 1.28252

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04964
Policy Update Magnitude: 0.02315
Value Function Update Magnitude: 0.02325

Collected Steps per Second: 22,254.95428
Overall Steps per Second: 16,192.28779

Timestep Collection Time: 2.24795
Timestep Consumption Time: 0.84167
PPO Batch Consumption Time: 0.06210
Total Iteration Time: 3.08962

Cumulative Model Updates: 11,341
Cumulative Timesteps: 189,361,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,159.73737
Policy Entropy: 0.38195
Value Function Loss: 1.19811

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05549
Policy Update Magnitude: 0.02478
Value Function Update Magnitude: 0.02109

Collected Steps per Second: 17,302.79405
Overall Steps per Second: 12,717.91553

Timestep Collection Time: 2.89075
Timestep Consumption Time: 1.04213
PPO Batch Consumption Time: 0.10668
Total Iteration Time: 3.93288

Cumulative Model Updates: 11,344
Cumulative Timesteps: 189,411,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 189411976...
Checkpoint 189411976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,801.97744
Policy Entropy: 0.38233
Value Function Loss: 1.22205

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04450
Policy Update Magnitude: 0.02171
Value Function Update Magnitude: 0.02118

Collected Steps per Second: 16,281.46760
Overall Steps per Second: 12,790.71786

Timestep Collection Time: 3.07245
Timestep Consumption Time: 0.83851
PPO Batch Consumption Time: 0.04331
Total Iteration Time: 3.91096

Cumulative Model Updates: 11,347
Cumulative Timesteps: 189,462,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,137.02826
Policy Entropy: 0.38291
Value Function Loss: 1.12033

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03800
Policy Update Magnitude: 0.01920
Value Function Update Magnitude: 0.02019

Collected Steps per Second: 20,281.72323
Overall Steps per Second: 15,330.29258

Timestep Collection Time: 2.46567
Timestep Consumption Time: 0.79637
PPO Batch Consumption Time: 0.03222
Total Iteration Time: 3.26204

Cumulative Model Updates: 11,350
Cumulative Timesteps: 189,512,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 189512008...
Checkpoint 189512008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,825.62663
Policy Entropy: 0.38450
Value Function Loss: 1.19501

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03483
Policy Update Magnitude: 0.02095
Value Function Update Magnitude: 0.02219

Collected Steps per Second: 19,820.55748
Overall Steps per Second: 14,024.13309

Timestep Collection Time: 2.52294
Timestep Consumption Time: 1.04277
PPO Batch Consumption Time: 0.09555
Total Iteration Time: 3.56571

Cumulative Model Updates: 11,353
Cumulative Timesteps: 189,562,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,005.43244
Policy Entropy: 0.38164
Value Function Loss: 1.21453

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02806
Policy Update Magnitude: 0.02501
Value Function Update Magnitude: 0.02111

Collected Steps per Second: 19,698.59651
Overall Steps per Second: 14,788.82655

Timestep Collection Time: 2.54028
Timestep Consumption Time: 0.84335
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 3.38364

Cumulative Model Updates: 11,356
Cumulative Timesteps: 189,612,054

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 189612054...
Checkpoint 189612054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,871.97786
Policy Entropy: 0.38387
Value Function Loss: 1.28231

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04197
Policy Update Magnitude: 0.02269
Value Function Update Magnitude: 0.02040

Collected Steps per Second: 18,007.60207
Overall Steps per Second: 13,846.81544

Timestep Collection Time: 2.77727
Timestep Consumption Time: 0.83453
PPO Batch Consumption Time: 0.03944
Total Iteration Time: 3.61181

Cumulative Model Updates: 11,359
Cumulative Timesteps: 189,662,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,806.90582
Policy Entropy: 0.38203
Value Function Loss: 1.21073

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05595
Policy Update Magnitude: 0.02364
Value Function Update Magnitude: 0.02082

Collected Steps per Second: 17,657.79897
Overall Steps per Second: 13,913.15938

Timestep Collection Time: 2.83286
Timestep Consumption Time: 0.76245
PPO Batch Consumption Time: 0.03127
Total Iteration Time: 3.59530

Cumulative Model Updates: 11,362
Cumulative Timesteps: 189,712,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 189712088...
Checkpoint 189712088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,545.74629
Policy Entropy: 0.38490
Value Function Loss: 1.14818

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04379
Policy Update Magnitude: 0.02573
Value Function Update Magnitude: 0.02093

Collected Steps per Second: 12,824.20526
Overall Steps per Second: 10,257.69606

Timestep Collection Time: 3.90090
Timestep Consumption Time: 0.97602
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 4.87692

Cumulative Model Updates: 11,365
Cumulative Timesteps: 189,762,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,183.24373
Policy Entropy: 0.38383
Value Function Loss: 1.06442

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.03191
Policy Update Magnitude: 0.02557
Value Function Update Magnitude: 0.02016

Collected Steps per Second: 16,162.86387
Overall Steps per Second: 11,568.10702

Timestep Collection Time: 3.09512
Timestep Consumption Time: 1.22936
PPO Batch Consumption Time: 0.14416
Total Iteration Time: 4.32448

Cumulative Model Updates: 11,368
Cumulative Timesteps: 189,812,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 189812140...
Checkpoint 189812140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,507.40120
Policy Entropy: 0.38301
Value Function Loss: 1.09208

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03241
Policy Update Magnitude: 0.02501
Value Function Update Magnitude: 0.02054

Collected Steps per Second: 8,387.05686
Overall Steps per Second: 6,710.85120

Timestep Collection Time: 5.96562
Timestep Consumption Time: 1.49007
PPO Batch Consumption Time: 0.06138
Total Iteration Time: 7.45569

Cumulative Model Updates: 11,371
Cumulative Timesteps: 189,862,174

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,982.96570
Policy Entropy: 0.37832
Value Function Loss: 1.13868

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04777
Policy Update Magnitude: 0.02399
Value Function Update Magnitude: 0.02110

Collected Steps per Second: 9,143.74708
Overall Steps per Second: 6,964.72672

Timestep Collection Time: 5.46866
Timestep Consumption Time: 1.71095
PPO Batch Consumption Time: 0.11272
Total Iteration Time: 7.17961

Cumulative Model Updates: 11,374
Cumulative Timesteps: 189,912,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 189912178...
Checkpoint 189912178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,654.54872
Policy Entropy: 0.37708
Value Function Loss: 1.16757

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04354
Policy Update Magnitude: 0.02293
Value Function Update Magnitude: 0.02029

Collected Steps per Second: 12,838.45374
Overall Steps per Second: 10,600.27405

Timestep Collection Time: 3.89626
Timestep Consumption Time: 0.82267
PPO Batch Consumption Time: 0.04917
Total Iteration Time: 4.71893

Cumulative Model Updates: 11,377
Cumulative Timesteps: 189,962,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,614.33334
Policy Entropy: 0.37554
Value Function Loss: 1.16605

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03031
Policy Update Magnitude: 0.02109
Value Function Update Magnitude: 0.02646

Collected Steps per Second: 16,754.38481
Overall Steps per Second: 13,225.15299

Timestep Collection Time: 2.98429
Timestep Consumption Time: 0.79638
PPO Batch Consumption Time: 0.04633
Total Iteration Time: 3.78067

Cumulative Model Updates: 11,380
Cumulative Timesteps: 190,012,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 190012200...
Checkpoint 190012200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,698.23430
Policy Entropy: 0.37717
Value Function Loss: 1.21508

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03307
Policy Update Magnitude: 0.01832
Value Function Update Magnitude: 0.02643

Collected Steps per Second: 16,374.58202
Overall Steps per Second: 12,961.88307

Timestep Collection Time: 3.05425
Timestep Consumption Time: 0.80414
PPO Batch Consumption Time: 0.04883
Total Iteration Time: 3.85839

Cumulative Model Updates: 11,383
Cumulative Timesteps: 190,062,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,125.65640
Policy Entropy: 0.37890
Value Function Loss: 1.08888

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01986
Policy Update Magnitude: 0.02132
Value Function Update Magnitude: 0.02412

Collected Steps per Second: 15,908.58256
Overall Steps per Second: 12,609.44424

Timestep Collection Time: 3.14384
Timestep Consumption Time: 0.82255
PPO Batch Consumption Time: 0.04867
Total Iteration Time: 3.96639

Cumulative Model Updates: 11,386
Cumulative Timesteps: 190,112,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 190112226...
Checkpoint 190112226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,555.14394
Policy Entropy: 0.38202
Value Function Loss: 1.11201

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03424
Policy Update Magnitude: 0.02163
Value Function Update Magnitude: 0.02358

Collected Steps per Second: 17,775.38486
Overall Steps per Second: 13,401.11796

Timestep Collection Time: 2.81423
Timestep Consumption Time: 0.91859
PPO Batch Consumption Time: 0.05051
Total Iteration Time: 3.73282

Cumulative Model Updates: 11,389
Cumulative Timesteps: 190,162,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,573.83705
Policy Entropy: 0.38344
Value Function Loss: 1.05097

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04563
Policy Update Magnitude: 0.01937
Value Function Update Magnitude: 0.02206

Collected Steps per Second: 15,487.16458
Overall Steps per Second: 12,435.99993

Timestep Collection Time: 3.23003
Timestep Consumption Time: 0.79249
PPO Batch Consumption Time: 0.04716
Total Iteration Time: 4.02252

Cumulative Model Updates: 11,392
Cumulative Timesteps: 190,212,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 190212274...
Checkpoint 190212274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,485.11290
Policy Entropy: 0.38195
Value Function Loss: 1.13292

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.04063
Policy Update Magnitude: 0.01877
Value Function Update Magnitude: 0.02125

Collected Steps per Second: 16,710.90696
Overall Steps per Second: 13,426.77196

Timestep Collection Time: 2.99361
Timestep Consumption Time: 0.73223
PPO Batch Consumption Time: 0.04833
Total Iteration Time: 3.72584

Cumulative Model Updates: 11,395
Cumulative Timesteps: 190,262,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,962.44167
Policy Entropy: 0.37808
Value Function Loss: 1.20175

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03702
Policy Update Magnitude: 0.01690
Value Function Update Magnitude: 0.03523

Collected Steps per Second: 16,229.93257
Overall Steps per Second: 12,984.65136

Timestep Collection Time: 3.08147
Timestep Consumption Time: 0.77016
PPO Batch Consumption Time: 0.04733
Total Iteration Time: 3.85162

Cumulative Model Updates: 11,398
Cumulative Timesteps: 190,312,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 190312312...
Checkpoint 190312312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,792.30137
Policy Entropy: 0.37823
Value Function Loss: 1.25676

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03467
Policy Update Magnitude: 0.02116
Value Function Update Magnitude: 0.03249

Collected Steps per Second: 14,873.73631
Overall Steps per Second: 12,022.03548

Timestep Collection Time: 3.36365
Timestep Consumption Time: 0.79788
PPO Batch Consumption Time: 0.04950
Total Iteration Time: 4.16152

Cumulative Model Updates: 11,401
Cumulative Timesteps: 190,362,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,612.51657
Policy Entropy: 0.37729
Value Function Loss: 1.26878

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04708
Policy Update Magnitude: 0.02200
Value Function Update Magnitude: 0.03276

Collected Steps per Second: 15,710.35911
Overall Steps per Second: 11,530.16526

Timestep Collection Time: 3.18440
Timestep Consumption Time: 1.15448
PPO Batch Consumption Time: 0.09984
Total Iteration Time: 4.33888

Cumulative Model Updates: 11,404
Cumulative Timesteps: 190,412,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 190412370...
Checkpoint 190412370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,365.13579
Policy Entropy: 0.37848
Value Function Loss: 1.23881

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04673
Policy Update Magnitude: 0.01926
Value Function Update Magnitude: 0.02978

Collected Steps per Second: 7,059.95829
Overall Steps per Second: 5,963.61859

Timestep Collection Time: 7.08248
Timestep Consumption Time: 1.30203
PPO Batch Consumption Time: 0.11456
Total Iteration Time: 8.38451

Cumulative Model Updates: 11,407
Cumulative Timesteps: 190,462,372

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,999.65188
Policy Entropy: 0.37517
Value Function Loss: 1.25129

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03669
Policy Update Magnitude: 0.02072
Value Function Update Magnitude: 0.02660

Collected Steps per Second: 10,128.76784
Overall Steps per Second: 8,086.35911

Timestep Collection Time: 4.93920
Timestep Consumption Time: 1.24752
PPO Batch Consumption Time: 0.09834
Total Iteration Time: 6.18672

Cumulative Model Updates: 11,410
Cumulative Timesteps: 190,512,400

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 190512400...
Checkpoint 190512400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,531.14535
Policy Entropy: 0.37664
Value Function Loss: 1.27458

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.03071
Policy Update Magnitude: 0.02238
Value Function Update Magnitude: 0.02644

Collected Steps per Second: 10,493.07885
Overall Steps per Second: 8,292.79033

Timestep Collection Time: 4.76771
Timestep Consumption Time: 1.26500
PPO Batch Consumption Time: 0.10453
Total Iteration Time: 6.03271

Cumulative Model Updates: 11,413
Cumulative Timesteps: 190,562,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,910.74004
Policy Entropy: 0.37674
Value Function Loss: 1.21113

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01802
Policy Update Magnitude: 0.02444
Value Function Update Magnitude: 0.02430

Collected Steps per Second: 5,681.67279
Overall Steps per Second: 4,986.05666

Timestep Collection Time: 8.80832
Timestep Consumption Time: 1.22887
PPO Batch Consumption Time: 0.10269
Total Iteration Time: 10.03719

Cumulative Model Updates: 11,416
Cumulative Timesteps: 190,612,474

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 190612474...
Checkpoint 190612474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,745.86244
Policy Entropy: 0.38430
Value Function Loss: 1.13264

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03765
Policy Update Magnitude: 0.02424
Value Function Update Magnitude: 0.02244

Collected Steps per Second: 4,991.39164
Overall Steps per Second: 4,455.63698

Timestep Collection Time: 10.02205
Timestep Consumption Time: 1.20507
PPO Batch Consumption Time: 0.10285
Total Iteration Time: 11.22713

Cumulative Model Updates: 11,419
Cumulative Timesteps: 190,662,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,310.54816
Policy Entropy: 0.38480
Value Function Loss: 1.02109

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03499
Policy Update Magnitude: 0.02232
Value Function Update Magnitude: 0.01856

Collected Steps per Second: 5,070.96533
Overall Steps per Second: 4,497.23620

Timestep Collection Time: 9.86242
Timestep Consumption Time: 1.25819
PPO Batch Consumption Time: 0.10653
Total Iteration Time: 11.12061

Cumulative Model Updates: 11,422
Cumulative Timesteps: 190,712,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 190712510...
Checkpoint 190712510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,206.91587
Policy Entropy: 0.38306
Value Function Loss: 1.01616

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02789
Policy Update Magnitude: 0.02484
Value Function Update Magnitude: 0.02627

Collected Steps per Second: 5,075.84205
Overall Steps per Second: 4,417.88807

Timestep Collection Time: 9.85176
Timestep Consumption Time: 1.46722
PPO Batch Consumption Time: 0.11590
Total Iteration Time: 11.31898

Cumulative Model Updates: 11,425
Cumulative Timesteps: 190,762,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,609.69687
Policy Entropy: 0.37864
Value Function Loss: 1.05526

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03203
Policy Update Magnitude: 0.02472
Value Function Update Magnitude: 0.02434

Collected Steps per Second: 5,018.17856
Overall Steps per Second: 4,426.12902

Timestep Collection Time: 9.96856
Timestep Consumption Time: 1.33342
PPO Batch Consumption Time: 0.11121
Total Iteration Time: 11.30198

Cumulative Model Updates: 11,428
Cumulative Timesteps: 190,812,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 190812540...
Checkpoint 190812540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,591.57453
Policy Entropy: 0.37517
Value Function Loss: 1.14307

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03244
Policy Update Magnitude: 0.02302
Value Function Update Magnitude: 0.02414

Collected Steps per Second: 4,871.99543
Overall Steps per Second: 4,316.47711

Timestep Collection Time: 10.26725
Timestep Consumption Time: 1.32137
PPO Batch Consumption Time: 0.11489
Total Iteration Time: 11.58862

Cumulative Model Updates: 11,431
Cumulative Timesteps: 190,862,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,432.19294
Policy Entropy: 0.37227
Value Function Loss: 1.13978

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 0.02100
Value Function Update Magnitude: 0.02630

Collected Steps per Second: 4,891.41914
Overall Steps per Second: 4,333.50507

Timestep Collection Time: 10.22444
Timestep Consumption Time: 1.31634
PPO Batch Consumption Time: 0.11188
Total Iteration Time: 11.54077

Cumulative Model Updates: 11,434
Cumulative Timesteps: 190,912,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 190912574...
Checkpoint 190912574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,537.89861
Policy Entropy: 0.37492
Value Function Loss: 1.16550

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02275
Policy Update Magnitude: 0.02148
Value Function Update Magnitude: 0.02567

Collected Steps per Second: 4,616.46986
Overall Steps per Second: 1,061.82757

Timestep Collection Time: 10.83599
Timestep Consumption Time: 36.27524
PPO Batch Consumption Time: 11.70800
Total Iteration Time: 47.11123

Cumulative Model Updates: 11,437
Cumulative Timesteps: 190,962,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,238.01137
Policy Entropy: 0.37941
Value Function Loss: 1.12316

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01525
Policy Update Magnitude: 0.02201
Value Function Update Magnitude: 0.02691

Collected Steps per Second: 4,712.40281
Overall Steps per Second: 2,763.86902

Timestep Collection Time: 10.61709
Timestep Consumption Time: 7.48507
PPO Batch Consumption Time: 2.11977
Total Iteration Time: 18.10216

Cumulative Model Updates: 11,440
Cumulative Timesteps: 191,012,630

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 191012630...
Checkpoint 191012630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,046.25328
Policy Entropy: 0.37988
Value Function Loss: 1.13561

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01390
Policy Update Magnitude: 0.02296
Value Function Update Magnitude: 0.02690

Collected Steps per Second: 6,254.84162
Overall Steps per Second: 1,410.64114

Timestep Collection Time: 7.99732
Timestep Consumption Time: 27.46315
PPO Batch Consumption Time: 8.78213
Total Iteration Time: 35.46047

Cumulative Model Updates: 11,443
Cumulative Timesteps: 191,062,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,023.19113
Policy Entropy: 0.37865
Value Function Loss: 1.09044

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.03211
Policy Update Magnitude: 0.02150
Value Function Update Magnitude: 0.02518

Collected Steps per Second: 4,461.69072
Overall Steps per Second: 2,828.65940

Timestep Collection Time: 11.21458
Timestep Consumption Time: 6.47436
PPO Batch Consumption Time: 1.77676
Total Iteration Time: 17.68894

Cumulative Model Updates: 11,446
Cumulative Timesteps: 191,112,688

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 191112688...
Checkpoint 191112688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,906.70405
Policy Entropy: 0.37314
Value Function Loss: 1.11361

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02293
Policy Update Magnitude: 0.02251
Value Function Update Magnitude: 0.02409

Collected Steps per Second: 4,629.55280
Overall Steps per Second: 1,155.42254

Timestep Collection Time: 10.80450
Timestep Consumption Time: 32.48702
PPO Batch Consumption Time: 10.44249
Total Iteration Time: 43.29152

Cumulative Model Updates: 11,449
Cumulative Timesteps: 191,162,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,948.65472
Policy Entropy: 0.37668
Value Function Loss: 1.08316

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.03080
Policy Update Magnitude: 0.02428
Value Function Update Magnitude: 0.02621

Collected Steps per Second: 4,548.46999
Overall Steps per Second: 4,068.92632

Timestep Collection Time: 10.99447
Timestep Consumption Time: 1.29575
PPO Batch Consumption Time: 0.06305
Total Iteration Time: 12.29022

Cumulative Model Updates: 11,452
Cumulative Timesteps: 191,212,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 191212716...
Checkpoint 191212716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,417.41965
Policy Entropy: 0.37974
Value Function Loss: 1.05014

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02955
Policy Update Magnitude: 0.02195
Value Function Update Magnitude: 0.02325

Collected Steps per Second: 5,021.48873
Overall Steps per Second: 4,437.33957

Timestep Collection Time: 9.95920
Timestep Consumption Time: 1.31107
PPO Batch Consumption Time: 0.03913
Total Iteration Time: 11.27027

Cumulative Model Updates: 11,455
Cumulative Timesteps: 191,262,726

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,224.53187
Policy Entropy: 0.38279
Value Function Loss: 1.04272

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.02078
Policy Update Magnitude: 0.02162
Value Function Update Magnitude: 0.02245

Collected Steps per Second: 5,543.24917
Overall Steps per Second: 4,819.49750

Timestep Collection Time: 9.02503
Timestep Consumption Time: 1.35530
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 10.38034

Cumulative Model Updates: 11,458
Cumulative Timesteps: 191,312,754

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 191312754...
Checkpoint 191312754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,781.08213
Policy Entropy: 0.38658
Value Function Loss: 1.07581

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02398
Policy Update Magnitude: 0.02419
Value Function Update Magnitude: 0.02229

Collected Steps per Second: 5,867.26193
Overall Steps per Second: 3,887.52411

Timestep Collection Time: 8.52459
Timestep Consumption Time: 4.34118
PPO Batch Consumption Time: 1.08489
Total Iteration Time: 12.86577

Cumulative Model Updates: 11,461
Cumulative Timesteps: 191,362,770

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,791.98891
Policy Entropy: 0.38526
Value Function Loss: 1.05039

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.04334
Policy Update Magnitude: 0.02408
Value Function Update Magnitude: 0.02128

Collected Steps per Second: 4,526.46061
Overall Steps per Second: 2,846.22014

Timestep Collection Time: 11.05190
Timestep Consumption Time: 6.52439
PPO Batch Consumption Time: 1.78813
Total Iteration Time: 17.57629

Cumulative Model Updates: 11,464
Cumulative Timesteps: 191,412,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 191412796...
Checkpoint 191412796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,213.40533
Policy Entropy: 0.38464
Value Function Loss: 1.06528

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.03167
Policy Update Magnitude: 0.02081
Value Function Update Magnitude: 0.02146

Collected Steps per Second: 4,704.71383
Overall Steps per Second: 4,210.48590

Timestep Collection Time: 10.63019
Timestep Consumption Time: 1.24777
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 11.87796

Cumulative Model Updates: 11,467
Cumulative Timesteps: 191,462,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,445.91477
Policy Entropy: 0.38472
Value Function Loss: 1.08215

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03640
Policy Update Magnitude: 0.02294
Value Function Update Magnitude: 0.02297

Collected Steps per Second: 5,693.89812
Overall Steps per Second: 4,874.94796

Timestep Collection Time: 8.78344
Timestep Consumption Time: 1.47554
PPO Batch Consumption Time: 0.04482
Total Iteration Time: 10.25898

Cumulative Model Updates: 11,470
Cumulative Timesteps: 191,512,820

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 191512820...
Checkpoint 191512820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,176.87969
Policy Entropy: 0.38074
Value Function Loss: 1.16399

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.04150
Policy Update Magnitude: 0.02118
Value Function Update Magnitude: 0.01998

Collected Steps per Second: 5,370.63906
Overall Steps per Second: 4,794.25331

Timestep Collection Time: 9.31249
Timestep Consumption Time: 1.11959
PPO Batch Consumption Time: 0.04566
Total Iteration Time: 10.43207

Cumulative Model Updates: 11,473
Cumulative Timesteps: 191,562,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,286.97804
Policy Entropy: 0.38233
Value Function Loss: 1.10002

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03205
Policy Update Magnitude: 0.02253
Value Function Update Magnitude: 0.02328

Collected Steps per Second: 5,377.62656
Overall Steps per Second: 4,760.48165

Timestep Collection Time: 9.29778
Timestep Consumption Time: 1.20536
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 10.50314

Cumulative Model Updates: 11,476
Cumulative Timesteps: 191,612,834

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 191612834...
Checkpoint 191612834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,465.60425
Policy Entropy: 0.38360
Value Function Loss: 1.11758

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.04119
Policy Update Magnitude: 0.02508
Value Function Update Magnitude: 0.02303

Collected Steps per Second: 5,137.93344
Overall Steps per Second: 4,219.73434

Timestep Collection Time: 9.73232
Timestep Consumption Time: 2.11772
PPO Batch Consumption Time: 0.35806
Total Iteration Time: 11.85004

Cumulative Model Updates: 11,479
Cumulative Timesteps: 191,662,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,833.56968
Policy Entropy: 0.38720
Value Function Loss: 1.08845

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.05439
Policy Update Magnitude: 0.02096
Value Function Update Magnitude: 0.02142

Collected Steps per Second: 4,579.57584
Overall Steps per Second: 4,095.49105

Timestep Collection Time: 10.92416
Timestep Consumption Time: 1.29123
PPO Batch Consumption Time: 0.04465
Total Iteration Time: 12.21538

Cumulative Model Updates: 11,482
Cumulative Timesteps: 191,712,866

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 191712866...
Checkpoint 191712866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,454.77129
Policy Entropy: 0.38316
Value Function Loss: 1.11184

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04985
Policy Update Magnitude: 0.01766
Value Function Update Magnitude: 0.01947

Collected Steps per Second: 5,260.10085
Overall Steps per Second: 2,423.64182

Timestep Collection Time: 9.50780
Timestep Consumption Time: 11.12726
PPO Batch Consumption Time: 3.37324
Total Iteration Time: 20.63506

Cumulative Model Updates: 11,485
Cumulative Timesteps: 191,762,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,319.69640
Policy Entropy: 0.38343
Value Function Loss: 1.09601

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.03091
Policy Update Magnitude: 0.01913
Value Function Update Magnitude: 0.02179

Collected Steps per Second: 5,410.74235
Overall Steps per Second: 4,835.10940

Timestep Collection Time: 9.24753
Timestep Consumption Time: 1.10094
PPO Batch Consumption Time: 0.03796
Total Iteration Time: 10.34847

Cumulative Model Updates: 11,488
Cumulative Timesteps: 191,812,914

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 191812914...
Checkpoint 191812914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,340.18218
Policy Entropy: 0.38083
Value Function Loss: 1.07321

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02626
Policy Update Magnitude: 0.02045
Value Function Update Magnitude: 0.02359

Collected Steps per Second: 5,726.77328
Overall Steps per Second: 3,821.66140

Timestep Collection Time: 8.73267
Timestep Consumption Time: 4.35327
PPO Batch Consumption Time: 1.11633
Total Iteration Time: 13.08593

Cumulative Model Updates: 11,491
Cumulative Timesteps: 191,862,924

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,395.66315
Policy Entropy: 0.38392
Value Function Loss: 1.05654

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.01563
Policy Update Magnitude: 0.02135
Value Function Update Magnitude: 0.02335

Collected Steps per Second: 4,744.32335
Overall Steps per Second: 1,745.43392

Timestep Collection Time: 10.54734
Timestep Consumption Time: 18.12175
PPO Batch Consumption Time: 5.71544
Total Iteration Time: 28.66909

Cumulative Model Updates: 11,494
Cumulative Timesteps: 191,912,964

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 191912964...
Checkpoint 191912964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,100.35157
Policy Entropy: 0.38488
Value Function Loss: 1.03061

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.02236
Value Function Update Magnitude: 0.02287

Collected Steps per Second: 5,064.26890
Overall Steps per Second: 4,448.29557

Timestep Collection Time: 9.87744
Timestep Consumption Time: 1.36777
PPO Batch Consumption Time: 0.11958
Total Iteration Time: 11.24521

Cumulative Model Updates: 11,497
Cumulative Timesteps: 191,962,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,201.98941
Policy Entropy: 0.39361
Value Function Loss: 0.92862

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02497
Policy Update Magnitude: 0.02118
Value Function Update Magnitude: 0.02005

Collected Steps per Second: 4,729.81868
Overall Steps per Second: 4,205.52328

Timestep Collection Time: 10.57250
Timestep Consumption Time: 1.31806
PPO Batch Consumption Time: 0.11305
Total Iteration Time: 11.89055

Cumulative Model Updates: 11,500
Cumulative Timesteps: 192,012,992

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 192012992...
Checkpoint 192012992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,275.80249
Policy Entropy: 0.39551
Value Function Loss: 0.93007

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03407
Policy Update Magnitude: 0.02094
Value Function Update Magnitude: 0.02286

Collected Steps per Second: 4,572.12012
Overall Steps per Second: 4,053.50201

Timestep Collection Time: 10.93760
Timestep Consumption Time: 1.39939
PPO Batch Consumption Time: 0.12459
Total Iteration Time: 12.33699

Cumulative Model Updates: 11,503
Cumulative Timesteps: 192,063,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,234.26692
Policy Entropy: 0.39989
Value Function Loss: 0.88457

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02346
Policy Update Magnitude: 0.02235
Value Function Update Magnitude: 0.02250

Collected Steps per Second: 4,922.92897
Overall Steps per Second: 4,330.10408

Timestep Collection Time: 10.16021
Timestep Consumption Time: 1.39101
PPO Batch Consumption Time: 0.11556
Total Iteration Time: 11.55122

Cumulative Model Updates: 11,506
Cumulative Timesteps: 192,113,018

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 192113018...
Checkpoint 192113018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,707.41025
Policy Entropy: 0.39308
Value Function Loss: 0.90678

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03651
Policy Update Magnitude: 0.02071
Value Function Update Magnitude: 0.01987

Collected Steps per Second: 4,962.82677
Overall Steps per Second: 4,419.87044

Timestep Collection Time: 10.07893
Timestep Consumption Time: 1.23814
PPO Batch Consumption Time: 0.11406
Total Iteration Time: 11.31707

Cumulative Model Updates: 11,509
Cumulative Timesteps: 192,163,038

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,191.19333
Policy Entropy: 0.39004
Value Function Loss: 0.97306

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02178
Policy Update Magnitude: 0.02204
Value Function Update Magnitude: 0.02512

Collected Steps per Second: 6,609.02027
Overall Steps per Second: 5,749.21046

Timestep Collection Time: 7.56602
Timestep Consumption Time: 1.13152
PPO Batch Consumption Time: 0.10988
Total Iteration Time: 8.69754

Cumulative Model Updates: 11,512
Cumulative Timesteps: 192,213,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 192213042...
Checkpoint 192213042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,566.80079
Policy Entropy: 0.38393
Value Function Loss: 1.03215

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01513
Policy Update Magnitude: 0.02192
Value Function Update Magnitude: 0.02144

Collected Steps per Second: 5,335.70525
Overall Steps per Second: 4,760.90640

Timestep Collection Time: 9.37571
Timestep Consumption Time: 1.13196
PPO Batch Consumption Time: 0.10804
Total Iteration Time: 10.50766

Cumulative Model Updates: 11,515
Cumulative Timesteps: 192,263,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,101.16368
Policy Entropy: 0.38698
Value Function Loss: 1.13274

Mean KL Divergence: 0.00128
SB3 Clip Fraction: 0.01338
Policy Update Magnitude: 0.02356
Value Function Update Magnitude: 0.02425

Collected Steps per Second: 5,070.16196
Overall Steps per Second: 4,541.21535

Timestep Collection Time: 9.86398
Timestep Consumption Time: 1.14893
PPO Batch Consumption Time: 0.11255
Total Iteration Time: 11.01291

Cumulative Model Updates: 11,518
Cumulative Timesteps: 192,313,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 192313080...
Checkpoint 192313080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,780.13883
Policy Entropy: 0.39194
Value Function Loss: 1.08494

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01534
Policy Update Magnitude: 0.02636
Value Function Update Magnitude: 0.02429

Collected Steps per Second: 5,045.29199
Overall Steps per Second: 3,968.29071

Timestep Collection Time: 9.91419
Timestep Consumption Time: 2.69073
PPO Batch Consumption Time: 0.55775
Total Iteration Time: 12.60492

Cumulative Model Updates: 11,521
Cumulative Timesteps: 192,363,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,369.56612
Policy Entropy: 0.39888
Value Function Loss: 1.03006

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.02428
Value Function Update Magnitude: 0.02408

Collected Steps per Second: 6,024.29448
Overall Steps per Second: 4,865.91085

Timestep Collection Time: 8.30205
Timestep Consumption Time: 1.97639
PPO Batch Consumption Time: 0.33281
Total Iteration Time: 10.27845

Cumulative Model Updates: 11,524
Cumulative Timesteps: 192,413,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 192413114...
Checkpoint 192413114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,696.29945
Policy Entropy: 0.39849
Value Function Loss: 0.91260

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.01340
Policy Update Magnitude: 0.02465
Value Function Update Magnitude: 0.02899

Collected Steps per Second: 5,733.40377
Overall Steps per Second: 2,920.31059

Timestep Collection Time: 8.72082
Timestep Consumption Time: 8.40064
PPO Batch Consumption Time: 2.48017
Total Iteration Time: 17.12147

Cumulative Model Updates: 11,527
Cumulative Timesteps: 192,463,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,754.59822
Policy Entropy: 0.40180
Value Function Loss: 0.92744

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02586
Policy Update Magnitude: 0.02492
Value Function Update Magnitude: 0.02566

Collected Steps per Second: 5,654.51273
Overall Steps per Second: 3,352.28591

Timestep Collection Time: 8.84320
Timestep Consumption Time: 6.07319
PPO Batch Consumption Time: 1.70334
Total Iteration Time: 14.91639

Cumulative Model Updates: 11,530
Cumulative Timesteps: 192,513,118

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 192513118...
Checkpoint 192513118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,129.23824
Policy Entropy: 0.39127
Value Function Loss: 0.87647

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03603
Policy Update Magnitude: 0.02308
Value Function Update Magnitude: 0.02289

Collected Steps per Second: 5,403.65081
Overall Steps per Second: 4,777.65836

Timestep Collection Time: 9.25633
Timestep Consumption Time: 1.21281
PPO Batch Consumption Time: 0.04081
Total Iteration Time: 10.46915

Cumulative Model Updates: 11,533
Cumulative Timesteps: 192,563,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,902.72162
Policy Entropy: 0.39031
Value Function Loss: 0.91489

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.02124
Value Function Update Magnitude: 0.02360

Collected Steps per Second: 5,501.02945
Overall Steps per Second: 4,870.77378

Timestep Collection Time: 9.09430
Timestep Consumption Time: 1.17676
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 10.27106

Cumulative Model Updates: 11,536
Cumulative Timesteps: 192,613,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 192613164...
Checkpoint 192613164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,879.43828
Policy Entropy: 0.38907
Value Function Loss: 0.91098

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03739
Policy Update Magnitude: 0.02294
Value Function Update Magnitude: 0.02403

Collected Steps per Second: 5,357.77318
Overall Steps per Second: 4,776.87962

Timestep Collection Time: 9.33559
Timestep Consumption Time: 1.13526
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 10.47085

Cumulative Model Updates: 11,539
Cumulative Timesteps: 192,663,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,786.27902
Policy Entropy: 0.39170
Value Function Loss: 0.92800

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03411
Policy Update Magnitude: 0.02152
Value Function Update Magnitude: 0.02050

Collected Steps per Second: 5,623.93134
Overall Steps per Second: 4,996.23299

Timestep Collection Time: 8.89271
Timestep Consumption Time: 1.11723
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 10.00994

Cumulative Model Updates: 11,542
Cumulative Timesteps: 192,713,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 192713194...
Checkpoint 192713194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,267.93316
Policy Entropy: 0.39300
Value Function Loss: 0.97109

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03929
Policy Update Magnitude: 0.01970
Value Function Update Magnitude: 0.02198

Collected Steps per Second: 5,736.73942
Overall Steps per Second: 5,048.40022

Timestep Collection Time: 8.71889
Timestep Consumption Time: 1.18880
PPO Batch Consumption Time: 0.04800
Total Iteration Time: 9.90769

Cumulative Model Updates: 11,545
Cumulative Timesteps: 192,763,212

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,240.61816
Policy Entropy: 0.39726
Value Function Loss: 0.92797

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03500
Policy Update Magnitude: 0.01927
Value Function Update Magnitude: 0.02030

Collected Steps per Second: 5,389.68636
Overall Steps per Second: 4,785.40640

Timestep Collection Time: 9.27809
Timestep Consumption Time: 1.17160
PPO Batch Consumption Time: 0.04733
Total Iteration Time: 10.44969

Cumulative Model Updates: 11,548
Cumulative Timesteps: 192,813,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 192813218...
Checkpoint 192813218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,521.51821
Policy Entropy: 0.39971
Value Function Loss: 0.91862

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03469
Policy Update Magnitude: 0.01851
Value Function Update Magnitude: 0.02075

Collected Steps per Second: 5,403.90652
Overall Steps per Second: 4,808.89022

Timestep Collection Time: 9.25516
Timestep Consumption Time: 1.14516
PPO Batch Consumption Time: 0.04298
Total Iteration Time: 10.40032

Cumulative Model Updates: 11,551
Cumulative Timesteps: 192,863,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,635.47556
Policy Entropy: 0.40121
Value Function Loss: 0.87602

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01575
Policy Update Magnitude: 0.01994
Value Function Update Magnitude: 0.02048

Collected Steps per Second: 5,527.93387
Overall Steps per Second: 4,002.53467

Timestep Collection Time: 9.05076
Timestep Consumption Time: 3.44932
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 12.50008

Cumulative Model Updates: 11,554
Cumulative Timesteps: 192,913,264

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 192913264...
Checkpoint 192913264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,029.26081
Policy Entropy: 0.39653
Value Function Loss: 0.87996

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.02188
Policy Update Magnitude: 0.02146
Value Function Update Magnitude: 0.01913

Collected Steps per Second: 5,538.77180
Overall Steps per Second: 3,302.23195

Timestep Collection Time: 9.03016
Timestep Consumption Time: 6.11596
PPO Batch Consumption Time: 0.04014
Total Iteration Time: 15.14612

Cumulative Model Updates: 11,557
Cumulative Timesteps: 192,963,280

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,243.97717
Policy Entropy: 0.39616
Value Function Loss: 0.96012

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02297
Policy Update Magnitude: 0.01986
Value Function Update Magnitude: 0.02207

Collected Steps per Second: 5,480.41565
Overall Steps per Second: 4,886.78441

Timestep Collection Time: 9.12850
Timestep Consumption Time: 1.10890
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 10.23741

Cumulative Model Updates: 11,560
Cumulative Timesteps: 193,013,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 193013308...
Checkpoint 193013308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,746.85071
Policy Entropy: 0.39440
Value Function Loss: 1.02107

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.02122
Policy Update Magnitude: 0.02145
Value Function Update Magnitude: 0.02075

Collected Steps per Second: 5,435.79887
Overall Steps per Second: 4,903.49911

Timestep Collection Time: 9.20306
Timestep Consumption Time: 0.99904
PPO Batch Consumption Time: 0.03863
Total Iteration Time: 10.20210

Cumulative Model Updates: 11,563
Cumulative Timesteps: 193,063,334

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,307.27469
Policy Entropy: 0.40328
Value Function Loss: 0.98896

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02321
Policy Update Magnitude: 0.02185
Value Function Update Magnitude: 0.02322

Collected Steps per Second: 5,156.22840
Overall Steps per Second: 4,572.61028

Timestep Collection Time: 9.70322
Timestep Consumption Time: 1.23846
PPO Batch Consumption Time: 0.07793
Total Iteration Time: 10.94167

Cumulative Model Updates: 11,566
Cumulative Timesteps: 193,113,366

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 193113366...
Checkpoint 193113366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,484.26961
Policy Entropy: 0.40236
Value Function Loss: 0.96412

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.03060
Policy Update Magnitude: 0.02199
Value Function Update Magnitude: 0.02232

Collected Steps per Second: 5,702.74614
Overall Steps per Second: 4,970.35762

Timestep Collection Time: 8.77051
Timestep Consumption Time: 1.29235
PPO Batch Consumption Time: 0.04315
Total Iteration Time: 10.06286

Cumulative Model Updates: 11,569
Cumulative Timesteps: 193,163,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,789.53126
Policy Entropy: 0.40433
Value Function Loss: 0.92198

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02605
Policy Update Magnitude: 0.02142
Value Function Update Magnitude: 0.02202

Collected Steps per Second: 5,498.81108
Overall Steps per Second: 2,469.92038

Timestep Collection Time: 9.09833
Timestep Consumption Time: 11.15738
PPO Batch Consumption Time: 0.04214
Total Iteration Time: 20.25571

Cumulative Model Updates: 11,572
Cumulative Timesteps: 193,213,412

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 193213412...
Checkpoint 193213412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,283.71649
Policy Entropy: 0.40685
Value Function Loss: 1.03638

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04322
Policy Update Magnitude: 0.02343
Value Function Update Magnitude: 0.02295

Collected Steps per Second: 5,537.42668
Overall Steps per Second: 4,298.95224

Timestep Collection Time: 9.02983
Timestep Consumption Time: 2.60138
PPO Batch Consumption Time: 0.04566
Total Iteration Time: 11.63121

Cumulative Model Updates: 11,575
Cumulative Timesteps: 193,263,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,811.18184
Policy Entropy: 0.41160
Value Function Loss: 1.04109

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04345
Policy Update Magnitude: 0.02334
Value Function Update Magnitude: 0.02036

Collected Steps per Second: 5,320.08544
Overall Steps per Second: 4,793.10771

Timestep Collection Time: 9.40286
Timestep Consumption Time: 1.03380
PPO Batch Consumption Time: 0.04248
Total Iteration Time: 10.43665

Cumulative Model Updates: 11,578
Cumulative Timesteps: 193,313,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 193313438...
Checkpoint 193313438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,242.86244
Policy Entropy: 0.40430
Value Function Loss: 1.09057

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06049
Policy Update Magnitude: 0.02130
Value Function Update Magnitude: 0.02230

Collected Steps per Second: 5,661.90461
Overall Steps per Second: 2,467.87295

Timestep Collection Time: 8.83448
Timestep Consumption Time: 11.43398
PPO Batch Consumption Time: 0.04483
Total Iteration Time: 20.26847

Cumulative Model Updates: 11,581
Cumulative Timesteps: 193,363,458

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,091.84755
Policy Entropy: 0.40164
Value Function Loss: 1.01774

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04899
Policy Update Magnitude: 0.01836
Value Function Update Magnitude: 0.02799

Collected Steps per Second: 5,466.33796
Overall Steps per Second: 4,909.47181

Timestep Collection Time: 9.15238
Timestep Consumption Time: 1.03813
PPO Batch Consumption Time: 0.04348
Total Iteration Time: 10.19051

Cumulative Model Updates: 11,584
Cumulative Timesteps: 193,413,488

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 193413488...
Checkpoint 193413488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,900.91233
Policy Entropy: 0.40181
Value Function Loss: 1.01341

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.04338
Policy Update Magnitude: 0.01959
Value Function Update Magnitude: 0.02412

Collected Steps per Second: 4,882.55495
Overall Steps per Second: 4,384.71210

Timestep Collection Time: 10.25078
Timestep Consumption Time: 1.16388
PPO Batch Consumption Time: 0.04198
Total Iteration Time: 11.41466

Cumulative Model Updates: 11,587
Cumulative Timesteps: 193,463,538

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,557.75712
Policy Entropy: 0.40590
Value Function Loss: 0.98082

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03402
Policy Update Magnitude: 0.02022
Value Function Update Magnitude: 0.02264

Collected Steps per Second: 5,489.22076
Overall Steps per Second: 4,881.61927

Timestep Collection Time: 9.11095
Timestep Consumption Time: 1.13401
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 10.24496

Cumulative Model Updates: 11,590
Cumulative Timesteps: 193,513,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 193513550...
Checkpoint 193513550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,138.52610
Policy Entropy: 0.40851
Value Function Loss: 0.97477

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03689
Policy Update Magnitude: 0.01987
Value Function Update Magnitude: 0.02133

Collected Steps per Second: 6,084.55466
Overall Steps per Second: 5,340.49595

Timestep Collection Time: 8.22246
Timestep Consumption Time: 1.14559
PPO Batch Consumption Time: 0.04348
Total Iteration Time: 9.36804

Cumulative Model Updates: 11,593
Cumulative Timesteps: 193,563,580

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,634.17981
Policy Entropy: 0.40541
Value Function Loss: 0.90939

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03533
Policy Update Magnitude: 0.01800
Value Function Update Magnitude: 0.02000

Collected Steps per Second: 5,813.51697
Overall Steps per Second: 5,149.46480

Timestep Collection Time: 8.60133
Timestep Consumption Time: 1.10919
PPO Batch Consumption Time: 0.04248
Total Iteration Time: 9.71052

Cumulative Model Updates: 11,596
Cumulative Timesteps: 193,613,584

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 193613584...
Checkpoint 193613584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,037.05716
Policy Entropy: 0.40718
Value Function Loss: 0.83665

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.05296
Policy Update Magnitude: 0.01886
Value Function Update Magnitude: 0.02224

Collected Steps per Second: 5,824.63708
Overall Steps per Second: 5,099.86139

Timestep Collection Time: 8.58663
Timestep Consumption Time: 1.22030
PPO Batch Consumption Time: 0.04081
Total Iteration Time: 9.80693

Cumulative Model Updates: 11,599
Cumulative Timesteps: 193,663,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,711.68959
Policy Entropy: 0.41118
Value Function Loss: 0.80759

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03736
Policy Update Magnitude: 0.01749
Value Function Update Magnitude: 0.02110

Collected Steps per Second: 5,451.71706
Overall Steps per Second: 4,825.39665

Timestep Collection Time: 9.17399
Timestep Consumption Time: 1.19075
PPO Batch Consumption Time: 0.04047
Total Iteration Time: 10.36474

Cumulative Model Updates: 11,602
Cumulative Timesteps: 193,713,612

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 193713612...
Checkpoint 193713612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,069.81819
Policy Entropy: 0.41040
Value Function Loss: 0.83263

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.01868
Value Function Update Magnitude: 0.02120

Collected Steps per Second: 5,480.75509
Overall Steps per Second: 4,873.11495

Timestep Collection Time: 9.12976
Timestep Consumption Time: 1.13841
PPO Batch Consumption Time: 0.04332
Total Iteration Time: 10.26818

Cumulative Model Updates: 11,605
Cumulative Timesteps: 193,763,650

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,721.28700
Policy Entropy: 0.40552
Value Function Loss: 0.87524

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02392
Policy Update Magnitude: 0.02083
Value Function Update Magnitude: 0.02052

Collected Steps per Second: 6,008.62060
Overall Steps per Second: 5,226.38188

Timestep Collection Time: 8.32770
Timestep Consumption Time: 1.24642
PPO Batch Consumption Time: 0.04198
Total Iteration Time: 9.57412

Cumulative Model Updates: 11,608
Cumulative Timesteps: 193,813,688

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 193813688...
Checkpoint 193813688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,623.08094
Policy Entropy: 0.40721
Value Function Loss: 0.82779

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 0.02271
Value Function Update Magnitude: 0.02065

Collected Steps per Second: 5,475.32549
Overall Steps per Second: 4,792.27818

Timestep Collection Time: 9.13772
Timestep Consumption Time: 1.30241
PPO Batch Consumption Time: 0.04198
Total Iteration Time: 10.44013

Cumulative Model Updates: 11,611
Cumulative Timesteps: 193,863,720

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,709.73564
Policy Entropy: 0.40831
Value Function Loss: 0.86500

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03621
Policy Update Magnitude: 0.02619
Value Function Update Magnitude: 0.01869

Collected Steps per Second: 5,439.17298
Overall Steps per Second: 4,830.91503

Timestep Collection Time: 9.19552
Timestep Consumption Time: 1.15780
PPO Batch Consumption Time: 0.05101
Total Iteration Time: 10.35332

Cumulative Model Updates: 11,614
Cumulative Timesteps: 193,913,736

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 193913736...
Checkpoint 193913736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,412.48088
Policy Entropy: 0.40672
Value Function Loss: 0.88085

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03479
Policy Update Magnitude: 0.02351
Value Function Update Magnitude: 0.01943

Collected Steps per Second: 5,172.52724
Overall Steps per Second: 4,633.56048

Timestep Collection Time: 9.66877
Timestep Consumption Time: 1.12465
PPO Batch Consumption Time: 0.04432
Total Iteration Time: 10.79343

Cumulative Model Updates: 11,617
Cumulative Timesteps: 193,963,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,294.81947
Policy Entropy: 0.40466
Value Function Loss: 0.91630

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02449
Policy Update Magnitude: 0.02069
Value Function Update Magnitude: 0.02022

Collected Steps per Second: 5,299.83924
Overall Steps per Second: 4,716.13970

Timestep Collection Time: 9.44217
Timestep Consumption Time: 1.16862
PPO Batch Consumption Time: 0.03980
Total Iteration Time: 10.61080

Cumulative Model Updates: 11,620
Cumulative Timesteps: 194,013,790

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 194013790...
Checkpoint 194013790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,908.36942
Policy Entropy: 0.40353
Value Function Loss: 0.84846

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02105
Policy Update Magnitude: 0.02160
Value Function Update Magnitude: 0.02026

Collected Steps per Second: 5,474.05063
Overall Steps per Second: 4,810.45710

Timestep Collection Time: 9.13620
Timestep Consumption Time: 1.26032
PPO Batch Consumption Time: 0.05051
Total Iteration Time: 10.39652

Cumulative Model Updates: 11,623
Cumulative Timesteps: 194,063,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,075.13474
Policy Entropy: 0.40916
Value Function Loss: 0.79530

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01739
Policy Update Magnitude: 0.02362
Value Function Update Magnitude: 0.01683

Collected Steps per Second: 5,553.52383
Overall Steps per Second: 4,927.94409

Timestep Collection Time: 9.00329
Timestep Consumption Time: 1.14293
PPO Batch Consumption Time: 0.04515
Total Iteration Time: 10.14622

Cumulative Model Updates: 11,626
Cumulative Timesteps: 194,113,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 194113802...
Checkpoint 194113802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,569.68271
Policy Entropy: 0.41248
Value Function Loss: 0.73624

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02090
Policy Update Magnitude: 0.02380
Value Function Update Magnitude: 0.02291

Collected Steps per Second: 5,375.31192
Overall Steps per Second: 4,777.60893

Timestep Collection Time: 9.30290
Timestep Consumption Time: 1.16384
PPO Batch Consumption Time: 0.04097
Total Iteration Time: 10.46674

Cumulative Model Updates: 11,629
Cumulative Timesteps: 194,163,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,745.60693
Policy Entropy: 0.41508
Value Function Loss: 0.75051

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03705
Policy Update Magnitude: 0.02218
Value Function Update Magnitude: 0.02176

Collected Steps per Second: 5,644.16304
Overall Steps per Second: 5,026.91230

Timestep Collection Time: 8.86261
Timestep Consumption Time: 1.08823
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 9.95084

Cumulative Model Updates: 11,632
Cumulative Timesteps: 194,213,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 194213830...
Checkpoint 194213830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,604.40946
Policy Entropy: 0.41543
Value Function Loss: 0.70976

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 0.01944
Value Function Update Magnitude: 0.01949

Collected Steps per Second: 5,171.39296
Overall Steps per Second: 4,577.09244

Timestep Collection Time: 9.66974
Timestep Consumption Time: 1.25554
PPO Batch Consumption Time: 0.04315
Total Iteration Time: 10.92528

Cumulative Model Updates: 11,635
Cumulative Timesteps: 194,263,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,005.93940
Policy Entropy: 0.41591
Value Function Loss: 0.81078

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02533
Policy Update Magnitude: 0.02035
Value Function Update Magnitude: 0.01953

Collected Steps per Second: 6,014.56314
Overall Steps per Second: 5,253.25595

Timestep Collection Time: 8.31914
Timestep Consumption Time: 1.20562
PPO Batch Consumption Time: 0.05870
Total Iteration Time: 9.52476

Cumulative Model Updates: 11,638
Cumulative Timesteps: 194,313,872

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 194313872...
Checkpoint 194313872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,303.96158
Policy Entropy: 0.41516
Value Function Loss: 0.77035

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01827
Policy Update Magnitude: 0.02102
Value Function Update Magnitude: 0.01862

Collected Steps per Second: 5,317.18035
Overall Steps per Second: 4,716.21837

Timestep Collection Time: 9.41138
Timestep Consumption Time: 1.19924
PPO Batch Consumption Time: 0.04499
Total Iteration Time: 10.61062

Cumulative Model Updates: 11,641
Cumulative Timesteps: 194,363,914

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,295.05106
Policy Entropy: 0.41487
Value Function Loss: 0.82923

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01963
Policy Update Magnitude: 0.02241
Value Function Update Magnitude: 0.01994

Collected Steps per Second: 5,437.22199
Overall Steps per Second: 4,805.67323

Timestep Collection Time: 9.19734
Timestep Consumption Time: 1.20869
PPO Batch Consumption Time: 0.04348
Total Iteration Time: 10.40603

Cumulative Model Updates: 11,644
Cumulative Timesteps: 194,413,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 194413922...
Checkpoint 194413922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,853.05703
Policy Entropy: 0.41498
Value Function Loss: 0.80125

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.05518
Policy Update Magnitude: 0.02155
Value Function Update Magnitude: 0.02024

Collected Steps per Second: 5,379.79683
Overall Steps per Second: 4,749.08417

Timestep Collection Time: 9.30147
Timestep Consumption Time: 1.23530
PPO Batch Consumption Time: 0.05101
Total Iteration Time: 10.53677

Cumulative Model Updates: 11,647
Cumulative Timesteps: 194,463,962

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,487.11343
Policy Entropy: 0.41630
Value Function Loss: 0.76358

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02775
Policy Update Magnitude: 0.02081
Value Function Update Magnitude: 0.02391

Collected Steps per Second: 5,389.19098
Overall Steps per Second: 4,736.80352

Timestep Collection Time: 9.28006
Timestep Consumption Time: 1.27812
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 10.55817

Cumulative Model Updates: 11,650
Cumulative Timesteps: 194,513,974

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 194513974...
Checkpoint 194513974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,254.69901
Policy Entropy: 0.41208
Value Function Loss: 0.72065

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03527
Policy Update Magnitude: 0.01887
Value Function Update Magnitude: 0.02501

Collected Steps per Second: 6,051.69132
Overall Steps per Second: 5,342.09159

Timestep Collection Time: 8.26381
Timestep Consumption Time: 1.09770
PPO Batch Consumption Time: 0.03880
Total Iteration Time: 9.36150

Cumulative Model Updates: 11,653
Cumulative Timesteps: 194,563,984

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,515.75153
Policy Entropy: 0.41555
Value Function Loss: 0.72155

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02928
Policy Update Magnitude: 0.01869
Value Function Update Magnitude: 0.02126

Collected Steps per Second: 5,401.67084
Overall Steps per Second: 4,817.52590

Timestep Collection Time: 9.25714
Timestep Consumption Time: 1.12247
PPO Batch Consumption Time: 0.04298
Total Iteration Time: 10.37960

Cumulative Model Updates: 11,656
Cumulative Timesteps: 194,613,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 194613988...
Checkpoint 194613988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,216.67795
Policy Entropy: 0.41480
Value Function Loss: 0.75938

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.03122
Policy Update Magnitude: 0.01961
Value Function Update Magnitude: 0.01922

Collected Steps per Second: 9,182.49002
Overall Steps per Second: 7,894.84404

Timestep Collection Time: 5.44776
Timestep Consumption Time: 0.88853
PPO Batch Consumption Time: 0.06405
Total Iteration Time: 6.33629

Cumulative Model Updates: 11,659
Cumulative Timesteps: 194,664,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,739.31207
Policy Entropy: 0.42090
Value Function Loss: 0.77434

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03599
Policy Update Magnitude: 0.02079
Value Function Update Magnitude: 0.01889

Collected Steps per Second: 19,712.22811
Overall Steps per Second: 14,566.97154

Timestep Collection Time: 2.53782
Timestep Consumption Time: 0.89639
PPO Batch Consumption Time: 0.07793
Total Iteration Time: 3.43421

Cumulative Model Updates: 11,662
Cumulative Timesteps: 194,714,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 194714038...
Checkpoint 194714038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,313.21195
Policy Entropy: 0.41206
Value Function Loss: 0.76824

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.05201
Policy Update Magnitude: 0.01923
Value Function Update Magnitude: 0.01977

Collected Steps per Second: 21,062.27191
Overall Steps per Second: 15,555.93044

Timestep Collection Time: 2.37467
Timestep Consumption Time: 0.84056
PPO Batch Consumption Time: 0.06506
Total Iteration Time: 3.21524

Cumulative Model Updates: 11,665
Cumulative Timesteps: 194,764,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,101.06208
Policy Entropy: 0.41665
Value Function Loss: 0.79779

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04417
Policy Update Magnitude: 0.02031
Value Function Update Magnitude: 0.03463

Collected Steps per Second: 19,466.46908
Overall Steps per Second: 14,127.77609

Timestep Collection Time: 2.57098
Timestep Consumption Time: 0.97154
PPO Batch Consumption Time: 0.11372
Total Iteration Time: 3.54252

Cumulative Model Updates: 11,668
Cumulative Timesteps: 194,814,102

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 194814102...
Checkpoint 194814102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,699.56833
Policy Entropy: 0.41124
Value Function Loss: 0.86139

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05455
Policy Update Magnitude: 0.02019
Value Function Update Magnitude: 0.02887

Collected Steps per Second: 21,305.83560
Overall Steps per Second: 15,892.63720

Timestep Collection Time: 2.34771
Timestep Consumption Time: 0.79966
PPO Batch Consumption Time: 0.06921
Total Iteration Time: 3.14737

Cumulative Model Updates: 11,671
Cumulative Timesteps: 194,864,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,409.67719
Policy Entropy: 0.41066
Value Function Loss: 0.83487

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.04257
Policy Update Magnitude: 0.01806
Value Function Update Magnitude: 0.02490

Collected Steps per Second: 23,435.11680
Overall Steps per Second: 16,533.44714

Timestep Collection Time: 2.13440
Timestep Consumption Time: 0.89098
PPO Batch Consumption Time: 0.10040
Total Iteration Time: 3.02538

Cumulative Model Updates: 11,674
Cumulative Timesteps: 194,914,142

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 194914142...
Checkpoint 194914142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,077.41582
Policy Entropy: 0.41208
Value Function Loss: 0.79560

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02875
Policy Update Magnitude: 0.01875
Value Function Update Magnitude: 0.02461

Collected Steps per Second: 23,453.34228
Overall Steps per Second: 16,612.30631

Timestep Collection Time: 2.13402
Timestep Consumption Time: 0.87880
PPO Batch Consumption Time: 0.07769
Total Iteration Time: 3.01283

Cumulative Model Updates: 11,677
Cumulative Timesteps: 194,964,192

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,335.37049
Policy Entropy: 0.41723
Value Function Loss: 0.74881

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.02185
Value Function Update Magnitude: 0.02535

Collected Steps per Second: 23,493.68691
Overall Steps per Second: 17,012.90352

Timestep Collection Time: 2.12908
Timestep Consumption Time: 0.81104
PPO Batch Consumption Time: 0.06141
Total Iteration Time: 2.94012

Cumulative Model Updates: 11,680
Cumulative Timesteps: 195,014,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 195014212...
Checkpoint 195014212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,826.13737
Policy Entropy: 0.42075
Value Function Loss: 0.72055

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.02132
Policy Update Magnitude: 0.02211
Value Function Update Magnitude: 0.02275

Collected Steps per Second: 20,790.22125
Overall Steps per Second: 15,803.94565

Timestep Collection Time: 2.40613
Timestep Consumption Time: 0.75915
PPO Batch Consumption Time: 0.03277
Total Iteration Time: 3.16529

Cumulative Model Updates: 11,683
Cumulative Timesteps: 195,064,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,963.39228
Policy Entropy: 0.41921
Value Function Loss: 0.72818

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.01079
Policy Update Magnitude: 0.02055
Value Function Update Magnitude: 0.01937

Collected Steps per Second: 17,853.50802
Overall Steps per Second: 13,688.68200

Timestep Collection Time: 2.80225
Timestep Consumption Time: 0.85259
PPO Batch Consumption Time: 0.06804
Total Iteration Time: 3.65484

Cumulative Model Updates: 11,686
Cumulative Timesteps: 195,114,266

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 195114266...
Checkpoint 195114266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,136.16067
Policy Entropy: 0.42218
Value Function Loss: 0.71950

Mean KL Divergence: 0.00121
SB3 Clip Fraction: 0.01255
Policy Update Magnitude: 0.02103
Value Function Update Magnitude: 0.02195

Collected Steps per Second: 19,776.99054
Overall Steps per Second: 15,445.58755

Timestep Collection Time: 2.53031
Timestep Consumption Time: 0.70958
PPO Batch Consumption Time: 0.02848
Total Iteration Time: 3.23989

Cumulative Model Updates: 11,689
Cumulative Timesteps: 195,164,308

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,314.76009
Policy Entropy: 0.42685
Value Function Loss: 0.76038

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02435
Policy Update Magnitude: 0.01985
Value Function Update Magnitude: 0.02107

Collected Steps per Second: 23,238.13709
Overall Steps per Second: 16,108.60091

Timestep Collection Time: 2.15181
Timestep Consumption Time: 0.95237
PPO Batch Consumption Time: 0.10342
Total Iteration Time: 3.10418

Cumulative Model Updates: 11,692
Cumulative Timesteps: 195,214,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 195214312...
Checkpoint 195214312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,925.71001
Policy Entropy: 0.42750
Value Function Loss: 0.72418

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04707
Policy Update Magnitude: 0.01943
Value Function Update Magnitude: 0.02133

Collected Steps per Second: 22,827.44413
Overall Steps per Second: 15,761.20579

Timestep Collection Time: 2.19061
Timestep Consumption Time: 0.98212
PPO Batch Consumption Time: 0.12218
Total Iteration Time: 3.17273

Cumulative Model Updates: 11,695
Cumulative Timesteps: 195,264,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,677.25695
Policy Entropy: 0.42446
Value Function Loss: 0.67242

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01557
Policy Update Magnitude: 0.01842
Value Function Update Magnitude: 0.01971

Collected Steps per Second: 24,086.18439
Overall Steps per Second: 16,662.76105

Timestep Collection Time: 2.07654
Timestep Consumption Time: 0.92512
PPO Batch Consumption Time: 0.08047
Total Iteration Time: 3.00166

Cumulative Model Updates: 11,698
Cumulative Timesteps: 195,314,334

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 195314334...
Checkpoint 195314334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,631.39517
Policy Entropy: 0.42085
Value Function Loss: 0.68330

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.02262
Value Function Update Magnitude: 0.01936

Collected Steps per Second: 19,841.37450
Overall Steps per Second: 14,698.55059

Timestep Collection Time: 2.52140
Timestep Consumption Time: 0.88220
PPO Batch Consumption Time: 0.06221
Total Iteration Time: 3.40360

Cumulative Model Updates: 11,701
Cumulative Timesteps: 195,364,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,581.40812
Policy Entropy: 0.42766
Value Function Loss: 0.71711

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.02101
Policy Update Magnitude: 0.02186
Value Function Update Magnitude: 0.02007

Collected Steps per Second: 17,661.64421
Overall Steps per Second: 13,205.66833

Timestep Collection Time: 2.83213
Timestep Consumption Time: 0.95564
PPO Batch Consumption Time: 0.08781
Total Iteration Time: 3.78777

Cumulative Model Updates: 11,704
Cumulative Timesteps: 195,414,382

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 195414382...
Checkpoint 195414382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,485.81963
Policy Entropy: 0.42665
Value Function Loss: 0.72859

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01581
Policy Update Magnitude: 0.02302
Value Function Update Magnitude: 0.02110

Collected Steps per Second: 21,651.81998
Overall Steps per Second: 16,456.49085

Timestep Collection Time: 2.31149
Timestep Consumption Time: 0.72974
PPO Batch Consumption Time: 0.05237
Total Iteration Time: 3.04123

Cumulative Model Updates: 11,707
Cumulative Timesteps: 195,464,430

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,310.16273
Policy Entropy: 0.42578
Value Function Loss: 0.69923

Mean KL Divergence: 0.00096
SB3 Clip Fraction: 0.00678
Policy Update Magnitude: 0.02178
Value Function Update Magnitude: 0.01875

Collected Steps per Second: 20,542.53801
Overall Steps per Second: 15,018.30200

Timestep Collection Time: 2.43524
Timestep Consumption Time: 0.89576
PPO Batch Consumption Time: 0.08603
Total Iteration Time: 3.33100

Cumulative Model Updates: 11,710
Cumulative Timesteps: 195,514,456

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 195514456...
Checkpoint 195514456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,511.57690
Policy Entropy: 0.42227
Value Function Loss: 0.66688

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02604
Policy Update Magnitude: 0.02237
Value Function Update Magnitude: 0.02012

Collected Steps per Second: 23,066.01031
Overall Steps per Second: 15,826.10372

Timestep Collection Time: 2.16839
Timestep Consumption Time: 0.99196
PPO Batch Consumption Time: 0.11909
Total Iteration Time: 3.16035

Cumulative Model Updates: 11,713
Cumulative Timesteps: 195,564,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,195.25047
Policy Entropy: 0.42331
Value Function Loss: 0.67894

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.02326
Policy Update Magnitude: 0.02124
Value Function Update Magnitude: 0.02145

Collected Steps per Second: 23,885.82425
Overall Steps per Second: 17,350.92458

Timestep Collection Time: 2.09488
Timestep Consumption Time: 0.78900
PPO Batch Consumption Time: 0.06118
Total Iteration Time: 2.88388

Cumulative Model Updates: 11,716
Cumulative Timesteps: 195,614,510

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 195614510...
Checkpoint 195614510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,702.67445
Policy Entropy: 0.42135
Value Function Loss: 0.71692

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03041
Policy Update Magnitude: 0.02522
Value Function Update Magnitude: 0.01974

Collected Steps per Second: 21,680.25909
Overall Steps per Second: 15,199.42421

Timestep Collection Time: 2.30680
Timestep Consumption Time: 0.98359
PPO Batch Consumption Time: 0.11478
Total Iteration Time: 3.29039

Cumulative Model Updates: 11,719
Cumulative Timesteps: 195,664,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,484.44301
Policy Entropy: 0.41857
Value Function Loss: 0.76415

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03797
Policy Update Magnitude: 0.02235
Value Function Update Magnitude: 0.02811

Collected Steps per Second: 23,806.44987
Overall Steps per Second: 16,335.87510

Timestep Collection Time: 2.10061
Timestep Consumption Time: 0.96063
PPO Batch Consumption Time: 0.07504
Total Iteration Time: 3.06124

Cumulative Model Updates: 11,722
Cumulative Timesteps: 195,714,530

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 195714530...
Checkpoint 195714530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,708.45377
Policy Entropy: 0.41899
Value Function Loss: 0.76013

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02511
Policy Update Magnitude: 0.02247
Value Function Update Magnitude: 0.02580

Collected Steps per Second: 19,872.22840
Overall Steps per Second: 14,278.44422

Timestep Collection Time: 2.51738
Timestep Consumption Time: 0.98622
PPO Batch Consumption Time: 0.12081
Total Iteration Time: 3.50360

Cumulative Model Updates: 11,725
Cumulative Timesteps: 195,764,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,844.55612
Policy Entropy: 0.41878
Value Function Loss: 0.69879

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01555
Policy Update Magnitude: 0.02391
Value Function Update Magnitude: 0.02238

Collected Steps per Second: 24,078.42599
Overall Steps per Second: 17,329.66510

Timestep Collection Time: 2.07763
Timestep Consumption Time: 0.80910
PPO Batch Consumption Time: 0.06383
Total Iteration Time: 2.88673

Cumulative Model Updates: 11,728
Cumulative Timesteps: 195,814,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 195814582...
Checkpoint 195814582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,872.54264
Policy Entropy: 0.42913
Value Function Loss: 0.64475

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.02079
Policy Update Magnitude: 0.02395
Value Function Update Magnitude: 0.02486

Collected Steps per Second: 21,061.45222
Overall Steps per Second: 15,127.79329

Timestep Collection Time: 2.37505
Timestep Consumption Time: 0.93158
PPO Batch Consumption Time: 0.09844
Total Iteration Time: 3.30663

Cumulative Model Updates: 11,731
Cumulative Timesteps: 195,864,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,636.67852
Policy Entropy: 0.42549
Value Function Loss: 0.67294

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01982
Policy Update Magnitude: 0.02256
Value Function Update Magnitude: 0.02481

Collected Steps per Second: 19,064.13845
Overall Steps per Second: 14,634.47157

Timestep Collection Time: 2.62514
Timestep Consumption Time: 0.79460
PPO Batch Consumption Time: 0.04554
Total Iteration Time: 3.41973

Cumulative Model Updates: 11,734
Cumulative Timesteps: 195,914,650

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 195914650...
Checkpoint 195914650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,029.81598
Policy Entropy: 0.42525
Value Function Loss: 0.64026

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01816
Policy Update Magnitude: 0.02340
Value Function Update Magnitude: 0.02328

Collected Steps per Second: 21,598.49878
Overall Steps per Second: 16,496.16898

Timestep Collection Time: 2.31572
Timestep Consumption Time: 0.71626
PPO Batch Consumption Time: 0.02927
Total Iteration Time: 3.03198

Cumulative Model Updates: 11,737
Cumulative Timesteps: 195,964,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,676.49029
Policy Entropy: 0.42322
Value Function Loss: 0.66445

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03290
Policy Update Magnitude: 0.02338
Value Function Update Magnitude: 0.02598

Collected Steps per Second: 22,092.61762
Overall Steps per Second: 15,927.03255

Timestep Collection Time: 2.26401
Timestep Consumption Time: 0.87643
PPO Batch Consumption Time: 0.07630
Total Iteration Time: 3.14045

Cumulative Model Updates: 11,740
Cumulative Timesteps: 196,014,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 196014684...
Checkpoint 196014684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,633.50968
Policy Entropy: 0.42596
Value Function Loss: 0.59610

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03121
Policy Update Magnitude: 0.01994
Value Function Update Magnitude: 0.02437

Collected Steps per Second: 19,734.10594
Overall Steps per Second: 14,289.56148

Timestep Collection Time: 2.53500
Timestep Consumption Time: 0.96588
PPO Batch Consumption Time: 0.08377
Total Iteration Time: 3.50088

Cumulative Model Updates: 11,743
Cumulative Timesteps: 196,064,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,261.97681
Policy Entropy: 0.42823
Value Function Loss: 0.56825

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03005
Policy Update Magnitude: 0.01934
Value Function Update Magnitude: 0.02078

Collected Steps per Second: 18,826.45425
Overall Steps per Second: 14,530.86175

Timestep Collection Time: 2.65764
Timestep Consumption Time: 0.78565
PPO Batch Consumption Time: 0.05035
Total Iteration Time: 3.44329

Cumulative Model Updates: 11,746
Cumulative Timesteps: 196,114,744

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 196114744...
Checkpoint 196114744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,632.94301
Policy Entropy: 0.42609
Value Function Loss: 0.57507

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03893
Policy Update Magnitude: 0.02117
Value Function Update Magnitude: 0.02027

Collected Steps per Second: 20,372.65521
Overall Steps per Second: 14,769.70870

Timestep Collection Time: 2.45653
Timestep Consumption Time: 0.93189
PPO Batch Consumption Time: 0.10471
Total Iteration Time: 3.38842

Cumulative Model Updates: 11,749
Cumulative Timesteps: 196,164,790

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,191.55973
Policy Entropy: 0.42049
Value Function Loss: 0.60965

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03773
Policy Update Magnitude: 0.01932
Value Function Update Magnitude: 0.02215

Collected Steps per Second: 23,188.16657
Overall Steps per Second: 16,686.06701

Timestep Collection Time: 2.15670
Timestep Consumption Time: 0.84041
PPO Batch Consumption Time: 0.06833
Total Iteration Time: 2.99711

Cumulative Model Updates: 11,752
Cumulative Timesteps: 196,214,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 196214800...
Checkpoint 196214800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,001.00688
Policy Entropy: 0.41874
Value Function Loss: 0.68576

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02845
Policy Update Magnitude: 0.02042
Value Function Update Magnitude: 0.02068

Collected Steps per Second: 20,772.78343
Overall Steps per Second: 14,766.13374

Timestep Collection Time: 2.40738
Timestep Consumption Time: 0.97929
PPO Batch Consumption Time: 0.11118
Total Iteration Time: 3.38667

Cumulative Model Updates: 11,755
Cumulative Timesteps: 196,264,808

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,899.19203
Policy Entropy: 0.41333
Value Function Loss: 0.67934

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.03103
Policy Update Magnitude: 0.02170
Value Function Update Magnitude: 0.02002

Collected Steps per Second: 21,996.86415
Overall Steps per Second: 15,699.24059

Timestep Collection Time: 2.27523
Timestep Consumption Time: 0.91269
PPO Batch Consumption Time: 0.09161
Total Iteration Time: 3.18792

Cumulative Model Updates: 11,758
Cumulative Timesteps: 196,314,856

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 196314856...
Checkpoint 196314856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,580.70302
Policy Entropy: 0.41754
Value Function Loss: 0.68614

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02507
Policy Update Magnitude: 0.02231
Value Function Update Magnitude: 0.01958

Collected Steps per Second: 23,107.00558
Overall Steps per Second: 16,813.56600

Timestep Collection Time: 2.16428
Timestep Consumption Time: 0.81011
PPO Batch Consumption Time: 0.05787
Total Iteration Time: 2.97438

Cumulative Model Updates: 11,761
Cumulative Timesteps: 196,364,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,262.53226
Policy Entropy: 0.41735
Value Function Loss: 0.65352

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03242
Policy Update Magnitude: 0.02287
Value Function Update Magnitude: 0.01760

Collected Steps per Second: 20,612.36863
Overall Steps per Second: 14,738.16981

Timestep Collection Time: 2.42602
Timestep Consumption Time: 0.96694
PPO Batch Consumption Time: 0.11516
Total Iteration Time: 3.39296

Cumulative Model Updates: 11,764
Cumulative Timesteps: 196,414,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 196414872...
Checkpoint 196414872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,041.98711
Policy Entropy: 0.42202
Value Function Loss: 0.63744

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02470
Policy Update Magnitude: 0.02099
Value Function Update Magnitude: 0.02000

Collected Steps per Second: 22,954.83266
Overall Steps per Second: 15,775.31889

Timestep Collection Time: 2.17924
Timestep Consumption Time: 0.99179
PPO Batch Consumption Time: 0.11619
Total Iteration Time: 3.17103

Cumulative Model Updates: 11,767
Cumulative Timesteps: 196,464,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,722.69408
Policy Entropy: 0.42433
Value Function Loss: 0.60962

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03311
Policy Update Magnitude: 0.02147
Value Function Update Magnitude: 0.02314

Collected Steps per Second: 22,403.88549
Overall Steps per Second: 16,497.16470

Timestep Collection Time: 2.23247
Timestep Consumption Time: 0.79932
PPO Batch Consumption Time: 0.06294
Total Iteration Time: 3.03179

Cumulative Model Updates: 11,770
Cumulative Timesteps: 196,514,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 196514912...
Checkpoint 196514912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,477.22779
Policy Entropy: 0.42317
Value Function Loss: 0.60515

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03721
Policy Update Magnitude: 0.02069
Value Function Update Magnitude: 0.02179

Collected Steps per Second: 20,256.63728
Overall Steps per Second: 14,865.82347

Timestep Collection Time: 2.46843
Timestep Consumption Time: 0.89513
PPO Batch Consumption Time: 0.08610
Total Iteration Time: 3.36355

Cumulative Model Updates: 11,773
Cumulative Timesteps: 196,564,914

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,537.31912
Policy Entropy: 0.42482
Value Function Loss: 0.57607

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.05566
Policy Update Magnitude: 0.01895
Value Function Update Magnitude: 0.01779

Collected Steps per Second: 23,179.13520
Overall Steps per Second: 15,779.08300

Timestep Collection Time: 2.15823
Timestep Consumption Time: 1.01217
PPO Batch Consumption Time: 0.12023
Total Iteration Time: 3.17040

Cumulative Model Updates: 11,776
Cumulative Timesteps: 196,614,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 196614940...
Checkpoint 196614940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,323.35166
Policy Entropy: 0.42396
Value Function Loss: 0.63590

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03976
Policy Update Magnitude: 0.01718
Value Function Update Magnitude: 0.01885

Collected Steps per Second: 22,949.94084
Overall Steps per Second: 16,728.99467

Timestep Collection Time: 2.17987
Timestep Consumption Time: 0.81062
PPO Batch Consumption Time: 0.05770
Total Iteration Time: 2.99050

Cumulative Model Updates: 11,779
Cumulative Timesteps: 196,664,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,780.47539
Policy Entropy: 0.42465
Value Function Loss: 0.60574

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03201
Policy Update Magnitude: 0.02018
Value Function Update Magnitude: 0.01849

Collected Steps per Second: 21,199.82713
Overall Steps per Second: 14,775.65163

Timestep Collection Time: 2.35898
Timestep Consumption Time: 1.02564
PPO Batch Consumption Time: 0.12704
Total Iteration Time: 3.38462

Cumulative Model Updates: 11,782
Cumulative Timesteps: 196,714,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 196714978...
Checkpoint 196714978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,563.22617
Policy Entropy: 0.41957
Value Function Loss: 0.63676

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03331
Policy Update Magnitude: 0.02035
Value Function Update Magnitude: 0.01867

Collected Steps per Second: 22,707.88587
Overall Steps per Second: 15,656.67238

Timestep Collection Time: 2.20205
Timestep Consumption Time: 0.99173
PPO Batch Consumption Time: 0.11561
Total Iteration Time: 3.19378

Cumulative Model Updates: 11,785
Cumulative Timesteps: 196,764,982

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,937.29800
Policy Entropy: 0.41548
Value Function Loss: 0.60125

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02964
Policy Update Magnitude: 0.01891
Value Function Update Magnitude: 0.02493

Collected Steps per Second: 23,078.97159
Overall Steps per Second: 16,777.65177

Timestep Collection Time: 2.16743
Timestep Consumption Time: 0.81404
PPO Batch Consumption Time: 0.06292
Total Iteration Time: 2.98147

Cumulative Model Updates: 11,788
Cumulative Timesteps: 196,815,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 196815004...
Checkpoint 196815004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,428.23671
Policy Entropy: 0.40977
Value Function Loss: 0.63295

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02563
Policy Update Magnitude: 0.02042
Value Function Update Magnitude: 0.02413

Collected Steps per Second: 20,280.13580
Overall Steps per Second: 14,738.61374

Timestep Collection Time: 2.46586
Timestep Consumption Time: 0.92713
PPO Batch Consumption Time: 0.11008
Total Iteration Time: 3.39299

Cumulative Model Updates: 11,791
Cumulative Timesteps: 196,865,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,677.75788
Policy Entropy: 0.41447
Value Function Loss: 0.63138

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03445
Policy Update Magnitude: 0.02116
Value Function Update Magnitude: 0.02276

Collected Steps per Second: 23,469.24739
Overall Steps per Second: 16,650.30151

Timestep Collection Time: 2.13224
Timestep Consumption Time: 0.87323
PPO Batch Consumption Time: 0.07856
Total Iteration Time: 3.00547

Cumulative Model Updates: 11,794
Cumulative Timesteps: 196,915,054

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 196915054...
Checkpoint 196915054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,029.60326
Policy Entropy: 0.41560
Value Function Loss: 0.61773

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04571
Policy Update Magnitude: 0.02052
Value Function Update Magnitude: 0.02154

Collected Steps per Second: 22,174.16190
Overall Steps per Second: 16,803.25173

Timestep Collection Time: 2.25587
Timestep Consumption Time: 0.72106
PPO Batch Consumption Time: 0.02879
Total Iteration Time: 2.97692

Cumulative Model Updates: 11,797
Cumulative Timesteps: 196,965,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,164.81343
Policy Entropy: 0.42398
Value Function Loss: 0.55261

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03555
Policy Update Magnitude: 0.01781
Value Function Update Magnitude: 0.02015

Collected Steps per Second: 22,216.94263
Overall Steps per Second: 15,662.43194

Timestep Collection Time: 2.25143
Timestep Consumption Time: 0.94219
PPO Batch Consumption Time: 0.09879
Total Iteration Time: 3.19363

Cumulative Model Updates: 11,800
Cumulative Timesteps: 197,015,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 197015096...
Checkpoint 197015096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,429.73548
Policy Entropy: 0.41898
Value Function Loss: 0.58277

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.05741
Policy Update Magnitude: 0.01957
Value Function Update Magnitude: 0.01838

Collected Steps per Second: 23,088.73196
Overall Steps per Second: 16,905.30090

Timestep Collection Time: 2.16591
Timestep Consumption Time: 0.79222
PPO Batch Consumption Time: 0.05964
Total Iteration Time: 2.95813

Cumulative Model Updates: 11,803
Cumulative Timesteps: 197,065,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,008.38821
Policy Entropy: 0.41751
Value Function Loss: 0.61081

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.05763
Policy Update Magnitude: 0.01969
Value Function Update Magnitude: 0.01998

Collected Steps per Second: 20,814.78277
Overall Steps per Second: 14,716.62249

Timestep Collection Time: 2.40300
Timestep Consumption Time: 0.99574
PPO Batch Consumption Time: 0.11727
Total Iteration Time: 3.39874

Cumulative Model Updates: 11,806
Cumulative Timesteps: 197,115,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 197115122...
Checkpoint 197115122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,365.54238
Policy Entropy: 0.41322
Value Function Loss: 0.67196

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.04073
Policy Update Magnitude: 0.02149
Value Function Update Magnitude: 0.02066

Collected Steps per Second: 22,954.58994
Overall Steps per Second: 15,716.29888

Timestep Collection Time: 2.17943
Timestep Consumption Time: 1.00376
PPO Batch Consumption Time: 0.11716
Total Iteration Time: 3.18319

Cumulative Model Updates: 11,809
Cumulative Timesteps: 197,165,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,404.45750
Policy Entropy: 0.41277
Value Function Loss: 0.62158

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03403
Policy Update Magnitude: 0.02103
Value Function Update Magnitude: 0.02320

Collected Steps per Second: 23,377.95126
Overall Steps per Second: 16,769.07054

Timestep Collection Time: 2.13894
Timestep Consumption Time: 0.84298
PPO Batch Consumption Time: 0.07085
Total Iteration Time: 2.98192

Cumulative Model Updates: 11,812
Cumulative Timesteps: 197,215,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 197215154...
Checkpoint 197215154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,420.70733
Policy Entropy: 0.41308
Value Function Loss: 0.61394

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03661
Policy Update Magnitude: 0.02089
Value Function Update Magnitude: 0.02228

Collected Steps per Second: 22,735.46314
Overall Steps per Second: 16,577.71260

Timestep Collection Time: 2.19991
Timestep Consumption Time: 0.81715
PPO Batch Consumption Time: 0.06848
Total Iteration Time: 3.01706

Cumulative Model Updates: 11,815
Cumulative Timesteps: 197,265,170

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,307.88561
Policy Entropy: 0.42164
Value Function Loss: 0.53391

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03822
Policy Update Magnitude: 0.01941
Value Function Update Magnitude: 0.02107

Collected Steps per Second: 20,299.80140
Overall Steps per Second: 14,751.21288

Timestep Collection Time: 2.46357
Timestep Consumption Time: 0.92666
PPO Batch Consumption Time: 0.08766
Total Iteration Time: 3.39023

Cumulative Model Updates: 11,818
Cumulative Timesteps: 197,315,180

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 197315180...
Checkpoint 197315180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,688.49297
Policy Entropy: 0.42434
Value Function Loss: 0.56001

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.01984
Value Function Update Magnitude: 0.02151

Collected Steps per Second: 23,277.40048
Overall Steps per Second: 15,829.47600

Timestep Collection Time: 2.14938
Timestep Consumption Time: 1.01130
PPO Batch Consumption Time: 0.12576
Total Iteration Time: 3.16069

Cumulative Model Updates: 11,821
Cumulative Timesteps: 197,365,212

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,753.71326
Policy Entropy: 0.42692
Value Function Loss: 0.59833

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02581
Policy Update Magnitude: 0.01913
Value Function Update Magnitude: 0.02230

Collected Steps per Second: 23,975.30527
Overall Steps per Second: 17,329.17256

Timestep Collection Time: 2.08556
Timestep Consumption Time: 0.79986
PPO Batch Consumption Time: 0.06069
Total Iteration Time: 2.88542

Cumulative Model Updates: 11,824
Cumulative Timesteps: 197,415,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 197415214...
Checkpoint 197415214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,235.95834
Policy Entropy: 0.42500
Value Function Loss: 0.60844

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02557
Policy Update Magnitude: 0.02312
Value Function Update Magnitude: 0.02246

Collected Steps per Second: 20,755.61012
Overall Steps per Second: 15,105.18539

Timestep Collection Time: 2.40957
Timestep Consumption Time: 0.90135
PPO Batch Consumption Time: 0.08991
Total Iteration Time: 3.31092

Cumulative Model Updates: 11,827
Cumulative Timesteps: 197,465,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,982.40188
Policy Entropy: 0.42336
Value Function Loss: 0.59421

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.02139
Value Function Update Magnitude: 0.02450

Collected Steps per Second: 23,263.11332
Overall Steps per Second: 16,959.11963

Timestep Collection Time: 2.15087
Timestep Consumption Time: 0.79952
PPO Batch Consumption Time: 0.06418
Total Iteration Time: 2.95039

Cumulative Model Updates: 11,830
Cumulative Timesteps: 197,515,262

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 197515262...
Checkpoint 197515262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,781.63917
Policy Entropy: 0.42655
Value Function Loss: 0.57921

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01827
Policy Update Magnitude: 0.02068
Value Function Update Magnitude: 0.02088

Collected Steps per Second: 23,214.88237
Overall Steps per Second: 16,534.79241

Timestep Collection Time: 2.15396
Timestep Consumption Time: 0.87021
PPO Batch Consumption Time: 0.08324
Total Iteration Time: 3.02417

Cumulative Model Updates: 11,833
Cumulative Timesteps: 197,565,266

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,594.31811
Policy Entropy: 0.41933
Value Function Loss: 0.61068

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02478
Policy Update Magnitude: 0.02046
Value Function Update Magnitude: 0.02720

Collected Steps per Second: 23,653.92173
Overall Steps per Second: 17,125.03084

Timestep Collection Time: 2.11432
Timestep Consumption Time: 0.80608
PPO Batch Consumption Time: 0.06371
Total Iteration Time: 2.92040

Cumulative Model Updates: 11,836
Cumulative Timesteps: 197,615,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 197615278...
Checkpoint 197615278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,444.01933
Policy Entropy: 0.42266
Value Function Loss: 0.61073

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03604
Policy Update Magnitude: 0.01973
Value Function Update Magnitude: 0.02734

Collected Steps per Second: 23,360.82976
Overall Steps per Second: 16,378.97456

Timestep Collection Time: 2.14076
Timestep Consumption Time: 0.91254
PPO Batch Consumption Time: 0.09403
Total Iteration Time: 3.05330

Cumulative Model Updates: 11,839
Cumulative Timesteps: 197,665,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,855.01496
Policy Entropy: 0.42067
Value Function Loss: 0.54608

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03888
Policy Update Magnitude: 0.01850
Value Function Update Magnitude: 0.02526

Collected Steps per Second: 23,336.42268
Overall Steps per Second: 16,954.90468

Timestep Collection Time: 2.14360
Timestep Consumption Time: 0.80681
PPO Batch Consumption Time: 0.06373
Total Iteration Time: 2.95041

Cumulative Model Updates: 11,842
Cumulative Timesteps: 197,715,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 197715312...
Checkpoint 197715312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,433.20093
Policy Entropy: 0.42459
Value Function Loss: 0.50068

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03253
Policy Update Magnitude: 0.01719
Value Function Update Magnitude: 0.02189

Collected Steps per Second: 23,338.85320
Overall Steps per Second: 16,526.71949

Timestep Collection Time: 2.14286
Timestep Consumption Time: 0.88327
PPO Batch Consumption Time: 0.08521
Total Iteration Time: 3.02613

Cumulative Model Updates: 11,845
Cumulative Timesteps: 197,765,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,358.74780
Policy Entropy: 0.42255
Value Function Loss: 0.51619

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.01843
Value Function Update Magnitude: 0.01758

Collected Steps per Second: 23,567.47824
Overall Steps per Second: 16,985.45129

Timestep Collection Time: 2.12174
Timestep Consumption Time: 0.82219
PPO Batch Consumption Time: 0.06422
Total Iteration Time: 2.94393

Cumulative Model Updates: 11,848
Cumulative Timesteps: 197,815,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 197815328...
Checkpoint 197815328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,937.22092
Policy Entropy: 0.42270
Value Function Loss: 0.53083

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.05507
Policy Update Magnitude: 0.01849
Value Function Update Magnitude: 0.01924

Collected Steps per Second: 23,415.29216
Overall Steps per Second: 16,495.62971

Timestep Collection Time: 2.13561
Timestep Consumption Time: 0.89586
PPO Batch Consumption Time: 0.08441
Total Iteration Time: 3.03147

Cumulative Model Updates: 11,851
Cumulative Timesteps: 197,865,334

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,451.95788
Policy Entropy: 0.41868
Value Function Loss: 0.54200

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04125
Policy Update Magnitude: 0.01733
Value Function Update Magnitude: 0.01839

Collected Steps per Second: 22,892.81103
Overall Steps per Second: 16,792.89245

Timestep Collection Time: 2.18593
Timestep Consumption Time: 0.79402
PPO Batch Consumption Time: 0.05954
Total Iteration Time: 2.97995

Cumulative Model Updates: 11,854
Cumulative Timesteps: 197,915,376

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 197915376...
Checkpoint 197915376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,399.19267
Policy Entropy: 0.42593
Value Function Loss: 0.49462

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03627
Policy Update Magnitude: 0.01776
Value Function Update Magnitude: 0.01941

Collected Steps per Second: 20,346.31609
Overall Steps per Second: 14,753.02791

Timestep Collection Time: 2.45853
Timestep Consumption Time: 0.93210
PPO Batch Consumption Time: 0.09115
Total Iteration Time: 3.39063

Cumulative Model Updates: 11,857
Cumulative Timesteps: 197,965,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,334.00654
Policy Entropy: 0.42453
Value Function Loss: 0.50470

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.03057
Policy Update Magnitude: 0.01769
Value Function Update Magnitude: 0.02036

Collected Steps per Second: 23,360.57941
Overall Steps per Second: 16,877.70373

Timestep Collection Time: 2.14233
Timestep Consumption Time: 0.82289
PPO Batch Consumption Time: 0.06263
Total Iteration Time: 2.96521

Cumulative Model Updates: 11,860
Cumulative Timesteps: 198,015,444

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 198015444...
Checkpoint 198015444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,964.82585
Policy Entropy: 0.43543
Value Function Loss: 0.48824

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01757
Policy Update Magnitude: 0.01764
Value Function Update Magnitude: 0.01951

Collected Steps per Second: 20,879.74645
Overall Steps per Second: 14,742.99917

Timestep Collection Time: 2.39534
Timestep Consumption Time: 0.99705
PPO Batch Consumption Time: 0.11329
Total Iteration Time: 3.39239

Cumulative Model Updates: 11,863
Cumulative Timesteps: 198,065,458

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,824.56782
Policy Entropy: 0.43584
Value Function Loss: 0.51573

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01952
Policy Update Magnitude: 0.01855
Value Function Update Magnitude: 0.01913

Collected Steps per Second: 23,485.75399
Overall Steps per Second: 16,611.77662

Timestep Collection Time: 2.13031
Timestep Consumption Time: 0.88153
PPO Batch Consumption Time: 0.08273
Total Iteration Time: 3.01184

Cumulative Model Updates: 11,866
Cumulative Timesteps: 198,115,490

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 198115490...
Checkpoint 198115490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,290.67028
Policy Entropy: 0.44599
Value Function Loss: 0.49650

Mean KL Divergence: 0.00098
SB3 Clip Fraction: 0.00809
Policy Update Magnitude: 0.02028
Value Function Update Magnitude: 0.01819

Collected Steps per Second: 23,119.74411
Overall Steps per Second: 15,819.00642

Timestep Collection Time: 2.16274
Timestep Consumption Time: 0.99814
PPO Batch Consumption Time: 0.11854
Total Iteration Time: 3.16088

Cumulative Model Updates: 11,869
Cumulative Timesteps: 198,165,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,160.71841
Policy Entropy: 0.44232
Value Function Loss: 0.51177

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.01462
Policy Update Magnitude: 0.02048
Value Function Update Magnitude: 0.01936

Collected Steps per Second: 23,540.73650
Overall Steps per Second: 16,961.21874

Timestep Collection Time: 2.12466
Timestep Consumption Time: 0.82419
PPO Batch Consumption Time: 0.06380
Total Iteration Time: 2.94884

Cumulative Model Updates: 11,872
Cumulative Timesteps: 198,215,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 198215508...
Checkpoint 198215508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,969.24358
Policy Entropy: 0.44208
Value Function Loss: 0.50341

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.02074
Policy Update Magnitude: 0.02072
Value Function Update Magnitude: 0.01763

Collected Steps per Second: 22,484.92053
Overall Steps per Second: 16,739.63685

Timestep Collection Time: 2.22380
Timestep Consumption Time: 0.76324
PPO Batch Consumption Time: 0.06028
Total Iteration Time: 2.98704

Cumulative Model Updates: 11,875
Cumulative Timesteps: 198,265,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,479.14007
Policy Entropy: 0.44366
Value Function Loss: 0.46648

Mean KL Divergence: 0.00103
SB3 Clip Fraction: 0.01040
Policy Update Magnitude: 0.02082
Value Function Update Magnitude: 0.01587

Collected Steps per Second: 23,111.72937
Overall Steps per Second: 16,853.72429

Timestep Collection Time: 2.16349
Timestep Consumption Time: 0.80333
PPO Batch Consumption Time: 0.06057
Total Iteration Time: 2.96682

Cumulative Model Updates: 11,878
Cumulative Timesteps: 198,315,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 198315512...
Checkpoint 198315512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,457.69269
Policy Entropy: 0.45025
Value Function Loss: 0.45837

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01959
Policy Update Magnitude: 0.02031
Value Function Update Magnitude: 0.01625

Collected Steps per Second: 23,352.54958
Overall Steps per Second: 16,840.35627

Timestep Collection Time: 2.14161
Timestep Consumption Time: 0.82816
PPO Batch Consumption Time: 0.06417
Total Iteration Time: 2.96977

Cumulative Model Updates: 11,881
Cumulative Timesteps: 198,365,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,710.64928
Policy Entropy: 0.44884
Value Function Loss: 0.47545

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03449
Policy Update Magnitude: 0.01947
Value Function Update Magnitude: 0.01961

Collected Steps per Second: 23,257.31937
Overall Steps per Second: 16,779.95282

Timestep Collection Time: 2.15038
Timestep Consumption Time: 0.83008
PPO Batch Consumption Time: 0.06586
Total Iteration Time: 2.98046

Cumulative Model Updates: 11,884
Cumulative Timesteps: 198,415,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 198415536...
Checkpoint 198415536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,416.39459
Policy Entropy: 0.45437
Value Function Loss: 0.46791

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.02004
Value Function Update Magnitude: 0.02018

Collected Steps per Second: 20,910.76484
Overall Steps per Second: 15,192.79276

Timestep Collection Time: 2.39236
Timestep Consumption Time: 0.90039
PPO Batch Consumption Time: 0.08747
Total Iteration Time: 3.29275

Cumulative Model Updates: 11,887
Cumulative Timesteps: 198,465,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,358.30978
Policy Entropy: 0.45319
Value Function Loss: 0.44569

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.02082
Value Function Update Magnitude: 0.02244

Collected Steps per Second: 23,508.80170
Overall Steps per Second: 17,020.78827

Timestep Collection Time: 2.12746
Timestep Consumption Time: 0.81095
PPO Batch Consumption Time: 0.06425
Total Iteration Time: 2.93841

Cumulative Model Updates: 11,890
Cumulative Timesteps: 198,515,576

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 198515576...
Checkpoint 198515576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,910.24252
Policy Entropy: 0.45523
Value Function Loss: 0.40295

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.02067
Policy Update Magnitude: 0.02178
Value Function Update Magnitude: 0.02166

Collected Steps per Second: 23,107.72838
Overall Steps per Second: 16,463.54787

Timestep Collection Time: 2.16404
Timestep Consumption Time: 0.87334
PPO Batch Consumption Time: 0.07469
Total Iteration Time: 3.03738

Cumulative Model Updates: 11,893
Cumulative Timesteps: 198,565,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,765.72011
Policy Entropy: 0.44873
Value Function Loss: 0.47229

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02829
Policy Update Magnitude: 0.02037
Value Function Update Magnitude: 0.02111

Collected Steps per Second: 22,456.85461
Overall Steps per Second: 16,421.93667

Timestep Collection Time: 2.22712
Timestep Consumption Time: 0.81845
PPO Batch Consumption Time: 0.06560
Total Iteration Time: 3.04556

Cumulative Model Updates: 11,896
Cumulative Timesteps: 198,615,596

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 198615596...
Checkpoint 198615596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,447.28152
Policy Entropy: 0.44245
Value Function Loss: 0.48078

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.03030
Policy Update Magnitude: 0.01952
Value Function Update Magnitude: 0.02087

Collected Steps per Second: 20,501.34359
Overall Steps per Second: 15,041.04250

Timestep Collection Time: 2.44004
Timestep Consumption Time: 0.88580
PPO Batch Consumption Time: 0.08145
Total Iteration Time: 3.32583

Cumulative Model Updates: 11,899
Cumulative Timesteps: 198,665,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,423.91302
Policy Entropy: 0.44592
Value Function Loss: 0.49065

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03111
Policy Update Magnitude: 0.02221
Value Function Update Magnitude: 0.02058

Collected Steps per Second: 23,388.80352
Overall Steps per Second: 16,976.97237

Timestep Collection Time: 2.13914
Timestep Consumption Time: 0.80791
PPO Batch Consumption Time: 0.06357
Total Iteration Time: 2.94705

Cumulative Model Updates: 11,902
Cumulative Timesteps: 198,715,652

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 198715652...
Checkpoint 198715652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,384.01772
Policy Entropy: 0.44761
Value Function Loss: 0.45997

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03697
Policy Update Magnitude: 0.02049
Value Function Update Magnitude: 0.02040

Collected Steps per Second: 21,351.63701
Overall Steps per Second: 15,851.12369

Timestep Collection Time: 2.34212
Timestep Consumption Time: 0.81274
PPO Batch Consumption Time: 0.06704
Total Iteration Time: 3.15486

Cumulative Model Updates: 11,905
Cumulative Timesteps: 198,765,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,525.66012
Policy Entropy: 0.45280
Value Function Loss: 0.42974

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03543
Policy Update Magnitude: 0.01785
Value Function Update Magnitude: 0.01860

Collected Steps per Second: 23,451.80664
Overall Steps per Second: 16,355.78832

Timestep Collection Time: 2.13297
Timestep Consumption Time: 0.92540
PPO Batch Consumption Time: 0.10113
Total Iteration Time: 3.05837

Cumulative Model Updates: 11,908
Cumulative Timesteps: 198,815,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 198815682...
Checkpoint 198815682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,785.85377
Policy Entropy: 0.45190
Value Function Loss: 0.45334

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02336
Policy Update Magnitude: 0.01865
Value Function Update Magnitude: 0.01824

Collected Steps per Second: 22,908.32484
Overall Steps per Second: 16,748.21882

Timestep Collection Time: 2.18322
Timestep Consumption Time: 0.80300
PPO Batch Consumption Time: 0.06049
Total Iteration Time: 2.98623

Cumulative Model Updates: 11,911
Cumulative Timesteps: 198,865,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,005.65434
Policy Entropy: 0.45302
Value Function Loss: 0.44790

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02881
Policy Update Magnitude: 0.01750
Value Function Update Magnitude: 0.02135

Collected Steps per Second: 20,534.03011
Overall Steps per Second: 14,745.63847

Timestep Collection Time: 2.43596
Timestep Consumption Time: 0.95623
PPO Batch Consumption Time: 0.10598
Total Iteration Time: 3.39219

Cumulative Model Updates: 11,914
Cumulative Timesteps: 198,915,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 198915716...
Checkpoint 198915716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,355.26202
Policy Entropy: 0.44830
Value Function Loss: 0.52247

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01578
Policy Update Magnitude: 0.01963
Value Function Update Magnitude: 0.01865

Collected Steps per Second: 22,635.83117
Overall Steps per Second: 16,501.54288

Timestep Collection Time: 2.20889
Timestep Consumption Time: 0.82113
PPO Batch Consumption Time: 0.06203
Total Iteration Time: 3.03002

Cumulative Model Updates: 11,917
Cumulative Timesteps: 198,965,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,396.26925
Policy Entropy: 0.45446
Value Function Loss: 0.50443

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01875
Policy Update Magnitude: 0.02052
Value Function Update Magnitude: 0.01816

Collected Steps per Second: 20,750.54241
Overall Steps per Second: 14,923.51668

Timestep Collection Time: 2.40996
Timestep Consumption Time: 0.94099
PPO Batch Consumption Time: 0.09726
Total Iteration Time: 3.35095

Cumulative Model Updates: 11,920
Cumulative Timesteps: 199,015,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 199015724...
Checkpoint 199015724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,332.91582
Policy Entropy: 0.45367
Value Function Loss: 0.50857

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.02087
Policy Update Magnitude: 0.02230
Value Function Update Magnitude: 0.01893

Collected Steps per Second: 22,908.67314
Overall Steps per Second: 15,818.22046

Timestep Collection Time: 2.18302
Timestep Consumption Time: 0.97853
PPO Batch Consumption Time: 0.11723
Total Iteration Time: 3.16154

Cumulative Model Updates: 11,923
Cumulative Timesteps: 199,065,734

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,698.35710
Policy Entropy: 0.46184
Value Function Loss: 0.44529

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01854
Policy Update Magnitude: 0.02108
Value Function Update Magnitude: 0.01768

Collected Steps per Second: 23,623.58445
Overall Steps per Second: 17,183.44826

Timestep Collection Time: 2.11704
Timestep Consumption Time: 0.79344
PPO Batch Consumption Time: 0.06277
Total Iteration Time: 2.91048

Cumulative Model Updates: 11,926
Cumulative Timesteps: 199,115,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 199115746...
Checkpoint 199115746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,524.34907
Policy Entropy: 0.46274
Value Function Loss: 0.46270

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.03033
Policy Update Magnitude: 0.01893
Value Function Update Magnitude: 0.01867

Collected Steps per Second: 17,417.51392
Overall Steps per Second: 12,892.25064

Timestep Collection Time: 2.87217
Timestep Consumption Time: 1.00815
PPO Batch Consumption Time: 0.10617
Total Iteration Time: 3.88032

Cumulative Model Updates: 11,929
Cumulative Timesteps: 199,165,772

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,238.50882
Policy Entropy: 0.46314
Value Function Loss: 0.42372

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02599
Policy Update Magnitude: 0.01804
Value Function Update Magnitude: 0.01732

Collected Steps per Second: 21,323.46987
Overall Steps per Second: 15,799.87358

Timestep Collection Time: 2.34530
Timestep Consumption Time: 0.81991
PPO Batch Consumption Time: 0.06258
Total Iteration Time: 3.16522

Cumulative Model Updates: 11,932
Cumulative Timesteps: 199,215,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 199215782...
Checkpoint 199215782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,623.67376
Policy Entropy: 0.46070
Value Function Loss: 0.46025

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04173
Policy Update Magnitude: 0.01828
Value Function Update Magnitude: 0.01794

Collected Steps per Second: 18,423.56449
Overall Steps per Second: 13,243.58789

Timestep Collection Time: 2.71554
Timestep Consumption Time: 1.06213
PPO Batch Consumption Time: 0.12697
Total Iteration Time: 3.77768

Cumulative Model Updates: 11,935
Cumulative Timesteps: 199,265,812

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,768.65951
Policy Entropy: 0.45773
Value Function Loss: 0.45254

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04715
Policy Update Magnitude: 0.01825
Value Function Update Magnitude: 0.02008

Collected Steps per Second: 23,760.83095
Overall Steps per Second: 17,210.65371

Timestep Collection Time: 2.10464
Timestep Consumption Time: 0.80100
PPO Batch Consumption Time: 0.06049
Total Iteration Time: 2.90564

Cumulative Model Updates: 11,938
Cumulative Timesteps: 199,315,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 199315820...
Checkpoint 199315820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,165.88076
Policy Entropy: 0.45812
Value Function Loss: 0.47328

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04382
Policy Update Magnitude: 0.01767
Value Function Update Magnitude: 0.01963

Collected Steps per Second: 18,080.86029
Overall Steps per Second: 13,422.48842

Timestep Collection Time: 2.76580
Timestep Consumption Time: 0.95989
PPO Batch Consumption Time: 0.09466
Total Iteration Time: 3.72569

Cumulative Model Updates: 11,941
Cumulative Timesteps: 199,365,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,444.44057
Policy Entropy: 0.45959
Value Function Loss: 0.47152

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.04020
Policy Update Magnitude: 0.02065
Value Function Update Magnitude: 0.02098

Collected Steps per Second: 22,212.39092
Overall Steps per Second: 16,450.07879

Timestep Collection Time: 2.25109
Timestep Consumption Time: 0.78853
PPO Batch Consumption Time: 0.05927
Total Iteration Time: 3.03962

Cumulative Model Updates: 11,944
Cumulative Timesteps: 199,415,830

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 199415830...
Checkpoint 199415830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,922.43356
Policy Entropy: 0.45738
Value Function Loss: 0.50356

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03650
Policy Update Magnitude: 0.02010
Value Function Update Magnitude: 0.01856

Collected Steps per Second: 20,775.07463
Overall Steps per Second: 15,127.49195

Timestep Collection Time: 2.40712
Timestep Consumption Time: 0.89865
PPO Batch Consumption Time: 0.08520
Total Iteration Time: 3.30577

Cumulative Model Updates: 11,947
Cumulative Timesteps: 199,465,838

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,595.48649
Policy Entropy: 0.46121
Value Function Loss: 0.47592

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03265
Policy Update Magnitude: 0.01867
Value Function Update Magnitude: 0.02209

Collected Steps per Second: 18,685.82374
Overall Steps per Second: 14,165.24610

Timestep Collection Time: 2.67711
Timestep Consumption Time: 0.85435
PPO Batch Consumption Time: 0.08438
Total Iteration Time: 3.53146

Cumulative Model Updates: 11,950
Cumulative Timesteps: 199,515,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 199515862...
Checkpoint 199515862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,268.94768
Policy Entropy: 0.46450
Value Function Loss: 0.45793

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04443
Policy Update Magnitude: 0.02028
Value Function Update Magnitude: 0.02462

Collected Steps per Second: 22,118.86093
Overall Steps per Second: 16,738.89252

Timestep Collection Time: 2.26124
Timestep Consumption Time: 0.72677
PPO Batch Consumption Time: 0.06079
Total Iteration Time: 2.98801

Cumulative Model Updates: 11,953
Cumulative Timesteps: 199,565,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,752.70664
Policy Entropy: 0.46623
Value Function Loss: 0.48618

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03891
Policy Update Magnitude: 0.01856
Value Function Update Magnitude: 0.01991

Collected Steps per Second: 22,768.70244
Overall Steps per Second: 16,436.75316

Timestep Collection Time: 2.19644
Timestep Consumption Time: 0.84614
PPO Batch Consumption Time: 0.09308
Total Iteration Time: 3.04257

Cumulative Model Updates: 11,956
Cumulative Timesteps: 199,615,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 199615888...
Checkpoint 199615888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,789.79808
Policy Entropy: 0.46485
Value Function Loss: 0.51939

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04173
Policy Update Magnitude: 0.01698
Value Function Update Magnitude: 0.01766

Collected Steps per Second: 22,275.29768
Overall Steps per Second: 15,819.85525

Timestep Collection Time: 2.24473
Timestep Consumption Time: 0.91598
PPO Batch Consumption Time: 0.12341
Total Iteration Time: 3.16071

Cumulative Model Updates: 11,959
Cumulative Timesteps: 199,665,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,757.06656
Policy Entropy: 0.46674
Value Function Loss: 0.48870

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04403
Policy Update Magnitude: 0.01962
Value Function Update Magnitude: 0.01667

Collected Steps per Second: 22,903.31540
Overall Steps per Second: 17,255.89001

Timestep Collection Time: 2.18475
Timestep Consumption Time: 0.71501
PPO Batch Consumption Time: 0.05991
Total Iteration Time: 2.89976

Cumulative Model Updates: 11,962
Cumulative Timesteps: 199,715,928

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 199715928...
Checkpoint 199715928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,095.37080
Policy Entropy: 0.47044
Value Function Loss: 0.40853

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05519
Policy Update Magnitude: 0.01990
Value Function Update Magnitude: 0.01703

Collected Steps per Second: 20,582.44824
Overall Steps per Second: 15,190.50479

Timestep Collection Time: 2.43139
Timestep Consumption Time: 0.86303
PPO Batch Consumption Time: 0.09588
Total Iteration Time: 3.29443

Cumulative Model Updates: 11,965
Cumulative Timesteps: 199,765,972

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,116.72449
Policy Entropy: 0.46572
Value Function Loss: 0.39538

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.06222
Policy Update Magnitude: 0.01882
Value Function Update Magnitude: 0.01647

Collected Steps per Second: 22,629.82615
Overall Steps per Second: 16,691.45377

Timestep Collection Time: 2.21009
Timestep Consumption Time: 0.78629
PPO Batch Consumption Time: 0.05960
Total Iteration Time: 2.99638

Cumulative Model Updates: 11,968
Cumulative Timesteps: 199,815,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 199815986...
Checkpoint 199815986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,652.13662
Policy Entropy: 0.46588
Value Function Loss: 0.45733

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05687
Policy Update Magnitude: 0.01695
Value Function Update Magnitude: 0.01628

Collected Steps per Second: 20,392.27482
Overall Steps per Second: 14,809.79258

Timestep Collection Time: 2.45230
Timestep Consumption Time: 0.92438
PPO Batch Consumption Time: 0.10667
Total Iteration Time: 3.37668

Cumulative Model Updates: 11,971
Cumulative Timesteps: 199,865,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,668.68492
Policy Entropy: 0.46408
Value Function Loss: 0.44449

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03921
Policy Update Magnitude: 0.01773
Value Function Update Magnitude: 0.01731

Collected Steps per Second: 23,344.14084
Overall Steps per Second: 17,052.92419

Timestep Collection Time: 2.14212
Timestep Consumption Time: 0.79028
PPO Batch Consumption Time: 0.06508
Total Iteration Time: 2.93240

Cumulative Model Updates: 11,974
Cumulative Timesteps: 199,916,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 199916000...
Checkpoint 199916000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,604.42985
Policy Entropy: 0.46762
Value Function Loss: 0.45221

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.05368
Policy Update Magnitude: 0.01650
Value Function Update Magnitude: 0.01695

Collected Steps per Second: 23,256.24333
Overall Steps per Second: 17,097.30932

Timestep Collection Time: 2.15022
Timestep Consumption Time: 0.77457
PPO Batch Consumption Time: 0.06427
Total Iteration Time: 2.92479

Cumulative Model Updates: 11,977
Cumulative Timesteps: 199,966,006

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,020.99598
Policy Entropy: 0.46053
Value Function Loss: 0.41137

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.05379
Policy Update Magnitude: 0.01734
Value Function Update Magnitude: 0.01738

Collected Steps per Second: 21,241.41846
Overall Steps per Second: 15,135.61258

Timestep Collection Time: 2.35530
Timestep Consumption Time: 0.95015
PPO Batch Consumption Time: 0.11208
Total Iteration Time: 3.30545

Cumulative Model Updates: 11,980
Cumulative Timesteps: 200,016,036

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 200016036...
Checkpoint 200016036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,544.25721
Policy Entropy: 0.45875
Value Function Loss: 0.41624

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04999
Policy Update Magnitude: 0.01812
Value Function Update Magnitude: 0.01725

Collected Steps per Second: 23,487.77106
Overall Steps per Second: 16,915.63896

Timestep Collection Time: 2.12953
Timestep Consumption Time: 0.82738
PPO Batch Consumption Time: 0.06996
Total Iteration Time: 2.95691

Cumulative Model Updates: 11,983
Cumulative Timesteps: 200,066,054

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,764.63084
Policy Entropy: 0.45348
Value Function Loss: 0.40236

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.04100
Policy Update Magnitude: 0.01918
Value Function Update Magnitude: 0.01773

Collected Steps per Second: 22,994.51080
Overall Steps per Second: 16,514.35743

Timestep Collection Time: 2.17556
Timestep Consumption Time: 0.85368
PPO Batch Consumption Time: 0.08750
Total Iteration Time: 3.02924

Cumulative Model Updates: 11,986
Cumulative Timesteps: 200,116,080

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 200116080...
Checkpoint 200116080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,501.96144
Policy Entropy: 0.45715
Value Function Loss: 0.40978

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.05165
Policy Update Magnitude: 0.01877
Value Function Update Magnitude: 0.01821

Collected Steps per Second: 23,113.21777
Overall Steps per Second: 16,931.34956

Timestep Collection Time: 2.16482
Timestep Consumption Time: 0.79041
PPO Batch Consumption Time: 0.06050
Total Iteration Time: 2.95523

Cumulative Model Updates: 11,989
Cumulative Timesteps: 200,166,116

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,105.85695
Policy Entropy: 0.45966
Value Function Loss: 0.39131

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04810
Policy Update Magnitude: 0.01669
Value Function Update Magnitude: 0.01859

Collected Steps per Second: 20,632.06249
Overall Steps per Second: 14,673.65726

Timestep Collection Time: 2.42370
Timestep Consumption Time: 0.98417
PPO Batch Consumption Time: 0.11506
Total Iteration Time: 3.40788

Cumulative Model Updates: 11,992
Cumulative Timesteps: 200,216,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 200216122...
Checkpoint 200216122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,299.79731
Policy Entropy: 0.46334
Value Function Loss: 0.36874

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03171
Policy Update Magnitude: 0.01891
Value Function Update Magnitude: 0.01978

Collected Steps per Second: 23,057.52906
Overall Steps per Second: 16,696.32970

Timestep Collection Time: 2.16875
Timestep Consumption Time: 0.82628
PPO Batch Consumption Time: 0.05996
Total Iteration Time: 2.99503

Cumulative Model Updates: 11,995
Cumulative Timesteps: 200,266,128

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,435.79406
Policy Entropy: 0.47076
Value Function Loss: 0.33513

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03612
Policy Update Magnitude: 0.01945
Value Function Update Magnitude: 0.01695

Collected Steps per Second: 20,122.92199
Overall Steps per Second: 14,751.01170

Timestep Collection Time: 2.48483
Timestep Consumption Time: 0.90491
PPO Batch Consumption Time: 0.08939
Total Iteration Time: 3.38973

Cumulative Model Updates: 11,998
Cumulative Timesteps: 200,316,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 200316130...
Checkpoint 200316130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,854.68810
Policy Entropy: 0.47074
Value Function Loss: 0.34668

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.04073
Policy Update Magnitude: 0.01956
Value Function Update Magnitude: 0.01704

Collected Steps per Second: 23,211.10101
Overall Steps per Second: 15,837.18954

Timestep Collection Time: 2.15483
Timestep Consumption Time: 1.00331
PPO Batch Consumption Time: 0.12374
Total Iteration Time: 3.15814

Cumulative Model Updates: 12,001
Cumulative Timesteps: 200,366,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,604.13798
Policy Entropy: 0.46579
Value Function Loss: 0.39252

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02622
Policy Update Magnitude: 0.01859
Value Function Update Magnitude: 0.01970

Collected Steps per Second: 23,185.35650
Overall Steps per Second: 17,020.86362

Timestep Collection Time: 2.15740
Timestep Consumption Time: 0.78135
PPO Batch Consumption Time: 0.06269
Total Iteration Time: 2.93875

Cumulative Model Updates: 12,004
Cumulative Timesteps: 200,416,166

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 200416166...
Checkpoint 200416166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,096.56603
Policy Entropy: 0.46632
Value Function Loss: 0.37744

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.01841
Value Function Update Magnitude: 0.01970

Collected Steps per Second: 23,245.18905
Overall Steps per Second: 16,935.58105

Timestep Collection Time: 2.15115
Timestep Consumption Time: 0.80145
PPO Batch Consumption Time: 0.06209
Total Iteration Time: 2.95260

Cumulative Model Updates: 12,007
Cumulative Timesteps: 200,466,170

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,353.12110
Policy Entropy: 0.46968
Value Function Loss: 0.36326

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01479
Policy Update Magnitude: 0.01918
Value Function Update Magnitude: 0.01811

Collected Steps per Second: 21,285.87395
Overall Steps per Second: 15,171.19016

Timestep Collection Time: 2.34982
Timestep Consumption Time: 0.94709
PPO Batch Consumption Time: 0.10320
Total Iteration Time: 3.29691

Cumulative Model Updates: 12,010
Cumulative Timesteps: 200,516,188

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 200516188...
Checkpoint 200516188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,086.27783
Policy Entropy: 0.46625
Value Function Loss: 0.34740

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.01230
Policy Update Magnitude: 0.01863
Value Function Update Magnitude: 0.01687

Collected Steps per Second: 23,570.10726
Overall Steps per Second: 17,135.67041

Timestep Collection Time: 2.12176
Timestep Consumption Time: 0.79672
PPO Batch Consumption Time: 0.06360
Total Iteration Time: 2.91847

Cumulative Model Updates: 12,013
Cumulative Timesteps: 200,566,198

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,180.82862
Policy Entropy: 0.46465
Value Function Loss: 0.37930

Mean KL Divergence: 0.00128
SB3 Clip Fraction: 0.01230
Policy Update Magnitude: 0.01843
Value Function Update Magnitude: 0.02073

Collected Steps per Second: 23,449.21315
Overall Steps per Second: 16,342.31893

Timestep Collection Time: 2.13235
Timestep Consumption Time: 0.92731
PPO Batch Consumption Time: 0.10464
Total Iteration Time: 3.05966

Cumulative Model Updates: 12,016
Cumulative Timesteps: 200,616,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 200616200...
Checkpoint 200616200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,121.36183
Policy Entropy: 0.46261
Value Function Loss: 0.35865

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01837
Policy Update Magnitude: 0.01956
Value Function Update Magnitude: 0.02232

Collected Steps per Second: 23,243.55000
Overall Steps per Second: 16,919.32857

Timestep Collection Time: 2.15208
Timestep Consumption Time: 0.80442
PPO Batch Consumption Time: 0.05990
Total Iteration Time: 2.95650

Cumulative Model Updates: 12,019
Cumulative Timesteps: 200,666,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,058.43748
Policy Entropy: 0.47427
Value Function Loss: 0.30187

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01455
Policy Update Magnitude: 0.01927
Value Function Update Magnitude: 0.02240

Collected Steps per Second: 21,404.88075
Overall Steps per Second: 15,511.06504

Timestep Collection Time: 2.33760
Timestep Consumption Time: 0.88823
PPO Batch Consumption Time: 0.07929
Total Iteration Time: 3.22583

Cumulative Model Updates: 12,022
Cumulative Timesteps: 200,716,258

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 200716258...
Checkpoint 200716258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,753.02753
Policy Entropy: 0.47465
Value Function Loss: 0.28726

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01885
Policy Update Magnitude: 0.01654
Value Function Update Magnitude: 0.02052

Collected Steps per Second: 23,004.29169
Overall Steps per Second: 15,782.83207

Timestep Collection Time: 2.17420
Timestep Consumption Time: 0.99481
PPO Batch Consumption Time: 0.11015
Total Iteration Time: 3.16901

Cumulative Model Updates: 12,025
Cumulative Timesteps: 200,766,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,201.72591
Policy Entropy: 0.47912
Value Function Loss: 0.27857

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.00876
Policy Update Magnitude: 0.01725
Value Function Update Magnitude: 0.01680

Collected Steps per Second: 23,360.26150
Overall Steps per Second: 16,876.33669

Timestep Collection Time: 2.14150
Timestep Consumption Time: 0.82277
PPO Batch Consumption Time: 0.06552
Total Iteration Time: 2.96427

Cumulative Model Updates: 12,028
Cumulative Timesteps: 200,816,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 200816300...
Checkpoint 200816300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,095.14909
Policy Entropy: 0.47406
Value Function Loss: 0.31143

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01889
Policy Update Magnitude: 0.01768
Value Function Update Magnitude: 0.01699

Collected Steps per Second: 22,729.26448
Overall Steps per Second: 16,555.70048

Timestep Collection Time: 2.19998
Timestep Consumption Time: 0.82037
PPO Batch Consumption Time: 0.06044
Total Iteration Time: 3.02035

Cumulative Model Updates: 12,031
Cumulative Timesteps: 200,866,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,395.74369
Policy Entropy: 0.47346
Value Function Loss: 0.31969

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01811
Policy Update Magnitude: 0.01806
Value Function Update Magnitude: 0.01678

Collected Steps per Second: 20,738.93023
Overall Steps per Second: 14,752.86184

Timestep Collection Time: 2.41160
Timestep Consumption Time: 0.97852
PPO Batch Consumption Time: 0.11098
Total Iteration Time: 3.39012

Cumulative Model Updates: 12,034
Cumulative Timesteps: 200,916,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 200916318...
Checkpoint 200916318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,291.41391
Policy Entropy: 0.46874
Value Function Loss: 0.38382

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01719
Policy Update Magnitude: 0.02042
Value Function Update Magnitude: 0.01709

Collected Steps per Second: 23,011.94918
Overall Steps per Second: 15,794.95003

Timestep Collection Time: 2.17417
Timestep Consumption Time: 0.99342
PPO Batch Consumption Time: 0.12115
Total Iteration Time: 3.16759

Cumulative Model Updates: 12,037
Cumulative Timesteps: 200,966,350

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,010.62654
Policy Entropy: 0.46882
Value Function Loss: 0.40694

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01470
Policy Update Magnitude: 0.02248
Value Function Update Magnitude: 0.02517

Collected Steps per Second: 23,724.15887
Overall Steps per Second: 17,275.71226

Timestep Collection Time: 2.10831
Timestep Consumption Time: 0.78696
PPO Batch Consumption Time: 0.06309
Total Iteration Time: 2.89528

Cumulative Model Updates: 12,040
Cumulative Timesteps: 201,016,368

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 201016368...
Checkpoint 201016368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,042.55298
Policy Entropy: 0.47526
Value Function Loss: 0.40189

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01964
Policy Update Magnitude: 0.02252
Value Function Update Magnitude: 0.02425

Collected Steps per Second: 21,024.67312
Overall Steps per Second: 15,148.32969

Timestep Collection Time: 2.37939
Timestep Consumption Time: 0.92302
PPO Batch Consumption Time: 0.09486
Total Iteration Time: 3.30241

Cumulative Model Updates: 12,043
Cumulative Timesteps: 201,066,394

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,587.84804
Policy Entropy: 0.47880
Value Function Loss: 0.36619

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03417
Policy Update Magnitude: 0.02020
Value Function Update Magnitude: 0.02323

Collected Steps per Second: 23,077.41500
Overall Steps per Second: 16,825.88166

Timestep Collection Time: 2.16731
Timestep Consumption Time: 0.80525
PPO Batch Consumption Time: 0.06083
Total Iteration Time: 2.97256

Cumulative Model Updates: 12,046
Cumulative Timesteps: 201,116,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 201116410...
Checkpoint 201116410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,736.52889
Policy Entropy: 0.48229
Value Function Loss: 0.34110

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.04115
Policy Update Magnitude: 0.01998
Value Function Update Magnitude: 0.02085

Collected Steps per Second: 20,665.37927
Overall Steps per Second: 14,750.81936

Timestep Collection Time: 2.42028
Timestep Consumption Time: 0.97045
PPO Batch Consumption Time: 0.11354
Total Iteration Time: 3.39073

Cumulative Model Updates: 12,049
Cumulative Timesteps: 201,166,426

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,204.86959
Policy Entropy: 0.48011
Value Function Loss: 0.31136

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.04139
Policy Update Magnitude: 0.01811
Value Function Update Magnitude: 0.01772

Collected Steps per Second: 23,528.07985
Overall Steps per Second: 17,024.01134

Timestep Collection Time: 2.12521
Timestep Consumption Time: 0.81194
PPO Batch Consumption Time: 0.06428
Total Iteration Time: 2.93715

Cumulative Model Updates: 12,052
Cumulative Timesteps: 201,216,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 201216428...
Checkpoint 201216428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,677.76980
Policy Entropy: 0.47852
Value Function Loss: 0.31293

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03420
Policy Update Magnitude: 0.01722
Value Function Update Magnitude: 0.01919

Collected Steps per Second: 19,917.68742
Overall Steps per Second: 15,248.10409

Timestep Collection Time: 2.51113
Timestep Consumption Time: 0.76901
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 3.28015

Cumulative Model Updates: 12,055
Cumulative Timesteps: 201,266,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,580.81348
Policy Entropy: 0.47510
Value Function Loss: 0.33308

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.03064
Policy Update Magnitude: 0.01701
Value Function Update Magnitude: 0.01921

Collected Steps per Second: 22,426.83241
Overall Steps per Second: 16,650.31887

Timestep Collection Time: 2.23001
Timestep Consumption Time: 0.77366
PPO Batch Consumption Time: 0.07146
Total Iteration Time: 3.00367

Cumulative Model Updates: 12,058
Cumulative Timesteps: 201,316,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 201316456...
Checkpoint 201316456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,567.08430
Policy Entropy: 0.47939
Value Function Loss: 0.34818

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01518
Policy Update Magnitude: 0.01732
Value Function Update Magnitude: 0.01835

Collected Steps per Second: 21,421.86883
Overall Steps per Second: 15,935.86655

Timestep Collection Time: 2.33481
Timestep Consumption Time: 0.80377
PPO Batch Consumption Time: 0.07772
Total Iteration Time: 3.13858

Cumulative Model Updates: 12,061
Cumulative Timesteps: 201,366,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,176.88155
Policy Entropy: 0.48416
Value Function Loss: 0.35911

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01791
Policy Update Magnitude: 0.01801
Value Function Update Magnitude: 0.02129

Collected Steps per Second: 20,763.83553
Overall Steps per Second: 15,432.24302

Timestep Collection Time: 2.40919
Timestep Consumption Time: 0.83234
PPO Batch Consumption Time: 0.08537
Total Iteration Time: 3.24152

Cumulative Model Updates: 12,064
Cumulative Timesteps: 201,416,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 201416496...
Checkpoint 201416496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,215.64267
Policy Entropy: 0.48747
Value Function Loss: 0.35300

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01950
Policy Update Magnitude: 0.01930
Value Function Update Magnitude: 0.01895

Collected Steps per Second: 21,263.88904
Overall Steps per Second: 16,130.87000

Timestep Collection Time: 2.35225
Timestep Consumption Time: 0.74851
PPO Batch Consumption Time: 0.06505
Total Iteration Time: 3.10076

Cumulative Model Updates: 12,067
Cumulative Timesteps: 201,466,514

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,652.42446
Policy Entropy: 0.48940
Value Function Loss: 0.33349

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02670
Policy Update Magnitude: 0.01877
Value Function Update Magnitude: 0.01859

Collected Steps per Second: 22,678.28446
Overall Steps per Second: 16,455.44159

Timestep Collection Time: 2.20660
Timestep Consumption Time: 0.83446
PPO Batch Consumption Time: 0.07655
Total Iteration Time: 3.04106

Cumulative Model Updates: 12,070
Cumulative Timesteps: 201,516,556

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 201516556...
Checkpoint 201516556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,340.43433
Policy Entropy: 0.48727
Value Function Loss: 0.31408

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02585
Policy Update Magnitude: 0.01805
Value Function Update Magnitude: 0.01762

Collected Steps per Second: 22,820.67877
Overall Steps per Second: 16,866.35526

Timestep Collection Time: 2.19231
Timestep Consumption Time: 0.77395
PPO Batch Consumption Time: 0.05815
Total Iteration Time: 2.96626

Cumulative Model Updates: 12,073
Cumulative Timesteps: 201,566,586

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,976.88454
Policy Entropy: 0.48970
Value Function Loss: 0.32305

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03927
Policy Update Magnitude: 0.01762
Value Function Update Magnitude: 0.01869

Collected Steps per Second: 20,619.60596
Overall Steps per Second: 14,745.75835

Timestep Collection Time: 2.42488
Timestep Consumption Time: 0.96593
PPO Batch Consumption Time: 0.10978
Total Iteration Time: 3.39081

Cumulative Model Updates: 12,076
Cumulative Timesteps: 201,616,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 201616586...
Checkpoint 201616586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,158.00791
Policy Entropy: 0.48911
Value Function Loss: 0.35845

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03574
Policy Update Magnitude: 0.01815
Value Function Update Magnitude: 0.01762

Collected Steps per Second: 23,076.46553
Overall Steps per Second: 16,957.17976

Timestep Collection Time: 2.16706
Timestep Consumption Time: 0.78202
PPO Batch Consumption Time: 0.06259
Total Iteration Time: 2.94908

Cumulative Model Updates: 12,079
Cumulative Timesteps: 201,666,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,105.66830
Policy Entropy: 0.48748
Value Function Loss: 0.39187

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02918
Policy Update Magnitude: 0.01866
Value Function Update Magnitude: 0.01940

Collected Steps per Second: 20,261.18739
Overall Steps per Second: 14,758.54216

Timestep Collection Time: 2.46915
Timestep Consumption Time: 0.92061
PPO Batch Consumption Time: 0.08644
Total Iteration Time: 3.38977

Cumulative Model Updates: 12,082
Cumulative Timesteps: 201,716,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 201716622...
Checkpoint 201716622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,784.66027
Policy Entropy: 0.49034
Value Function Loss: 0.39444

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02343
Policy Update Magnitude: 0.01803
Value Function Update Magnitude: 0.01880

Collected Steps per Second: 21,700.09473
Overall Steps per Second: 15,550.26200

Timestep Collection Time: 2.30469
Timestep Consumption Time: 0.91146
PPO Batch Consumption Time: 0.09296
Total Iteration Time: 3.21615

Cumulative Model Updates: 12,085
Cumulative Timesteps: 201,766,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,944.99565
Policy Entropy: 0.49022
Value Function Loss: 0.38495

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.03121
Policy Update Magnitude: 0.01846
Value Function Update Magnitude: 0.01824

Collected Steps per Second: 22,953.30435
Overall Steps per Second: 16,742.44672

Timestep Collection Time: 2.17860
Timestep Consumption Time: 0.80818
PPO Batch Consumption Time: 0.06010
Total Iteration Time: 2.98678

Cumulative Model Updates: 12,088
Cumulative Timesteps: 201,816,640

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 201816640...
Checkpoint 201816640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,261.78736
Policy Entropy: 0.49960
Value Function Loss: 0.34653

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03365
Policy Update Magnitude: 0.02006
Value Function Update Magnitude: 0.01785

Collected Steps per Second: 20,985.15518
Overall Steps per Second: 14,857.30390

Timestep Collection Time: 2.38511
Timestep Consumption Time: 0.98373
PPO Batch Consumption Time: 0.11650
Total Iteration Time: 3.36885

Cumulative Model Updates: 12,091
Cumulative Timesteps: 201,866,692

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,516.08665
Policy Entropy: 0.50058
Value Function Loss: 0.30770

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02314
Policy Update Magnitude: 0.01938
Value Function Update Magnitude: 0.01722

Collected Steps per Second: 23,209.55846
Overall Steps per Second: 16,542.24708

Timestep Collection Time: 2.15532
Timestep Consumption Time: 0.86870
PPO Batch Consumption Time: 0.07807
Total Iteration Time: 3.02401

Cumulative Model Updates: 12,094
Cumulative Timesteps: 201,916,716

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 201916716...
Checkpoint 201916716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,336.47807
Policy Entropy: 0.50226
Value Function Loss: 0.31303

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02345
Policy Update Magnitude: 0.01838
Value Function Update Magnitude: 0.01722

Collected Steps per Second: 23,015.49442
Overall Steps per Second: 15,787.18018

Timestep Collection Time: 2.17367
Timestep Consumption Time: 0.99523
PPO Batch Consumption Time: 0.11402
Total Iteration Time: 3.16890

Cumulative Model Updates: 12,097
Cumulative Timesteps: 201,966,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,416.12542
Policy Entropy: 0.49743
Value Function Loss: 0.30794

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.01782
Value Function Update Magnitude: 0.02002

Collected Steps per Second: 21,063.85437
Overall Steps per Second: 15,702.25224

Timestep Collection Time: 2.37430
Timestep Consumption Time: 0.81072
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 3.18502

Cumulative Model Updates: 12,100
Cumulative Timesteps: 202,016,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 202016756...
Checkpoint 202016756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,151.39230
Policy Entropy: 0.49600
Value Function Loss: 0.32199

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02160
Policy Update Magnitude: 0.01889
Value Function Update Magnitude: 0.01762

Collected Steps per Second: 20,164.48887
Overall Steps per Second: 14,723.84776

Timestep Collection Time: 2.47971
Timestep Consumption Time: 0.91628
PPO Batch Consumption Time: 0.09550
Total Iteration Time: 3.39599

Cumulative Model Updates: 12,103
Cumulative Timesteps: 202,066,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,398.15323
Policy Entropy: 0.49798
Value Function Loss: 0.30438

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01446
Policy Update Magnitude: 0.02136
Value Function Update Magnitude: 0.01703

Collected Steps per Second: 23,016.23684
Overall Steps per Second: 16,829.77188

Timestep Collection Time: 2.17334
Timestep Consumption Time: 0.79890
PPO Batch Consumption Time: 0.05953
Total Iteration Time: 2.97223

Cumulative Model Updates: 12,106
Cumulative Timesteps: 202,116,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 202116780...
Checkpoint 202116780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,486.10677
Policy Entropy: 0.49424
Value Function Loss: 0.33154

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02607
Policy Update Magnitude: 0.01974
Value Function Update Magnitude: 0.01678

Collected Steps per Second: 20,105.77378
Overall Steps per Second: 14,721.25707

Timestep Collection Time: 2.48774
Timestep Consumption Time: 0.90993
PPO Batch Consumption Time: 0.09140
Total Iteration Time: 3.39767

Cumulative Model Updates: 12,109
Cumulative Timesteps: 202,166,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,412.24856
Policy Entropy: 0.50065
Value Function Loss: 0.30572

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.03007
Policy Update Magnitude: 0.01711
Value Function Update Magnitude: 0.02104

Collected Steps per Second: 23,110.53278
Overall Steps per Second: 15,643.91856

Timestep Collection Time: 2.16378
Timestep Consumption Time: 1.03274
PPO Batch Consumption Time: 0.13130
Total Iteration Time: 3.19651

Cumulative Model Updates: 12,112
Cumulative Timesteps: 202,216,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 202216804...
Checkpoint 202216804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,059.90443
Policy Entropy: 0.50426
Value Function Loss: 0.27910

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.01928
Value Function Update Magnitude: 0.02032

Collected Steps per Second: 23,348.06619
Overall Steps per Second: 16,934.68115

Timestep Collection Time: 2.14168
Timestep Consumption Time: 0.81108
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 2.95276

Cumulative Model Updates: 12,115
Cumulative Timesteps: 202,266,808

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,722.57424
Policy Entropy: 0.51110
Value Function Loss: 0.27376

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.03185
Policy Update Magnitude: 0.01992
Value Function Update Magnitude: 0.01868

Collected Steps per Second: 20,209.06109
Overall Steps per Second: 14,686.27119

Timestep Collection Time: 2.47443
Timestep Consumption Time: 0.93051
PPO Batch Consumption Time: 0.11946
Total Iteration Time: 3.40495

Cumulative Model Updates: 12,118
Cumulative Timesteps: 202,316,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 202316814...
Checkpoint 202316814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,498.47355
Policy Entropy: 0.50671
Value Function Loss: 0.30640

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03650
Policy Update Magnitude: 0.01977
Value Function Update Magnitude: 0.01637

Collected Steps per Second: 22,166.75067
Overall Steps per Second: 15,740.99447

Timestep Collection Time: 2.25581
Timestep Consumption Time: 0.92086
PPO Batch Consumption Time: 0.12252
Total Iteration Time: 3.17667

Cumulative Model Updates: 12,121
Cumulative Timesteps: 202,366,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,662.94715
Policy Entropy: 0.50663
Value Function Loss: 0.30388

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03691
Policy Update Magnitude: 0.01722
Value Function Update Magnitude: 0.01741

Collected Steps per Second: 22,872.27133
Overall Steps per Second: 17,147.28608

Timestep Collection Time: 2.18623
Timestep Consumption Time: 0.72992
PPO Batch Consumption Time: 0.06103
Total Iteration Time: 2.91615

Cumulative Model Updates: 12,124
Cumulative Timesteps: 202,416,822

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 202416822...
Checkpoint 202416822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,962.05829
Policy Entropy: 0.50617
Value Function Loss: 0.29263

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03015
Policy Update Magnitude: 0.01908
Value Function Update Magnitude: 0.01575

Collected Steps per Second: 21,220.08806
Overall Steps per Second: 16,113.85302

Timestep Collection Time: 2.35795
Timestep Consumption Time: 0.74720
PPO Batch Consumption Time: 0.05955
Total Iteration Time: 3.10515

Cumulative Model Updates: 12,127
Cumulative Timesteps: 202,466,858

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,278.89391
Policy Entropy: 0.50859
Value Function Loss: 0.26936

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04786
Policy Update Magnitude: 0.02027
Value Function Update Magnitude: 0.01603

Collected Steps per Second: 18,591.65984
Overall Steps per Second: 14,860.06534

Timestep Collection Time: 2.69088
Timestep Consumption Time: 0.67572
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 3.36661

Cumulative Model Updates: 12,130
Cumulative Timesteps: 202,516,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 202516886...
Checkpoint 202516886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,621.60767
Policy Entropy: 0.49884
Value Function Loss: 0.30603

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04482
Policy Update Magnitude: 0.01699
Value Function Update Magnitude: 0.01646

Collected Steps per Second: 23,412.87649
Overall Steps per Second: 16,519.92034

Timestep Collection Time: 2.13677
Timestep Consumption Time: 0.89157
PPO Batch Consumption Time: 0.08152
Total Iteration Time: 3.02834

Cumulative Model Updates: 12,133
Cumulative Timesteps: 202,566,914

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,101.55117
Policy Entropy: 0.50141
Value Function Loss: 0.29205

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.04135
Policy Update Magnitude: 0.01653
Value Function Update Magnitude: 0.01658

Collected Steps per Second: 20,743.37917
Overall Steps per Second: 14,898.21671

Timestep Collection Time: 2.41243
Timestep Consumption Time: 0.94649
PPO Batch Consumption Time: 0.09769
Total Iteration Time: 3.35893

Cumulative Model Updates: 12,136
Cumulative Timesteps: 202,616,956

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 202616956...
Checkpoint 202616956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,765.66080
Policy Entropy: 0.50013
Value Function Loss: 0.29666

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03961
Policy Update Magnitude: 0.01817
Value Function Update Magnitude: 0.01778

Collected Steps per Second: 20,135.73298
Overall Steps per Second: 15,267.99275

Timestep Collection Time: 2.48335
Timestep Consumption Time: 0.79174
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 3.27509

Cumulative Model Updates: 12,139
Cumulative Timesteps: 202,666,960

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,535.72341
Policy Entropy: 0.50524
Value Function Loss: 0.26730

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.04179
Policy Update Magnitude: 0.01718
Value Function Update Magnitude: 0.01838

Collected Steps per Second: 21,259.02613
Overall Steps per Second: 15,235.46521

Timestep Collection Time: 2.35307
Timestep Consumption Time: 0.93032
PPO Batch Consumption Time: 0.09989
Total Iteration Time: 3.28339

Cumulative Model Updates: 12,142
Cumulative Timesteps: 202,716,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 202716984...
Checkpoint 202716984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,847.61266
Policy Entropy: 0.50081
Value Function Loss: 0.27207

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04576
Policy Update Magnitude: 0.01635
Value Function Update Magnitude: 0.01816

Collected Steps per Second: 23,079.67318
Overall Steps per Second: 16,768.99054

Timestep Collection Time: 2.16719
Timestep Consumption Time: 0.81558
PPO Batch Consumption Time: 0.05878
Total Iteration Time: 2.98277

Cumulative Model Updates: 12,145
Cumulative Timesteps: 202,767,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,278.24825
Policy Entropy: 0.49627
Value Function Loss: 0.26698

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03313
Policy Update Magnitude: 0.01584
Value Function Update Magnitude: 0.01776

Collected Steps per Second: 19,953.33428
Overall Steps per Second: 14,699.86531

Timestep Collection Time: 2.50745
Timestep Consumption Time: 0.89612
PPO Batch Consumption Time: 0.08414
Total Iteration Time: 3.40357

Cumulative Model Updates: 12,148
Cumulative Timesteps: 202,817,034

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 202817034...
Checkpoint 202817034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,458.31341
Policy Entropy: 0.49267
Value Function Loss: 0.28749

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.01539
Value Function Update Magnitude: 0.01664

Collected Steps per Second: 22,903.63535
Overall Steps per Second: 16,740.03348

Timestep Collection Time: 2.18323
Timestep Consumption Time: 0.80386
PPO Batch Consumption Time: 0.05846
Total Iteration Time: 2.98709

Cumulative Model Updates: 12,151
Cumulative Timesteps: 202,867,038

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,899.07995
Policy Entropy: 0.49674
Value Function Loss: 0.30471

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02039
Policy Update Magnitude: 0.01764
Value Function Update Magnitude: 0.01867

Collected Steps per Second: 20,586.95547
Overall Steps per Second: 14,803.10973

Timestep Collection Time: 2.42911
Timestep Consumption Time: 0.94910
PPO Batch Consumption Time: 0.10735
Total Iteration Time: 3.37821

Cumulative Model Updates: 12,154
Cumulative Timesteps: 202,917,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 202917046...
Checkpoint 202917046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,399.91783
Policy Entropy: 0.50134
Value Function Loss: 0.30363

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03413
Policy Update Magnitude: 0.01805
Value Function Update Magnitude: 0.01933

Collected Steps per Second: 22,774.76449
Overall Steps per Second: 15,708.27507

Timestep Collection Time: 2.19550
Timestep Consumption Time: 0.98766
PPO Batch Consumption Time: 0.11230
Total Iteration Time: 3.18316

Cumulative Model Updates: 12,157
Cumulative Timesteps: 202,967,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,377.43787
Policy Entropy: 0.49749
Value Function Loss: 0.33820

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02985
Policy Update Magnitude: 0.01731
Value Function Update Magnitude: 0.01998

Collected Steps per Second: 22,047.98340
Overall Steps per Second: 16,251.24801

Timestep Collection Time: 2.26941
Timestep Consumption Time: 0.80949
PPO Batch Consumption Time: 0.06192
Total Iteration Time: 3.07890

Cumulative Model Updates: 12,160
Cumulative Timesteps: 203,017,084

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 203017084...
Checkpoint 203017084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,909.96880
Policy Entropy: 0.49556
Value Function Loss: 0.32978

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03199
Policy Update Magnitude: 0.01895
Value Function Update Magnitude: 0.01933

Collected Steps per Second: 19,792.44057
Overall Steps per Second: 15,383.51230

Timestep Collection Time: 2.52682
Timestep Consumption Time: 0.72419
PPO Batch Consumption Time: 0.02933
Total Iteration Time: 3.25101

Cumulative Model Updates: 12,163
Cumulative Timesteps: 203,067,096

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,433.09231
Policy Entropy: 0.48423
Value Function Loss: 0.35949

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04733
Policy Update Magnitude: 0.01921
Value Function Update Magnitude: 0.02576

Collected Steps per Second: 22,864.90002
Overall Steps per Second: 17,847.24693

Timestep Collection Time: 2.18755
Timestep Consumption Time: 0.61502
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 2.80256

Cumulative Model Updates: 12,166
Cumulative Timesteps: 203,117,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 203117114...
Checkpoint 203117114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,165.85721
Policy Entropy: 0.48618
Value Function Loss: 0.34797

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.06093
Policy Update Magnitude: 0.01777
Value Function Update Magnitude: 0.02309

Collected Steps per Second: 21,170.53811
Overall Steps per Second: 15,541.52332

Timestep Collection Time: 2.36291
Timestep Consumption Time: 0.85583
PPO Batch Consumption Time: 0.09729
Total Iteration Time: 3.21873

Cumulative Model Updates: 12,169
Cumulative Timesteps: 203,167,138

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,019.22347
Policy Entropy: 0.48522
Value Function Loss: 0.35272

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03351
Policy Update Magnitude: 0.01785
Value Function Update Magnitude: 0.02135

Collected Steps per Second: 22,253.72152
Overall Steps per Second: 16,775.80440

Timestep Collection Time: 2.24816
Timestep Consumption Time: 0.73411
PPO Batch Consumption Time: 0.06245
Total Iteration Time: 2.98227

Cumulative Model Updates: 12,172
Cumulative Timesteps: 203,217,168

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 203217168...
Checkpoint 203217168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,943.10860
Policy Entropy: 0.49185
Value Function Loss: 0.34509

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02603
Policy Update Magnitude: 0.01968
Value Function Update Magnitude: 0.02267

Collected Steps per Second: 19,961.36865
Overall Steps per Second: 14,629.01140

Timestep Collection Time: 2.50584
Timestep Consumption Time: 0.91339
PPO Batch Consumption Time: 0.10833
Total Iteration Time: 3.41923

Cumulative Model Updates: 12,175
Cumulative Timesteps: 203,267,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,622.53962
Policy Entropy: 0.50085
Value Function Loss: 0.30361

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.03103
Policy Update Magnitude: 0.01808
Value Function Update Magnitude: 0.01953

Collected Steps per Second: 22,208.65175
Overall Steps per Second: 16,127.86840

Timestep Collection Time: 2.25228
Timestep Consumption Time: 0.84919
PPO Batch Consumption Time: 0.07445
Total Iteration Time: 3.10146

Cumulative Model Updates: 12,178
Cumulative Timesteps: 203,317,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 203317208...
Checkpoint 203317208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,350.77995
Policy Entropy: 0.50555
Value Function Loss: 0.31249

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02530
Policy Update Magnitude: 0.01949
Value Function Update Magnitude: 0.01898

Collected Steps per Second: 23,037.48705
Overall Steps per Second: 16,425.67607

Timestep Collection Time: 2.17090
Timestep Consumption Time: 0.87385
PPO Batch Consumption Time: 0.08668
Total Iteration Time: 3.04475

Cumulative Model Updates: 12,181
Cumulative Timesteps: 203,367,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,981.80325
Policy Entropy: 0.50607
Value Function Loss: 0.29911

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04141
Policy Update Magnitude: 0.01887
Value Function Update Magnitude: 0.01722

Collected Steps per Second: 22,058.27696
Overall Steps per Second: 16,505.37762

Timestep Collection Time: 2.26681
Timestep Consumption Time: 0.76262
PPO Batch Consumption Time: 0.05446
Total Iteration Time: 3.02944

Cumulative Model Updates: 12,184
Cumulative Timesteps: 203,417,222

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 203417222...
Checkpoint 203417222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,292.30645
Policy Entropy: 0.50039
Value Function Loss: 0.31545

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03457
Policy Update Magnitude: 0.01913
Value Function Update Magnitude: 0.01699

Collected Steps per Second: 20,525.02879
Overall Steps per Second: 14,838.93159

Timestep Collection Time: 2.43819
Timestep Consumption Time: 0.93429
PPO Batch Consumption Time: 0.10073
Total Iteration Time: 3.37248

Cumulative Model Updates: 12,187
Cumulative Timesteps: 203,467,266

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,682.83894
Policy Entropy: 0.49986
Value Function Loss: 0.34113

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04151
Policy Update Magnitude: 0.01986
Value Function Update Magnitude: 0.02457

Collected Steps per Second: 20,524.21156
Overall Steps per Second: 15,198.31668

Timestep Collection Time: 2.43790
Timestep Consumption Time: 0.85431
PPO Batch Consumption Time: 0.06452
Total Iteration Time: 3.29221

Cumulative Model Updates: 12,190
Cumulative Timesteps: 203,517,302

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 203517302...
Checkpoint 203517302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,669.47355
Policy Entropy: 0.49356
Value Function Loss: 0.34487

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02938
Policy Update Magnitude: 0.01983
Value Function Update Magnitude: 0.02328

Collected Steps per Second: 21,858.16141
Overall Steps per Second: 16,186.79151

Timestep Collection Time: 2.28766
Timestep Consumption Time: 0.80153
PPO Batch Consumption Time: 0.05978
Total Iteration Time: 3.08919

Cumulative Model Updates: 12,193
Cumulative Timesteps: 203,567,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,190.34180
Policy Entropy: 0.50067
Value Function Loss: 0.30377

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03242
Policy Update Magnitude: 0.02006
Value Function Update Magnitude: 0.02285

Collected Steps per Second: 20,099.12358
Overall Steps per Second: 14,875.85331

Timestep Collection Time: 2.48827
Timestep Consumption Time: 0.87369
PPO Batch Consumption Time: 0.08394
Total Iteration Time: 3.36196

Cumulative Model Updates: 12,196
Cumulative Timesteps: 203,617,318

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 203617318...
Checkpoint 203617318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,779.46068
Policy Entropy: 0.49426
Value Function Loss: 0.27150

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02331
Policy Update Magnitude: 0.01992
Value Function Update Magnitude: 0.02104

Collected Steps per Second: 22,453.89495
Overall Steps per Second: 15,760.65533

Timestep Collection Time: 2.22759
Timestep Consumption Time: 0.94601
PPO Batch Consumption Time: 0.10673
Total Iteration Time: 3.17360

Cumulative Model Updates: 12,199
Cumulative Timesteps: 203,667,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,899.74267
Policy Entropy: 0.49938
Value Function Loss: 0.24091

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03249
Policy Update Magnitude: 0.01896
Value Function Update Magnitude: 0.01914

Collected Steps per Second: 23,155.26347
Overall Steps per Second: 16,785.77118

Timestep Collection Time: 2.15985
Timestep Consumption Time: 0.81957
PPO Batch Consumption Time: 0.06180
Total Iteration Time: 2.97943

Cumulative Model Updates: 12,202
Cumulative Timesteps: 203,717,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 203717348...
Checkpoint 203717348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,912.97039
Policy Entropy: 0.49434
Value Function Loss: 0.26903

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.05109
Policy Update Magnitude: 0.01704
Value Function Update Magnitude: 0.01803

Collected Steps per Second: 21,054.22695
Overall Steps per Second: 14,780.29582

Timestep Collection Time: 2.37529
Timestep Consumption Time: 1.00826
PPO Batch Consumption Time: 0.12756
Total Iteration Time: 3.38356

Cumulative Model Updates: 12,205
Cumulative Timesteps: 203,767,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,130.21222
Policy Entropy: 0.49672
Value Function Loss: 0.29055

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04573
Policy Update Magnitude: 0.01649
Value Function Update Magnitude: 0.01845

Collected Steps per Second: 23,271.84057
Overall Steps per Second: 16,577.85272

Timestep Collection Time: 2.14861
Timestep Consumption Time: 0.86759
PPO Batch Consumption Time: 0.07934
Total Iteration Time: 3.01619

Cumulative Model Updates: 12,208
Cumulative Timesteps: 203,817,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 203817360...
Checkpoint 203817360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,179.53329
Policy Entropy: 0.49306
Value Function Loss: 0.28226

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.06255
Policy Update Magnitude: 0.01722
Value Function Update Magnitude: 0.01820

Collected Steps per Second: 22,601.34400
Overall Steps per Second: 16,513.67366

Timestep Collection Time: 2.21243
Timestep Consumption Time: 0.81560
PPO Batch Consumption Time: 0.08334
Total Iteration Time: 3.02804

Cumulative Model Updates: 12,211
Cumulative Timesteps: 203,867,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,177.81117
Policy Entropy: 0.49887
Value Function Loss: 0.25676

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.05695
Policy Update Magnitude: 0.01695
Value Function Update Magnitude: 0.01875

Collected Steps per Second: 21,004.15742
Overall Steps per Second: 15,066.27202

Timestep Collection Time: 2.38191
Timestep Consumption Time: 0.93875
PPO Batch Consumption Time: 0.12404
Total Iteration Time: 3.32066

Cumulative Model Updates: 12,214
Cumulative Timesteps: 203,917,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 203917394...
Checkpoint 203917394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,436.58551
Policy Entropy: 0.49831
Value Function Loss: 0.25247

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04697
Policy Update Magnitude: 0.01733
Value Function Update Magnitude: 0.02012

Collected Steps per Second: 22,414.32094
Overall Steps per Second: 16,891.17385

Timestep Collection Time: 2.23197
Timestep Consumption Time: 0.72982
PPO Batch Consumption Time: 0.06207
Total Iteration Time: 2.96178

Cumulative Model Updates: 12,217
Cumulative Timesteps: 203,967,422

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,100.54048
Policy Entropy: 0.49882
Value Function Loss: 0.24874

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03225
Policy Update Magnitude: 0.01797
Value Function Update Magnitude: 0.01990

Collected Steps per Second: 22,610.35351
Overall Steps per Second: 16,214.29766

Timestep Collection Time: 2.21217
Timestep Consumption Time: 0.87264
PPO Batch Consumption Time: 0.08484
Total Iteration Time: 3.08481

Cumulative Model Updates: 12,220
Cumulative Timesteps: 204,017,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 204017440...
Checkpoint 204017440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,705.09802
Policy Entropy: 0.49691
Value Function Loss: 0.26082

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.01538
Value Function Update Magnitude: 0.01668

Collected Steps per Second: 21,701.37759
Overall Steps per Second: 15,884.34066

Timestep Collection Time: 2.30492
Timestep Consumption Time: 0.84409
PPO Batch Consumption Time: 0.07716
Total Iteration Time: 3.14901

Cumulative Model Updates: 12,223
Cumulative Timesteps: 204,067,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,123.08879
Policy Entropy: 0.49255
Value Function Loss: 0.25254

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02864
Policy Update Magnitude: 0.01536
Value Function Update Magnitude: 0.01740

Collected Steps per Second: 23,241.72274
Overall Steps per Second: 17,054.16256

Timestep Collection Time: 2.15242
Timestep Consumption Time: 0.78094
PPO Batch Consumption Time: 0.06389
Total Iteration Time: 2.93336

Cumulative Model Updates: 12,226
Cumulative Timesteps: 204,117,486

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 204117486...
Checkpoint 204117486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,309.71237
Policy Entropy: 0.49486
Value Function Loss: 0.26899

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02947
Policy Update Magnitude: 0.01725
Value Function Update Magnitude: 0.01638

Collected Steps per Second: 22,962.49936
Overall Steps per Second: 16,453.39291

Timestep Collection Time: 2.17842
Timestep Consumption Time: 0.86180
PPO Batch Consumption Time: 0.07693
Total Iteration Time: 3.04022

Cumulative Model Updates: 12,229
Cumulative Timesteps: 204,167,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,498.57064
Policy Entropy: 0.49295
Value Function Loss: 0.25337

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.03129
Policy Update Magnitude: 0.01616
Value Function Update Magnitude: 0.01884

Collected Steps per Second: 22,762.56165
Overall Steps per Second: 15,908.00037

Timestep Collection Time: 2.19738
Timestep Consumption Time: 0.94682
PPO Batch Consumption Time: 0.10628
Total Iteration Time: 3.14420

Cumulative Model Updates: 12,232
Cumulative Timesteps: 204,217,526

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 204217526...
Checkpoint 204217526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,412.04403
Policy Entropy: 0.49796
Value Function Loss: 0.24498

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02733
Policy Update Magnitude: 0.01620
Value Function Update Magnitude: 0.02008

Collected Steps per Second: 22,690.31083
Overall Steps per Second: 16,611.90372

Timestep Collection Time: 2.20411
Timestep Consumption Time: 0.80650
PPO Batch Consumption Time: 0.05914
Total Iteration Time: 3.01061

Cumulative Model Updates: 12,235
Cumulative Timesteps: 204,267,538

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,877.66140
Policy Entropy: 0.49167
Value Function Loss: 0.24025

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02267
Policy Update Magnitude: 0.01713
Value Function Update Magnitude: 0.02053

Collected Steps per Second: 20,551.19377
Overall Steps per Second: 14,733.64254

Timestep Collection Time: 2.43353
Timestep Consumption Time: 0.96088
PPO Batch Consumption Time: 0.10621
Total Iteration Time: 3.39441

Cumulative Model Updates: 12,238
Cumulative Timesteps: 204,317,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 204317550...
Checkpoint 204317550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,355.00744
Policy Entropy: 0.48904
Value Function Loss: 0.26608

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00970
Policy Update Magnitude: 0.01900
Value Function Update Magnitude: 0.01862

Collected Steps per Second: 22,806.22409
Overall Steps per Second: 15,761.76807

Timestep Collection Time: 2.19361
Timestep Consumption Time: 0.98040
PPO Batch Consumption Time: 0.11895
Total Iteration Time: 3.17401

Cumulative Model Updates: 12,241
Cumulative Timesteps: 204,367,578

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,862.68911
Policy Entropy: 0.48890
Value Function Loss: 0.25719

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02211
Policy Update Magnitude: 0.01814
Value Function Update Magnitude: 0.02178

Collected Steps per Second: 23,479.61775
Overall Steps per Second: 16,983.13431

Timestep Collection Time: 2.12976
Timestep Consumption Time: 0.81469
PPO Batch Consumption Time: 0.06438
Total Iteration Time: 2.94445

Cumulative Model Updates: 12,244
Cumulative Timesteps: 204,417,584

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 204417584...
Checkpoint 204417584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,039.77482
Policy Entropy: 0.49013
Value Function Loss: 0.23999

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01798
Policy Update Magnitude: 0.01702
Value Function Update Magnitude: 0.02227

Collected Steps per Second: 23,036.09610
Overall Steps per Second: 16,804.00038

Timestep Collection Time: 2.17068
Timestep Consumption Time: 0.80504
PPO Batch Consumption Time: 0.06375
Total Iteration Time: 2.97572

Cumulative Model Updates: 12,247
Cumulative Timesteps: 204,467,588

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,450.00274
Policy Entropy: 0.49602
Value Function Loss: 0.21920

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01232
Policy Update Magnitude: 0.01689
Value Function Update Magnitude: 0.01901

Collected Steps per Second: 22,479.53436
Overall Steps per Second: 16,879.22379

Timestep Collection Time: 2.22442
Timestep Consumption Time: 0.73804
PPO Batch Consumption Time: 0.06556
Total Iteration Time: 2.96246

Cumulative Model Updates: 12,250
Cumulative Timesteps: 204,517,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 204517592...
Checkpoint 204517592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,976.61876
Policy Entropy: 0.49725
Value Function Loss: 0.22493

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01870
Policy Update Magnitude: 0.01622
Value Function Update Magnitude: 0.01726

Collected Steps per Second: 21,886.42963
Overall Steps per Second: 16,665.06537

Timestep Collection Time: 2.28562
Timestep Consumption Time: 0.71611
PPO Batch Consumption Time: 0.05987
Total Iteration Time: 3.00173

Cumulative Model Updates: 12,253
Cumulative Timesteps: 204,567,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,471.67804
Policy Entropy: 0.50110
Value Function Loss: 0.23843

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02147
Policy Update Magnitude: 0.01595
Value Function Update Magnitude: 0.01787

Collected Steps per Second: 22,199.86151
Overall Steps per Second: 16,758.30152

Timestep Collection Time: 2.25326
Timestep Consumption Time: 0.73165
PPO Batch Consumption Time: 0.06090
Total Iteration Time: 2.98491

Cumulative Model Updates: 12,256
Cumulative Timesteps: 204,617,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 204617638...
Checkpoint 204617638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,510.95442
Policy Entropy: 0.50276
Value Function Loss: 0.21656

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03217
Policy Update Magnitude: 0.01752
Value Function Update Magnitude: 0.01905

Collected Steps per Second: 22,209.37439
Overall Steps per Second: 16,532.86641

Timestep Collection Time: 2.25148
Timestep Consumption Time: 0.77304
PPO Batch Consumption Time: 0.06283
Total Iteration Time: 3.02452

Cumulative Model Updates: 12,259
Cumulative Timesteps: 204,667,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,290.15414
Policy Entropy: 0.49636
Value Function Loss: 0.23266

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02239
Policy Update Magnitude: 0.01701
Value Function Update Magnitude: 0.02177

Collected Steps per Second: 23,103.98280
Overall Steps per Second: 16,975.93605

Timestep Collection Time: 2.16422
Timestep Consumption Time: 0.78125
PPO Batch Consumption Time: 0.06516
Total Iteration Time: 2.94546

Cumulative Model Updates: 12,262
Cumulative Timesteps: 204,717,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 204717644...
Checkpoint 204717644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,680.10743
Policy Entropy: 0.49182
Value Function Loss: 0.26260

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02952
Policy Update Magnitude: 0.01832
Value Function Update Magnitude: 0.01900

Collected Steps per Second: 23,005.59218
Overall Steps per Second: 16,864.23305

Timestep Collection Time: 2.17434
Timestep Consumption Time: 0.79182
PPO Batch Consumption Time: 0.06438
Total Iteration Time: 2.96616

Cumulative Model Updates: 12,265
Cumulative Timesteps: 204,767,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,680.10743
Policy Entropy: 0.49025
Value Function Loss: 0.25845

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02991
Policy Update Magnitude: 0.02058
Value Function Update Magnitude: 0.02355

Collected Steps per Second: 23,134.16167
Overall Steps per Second: 17,043.43680

Timestep Collection Time: 2.16148
Timestep Consumption Time: 0.77244
PPO Batch Consumption Time: 0.06218
Total Iteration Time: 2.93392

Cumulative Model Updates: 12,268
Cumulative Timesteps: 204,817,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 204817670...
Checkpoint 204817670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,507.98266
Policy Entropy: 0.49437
Value Function Loss: 0.23950

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03224
Policy Update Magnitude: 0.02083
Value Function Update Magnitude: 0.02126

Collected Steps per Second: 19,945.92976
Overall Steps per Second: 14,158.42683

Timestep Collection Time: 2.50748
Timestep Consumption Time: 1.02498
PPO Batch Consumption Time: 0.11068
Total Iteration Time: 3.53245

Cumulative Model Updates: 12,271
Cumulative Timesteps: 204,867,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,513.51193
Policy Entropy: 0.49905
Value Function Loss: 0.21343

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01948
Policy Update Magnitude: 0.01965
Value Function Update Magnitude: 0.01773

Collected Steps per Second: 23,255.81828
Overall Steps per Second: 16,604.95160

Timestep Collection Time: 2.15000
Timestep Consumption Time: 0.86115
PPO Batch Consumption Time: 0.07809
Total Iteration Time: 3.01115

Cumulative Model Updates: 12,274
Cumulative Timesteps: 204,917,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 204917684...
Checkpoint 204917684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,950.31047
Policy Entropy: 0.50184
Value Function Loss: 0.22017

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.02019
Policy Update Magnitude: 0.01820
Value Function Update Magnitude: 0.01637

Collected Steps per Second: 22,763.84927
Overall Steps per Second: 15,902.93450

Timestep Collection Time: 2.19770
Timestep Consumption Time: 0.94814
PPO Batch Consumption Time: 0.10355
Total Iteration Time: 3.14583

Cumulative Model Updates: 12,277
Cumulative Timesteps: 204,967,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,883.89980
Policy Entropy: 0.49846
Value Function Loss: 0.24333

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03380
Policy Update Magnitude: 0.01768
Value Function Update Magnitude: 0.01743

Collected Steps per Second: 22,676.13598
Overall Steps per Second: 16,614.93165

Timestep Collection Time: 2.20496
Timestep Consumption Time: 0.80438
PPO Batch Consumption Time: 0.06231
Total Iteration Time: 3.00934

Cumulative Model Updates: 12,280
Cumulative Timesteps: 205,017,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 205017712...
Checkpoint 205017712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,776.95183
Policy Entropy: 0.49887
Value Function Loss: 0.22904

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02855
Policy Update Magnitude: 0.01615
Value Function Update Magnitude: 0.01595

Collected Steps per Second: 20,589.03924
Overall Steps per Second: 14,764.95128

Timestep Collection Time: 2.42848
Timestep Consumption Time: 0.95792
PPO Batch Consumption Time: 0.10669
Total Iteration Time: 3.38640

Cumulative Model Updates: 12,283
Cumulative Timesteps: 205,067,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,910.21195
Policy Entropy: 0.49889
Value Function Loss: 0.22448

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01815
Policy Update Magnitude: 0.01644
Value Function Update Magnitude: 0.01714

Collected Steps per Second: 23,183.70051
Overall Steps per Second: 16,470.26377

Timestep Collection Time: 2.15755
Timestep Consumption Time: 0.87944
PPO Batch Consumption Time: 0.08317
Total Iteration Time: 3.03699

Cumulative Model Updates: 12,286
Cumulative Timesteps: 205,117,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 205117732...
Checkpoint 205117732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,148.40047
Policy Entropy: 0.49931
Value Function Loss: 0.23274

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01974
Policy Update Magnitude: 0.01807
Value Function Update Magnitude: 0.01527

Collected Steps per Second: 21,821.81002
Overall Steps per Second: 15,075.22783

Timestep Collection Time: 2.29174
Timestep Consumption Time: 1.02562
PPO Batch Consumption Time: 0.12794
Total Iteration Time: 3.31736

Cumulative Model Updates: 12,289
Cumulative Timesteps: 205,167,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,357.92445
Policy Entropy: 0.49604
Value Function Loss: 0.27314

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03435
Policy Update Magnitude: 0.01912
Value Function Update Magnitude: 0.01996

Collected Steps per Second: 23,422.24395
Overall Steps per Second: 17,004.94831

Timestep Collection Time: 2.13532
Timestep Consumption Time: 0.80582
PPO Batch Consumption Time: 0.06123
Total Iteration Time: 2.94114

Cumulative Model Updates: 12,292
Cumulative Timesteps: 205,217,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 205217756...
Checkpoint 205217756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,432.07698
Policy Entropy: 0.49351
Value Function Loss: 0.29437

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03179
Policy Update Magnitude: 0.01933
Value Function Update Magnitude: 0.01932

Collected Steps per Second: 22,170.33105
Overall Steps per Second: 16,368.10093

Timestep Collection Time: 2.25545
Timestep Consumption Time: 0.79952
PPO Batch Consumption Time: 0.08693
Total Iteration Time: 3.05497

Cumulative Model Updates: 12,295
Cumulative Timesteps: 205,267,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,683.07062
Policy Entropy: 0.49284
Value Function Loss: 0.29258

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02910
Policy Update Magnitude: 0.02020
Value Function Update Magnitude: 0.01940

Collected Steps per Second: 22,537.10464
Overall Steps per Second: 16,962.06556

Timestep Collection Time: 2.21856
Timestep Consumption Time: 0.72919
PPO Batch Consumption Time: 0.06337
Total Iteration Time: 2.94775

Cumulative Model Updates: 12,298
Cumulative Timesteps: 205,317,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 205317760...
Checkpoint 205317760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,954.99753
Policy Entropy: 0.50274
Value Function Loss: 0.26885

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03253
Policy Update Magnitude: 0.01934
Value Function Update Magnitude: 0.02188

Collected Steps per Second: 22,552.00811
Overall Steps per Second: 16,506.93699

Timestep Collection Time: 2.21745
Timestep Consumption Time: 0.81206
PPO Batch Consumption Time: 0.07991
Total Iteration Time: 3.02951

Cumulative Model Updates: 12,301
Cumulative Timesteps: 205,367,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,864.30143
Policy Entropy: 0.49956
Value Function Loss: 0.27713

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03114
Policy Update Magnitude: 0.01937
Value Function Update Magnitude: 0.02502

Collected Steps per Second: 22,041.21668
Overall Steps per Second: 16,738.17332

Timestep Collection Time: 2.26984
Timestep Consumption Time: 0.71914
PPO Batch Consumption Time: 0.06014
Total Iteration Time: 2.98898

Cumulative Model Updates: 12,304
Cumulative Timesteps: 205,417,798

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 205417798...
Checkpoint 205417798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,681.37224
Policy Entropy: 0.51129
Value Function Loss: 0.25831

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03207
Policy Update Magnitude: 0.02101
Value Function Update Magnitude: 0.02337

Collected Steps per Second: 19,432.50403
Overall Steps per Second: 14,049.08120

Timestep Collection Time: 2.57301
Timestep Consumption Time: 0.98594
PPO Batch Consumption Time: 0.12285
Total Iteration Time: 3.55895

Cumulative Model Updates: 12,307
Cumulative Timesteps: 205,467,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,519.14616
Policy Entropy: 0.50494
Value Function Loss: 0.24834

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02709
Policy Update Magnitude: 0.02492
Value Function Update Magnitude: 0.01929

Collected Steps per Second: 23,059.46378
Overall Steps per Second: 16,863.70548

Timestep Collection Time: 2.16900
Timestep Consumption Time: 0.79690
PPO Batch Consumption Time: 0.06497
Total Iteration Time: 2.96590

Cumulative Model Updates: 12,310
Cumulative Timesteps: 205,517,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 205517814...
Checkpoint 205517814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,435.67543
Policy Entropy: 0.50272
Value Function Loss: 0.24619

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01794
Policy Update Magnitude: 0.02058
Value Function Update Magnitude: 0.01876

Collected Steps per Second: 22,560.70140
Overall Steps per Second: 16,078.36465

Timestep Collection Time: 2.21722
Timestep Consumption Time: 0.89392
PPO Batch Consumption Time: 0.08458
Total Iteration Time: 3.11114

Cumulative Model Updates: 12,313
Cumulative Timesteps: 205,567,836

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,758.31716
Policy Entropy: 0.49287
Value Function Loss: 0.28362

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02381
Policy Update Magnitude: 0.01866
Value Function Update Magnitude: 0.02166

Collected Steps per Second: 23,282.38337
Overall Steps per Second: 15,991.40257

Timestep Collection Time: 2.14935
Timestep Consumption Time: 0.97996
PPO Batch Consumption Time: 0.11971
Total Iteration Time: 3.12931

Cumulative Model Updates: 12,316
Cumulative Timesteps: 205,617,878

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 205617878...
Checkpoint 205617878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,387.63452
Policy Entropy: 0.48984
Value Function Loss: 0.26236

Mean KL Divergence: 0.00123
SB3 Clip Fraction: 0.01051
Policy Update Magnitude: 0.01901
Value Function Update Magnitude: 0.01982

Collected Steps per Second: 22,738.84976
Overall Steps per Second: 15,965.93899

Timestep Collection Time: 2.19950
Timestep Consumption Time: 0.93305
PPO Batch Consumption Time: 0.10533
Total Iteration Time: 3.13254

Cumulative Model Updates: 12,319
Cumulative Timesteps: 205,667,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,595.80222
Policy Entropy: 0.48893
Value Function Loss: 0.27638

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01707
Policy Update Magnitude: 0.02011
Value Function Update Magnitude: 0.02036

Collected Steps per Second: 23,236.96271
Overall Steps per Second: 17,015.75432

Timestep Collection Time: 2.15235
Timestep Consumption Time: 0.78693
PPO Batch Consumption Time: 0.06645
Total Iteration Time: 2.93928

Cumulative Model Updates: 12,322
Cumulative Timesteps: 205,717,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 205717906...
Checkpoint 205717906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,994.12754
Policy Entropy: 0.49247
Value Function Loss: 0.23915

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01492
Policy Update Magnitude: 0.01914
Value Function Update Magnitude: 0.01918

Collected Steps per Second: 22,886.19982
Overall Steps per Second: 16,684.96255

Timestep Collection Time: 2.18542
Timestep Consumption Time: 0.81225
PPO Batch Consumption Time: 0.06496
Total Iteration Time: 2.99767

Cumulative Model Updates: 12,325
Cumulative Timesteps: 205,767,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,849.70346
Policy Entropy: 0.49246
Value Function Loss: 0.24339

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01621
Policy Update Magnitude: 0.02035
Value Function Update Magnitude: 0.02240

Collected Steps per Second: 23,091.77308
Overall Steps per Second: 16,800.99242

Timestep Collection Time: 2.16597
Timestep Consumption Time: 0.81100
PPO Batch Consumption Time: 0.06639
Total Iteration Time: 2.97697

Cumulative Model Updates: 12,328
Cumulative Timesteps: 205,817,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 205817938...
Checkpoint 205817938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,525.47809
Policy Entropy: 0.49348
Value Function Loss: 0.21912

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01547
Policy Update Magnitude: 0.02168
Value Function Update Magnitude: 0.02473

Collected Steps per Second: 22,635.50644
Overall Steps per Second: 16,508.56111

Timestep Collection Time: 2.20971
Timestep Consumption Time: 0.82011
PPO Batch Consumption Time: 0.06507
Total Iteration Time: 3.02982

Cumulative Model Updates: 12,331
Cumulative Timesteps: 205,867,956

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,989.23584
Policy Entropy: 0.49839
Value Function Loss: 0.22683

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02237
Policy Update Magnitude: 0.01997
Value Function Update Magnitude: 0.02568

Collected Steps per Second: 23,294.95633
Overall Steps per Second: 16,823.15372

Timestep Collection Time: 2.14768
Timestep Consumption Time: 0.82620
PPO Batch Consumption Time: 0.06811
Total Iteration Time: 2.97388

Cumulative Model Updates: 12,334
Cumulative Timesteps: 205,917,986

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 205917986...
Checkpoint 205917986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,399.10842
Policy Entropy: 0.49540
Value Function Loss: 0.25413

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.01894
Value Function Update Magnitude: 0.02311

Collected Steps per Second: 22,795.00658
Overall Steps per Second: 16,631.17603

Timestep Collection Time: 2.19495
Timestep Consumption Time: 0.81349
PPO Batch Consumption Time: 0.06150
Total Iteration Time: 3.00845

Cumulative Model Updates: 12,337
Cumulative Timesteps: 205,968,020

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,154.60550
Policy Entropy: 0.50223
Value Function Loss: 0.24629

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01705
Policy Update Magnitude: 0.01797
Value Function Update Magnitude: 0.02405

Collected Steps per Second: 21,008.10156
Overall Steps per Second: 14,698.63795

Timestep Collection Time: 2.38070
Timestep Consumption Time: 1.02193
PPO Batch Consumption Time: 0.12336
Total Iteration Time: 3.40263

Cumulative Model Updates: 12,340
Cumulative Timesteps: 206,018,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 206018034...
Checkpoint 206018034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,882.48101
Policy Entropy: 0.50000
Value Function Loss: 0.22995

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01879
Policy Update Magnitude: 0.01783
Value Function Update Magnitude: 0.02163

Collected Steps per Second: 22,923.96119
Overall Steps per Second: 16,388.35896

Timestep Collection Time: 2.18226
Timestep Consumption Time: 0.87027
PPO Batch Consumption Time: 0.08259
Total Iteration Time: 3.05253

Cumulative Model Updates: 12,343
Cumulative Timesteps: 206,068,060

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,340.82829
Policy Entropy: 0.49989
Value Function Loss: 0.21582

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.01819
Value Function Update Magnitude: 0.01928

Collected Steps per Second: 21,917.34877
Overall Steps per Second: 15,839.74371

Timestep Collection Time: 2.28267
Timestep Consumption Time: 0.87584
PPO Batch Consumption Time: 0.07779
Total Iteration Time: 3.15851

Cumulative Model Updates: 12,346
Cumulative Timesteps: 206,118,090

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 206118090...
Checkpoint 206118090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,860.36130
Policy Entropy: 0.49794
Value Function Loss: 0.22417

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03209
Policy Update Magnitude: 0.01671
Value Function Update Magnitude: 0.02170

Collected Steps per Second: 22,319.63966
Overall Steps per Second: 16,309.04509

Timestep Collection Time: 2.24099
Timestep Consumption Time: 0.82590
PPO Batch Consumption Time: 0.06371
Total Iteration Time: 3.06689

Cumulative Model Updates: 12,349
Cumulative Timesteps: 206,168,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,031.21256
Policy Entropy: 0.49810
Value Function Loss: 0.23379

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02571
Policy Update Magnitude: 0.01868
Value Function Update Magnitude: 0.02857

Collected Steps per Second: 23,149.32034
Overall Steps per Second: 16,174.00712

Timestep Collection Time: 2.16041
Timestep Consumption Time: 0.93171
PPO Batch Consumption Time: 0.10765
Total Iteration Time: 3.09212

Cumulative Model Updates: 12,352
Cumulative Timesteps: 206,218,120

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 206218120...
Checkpoint 206218120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,656.51896
Policy Entropy: 0.49791
Value Function Loss: 0.23973

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03975
Policy Update Magnitude: 0.02053
Value Function Update Magnitude: 0.03340

Collected Steps per Second: 23,027.49691
Overall Steps per Second: 16,802.95461

Timestep Collection Time: 2.17149
Timestep Consumption Time: 0.80441
PPO Batch Consumption Time: 0.05995
Total Iteration Time: 2.97591

Cumulative Model Updates: 12,355
Cumulative Timesteps: 206,268,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,469.13498
Policy Entropy: 0.49778
Value Function Loss: 0.25229

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03803
Policy Update Magnitude: 0.01817
Value Function Update Magnitude: 0.02778

Collected Steps per Second: 19,993.37232
Overall Steps per Second: 14,674.00557

Timestep Collection Time: 2.50133
Timestep Consumption Time: 0.90674
PPO Batch Consumption Time: 0.08767
Total Iteration Time: 3.40807

Cumulative Model Updates: 12,358
Cumulative Timesteps: 206,318,134

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 206318134...
Checkpoint 206318134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,968.51978
Policy Entropy: 0.50103
Value Function Loss: 0.21831

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03548
Policy Update Magnitude: 0.01914
Value Function Update Magnitude: 0.03996

Collected Steps per Second: 23,112.70295
Overall Steps per Second: 16,820.98857

Timestep Collection Time: 2.16349
Timestep Consumption Time: 0.80923
PPO Batch Consumption Time: 0.06066
Total Iteration Time: 2.97271

Cumulative Model Updates: 12,361
Cumulative Timesteps: 206,368,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,271.25540
Policy Entropy: 0.50023
Value Function Loss: 0.20310

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05673
Policy Update Magnitude: 0.01849
Value Function Update Magnitude: 0.03095

Collected Steps per Second: 20,759.24541
Overall Steps per Second: 14,746.19558

Timestep Collection Time: 2.40972
Timestep Consumption Time: 0.98261
PPO Batch Consumption Time: 0.11467
Total Iteration Time: 3.39233

Cumulative Model Updates: 12,364
Cumulative Timesteps: 206,418,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 206418162...
Checkpoint 206418162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,883.49243
Policy Entropy: 0.49913
Value Function Loss: 0.19495

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05245
Policy Update Magnitude: 0.01698
Value Function Update Magnitude: 0.02602

Collected Steps per Second: 22,696.92894
Overall Steps per Second: 15,708.65646

Timestep Collection Time: 2.20391
Timestep Consumption Time: 0.98045
PPO Batch Consumption Time: 0.11335
Total Iteration Time: 3.18436

Cumulative Model Updates: 12,367
Cumulative Timesteps: 206,468,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,932.54611
Policy Entropy: 0.49075
Value Function Loss: 0.22645

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04419
Policy Update Magnitude: 0.01453
Value Function Update Magnitude: 0.02208

Collected Steps per Second: 23,381.86663
Overall Steps per Second: 16,948.37189

Timestep Collection Time: 2.13875
Timestep Consumption Time: 0.81186
PPO Batch Consumption Time: 0.06490
Total Iteration Time: 2.95061

Cumulative Model Updates: 12,370
Cumulative Timesteps: 206,518,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 206518192...
Checkpoint 206518192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,824.84189
Policy Entropy: 0.48944
Value Function Loss: 0.23661

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03478
Policy Update Magnitude: 0.01763
Value Function Update Magnitude: 0.02033

Collected Steps per Second: 22,938.67207
Overall Steps per Second: 16,652.46782

Timestep Collection Time: 2.18077
Timestep Consumption Time: 0.82323
PPO Batch Consumption Time: 0.06966
Total Iteration Time: 3.00400

Cumulative Model Updates: 12,373
Cumulative Timesteps: 206,568,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,901.01672
Policy Entropy: 0.48759
Value Function Loss: 0.22560

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03397
Policy Update Magnitude: 0.01752
Value Function Update Magnitude: 0.02194

Collected Steps per Second: 22,462.80623
Overall Steps per Second: 16,568.11133

Timestep Collection Time: 2.22599
Timestep Consumption Time: 0.79198
PPO Batch Consumption Time: 0.06021
Total Iteration Time: 3.01797

Cumulative Model Updates: 12,376
Cumulative Timesteps: 206,618,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 206618218...
Checkpoint 206618218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,462.57920
Policy Entropy: 0.49179
Value Function Loss: 0.19989

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02933
Policy Update Magnitude: 0.01712
Value Function Update Magnitude: 0.02092

Collected Steps per Second: 19,409.75466
Overall Steps per Second: 14,759.04234

Timestep Collection Time: 2.57623
Timestep Consumption Time: 0.81179
PPO Batch Consumption Time: 0.08488
Total Iteration Time: 3.38802

Cumulative Model Updates: 12,379
Cumulative Timesteps: 206,668,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,499.09404
Policy Entropy: 0.49043
Value Function Loss: 0.20548

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02215
Policy Update Magnitude: 0.01713
Value Function Update Magnitude: 0.02017

Collected Steps per Second: 22,347.70749
Overall Steps per Second: 15,783.26910

Timestep Collection Time: 2.23835
Timestep Consumption Time: 0.93095
PPO Batch Consumption Time: 0.12167
Total Iteration Time: 3.16931

Cumulative Model Updates: 12,382
Cumulative Timesteps: 206,718,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 206718244...
Checkpoint 206718244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,038.68099
Policy Entropy: 0.48670
Value Function Loss: 0.22394

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02872
Policy Update Magnitude: 0.01808
Value Function Update Magnitude: 0.01881

Collected Steps per Second: 22,496.44423
Overall Steps per Second: 17,012.40950

Timestep Collection Time: 2.22364
Timestep Consumption Time: 0.71680
PPO Batch Consumption Time: 0.05973
Total Iteration Time: 2.94044

Cumulative Model Updates: 12,385
Cumulative Timesteps: 206,768,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,646.12774
Policy Entropy: 0.48399
Value Function Loss: 0.24028

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03563
Policy Update Magnitude: 0.01622
Value Function Update Magnitude: 0.02164

Collected Steps per Second: 22,507.47692
Overall Steps per Second: 16,883.37547

Timestep Collection Time: 2.22237
Timestep Consumption Time: 0.74031
PPO Batch Consumption Time: 0.06528
Total Iteration Time: 2.96268

Cumulative Model Updates: 12,388
Cumulative Timesteps: 206,818,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 206818288...
Checkpoint 206818288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,588.83259
Policy Entropy: 0.48555
Value Function Loss: 0.22468

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02060
Policy Update Magnitude: 0.01793
Value Function Update Magnitude: 0.01947

Collected Steps per Second: 22,460.41240
Overall Steps per Second: 16,490.08806

Timestep Collection Time: 2.22614
Timestep Consumption Time: 0.80599
PPO Batch Consumption Time: 0.06592
Total Iteration Time: 3.03212

Cumulative Model Updates: 12,391
Cumulative Timesteps: 206,868,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,355.06527
Policy Entropy: 0.48630
Value Function Loss: 0.22553

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02655
Policy Update Magnitude: 0.01895
Value Function Update Magnitude: 0.01960

Collected Steps per Second: 22,816.02515
Overall Steps per Second: 16,700.84723

Timestep Collection Time: 2.19162
Timestep Consumption Time: 0.80248
PPO Batch Consumption Time: 0.06572
Total Iteration Time: 2.99410

Cumulative Model Updates: 12,394
Cumulative Timesteps: 206,918,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 206918292...
Checkpoint 206918292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,850.35622
Policy Entropy: 0.49079
Value Function Loss: 0.22731

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.01892
Value Function Update Magnitude: 0.01918

Collected Steps per Second: 23,024.50756
Overall Steps per Second: 16,853.50959

Timestep Collection Time: 2.17282
Timestep Consumption Time: 0.79559
PPO Batch Consumption Time: 0.06313
Total Iteration Time: 2.96840

Cumulative Model Updates: 12,397
Cumulative Timesteps: 206,968,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,846.88847
Policy Entropy: 0.49334
Value Function Loss: 0.20534

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02424
Policy Update Magnitude: 0.01983
Value Function Update Magnitude: 0.01947

Collected Steps per Second: 23,064.81112
Overall Steps per Second: 16,921.68772

Timestep Collection Time: 2.16893
Timestep Consumption Time: 0.78739
PPO Batch Consumption Time: 0.06609
Total Iteration Time: 2.95632

Cumulative Model Updates: 12,400
Cumulative Timesteps: 207,018,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 207018346...
Checkpoint 207018346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,817.81483
Policy Entropy: 0.49637
Value Function Loss: 0.18932

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03547
Policy Update Magnitude: 0.01943
Value Function Update Magnitude: 0.01833

Collected Steps per Second: 23,080.67232
Overall Steps per Second: 16,635.86776

Timestep Collection Time: 2.16761
Timestep Consumption Time: 0.83974
PPO Batch Consumption Time: 0.06571
Total Iteration Time: 3.00736

Cumulative Model Updates: 12,403
Cumulative Timesteps: 207,068,376

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,703.18407
Policy Entropy: 0.49709
Value Function Loss: 0.17549

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03268
Policy Update Magnitude: 0.01660
Value Function Update Magnitude: 0.01661

Collected Steps per Second: 23,355.47080
Overall Steps per Second: 16,901.23487

Timestep Collection Time: 2.14202
Timestep Consumption Time: 0.81800
PPO Batch Consumption Time: 0.06456
Total Iteration Time: 2.96002

Cumulative Model Updates: 12,406
Cumulative Timesteps: 207,118,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 207118404...
Checkpoint 207118404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,234.39282
Policy Entropy: 0.49390
Value Function Loss: 0.20112

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.04717
Policy Update Magnitude: 0.01670
Value Function Update Magnitude: 0.01576

Collected Steps per Second: 23,177.33291
Overall Steps per Second: 16,814.28965

Timestep Collection Time: 2.15866
Timestep Consumption Time: 0.81690
PPO Batch Consumption Time: 0.06404
Total Iteration Time: 2.97556

Cumulative Model Updates: 12,409
Cumulative Timesteps: 207,168,436

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,656.37611
Policy Entropy: 0.49226
Value Function Loss: 0.21207

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03885
Policy Update Magnitude: 0.01690
Value Function Update Magnitude: 0.02073

Collected Steps per Second: 20,652.37424
Overall Steps per Second: 15,099.93132

Timestep Collection Time: 2.42209
Timestep Consumption Time: 0.89064
PPO Batch Consumption Time: 0.07557
Total Iteration Time: 3.31273

Cumulative Model Updates: 12,412
Cumulative Timesteps: 207,218,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 207218458...
Checkpoint 207218458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,293.56128
Policy Entropy: 0.48777
Value Function Loss: 0.22548

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.01824
Value Function Update Magnitude: 0.02116

Collected Steps per Second: 22,899.08014
Overall Steps per Second: 16,551.55251

Timestep Collection Time: 2.18411
Timestep Consumption Time: 0.83761
PPO Batch Consumption Time: 0.06566
Total Iteration Time: 3.02171

Cumulative Model Updates: 12,415
Cumulative Timesteps: 207,268,472

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,957.81509
Policy Entropy: 0.48365
Value Function Loss: 0.22750

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04845
Policy Update Magnitude: 0.01808
Value Function Update Magnitude: 0.02249

Collected Steps per Second: 20,587.93213
Overall Steps per Second: 14,974.57565

Timestep Collection Time: 2.42929
Timestep Consumption Time: 0.91064
PPO Batch Consumption Time: 0.08718
Total Iteration Time: 3.33993

Cumulative Model Updates: 12,418
Cumulative Timesteps: 207,318,486

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 207318486...
Checkpoint 207318486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,641.23065
Policy Entropy: 0.48118
Value Function Loss: 0.22962

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03487
Policy Update Magnitude: 0.01864
Value Function Update Magnitude: 0.02141

Collected Steps per Second: 22,995.44395
Overall Steps per Second: 16,885.74148

Timestep Collection Time: 2.17487
Timestep Consumption Time: 0.78692
PPO Batch Consumption Time: 0.05905
Total Iteration Time: 2.96179

Cumulative Model Updates: 12,421
Cumulative Timesteps: 207,368,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,482.15768
Policy Entropy: 0.48169
Value Function Loss: 0.22625

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03416
Policy Update Magnitude: 0.01925
Value Function Update Magnitude: 0.02135

Collected Steps per Second: 20,587.86621
Overall Steps per Second: 14,684.05152

Timestep Collection Time: 2.42891
Timestep Consumption Time: 0.97656
PPO Batch Consumption Time: 0.10487
Total Iteration Time: 3.40546

Cumulative Model Updates: 12,424
Cumulative Timesteps: 207,418,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 207418504...
Checkpoint 207418504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,821.43006
Policy Entropy: 0.47982
Value Function Loss: 0.23276

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03723
Policy Update Magnitude: 0.01906
Value Function Update Magnitude: 0.02046

Collected Steps per Second: 22,680.68398
Overall Steps per Second: 15,725.18009

Timestep Collection Time: 2.20522
Timestep Consumption Time: 0.97541
PPO Batch Consumption Time: 0.11087
Total Iteration Time: 3.18063

Cumulative Model Updates: 12,427
Cumulative Timesteps: 207,468,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,044.63359
Policy Entropy: 0.47383
Value Function Loss: 0.25366

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04222
Policy Update Magnitude: 0.01844
Value Function Update Magnitude: 0.02528

Collected Steps per Second: 23,088.56575
Overall Steps per Second: 16,607.19244

Timestep Collection Time: 2.16557
Timestep Consumption Time: 0.84517
PPO Batch Consumption Time: 0.06096
Total Iteration Time: 3.01074

Cumulative Model Updates: 12,430
Cumulative Timesteps: 207,518,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 207518520...
Checkpoint 207518520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,858.64737
Policy Entropy: 0.46835
Value Function Loss: 0.27197

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.04109
Policy Update Magnitude: 0.01784
Value Function Update Magnitude: 0.02337

Collected Steps per Second: 20,366.01743
Overall Steps per Second: 14,817.58383

Timestep Collection Time: 2.45586
Timestep Consumption Time: 0.91959
PPO Batch Consumption Time: 0.08731
Total Iteration Time: 3.37545

Cumulative Model Updates: 12,433
Cumulative Timesteps: 207,568,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,118.23149
Policy Entropy: 0.46970
Value Function Loss: 0.27244

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02554
Policy Update Magnitude: 0.01748
Value Function Update Magnitude: 0.02994

Collected Steps per Second: 22,544.06084
Overall Steps per Second: 15,706.44156

Timestep Collection Time: 2.21823
Timestep Consumption Time: 0.96568
PPO Batch Consumption Time: 0.10873
Total Iteration Time: 3.18392

Cumulative Model Updates: 12,436
Cumulative Timesteps: 207,618,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 207618544...
Checkpoint 207618544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,701.67149
Policy Entropy: 0.47152
Value Function Loss: 0.25523

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02157
Policy Update Magnitude: 0.01660
Value Function Update Magnitude: 0.02734

Collected Steps per Second: 22,682.53803
Overall Steps per Second: 16,574.26631

Timestep Collection Time: 2.20487
Timestep Consumption Time: 0.81258
PPO Batch Consumption Time: 0.05840
Total Iteration Time: 3.01745

Cumulative Model Updates: 12,439
Cumulative Timesteps: 207,668,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,742.34797
Policy Entropy: 0.47707
Value Function Loss: 0.23502

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02925
Policy Update Magnitude: 0.01868
Value Function Update Magnitude: 0.02456

Collected Steps per Second: 20,941.29856
Overall Steps per Second: 14,907.52258

Timestep Collection Time: 2.38896
Timestep Consumption Time: 0.96693
PPO Batch Consumption Time: 0.11319
Total Iteration Time: 3.35589

Cumulative Model Updates: 12,442
Cumulative Timesteps: 207,718,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 207718584...
Checkpoint 207718584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,751.01574
Policy Entropy: 0.47312
Value Function Loss: 0.23092

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03266
Policy Update Magnitude: 0.02076
Value Function Update Magnitude: 0.02352

Collected Steps per Second: 22,863.82244
Overall Steps per Second: 15,802.46346

Timestep Collection Time: 2.18765
Timestep Consumption Time: 0.97755
PPO Batch Consumption Time: 0.12000
Total Iteration Time: 3.16520

Cumulative Model Updates: 12,445
Cumulative Timesteps: 207,768,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,961.99797
Policy Entropy: 0.47369
Value Function Loss: 0.24303

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.03161
Policy Update Magnitude: 0.01878
Value Function Update Magnitude: 0.02222

Collected Steps per Second: 21,487.87766
Overall Steps per Second: 16,438.83047

Timestep Collection Time: 2.32792
Timestep Consumption Time: 0.71500
PPO Batch Consumption Time: 0.06155
Total Iteration Time: 3.04292

Cumulative Model Updates: 12,448
Cumulative Timesteps: 207,818,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 207818624...
Checkpoint 207818624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,624.83717
Policy Entropy: 0.47345
Value Function Loss: 0.23847

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02651
Policy Update Magnitude: 0.02274
Value Function Update Magnitude: 0.02197

Collected Steps per Second: 20,517.30643
Overall Steps per Second: 15,007.70043

Timestep Collection Time: 2.43726
Timestep Consumption Time: 0.89476
PPO Batch Consumption Time: 0.11560
Total Iteration Time: 3.33202

Cumulative Model Updates: 12,451
Cumulative Timesteps: 207,868,630

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,960.12388
Policy Entropy: 0.47694
Value Function Loss: 0.23561

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.05022
Policy Update Magnitude: 0.02114
Value Function Update Magnitude: 0.02208

Collected Steps per Second: 23,533.02624
Overall Steps per Second: 16,689.07592

Timestep Collection Time: 2.12544
Timestep Consumption Time: 0.87161
PPO Batch Consumption Time: 0.10680
Total Iteration Time: 2.99705

Cumulative Model Updates: 12,454
Cumulative Timesteps: 207,918,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 207918648...
Checkpoint 207918648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,252.54132
Policy Entropy: 0.47852
Value Function Loss: 0.20430

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.06211
Policy Update Magnitude: 0.01853
Value Function Update Magnitude: 0.01983

Collected Steps per Second: 23,359.86224
Overall Steps per Second: 16,661.23496

Timestep Collection Time: 2.14102
Timestep Consumption Time: 0.86080
PPO Batch Consumption Time: 0.08464
Total Iteration Time: 3.00182

Cumulative Model Updates: 12,457
Cumulative Timesteps: 207,968,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,111.67126
Policy Entropy: 0.47983
Value Function Loss: 0.20644

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04965
Policy Update Magnitude: 0.01741
Value Function Update Magnitude: 0.02002

Collected Steps per Second: 23,803.15289
Overall Steps per Second: 16,761.41352

Timestep Collection Time: 2.10107
Timestep Consumption Time: 0.88269
PPO Batch Consumption Time: 0.09966
Total Iteration Time: 2.98376

Cumulative Model Updates: 12,460
Cumulative Timesteps: 208,018,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 208018674...
Checkpoint 208018674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,127.84821
Policy Entropy: 0.47928
Value Function Loss: 0.19722

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.04034
Policy Update Magnitude: 0.02003
Value Function Update Magnitude: 0.02395

Collected Steps per Second: 24,042.70084
Overall Steps per Second: 16,710.45561

Timestep Collection Time: 2.08047
Timestep Consumption Time: 0.91287
PPO Batch Consumption Time: 0.10669
Total Iteration Time: 2.99334

Cumulative Model Updates: 12,463
Cumulative Timesteps: 208,068,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,802.60812
Policy Entropy: 0.47733
Value Function Loss: 0.22432

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02809
Policy Update Magnitude: 0.02021
Value Function Update Magnitude: 0.03024

Collected Steps per Second: 21,983.44571
Overall Steps per Second: 15,636.13549

Timestep Collection Time: 2.27571
Timestep Consumption Time: 0.92380
PPO Batch Consumption Time: 0.08800
Total Iteration Time: 3.19951

Cumulative Model Updates: 12,466
Cumulative Timesteps: 208,118,722

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 208118722...
Checkpoint 208118722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,028.66094
Policy Entropy: 0.47271
Value Function Loss: 0.23982

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02268
Policy Update Magnitude: 0.02181
Value Function Update Magnitude: 0.02336

Collected Steps per Second: 20,499.40717
Overall Steps per Second: 15,336.10234

Timestep Collection Time: 2.43997
Timestep Consumption Time: 0.82148
PPO Batch Consumption Time: 0.06558
Total Iteration Time: 3.26145

Cumulative Model Updates: 12,469
Cumulative Timesteps: 208,168,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,585.67175
Policy Entropy: 0.46974
Value Function Loss: 0.25092

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01629
Policy Update Magnitude: 0.02625
Value Function Update Magnitude: 0.02877

Collected Steps per Second: 20,888.97712
Overall Steps per Second: 15,117.96329

Timestep Collection Time: 2.39380
Timestep Consumption Time: 0.91379
PPO Batch Consumption Time: 0.08795
Total Iteration Time: 3.30759

Cumulative Model Updates: 12,472
Cumulative Timesteps: 208,218,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 208218744...
Checkpoint 208218744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,573.94451
Policy Entropy: 0.46881
Value Function Loss: 0.24273

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02997
Policy Update Magnitude: 0.02153
Value Function Update Magnitude: 0.02250

Collected Steps per Second: 24,019.19114
Overall Steps per Second: 17,406.49067

Timestep Collection Time: 2.08184
Timestep Consumption Time: 0.79089
PPO Batch Consumption Time: 0.06174
Total Iteration Time: 2.87272

Cumulative Model Updates: 12,475
Cumulative Timesteps: 208,268,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,012.88514
Policy Entropy: 0.47532
Value Function Loss: 0.23704

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02370
Policy Update Magnitude: 0.02162
Value Function Update Magnitude: 0.02270

Collected Steps per Second: 20,240.42053
Overall Steps per Second: 15,105.51808

Timestep Collection Time: 2.47189
Timestep Consumption Time: 0.84028
PPO Batch Consumption Time: 0.07304
Total Iteration Time: 3.31217

Cumulative Model Updates: 12,478
Cumulative Timesteps: 208,318,780

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 208318780...
Checkpoint 208318780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,468.51313
Policy Entropy: 0.47788
Value Function Loss: 0.23822

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02368
Policy Update Magnitude: 0.02702
Value Function Update Magnitude: 0.02124

Collected Steps per Second: 23,610.67153
Overall Steps per Second: 16,930.76949

Timestep Collection Time: 2.11786
Timestep Consumption Time: 0.83558
PPO Batch Consumption Time: 0.06542
Total Iteration Time: 2.95344

Cumulative Model Updates: 12,481
Cumulative Timesteps: 208,368,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,465.13389
Policy Entropy: 0.48003
Value Function Loss: 0.23374

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01587
Policy Update Magnitude: 0.02523
Value Function Update Magnitude: 0.02457

Collected Steps per Second: 20,352.89282
Overall Steps per Second: 15,528.92915

Timestep Collection Time: 2.45705
Timestep Consumption Time: 0.76327
PPO Batch Consumption Time: 0.04529
Total Iteration Time: 3.22031

Cumulative Model Updates: 12,484
Cumulative Timesteps: 208,418,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 208418792...
Checkpoint 208418792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,519.73125
Policy Entropy: 0.48287
Value Function Loss: 0.24104

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01495
Policy Update Magnitude: 0.02270
Value Function Update Magnitude: 0.02258

Collected Steps per Second: 23,653.78741
Overall Steps per Second: 17,818.68356

Timestep Collection Time: 2.11416
Timestep Consumption Time: 0.69233
PPO Batch Consumption Time: 0.02881
Total Iteration Time: 2.80649

Cumulative Model Updates: 12,487
Cumulative Timesteps: 208,468,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,155.71731
Policy Entropy: 0.48465
Value Function Loss: 0.23569

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01848
Policy Update Magnitude: 0.02086
Value Function Update Magnitude: 0.02239

Collected Steps per Second: 23,476.18521
Overall Steps per Second: 16,872.18914

Timestep Collection Time: 2.13007
Timestep Consumption Time: 0.83374
PPO Batch Consumption Time: 0.07909
Total Iteration Time: 2.96381

Cumulative Model Updates: 12,490
Cumulative Timesteps: 208,518,806

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 208518806...
Checkpoint 208518806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,781.37558
Policy Entropy: 0.48684
Value Function Loss: 0.25301

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.02059
Policy Update Magnitude: 0.01981
Value Function Update Magnitude: 0.01927

Collected Steps per Second: 24,015.79777
Overall Steps per Second: 17,145.53916

Timestep Collection Time: 2.08313
Timestep Consumption Time: 0.83471
PPO Batch Consumption Time: 0.06508
Total Iteration Time: 2.91784

Cumulative Model Updates: 12,493
Cumulative Timesteps: 208,568,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,340.40758
Policy Entropy: 0.48799
Value Function Loss: 0.24266

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02914
Policy Update Magnitude: 0.01957
Value Function Update Magnitude: 0.02024

Collected Steps per Second: 24,419.61785
Overall Steps per Second: 16,473.87529

Timestep Collection Time: 2.04819
Timestep Consumption Time: 0.98789
PPO Batch Consumption Time: 0.10925
Total Iteration Time: 3.03608

Cumulative Model Updates: 12,496
Cumulative Timesteps: 208,618,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 208618850...
Checkpoint 208618850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,714.37059
Policy Entropy: 0.49094
Value Function Loss: 0.24937

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02563
Policy Update Magnitude: 0.01844
Value Function Update Magnitude: 0.01936

Collected Steps per Second: 22,134.89495
Overall Steps per Second: 16,380.13065

Timestep Collection Time: 2.25942
Timestep Consumption Time: 0.79379
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 3.05321

Cumulative Model Updates: 12,499
Cumulative Timesteps: 208,668,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,757.18789
Policy Entropy: 0.49215
Value Function Loss: 0.22548

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02756
Policy Update Magnitude: 0.01864
Value Function Update Magnitude: 0.02010

Collected Steps per Second: 21,010.18682
Overall Steps per Second: 14,987.47229

Timestep Collection Time: 2.38065
Timestep Consumption Time: 0.95667
PPO Batch Consumption Time: 0.10472
Total Iteration Time: 3.33732

Cumulative Model Updates: 12,502
Cumulative Timesteps: 208,718,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 208718880...
Checkpoint 208718880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,044.29309
Policy Entropy: 0.49134
Value Function Loss: 0.20341

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02087
Policy Update Magnitude: 0.01766
Value Function Update Magnitude: 0.01864

Collected Steps per Second: 22,898.11670
Overall Steps per Second: 16,893.26826

Timestep Collection Time: 2.18481
Timestep Consumption Time: 0.77661
PPO Batch Consumption Time: 0.06147
Total Iteration Time: 2.96142

Cumulative Model Updates: 12,505
Cumulative Timesteps: 208,768,908

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,264.17968
Policy Entropy: 0.48923
Value Function Loss: 0.18423

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.01681
Value Function Update Magnitude: 0.01891

Collected Steps per Second: 17,664.74301
Overall Steps per Second: 13,458.73071

Timestep Collection Time: 2.83118
Timestep Consumption Time: 0.88478
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 3.71595

Cumulative Model Updates: 12,508
Cumulative Timesteps: 208,818,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 208818920...
Checkpoint 208818920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,718.57760
Policy Entropy: 0.48874
Value Function Loss: 0.19412

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.03024
Policy Update Magnitude: 0.01688
Value Function Update Magnitude: 0.02040

Collected Steps per Second: 19,562.37087
Overall Steps per Second: 15,126.88114

Timestep Collection Time: 2.55644
Timestep Consumption Time: 0.74960
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 3.30604

Cumulative Model Updates: 12,511
Cumulative Timesteps: 208,868,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,132.14310
Policy Entropy: 0.49044
Value Function Loss: 0.19138

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04044
Policy Update Magnitude: 0.01448
Value Function Update Magnitude: 0.01721

Collected Steps per Second: 19,832.79495
Overall Steps per Second: 14,823.91623

Timestep Collection Time: 2.52309
Timestep Consumption Time: 0.85253
PPO Batch Consumption Time: 0.06324
Total Iteration Time: 3.37563

Cumulative Model Updates: 12,514
Cumulative Timesteps: 208,918,970

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 208918970...
Checkpoint 208918970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,944.22974
Policy Entropy: 0.48920
Value Function Loss: 0.20796

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02946
Policy Update Magnitude: 0.01538
Value Function Update Magnitude: 0.01805

Collected Steps per Second: 19,199.55200
Overall Steps per Second: 14,016.61894

Timestep Collection Time: 2.60569
Timestep Consumption Time: 0.96351
PPO Batch Consumption Time: 0.07823
Total Iteration Time: 3.56919

Cumulative Model Updates: 12,517
Cumulative Timesteps: 208,968,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,480.32497
Policy Entropy: 0.49111
Value Function Loss: 0.19486

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04175
Policy Update Magnitude: 0.01824
Value Function Update Magnitude: 0.01683

Collected Steps per Second: 23,386.33122
Overall Steps per Second: 17,411.53058

Timestep Collection Time: 2.13834
Timestep Consumption Time: 0.73378
PPO Batch Consumption Time: 0.02968
Total Iteration Time: 2.87212

Cumulative Model Updates: 12,520
Cumulative Timesteps: 209,019,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 209019006...
Checkpoint 209019006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,001.13994
Policy Entropy: 0.49315
Value Function Loss: 0.19099

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.05125
Policy Update Magnitude: 0.01841
Value Function Update Magnitude: 0.01834

Collected Steps per Second: 21,793.48824
Overall Steps per Second: 15,661.43048

Timestep Collection Time: 2.29454
Timestep Consumption Time: 0.89840
PPO Batch Consumption Time: 0.08324
Total Iteration Time: 3.19294

Cumulative Model Updates: 12,523
Cumulative Timesteps: 209,069,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,457.44616
Policy Entropy: 0.50002
Value Function Loss: 0.16714

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03919
Policy Update Magnitude: 0.01865
Value Function Update Magnitude: 0.01713

Collected Steps per Second: 23,185.06956
Overall Steps per Second: 16,196.14785

Timestep Collection Time: 2.15742
Timestep Consumption Time: 0.93097
PPO Batch Consumption Time: 0.10410
Total Iteration Time: 3.08839

Cumulative Model Updates: 12,526
Cumulative Timesteps: 209,119,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 209119032...
Checkpoint 209119032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,059.58023
Policy Entropy: 0.49964
Value Function Loss: 0.19013

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03441
Policy Update Magnitude: 0.01723
Value Function Update Magnitude: 0.01829

Collected Steps per Second: 23,176.36713
Overall Steps per Second: 16,644.64642

Timestep Collection Time: 2.15797
Timestep Consumption Time: 0.84684
PPO Batch Consumption Time: 0.07588
Total Iteration Time: 3.00481

Cumulative Model Updates: 12,529
Cumulative Timesteps: 209,169,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,421.64110
Policy Entropy: 0.49781
Value Function Loss: 0.20023

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01705
Policy Update Magnitude: 0.01692
Value Function Update Magnitude: 0.01919

Collected Steps per Second: 24,383.58304
Overall Steps per Second: 16,757.70925

Timestep Collection Time: 2.05130
Timestep Consumption Time: 0.93348
PPO Batch Consumption Time: 0.10284
Total Iteration Time: 2.98478

Cumulative Model Updates: 12,532
Cumulative Timesteps: 209,219,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 209219064...
Checkpoint 209219064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,528.24830
Policy Entropy: 0.49389
Value Function Loss: 0.21211

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02567
Policy Update Magnitude: 0.01666
Value Function Update Magnitude: 0.01991

Collected Steps per Second: 23,088.02575
Overall Steps per Second: 17,224.78841

Timestep Collection Time: 2.16580
Timestep Consumption Time: 0.73723
PPO Batch Consumption Time: 0.03014
Total Iteration Time: 2.90303

Cumulative Model Updates: 12,535
Cumulative Timesteps: 209,269,068

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,404.74270
Policy Entropy: 0.49778
Value Function Loss: 0.19023

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01941
Policy Update Magnitude: 0.01608
Value Function Update Magnitude: 0.02130

Collected Steps per Second: 20,706.13587
Overall Steps per Second: 16,012.44778

Timestep Collection Time: 2.41532
Timestep Consumption Time: 0.70800
PPO Batch Consumption Time: 0.02866
Total Iteration Time: 3.12332

Cumulative Model Updates: 12,538
Cumulative Timesteps: 209,319,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 209319080...
Checkpoint 209319080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,187.72273
Policy Entropy: 0.49553
Value Function Loss: 0.19427

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02871
Policy Update Magnitude: 0.01557
Value Function Update Magnitude: 0.01939

Collected Steps per Second: 23,189.41367
Overall Steps per Second: 16,041.16246

Timestep Collection Time: 2.15693
Timestep Consumption Time: 0.96117
PPO Batch Consumption Time: 0.10642
Total Iteration Time: 3.11810

Cumulative Model Updates: 12,541
Cumulative Timesteps: 209,369,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,423.63531
Policy Entropy: 0.50376
Value Function Loss: 0.19184

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03176
Policy Update Magnitude: 0.01542
Value Function Update Magnitude: 0.01966

Collected Steps per Second: 24,182.55138
Overall Steps per Second: 17,377.94753

Timestep Collection Time: 2.06794
Timestep Consumption Time: 0.80973
PPO Batch Consumption Time: 0.06387
Total Iteration Time: 2.87767

Cumulative Model Updates: 12,544
Cumulative Timesteps: 209,419,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 209419106...
Checkpoint 209419106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,423.63531
Policy Entropy: 0.50792
Value Function Loss: 0.17300

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02959
Policy Update Magnitude: 0.01662
Value Function Update Magnitude: 0.01755

Collected Steps per Second: 18,553.72517
Overall Steps per Second: 13,533.22839

Timestep Collection Time: 2.69509
Timestep Consumption Time: 0.99981
PPO Batch Consumption Time: 0.11807
Total Iteration Time: 3.69491

Cumulative Model Updates: 12,547
Cumulative Timesteps: 209,469,110

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,073.72528
Policy Entropy: 0.50540
Value Function Loss: 0.17857

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02035
Policy Update Magnitude: 0.01614
Value Function Update Magnitude: 0.01887

Collected Steps per Second: 24,529.89155
Overall Steps per Second: 17,728.03414

Timestep Collection Time: 2.03947
Timestep Consumption Time: 0.78250
PPO Batch Consumption Time: 0.05887
Total Iteration Time: 2.82197

Cumulative Model Updates: 12,550
Cumulative Timesteps: 209,519,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 209519138...
Checkpoint 209519138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,074.34529
Policy Entropy: 0.49939
Value Function Loss: 0.19518

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.01683
Value Function Update Magnitude: 0.01713

Collected Steps per Second: 21,356.03293
Overall Steps per Second: 14,915.08738

Timestep Collection Time: 2.34163
Timestep Consumption Time: 1.01121
PPO Batch Consumption Time: 0.12484
Total Iteration Time: 3.35285

Cumulative Model Updates: 12,553
Cumulative Timesteps: 209,569,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,436.28860
Policy Entropy: 0.49550
Value Function Loss: 0.20850

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02329
Policy Update Magnitude: 0.01717
Value Function Update Magnitude: 0.02713

Collected Steps per Second: 24,154.04942
Overall Steps per Second: 17,682.97155

Timestep Collection Time: 2.07121
Timestep Consumption Time: 0.75796
PPO Batch Consumption Time: 0.05926
Total Iteration Time: 2.82916

Cumulative Model Updates: 12,556
Cumulative Timesteps: 209,619,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 209619174...
Checkpoint 209619174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,702.41248
Policy Entropy: 0.49481
Value Function Loss: 0.19982

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.01852
Value Function Update Magnitude: 0.02670

Collected Steps per Second: 20,679.05494
Overall Steps per Second: 14,957.25499

Timestep Collection Time: 2.41810
Timestep Consumption Time: 0.92503
PPO Batch Consumption Time: 0.12623
Total Iteration Time: 3.34313

Cumulative Model Updates: 12,559
Cumulative Timesteps: 209,669,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,918.86590
Policy Entropy: 0.49542
Value Function Loss: 0.17989

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01587
Policy Update Magnitude: 0.01747
Value Function Update Magnitude: 0.02541

Collected Steps per Second: 23,723.51835
Overall Steps per Second: 16,687.96099

Timestep Collection Time: 2.10795
Timestep Consumption Time: 0.88870
PPO Batch Consumption Time: 0.12018
Total Iteration Time: 2.99665

Cumulative Model Updates: 12,562
Cumulative Timesteps: 209,719,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 209719186...
Checkpoint 209719186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,404.42822
Policy Entropy: 0.49248
Value Function Loss: 0.17946

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02408
Policy Update Magnitude: 0.01760
Value Function Update Magnitude: 0.02021

Collected Steps per Second: 23,349.41929
Overall Steps per Second: 16,614.78588

Timestep Collection Time: 2.14172
Timestep Consumption Time: 0.86813
PPO Batch Consumption Time: 0.10556
Total Iteration Time: 3.00985

Cumulative Model Updates: 12,565
Cumulative Timesteps: 209,769,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,029.50289
Policy Entropy: 0.49343
Value Function Loss: 0.16849

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02270
Policy Update Magnitude: 0.01576
Value Function Update Magnitude: 0.01889

Collected Steps per Second: 23,688.86128
Overall Steps per Second: 16,753.62106

Timestep Collection Time: 2.11087
Timestep Consumption Time: 0.87380
PPO Batch Consumption Time: 0.09086
Total Iteration Time: 2.98467

Cumulative Model Updates: 12,568
Cumulative Timesteps: 209,819,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 209819198...
Checkpoint 209819198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,907.04796
Policy Entropy: 0.49646
Value Function Loss: 0.16393

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02371
Policy Update Magnitude: 0.01562
Value Function Update Magnitude: 0.01732

Collected Steps per Second: 23,094.77781
Overall Steps per Second: 16,714.69789

Timestep Collection Time: 2.16542
Timestep Consumption Time: 0.82655
PPO Batch Consumption Time: 0.07441
Total Iteration Time: 2.99198

Cumulative Model Updates: 12,571
Cumulative Timesteps: 209,869,208

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,875.83377
Policy Entropy: 0.49254
Value Function Loss: 0.16799

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03049
Policy Update Magnitude: 0.01553
Value Function Update Magnitude: 0.01822

Collected Steps per Second: 24,213.19459
Overall Steps per Second: 16,855.03053

Timestep Collection Time: 2.06623
Timestep Consumption Time: 0.90202
PPO Batch Consumption Time: 0.10461
Total Iteration Time: 2.96825

Cumulative Model Updates: 12,574
Cumulative Timesteps: 209,919,238

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 209919238...
Checkpoint 209919238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,153.69597
Policy Entropy: 0.49486
Value Function Loss: 0.16967

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.01545
Value Function Update Magnitude: 0.01922

Collected Steps per Second: 24,176.01251
Overall Steps per Second: 16,715.06110

Timestep Collection Time: 2.06908
Timestep Consumption Time: 0.92355
PPO Batch Consumption Time: 0.10341
Total Iteration Time: 2.99263

Cumulative Model Updates: 12,577
Cumulative Timesteps: 209,969,260

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,997.28672
Policy Entropy: 0.49185
Value Function Loss: 0.17369

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.01531
Value Function Update Magnitude: 0.01888

Collected Steps per Second: 24,383.09360
Overall Steps per Second: 16,761.09723

Timestep Collection Time: 2.05142
Timestep Consumption Time: 0.93287
PPO Batch Consumption Time: 0.10894
Total Iteration Time: 2.98429

Cumulative Model Updates: 12,580
Cumulative Timesteps: 210,019,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 210019280...
Checkpoint 210019280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,641.62377
Policy Entropy: 0.48722
Value Function Loss: 0.18466

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02134
Policy Update Magnitude: 0.01502
Value Function Update Magnitude: 0.01953

Collected Steps per Second: 20,085.33194
Overall Steps per Second: 14,678.30130

Timestep Collection Time: 2.48988
Timestep Consumption Time: 0.91719
PPO Batch Consumption Time: 0.09202
Total Iteration Time: 3.40707

Cumulative Model Updates: 12,583
Cumulative Timesteps: 210,069,290

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,638.17269
Policy Entropy: 0.48386
Value Function Loss: 0.18973

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.03121
Policy Update Magnitude: 0.01757
Value Function Update Magnitude: 0.01901

Collected Steps per Second: 22,715.08075
Overall Steps per Second: 16,683.87251

Timestep Collection Time: 2.20171
Timestep Consumption Time: 0.79592
PPO Batch Consumption Time: 0.05792
Total Iteration Time: 2.99763

Cumulative Model Updates: 12,586
Cumulative Timesteps: 210,119,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 210119302...
Checkpoint 210119302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,910.49979
Policy Entropy: 0.48724
Value Function Loss: 0.18893

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 0.01868
Value Function Update Magnitude: 0.01796

Collected Steps per Second: 19,781.01311
Overall Steps per Second: 14,074.49274

Timestep Collection Time: 2.52768
Timestep Consumption Time: 1.02485
PPO Batch Consumption Time: 0.12414
Total Iteration Time: 3.55253

Cumulative Model Updates: 12,589
Cumulative Timesteps: 210,169,302

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,099.91526
Policy Entropy: 0.48827
Value Function Loss: 0.19022

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03040
Policy Update Magnitude: 0.01723
Value Function Update Magnitude: 0.02053

Collected Steps per Second: 23,359.82735
Overall Steps per Second: 16,869.44156

Timestep Collection Time: 2.14154
Timestep Consumption Time: 0.82394
PPO Batch Consumption Time: 0.06454
Total Iteration Time: 2.96548

Cumulative Model Updates: 12,592
Cumulative Timesteps: 210,219,328

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 210219328...
Checkpoint 210219328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,044.73294
Policy Entropy: 0.49828
Value Function Loss: 0.17713

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02446
Policy Update Magnitude: 0.01706
Value Function Update Magnitude: 0.02011

Collected Steps per Second: 22,508.30994
Overall Steps per Second: 15,976.34546

Timestep Collection Time: 2.22300
Timestep Consumption Time: 0.90888
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 3.13188

Cumulative Model Updates: 12,595
Cumulative Timesteps: 210,269,364

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,597.11406
Policy Entropy: 0.49609
Value Function Loss: 0.18912

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02931
Policy Update Magnitude: 0.01553
Value Function Update Magnitude: 0.02013

Collected Steps per Second: 22,534.94328
Overall Steps per Second: 16,400.70756

Timestep Collection Time: 2.22002
Timestep Consumption Time: 0.83034
PPO Batch Consumption Time: 0.05917
Total Iteration Time: 3.05036

Cumulative Model Updates: 12,598
Cumulative Timesteps: 210,319,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 210319392...
Checkpoint 210319392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,929.98073
Policy Entropy: 0.49226
Value Function Loss: 0.20475

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01437
Policy Update Magnitude: 0.01590
Value Function Update Magnitude: 0.02064

Collected Steps per Second: 22,444.83094
Overall Steps per Second: 16,615.83829

Timestep Collection Time: 2.22875
Timestep Consumption Time: 0.78187
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 3.01062

Cumulative Model Updates: 12,601
Cumulative Timesteps: 210,369,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,099.15011
Policy Entropy: 0.48695
Value Function Loss: 0.19957

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.01677
Value Function Update Magnitude: 0.02466

Collected Steps per Second: 20,531.24009
Overall Steps per Second: 14,579.64748

Timestep Collection Time: 2.43531
Timestep Consumption Time: 0.99412
PPO Batch Consumption Time: 0.11172
Total Iteration Time: 3.42944

Cumulative Model Updates: 12,604
Cumulative Timesteps: 210,419,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 210419416...
Checkpoint 210419416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,062.43879
Policy Entropy: 0.48748
Value Function Loss: 0.17886

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.02024
Policy Update Magnitude: 0.01741
Value Function Update Magnitude: 0.02826

Collected Steps per Second: 22,547.07043
Overall Steps per Second: 16,443.11285

Timestep Collection Time: 2.21767
Timestep Consumption Time: 0.82324
PPO Batch Consumption Time: 0.06299
Total Iteration Time: 3.04091

Cumulative Model Updates: 12,607
Cumulative Timesteps: 210,469,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,731.61014
Policy Entropy: 0.48748
Value Function Loss: 0.16256

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01091
Policy Update Magnitude: 0.02021
Value Function Update Magnitude: 0.03061

Collected Steps per Second: 20,481.37327
Overall Steps per Second: 15,055.40625

Timestep Collection Time: 2.44251
Timestep Consumption Time: 0.88028
PPO Batch Consumption Time: 0.08220
Total Iteration Time: 3.32279

Cumulative Model Updates: 12,610
Cumulative Timesteps: 210,519,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 210519444...
Checkpoint 210519444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,616.25781
Policy Entropy: 0.48415
Value Function Loss: 0.18938

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01495
Policy Update Magnitude: 0.01816
Value Function Update Magnitude: 0.02666

Collected Steps per Second: 22,746.83629
Overall Steps per Second: 16,629.75508

Timestep Collection Time: 2.19820
Timestep Consumption Time: 0.80858
PPO Batch Consumption Time: 0.06146
Total Iteration Time: 3.00678

Cumulative Model Updates: 12,613
Cumulative Timesteps: 210,569,446

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,930.20041
Policy Entropy: 0.48435
Value Function Loss: 0.19206

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.00897
Policy Update Magnitude: 0.01733
Value Function Update Magnitude: 0.02549

Collected Steps per Second: 17,264.36403
Overall Steps per Second: 13,277.76010

Timestep Collection Time: 2.89660
Timestep Consumption Time: 0.86970
PPO Batch Consumption Time: 0.08192
Total Iteration Time: 3.76630

Cumulative Model Updates: 12,616
Cumulative Timesteps: 210,619,454

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 210619454...
Checkpoint 210619454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,140.58483
Policy Entropy: 0.48334
Value Function Loss: 0.21179

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01707
Policy Update Magnitude: 0.01815
Value Function Update Magnitude: 0.02234

Collected Steps per Second: 23,094.22016
Overall Steps per Second: 17,497.55265

Timestep Collection Time: 2.16608
Timestep Consumption Time: 0.69283
PPO Batch Consumption Time: 0.02877
Total Iteration Time: 2.85891

Cumulative Model Updates: 12,619
Cumulative Timesteps: 210,669,478

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,793.59943
Policy Entropy: 0.48509
Value Function Loss: 0.20431

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01441
Policy Update Magnitude: 0.01973
Value Function Update Magnitude: 0.02062

Collected Steps per Second: 20,534.12115
Overall Steps per Second: 15,713.80690

Timestep Collection Time: 2.43595
Timestep Consumption Time: 0.74724
PPO Batch Consumption Time: 0.04194
Total Iteration Time: 3.18319

Cumulative Model Updates: 12,622
Cumulative Timesteps: 210,719,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 210719498...
Checkpoint 210719498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,534.27031
Policy Entropy: 0.48177
Value Function Loss: 0.21415

Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.01141
Policy Update Magnitude: 0.01895
Value Function Update Magnitude: 0.02120

Collected Steps per Second: 21,915.14360
Overall Steps per Second: 15,916.18313

Timestep Collection Time: 2.28217
Timestep Consumption Time: 0.86017
PPO Batch Consumption Time: 0.10010
Total Iteration Time: 3.14234

Cumulative Model Updates: 12,625
Cumulative Timesteps: 210,769,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,962.22110
Policy Entropy: 0.48723
Value Function Loss: 0.19687

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01611
Policy Update Magnitude: 0.01918
Value Function Update Magnitude: 0.02114

Collected Steps per Second: 17,946.36129
Overall Steps per Second: 14,234.99659

Timestep Collection Time: 2.78686
Timestep Consumption Time: 0.72659
PPO Batch Consumption Time: 0.06216
Total Iteration Time: 3.51345

Cumulative Model Updates: 12,628
Cumulative Timesteps: 210,819,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 210819526...
Checkpoint 210819526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,997.92702
Policy Entropy: 0.49441
Value Function Loss: 0.18976

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01916
Policy Update Magnitude: 0.01849
Value Function Update Magnitude: 0.02240

Collected Steps per Second: 21,195.53474
Overall Steps per Second: 16,362.13195

Timestep Collection Time: 2.36069
Timestep Consumption Time: 0.69735
PPO Batch Consumption Time: 0.03146
Total Iteration Time: 3.05804

Cumulative Model Updates: 12,631
Cumulative Timesteps: 210,869,562

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,710.67257
Policy Entropy: 0.49494
Value Function Loss: 0.18225

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02229
Policy Update Magnitude: 0.01830
Value Function Update Magnitude: 0.02145

Collected Steps per Second: 22,815.58622
Overall Steps per Second: 17,273.30224

Timestep Collection Time: 2.19201
Timestep Consumption Time: 0.70332
PPO Batch Consumption Time: 0.02963
Total Iteration Time: 2.89534

Cumulative Model Updates: 12,634
Cumulative Timesteps: 210,919,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 210919574...
Checkpoint 210919574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,903.98342
Policy Entropy: 0.49849
Value Function Loss: 0.17355

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01423
Policy Update Magnitude: 0.01677
Value Function Update Magnitude: 0.02066

Collected Steps per Second: 21,878.22837
Overall Steps per Second: 15,770.32038

Timestep Collection Time: 2.28657
Timestep Consumption Time: 0.88560
PPO Batch Consumption Time: 0.04780
Total Iteration Time: 3.17216

Cumulative Model Updates: 12,637
Cumulative Timesteps: 210,969,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,930.36167
Policy Entropy: 0.49607
Value Function Loss: 0.16302

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01705
Policy Update Magnitude: 0.01644
Value Function Update Magnitude: 0.01890

Collected Steps per Second: 23,103.37432
Overall Steps per Second: 16,871.09796

Timestep Collection Time: 2.16427
Timestep Consumption Time: 0.79949
PPO Batch Consumption Time: 0.06784
Total Iteration Time: 2.96377

Cumulative Model Updates: 12,640
Cumulative Timesteps: 211,019,602

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 211019602...
Checkpoint 211019602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,710.81314
Policy Entropy: 0.49440
Value Function Loss: 0.16029

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01565
Policy Update Magnitude: 0.01625
Value Function Update Magnitude: 0.01732

Collected Steps per Second: 22,901.24885
Overall Steps per Second: 16,262.93884

Timestep Collection Time: 2.18399
Timestep Consumption Time: 0.89147
PPO Batch Consumption Time: 0.09338
Total Iteration Time: 3.07546

Cumulative Model Updates: 12,643
Cumulative Timesteps: 211,069,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,807.17353
Policy Entropy: 0.49679
Value Function Loss: 0.15088

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01639
Policy Update Magnitude: 0.01551
Value Function Update Magnitude: 0.01711

Collected Steps per Second: 23,385.28713
Overall Steps per Second: 16,987.18677

Timestep Collection Time: 2.13818
Timestep Consumption Time: 0.80533
PPO Batch Consumption Time: 0.06662
Total Iteration Time: 2.94351

Cumulative Model Updates: 12,646
Cumulative Timesteps: 211,119,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 211119620...
Checkpoint 211119620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,094.94335
Policy Entropy: 0.49526
Value Function Loss: 0.15508

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01807
Policy Update Magnitude: 0.01508
Value Function Update Magnitude: 0.01530

Collected Steps per Second: 22,209.87748
Overall Steps per Second: 16,563.53370

Timestep Collection Time: 2.25197
Timestep Consumption Time: 0.76767
PPO Batch Consumption Time: 0.05361
Total Iteration Time: 3.01965

Cumulative Model Updates: 12,649
Cumulative Timesteps: 211,169,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,059.88674
Policy Entropy: 0.50264
Value Function Loss: 0.15620

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02021
Policy Update Magnitude: 0.01609
Value Function Update Magnitude: 0.01705

Collected Steps per Second: 21,237.63237
Overall Steps per Second: 15,559.86543

Timestep Collection Time: 2.35431
Timestep Consumption Time: 0.85908
PPO Batch Consumption Time: 0.08137
Total Iteration Time: 3.21340

Cumulative Model Updates: 12,652
Cumulative Timesteps: 211,219,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 211219636...
Checkpoint 211219636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,239.96469
Policy Entropy: 0.49618
Value Function Loss: 0.17905

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01217
Policy Update Magnitude: 0.01669
Value Function Update Magnitude: 0.01547

Collected Steps per Second: 23,933.23193
Overall Steps per Second: 17,317.06162

Timestep Collection Time: 2.08998
Timestep Consumption Time: 0.79850
PPO Batch Consumption Time: 0.06297
Total Iteration Time: 2.88848

Cumulative Model Updates: 12,655
Cumulative Timesteps: 211,269,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,381.59116
Policy Entropy: 0.49839
Value Function Loss: 0.19377

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01289
Policy Update Magnitude: 0.01720
Value Function Update Magnitude: 0.02285

Collected Steps per Second: 24,674.50744
Overall Steps per Second: 17,333.63455

Timestep Collection Time: 2.02711
Timestep Consumption Time: 0.85849
PPO Batch Consumption Time: 0.08197
Total Iteration Time: 2.88560

Cumulative Model Updates: 12,658
Cumulative Timesteps: 211,319,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 211319674...
Checkpoint 211319674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,290.77573
Policy Entropy: 0.49427
Value Function Loss: 0.19533

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01399
Policy Update Magnitude: 0.01813
Value Function Update Magnitude: 0.02209

Collected Steps per Second: 24,281.16201
Overall Steps per Second: 17,734.17181

Timestep Collection Time: 2.05979
Timestep Consumption Time: 0.76042
PPO Batch Consumption Time: 0.06023
Total Iteration Time: 2.82020

Cumulative Model Updates: 12,661
Cumulative Timesteps: 211,369,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,379.11034
Policy Entropy: 0.49657
Value Function Loss: 0.18362

Mean KL Divergence: 0.00123
SB3 Clip Fraction: 0.01061
Policy Update Magnitude: 0.01853
Value Function Update Magnitude: 0.02198

Collected Steps per Second: 21,121.71142
Overall Steps per Second: 15,825.46595

Timestep Collection Time: 2.36827
Timestep Consumption Time: 0.79258
PPO Batch Consumption Time: 0.08615
Total Iteration Time: 3.16085

Cumulative Model Updates: 12,664
Cumulative Timesteps: 211,419,710

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 211419710...
Checkpoint 211419710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,875.11754
Policy Entropy: 0.49772
Value Function Loss: 0.18596

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.02051
Policy Update Magnitude: 0.01846
Value Function Update Magnitude: 0.02004

Collected Steps per Second: 23,361.00575
Overall Steps per Second: 17,409.99843

Timestep Collection Time: 2.14160
Timestep Consumption Time: 0.73203
PPO Batch Consumption Time: 0.06277
Total Iteration Time: 2.87364

Cumulative Model Updates: 12,667
Cumulative Timesteps: 211,469,740

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,981.08069
Policy Entropy: 0.49987
Value Function Loss: 0.19016

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01835
Policy Update Magnitude: 0.01654
Value Function Update Magnitude: 0.02106

Collected Steps per Second: 21,306.09652
Overall Steps per Second: 15,268.03367

Timestep Collection Time: 2.34722
Timestep Consumption Time: 0.92826
PPO Batch Consumption Time: 0.12708
Total Iteration Time: 3.27547

Cumulative Model Updates: 12,670
Cumulative Timesteps: 211,519,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 211519750...
Checkpoint 211519750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,322.21230
Policy Entropy: 0.49406
Value Function Loss: 0.20125

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03368
Policy Update Magnitude: 0.01687
Value Function Update Magnitude: 0.02015

Collected Steps per Second: 23,059.34191
Overall Steps per Second: 16,986.31068

Timestep Collection Time: 2.16858
Timestep Consumption Time: 0.77532
PPO Batch Consumption Time: 0.06574
Total Iteration Time: 2.94390

Cumulative Model Updates: 12,673
Cumulative Timesteps: 211,569,756

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,983.06677
Policy Entropy: 0.49732
Value Function Loss: 0.18589

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02053
Policy Update Magnitude: 0.01707
Value Function Update Magnitude: 0.02020

Collected Steps per Second: 23,870.37931
Overall Steps per Second: 16,509.76600

Timestep Collection Time: 2.09481
Timestep Consumption Time: 0.93394
PPO Batch Consumption Time: 0.12421
Total Iteration Time: 3.02875

Cumulative Model Updates: 12,676
Cumulative Timesteps: 211,619,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 211619760...
Checkpoint 211619760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,175.11663
Policy Entropy: 0.49117
Value Function Loss: 0.18210

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02444
Policy Update Magnitude: 0.01732
Value Function Update Magnitude: 0.02023

Collected Steps per Second: 24,161.81518
Overall Steps per Second: 17,743.80465

Timestep Collection Time: 2.07021
Timestep Consumption Time: 0.74880
PPO Batch Consumption Time: 0.05782
Total Iteration Time: 2.81901

Cumulative Model Updates: 12,679
Cumulative Timesteps: 211,669,780

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,910.05866
Policy Entropy: 0.49848
Value Function Loss: 0.17998

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03585
Policy Update Magnitude: 0.01632
Value Function Update Magnitude: 0.02079

Collected Steps per Second: 21,569.18983
Overall Steps per Second: 15,683.83014

Timestep Collection Time: 2.31821
Timestep Consumption Time: 0.86991
PPO Batch Consumption Time: 0.08643
Total Iteration Time: 3.18812

Cumulative Model Updates: 12,682
Cumulative Timesteps: 211,719,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 211719782...
Checkpoint 211719782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,005.95225
Policy Entropy: 0.49287
Value Function Loss: 0.18529

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.04059
Policy Update Magnitude: 0.01719
Value Function Update Magnitude: 0.01932

Collected Steps per Second: 24,002.82386
Overall Steps per Second: 17,533.38193

Timestep Collection Time: 2.08367
Timestep Consumption Time: 0.76883
PPO Batch Consumption Time: 0.06210
Total Iteration Time: 2.85250

Cumulative Model Updates: 12,685
Cumulative Timesteps: 211,769,796

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,556.90016
Policy Entropy: 0.50098
Value Function Loss: 0.19939

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03861
Policy Update Magnitude: 0.01707
Value Function Update Magnitude: 0.02092

Collected Steps per Second: 21,542.10160
Overall Steps per Second: 15,154.86528

Timestep Collection Time: 2.32169
Timestep Consumption Time: 0.97851
PPO Batch Consumption Time: 0.11374
Total Iteration Time: 3.30019

Cumulative Model Updates: 12,688
Cumulative Timesteps: 211,819,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 211819810...
Checkpoint 211819810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,863.72108
Policy Entropy: 0.49559
Value Function Loss: 0.20485

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.05097
Policy Update Magnitude: 0.01640
Value Function Update Magnitude: 0.02191

Collected Steps per Second: 24,399.60416
Overall Steps per Second: 16,606.41268

Timestep Collection Time: 2.05044
Timestep Consumption Time: 0.96225
PPO Batch Consumption Time: 0.10296
Total Iteration Time: 3.01269

Cumulative Model Updates: 12,691
Cumulative Timesteps: 211,869,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,181.52314
Policy Entropy: 0.49483
Value Function Loss: 0.19657

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02301
Policy Update Magnitude: 0.01694
Value Function Update Magnitude: 0.02069

Collected Steps per Second: 24,353.02004
Overall Steps per Second: 16,790.61659

Timestep Collection Time: 2.05363
Timestep Consumption Time: 0.92494
PPO Batch Consumption Time: 0.09903
Total Iteration Time: 2.97857

Cumulative Model Updates: 12,694
Cumulative Timesteps: 211,919,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 211919852...
Checkpoint 211919852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,528.85524
Policy Entropy: 0.48797
Value Function Loss: 0.18036

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 0.01618
Value Function Update Magnitude: 0.01918

Collected Steps per Second: 24,182.56170
Overall Steps per Second: 16,747.09403

Timestep Collection Time: 2.06761
Timestep Consumption Time: 0.91799
PPO Batch Consumption Time: 0.09774
Total Iteration Time: 2.98559

Cumulative Model Updates: 12,697
Cumulative Timesteps: 211,969,852

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,457.65768
Policy Entropy: 0.49198
Value Function Loss: 0.18483

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01985
Policy Update Magnitude: 0.01622
Value Function Update Magnitude: 0.01861

Collected Steps per Second: 24,484.26169
Overall Steps per Second: 16,796.96854

Timestep Collection Time: 2.04295
Timestep Consumption Time: 0.93497
PPO Batch Consumption Time: 0.11739
Total Iteration Time: 2.97792

Cumulative Model Updates: 12,700
Cumulative Timesteps: 212,019,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 212019872...
Checkpoint 212019872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,746.88972
Policy Entropy: 0.49449
Value Function Loss: 0.17619

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02001
Policy Update Magnitude: 0.01480
Value Function Update Magnitude: 0.02156

Collected Steps per Second: 23,846.24228
Overall Steps per Second: 16,675.46323

Timestep Collection Time: 2.09710
Timestep Consumption Time: 0.90180
PPO Batch Consumption Time: 0.09067
Total Iteration Time: 2.99890

Cumulative Model Updates: 12,703
Cumulative Timesteps: 212,069,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,073.90494
Policy Entropy: 0.49487
Value Function Loss: 0.18057

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.01275
Policy Update Magnitude: 0.01511
Value Function Update Magnitude: 0.02205

Collected Steps per Second: 24,459.48696
Overall Steps per Second: 16,783.49599

Timestep Collection Time: 2.04444
Timestep Consumption Time: 0.93503
PPO Batch Consumption Time: 0.11066
Total Iteration Time: 2.97947

Cumulative Model Updates: 12,706
Cumulative Timesteps: 212,119,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 212119886...
Checkpoint 212119886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,476.89868
Policy Entropy: 0.49399
Value Function Loss: 0.17853

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.01553
Value Function Update Magnitude: 0.01812

Collected Steps per Second: 24,153.63968
Overall Steps per Second: 16,710.40368

Timestep Collection Time: 2.07033
Timestep Consumption Time: 0.92218
PPO Batch Consumption Time: 0.10460
Total Iteration Time: 2.99251

Cumulative Model Updates: 12,709
Cumulative Timesteps: 212,169,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,457.58179
Policy Entropy: 0.49267
Value Function Loss: 0.19329

Mean KL Divergence: 0.00115
SB3 Clip Fraction: 0.00933
Policy Update Magnitude: 0.01690
Value Function Update Magnitude: 0.01990

Collected Steps per Second: 23,043.80996
Overall Steps per Second: 16,619.89814

Timestep Collection Time: 2.17065
Timestep Consumption Time: 0.83900
PPO Batch Consumption Time: 0.07540
Total Iteration Time: 3.00965

Cumulative Model Updates: 12,712
Cumulative Timesteps: 212,219,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 212219912...
Checkpoint 212219912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,177.70647
Policy Entropy: 0.49157
Value Function Loss: 0.19529

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01474
Policy Update Magnitude: 0.01923
Value Function Update Magnitude: 0.02087

Collected Steps per Second: 24,119.84532
Overall Steps per Second: 16,804.13406

Timestep Collection Time: 2.07348
Timestep Consumption Time: 0.90269
PPO Batch Consumption Time: 0.09158
Total Iteration Time: 2.97617

Cumulative Model Updates: 12,715
Cumulative Timesteps: 212,269,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,437.37671
Policy Entropy: 0.50587
Value Function Loss: 0.17272

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.03053
Policy Update Magnitude: 0.01851
Value Function Update Magnitude: 0.02185

Collected Steps per Second: 24,276.01470
Overall Steps per Second: 16,770.66187

Timestep Collection Time: 2.06047
Timestep Consumption Time: 0.92212
PPO Batch Consumption Time: 0.10504
Total Iteration Time: 2.98259

Cumulative Model Updates: 12,718
Cumulative Timesteps: 212,319,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 212319944...
Checkpoint 212319944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,599.42320
Policy Entropy: 0.50816
Value Function Loss: 0.16971

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03328
Policy Update Magnitude: 0.01696
Value Function Update Magnitude: 0.02282

Collected Steps per Second: 24,371.22650
Overall Steps per Second: 16,752.08657

Timestep Collection Time: 2.05242
Timestep Consumption Time: 0.93348
PPO Batch Consumption Time: 0.10508
Total Iteration Time: 2.98590

Cumulative Model Updates: 12,721
Cumulative Timesteps: 212,369,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,173.09670
Policy Entropy: 0.50868
Value Function Loss: 0.16318

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02687
Policy Update Magnitude: 0.01632
Value Function Update Magnitude: 0.01995

Collected Steps per Second: 24,361.52084
Overall Steps per Second: 16,725.50961

Timestep Collection Time: 2.05291
Timestep Consumption Time: 0.93725
PPO Batch Consumption Time: 0.10525
Total Iteration Time: 2.99016

Cumulative Model Updates: 12,724
Cumulative Timesteps: 212,419,976

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 212419976...
Checkpoint 212419976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,858.30100
Policy Entropy: 0.50690
Value Function Loss: 0.16823

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.02061
Policy Update Magnitude: 0.01655
Value Function Update Magnitude: 0.01726

Collected Steps per Second: 24,084.22529
Overall Steps per Second: 16,719.10737

Timestep Collection Time: 2.07787
Timestep Consumption Time: 0.91535
PPO Batch Consumption Time: 0.09683
Total Iteration Time: 2.99322

Cumulative Model Updates: 12,727
Cumulative Timesteps: 212,470,020

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,081.50411
Policy Entropy: 0.50138
Value Function Loss: 0.16089

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01420
Policy Update Magnitude: 0.01582
Value Function Update Magnitude: 0.01976

Collected Steps per Second: 24,457.06332
Overall Steps per Second: 16,785.44694

Timestep Collection Time: 2.04464
Timestep Consumption Time: 0.93448
PPO Batch Consumption Time: 0.10841
Total Iteration Time: 2.97913

Cumulative Model Updates: 12,730
Cumulative Timesteps: 212,520,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 212520026...
Checkpoint 212520026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,097.06034
Policy Entropy: 0.50672
Value Function Loss: 0.15614

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01814
Policy Update Magnitude: 0.01520
Value Function Update Magnitude: 0.02075

Collected Steps per Second: 23,954.35330
Overall Steps per Second: 16,678.68100

Timestep Collection Time: 2.08805
Timestep Consumption Time: 0.91086
PPO Batch Consumption Time: 0.09585
Total Iteration Time: 2.99892

Cumulative Model Updates: 12,733
Cumulative Timesteps: 212,570,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,247.53388
Policy Entropy: 0.50466
Value Function Loss: 0.16873

Mean KL Divergence: 0.00116
SB3 Clip Fraction: 0.01073
Policy Update Magnitude: 0.01566
Value Function Update Magnitude: 0.02167

Collected Steps per Second: 24,777.74104
Overall Steps per Second: 16,786.18333

Timestep Collection Time: 2.01834
Timestep Consumption Time: 0.96089
PPO Batch Consumption Time: 0.11520
Total Iteration Time: 2.97924

Cumulative Model Updates: 12,736
Cumulative Timesteps: 212,620,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 212620054...
Checkpoint 212620054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,185.47378
Policy Entropy: 0.51167
Value Function Loss: 0.16969

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01547
Policy Update Magnitude: 0.01579
Value Function Update Magnitude: 0.02176

Collected Steps per Second: 23,659.34069
Overall Steps per Second: 16,756.71862

Timestep Collection Time: 2.11401
Timestep Consumption Time: 0.87083
PPO Batch Consumption Time: 0.10929
Total Iteration Time: 2.98483

Cumulative Model Updates: 12,739
Cumulative Timesteps: 212,670,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,792.60149
Policy Entropy: 0.51375
Value Function Loss: 0.16428

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01517
Policy Update Magnitude: 0.01526
Value Function Update Magnitude: 0.01999

Collected Steps per Second: 23,653.37498
Overall Steps per Second: 16,709.06367

Timestep Collection Time: 2.11581
Timestep Consumption Time: 0.87933
PPO Batch Consumption Time: 0.10736
Total Iteration Time: 2.99514

Cumulative Model Updates: 12,742
Cumulative Timesteps: 212,720,116

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 212720116...
Checkpoint 212720116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,920.60142
Policy Entropy: 0.51983
Value Function Loss: 0.14856

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01611
Policy Update Magnitude: 0.01638
Value Function Update Magnitude: 0.01923

Collected Steps per Second: 23,530.56084
Overall Steps per Second: 16,772.38921

Timestep Collection Time: 2.12549
Timestep Consumption Time: 0.85643
PPO Batch Consumption Time: 0.10785
Total Iteration Time: 2.98192

Cumulative Model Updates: 12,745
Cumulative Timesteps: 212,770,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,228.29464
Policy Entropy: 0.52536
Value Function Loss: 0.14216

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01499
Policy Update Magnitude: 0.01821
Value Function Update Magnitude: 0.01844

Collected Steps per Second: 23,916.60710
Overall Steps per Second: 16,641.40353

Timestep Collection Time: 2.09185
Timestep Consumption Time: 0.91451
PPO Batch Consumption Time: 0.10306
Total Iteration Time: 3.00636

Cumulative Model Updates: 12,748
Cumulative Timesteps: 212,820,160

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 212820160...
Checkpoint 212820160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,288.78363
Policy Entropy: 0.52113
Value Function Loss: 0.15444

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01397
Policy Update Magnitude: 0.01875
Value Function Update Magnitude: 0.02079

Collected Steps per Second: 23,482.74445
Overall Steps per Second: 16,739.08086

Timestep Collection Time: 2.12982
Timestep Consumption Time: 0.85804
PPO Batch Consumption Time: 0.08971
Total Iteration Time: 2.98786

Cumulative Model Updates: 12,751
Cumulative Timesteps: 212,870,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,500.77666
Policy Entropy: 0.52967
Value Function Loss: 0.14418

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01716
Policy Update Magnitude: 0.01837
Value Function Update Magnitude: 0.02163

Collected Steps per Second: 23,886.95419
Overall Steps per Second: 16,642.99348

Timestep Collection Time: 2.09386
Timestep Consumption Time: 0.91137
PPO Batch Consumption Time: 0.10123
Total Iteration Time: 3.00523

Cumulative Model Updates: 12,754
Cumulative Timesteps: 212,920,190

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 212920190...
Checkpoint 212920190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,357.94258
Policy Entropy: 0.53333
Value Function Loss: 0.14823

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01927
Policy Update Magnitude: 0.01630
Value Function Update Magnitude: 0.01919

Collected Steps per Second: 24,321.07870
Overall Steps per Second: 16,874.23931

Timestep Collection Time: 2.05641
Timestep Consumption Time: 0.90752
PPO Batch Consumption Time: 0.10397
Total Iteration Time: 2.96393

Cumulative Model Updates: 12,757
Cumulative Timesteps: 212,970,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,371.75949
Policy Entropy: 0.53849
Value Function Loss: 0.13681

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02138
Policy Update Magnitude: 0.01604
Value Function Update Magnitude: 0.02075

Collected Steps per Second: 22,314.41485
Overall Steps per Second: 15,587.59263

Timestep Collection Time: 2.24178
Timestep Consumption Time: 0.96744
PPO Batch Consumption Time: 0.10649
Total Iteration Time: 3.20922

Cumulative Model Updates: 12,760
Cumulative Timesteps: 213,020,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 213020228...
Checkpoint 213020228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,846.23017
Policy Entropy: 0.53714
Value Function Loss: 0.13867

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02882
Policy Update Magnitude: 0.01505
Value Function Update Magnitude: 0.02354

Collected Steps per Second: 22,312.44137
Overall Steps per Second: 16,225.65884

Timestep Collection Time: 2.24153
Timestep Consumption Time: 0.84087
PPO Batch Consumption Time: 0.06442
Total Iteration Time: 3.08240

Cumulative Model Updates: 12,763
Cumulative Timesteps: 213,070,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,521.36856
Policy Entropy: 0.53309
Value Function Loss: 0.13857

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03432
Policy Update Magnitude: 0.01492
Value Function Update Magnitude: 0.02920

Collected Steps per Second: 23,079.58742
Overall Steps per Second: 16,171.82955

Timestep Collection Time: 2.16650
Timestep Consumption Time: 0.92542
PPO Batch Consumption Time: 0.10210
Total Iteration Time: 3.09192

Cumulative Model Updates: 12,766
Cumulative Timesteps: 213,120,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 213120244...
Checkpoint 213120244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,390.17039
Policy Entropy: 0.53610
Value Function Loss: 0.13210

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.03111
Policy Update Magnitude: 0.01388
Value Function Update Magnitude: 0.02234

Collected Steps per Second: 22,277.95223
Overall Steps per Second: 16,371.31241

Timestep Collection Time: 2.24563
Timestep Consumption Time: 0.81020
PPO Batch Consumption Time: 0.06254
Total Iteration Time: 3.05583

Cumulative Model Updates: 12,769
Cumulative Timesteps: 213,170,272

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,561.12565
Policy Entropy: 0.53211
Value Function Loss: 0.14830

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.01506
Value Function Update Magnitude: 0.02752

Collected Steps per Second: 20,745.49884
Overall Steps per Second: 15,052.97589

Timestep Collection Time: 2.41055
Timestep Consumption Time: 0.91159
PPO Batch Consumption Time: 0.08643
Total Iteration Time: 3.32213

Cumulative Model Updates: 12,772
Cumulative Timesteps: 213,220,280

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 213220280...
Checkpoint 213220280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,929.50214
Policy Entropy: 0.53763
Value Function Loss: 0.13297

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01764
Policy Update Magnitude: 0.01467
Value Function Update Magnitude: 0.02284

Collected Steps per Second: 23,038.70134
Overall Steps per Second: 16,887.71466

Timestep Collection Time: 2.17096
Timestep Consumption Time: 0.79072
PPO Batch Consumption Time: 0.06059
Total Iteration Time: 2.96168

Cumulative Model Updates: 12,775
Cumulative Timesteps: 213,270,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,221.05513
Policy Entropy: 0.53468
Value Function Loss: 0.15400

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01837
Policy Update Magnitude: 0.01505
Value Function Update Magnitude: 0.02464

Collected Steps per Second: 20,732.93968
Overall Steps per Second: 14,709.55005

Timestep Collection Time: 2.41259
Timestep Consumption Time: 0.98793
PPO Batch Consumption Time: 0.12152
Total Iteration Time: 3.40051

Cumulative Model Updates: 12,778
Cumulative Timesteps: 213,320,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 213320316...
Checkpoint 213320316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,585.74050
Policy Entropy: 0.53813
Value Function Loss: 0.13531

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.01448
Value Function Update Magnitude: 0.02238

Collected Steps per Second: 22,768.51647
Overall Steps per Second: 15,684.16788

Timestep Collection Time: 2.19637
Timestep Consumption Time: 0.99207
PPO Batch Consumption Time: 0.11352
Total Iteration Time: 3.18844

Cumulative Model Updates: 12,781
Cumulative Timesteps: 213,370,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,062.71674
Policy Entropy: 0.53447
Value Function Loss: 0.14607

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02302
Policy Update Magnitude: 0.01528
Value Function Update Magnitude: 0.02130

Collected Steps per Second: 23,384.01366
Overall Steps per Second: 16,880.54736

Timestep Collection Time: 2.13847
Timestep Consumption Time: 0.82388
PPO Batch Consumption Time: 0.06136
Total Iteration Time: 2.96234

Cumulative Model Updates: 12,784
Cumulative Timesteps: 213,420,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 213420330...
Checkpoint 213420330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,846.06498
Policy Entropy: 0.53885
Value Function Loss: 0.12987

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.01506
Value Function Update Magnitude: 0.02021

Collected Steps per Second: 23,027.01403
Overall Steps per Second: 16,786.62264

Timestep Collection Time: 2.17275
Timestep Consumption Time: 0.80772
PPO Batch Consumption Time: 0.06451
Total Iteration Time: 2.98047

Cumulative Model Updates: 12,787
Cumulative Timesteps: 213,470,362

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,950.50512
Policy Entropy: 0.53287
Value Function Loss: 0.14386

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 0.01475
Value Function Update Magnitude: 0.02000

Collected Steps per Second: 19,021.22407
Overall Steps per Second: 14,377.07664

Timestep Collection Time: 2.63001
Timestep Consumption Time: 0.84956
PPO Batch Consumption Time: 0.05366
Total Iteration Time: 3.47957

Cumulative Model Updates: 12,790
Cumulative Timesteps: 213,520,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 213520388...
Checkpoint 213520388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,239.45905
Policy Entropy: 0.52894
Value Function Loss: 0.13751

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.01591
Value Function Update Magnitude: 0.01687

Collected Steps per Second: 20,804.33706
Overall Steps per Second: 15,034.73605

Timestep Collection Time: 2.40469
Timestep Consumption Time: 0.92280
PPO Batch Consumption Time: 0.09501
Total Iteration Time: 3.32749

Cumulative Model Updates: 12,793
Cumulative Timesteps: 213,570,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,239.45905
Policy Entropy: 0.53319
Value Function Loss: 0.13181

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04193
Policy Update Magnitude: 0.01515
Value Function Update Magnitude: 0.02070

Collected Steps per Second: 17,431.72837
Overall Steps per Second: 13,529.45872

Timestep Collection Time: 2.86902
Timestep Consumption Time: 0.82750
PPO Batch Consumption Time: 0.07308
Total Iteration Time: 3.69653

Cumulative Model Updates: 12,796
Cumulative Timesteps: 213,620,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 213620428...
Checkpoint 213620428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,358.00175
Policy Entropy: 0.53189
Value Function Loss: 0.13031

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03057
Policy Update Magnitude: 0.01513
Value Function Update Magnitude: 0.01909

Collected Steps per Second: 20,024.94668
Overall Steps per Second: 15,230.74469

Timestep Collection Time: 2.49709
Timestep Consumption Time: 0.78601
PPO Batch Consumption Time: 0.07477
Total Iteration Time: 3.28310

Cumulative Model Updates: 12,799
Cumulative Timesteps: 213,670,432

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,454.48091
Policy Entropy: 0.53125
Value Function Loss: 0.13706

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03395
Policy Update Magnitude: 0.01466
Value Function Update Magnitude: 0.01799

Collected Steps per Second: 21,579.02128
Overall Steps per Second: 16,540.95390

Timestep Collection Time: 2.31725
Timestep Consumption Time: 0.70579
PPO Batch Consumption Time: 0.05424
Total Iteration Time: 3.02304

Cumulative Model Updates: 12,802
Cumulative Timesteps: 213,720,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 213720436...
Checkpoint 213720436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,900.24991
Policy Entropy: 0.52100
Value Function Loss: 0.15829

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.01527
Value Function Update Magnitude: 0.01862

Collected Steps per Second: 20,960.24093
Overall Steps per Second: 15,047.41814

Timestep Collection Time: 2.38566
Timestep Consumption Time: 0.93744
PPO Batch Consumption Time: 0.10932
Total Iteration Time: 3.32309

Cumulative Model Updates: 12,805
Cumulative Timesteps: 213,770,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,454.07249
Policy Entropy: 0.52469
Value Function Loss: 0.15593

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02710
Policy Update Magnitude: 0.01673
Value Function Update Magnitude: 0.01802

Collected Steps per Second: 24,533.15868
Overall Steps per Second: 16,722.78310

Timestep Collection Time: 2.03920
Timestep Consumption Time: 0.95241
PPO Batch Consumption Time: 0.11608
Total Iteration Time: 2.99161

Cumulative Model Updates: 12,808
Cumulative Timesteps: 213,820,468

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 213820468...
Checkpoint 213820468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,828.27815
Policy Entropy: 0.52799
Value Function Loss: 0.14715

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04089
Policy Update Magnitude: 0.01794
Value Function Update Magnitude: 0.01910

Collected Steps per Second: 22,446.90773
Overall Steps per Second: 15,450.72694

Timestep Collection Time: 2.22810
Timestep Consumption Time: 1.00890
PPO Batch Consumption Time: 0.13039
Total Iteration Time: 3.23700

Cumulative Model Updates: 12,811
Cumulative Timesteps: 213,870,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,409.70747
Policy Entropy: 0.53008
Value Function Loss: 0.14229

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03242
Policy Update Magnitude: 0.01613
Value Function Update Magnitude: 0.01890

Collected Steps per Second: 19,511.85195
Overall Steps per Second: 14,569.05923

Timestep Collection Time: 2.56429
Timestep Consumption Time: 0.86998
PPO Batch Consumption Time: 0.06892
Total Iteration Time: 3.43426

Cumulative Model Updates: 12,814
Cumulative Timesteps: 213,920,516

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 213920516...
Checkpoint 213920516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,227.17435
Policy Entropy: 0.52907
Value Function Loss: 0.14308

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04155
Policy Update Magnitude: 0.01521
Value Function Update Magnitude: 0.01628

Collected Steps per Second: 18,615.08291
Overall Steps per Second: 14,002.67469

Timestep Collection Time: 2.68857
Timestep Consumption Time: 0.88560
PPO Batch Consumption Time: 0.07029
Total Iteration Time: 3.57417

Cumulative Model Updates: 12,817
Cumulative Timesteps: 213,970,564

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,390.56101
Policy Entropy: 0.53078
Value Function Loss: 0.14885

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.01571
Value Function Update Magnitude: 0.01815

Collected Steps per Second: 18,688.25757
Overall Steps per Second: 14,107.68126

Timestep Collection Time: 2.67590
Timestep Consumption Time: 0.86883
PPO Batch Consumption Time: 0.06555
Total Iteration Time: 3.54474

Cumulative Model Updates: 12,820
Cumulative Timesteps: 214,020,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 214020572...
Checkpoint 214020572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,881.87745
Policy Entropy: 0.52269
Value Function Loss: 0.16212

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03422
Policy Update Magnitude: 0.01626
Value Function Update Magnitude: 0.01854

Collected Steps per Second: 18,164.19544
Overall Steps per Second: 13,953.09254

Timestep Collection Time: 2.75388
Timestep Consumption Time: 0.83113
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 3.58501

Cumulative Model Updates: 12,823
Cumulative Timesteps: 214,070,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,061.77515
Policy Entropy: 0.52340
Value Function Loss: 0.17720

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03310
Policy Update Magnitude: 0.01587
Value Function Update Magnitude: 0.02608

Collected Steps per Second: 19,680.55445
Overall Steps per Second: 14,577.71163

Timestep Collection Time: 2.54088
Timestep Consumption Time: 0.88942
PPO Batch Consumption Time: 0.06614
Total Iteration Time: 3.43031

Cumulative Model Updates: 12,826
Cumulative Timesteps: 214,120,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 214120600...
Checkpoint 214120600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,893.53062
Policy Entropy: 0.52222
Value Function Loss: 0.17798

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03850
Policy Update Magnitude: 0.01820
Value Function Update Magnitude: 0.02572

Collected Steps per Second: 18,913.78675
Overall Steps per Second: 14,219.15545

Timestep Collection Time: 2.64463
Timestep Consumption Time: 0.87316
PPO Batch Consumption Time: 0.06878
Total Iteration Time: 3.51779

Cumulative Model Updates: 12,829
Cumulative Timesteps: 214,170,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,527.07311
Policy Entropy: 0.51816
Value Function Loss: 0.17698

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03591
Policy Update Magnitude: 0.01840
Value Function Update Magnitude: 0.02587

Collected Steps per Second: 21,878.48686
Overall Steps per Second: 15,658.61551

Timestep Collection Time: 2.28599
Timestep Consumption Time: 0.90803
PPO Batch Consumption Time: 0.08984
Total Iteration Time: 3.19402

Cumulative Model Updates: 12,832
Cumulative Timesteps: 214,220,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 214220634...
Checkpoint 214220634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,753.51141
Policy Entropy: 0.51568
Value Function Loss: 0.16296

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04425
Policy Update Magnitude: 0.01893
Value Function Update Magnitude: 0.02456

Collected Steps per Second: 23,002.36931
Overall Steps per Second: 16,857.41064

Timestep Collection Time: 2.17456
Timestep Consumption Time: 0.79268
PPO Batch Consumption Time: 0.05847
Total Iteration Time: 2.96724

Cumulative Model Updates: 12,835
Cumulative Timesteps: 214,270,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,746.04778
Policy Entropy: 0.51471
Value Function Loss: 0.17448

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04697
Policy Update Magnitude: 0.01892
Value Function Update Magnitude: 0.02310

Collected Steps per Second: 19,548.48587
Overall Steps per Second: 13,924.46924

Timestep Collection Time: 2.55825
Timestep Consumption Time: 1.03326
PPO Batch Consumption Time: 0.12892
Total Iteration Time: 3.59152

Cumulative Model Updates: 12,838
Cumulative Timesteps: 214,320,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 214320664...
Checkpoint 214320664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,423.88080
Policy Entropy: 0.51042
Value Function Loss: 0.18358

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06858
Policy Update Magnitude: 0.01838
Value Function Update Magnitude: 0.02180

Collected Steps per Second: 22,617.74492
Overall Steps per Second: 16,628.39844

Timestep Collection Time: 2.21189
Timestep Consumption Time: 0.79670
PPO Batch Consumption Time: 0.07724
Total Iteration Time: 3.00859

Cumulative Model Updates: 12,841
Cumulative Timesteps: 214,370,692

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,780.95168
Policy Entropy: 0.51237
Value Function Loss: 0.19111

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06573
Policy Update Magnitude: 0.01608
Value Function Update Magnitude: 0.02507

Collected Steps per Second: 22,259.83405
Overall Steps per Second: 15,766.29632

Timestep Collection Time: 2.24782
Timestep Consumption Time: 0.92579
PPO Batch Consumption Time: 0.11859
Total Iteration Time: 3.17361

Cumulative Model Updates: 12,844
Cumulative Timesteps: 214,420,728

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 214420728...
Checkpoint 214420728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,343.37689
Policy Entropy: 0.51420
Value Function Loss: 0.17670

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05429
Policy Update Magnitude: 0.01707
Value Function Update Magnitude: 0.02379

Collected Steps per Second: 22,194.60542
Overall Steps per Second: 16,777.91061

Timestep Collection Time: 2.25370
Timestep Consumption Time: 0.72760
PPO Batch Consumption Time: 0.05852
Total Iteration Time: 2.98130

Cumulative Model Updates: 12,847
Cumulative Timesteps: 214,470,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,226.27343
Policy Entropy: 0.51659
Value Function Loss: 0.16120

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05737
Policy Update Magnitude: 0.01549
Value Function Update Magnitude: 0.02360

Collected Steps per Second: 20,534.63705
Overall Steps per Second: 14,710.41481

Timestep Collection Time: 2.43588
Timestep Consumption Time: 0.96443
PPO Batch Consumption Time: 0.11497
Total Iteration Time: 3.40031

Cumulative Model Updates: 12,850
Cumulative Timesteps: 214,520,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 214520768...
Checkpoint 214520768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,934.03880
Policy Entropy: 0.51850
Value Function Loss: 0.15724

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.04013
Policy Update Magnitude: 0.01538
Value Function Update Magnitude: 0.02105

Collected Steps per Second: 22,588.08851
Overall Steps per Second: 15,717.71628

Timestep Collection Time: 2.21471
Timestep Consumption Time: 0.96807
PPO Batch Consumption Time: 0.11384
Total Iteration Time: 3.18278

Cumulative Model Updates: 12,853
Cumulative Timesteps: 214,570,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,554.70281
Policy Entropy: 0.52232
Value Function Loss: 0.14212

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05859
Policy Update Magnitude: 0.01706
Value Function Update Magnitude: 0.02062

Collected Steps per Second: 22,828.33189
Overall Steps per Second: 16,797.10930

Timestep Collection Time: 2.19044
Timestep Consumption Time: 0.78650
PPO Batch Consumption Time: 0.06438
Total Iteration Time: 2.97694

Cumulative Model Updates: 12,856
Cumulative Timesteps: 214,620,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 214620798...
Checkpoint 214620798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,809.05357
Policy Entropy: 0.52698
Value Function Loss: 0.12648

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.04099
Policy Update Magnitude: 0.01721
Value Function Update Magnitude: 0.01946

Collected Steps per Second: 20,062.75274
Overall Steps per Second: 14,651.20467

Timestep Collection Time: 2.49407
Timestep Consumption Time: 0.92121
PPO Batch Consumption Time: 0.03488
Total Iteration Time: 3.41528

Cumulative Model Updates: 12,859
Cumulative Timesteps: 214,670,836

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,783.97040
Policy Entropy: 0.52502
Value Function Loss: 0.10984

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02762
Policy Update Magnitude: 0.01576
Value Function Update Magnitude: 0.01737

Collected Steps per Second: 18,278.84904
Overall Steps per Second: 13,856.08648

Timestep Collection Time: 2.73617
Timestep Consumption Time: 0.87337
PPO Batch Consumption Time: 0.06626
Total Iteration Time: 3.60953

Cumulative Model Updates: 12,862
Cumulative Timesteps: 214,720,850

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 214720850...
Checkpoint 214720850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,217.81489
Policy Entropy: 0.52674
Value Function Loss: 0.11793

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.01666
Value Function Update Magnitude: 0.02063

Collected Steps per Second: 17,785.71826
Overall Steps per Second: 13,295.74156

Timestep Collection Time: 2.81181
Timestep Consumption Time: 0.94955
PPO Batch Consumption Time: 0.03398
Total Iteration Time: 3.76135

Cumulative Model Updates: 12,865
Cumulative Timesteps: 214,770,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,154.65834
Policy Entropy: 0.51741
Value Function Loss: 0.15057

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03369
Policy Update Magnitude: 0.01620
Value Function Update Magnitude: 0.02842

Collected Steps per Second: 18,864.75822
Overall Steps per Second: 14,391.72649

Timestep Collection Time: 2.65055
Timestep Consumption Time: 0.82381
PPO Batch Consumption Time: 0.05176
Total Iteration Time: 3.47436

Cumulative Model Updates: 12,868
Cumulative Timesteps: 214,820,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 214820862...
Checkpoint 214820862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,955.47409
Policy Entropy: 0.51483
Value Function Loss: 0.17656

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03387
Policy Update Magnitude: 0.01457
Value Function Update Magnitude: 0.03408

Collected Steps per Second: 21,359.60890
Overall Steps per Second: 15,188.87080

Timestep Collection Time: 2.34105
Timestep Consumption Time: 0.95109
PPO Batch Consumption Time: 0.10017
Total Iteration Time: 3.29215

Cumulative Model Updates: 12,871
Cumulative Timesteps: 214,870,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,091.40493
Policy Entropy: 0.50459
Value Function Loss: 0.20067

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02641
Policy Update Magnitude: 0.01586
Value Function Update Magnitude: 0.05046

Collected Steps per Second: 23,068.80383
Overall Steps per Second: 16,808.75039

Timestep Collection Time: 2.16873
Timestep Consumption Time: 0.80770
PPO Batch Consumption Time: 0.06017
Total Iteration Time: 2.97643

Cumulative Model Updates: 12,874
Cumulative Timesteps: 214,920,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 214920896...
Checkpoint 214920896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,041.10434
Policy Entropy: 0.50576
Value Function Loss: 0.19174

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01999
Policy Update Magnitude: 0.01721
Value Function Update Magnitude: 0.04289

Collected Steps per Second: 20,368.93572
Overall Steps per Second: 14,722.47883

Timestep Collection Time: 2.45678
Timestep Consumption Time: 0.94224
PPO Batch Consumption Time: 0.09972
Total Iteration Time: 3.39902

Cumulative Model Updates: 12,877
Cumulative Timesteps: 214,970,938

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,852.78122
Policy Entropy: 0.50665
Value Function Loss: 0.17212

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02309
Policy Update Magnitude: 0.01891
Value Function Update Magnitude: 0.03795

Collected Steps per Second: 23,081.41080
Overall Steps per Second: 16,785.96273

Timestep Collection Time: 2.16677
Timestep Consumption Time: 0.81263
PPO Batch Consumption Time: 0.05981
Total Iteration Time: 2.97939

Cumulative Model Updates: 12,880
Cumulative Timesteps: 215,020,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 215020950...
Checkpoint 215020950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,475.12443
Policy Entropy: 0.50603
Value Function Loss: 0.17202

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02912
Policy Update Magnitude: 0.02049
Value Function Update Magnitude: 0.03237

Collected Steps per Second: 20,139.44327
Overall Steps per Second: 14,727.10633

Timestep Collection Time: 2.48299
Timestep Consumption Time: 0.91252
PPO Batch Consumption Time: 0.09321
Total Iteration Time: 3.39551

Cumulative Model Updates: 12,883
Cumulative Timesteps: 215,070,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,593.37448
Policy Entropy: 0.50572
Value Function Loss: 0.16429

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04919
Policy Update Magnitude: 0.01843
Value Function Update Magnitude: 0.03430

Collected Steps per Second: 23,379.85892
Overall Steps per Second: 16,668.06211

Timestep Collection Time: 2.13979
Timestep Consumption Time: 0.86164
PPO Batch Consumption Time: 0.07929
Total Iteration Time: 3.00143

Cumulative Model Updates: 12,886
Cumulative Timesteps: 215,120,984

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 215120984...
Checkpoint 215120984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,399.32669
Policy Entropy: 0.50232
Value Function Loss: 0.16024

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03446
Policy Update Magnitude: 0.01774
Value Function Update Magnitude: 0.02839

Collected Steps per Second: 22,259.59013
Overall Steps per Second: 15,748.69614

Timestep Collection Time: 2.24631
Timestep Consumption Time: 0.92868
PPO Batch Consumption Time: 0.09890
Total Iteration Time: 3.17499

Cumulative Model Updates: 12,889
Cumulative Timesteps: 215,170,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,021.81533
Policy Entropy: 0.50212
Value Function Loss: 0.15058

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04643
Policy Update Magnitude: 0.01632
Value Function Update Magnitude: 0.02458

Collected Steps per Second: 23,048.31689
Overall Steps per Second: 16,835.22823

Timestep Collection Time: 2.16970
Timestep Consumption Time: 0.80073
PPO Batch Consumption Time: 0.06158
Total Iteration Time: 2.97044

Cumulative Model Updates: 12,892
Cumulative Timesteps: 215,220,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 215220994...
Checkpoint 215220994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,523.31649
Policy Entropy: 0.50355
Value Function Loss: 0.15287

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.03075
Policy Update Magnitude: 0.01592
Value Function Update Magnitude: 0.02318

Collected Steps per Second: 20,606.85507
Overall Steps per Second: 14,705.04975

Timestep Collection Time: 2.42754
Timestep Consumption Time: 0.97428
PPO Batch Consumption Time: 0.11143
Total Iteration Time: 3.40182

Cumulative Model Updates: 12,895
Cumulative Timesteps: 215,271,018

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,939.78912
Policy Entropy: 0.50637
Value Function Loss: 0.16373

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05212
Policy Update Magnitude: 0.01816
Value Function Update Magnitude: 0.02140

Collected Steps per Second: 23,332.92908
Overall Steps per Second: 16,645.89370

Timestep Collection Time: 2.14307
Timestep Consumption Time: 0.86092
PPO Batch Consumption Time: 0.07952
Total Iteration Time: 3.00398

Cumulative Model Updates: 12,898
Cumulative Timesteps: 215,321,022

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 215321022...
Checkpoint 215321022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,897.29013
Policy Entropy: 0.51003
Value Function Loss: 0.16260

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.05275
Policy Update Magnitude: 0.01539
Value Function Update Magnitude: 0.02199

Collected Steps per Second: 22,378.11351
Overall Steps per Second: 15,732.54200

Timestep Collection Time: 2.23486
Timestep Consumption Time: 0.94403
PPO Batch Consumption Time: 0.09403
Total Iteration Time: 3.17889

Cumulative Model Updates: 12,901
Cumulative Timesteps: 215,371,034

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,184.67935
Policy Entropy: 0.51032
Value Function Loss: 0.16387

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03429
Policy Update Magnitude: 0.01672
Value Function Update Magnitude: 0.02971

Collected Steps per Second: 22,683.85940
Overall Steps per Second: 16,960.52165

Timestep Collection Time: 2.20492
Timestep Consumption Time: 0.74405
PPO Batch Consumption Time: 0.06448
Total Iteration Time: 2.94897

Cumulative Model Updates: 12,904
Cumulative Timesteps: 215,421,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 215421050...
Checkpoint 215421050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,785.05038
Policy Entropy: 0.50900
Value Function Loss: 0.16077

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04299
Policy Update Magnitude: 0.01849
Value Function Update Magnitude: 0.04272

Collected Steps per Second: 22,416.00856
Overall Steps per Second: 16,931.71198

Timestep Collection Time: 2.23073
Timestep Consumption Time: 0.72255
PPO Batch Consumption Time: 0.06286
Total Iteration Time: 2.95327

Cumulative Model Updates: 12,907
Cumulative Timesteps: 215,471,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,951.76126
Policy Entropy: 0.51499
Value Function Loss: 0.15026

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03423
Policy Update Magnitude: 0.01868
Value Function Update Magnitude: 0.04752

Collected Steps per Second: 22,145.96449
Overall Steps per Second: 16,717.78647

Timestep Collection Time: 2.25973
Timestep Consumption Time: 0.73372
PPO Batch Consumption Time: 0.06718
Total Iteration Time: 2.99346

Cumulative Model Updates: 12,910
Cumulative Timesteps: 215,521,098

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 215521098...
Checkpoint 215521098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,453.57638
Policy Entropy: 0.51640
Value Function Loss: 0.14500

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04375
Policy Update Magnitude: 0.01776
Value Function Update Magnitude: 0.04092

Collected Steps per Second: 22,420.96898
Overall Steps per Second: 16,919.25490

Timestep Collection Time: 2.23130
Timestep Consumption Time: 0.72556
PPO Batch Consumption Time: 0.06135
Total Iteration Time: 2.95687

Cumulative Model Updates: 12,913
Cumulative Timesteps: 215,571,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,288.39341
Policy Entropy: 0.51425
Value Function Loss: 0.15101

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03673
Policy Update Magnitude: 0.01699
Value Function Update Magnitude: 0.03321

Collected Steps per Second: 22,748.46555
Overall Steps per Second: 16,677.99912

Timestep Collection Time: 2.19821
Timestep Consumption Time: 0.80011
PPO Batch Consumption Time: 0.06591
Total Iteration Time: 2.99832

Cumulative Model Updates: 12,916
Cumulative Timesteps: 215,621,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 215621132...
Checkpoint 215621132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,368.27496
Policy Entropy: 0.50249
Value Function Loss: 0.17420

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.01691
Value Function Update Magnitude: 0.02913

Collected Steps per Second: 22,119.65119
Overall Steps per Second: 16,410.27673

Timestep Collection Time: 2.26161
Timestep Consumption Time: 0.78685
PPO Batch Consumption Time: 0.06274
Total Iteration Time: 3.04846

Cumulative Model Updates: 12,919
Cumulative Timesteps: 215,671,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,822.08320
Policy Entropy: 0.50282
Value Function Loss: 0.17240

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.01289
Policy Update Magnitude: 0.01694
Value Function Update Magnitude: 0.03116

Collected Steps per Second: 20,276.47513
Overall Steps per Second: 14,660.91720

Timestep Collection Time: 2.46690
Timestep Consumption Time: 0.94489
PPO Batch Consumption Time: 0.10961
Total Iteration Time: 3.41179

Cumulative Model Updates: 12,922
Cumulative Timesteps: 215,721,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 215721178...
Checkpoint 215721178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,794.91141
Policy Entropy: 0.50229
Value Function Loss: 0.17200

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01483
Policy Update Magnitude: 0.01783
Value Function Update Magnitude: 0.02806

Collected Steps per Second: 23,141.37127
Overall Steps per Second: 16,639.27839

Timestep Collection Time: 2.16081
Timestep Consumption Time: 0.84437
PPO Batch Consumption Time: 0.07719
Total Iteration Time: 3.00518

Cumulative Model Updates: 12,925
Cumulative Timesteps: 215,771,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,430.04574
Policy Entropy: 0.50813
Value Function Loss: 0.16102

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01977
Policy Update Magnitude: 0.01673
Value Function Update Magnitude: 0.02458

Collected Steps per Second: 22,980.63379
Overall Steps per Second: 16,823.22849

Timestep Collection Time: 2.17592
Timestep Consumption Time: 0.79640
PPO Batch Consumption Time: 0.05839
Total Iteration Time: 2.97232

Cumulative Model Updates: 12,928
Cumulative Timesteps: 215,821,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 215821186...
Checkpoint 215821186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,422.10434
Policy Entropy: 0.50820
Value Function Loss: 0.16737

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.01701
Value Function Update Magnitude: 0.02330

Collected Steps per Second: 19,279.95946
Overall Steps per Second: 13,984.49702

Timestep Collection Time: 2.59472
Timestep Consumption Time: 0.98253
PPO Batch Consumption Time: 0.11538
Total Iteration Time: 3.57725

Cumulative Model Updates: 12,931
Cumulative Timesteps: 215,871,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,269.43235
Policy Entropy: 0.50671
Value Function Loss: 0.16450

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03340
Policy Update Magnitude: 0.01756
Value Function Update Magnitude: 0.02507

Collected Steps per Second: 23,115.96797
Overall Steps per Second: 15,725.92883

Timestep Collection Time: 2.16396
Timestep Consumption Time: 1.01690
PPO Batch Consumption Time: 0.12480
Total Iteration Time: 3.18086

Cumulative Model Updates: 12,934
Cumulative Timesteps: 215,921,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 215921234...
Checkpoint 215921234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,525.82558
Policy Entropy: 0.50567
Value Function Loss: 0.15211

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02875
Policy Update Magnitude: 0.01785
Value Function Update Magnitude: 0.02340

Collected Steps per Second: 23,393.65459
Overall Steps per Second: 17,011.99307

Timestep Collection Time: 2.13759
Timestep Consumption Time: 0.80187
PPO Batch Consumption Time: 0.06018
Total Iteration Time: 2.93946

Cumulative Model Updates: 12,937
Cumulative Timesteps: 215,971,240

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,300.58833
Policy Entropy: 0.50996
Value Function Loss: 0.13290

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03896
Policy Update Magnitude: 0.01613
Value Function Update Magnitude: 0.02090

Collected Steps per Second: 23,228.56104
Overall Steps per Second: 16,651.17581

Timestep Collection Time: 2.15364
Timestep Consumption Time: 0.85071
PPO Batch Consumption Time: 0.06705
Total Iteration Time: 3.00435

Cumulative Model Updates: 12,940
Cumulative Timesteps: 216,021,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 216021266...
Checkpoint 216021266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,268.23894
Policy Entropy: 0.50479
Value Function Loss: 0.14369

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02852
Policy Update Magnitude: 0.01427
Value Function Update Magnitude: 0.01901

Collected Steps per Second: 23,217.99131
Overall Steps per Second: 16,898.73474

Timestep Collection Time: 2.15350
Timestep Consumption Time: 0.80530
PPO Batch Consumption Time: 0.06718
Total Iteration Time: 2.95880

Cumulative Model Updates: 12,943
Cumulative Timesteps: 216,071,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,778.13995
Policy Entropy: 0.50904
Value Function Loss: 0.15117

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01319
Policy Update Magnitude: 0.01636
Value Function Update Magnitude: 0.01886

Collected Steps per Second: 23,205.15763
Overall Steps per Second: 16,949.66276

Timestep Collection Time: 2.15469
Timestep Consumption Time: 0.79522
PPO Batch Consumption Time: 0.06379
Total Iteration Time: 2.94991

Cumulative Model Updates: 12,946
Cumulative Timesteps: 216,121,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 216121266...
Checkpoint 216121266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,778.13995
Policy Entropy: 0.50817
Value Function Loss: 0.14428

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01353
Policy Update Magnitude: 0.01813
Value Function Update Magnitude: 0.01717

Collected Steps per Second: 20,038.90168
Overall Steps per Second: 15,147.97269

Timestep Collection Time: 2.49634
Timestep Consumption Time: 0.80601
PPO Batch Consumption Time: 0.08471
Total Iteration Time: 3.30236

Cumulative Model Updates: 12,949
Cumulative Timesteps: 216,171,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,290.92866
Policy Entropy: 0.51142
Value Function Loss: 0.13165

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01597
Policy Update Magnitude: 0.01761
Value Function Update Magnitude: 0.01892

Collected Steps per Second: 22,585.06903
Overall Steps per Second: 16,952.27104

Timestep Collection Time: 2.21518
Timestep Consumption Time: 0.73605
PPO Batch Consumption Time: 0.06224
Total Iteration Time: 2.95123

Cumulative Model Updates: 12,952
Cumulative Timesteps: 216,221,320

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 216221320...
Checkpoint 216221320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,771.71458
Policy Entropy: 0.51843
Value Function Loss: 0.12285

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01276
Policy Update Magnitude: 0.01644
Value Function Update Magnitude: 0.01848

Collected Steps per Second: 22,605.49566
Overall Steps per Second: 16,569.75045

Timestep Collection Time: 2.21397
Timestep Consumption Time: 0.80647
PPO Batch Consumption Time: 0.08602
Total Iteration Time: 3.02044

Cumulative Model Updates: 12,955
Cumulative Timesteps: 216,271,368

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,150.80577
Policy Entropy: 0.51645
Value Function Loss: 0.14410

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01322
Policy Update Magnitude: 0.01625
Value Function Update Magnitude: 0.02209

Collected Steps per Second: 22,328.70488
Overall Steps per Second: 16,832.50776

Timestep Collection Time: 2.23972
Timestep Consumption Time: 0.73132
PPO Batch Consumption Time: 0.06079
Total Iteration Time: 2.97104

Cumulative Model Updates: 12,958
Cumulative Timesteps: 216,321,378

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 216321378...
Checkpoint 216321378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,392.02534
Policy Entropy: 0.51765
Value Function Loss: 0.16216

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01603
Policy Update Magnitude: 0.01659
Value Function Update Magnitude: 0.02174

Collected Steps per Second: 19,067.51304
Overall Steps per Second: 13,848.21992

Timestep Collection Time: 2.62247
Timestep Consumption Time: 0.98839
PPO Batch Consumption Time: 0.12212
Total Iteration Time: 3.61086

Cumulative Model Updates: 12,961
Cumulative Timesteps: 216,371,382

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,830.89007
Policy Entropy: 0.52074
Value Function Loss: 0.16001

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01523
Policy Update Magnitude: 0.01651
Value Function Update Magnitude: 0.02516

Collected Steps per Second: 23,034.24487
Overall Steps per Second: 17,000.88682

Timestep Collection Time: 2.17164
Timestep Consumption Time: 0.77068
PPO Batch Consumption Time: 0.06176
Total Iteration Time: 2.94232

Cumulative Model Updates: 12,964
Cumulative Timesteps: 216,421,404

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 216421404...
Checkpoint 216421404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,699.29837
Policy Entropy: 0.52447
Value Function Loss: 0.14492

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01604
Policy Update Magnitude: 0.01688
Value Function Update Magnitude: 0.02083

Collected Steps per Second: 22,862.04722
Overall Steps per Second: 16,490.25919

Timestep Collection Time: 2.18721
Timestep Consumption Time: 0.84513
PPO Batch Consumption Time: 0.07829
Total Iteration Time: 3.03234

Cumulative Model Updates: 12,967
Cumulative Timesteps: 216,471,408

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,123.81535
Policy Entropy: 0.53239
Value Function Loss: 0.12703

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01264
Policy Update Magnitude: 0.01614
Value Function Update Magnitude: 0.01879

Collected Steps per Second: 22,077.72912
Overall Steps per Second: 16,538.32157

Timestep Collection Time: 2.26618
Timestep Consumption Time: 0.75904
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 3.02522

Cumulative Model Updates: 12,970
Cumulative Timesteps: 216,521,440

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 216521440...
Checkpoint 216521440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,114.41631
Policy Entropy: 0.52769
Value Function Loss: 0.12978

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02655
Policy Update Magnitude: 0.01636
Value Function Update Magnitude: 0.01820

Collected Steps per Second: 21,170.26929
Overall Steps per Second: 15,040.34186

Timestep Collection Time: 2.36228
Timestep Consumption Time: 0.96278
PPO Batch Consumption Time: 0.11203
Total Iteration Time: 3.32506

Cumulative Model Updates: 12,973
Cumulative Timesteps: 216,571,450

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,675.43383
Policy Entropy: 0.53312
Value Function Loss: 0.12464

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01956
Policy Update Magnitude: 0.01704
Value Function Update Magnitude: 0.01695

Collected Steps per Second: 24,055.43002
Overall Steps per Second: 17,312.57836

Timestep Collection Time: 2.07936
Timestep Consumption Time: 0.80986
PPO Batch Consumption Time: 0.06510
Total Iteration Time: 2.88923

Cumulative Model Updates: 12,976
Cumulative Timesteps: 216,621,470

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 216621470...
Checkpoint 216621470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,893.17390
Policy Entropy: 0.52754
Value Function Loss: 0.12670

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.01606
Value Function Update Magnitude: 0.01623

Collected Steps per Second: 21,861.71858
Overall Steps per Second: 15,250.56392

Timestep Collection Time: 2.28884
Timestep Consumption Time: 0.99222
PPO Batch Consumption Time: 0.12334
Total Iteration Time: 3.28106

Cumulative Model Updates: 12,979
Cumulative Timesteps: 216,671,508

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,016.26290
Policy Entropy: 0.52441
Value Function Loss: 0.13537

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.01483
Value Function Update Magnitude: 0.01763

Collected Steps per Second: 24,319.24236
Overall Steps per Second: 17,554.68349

Timestep Collection Time: 2.05640
Timestep Consumption Time: 0.79242
PPO Batch Consumption Time: 0.06143
Total Iteration Time: 2.84881

Cumulative Model Updates: 12,982
Cumulative Timesteps: 216,721,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 216721518...
Checkpoint 216721518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,941.27628
Policy Entropy: 0.52176
Value Function Loss: 0.13694

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01661
Policy Update Magnitude: 0.01552
Value Function Update Magnitude: 0.02120

Collected Steps per Second: 21,704.66212
Overall Steps per Second: 15,871.87456

Timestep Collection Time: 2.30457
Timestep Consumption Time: 0.84691
PPO Batch Consumption Time: 0.08039
Total Iteration Time: 3.15149

Cumulative Model Updates: 12,985
Cumulative Timesteps: 216,771,538

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,395.56234
Policy Entropy: 0.51776
Value Function Loss: 0.14145

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02605
Policy Update Magnitude: 0.01590
Value Function Update Magnitude: 0.02112

Collected Steps per Second: 24,331.55950
Overall Steps per Second: 17,530.38087

Timestep Collection Time: 2.05568
Timestep Consumption Time: 0.79753
PPO Batch Consumption Time: 0.06142
Total Iteration Time: 2.85322

Cumulative Model Updates: 12,988
Cumulative Timesteps: 216,821,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 216821556...
Checkpoint 216821556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,778.67045
Policy Entropy: 0.52247
Value Function Loss: 0.13211

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02123
Policy Update Magnitude: 0.01592
Value Function Update Magnitude: 0.02288

Collected Steps per Second: 21,147.37442
Overall Steps per Second: 15,120.07499

Timestep Collection Time: 2.36549
Timestep Consumption Time: 0.94295
PPO Batch Consumption Time: 0.10598
Total Iteration Time: 3.30845

Cumulative Model Updates: 12,991
Cumulative Timesteps: 216,871,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,190.00684
Policy Entropy: 0.51691
Value Function Loss: 0.14735

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03661
Policy Update Magnitude: 0.01540
Value Function Update Magnitude: 0.02401

Collected Steps per Second: 23,560.60711
Overall Steps per Second: 16,640.84158

Timestep Collection Time: 2.12422
Timestep Consumption Time: 0.88332
PPO Batch Consumption Time: 0.08397
Total Iteration Time: 3.00754

Cumulative Model Updates: 12,994
Cumulative Timesteps: 216,921,628

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 216921628...
Checkpoint 216921628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,072.11628
Policy Entropy: 0.52301
Value Function Loss: 0.13813

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02049
Policy Update Magnitude: 0.01610
Value Function Update Magnitude: 0.02400

Collected Steps per Second: 22,561.32066
Overall Steps per Second: 15,859.88306

Timestep Collection Time: 2.21689
Timestep Consumption Time: 0.93673
PPO Batch Consumption Time: 0.10251
Total Iteration Time: 3.15362

Cumulative Model Updates: 12,997
Cumulative Timesteps: 216,971,644

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,565.72507
Policy Entropy: 0.51475
Value Function Loss: 0.14595

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04516
Policy Update Magnitude: 0.01702
Value Function Update Magnitude: 0.02486

Collected Steps per Second: 22,211.06632
Overall Steps per Second: 16,841.78970

Timestep Collection Time: 2.25212
Timestep Consumption Time: 0.71799
PPO Batch Consumption Time: 0.06565
Total Iteration Time: 2.97011

Cumulative Model Updates: 13,000
Cumulative Timesteps: 217,021,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 217021666...
Checkpoint 217021666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,433.30381
Policy Entropy: 0.51532
Value Function Loss: 0.14723

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04967
Policy Update Magnitude: 0.02321
Value Function Update Magnitude: 0.02375

Collected Steps per Second: 22,187.67868
Overall Steps per Second: 16,725.84719

Timestep Collection Time: 2.25422
Timestep Consumption Time: 0.73612
PPO Batch Consumption Time: 0.06167
Total Iteration Time: 2.99034

Cumulative Model Updates: 13,003
Cumulative Timesteps: 217,071,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,507.02979
Policy Entropy: 0.51369
Value Function Loss: 0.15664

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03818
Policy Update Magnitude: 0.02370
Value Function Update Magnitude: 0.02565

Collected Steps per Second: 20,154.23460
Overall Steps per Second: 14,675.22958

Timestep Collection Time: 2.48226
Timestep Consumption Time: 0.92675
PPO Batch Consumption Time: 0.12368
Total Iteration Time: 3.40901

Cumulative Model Updates: 13,006
Cumulative Timesteps: 217,121,710

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 217121710...
Checkpoint 217121710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,426.47146
Policy Entropy: 0.51386
Value Function Loss: 0.17923

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.05194
Policy Update Magnitude: 0.02089
Value Function Update Magnitude: 0.02442

Collected Steps per Second: 22,538.33326
Overall Steps per Second: 15,764.55475

Timestep Collection Time: 2.21924
Timestep Consumption Time: 0.95357
PPO Batch Consumption Time: 0.12334
Total Iteration Time: 3.17281

Cumulative Model Updates: 13,009
Cumulative Timesteps: 217,171,728

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,922.96839
Policy Entropy: 0.51583
Value Function Loss: 0.15389

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03824
Policy Update Magnitude: 0.01991
Value Function Update Magnitude: 0.02282

Collected Steps per Second: 22,431.01997
Overall Steps per Second: 16,608.25401

Timestep Collection Time: 2.23004
Timestep Consumption Time: 0.78184
PPO Batch Consumption Time: 0.05940
Total Iteration Time: 3.01188

Cumulative Model Updates: 13,012
Cumulative Timesteps: 217,221,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 217221750...
Checkpoint 217221750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,760.10424
Policy Entropy: 0.52171
Value Function Loss: 0.14846

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06729
Policy Update Magnitude: 0.01825
Value Function Update Magnitude: 0.02411

Collected Steps per Second: 20,035.01482
Overall Steps per Second: 14,791.68403

Timestep Collection Time: 2.49723
Timestep Consumption Time: 0.88521
PPO Batch Consumption Time: 0.09743
Total Iteration Time: 3.38244

Cumulative Model Updates: 13,015
Cumulative Timesteps: 217,271,782

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,316.70186
Policy Entropy: 0.52288
Value Function Loss: 0.12187

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04876
Policy Update Magnitude: 0.01528
Value Function Update Magnitude: 0.01946

Collected Steps per Second: 23,189.07891
Overall Steps per Second: 16,602.46580

Timestep Collection Time: 2.15653
Timestep Consumption Time: 0.85555
PPO Batch Consumption Time: 0.07617
Total Iteration Time: 3.01208

Cumulative Model Updates: 13,018
Cumulative Timesteps: 217,321,790

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 217321790...
Checkpoint 217321790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,740.43933
Policy Entropy: 0.52211
Value Function Loss: 0.12083

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.04081
Policy Update Magnitude: 0.01700
Value Function Update Magnitude: 0.01853

Collected Steps per Second: 22,713.22159
Overall Steps per Second: 16,698.33419

Timestep Collection Time: 2.20154
Timestep Consumption Time: 0.79301
PPO Batch Consumption Time: 0.05869
Total Iteration Time: 2.99455

Cumulative Model Updates: 13,021
Cumulative Timesteps: 217,371,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,670.77041
Policy Entropy: 0.51493
Value Function Loss: 0.12577

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02677
Policy Update Magnitude: 0.01731
Value Function Update Magnitude: 0.01887

Collected Steps per Second: 19,510.08587
Overall Steps per Second: 14,058.26235

Timestep Collection Time: 2.56431
Timestep Consumption Time: 0.99445
PPO Batch Consumption Time: 0.11458
Total Iteration Time: 3.55876

Cumulative Model Updates: 13,024
Cumulative Timesteps: 217,421,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 217421824...
Checkpoint 217421824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,286.71689
Policy Entropy: 0.51777
Value Function Loss: 0.11924

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03191
Policy Update Magnitude: 0.01674
Value Function Update Magnitude: 0.02033

Collected Steps per Second: 23,065.58473
Overall Steps per Second: 15,814.55654

Timestep Collection Time: 2.16834
Timestep Consumption Time: 0.99419
PPO Batch Consumption Time: 0.11966
Total Iteration Time: 3.16253

Cumulative Model Updates: 13,027
Cumulative Timesteps: 217,471,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,313.45587
Policy Entropy: 0.51739
Value Function Loss: 0.12516

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02831
Policy Update Magnitude: 0.01623
Value Function Update Magnitude: 0.02079

Collected Steps per Second: 23,618.15986
Overall Steps per Second: 17,121.70149

Timestep Collection Time: 2.11769
Timestep Consumption Time: 0.80351
PPO Batch Consumption Time: 0.06116
Total Iteration Time: 2.92120

Cumulative Model Updates: 13,030
Cumulative Timesteps: 217,521,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 217521854...
Checkpoint 217521854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,952.58905
Policy Entropy: 0.52476
Value Function Loss: 0.10843

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01218
Policy Update Magnitude: 0.01717
Value Function Update Magnitude: 0.01881

Collected Steps per Second: 22,577.62344
Overall Steps per Second: 16,448.12181

Timestep Collection Time: 2.21706
Timestep Consumption Time: 0.82620
PPO Batch Consumption Time: 0.06220
Total Iteration Time: 3.04327

Cumulative Model Updates: 13,033
Cumulative Timesteps: 217,571,910

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,330.69045
Policy Entropy: 0.52588
Value Function Loss: 0.10858

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01271
Policy Update Magnitude: 0.01573
Value Function Update Magnitude: 0.01786

Collected Steps per Second: 23,098.59902
Overall Steps per Second: 16,812.77682

Timestep Collection Time: 2.16550
Timestep Consumption Time: 0.80962
PPO Batch Consumption Time: 0.06428
Total Iteration Time: 2.97512

Cumulative Model Updates: 13,036
Cumulative Timesteps: 217,621,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 217621930...
Checkpoint 217621930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,380.98120
Policy Entropy: 0.51859
Value Function Loss: 0.13747

Mean KL Divergence: 0.00108
SB3 Clip Fraction: 0.00786
Policy Update Magnitude: 0.01876
Value Function Update Magnitude: 0.02199

Collected Steps per Second: 23,033.58758
Overall Steps per Second: 16,721.74730

Timestep Collection Time: 2.17178
Timestep Consumption Time: 0.81977
PPO Batch Consumption Time: 0.06440
Total Iteration Time: 2.99155

Cumulative Model Updates: 13,039
Cumulative Timesteps: 217,671,954

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,123.00743
Policy Entropy: 0.51757
Value Function Loss: 0.14587

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.01286
Policy Update Magnitude: 0.02082
Value Function Update Magnitude: 0.03319

Collected Steps per Second: 22,010.53692
Overall Steps per Second: 15,591.58601

Timestep Collection Time: 2.27182
Timestep Consumption Time: 0.93529
PPO Batch Consumption Time: 0.09377
Total Iteration Time: 3.20711

Cumulative Model Updates: 13,042
Cumulative Timesteps: 217,721,958

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 217721958...
Checkpoint 217721958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,947.69583
Policy Entropy: 0.51446
Value Function Loss: 0.14672

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01925
Policy Update Magnitude: 0.02309
Value Function Update Magnitude: 0.03416

Collected Steps per Second: 17,935.64042
Overall Steps per Second: 14,247.28524

Timestep Collection Time: 2.78830
Timestep Consumption Time: 0.72184
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 3.51014

Cumulative Model Updates: 13,045
Cumulative Timesteps: 217,771,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,023.91961
Policy Entropy: 0.52023
Value Function Loss: 0.12522

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01849
Policy Update Magnitude: 0.02247
Value Function Update Magnitude: 0.02921

Collected Steps per Second: 21,541.39201
Overall Steps per Second: 16,087.14638

Timestep Collection Time: 2.32223
Timestep Consumption Time: 0.78734
PPO Batch Consumption Time: 0.07581
Total Iteration Time: 3.10956

Cumulative Model Updates: 13,048
Cumulative Timesteps: 217,821,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 217821992...
Checkpoint 217821992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,382.07317
Policy Entropy: 0.51829
Value Function Loss: 0.12097

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03758
Policy Update Magnitude: 0.01971
Value Function Update Magnitude: 0.02539

Collected Steps per Second: 22,132.99478
Overall Steps per Second: 16,762.77492

Timestep Collection Time: 2.25907
Timestep Consumption Time: 0.72373
PPO Batch Consumption Time: 0.05848
Total Iteration Time: 2.98280

Cumulative Model Updates: 13,051
Cumulative Timesteps: 217,871,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,539.15882
Policy Entropy: 0.51340
Value Function Loss: 0.13477

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02712
Policy Update Magnitude: 0.01825
Value Function Update Magnitude: 0.02529

Collected Steps per Second: 20,000.91811
Overall Steps per Second: 14,761.29280

Timestep Collection Time: 2.50079
Timestep Consumption Time: 0.88767
PPO Batch Consumption Time: 0.08150
Total Iteration Time: 3.38846

Cumulative Model Updates: 13,054
Cumulative Timesteps: 217,922,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 217922010...
Checkpoint 217922010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,009.96159
Policy Entropy: 0.51243
Value Function Loss: 0.14313

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02809
Policy Update Magnitude: 0.01777
Value Function Update Magnitude: 0.02346

Collected Steps per Second: 22,267.28187
Overall Steps per Second: 16,400.33170

Timestep Collection Time: 2.24724
Timestep Consumption Time: 0.80391
PPO Batch Consumption Time: 0.06388
Total Iteration Time: 3.05116

Cumulative Model Updates: 13,057
Cumulative Timesteps: 217,972,050

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,425.29804
Policy Entropy: 0.51522
Value Function Loss: 0.14839

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03780
Policy Update Magnitude: 0.01760
Value Function Update Magnitude: 0.02472

Collected Steps per Second: 20,745.55779
Overall Steps per Second: 15,084.78603

Timestep Collection Time: 2.41131
Timestep Consumption Time: 0.90488
PPO Batch Consumption Time: 0.09818
Total Iteration Time: 3.31619

Cumulative Model Updates: 13,060
Cumulative Timesteps: 218,022,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 218022074...
Checkpoint 218022074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,446.75820
Policy Entropy: 0.52403
Value Function Loss: 0.13641

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03141
Policy Update Magnitude: 0.01681
Value Function Update Magnitude: 0.02686

Collected Steps per Second: 22,658.87951
Overall Steps per Second: 15,770.95526

Timestep Collection Time: 2.20779
Timestep Consumption Time: 0.96425
PPO Batch Consumption Time: 0.11179
Total Iteration Time: 3.17203

Cumulative Model Updates: 13,063
Cumulative Timesteps: 218,072,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,714.00713
Policy Entropy: 0.52388
Value Function Loss: 0.10816

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.03137
Policy Update Magnitude: 0.01597
Value Function Update Magnitude: 0.02459

Collected Steps per Second: 23,079.21189
Overall Steps per Second: 16,823.53869

Timestep Collection Time: 2.16706
Timestep Consumption Time: 0.80580
PPO Batch Consumption Time: 0.06334
Total Iteration Time: 2.97286

Cumulative Model Updates: 13,066
Cumulative Timesteps: 218,122,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 218122114...
Checkpoint 218122114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,798.98504
Policy Entropy: 0.52127
Value Function Loss: 0.10817

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.01438
Value Function Update Magnitude: 0.02220

Collected Steps per Second: 20,695.92178
Overall Steps per Second: 14,699.88100

Timestep Collection Time: 2.41719
Timestep Consumption Time: 0.98597
PPO Batch Consumption Time: 0.11641
Total Iteration Time: 3.40316

Cumulative Model Updates: 13,069
Cumulative Timesteps: 218,172,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,912.38034
Policy Entropy: 0.51720
Value Function Loss: 0.10165

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.02032
Policy Update Magnitude: 0.01545
Value Function Update Magnitude: 0.02045

Collected Steps per Second: 23,171.03727
Overall Steps per Second: 16,369.90769

Timestep Collection Time: 2.15916
Timestep Consumption Time: 0.89706
PPO Batch Consumption Time: 0.08469
Total Iteration Time: 3.05622

Cumulative Model Updates: 13,072
Cumulative Timesteps: 218,222,170

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 218222170...
Checkpoint 218222170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,291.31231
Policy Entropy: 0.51328
Value Function Loss: 0.11368

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.01690
Value Function Update Magnitude: 0.01856

Collected Steps per Second: 21,304.06189
Overall Steps per Second: 15,630.40043

Timestep Collection Time: 2.34819
Timestep Consumption Time: 0.85237
PPO Batch Consumption Time: 0.07003
Total Iteration Time: 3.20056

Cumulative Model Updates: 13,075
Cumulative Timesteps: 218,272,196

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,816.87332
Policy Entropy: 0.51022
Value Function Loss: 0.12368

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03709
Policy Update Magnitude: 0.01557
Value Function Update Magnitude: 0.01976

Collected Steps per Second: 24,203.34368
Overall Steps per Second: 18,316.60637

Timestep Collection Time: 2.06765
Timestep Consumption Time: 0.66452
PPO Batch Consumption Time: 0.02882
Total Iteration Time: 2.73217

Cumulative Model Updates: 13,078
Cumulative Timesteps: 218,322,240

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 218322240...
Checkpoint 218322240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,563.50186
Policy Entropy: 0.51062
Value Function Loss: 0.13288

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02989
Policy Update Magnitude: 0.01474
Value Function Update Magnitude: 0.02020

Collected Steps per Second: 22,782.03936
Overall Steps per Second: 15,886.83879

Timestep Collection Time: 2.19497
Timestep Consumption Time: 0.95266
PPO Batch Consumption Time: 0.11235
Total Iteration Time: 3.14764

Cumulative Model Updates: 13,081
Cumulative Timesteps: 218,372,246

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,517.60483
Policy Entropy: 0.50940
Value Function Loss: 0.12888

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02237
Policy Update Magnitude: 0.01647
Value Function Update Magnitude: 0.01946

Collected Steps per Second: 23,137.69472
Overall Steps per Second: 17,390.67916

Timestep Collection Time: 2.16193
Timestep Consumption Time: 0.71444
PPO Batch Consumption Time: 0.05834
Total Iteration Time: 2.87637

Cumulative Model Updates: 13,084
Cumulative Timesteps: 218,422,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 218422268...
Checkpoint 218422268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,793.59922
Policy Entropy: 0.51110
Value Function Loss: 0.11871

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01622
Policy Update Magnitude: 0.01610
Value Function Update Magnitude: 0.02210

Collected Steps per Second: 21,229.66021
Overall Steps per Second: 16,021.65479

Timestep Collection Time: 2.35651
Timestep Consumption Time: 0.76601
PPO Batch Consumption Time: 0.07819
Total Iteration Time: 3.12252

Cumulative Model Updates: 13,087
Cumulative Timesteps: 218,472,296

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,155.50259
Policy Entropy: 0.50812
Value Function Loss: 0.11780

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02388
Policy Update Magnitude: 0.01604
Value Function Update Magnitude: 0.01742

Collected Steps per Second: 23,833.31642
Overall Steps per Second: 17,853.90838

Timestep Collection Time: 2.09849
Timestep Consumption Time: 0.70280
PPO Batch Consumption Time: 0.05860
Total Iteration Time: 2.80129

Cumulative Model Updates: 13,090
Cumulative Timesteps: 218,522,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 218522310...
Checkpoint 218522310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,767.87971
Policy Entropy: 0.50836
Value Function Loss: 0.12054

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02386
Policy Update Magnitude: 0.01810
Value Function Update Magnitude: 0.02062

Collected Steps per Second: 20,714.22145
Overall Steps per Second: 14,931.67820

Timestep Collection Time: 2.41419
Timestep Consumption Time: 0.93493
PPO Batch Consumption Time: 0.11265
Total Iteration Time: 3.34912

Cumulative Model Updates: 13,093
Cumulative Timesteps: 218,572,318

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,719.75231
Policy Entropy: 0.51009
Value Function Loss: 0.12467

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.02024
Value Function Update Magnitude: 0.02080

Collected Steps per Second: 24,573.13391
Overall Steps per Second: 17,886.07287

Timestep Collection Time: 2.03556
Timestep Consumption Time: 0.76103
PPO Batch Consumption Time: 0.06103
Total Iteration Time: 2.79659

Cumulative Model Updates: 13,096
Cumulative Timesteps: 218,622,338

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 218622338...
Checkpoint 218622338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,012.03164
Policy Entropy: 0.51117
Value Function Loss: 0.11729

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01523
Policy Update Magnitude: 0.01747
Value Function Update Magnitude: 0.02261

Collected Steps per Second: 21,252.17246
Overall Steps per Second: 15,631.59397

Timestep Collection Time: 2.35327
Timestep Consumption Time: 0.84615
PPO Batch Consumption Time: 0.07935
Total Iteration Time: 3.19942

Cumulative Model Updates: 13,099
Cumulative Timesteps: 218,672,350

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,448.83353
Policy Entropy: 0.50928
Value Function Loss: 0.11981

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01269
Policy Update Magnitude: 0.01728
Value Function Update Magnitude: 0.02094

Collected Steps per Second: 24,238.74862
Overall Steps per Second: 17,416.27951

Timestep Collection Time: 2.06372
Timestep Consumption Time: 0.80842
PPO Batch Consumption Time: 0.06239
Total Iteration Time: 2.87214

Cumulative Model Updates: 13,102
Cumulative Timesteps: 218,722,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 218722372...
Checkpoint 218722372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,369.64531
Policy Entropy: 0.50824
Value Function Loss: 0.11033

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.00736
Policy Update Magnitude: 0.01777
Value Function Update Magnitude: 0.02233

Collected Steps per Second: 22,287.92206
Overall Steps per Second: 16,125.78577

Timestep Collection Time: 2.24337
Timestep Consumption Time: 0.85726
PPO Batch Consumption Time: 0.08002
Total Iteration Time: 3.10062

Cumulative Model Updates: 13,105
Cumulative Timesteps: 218,772,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,913.67372
Policy Entropy: 0.51191
Value Function Loss: 0.11069

Mean KL Divergence: 0.00121
SB3 Clip Fraction: 0.00948
Policy Update Magnitude: 0.01704
Value Function Update Magnitude: 0.01976

Collected Steps per Second: 24,025.61836
Overall Steps per Second: 17,223.55958

Timestep Collection Time: 2.08244
Timestep Consumption Time: 0.82241
PPO Batch Consumption Time: 0.06453
Total Iteration Time: 2.90486

Cumulative Model Updates: 13,108
Cumulative Timesteps: 218,822,404

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 218822404...
Checkpoint 218822404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,722.93518
Policy Entropy: 0.51620
Value Function Loss: 0.10834

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.01051
Policy Update Magnitude: 0.01797
Value Function Update Magnitude: 0.02117

Collected Steps per Second: 23,725.15473
Overall Steps per Second: 16,390.82028

Timestep Collection Time: 2.10848
Timestep Consumption Time: 0.94347
PPO Batch Consumption Time: 0.11108
Total Iteration Time: 3.05195

Cumulative Model Updates: 13,111
Cumulative Timesteps: 218,872,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,043.62477
Policy Entropy: 0.51930
Value Function Loss: 0.10492

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.01265
Policy Update Magnitude: 0.01603
Value Function Update Magnitude: 0.02148

Collected Steps per Second: 24,487.17521
Overall Steps per Second: 17,601.91801

Timestep Collection Time: 2.04213
Timestep Consumption Time: 0.79881
PPO Batch Consumption Time: 0.06047
Total Iteration Time: 2.84094

Cumulative Model Updates: 13,114
Cumulative Timesteps: 218,922,434

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 218922434...
Checkpoint 218922434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,499.00775
Policy Entropy: 0.52130
Value Function Loss: 0.11175

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.00798
Policy Update Magnitude: 0.01569
Value Function Update Magnitude: 0.01970

Collected Steps per Second: 21,543.80652
Overall Steps per Second: 15,024.81257

Timestep Collection Time: 2.32132
Timestep Consumption Time: 1.00718
PPO Batch Consumption Time: 0.12677
Total Iteration Time: 3.32849

Cumulative Model Updates: 13,117
Cumulative Timesteps: 218,972,444

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,437.12294
Policy Entropy: 0.52178
Value Function Loss: 0.10755

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01454
Policy Update Magnitude: 0.01641
Value Function Update Magnitude: 0.01924

Collected Steps per Second: 24,487.16233
Overall Steps per Second: 16,681.15355

Timestep Collection Time: 2.04238
Timestep Consumption Time: 0.95574
PPO Batch Consumption Time: 0.11141
Total Iteration Time: 2.99811

Cumulative Model Updates: 13,120
Cumulative Timesteps: 219,022,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 219022456...
Checkpoint 219022456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,477.58096
Policy Entropy: 0.51921
Value Function Loss: 0.11691

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.01548
Value Function Update Magnitude: 0.01939

Collected Steps per Second: 23,510.68769
Overall Steps per Second: 16,754.34351

Timestep Collection Time: 2.12686
Timestep Consumption Time: 0.85768
PPO Batch Consumption Time: 0.10373
Total Iteration Time: 2.98454

Cumulative Model Updates: 13,123
Cumulative Timesteps: 219,072,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,842.38967
Policy Entropy: 0.51623
Value Function Loss: 0.10153

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02669
Policy Update Magnitude: 0.01532
Value Function Update Magnitude: 0.01815

Collected Steps per Second: 23,435.25278
Overall Steps per Second: 16,727.27068

Timestep Collection Time: 2.13354
Timestep Consumption Time: 0.85559
PPO Batch Consumption Time: 0.10631
Total Iteration Time: 2.98913

Cumulative Model Updates: 13,126
Cumulative Timesteps: 219,122,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 219122460...
Checkpoint 219122460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,865.87938
Policy Entropy: 0.51987
Value Function Loss: 0.10814

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.01486
Value Function Update Magnitude: 0.01844

Collected Steps per Second: 23,191.59113
Overall Steps per Second: 16,678.11348

Timestep Collection Time: 2.15699
Timestep Consumption Time: 0.84239
PPO Batch Consumption Time: 0.10120
Total Iteration Time: 2.99938

Cumulative Model Updates: 13,129
Cumulative Timesteps: 219,172,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,725.72785
Policy Entropy: 0.51541
Value Function Loss: 0.10710

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02159
Policy Update Magnitude: 0.01481
Value Function Update Magnitude: 0.01780

Collected Steps per Second: 23,717.45359
Overall Steps per Second: 16,704.16370

Timestep Collection Time: 2.10874
Timestep Consumption Time: 0.88536
PPO Batch Consumption Time: 0.09494
Total Iteration Time: 2.99410

Cumulative Model Updates: 13,132
Cumulative Timesteps: 219,222,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 219222498...
Checkpoint 219222498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,990.30192
Policy Entropy: 0.51360
Value Function Loss: 0.12845

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01822
Policy Update Magnitude: 0.01557
Value Function Update Magnitude: 0.01780

Collected Steps per Second: 24,208.13674
Overall Steps per Second: 16,814.06285

Timestep Collection Time: 2.06616
Timestep Consumption Time: 0.90861
PPO Batch Consumption Time: 0.10328
Total Iteration Time: 2.97477

Cumulative Model Updates: 13,135
Cumulative Timesteps: 219,272,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,906.95333
Policy Entropy: 0.51002
Value Function Loss: 0.12561

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01978
Policy Update Magnitude: 0.01622
Value Function Update Magnitude: 0.01965

Collected Steps per Second: 24,366.45939
Overall Steps per Second: 16,767.44145

Timestep Collection Time: 2.05340
Timestep Consumption Time: 0.93060
PPO Batch Consumption Time: 0.11939
Total Iteration Time: 2.98400

Cumulative Model Updates: 13,138
Cumulative Timesteps: 219,322,550

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 219322550...
Checkpoint 219322550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,951.08408
Policy Entropy: 0.51650
Value Function Loss: 0.11779

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02827
Policy Update Magnitude: 0.01584
Value Function Update Magnitude: 0.02053

Collected Steps per Second: 22,917.44195
Overall Steps per Second: 16,601.03266

Timestep Collection Time: 2.18253
Timestep Consumption Time: 0.83042
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 3.01295

Cumulative Model Updates: 13,141
Cumulative Timesteps: 219,372,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,519.23346
Policy Entropy: 0.51407
Value Function Loss: 0.11857

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03493
Policy Update Magnitude: 0.01642
Value Function Update Magnitude: 0.02048

Collected Steps per Second: 20,144.59590
Overall Steps per Second: 15,694.31584

Timestep Collection Time: 2.48345
Timestep Consumption Time: 0.70421
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 3.18765

Cumulative Model Updates: 13,144
Cumulative Timesteps: 219,422,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 219422596...
Checkpoint 219422596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,945.41822
Policy Entropy: 0.51898
Value Function Loss: 0.12102

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04863
Policy Update Magnitude: 0.01604
Value Function Update Magnitude: 0.01853

Collected Steps per Second: 21,305.94900
Overall Steps per Second: 15,447.09962

Timestep Collection Time: 2.34676
Timestep Consumption Time: 0.89009
PPO Batch Consumption Time: 0.07891
Total Iteration Time: 3.23685

Cumulative Model Updates: 13,147
Cumulative Timesteps: 219,472,596

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,584.76538
Policy Entropy: 0.51001
Value Function Loss: 0.13254

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.04517
Policy Update Magnitude: 0.01812
Value Function Update Magnitude: 0.02250

Collected Steps per Second: 21,832.51149
Overall Steps per Second: 15,041.03658

Timestep Collection Time: 2.29099
Timestep Consumption Time: 1.03445
PPO Batch Consumption Time: 0.12593
Total Iteration Time: 3.32544

Cumulative Model Updates: 13,150
Cumulative Timesteps: 219,522,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 219522614...
Checkpoint 219522614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,477.49214
Policy Entropy: 0.52013
Value Function Loss: 0.11971

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.07132
Policy Update Magnitude: 0.01952
Value Function Update Magnitude: 0.02151

Collected Steps per Second: 23,152.88673
Overall Steps per Second: 16,957.99294

Timestep Collection Time: 2.16016
Timestep Consumption Time: 0.78913
PPO Batch Consumption Time: 0.06126
Total Iteration Time: 2.94929

Cumulative Model Updates: 13,153
Cumulative Timesteps: 219,572,628

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,477.49214
Policy Entropy: 0.51154
Value Function Loss: 0.11623

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06808
Policy Update Magnitude: 0.01539
Value Function Update Magnitude: 0.02048

Collected Steps per Second: 23,521.87852
Overall Steps per Second: 16,996.42478

Timestep Collection Time: 2.12704
Timestep Consumption Time: 0.81664
PPO Batch Consumption Time: 0.06467
Total Iteration Time: 2.94368

Cumulative Model Updates: 13,156
Cumulative Timesteps: 219,622,660

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 219622660...
Checkpoint 219622660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,147.92419
Policy Entropy: 0.51393
Value Function Loss: 0.11350

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05471
Policy Update Magnitude: 0.01511
Value Function Update Magnitude: 0.02186

Collected Steps per Second: 23,079.55483
Overall Steps per Second: 16,770.70367

Timestep Collection Time: 2.16703
Timestep Consumption Time: 0.81520
PPO Batch Consumption Time: 0.06501
Total Iteration Time: 2.98222

Cumulative Model Updates: 13,159
Cumulative Timesteps: 219,672,674

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,578.17376
Policy Entropy: 0.51272
Value Function Loss: 0.11925

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05870
Policy Update Magnitude: 0.01648
Value Function Update Magnitude: 0.01941

Collected Steps per Second: 23,020.51705
Overall Steps per Second: 16,715.25458

Timestep Collection Time: 2.17215
Timestep Consumption Time: 0.81937
PPO Batch Consumption Time: 0.06456
Total Iteration Time: 2.99152

Cumulative Model Updates: 13,162
Cumulative Timesteps: 219,722,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 219722678...
Checkpoint 219722678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,091.80756
Policy Entropy: 0.51957
Value Function Loss: 0.11456

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03987
Policy Update Magnitude: 0.01553
Value Function Update Magnitude: 0.02099

Collected Steps per Second: 23,444.12530
Overall Steps per Second: 16,974.07413

Timestep Collection Time: 2.13316
Timestep Consumption Time: 0.81310
PPO Batch Consumption Time: 0.06372
Total Iteration Time: 2.94626

Cumulative Model Updates: 13,165
Cumulative Timesteps: 219,772,688

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,830.48349
Policy Entropy: 0.51506
Value Function Loss: 0.11395

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03516
Policy Update Magnitude: 0.01603
Value Function Update Magnitude: 0.02193

Collected Steps per Second: 19,740.13559
Overall Steps per Second: 14,073.76862

Timestep Collection Time: 2.53311
Timestep Consumption Time: 1.01988
PPO Batch Consumption Time: 0.10853
Total Iteration Time: 3.55299

Cumulative Model Updates: 13,168
Cumulative Timesteps: 219,822,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 219822692...
Checkpoint 219822692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,630.45384
Policy Entropy: 0.51705
Value Function Loss: 0.10815

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02859
Policy Update Magnitude: 0.01621
Value Function Update Magnitude: 0.02166

Collected Steps per Second: 22,694.09014
Overall Steps per Second: 16,643.95771

Timestep Collection Time: 2.20392
Timestep Consumption Time: 0.80113
PPO Batch Consumption Time: 0.06318
Total Iteration Time: 3.00505

Cumulative Model Updates: 13,171
Cumulative Timesteps: 219,872,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,075.82748
Policy Entropy: 0.51394
Value Function Loss: 0.11789

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01977
Policy Update Magnitude: 0.01744
Value Function Update Magnitude: 0.02487

Collected Steps per Second: 20,342.29257
Overall Steps per Second: 14,112.93253

Timestep Collection Time: 2.45803
Timestep Consumption Time: 1.08496
PPO Batch Consumption Time: 0.13463
Total Iteration Time: 3.54299

Cumulative Model Updates: 13,174
Cumulative Timesteps: 219,922,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 219922710...
Checkpoint 219922710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,102.03488
Policy Entropy: 0.52040
Value Function Loss: 0.10685

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02934
Policy Update Magnitude: 0.01782
Value Function Update Magnitude: 0.02713

Collected Steps per Second: 22,817.39021
Overall Steps per Second: 16,786.78186

Timestep Collection Time: 2.19201
Timestep Consumption Time: 0.78747
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 2.97949

Cumulative Model Updates: 13,177
Cumulative Timesteps: 219,972,726

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,142.30189
Policy Entropy: 0.51641
Value Function Loss: 0.11105

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03563
Policy Update Magnitude: 0.01930
Value Function Update Magnitude: 0.02805

Collected Steps per Second: 20,241.24200
Overall Steps per Second: 14,611.06512

Timestep Collection Time: 2.47080
Timestep Consumption Time: 0.95209
PPO Batch Consumption Time: 0.10055
Total Iteration Time: 3.42289

Cumulative Model Updates: 13,180
Cumulative Timesteps: 220,022,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 220022738...
Checkpoint 220022738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,993.97170
Policy Entropy: 0.51970
Value Function Loss: 0.10428

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03314
Policy Update Magnitude: 0.01867
Value Function Update Magnitude: 0.02403

Collected Steps per Second: 16,985.45871
Overall Steps per Second: 13,398.48952

Timestep Collection Time: 2.94464
Timestep Consumption Time: 0.78832
PPO Batch Consumption Time: 0.06682
Total Iteration Time: 3.73296

Cumulative Model Updates: 13,183
Cumulative Timesteps: 220,072,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,938.58757
Policy Entropy: 0.51899
Value Function Loss: 0.11230

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02441
Policy Update Magnitude: 0.01732
Value Function Update Magnitude: 0.02053

Collected Steps per Second: 20,814.82090
Overall Steps per Second: 15,548.94357

Timestep Collection Time: 2.40233
Timestep Consumption Time: 0.81358
PPO Batch Consumption Time: 0.08436
Total Iteration Time: 3.21591

Cumulative Model Updates: 13,186
Cumulative Timesteps: 220,122,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 220122758...
Checkpoint 220122758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,296.97358
Policy Entropy: 0.52167
Value Function Loss: 0.10394

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02764
Policy Update Magnitude: 0.01960
Value Function Update Magnitude: 0.01790

Collected Steps per Second: 22,164.01629
Overall Steps per Second: 16,854.14627

Timestep Collection Time: 2.25708
Timestep Consumption Time: 0.71109
PPO Batch Consumption Time: 0.05818
Total Iteration Time: 2.96817

Cumulative Model Updates: 13,189
Cumulative Timesteps: 220,172,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,311.14625
Policy Entropy: 0.52226
Value Function Loss: 0.11136

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02128
Policy Update Magnitude: 0.02032
Value Function Update Magnitude: 0.02039

Collected Steps per Second: 20,310.98521
Overall Steps per Second: 14,692.50596

Timestep Collection Time: 2.46281
Timestep Consumption Time: 0.94179
PPO Batch Consumption Time: 0.09736
Total Iteration Time: 3.40459

Cumulative Model Updates: 13,192
Cumulative Timesteps: 220,222,806

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 220222806...
Checkpoint 220222806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,466.01291
Policy Entropy: 0.52156
Value Function Loss: 0.10652

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03040
Policy Update Magnitude: 0.02066
Value Function Update Magnitude: 0.01697

Collected Steps per Second: 22,758.73382
Overall Steps per Second: 15,778.31312

Timestep Collection Time: 2.19889
Timestep Consumption Time: 0.97280
PPO Batch Consumption Time: 0.12043
Total Iteration Time: 3.17170

Cumulative Model Updates: 13,195
Cumulative Timesteps: 220,272,850

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,557.05971
Policy Entropy: 0.52339
Value Function Loss: 0.10659

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04497
Policy Update Magnitude: 0.01840
Value Function Update Magnitude: 0.02034

Collected Steps per Second: 23,436.90733
Overall Steps per Second: 17,204.62685

Timestep Collection Time: 2.13416
Timestep Consumption Time: 0.77309
PPO Batch Consumption Time: 0.06192
Total Iteration Time: 2.90724

Cumulative Model Updates: 13,198
Cumulative Timesteps: 220,322,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 220322868...
Checkpoint 220322868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,646.49205
Policy Entropy: 0.52860
Value Function Loss: 0.10841

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04605
Policy Update Magnitude: 0.01770
Value Function Update Magnitude: 0.01828

Collected Steps per Second: 23,206.00739
Overall Steps per Second: 16,601.43741

Timestep Collection Time: 2.15461
Timestep Consumption Time: 0.85717
PPO Batch Consumption Time: 0.07083
Total Iteration Time: 3.01179

Cumulative Model Updates: 13,201
Cumulative Timesteps: 220,372,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,041.87658
Policy Entropy: 0.52396
Value Function Loss: 0.11932

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04889
Policy Update Magnitude: 0.01770
Value Function Update Magnitude: 0.02447

Collected Steps per Second: 23,279.89005
Overall Steps per Second: 16,592.58811

Timestep Collection Time: 2.14881
Timestep Consumption Time: 0.86603
PPO Batch Consumption Time: 0.07643
Total Iteration Time: 3.01484

Cumulative Model Updates: 13,204
Cumulative Timesteps: 220,422,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 220422892...
Checkpoint 220422892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,640.86116
Policy Entropy: 0.52286
Value Function Loss: 0.12657

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.06347
Policy Update Magnitude: 0.01749
Value Function Update Magnitude: 0.02272

Collected Steps per Second: 22,697.50321
Overall Steps per Second: 16,235.78185

Timestep Collection Time: 2.20421
Timestep Consumption Time: 0.87726
PPO Batch Consumption Time: 0.06355
Total Iteration Time: 3.08147

Cumulative Model Updates: 13,207
Cumulative Timesteps: 220,472,922

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,685.21250
Policy Entropy: 0.52118
Value Function Loss: 0.11701

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.05273
Policy Update Magnitude: 0.01821
Value Function Update Magnitude: 0.02109

Collected Steps per Second: 20,606.78453
Overall Steps per Second: 14,994.23717

Timestep Collection Time: 2.42736
Timestep Consumption Time: 0.90859
PPO Batch Consumption Time: 0.09412
Total Iteration Time: 3.33595

Cumulative Model Updates: 13,210
Cumulative Timesteps: 220,522,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 220522942...
Checkpoint 220522942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,829.26464
Policy Entropy: 0.51957
Value Function Loss: 0.11685

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04956
Policy Update Magnitude: 0.01751
Value Function Update Magnitude: 0.02199

Collected Steps per Second: 22,968.08763
Overall Steps per Second: 15,822.90894

Timestep Collection Time: 2.17780
Timestep Consumption Time: 0.98343
PPO Batch Consumption Time: 0.12168
Total Iteration Time: 3.16124

Cumulative Model Updates: 13,213
Cumulative Timesteps: 220,572,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,572.90620
Policy Entropy: 0.51816
Value Function Loss: 0.11586

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04610
Policy Update Magnitude: 0.01679
Value Function Update Magnitude: 0.02176

Collected Steps per Second: 23,753.61110
Overall Steps per Second: 17,302.77345

Timestep Collection Time: 2.10528
Timestep Consumption Time: 0.78489
PPO Batch Consumption Time: 0.06042
Total Iteration Time: 2.89017

Cumulative Model Updates: 13,216
Cumulative Timesteps: 220,622,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 220622970...
Checkpoint 220622970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,763.14893
Policy Entropy: 0.51977
Value Function Loss: 0.11746

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.05373
Policy Update Magnitude: 0.01839
Value Function Update Magnitude: 0.02417

Collected Steps per Second: 20,072.21840
Overall Steps per Second: 15,116.03795

Timestep Collection Time: 2.49130
Timestep Consumption Time: 0.81684
PPO Batch Consumption Time: 0.08613
Total Iteration Time: 3.30814

Cumulative Model Updates: 13,219
Cumulative Timesteps: 220,672,976

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,125.96325
Policy Entropy: 0.51295
Value Function Loss: 0.11364

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04377
Policy Update Magnitude: 0.01680
Value Function Update Magnitude: 0.02421

Collected Steps per Second: 22,480.71236
Overall Steps per Second: 16,873.30550

Timestep Collection Time: 2.22466
Timestep Consumption Time: 0.73931
PPO Batch Consumption Time: 0.06161
Total Iteration Time: 2.96397

Cumulative Model Updates: 13,222
Cumulative Timesteps: 220,722,988

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 220722988...
Checkpoint 220722988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,913.36110
Policy Entropy: 0.51168
Value Function Loss: 0.10948

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04199
Policy Update Magnitude: 0.01621
Value Function Update Magnitude: 0.02270

Collected Steps per Second: 20,236.90732
Overall Steps per Second: 14,750.52797

Timestep Collection Time: 2.47222
Timestep Consumption Time: 0.91953
PPO Batch Consumption Time: 0.11957
Total Iteration Time: 3.39174

Cumulative Model Updates: 13,225
Cumulative Timesteps: 220,773,018

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,425.70041
Policy Entropy: 0.51405
Value Function Loss: 0.10793

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03841
Policy Update Magnitude: 0.01822
Value Function Update Magnitude: 0.02106

Collected Steps per Second: 22,098.20245
Overall Steps per Second: 16,415.72749

Timestep Collection Time: 2.26308
Timestep Consumption Time: 0.78339
PPO Batch Consumption Time: 0.06212
Total Iteration Time: 3.04647

Cumulative Model Updates: 13,228
Cumulative Timesteps: 220,823,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 220823028...
Checkpoint 220823028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,162.59438
Policy Entropy: 0.51496
Value Function Loss: 0.11494

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04485
Policy Update Magnitude: 0.01792
Value Function Update Magnitude: 0.01927

Collected Steps per Second: 20,487.11158
Overall Steps per Second: 14,958.77139

Timestep Collection Time: 2.44066
Timestep Consumption Time: 0.90200
PPO Batch Consumption Time: 0.09607
Total Iteration Time: 3.34265

Cumulative Model Updates: 13,231
Cumulative Timesteps: 220,873,030

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,244.26144
Policy Entropy: 0.51707
Value Function Loss: 0.12070

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04087
Policy Update Magnitude: 0.01788
Value Function Update Magnitude: 0.02288

Collected Steps per Second: 23,202.89264
Overall Steps per Second: 16,671.59746

Timestep Collection Time: 2.15568
Timestep Consumption Time: 0.84451
PPO Batch Consumption Time: 0.07683
Total Iteration Time: 3.00019

Cumulative Model Updates: 13,234
Cumulative Timesteps: 220,923,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 220923048...
Checkpoint 220923048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,129.48528
Policy Entropy: 0.51991
Value Function Loss: 0.11733

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04624
Policy Update Magnitude: 0.01799
Value Function Update Magnitude: 0.02180

Collected Steps per Second: 22,996.62000
Overall Steps per Second: 15,867.93602

Timestep Collection Time: 2.17441
Timestep Consumption Time: 0.97685
PPO Batch Consumption Time: 0.12001
Total Iteration Time: 3.15126

Cumulative Model Updates: 13,237
Cumulative Timesteps: 220,973,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,841.52887
Policy Entropy: 0.52422
Value Function Loss: 0.12038

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03261
Policy Update Magnitude: 0.01828
Value Function Update Magnitude: 0.02390

Collected Steps per Second: 23,562.77086
Overall Steps per Second: 17,083.36314

Timestep Collection Time: 2.12250
Timestep Consumption Time: 0.80503
PPO Batch Consumption Time: 0.06218
Total Iteration Time: 2.92753

Cumulative Model Updates: 13,240
Cumulative Timesteps: 221,023,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 221023064...
Checkpoint 221023064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,713.67814
Policy Entropy: 0.52116
Value Function Loss: 0.11395

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03374
Policy Update Magnitude: 0.01926
Value Function Update Magnitude: 0.02086

Collected Steps per Second: 23,093.26261
Overall Steps per Second: 16,804.05477

Timestep Collection Time: 2.16591
Timestep Consumption Time: 0.81063
PPO Batch Consumption Time: 0.06383
Total Iteration Time: 2.97654

Cumulative Model Updates: 13,243
Cumulative Timesteps: 221,073,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,637.27480
Policy Entropy: 0.51792
Value Function Loss: 0.11942

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02581
Policy Update Magnitude: 0.01876
Value Function Update Magnitude: 0.02201

Collected Steps per Second: 23,410.97394
Overall Steps per Second: 16,966.27887

Timestep Collection Time: 2.13652
Timestep Consumption Time: 0.81156
PPO Batch Consumption Time: 0.06486
Total Iteration Time: 2.94808

Cumulative Model Updates: 13,246
Cumulative Timesteps: 221,123,100

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 221123100...
Checkpoint 221123100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,259.60118
Policy Entropy: 0.51587
Value Function Loss: 0.11428

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02370
Policy Update Magnitude: 0.01670
Value Function Update Magnitude: 0.02011

Collected Steps per Second: 20,150.97028
Overall Steps per Second: 14,207.19658

Timestep Collection Time: 2.48147
Timestep Consumption Time: 1.03816
PPO Batch Consumption Time: 0.11169
Total Iteration Time: 3.51962

Cumulative Model Updates: 13,249
Cumulative Timesteps: 221,173,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,666.34238
Policy Entropy: 0.51086
Value Function Loss: 0.12250

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02356
Policy Update Magnitude: 0.01949
Value Function Update Magnitude: 0.02212

Collected Steps per Second: 22,917.25994
Overall Steps per Second: 15,702.98643

Timestep Collection Time: 2.18176
Timestep Consumption Time: 1.00235
PPO Batch Consumption Time: 0.11696
Total Iteration Time: 3.18411

Cumulative Model Updates: 13,252
Cumulative Timesteps: 221,223,104

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 221223104...
Checkpoint 221223104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,376.50318
Policy Entropy: 0.51287
Value Function Loss: 0.12062

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03617
Policy Update Magnitude: 0.01772
Value Function Update Magnitude: 0.02686

Collected Steps per Second: 22,903.01143
Overall Steps per Second: 16,715.26939

Timestep Collection Time: 2.18338
Timestep Consumption Time: 0.80825
PPO Batch Consumption Time: 0.06463
Total Iteration Time: 2.99164

Cumulative Model Updates: 13,255
Cumulative Timesteps: 221,273,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,009.99640
Policy Entropy: 0.51200
Value Function Loss: 0.12218

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02874
Policy Update Magnitude: 0.01599
Value Function Update Magnitude: 0.02935

Collected Steps per Second: 20,613.26292
Overall Steps per Second: 14,761.17507

Timestep Collection Time: 2.42572
Timestep Consumption Time: 0.96168
PPO Batch Consumption Time: 0.11228
Total Iteration Time: 3.38740

Cumulative Model Updates: 13,258
Cumulative Timesteps: 221,323,112

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 221323112...
Checkpoint 221323112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,464.62205
Policy Entropy: 0.51479
Value Function Loss: 0.13104

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03606
Policy Update Magnitude: 0.01754
Value Function Update Magnitude: 0.02773

Collected Steps per Second: 22,789.68345
Overall Steps per Second: 15,661.16962

Timestep Collection Time: 2.19459
Timestep Consumption Time: 0.99891
PPO Batch Consumption Time: 0.10988
Total Iteration Time: 3.19350

Cumulative Model Updates: 13,261
Cumulative Timesteps: 221,373,126

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,677.63792
Policy Entropy: 0.50762
Value Function Loss: 0.13086

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03213
Policy Update Magnitude: 0.01813
Value Function Update Magnitude: 0.02767

Collected Steps per Second: 23,356.54353
Overall Steps per Second: 16,905.42717

Timestep Collection Time: 2.14098
Timestep Consumption Time: 0.81700
PPO Batch Consumption Time: 0.06686
Total Iteration Time: 2.95799

Cumulative Model Updates: 13,264
Cumulative Timesteps: 221,423,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 221423132...
Checkpoint 221423132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,478.29686
Policy Entropy: 0.50964
Value Function Loss: 0.12112

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04387
Policy Update Magnitude: 0.01775
Value Function Update Magnitude: 0.03696

Collected Steps per Second: 22,969.71173
Overall Steps per Second: 16,734.17804

Timestep Collection Time: 2.17800
Timestep Consumption Time: 0.81157
PPO Batch Consumption Time: 0.05988
Total Iteration Time: 2.98957

Cumulative Model Updates: 13,267
Cumulative Timesteps: 221,473,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,485.44329
Policy Entropy: 0.51235
Value Function Loss: 0.11409

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.01779
Value Function Update Magnitude: 0.03046

Collected Steps per Second: 20,337.39878
Overall Steps per Second: 14,606.77620

Timestep Collection Time: 2.45892
Timestep Consumption Time: 0.96470
PPO Batch Consumption Time: 0.10153
Total Iteration Time: 3.42362

Cumulative Model Updates: 13,270
Cumulative Timesteps: 221,523,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 221523168...
Checkpoint 221523168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,201.48016
Policy Entropy: 0.51961
Value Function Loss: 0.10584

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03935
Policy Update Magnitude: 0.01939
Value Function Update Magnitude: 0.02762

Collected Steps per Second: 23,011.07916
Overall Steps per Second: 16,498.96392

Timestep Collection Time: 2.17365
Timestep Consumption Time: 0.85794
PPO Batch Consumption Time: 0.08270
Total Iteration Time: 3.03158

Cumulative Model Updates: 13,273
Cumulative Timesteps: 221,573,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,471.23110
Policy Entropy: 0.52049
Value Function Loss: 0.11652

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.04041
Policy Update Magnitude: 0.01882
Value Function Update Magnitude: 0.03370

Collected Steps per Second: 22,240.97550
Overall Steps per Second: 15,876.94973

Timestep Collection Time: 2.24873
Timestep Consumption Time: 0.90137
PPO Batch Consumption Time: 0.08573
Total Iteration Time: 3.15010

Cumulative Model Updates: 13,276
Cumulative Timesteps: 221,623,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 221623200...
Checkpoint 221623200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,828.84207
Policy Entropy: 0.52390
Value Function Loss: 0.11023

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.01819
Value Function Update Magnitude: 0.03942

Collected Steps per Second: 22,923.35348
Overall Steps per Second: 16,713.87755

Timestep Collection Time: 2.18240
Timestep Consumption Time: 0.81080
PPO Batch Consumption Time: 0.06009
Total Iteration Time: 2.99320

Cumulative Model Updates: 13,279
Cumulative Timesteps: 221,673,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,312.07320
Policy Entropy: 0.51197
Value Function Loss: 0.12847

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03923
Policy Update Magnitude: 0.01885
Value Function Update Magnitude: 0.04098

Collected Steps per Second: 20,431.92065
Overall Steps per Second: 14,821.61306

Timestep Collection Time: 2.44744
Timestep Consumption Time: 0.92641
PPO Batch Consumption Time: 0.10146
Total Iteration Time: 3.37386

Cumulative Model Updates: 13,282
Cumulative Timesteps: 221,723,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 221723234...
Checkpoint 221723234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,920.24760
Policy Entropy: 0.51012
Value Function Loss: 0.13294

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02740
Policy Update Magnitude: 0.01631
Value Function Update Magnitude: 0.03519

Collected Steps per Second: 22,814.32790
Overall Steps per Second: 15,749.11309

Timestep Collection Time: 2.19213
Timestep Consumption Time: 0.98341
PPO Batch Consumption Time: 0.11628
Total Iteration Time: 3.17554

Cumulative Model Updates: 13,285
Cumulative Timesteps: 221,773,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,582.75108
Policy Entropy: 0.50788
Value Function Loss: 0.13638

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.01666
Value Function Update Magnitude: 0.03423

Collected Steps per Second: 21,713.66671
Overall Steps per Second: 16,471.10278

Timestep Collection Time: 2.30362
Timestep Consumption Time: 0.73322
PPO Batch Consumption Time: 0.06265
Total Iteration Time: 3.03683

Cumulative Model Updates: 13,288
Cumulative Timesteps: 221,823,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 221823266...
Checkpoint 221823266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,086.66359
Policy Entropy: 0.51398
Value Function Loss: 0.12270

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01683
Policy Update Magnitude: 0.01795
Value Function Update Magnitude: 0.02909

Collected Steps per Second: 20,201.59661
Overall Steps per Second: 14,934.97667

Timestep Collection Time: 2.47525
Timestep Consumption Time: 0.87286
PPO Batch Consumption Time: 0.10291
Total Iteration Time: 3.34811

Cumulative Model Updates: 13,291
Cumulative Timesteps: 221,873,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,212.85050
Policy Entropy: 0.51395
Value Function Loss: 0.12310

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.01874
Value Function Update Magnitude: 0.02753

Collected Steps per Second: 22,575.92567
Overall Steps per Second: 16,709.95704

Timestep Collection Time: 2.21572
Timestep Consumption Time: 0.77782
PPO Batch Consumption Time: 0.07798
Total Iteration Time: 2.99354

Cumulative Model Updates: 13,294
Cumulative Timesteps: 221,923,292

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 221923292...
Checkpoint 221923292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,434.05676
Policy Entropy: 0.51610
Value Function Loss: 0.12029

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02319
Policy Update Magnitude: 0.01972
Value Function Update Magnitude: 0.02425

Collected Steps per Second: 22,180.18865
Overall Steps per Second: 15,779.61514

Timestep Collection Time: 2.25508
Timestep Consumption Time: 0.91471
PPO Batch Consumption Time: 0.12102
Total Iteration Time: 3.16979

Cumulative Model Updates: 13,297
Cumulative Timesteps: 221,973,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,186.96430
Policy Entropy: 0.50870
Value Function Loss: 0.12253

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01934
Policy Update Magnitude: 0.01997
Value Function Update Magnitude: 0.02351

Collected Steps per Second: 22,538.46299
Overall Steps per Second: 16,713.93237

Timestep Collection Time: 2.21941
Timestep Consumption Time: 0.77343
PPO Batch Consumption Time: 0.06003
Total Iteration Time: 2.99283

Cumulative Model Updates: 13,300
Cumulative Timesteps: 222,023,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 222023332...
Checkpoint 222023332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,579.31859
Policy Entropy: 0.51197
Value Function Loss: 0.11518

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02869
Policy Update Magnitude: 0.01827
Value Function Update Magnitude: 0.02379

Collected Steps per Second: 20,300.32979
Overall Steps per Second: 14,747.23884

Timestep Collection Time: 2.46410
Timestep Consumption Time: 0.92786
PPO Batch Consumption Time: 0.10166
Total Iteration Time: 3.39196

Cumulative Model Updates: 13,303
Cumulative Timesteps: 222,073,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,202.65338
Policy Entropy: 0.50864
Value Function Loss: 0.12027

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01981
Policy Update Magnitude: 0.01716
Value Function Update Magnitude: 0.02323

Collected Steps per Second: 23,254.46125
Overall Steps per Second: 16,701.74554

Timestep Collection Time: 2.15073
Timestep Consumption Time: 0.84381
PPO Batch Consumption Time: 0.07970
Total Iteration Time: 2.99454

Cumulative Model Updates: 13,306
Cumulative Timesteps: 222,123,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 222123368...
Checkpoint 222123368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,929.18946
Policy Entropy: 0.51880
Value Function Loss: 0.11201

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01429
Policy Update Magnitude: 0.01912
Value Function Update Magnitude: 0.02010

Collected Steps per Second: 22,814.39896
Overall Steps per Second: 15,763.82999

Timestep Collection Time: 2.19230
Timestep Consumption Time: 0.98053
PPO Batch Consumption Time: 0.11208
Total Iteration Time: 3.17283

Cumulative Model Updates: 13,309
Cumulative Timesteps: 222,173,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,824.99146
Policy Entropy: 0.52126
Value Function Loss: 0.10799

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02158
Policy Update Magnitude: 0.01686
Value Function Update Magnitude: 0.01971

Collected Steps per Second: 23,285.49498
Overall Steps per Second: 16,888.66823

Timestep Collection Time: 2.14803
Timestep Consumption Time: 0.81360
PPO Batch Consumption Time: 0.06321
Total Iteration Time: 2.96163

Cumulative Model Updates: 13,312
Cumulative Timesteps: 222,223,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 222223402...
Checkpoint 222223402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,662.06755
Policy Entropy: 0.52792
Value Function Loss: 0.09108

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01585
Policy Update Magnitude: 0.01515
Value Function Update Magnitude: 0.01971

Collected Steps per Second: 23,037.35636
Overall Steps per Second: 16,742.07968

Timestep Collection Time: 2.17082
Timestep Consumption Time: 0.81626
PPO Batch Consumption Time: 0.06202
Total Iteration Time: 2.98708

Cumulative Model Updates: 13,315
Cumulative Timesteps: 222,273,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,669.30097
Policy Entropy: 0.51830
Value Function Loss: 0.11195

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01612
Policy Update Magnitude: 0.01600
Value Function Update Magnitude: 0.01991

Collected Steps per Second: 22,151.07540
Overall Steps per Second: 16,345.39104

Timestep Collection Time: 2.25849
Timestep Consumption Time: 0.80219
PPO Batch Consumption Time: 0.06203
Total Iteration Time: 3.06068

Cumulative Model Updates: 13,318
Cumulative Timesteps: 222,323,440

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 222323440...
Checkpoint 222323440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,971.95768
Policy Entropy: 0.51885
Value Function Loss: 0.11970

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01583
Policy Update Magnitude: 0.01606
Value Function Update Magnitude: 0.01837

Collected Steps per Second: 19,632.89662
Overall Steps per Second: 14,064.58650

Timestep Collection Time: 2.54827
Timestep Consumption Time: 1.00889
PPO Batch Consumption Time: 0.12174
Total Iteration Time: 3.55716

Cumulative Model Updates: 13,321
Cumulative Timesteps: 222,373,470

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,459.92186
Policy Entropy: 0.51807
Value Function Loss: 0.12982

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.00817
Policy Update Magnitude: 0.01675
Value Function Update Magnitude: 0.02894

Collected Steps per Second: 23,405.96467
Overall Steps per Second: 16,921.29918

Timestep Collection Time: 2.13706
Timestep Consumption Time: 0.81898
PPO Batch Consumption Time: 0.06463
Total Iteration Time: 2.95604

Cumulative Model Updates: 13,324
Cumulative Timesteps: 222,423,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 222423490...
Checkpoint 222423490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,347.90817
Policy Entropy: 0.52017
Value Function Loss: 0.11825

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.01275
Policy Update Magnitude: 0.01902
Value Function Update Magnitude: 0.02959

Collected Steps per Second: 23,063.88662
Overall Steps per Second: 16,778.57416

Timestep Collection Time: 2.16824
Timestep Consumption Time: 0.81223
PPO Batch Consumption Time: 0.06037
Total Iteration Time: 2.98047

Cumulative Model Updates: 13,327
Cumulative Timesteps: 222,473,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,637.19458
Policy Entropy: 0.52251
Value Function Loss: 0.10188

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01910
Policy Update Magnitude: 0.01937
Value Function Update Magnitude: 0.03051

Collected Steps per Second: 21,379.84703
Overall Steps per Second: 15,480.82974

Timestep Collection Time: 2.33912
Timestep Consumption Time: 0.89133
PPO Batch Consumption Time: 0.08050
Total Iteration Time: 3.23045

Cumulative Model Updates: 13,330
Cumulative Timesteps: 222,523,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 222523508...
Checkpoint 222523508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,512.52722
Policy Entropy: 0.52737
Value Function Loss: 0.09465

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01354
Policy Update Magnitude: 0.01770
Value Function Update Magnitude: 0.03440

Collected Steps per Second: 22,752.54683
Overall Steps per Second: 16,584.63384

Timestep Collection Time: 2.19817
Timestep Consumption Time: 0.81751
PPO Batch Consumption Time: 0.06213
Total Iteration Time: 3.01568

Cumulative Model Updates: 13,333
Cumulative Timesteps: 222,573,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,065.20463
Policy Entropy: 0.52735
Value Function Loss: 0.09170

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.00877
Policy Update Magnitude: 0.02043
Value Function Update Magnitude: 0.03282

Collected Steps per Second: 20,640.83855
Overall Steps per Second: 14,910.69848

Timestep Collection Time: 2.42248
Timestep Consumption Time: 0.93095
PPO Batch Consumption Time: 0.10074
Total Iteration Time: 3.35343

Cumulative Model Updates: 13,336
Cumulative Timesteps: 222,623,524

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 222623524...
Checkpoint 222623524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,601.63234
Policy Entropy: 0.52698
Value Function Loss: 0.09998

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01687
Policy Update Magnitude: 0.01929
Value Function Update Magnitude: 0.03156

Collected Steps per Second: 22,868.40147
Overall Steps per Second: 16,655.36723

Timestep Collection Time: 2.18773
Timestep Consumption Time: 0.81610
PPO Batch Consumption Time: 0.05957
Total Iteration Time: 3.00384

Cumulative Model Updates: 13,339
Cumulative Timesteps: 222,673,554

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,472.83438
Policy Entropy: 0.52203
Value Function Loss: 0.10574

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.01236
Policy Update Magnitude: 0.02165
Value Function Update Magnitude: 0.03413

Collected Steps per Second: 20,625.80299
Overall Steps per Second: 14,830.63986

Timestep Collection Time: 2.42570
Timestep Consumption Time: 0.94786
PPO Batch Consumption Time: 0.10233
Total Iteration Time: 3.37356

Cumulative Model Updates: 13,342
Cumulative Timesteps: 222,723,586

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 222723586...
Checkpoint 222723586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,339.86485
Policy Entropy: 0.52467
Value Function Loss: 0.10232

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01749
Policy Update Magnitude: 0.02140
Value Function Update Magnitude: 0.03176

Collected Steps per Second: 22,998.31495
Overall Steps per Second: 15,774.67710

Timestep Collection Time: 2.17459
Timestep Consumption Time: 0.99580
PPO Batch Consumption Time: 0.11737
Total Iteration Time: 3.17040

Cumulative Model Updates: 13,345
Cumulative Timesteps: 222,773,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,482.55920
Policy Entropy: 0.52605
Value Function Loss: 0.09382

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01502
Policy Update Magnitude: 0.01835
Value Function Update Magnitude: 0.03456

Collected Steps per Second: 22,828.95885
Overall Steps per Second: 16,723.84945

Timestep Collection Time: 2.19099
Timestep Consumption Time: 0.79983
PPO Batch Consumption Time: 0.06199
Total Iteration Time: 2.99082

Cumulative Model Updates: 13,348
Cumulative Timesteps: 222,823,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 222823616...
Checkpoint 222823616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,778.99572
Policy Entropy: 0.52771
Value Function Loss: 0.08650

Mean KL Divergence: 0.00120
SB3 Clip Fraction: 0.01065
Policy Update Magnitude: 0.01687
Value Function Update Magnitude: 0.03045

Collected Steps per Second: 20,238.04220
Overall Steps per Second: 14,732.28499

Timestep Collection Time: 2.47139
Timestep Consumption Time: 0.92361
PPO Batch Consumption Time: 0.09992
Total Iteration Time: 3.39499

Cumulative Model Updates: 13,351
Cumulative Timesteps: 222,873,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,533.31769
Policy Entropy: 0.53039
Value Function Loss: 0.08245

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01577
Policy Update Magnitude: 0.01638
Value Function Update Magnitude: 0.03223

Collected Steps per Second: 22,517.87741
Overall Steps per Second: 16,994.11091

Timestep Collection Time: 2.22117
Timestep Consumption Time: 0.72197
PPO Batch Consumption Time: 0.06393
Total Iteration Time: 2.94314

Cumulative Model Updates: 13,354
Cumulative Timesteps: 222,923,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 222923648...
Checkpoint 222923648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,871.59391
Policy Entropy: 0.52912
Value Function Loss: 0.09119

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01492
Policy Update Magnitude: 0.01701
Value Function Update Magnitude: 0.02988

Collected Steps per Second: 22,201.93041
Overall Steps per Second: 16,468.69157

Timestep Collection Time: 2.25269
Timestep Consumption Time: 0.78423
PPO Batch Consumption Time: 0.07745
Total Iteration Time: 3.03691

Cumulative Model Updates: 13,357
Cumulative Timesteps: 222,973,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,213.24529
Policy Entropy: 0.53083
Value Function Loss: 0.09643

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03655
Policy Update Magnitude: 0.01753
Value Function Update Magnitude: 0.04351

Collected Steps per Second: 22,564.04518
Overall Steps per Second: 16,652.67066

Timestep Collection Time: 2.21609
Timestep Consumption Time: 0.78667
PPO Batch Consumption Time: 0.07446
Total Iteration Time: 3.00276

Cumulative Model Updates: 13,360
Cumulative Timesteps: 223,023,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 223023666...
Checkpoint 223023666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,211.04311
Policy Entropy: 0.52481
Value Function Loss: 0.10498

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03807
Policy Update Magnitude: 0.01747
Value Function Update Magnitude: 0.03923

Collected Steps per Second: 22,315.10493
Overall Steps per Second: 15,931.23322

Timestep Collection Time: 2.24180
Timestep Consumption Time: 0.89832
PPO Batch Consumption Time: 0.10298
Total Iteration Time: 3.14012

Cumulative Model Updates: 13,363
Cumulative Timesteps: 223,073,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,257.02446
Policy Entropy: 0.52479
Value Function Loss: 0.10592

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03779
Policy Update Magnitude: 0.01740
Value Function Update Magnitude: 0.04556

Collected Steps per Second: 23,064.98311
Overall Steps per Second: 16,910.14939

Timestep Collection Time: 2.16796
Timestep Consumption Time: 0.78908
PPO Batch Consumption Time: 0.06508
Total Iteration Time: 2.95704

Cumulative Model Updates: 13,366
Cumulative Timesteps: 223,123,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 223123696...
Checkpoint 223123696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,740.21153
Policy Entropy: 0.52263
Value Function Loss: 0.10361

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02921
Policy Update Magnitude: 0.01956
Value Function Update Magnitude: 0.04316

Collected Steps per Second: 23,056.91226
Overall Steps per Second: 16,892.41796

Timestep Collection Time: 2.16898
Timestep Consumption Time: 0.79152
PPO Batch Consumption Time: 0.06383
Total Iteration Time: 2.96050

Cumulative Model Updates: 13,369
Cumulative Timesteps: 223,173,706

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,099.27034
Policy Entropy: 0.52540
Value Function Loss: 0.10087

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.05302
Policy Update Magnitude: 0.01972
Value Function Update Magnitude: 0.04353

Collected Steps per Second: 23,296.35234
Overall Steps per Second: 16,989.50831

Timestep Collection Time: 2.14686
Timestep Consumption Time: 0.79696
PPO Batch Consumption Time: 0.06458
Total Iteration Time: 2.94382

Cumulative Model Updates: 13,372
Cumulative Timesteps: 223,223,720

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 223223720...
Checkpoint 223223720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,919.04398
Policy Entropy: 0.52783
Value Function Loss: 0.09814

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05729
Policy Update Magnitude: 0.01962
Value Function Update Magnitude: 0.03661

Collected Steps per Second: 20,151.53267
Overall Steps per Second: 14,274.32747

Timestep Collection Time: 2.48378
Timestep Consumption Time: 1.02265
PPO Batch Consumption Time: 0.11167
Total Iteration Time: 3.50643

Cumulative Model Updates: 13,375
Cumulative Timesteps: 223,273,772

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,725.08283
Policy Entropy: 0.52156
Value Function Loss: 0.10440

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.05399
Policy Update Magnitude: 0.01890
Value Function Update Magnitude: 0.03738

Collected Steps per Second: 23,154.85555
Overall Steps per Second: 16,383.31022

Timestep Collection Time: 2.15937
Timestep Consumption Time: 0.89251
PPO Batch Consumption Time: 0.08215
Total Iteration Time: 3.05189

Cumulative Model Updates: 13,378
Cumulative Timesteps: 223,323,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 223323772...
Checkpoint 223323772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,518.75648
Policy Entropy: 0.51866
Value Function Loss: 0.10196

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.07070
Policy Update Magnitude: 0.01858
Value Function Update Magnitude: 0.03694

Collected Steps per Second: 21,779.70982
Overall Steps per Second: 15,015.14841

Timestep Collection Time: 2.29700
Timestep Consumption Time: 1.03483
PPO Batch Consumption Time: 0.12497
Total Iteration Time: 3.33184

Cumulative Model Updates: 13,381
Cumulative Timesteps: 223,373,800

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,979.82727
Policy Entropy: 0.51879
Value Function Loss: 0.10598

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.06043
Policy Update Magnitude: 0.01622
Value Function Update Magnitude: 0.04360

Collected Steps per Second: 23,104.20273
Overall Steps per Second: 16,674.04884

Timestep Collection Time: 2.16541
Timestep Consumption Time: 0.83506
PPO Batch Consumption Time: 0.06529
Total Iteration Time: 3.00047

Cumulative Model Updates: 13,384
Cumulative Timesteps: 223,423,830

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 223423830...
Checkpoint 223423830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,947.78928
Policy Entropy: 0.52029
Value Function Loss: 0.09767

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05985
Policy Update Magnitude: 0.01780
Value Function Update Magnitude: 0.03939

Collected Steps per Second: 20,234.35840
Overall Steps per Second: 14,838.35187

Timestep Collection Time: 2.47223
Timestep Consumption Time: 0.89903
PPO Batch Consumption Time: 0.09227
Total Iteration Time: 3.37126

Cumulative Model Updates: 13,387
Cumulative Timesteps: 223,473,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,216.32935
Policy Entropy: 0.52290
Value Function Loss: 0.10261

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03610
Policy Update Magnitude: 0.01754
Value Function Update Magnitude: 0.04210

Collected Steps per Second: 23,409.64787
Overall Steps per Second: 16,974.99473

Timestep Collection Time: 2.13707
Timestep Consumption Time: 0.81009
PPO Batch Consumption Time: 0.06443
Total Iteration Time: 2.94716

Cumulative Model Updates: 13,390
Cumulative Timesteps: 223,523,882

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 223523882...
Checkpoint 223523882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,485.95230
Policy Entropy: 0.52167
Value Function Loss: 0.10622

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04511
Policy Update Magnitude: 0.01987
Value Function Update Magnitude: 0.03714

Collected Steps per Second: 23,110.39600
Overall Steps per Second: 16,790.19750

Timestep Collection Time: 2.16483
Timestep Consumption Time: 0.81489
PPO Batch Consumption Time: 0.06584
Total Iteration Time: 2.97971

Cumulative Model Updates: 13,393
Cumulative Timesteps: 223,573,912

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,339.45840
Policy Entropy: 0.51838
Value Function Loss: 0.11566

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.05145
Policy Update Magnitude: 0.01772
Value Function Update Magnitude: 0.04595

Collected Steps per Second: 23,163.29222
Overall Steps per Second: 16,686.97861

Timestep Collection Time: 2.15859
Timestep Consumption Time: 0.83776
PPO Batch Consumption Time: 0.06705
Total Iteration Time: 2.99635

Cumulative Model Updates: 13,396
Cumulative Timesteps: 223,623,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 223623912...
Checkpoint 223623912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,897.68819
Policy Entropy: 0.51662
Value Function Loss: 0.11450

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03575
Policy Update Magnitude: 0.01915
Value Function Update Magnitude: 0.04027

Collected Steps per Second: 22,859.41842
Overall Steps per Second: 16,694.56996

Timestep Collection Time: 2.18772
Timestep Consumption Time: 0.80787
PPO Batch Consumption Time: 0.06114
Total Iteration Time: 2.99558

Cumulative Model Updates: 13,399
Cumulative Timesteps: 223,673,922

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,329.58590
Policy Entropy: 0.51310
Value Function Loss: 0.11022

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04640
Policy Update Magnitude: 0.02142
Value Function Update Magnitude: 0.04735

Collected Steps per Second: 20,938.75078
Overall Steps per Second: 14,706.26016

Timestep Collection Time: 2.38935
Timestep Consumption Time: 1.01260
PPO Batch Consumption Time: 0.12666
Total Iteration Time: 3.40195

Cumulative Model Updates: 13,402
Cumulative Timesteps: 223,723,952

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 223723952...
Checkpoint 223723952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,200.06170
Policy Entropy: 0.51396
Value Function Loss: 0.09802

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.06456
Policy Update Magnitude: 0.01954
Value Function Update Magnitude: 0.04303

Collected Steps per Second: 22,929.79832
Overall Steps per Second: 15,719.65012

Timestep Collection Time: 2.18066
Timestep Consumption Time: 1.00020
PPO Batch Consumption Time: 0.11989
Total Iteration Time: 3.18086

Cumulative Model Updates: 13,405
Cumulative Timesteps: 223,773,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,199.77990
Policy Entropy: 0.51707
Value Function Loss: 0.09354

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04895
Policy Update Magnitude: 0.01934
Value Function Update Magnitude: 0.04327

Collected Steps per Second: 23,622.33320
Overall Steps per Second: 17,192.93950

Timestep Collection Time: 2.11749
Timestep Consumption Time: 0.79185
PPO Batch Consumption Time: 0.06009
Total Iteration Time: 2.90933

Cumulative Model Updates: 13,408
Cumulative Timesteps: 223,823,974

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 223823974...
Checkpoint 223823974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,121.85976
Policy Entropy: 0.51639
Value Function Loss: 0.09762

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05707
Policy Update Magnitude: 0.01798
Value Function Update Magnitude: 0.03693

Collected Steps per Second: 20,946.61394
Overall Steps per Second: 15,192.20727

Timestep Collection Time: 2.38826
Timestep Consumption Time: 0.90461
PPO Batch Consumption Time: 0.07979
Total Iteration Time: 3.29287

Cumulative Model Updates: 13,411
Cumulative Timesteps: 223,874,000

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,440.73952
Policy Entropy: 0.50949
Value Function Loss: 0.10552

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04715
Policy Update Magnitude: 0.01687
Value Function Update Magnitude: 0.03360

Collected Steps per Second: 23,235.24173
Overall Steps per Second: 16,902.68787

Timestep Collection Time: 2.15294
Timestep Consumption Time: 0.80659
PPO Batch Consumption Time: 0.06180
Total Iteration Time: 2.95953

Cumulative Model Updates: 13,414
Cumulative Timesteps: 223,924,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 223924024...
Checkpoint 223924024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,895.77446
Policy Entropy: 0.51328
Value Function Loss: 0.09938

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04947
Policy Update Magnitude: 0.01924
Value Function Update Magnitude: 0.03278

Collected Steps per Second: 20,557.93073
Overall Steps per Second: 14,688.80014

Timestep Collection Time: 2.43215
Timestep Consumption Time: 0.97180
PPO Batch Consumption Time: 0.11075
Total Iteration Time: 3.40395

Cumulative Model Updates: 13,417
Cumulative Timesteps: 223,974,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,764.98503
Policy Entropy: 0.50676
Value Function Loss: 0.10653

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05631
Policy Update Magnitude: 0.01983
Value Function Update Magnitude: 0.03857

Collected Steps per Second: 23,232.96518
Overall Steps per Second: 16,897.22423

Timestep Collection Time: 2.15349
Timestep Consumption Time: 0.80747
PPO Batch Consumption Time: 0.06317
Total Iteration Time: 2.96096

Cumulative Model Updates: 13,420
Cumulative Timesteps: 224,024,056

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 224024056...
Checkpoint 224024056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,366.82155
Policy Entropy: 0.50484
Value Function Loss: 0.10894

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06559
Policy Update Magnitude: 0.01780
Value Function Update Magnitude: 0.03485

Collected Steps per Second: 22,946.79609
Overall Steps per Second: 16,724.93315

Timestep Collection Time: 2.18026
Timestep Consumption Time: 0.81108
PPO Batch Consumption Time: 0.06266
Total Iteration Time: 2.99134

Cumulative Model Updates: 13,423
Cumulative Timesteps: 224,074,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,163.00332
Policy Entropy: 0.50437
Value Function Loss: 0.10952

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05010
Policy Update Magnitude: 0.02087
Value Function Update Magnitude: 0.04288

Collected Steps per Second: 19,983.73994
Overall Steps per Second: 14,624.78174

Timestep Collection Time: 2.50344
Timestep Consumption Time: 0.91733
PPO Batch Consumption Time: 0.09532
Total Iteration Time: 3.42077

Cumulative Model Updates: 13,426
Cumulative Timesteps: 224,124,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 224124114...
Checkpoint 224124114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,900.62386
Policy Entropy: 0.50332
Value Function Loss: 0.11263

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05843
Policy Update Magnitude: 0.01961
Value Function Update Magnitude: 0.03728

Collected Steps per Second: 22,497.53791
Overall Steps per Second: 15,750.59639

Timestep Collection Time: 2.22362
Timestep Consumption Time: 0.95251
PPO Batch Consumption Time: 0.10511
Total Iteration Time: 3.17613

Cumulative Model Updates: 13,429
Cumulative Timesteps: 224,174,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,043.55169
Policy Entropy: 0.50784
Value Function Loss: 0.11430

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05972
Policy Update Magnitude: 0.01933
Value Function Update Magnitude: 0.04547

Collected Steps per Second: 22,203.68808
Overall Steps per Second: 16,342.98388

Timestep Collection Time: 2.25278
Timestep Consumption Time: 0.80786
PPO Batch Consumption Time: 0.06195
Total Iteration Time: 3.06064

Cumulative Model Updates: 13,432
Cumulative Timesteps: 224,224,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 224224160...
Checkpoint 224224160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,894.81502
Policy Entropy: 0.50579
Value Function Loss: 0.12827

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05111
Policy Update Magnitude: 0.02322
Value Function Update Magnitude: 0.05624

Collected Steps per Second: 20,447.95263
Overall Steps per Second: 14,991.81737

Timestep Collection Time: 2.44543
Timestep Consumption Time: 0.88999
PPO Batch Consumption Time: 0.07860
Total Iteration Time: 3.33542

Cumulative Model Updates: 13,435
Cumulative Timesteps: 224,274,164

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,047.63195
Policy Entropy: 0.50411
Value Function Loss: 0.12479

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.06005
Policy Update Magnitude: 0.02193
Value Function Update Magnitude: 0.05104

Collected Steps per Second: 23,425.34551
Overall Steps per Second: 17,044.09358

Timestep Collection Time: 2.13572
Timestep Consumption Time: 0.79961
PPO Batch Consumption Time: 0.06179
Total Iteration Time: 2.93533

Cumulative Model Updates: 13,438
Cumulative Timesteps: 224,324,194

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 224324194...
Checkpoint 224324194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,869.61249
Policy Entropy: 0.49548
Value Function Loss: 0.12931

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04014
Policy Update Magnitude: 0.01934
Value Function Update Magnitude: 0.04591

Collected Steps per Second: 22,927.85868
Overall Steps per Second: 15,585.68823

Timestep Collection Time: 2.18206
Timestep Consumption Time: 1.02793
PPO Batch Consumption Time: 0.12059
Total Iteration Time: 3.21000

Cumulative Model Updates: 13,441
Cumulative Timesteps: 224,374,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,382.41216
Policy Entropy: 0.50043
Value Function Loss: 0.11720

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.03067
Policy Update Magnitude: 0.02087
Value Function Update Magnitude: 0.04395

Collected Steps per Second: 23,585.80986
Overall Steps per Second: 17,009.20291

Timestep Collection Time: 2.12060
Timestep Consumption Time: 0.81993
PPO Batch Consumption Time: 0.06369
Total Iteration Time: 2.94053

Cumulative Model Updates: 13,444
Cumulative Timesteps: 224,424,240

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 224424240...
Checkpoint 224424240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,558.58492
Policy Entropy: 0.50148
Value Function Loss: 0.11595

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03497
Policy Update Magnitude: 0.01873
Value Function Update Magnitude: 0.03919

Collected Steps per Second: 23,431.49189
Overall Steps per Second: 16,966.68216

Timestep Collection Time: 2.13397
Timestep Consumption Time: 0.81310
PPO Batch Consumption Time: 0.06204
Total Iteration Time: 2.94707

Cumulative Model Updates: 13,447
Cumulative Timesteps: 224,474,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,425.49478
Policy Entropy: 0.49988
Value Function Loss: 0.10955

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02923
Policy Update Magnitude: 0.02046
Value Function Update Magnitude: 0.04038

Collected Steps per Second: 23,283.63917
Overall Steps per Second: 16,893.08696

Timestep Collection Time: 2.14846
Timestep Consumption Time: 0.81275
PPO Batch Consumption Time: 0.06560
Total Iteration Time: 2.96121

Cumulative Model Updates: 13,450
Cumulative Timesteps: 224,524,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 224524266...
Checkpoint 224524266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,598.34127
Policy Entropy: 0.49654
Value Function Loss: 0.10563

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03855
Policy Update Magnitude: 0.01992
Value Function Update Magnitude: 0.03605

Collected Steps per Second: 19,808.86877
Overall Steps per Second: 14,230.40340

Timestep Collection Time: 2.52564
Timestep Consumption Time: 0.99008
PPO Batch Consumption Time: 0.09879
Total Iteration Time: 3.51571

Cumulative Model Updates: 13,453
Cumulative Timesteps: 224,574,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,237.32759
Policy Entropy: 0.49454
Value Function Loss: 0.10575

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03567
Policy Update Magnitude: 0.01944
Value Function Update Magnitude: 0.04239

Collected Steps per Second: 22,988.57020
Overall Steps per Second: 15,737.51420

Timestep Collection Time: 2.17578
Timestep Consumption Time: 1.00249
PPO Batch Consumption Time: 0.12159
Total Iteration Time: 3.17827

Cumulative Model Updates: 13,456
Cumulative Timesteps: 224,624,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 224624314...
Checkpoint 224624314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,370.64629
Policy Entropy: 0.49242
Value Function Loss: 0.10930

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04889
Policy Update Magnitude: 0.01848
Value Function Update Magnitude: 0.04159

Collected Steps per Second: 23,383.16629
Overall Steps per Second: 17,020.27421

Timestep Collection Time: 2.13829
Timestep Consumption Time: 0.79938
PPO Batch Consumption Time: 0.06053
Total Iteration Time: 2.93767

Cumulative Model Updates: 13,459
Cumulative Timesteps: 224,674,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,404.26892
Policy Entropy: 0.49328
Value Function Loss: 0.11303

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.05000
Policy Update Magnitude: 0.01840
Value Function Update Magnitude: 0.04372

Collected Steps per Second: 23,071.67632
Overall Steps per Second: 16,934.27307

Timestep Collection Time: 2.16837
Timestep Consumption Time: 0.78587
PPO Batch Consumption Time: 0.06504
Total Iteration Time: 2.95425

Cumulative Model Updates: 13,462
Cumulative Timesteps: 224,724,342

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 224724342...
Checkpoint 224724342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,222.23548
Policy Entropy: 0.49284
Value Function Loss: 0.11296

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.05455
Policy Update Magnitude: 0.01876
Value Function Update Magnitude: 0.03979

Collected Steps per Second: 23,068.83927
Overall Steps per Second: 16,718.67125

Timestep Collection Time: 2.16777
Timestep Consumption Time: 0.82337
PPO Batch Consumption Time: 0.06418
Total Iteration Time: 2.99115

Cumulative Model Updates: 13,465
Cumulative Timesteps: 224,774,350

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,574.94733
Policy Entropy: 0.49324
Value Function Loss: 0.11300

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.01806
Value Function Update Magnitude: 0.04388

Collected Steps per Second: 23,298.36420
Overall Steps per Second: 16,892.70599

Timestep Collection Time: 2.14685
Timestep Consumption Time: 0.81408
PPO Batch Consumption Time: 0.06496
Total Iteration Time: 2.96092

Cumulative Model Updates: 13,468
Cumulative Timesteps: 224,824,368

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 224824368...
Checkpoint 224824368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,047.20444
Policy Entropy: 0.48998
Value Function Loss: 0.11409

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.07011
Policy Update Magnitude: 0.01628
Value Function Update Magnitude: 0.04738

Collected Steps per Second: 17,238.21757
Overall Steps per Second: 13,226.08260

Timestep Collection Time: 2.90216
Timestep Consumption Time: 0.88037
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 3.78253

Cumulative Model Updates: 13,471
Cumulative Timesteps: 224,874,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,225.36526
Policy Entropy: 0.49407
Value Function Loss: 0.10513

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05322
Policy Update Magnitude: 0.01729
Value Function Update Magnitude: 0.04876

Collected Steps per Second: 20,157.30127
Overall Steps per Second: 15,521.15878

Timestep Collection Time: 2.48109
Timestep Consumption Time: 0.74110
PPO Batch Consumption Time: 0.03284
Total Iteration Time: 3.22218

Cumulative Model Updates: 13,474
Cumulative Timesteps: 224,924,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 224924408...
Checkpoint 224924408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,937.80249
Policy Entropy: 0.49217
Value Function Loss: 0.10020

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04829
Policy Update Magnitude: 0.01676
Value Function Update Magnitude: 0.04172

Collected Steps per Second: 22,486.67518
Overall Steps per Second: 16,478.19777

Timestep Collection Time: 2.22389
Timestep Consumption Time: 0.81090
PPO Batch Consumption Time: 0.05368
Total Iteration Time: 3.03480

Cumulative Model Updates: 13,477
Cumulative Timesteps: 224,974,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,650.90212
Policy Entropy: 0.49294
Value Function Loss: 0.09870

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02980
Policy Update Magnitude: 0.01961
Value Function Update Magnitude: 0.03773

Collected Steps per Second: 20,399.88540
Overall Steps per Second: 14,502.67401

Timestep Collection Time: 2.45158
Timestep Consumption Time: 0.99689
PPO Batch Consumption Time: 0.11399
Total Iteration Time: 3.44847

Cumulative Model Updates: 13,480
Cumulative Timesteps: 225,024,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 225024428...
Checkpoint 225024428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,498.91401
Policy Entropy: 0.49433
Value Function Loss: 0.10107

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.03105
Policy Update Magnitude: 0.01870
Value Function Update Magnitude: 0.03194

Collected Steps per Second: 22,661.05844
Overall Steps per Second: 16,575.08454

Timestep Collection Time: 2.20802
Timestep Consumption Time: 0.81073
PPO Batch Consumption Time: 0.06198
Total Iteration Time: 3.01875

Cumulative Model Updates: 13,483
Cumulative Timesteps: 225,074,464

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,467.34647
Policy Entropy: 0.49330
Value Function Loss: 0.11189

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02572
Policy Update Magnitude: 0.01691
Value Function Update Magnitude: 0.03073

Collected Steps per Second: 19,559.81004
Overall Steps per Second: 14,045.81025

Timestep Collection Time: 2.55739
Timestep Consumption Time: 1.00396
PPO Batch Consumption Time: 0.11877
Total Iteration Time: 3.56135

Cumulative Model Updates: 13,486
Cumulative Timesteps: 225,124,486

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 225124486...
Checkpoint 225124486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,958.75449
Policy Entropy: 0.48287
Value Function Loss: 0.12937

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02310
Policy Update Magnitude: 0.01742
Value Function Update Magnitude: 0.02934

Collected Steps per Second: 22,495.81459
Overall Steps per Second: 16,355.50223

Timestep Collection Time: 2.22308
Timestep Consumption Time: 0.83461
PPO Batch Consumption Time: 0.06670
Total Iteration Time: 3.05769

Cumulative Model Updates: 13,489
Cumulative Timesteps: 225,174,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,329.72168
Policy Entropy: 0.48545
Value Function Loss: 0.12628

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04749
Policy Update Magnitude: 0.01824
Value Function Update Magnitude: 0.03649

Collected Steps per Second: 20,421.48108
Overall Steps per Second: 15,175.69139

Timestep Collection Time: 2.44938
Timestep Consumption Time: 0.84668
PPO Batch Consumption Time: 0.09338
Total Iteration Time: 3.29606

Cumulative Model Updates: 13,492
Cumulative Timesteps: 225,224,516

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 225224516...
Checkpoint 225224516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,738.56270
Policy Entropy: 0.48640
Value Function Loss: 0.12746

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03179
Policy Update Magnitude: 0.01956
Value Function Update Magnitude: 0.03704

Collected Steps per Second: 22,303.92508
Overall Steps per Second: 16,900.65120

Timestep Collection Time: 2.24203
Timestep Consumption Time: 0.71679
PPO Batch Consumption Time: 0.05891
Total Iteration Time: 2.95882

Cumulative Model Updates: 13,495
Cumulative Timesteps: 225,274,522

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,624.01348
Policy Entropy: 0.49213
Value Function Loss: 0.11059

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05687
Policy Update Magnitude: 0.01849
Value Function Update Magnitude: 0.04662

Collected Steps per Second: 20,120.20292
Overall Steps per Second: 14,640.74568

Timestep Collection Time: 2.48506
Timestep Consumption Time: 0.93006
PPO Batch Consumption Time: 0.12467
Total Iteration Time: 3.41513

Cumulative Model Updates: 13,498
Cumulative Timesteps: 225,324,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 225324522...
Checkpoint 225324522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,481.98204
Policy Entropy: 0.49101
Value Function Loss: 0.11811

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04859
Policy Update Magnitude: 0.01803
Value Function Update Magnitude: 0.04167

Collected Steps per Second: 22,195.18784
Overall Steps per Second: 17,361.76543

Timestep Collection Time: 2.25400
Timestep Consumption Time: 0.62750
PPO Batch Consumption Time: 0.02942
Total Iteration Time: 2.88150

Cumulative Model Updates: 13,501
Cumulative Timesteps: 225,374,550

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,114.92403
Policy Entropy: 0.49483
Value Function Loss: 0.11361

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.04281
Policy Update Magnitude: 0.01732
Value Function Update Magnitude: 0.04749

Collected Steps per Second: 17,668.75584
Overall Steps per Second: 13,833.35783

Timestep Collection Time: 2.83053
Timestep Consumption Time: 0.78479
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 3.61532

Cumulative Model Updates: 13,504
Cumulative Timesteps: 225,424,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 225424562...
Checkpoint 225424562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,287.60662
Policy Entropy: 0.49387
Value Function Loss: 0.11373

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03799
Policy Update Magnitude: 0.01695
Value Function Update Magnitude: 0.04310

Collected Steps per Second: 19,071.98054
Overall Steps per Second: 14,856.71470

Timestep Collection Time: 2.62217
Timestep Consumption Time: 0.74398
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 3.36615

Cumulative Model Updates: 13,507
Cumulative Timesteps: 225,474,572

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,859.53169
Policy Entropy: 0.49601
Value Function Loss: 0.10411

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02735
Policy Update Magnitude: 0.01799
Value Function Update Magnitude: 0.04533

Collected Steps per Second: 22,125.58556
Overall Steps per Second: 16,043.59157

Timestep Collection Time: 2.26109
Timestep Consumption Time: 0.85716
PPO Batch Consumption Time: 0.07117
Total Iteration Time: 3.11825

Cumulative Model Updates: 13,510
Cumulative Timesteps: 225,524,600

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 225524600...
Checkpoint 225524600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,526.19466
Policy Entropy: 0.48989
Value Function Loss: 0.10818

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.01738
Value Function Update Magnitude: 0.04282

Collected Steps per Second: 18,847.78011
Overall Steps per Second: 14,084.48285

Timestep Collection Time: 2.65358
Timestep Consumption Time: 0.89743
PPO Batch Consumption Time: 0.08636
Total Iteration Time: 3.55100

Cumulative Model Updates: 13,513
Cumulative Timesteps: 225,574,614

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,185.52416
Policy Entropy: 0.48994
Value Function Loss: 0.11017

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.01743
Value Function Update Magnitude: 0.04739

Collected Steps per Second: 22,589.70569
Overall Steps per Second: 16,523.04046

Timestep Collection Time: 2.21393
Timestep Consumption Time: 0.81287
PPO Batch Consumption Time: 0.06126
Total Iteration Time: 3.02680

Cumulative Model Updates: 13,516
Cumulative Timesteps: 225,624,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 225624626...
Checkpoint 225624626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,822.79013
Policy Entropy: 0.48523
Value Function Loss: 0.11366

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.02155
Policy Update Magnitude: 0.01770
Value Function Update Magnitude: 0.04025

Collected Steps per Second: 20,184.46355
Overall Steps per Second: 14,914.02879

Timestep Collection Time: 2.47844
Timestep Consumption Time: 0.87585
PPO Batch Consumption Time: 0.07476
Total Iteration Time: 3.35429

Cumulative Model Updates: 13,519
Cumulative Timesteps: 225,674,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,518.14412
Policy Entropy: 0.48721
Value Function Loss: 0.11489

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01866
Policy Update Magnitude: 0.01928
Value Function Update Magnitude: 0.04780

Collected Steps per Second: 23,329.56291
Overall Steps per Second: 16,983.29388

Timestep Collection Time: 2.14423
Timestep Consumption Time: 0.80125
PPO Batch Consumption Time: 0.06022
Total Iteration Time: 2.94548

Cumulative Model Updates: 13,522
Cumulative Timesteps: 225,724,676

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 225724676...
Checkpoint 225724676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,649.69916
Policy Entropy: 0.48704
Value Function Loss: 0.11173

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02277
Policy Update Magnitude: 0.01925
Value Function Update Magnitude: 0.04282

Collected Steps per Second: 21,286.34035
Overall Steps per Second: 15,470.91560

Timestep Collection Time: 2.34958
Timestep Consumption Time: 0.88319
PPO Batch Consumption Time: 0.07873
Total Iteration Time: 3.23278

Cumulative Model Updates: 13,525
Cumulative Timesteps: 225,774,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,610.75310
Policy Entropy: 0.49386
Value Function Loss: 0.10931

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01622
Policy Update Magnitude: 0.01907
Value Function Update Magnitude: 0.04630

Collected Steps per Second: 23,114.01763
Overall Steps per Second: 16,745.70828

Timestep Collection Time: 2.16354
Timestep Consumption Time: 0.82278
PPO Batch Consumption Time: 0.06060
Total Iteration Time: 2.98632

Cumulative Model Updates: 13,528
Cumulative Timesteps: 225,824,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 225824698...
Checkpoint 225824698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,409.38054
Policy Entropy: 0.49961
Value Function Loss: 0.09982

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02707
Policy Update Magnitude: 0.01820
Value Function Update Magnitude: 0.04208

Collected Steps per Second: 20,191.52364
Overall Steps per Second: 14,836.48374

Timestep Collection Time: 2.47777
Timestep Consumption Time: 0.89432
PPO Batch Consumption Time: 0.08627
Total Iteration Time: 3.37209

Cumulative Model Updates: 13,531
Cumulative Timesteps: 225,874,728

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,763.48256
Policy Entropy: 0.49963
Value Function Loss: 0.10355

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02389
Policy Update Magnitude: 0.01672
Value Function Update Magnitude: 0.04300

Collected Steps per Second: 23,311.68814
Overall Steps per Second: 16,947.69688

Timestep Collection Time: 2.14502
Timestep Consumption Time: 0.80547
PPO Batch Consumption Time: 0.06250
Total Iteration Time: 2.95049

Cumulative Model Updates: 13,534
Cumulative Timesteps: 225,924,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 225924732...
Checkpoint 225924732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,950.57302
Policy Entropy: 0.49549
Value Function Loss: 0.09875

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02491
Policy Update Magnitude: 0.01710
Value Function Update Magnitude: 0.03264

Collected Steps per Second: 22,699.31346
Overall Steps per Second: 16,364.75216

Timestep Collection Time: 2.20386
Timestep Consumption Time: 0.85308
PPO Batch Consumption Time: 0.06113
Total Iteration Time: 3.05694

Cumulative Model Updates: 13,537
Cumulative Timesteps: 225,974,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,769.99331
Policy Entropy: 0.49039
Value Function Loss: 0.10708

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02329
Policy Update Magnitude: 0.01813
Value Function Update Magnitude: 0.02770

Collected Steps per Second: 20,090.79320
Overall Steps per Second: 14,828.48431

Timestep Collection Time: 2.49069
Timestep Consumption Time: 0.88389
PPO Batch Consumption Time: 0.07518
Total Iteration Time: 3.37459

Cumulative Model Updates: 13,540
Cumulative Timesteps: 226,024,798

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 226024798...
Checkpoint 226024798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,803.30166
Policy Entropy: 0.49119
Value Function Loss: 0.11426

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.04021
Policy Update Magnitude: 0.01629
Value Function Update Magnitude: 0.02674

Collected Steps per Second: 22,784.29889
Overall Steps per Second: 16,772.71202

Timestep Collection Time: 2.19572
Timestep Consumption Time: 0.78698
PPO Batch Consumption Time: 0.05877
Total Iteration Time: 2.98270

Cumulative Model Updates: 13,543
Cumulative Timesteps: 226,074,826

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,768.58393
Policy Entropy: 0.49150
Value Function Loss: 0.11214

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.05045
Policy Update Magnitude: 0.01520
Value Function Update Magnitude: 0.02974

Collected Steps per Second: 19,449.72987
Overall Steps per Second: 14,021.49930

Timestep Collection Time: 2.57217
Timestep Consumption Time: 0.99578
PPO Batch Consumption Time: 0.11742
Total Iteration Time: 3.56795

Cumulative Model Updates: 13,546
Cumulative Timesteps: 226,124,854

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 226124854...
Checkpoint 226124854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,742.40438
Policy Entropy: 0.49321
Value Function Loss: 0.11553

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.01715
Value Function Update Magnitude: 0.02488

Collected Steps per Second: 23,072.87232
Overall Steps per Second: 15,713.93264

Timestep Collection Time: 2.16731
Timestep Consumption Time: 1.01496
PPO Batch Consumption Time: 0.11560
Total Iteration Time: 3.18227

Cumulative Model Updates: 13,549
Cumulative Timesteps: 226,174,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,607.60521
Policy Entropy: 0.49765
Value Function Loss: 0.11185

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.04098
Policy Update Magnitude: 0.01900
Value Function Update Magnitude: 0.02193

Collected Steps per Second: 23,372.56870
Overall Steps per Second: 16,974.87735

Timestep Collection Time: 2.14054
Timestep Consumption Time: 0.80675
PPO Batch Consumption Time: 0.06309
Total Iteration Time: 2.94730

Cumulative Model Updates: 13,552
Cumulative Timesteps: 226,224,890

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 226224890...
Checkpoint 226224890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,432.20874
Policy Entropy: 0.50016
Value Function Loss: 0.11066

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03457
Policy Update Magnitude: 0.01655
Value Function Update Magnitude: 0.02381

Collected Steps per Second: 22,498.53554
Overall Steps per Second: 16,546.51540

Timestep Collection Time: 2.22352
Timestep Consumption Time: 0.79983
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 3.02336

Cumulative Model Updates: 13,555
Cumulative Timesteps: 226,274,916

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,082.76806
Policy Entropy: 0.49947
Value Function Loss: 0.11257

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 0.01817
Value Function Update Magnitude: 0.02337

Collected Steps per Second: 19,515.32953
Overall Steps per Second: 13,951.65362

Timestep Collection Time: 2.56352
Timestep Consumption Time: 1.02229
PPO Batch Consumption Time: 0.12821
Total Iteration Time: 3.58581

Cumulative Model Updates: 13,558
Cumulative Timesteps: 226,324,944

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 226324944...
Checkpoint 226324944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,596.79867
Policy Entropy: 0.50240
Value Function Loss: 0.11839

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04681
Policy Update Magnitude: 0.01813
Value Function Update Magnitude: 0.02624

Collected Steps per Second: 23,383.15743
Overall Steps per Second: 16,832.99226

Timestep Collection Time: 2.13880
Timestep Consumption Time: 0.83227
PPO Batch Consumption Time: 0.06179
Total Iteration Time: 2.97107

Cumulative Model Updates: 13,561
Cumulative Timesteps: 226,374,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,128.81327
Policy Entropy: 0.50096
Value Function Loss: 0.12082

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03883
Policy Update Magnitude: 0.01825
Value Function Update Magnitude: 0.02280

Collected Steps per Second: 22,334.29263
Overall Steps per Second: 16,711.80333

Timestep Collection Time: 2.23925
Timestep Consumption Time: 0.75337
PPO Batch Consumption Time: 0.06397
Total Iteration Time: 2.99262

Cumulative Model Updates: 13,564
Cumulative Timesteps: 226,424,968

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 226424968...
Checkpoint 226424968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,492.61105
Policy Entropy: 0.50665
Value Function Loss: 0.10385

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03246
Policy Update Magnitude: 0.01834
Value Function Update Magnitude: 0.02067

Collected Steps per Second: 22,027.13109
Overall Steps per Second: 16,740.89194

Timestep Collection Time: 2.27075
Timestep Consumption Time: 0.71703
PPO Batch Consumption Time: 0.06060
Total Iteration Time: 2.98777

Cumulative Model Updates: 13,567
Cumulative Timesteps: 226,474,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,339.66218
Policy Entropy: 0.50094
Value Function Loss: 0.10386

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02134
Policy Update Magnitude: 0.01739
Value Function Update Magnitude: 0.01982

Collected Steps per Second: 19,693.62470
Overall Steps per Second: 14,627.24071

Timestep Collection Time: 2.53889
Timestep Consumption Time: 0.87939
PPO Batch Consumption Time: 0.11080
Total Iteration Time: 3.41828

Cumulative Model Updates: 13,570
Cumulative Timesteps: 226,524,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 226524986...
Checkpoint 226524986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,455.06786
Policy Entropy: 0.50019
Value Function Loss: 0.10641

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01481
Policy Update Magnitude: 0.01854
Value Function Update Magnitude: 0.01991

Collected Steps per Second: 22,282.19294
Overall Steps per Second: 15,714.15122

Timestep Collection Time: 2.24502
Timestep Consumption Time: 0.93835
PPO Batch Consumption Time: 0.10600
Total Iteration Time: 3.18337

Cumulative Model Updates: 13,573
Cumulative Timesteps: 226,575,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,497.87923
Policy Entropy: 0.50217
Value Function Loss: 0.10872

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01701
Policy Update Magnitude: 0.01861
Value Function Update Magnitude: 0.01939

Collected Steps per Second: 23,110.25971
Overall Steps per Second: 16,833.07593

Timestep Collection Time: 2.16449
Timestep Consumption Time: 0.80716
PPO Batch Consumption Time: 0.06156
Total Iteration Time: 2.97165

Cumulative Model Updates: 13,576
Cumulative Timesteps: 226,625,032

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 226625032...
Checkpoint 226625032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,506.42856
Policy Entropy: 0.50683
Value Function Loss: 0.10493

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01477
Policy Update Magnitude: 0.01779
Value Function Update Magnitude: 0.01896

Collected Steps per Second: 20,926.33205
Overall Steps per Second: 15,517.83001

Timestep Collection Time: 2.38991
Timestep Consumption Time: 0.83297
PPO Batch Consumption Time: 0.07641
Total Iteration Time: 3.22287

Cumulative Model Updates: 13,579
Cumulative Timesteps: 226,675,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,589.89128
Policy Entropy: 0.50621
Value Function Loss: 0.10289

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01658
Policy Update Magnitude: 0.01769
Value Function Update Magnitude: 0.01890

Collected Steps per Second: 23,334.86554
Overall Steps per Second: 17,035.08811

Timestep Collection Time: 2.14332
Timestep Consumption Time: 0.79262
PPO Batch Consumption Time: 0.06431
Total Iteration Time: 2.93594

Cumulative Model Updates: 13,582
Cumulative Timesteps: 226,725,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 226725058...
Checkpoint 226725058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,856.62285
Policy Entropy: 0.50461
Value Function Loss: 0.10793

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01859
Policy Update Magnitude: 0.02059
Value Function Update Magnitude: 0.02000

Collected Steps per Second: 22,814.87965
Overall Steps per Second: 15,614.69066

Timestep Collection Time: 2.19182
Timestep Consumption Time: 1.01068
PPO Batch Consumption Time: 0.11938
Total Iteration Time: 3.20250

Cumulative Model Updates: 13,585
Cumulative Timesteps: 226,775,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,740.16113
Policy Entropy: 0.50424
Value Function Loss: 0.10756

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02631
Policy Update Magnitude: 0.02204
Value Function Update Magnitude: 0.02097

Collected Steps per Second: 23,738.00209
Overall Steps per Second: 16,572.85554

Timestep Collection Time: 2.10709
Timestep Consumption Time: 0.91098
PPO Batch Consumption Time: 0.08514
Total Iteration Time: 3.01807

Cumulative Model Updates: 13,588
Cumulative Timesteps: 226,825,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 226825082...
Checkpoint 226825082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,321.08882
Policy Entropy: 0.50560
Value Function Loss: 0.09958

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01916
Policy Update Magnitude: 0.01864
Value Function Update Magnitude: 0.02284

Collected Steps per Second: 23,117.67491
Overall Steps per Second: 16,934.96834

Timestep Collection Time: 2.16492
Timestep Consumption Time: 0.79038
PPO Batch Consumption Time: 0.06044
Total Iteration Time: 2.95531

Cumulative Model Updates: 13,591
Cumulative Timesteps: 226,875,130

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,628.31043
Policy Entropy: 0.50413
Value Function Loss: 0.09105

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02538
Policy Update Magnitude: 0.01724
Value Function Update Magnitude: 0.02020

Collected Steps per Second: 20,712.20793
Overall Steps per Second: 14,674.36410

Timestep Collection Time: 2.41490
Timestep Consumption Time: 0.99363
PPO Batch Consumption Time: 0.11635
Total Iteration Time: 3.40853

Cumulative Model Updates: 13,594
Cumulative Timesteps: 226,925,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 226925148...
Checkpoint 226925148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,175.29215
Policy Entropy: 0.50263
Value Function Loss: 0.09116

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01815
Policy Update Magnitude: 0.01660
Value Function Update Magnitude: 0.02096

Collected Steps per Second: 22,707.21560
Overall Steps per Second: 16,596.38384

Timestep Collection Time: 2.20212
Timestep Consumption Time: 0.81083
PPO Batch Consumption Time: 0.05947
Total Iteration Time: 3.01295

Cumulative Model Updates: 13,597
Cumulative Timesteps: 226,975,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,080.96183
Policy Entropy: 0.49807
Value Function Loss: 0.09256

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02480
Policy Update Magnitude: 0.01613
Value Function Update Magnitude: 0.01930

Collected Steps per Second: 20,804.46194
Overall Steps per Second: 14,840.11292

Timestep Collection Time: 2.40333
Timestep Consumption Time: 0.96592
PPO Batch Consumption Time: 0.10999
Total Iteration Time: 3.36925

Cumulative Model Updates: 13,600
Cumulative Timesteps: 227,025,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 227025152...
Checkpoint 227025152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,899.03437
Policy Entropy: 0.49488
Value Function Loss: 0.10207

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02172
Policy Update Magnitude: 0.01486
Value Function Update Magnitude: 0.01888

Collected Steps per Second: 22,600.36984
Overall Steps per Second: 16,372.32954

Timestep Collection Time: 2.21350
Timestep Consumption Time: 0.84202
PPO Batch Consumption Time: 0.06369
Total Iteration Time: 3.05552

Cumulative Model Updates: 13,603
Cumulative Timesteps: 227,075,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,153.11466
Policy Entropy: 0.49517
Value Function Loss: 0.10331

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.00992
Policy Update Magnitude: 0.01628
Value Function Update Magnitude: 0.02100

Collected Steps per Second: 20,144.98962
Overall Steps per Second: 14,281.52197

Timestep Collection Time: 2.48221
Timestep Consumption Time: 1.01910
PPO Batch Consumption Time: 0.12247
Total Iteration Time: 3.50131

Cumulative Model Updates: 13,606
Cumulative Timesteps: 227,125,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 227125182...
Checkpoint 227125182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,900.65639
Policy Entropy: 0.49570
Value Function Loss: 0.11018

Mean KL Divergence: 0.00085
SB3 Clip Fraction: 0.00491
Policy Update Magnitude: 0.01658
Value Function Update Magnitude: 0.02073

Collected Steps per Second: 23,035.09459
Overall Steps per Second: 16,825.69357

Timestep Collection Time: 2.17086
Timestep Consumption Time: 0.80114
PPO Batch Consumption Time: 0.05787
Total Iteration Time: 2.97200

Cumulative Model Updates: 13,609
Cumulative Timesteps: 227,175,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,057.65548
Policy Entropy: 0.50356
Value Function Loss: 0.10049

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.02072
Policy Update Magnitude: 0.01757
Value Function Update Magnitude: 0.02049

Collected Steps per Second: 21,250.31162
Overall Steps per Second: 15,424.00665

Timestep Collection Time: 2.35422
Timestep Consumption Time: 0.88929
PPO Batch Consumption Time: 0.07986
Total Iteration Time: 3.24352

Cumulative Model Updates: 13,612
Cumulative Timesteps: 227,225,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 227225216...
Checkpoint 227225216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,355.28453
Policy Entropy: 0.49499
Value Function Loss: 0.10936

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02805
Policy Update Magnitude: 0.01717
Value Function Update Magnitude: 0.01995

Collected Steps per Second: 22,958.10596
Overall Steps per Second: 16,724.00342

Timestep Collection Time: 2.17840
Timestep Consumption Time: 0.81203
PPO Batch Consumption Time: 0.06155
Total Iteration Time: 2.99043

Cumulative Model Updates: 13,615
Cumulative Timesteps: 227,275,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,022.52863
Policy Entropy: 0.49831
Value Function Loss: 0.10976

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.01620
Value Function Update Magnitude: 0.02207

Collected Steps per Second: 18,009.97382
Overall Steps per Second: 13,344.17164

Timestep Collection Time: 2.77879
Timestep Consumption Time: 0.97161
PPO Batch Consumption Time: 0.08790
Total Iteration Time: 3.75040

Cumulative Model Updates: 13,618
Cumulative Timesteps: 227,325,274

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 227325274...
Checkpoint 227325274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,941.91429
Policy Entropy: 0.49417
Value Function Loss: 0.11594

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01493
Policy Update Magnitude: 0.01793
Value Function Update Magnitude: 0.02089

Collected Steps per Second: 21,996.24717
Overall Steps per Second: 15,740.91166

Timestep Collection Time: 2.27375
Timestep Consumption Time: 0.90357
PPO Batch Consumption Time: 0.09268
Total Iteration Time: 3.17733

Cumulative Model Updates: 13,621
Cumulative Timesteps: 227,375,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,797.58164
Policy Entropy: 0.49637
Value Function Loss: 0.11628

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01472
Policy Update Magnitude: 0.01965
Value Function Update Magnitude: 0.02200

Collected Steps per Second: 19,768.94229
Overall Steps per Second: 14,717.41282

Timestep Collection Time: 2.53145
Timestep Consumption Time: 0.86888
PPO Batch Consumption Time: 0.06892
Total Iteration Time: 3.40033

Cumulative Model Updates: 13,624
Cumulative Timesteps: 227,425,332

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 227425332...
Checkpoint 227425332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,334.84124
Policy Entropy: 0.49584
Value Function Loss: 0.11805

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01497
Policy Update Magnitude: 0.01936
Value Function Update Magnitude: 0.02073

Collected Steps per Second: 19,705.40867
Overall Steps per Second: 15,063.86464

Timestep Collection Time: 2.53788
Timestep Consumption Time: 0.78198
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 3.31987

Cumulative Model Updates: 13,627
Cumulative Timesteps: 227,475,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,240.70762
Policy Entropy: 0.49558
Value Function Loss: 0.12412

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02545
Policy Update Magnitude: 0.02117
Value Function Update Magnitude: 0.02385

Collected Steps per Second: 21,914.47127
Overall Steps per Second: 16,188.18289

Timestep Collection Time: 2.28278
Timestep Consumption Time: 0.80750
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 3.09028

Cumulative Model Updates: 13,630
Cumulative Timesteps: 227,525,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 227525368...
Checkpoint 227525368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,351.72528
Policy Entropy: 0.49524
Value Function Loss: 0.11922

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03683
Policy Update Magnitude: 0.02210
Value Function Update Magnitude: 0.02236

Collected Steps per Second: 19,741.07875
Overall Steps per Second: 14,183.32986

Timestep Collection Time: 2.53319
Timestep Consumption Time: 0.99263
PPO Batch Consumption Time: 0.11639
Total Iteration Time: 3.52583

Cumulative Model Updates: 13,633
Cumulative Timesteps: 227,575,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,559.21462
Policy Entropy: 0.49324
Value Function Loss: 0.11697

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.02249
Policy Update Magnitude: 0.02053
Value Function Update Magnitude: 0.02724

Collected Steps per Second: 22,914.51341
Overall Steps per Second: 16,721.48642

Timestep Collection Time: 2.18342
Timestep Consumption Time: 0.80866
PPO Batch Consumption Time: 0.06070
Total Iteration Time: 2.99208

Cumulative Model Updates: 13,636
Cumulative Timesteps: 227,625,408

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 227625408...
Checkpoint 227625408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,125.07938
Policy Entropy: 0.49206
Value Function Loss: 0.11928

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04797
Policy Update Magnitude: 0.02315
Value Function Update Magnitude: 0.02549

Collected Steps per Second: 20,392.29807
Overall Steps per Second: 14,758.70584

Timestep Collection Time: 2.45397
Timestep Consumption Time: 0.93671
PPO Batch Consumption Time: 0.09772
Total Iteration Time: 3.39068

Cumulative Model Updates: 13,639
Cumulative Timesteps: 227,675,450

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,374.21554
Policy Entropy: 0.49233
Value Function Loss: 0.11537

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05608
Policy Update Magnitude: 0.01851
Value Function Update Magnitude: 0.02322

Collected Steps per Second: 21,694.63097
Overall Steps per Second: 15,902.30894

Timestep Collection Time: 2.30472
Timestep Consumption Time: 0.83948
PPO Batch Consumption Time: 0.06818
Total Iteration Time: 3.14420

Cumulative Model Updates: 13,642
Cumulative Timesteps: 227,725,450

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 227725450...
Checkpoint 227725450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,251.76476
Policy Entropy: 0.48771
Value Function Loss: 0.11766

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04367
Policy Update Magnitude: 0.01888
Value Function Update Magnitude: 0.02481

Collected Steps per Second: 23,268.44558
Overall Steps per Second: 16,468.42489

Timestep Collection Time: 2.14909
Timestep Consumption Time: 0.88739
PPO Batch Consumption Time: 0.08113
Total Iteration Time: 3.03648

Cumulative Model Updates: 13,645
Cumulative Timesteps: 227,775,456

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,223.20043
Policy Entropy: 0.49116
Value Function Loss: 0.10581

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.04059
Policy Update Magnitude: 0.01891
Value Function Update Magnitude: 0.02181

Collected Steps per Second: 23,504.60338
Overall Steps per Second: 16,948.38003

Timestep Collection Time: 2.12784
Timestep Consumption Time: 0.82312
PPO Batch Consumption Time: 0.06514
Total Iteration Time: 2.95096

Cumulative Model Updates: 13,648
Cumulative Timesteps: 227,825,470

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 227825470...
Checkpoint 227825470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,919.51181
Policy Entropy: 0.49396
Value Function Loss: 0.10713

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04989
Policy Update Magnitude: 0.01845
Value Function Update Magnitude: 0.02543

Collected Steps per Second: 23,351.83246
Overall Steps per Second: 16,548.51701

Timestep Collection Time: 2.14210
Timestep Consumption Time: 0.88065
PPO Batch Consumption Time: 0.07927
Total Iteration Time: 3.02275

Cumulative Model Updates: 13,651
Cumulative Timesteps: 227,875,492

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,946.09677
Policy Entropy: 0.49559
Value Function Loss: 0.11242

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04997
Policy Update Magnitude: 0.01913
Value Function Update Magnitude: 0.02630

Collected Steps per Second: 22,980.96346
Overall Steps per Second: 16,764.32560

Timestep Collection Time: 2.17624
Timestep Consumption Time: 0.80700
PPO Batch Consumption Time: 0.06142
Total Iteration Time: 2.98324

Cumulative Model Updates: 13,654
Cumulative Timesteps: 227,925,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 227925504...
Checkpoint 227925504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,199.27293
Policy Entropy: 0.48869
Value Function Loss: 0.11509

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.05120
Policy Update Magnitude: 0.01821
Value Function Update Magnitude: 0.02437

Collected Steps per Second: 20,479.98134
Overall Steps per Second: 14,764.95312

Timestep Collection Time: 2.44180
Timestep Consumption Time: 0.94514
PPO Batch Consumption Time: 0.10240
Total Iteration Time: 3.38694

Cumulative Model Updates: 13,657
Cumulative Timesteps: 227,975,512

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,089.77384
Policy Entropy: 0.48432
Value Function Loss: 0.12170

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.05198
Policy Update Magnitude: 0.01672
Value Function Update Magnitude: 0.02392

Collected Steps per Second: 23,135.71924
Overall Steps per Second: 16,907.40961

Timestep Collection Time: 2.16211
Timestep Consumption Time: 0.79647
PPO Batch Consumption Time: 0.06274
Total Iteration Time: 2.95858

Cumulative Model Updates: 13,660
Cumulative Timesteps: 228,025,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 228025534...
Checkpoint 228025534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,900.96390
Policy Entropy: 0.48083
Value Function Loss: 0.11866

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03740
Policy Update Magnitude: 0.01750
Value Function Update Magnitude: 0.02557

Collected Steps per Second: 23,036.61198
Overall Steps per Second: 16,468.80460

Timestep Collection Time: 2.17115
Timestep Consumption Time: 0.86586
PPO Batch Consumption Time: 0.07627
Total Iteration Time: 3.03701

Cumulative Model Updates: 13,663
Cumulative Timesteps: 228,075,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,530.00374
Policy Entropy: 0.48366
Value Function Loss: 0.11177

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.01915
Value Function Update Magnitude: 0.02837

Collected Steps per Second: 20,114.73492
Overall Steps per Second: 14,987.40709

Timestep Collection Time: 2.48594
Timestep Consumption Time: 0.85046
PPO Batch Consumption Time: 0.06358
Total Iteration Time: 3.33640

Cumulative Model Updates: 13,666
Cumulative Timesteps: 228,125,554

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 228125554...
Checkpoint 228125554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,502.02982
Policy Entropy: 0.48572
Value Function Loss: 0.10671

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02564
Policy Update Magnitude: 0.01665
Value Function Update Magnitude: 0.02823

Collected Steps per Second: 21,861.15405
Overall Steps per Second: 16,655.04259

Timestep Collection Time: 2.28826
Timestep Consumption Time: 0.71528
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 3.00353

Cumulative Model Updates: 13,669
Cumulative Timesteps: 228,175,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,378.88346
Policy Entropy: 0.48713
Value Function Loss: 0.10148

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02291
Policy Update Magnitude: 0.01610
Value Function Update Magnitude: 0.02483

Collected Steps per Second: 19,505.90298
Overall Steps per Second: 14,448.79878

Timestep Collection Time: 2.56394
Timestep Consumption Time: 0.89738
PPO Batch Consumption Time: 0.08053
Total Iteration Time: 3.46133

Cumulative Model Updates: 13,672
Cumulative Timesteps: 228,225,590

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 228225590...
Checkpoint 228225590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,458.95951
Policy Entropy: 0.48577
Value Function Loss: 0.11282

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01765
Policy Update Magnitude: 0.01855
Value Function Update Magnitude: 0.02333

Collected Steps per Second: 21,495.23771
Overall Steps per Second: 15,064.45047

Timestep Collection Time: 2.32731
Timestep Consumption Time: 0.99349
PPO Batch Consumption Time: 0.12256
Total Iteration Time: 3.32080

Cumulative Model Updates: 13,675
Cumulative Timesteps: 228,275,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,632.17161
Policy Entropy: 0.49624
Value Function Loss: 0.10610

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.04245
Policy Update Magnitude: 0.01995
Value Function Update Magnitude: 0.02217

Collected Steps per Second: 23,618.90551
Overall Steps per Second: 17,008.70300

Timestep Collection Time: 2.11780
Timestep Consumption Time: 0.82305
PPO Batch Consumption Time: 0.06197
Total Iteration Time: 2.94085

Cumulative Model Updates: 13,678
Cumulative Timesteps: 228,325,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 228325636...
Checkpoint 228325636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,335.81236
Policy Entropy: 0.49777
Value Function Loss: 0.11332

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.04007
Policy Update Magnitude: 0.02086
Value Function Update Magnitude: 0.02149

Collected Steps per Second: 21,182.34327
Overall Steps per Second: 16,189.97025

Timestep Collection Time: 2.36301
Timestep Consumption Time: 0.72866
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 3.09167

Cumulative Model Updates: 13,681
Cumulative Timesteps: 228,375,690

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,807.50000
Policy Entropy: 0.49938
Value Function Loss: 0.10706

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02813
Policy Update Magnitude: 0.02111
Value Function Update Magnitude: 0.02489

Collected Steps per Second: 19,424.54259
Overall Steps per Second: 14,879.29615

Timestep Collection Time: 2.57540
Timestep Consumption Time: 0.78672
PPO Batch Consumption Time: 0.07663
Total Iteration Time: 3.36212

Cumulative Model Updates: 13,684
Cumulative Timesteps: 228,425,716

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 228425716...
Checkpoint 228425716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,009.02204
Policy Entropy: 0.49716
Value Function Loss: 0.10833

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.02121
Value Function Update Magnitude: 0.02335

Collected Steps per Second: 22,204.01390
Overall Steps per Second: 16,882.65981

Timestep Collection Time: 2.25221
Timestep Consumption Time: 0.70989
PPO Batch Consumption Time: 0.05822
Total Iteration Time: 2.96209

Cumulative Model Updates: 13,687
Cumulative Timesteps: 228,475,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,294.80524
Policy Entropy: 0.49830
Value Function Loss: 0.09605

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.01212
Policy Update Magnitude: 0.02023
Value Function Update Magnitude: 0.02200

Collected Steps per Second: 19,865.80968
Overall Steps per Second: 13,941.63576

Timestep Collection Time: 2.51810
Timestep Consumption Time: 1.07001
PPO Batch Consumption Time: 0.12894
Total Iteration Time: 3.58810

Cumulative Model Updates: 13,690
Cumulative Timesteps: 228,525,748

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 228525748...
Checkpoint 228525748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,304.12188
Policy Entropy: 0.50259
Value Function Loss: 0.09341

Mean KL Divergence: 0.00128
SB3 Clip Fraction: 0.01069
Policy Update Magnitude: 0.02073
Value Function Update Magnitude: 0.02159

Collected Steps per Second: 22,963.03383
Overall Steps per Second: 16,935.58138

Timestep Collection Time: 2.17828
Timestep Consumption Time: 0.77526
PPO Batch Consumption Time: 0.05828
Total Iteration Time: 2.95354

Cumulative Model Updates: 13,693
Cumulative Timesteps: 228,575,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,821.01596
Policy Entropy: 0.50053
Value Function Loss: 0.09259

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.01317
Policy Update Magnitude: 0.01915
Value Function Update Magnitude: 0.01875

Collected Steps per Second: 21,772.15596
Overall Steps per Second: 15,510.62802

Timestep Collection Time: 2.29651
Timestep Consumption Time: 0.92708
PPO Batch Consumption Time: 0.10540
Total Iteration Time: 3.22360

Cumulative Model Updates: 13,696
Cumulative Timesteps: 228,625,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 228625768...
Checkpoint 228625768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,235.84320
Policy Entropy: 0.49790
Value Function Loss: 0.09447

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.01707
Value Function Update Magnitude: 0.01919

Collected Steps per Second: 22,328.54267
Overall Steps per Second: 16,354.88519

Timestep Collection Time: 2.24090
Timestep Consumption Time: 0.81849
PPO Batch Consumption Time: 0.06026
Total Iteration Time: 3.05939

Cumulative Model Updates: 13,699
Cumulative Timesteps: 228,675,804

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,375.77511
Policy Entropy: 0.49710
Value Function Loss: 0.09895

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01887
Policy Update Magnitude: 0.01757
Value Function Update Magnitude: 0.02172

Collected Steps per Second: 20,545.66301
Overall Steps per Second: 15,034.57553

Timestep Collection Time: 2.43487
Timestep Consumption Time: 0.89253
PPO Batch Consumption Time: 0.09760
Total Iteration Time: 3.32740

Cumulative Model Updates: 13,702
Cumulative Timesteps: 228,725,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 228725830...
Checkpoint 228725830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,759.83811
Policy Entropy: 0.49579
Value Function Loss: 0.11090

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01869
Policy Update Magnitude: 0.01740
Value Function Update Magnitude: 0.02104

Collected Steps per Second: 22,775.56957
Overall Steps per Second: 16,770.79145

Timestep Collection Time: 2.19613
Timestep Consumption Time: 0.78632
PPO Batch Consumption Time: 0.05812
Total Iteration Time: 2.98245

Cumulative Model Updates: 13,705
Cumulative Timesteps: 228,775,848

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,354.02620
Policy Entropy: 0.50040
Value Function Loss: 0.10463

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01780
Policy Update Magnitude: 0.01728
Value Function Update Magnitude: 0.02389

Collected Steps per Second: 20,001.27142
Overall Steps per Second: 14,024.98907

Timestep Collection Time: 2.50114
Timestep Consumption Time: 1.06578
PPO Batch Consumption Time: 0.12576
Total Iteration Time: 3.56692

Cumulative Model Updates: 13,708
Cumulative Timesteps: 228,825,874

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 228825874...
Checkpoint 228825874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,257.24238
Policy Entropy: 0.50076
Value Function Loss: 0.10727

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.00861
Policy Update Magnitude: 0.01798
Value Function Update Magnitude: 0.02849

Collected Steps per Second: 22,771.13732
Overall Steps per Second: 15,630.73439

Timestep Collection Time: 2.19638
Timestep Consumption Time: 1.00334
PPO Batch Consumption Time: 0.11960
Total Iteration Time: 3.19972

Cumulative Model Updates: 13,711
Cumulative Timesteps: 228,875,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,185.09909
Policy Entropy: 0.50610
Value Function Loss: 0.09629

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.00896
Policy Update Magnitude: 0.01737
Value Function Update Magnitude: 0.02876

Collected Steps per Second: 22,867.93571
Overall Steps per Second: 16,825.38813

Timestep Collection Time: 2.18769
Timestep Consumption Time: 0.78567
PPO Batch Consumption Time: 0.05844
Total Iteration Time: 2.97336

Cumulative Model Updates: 13,714
Cumulative Timesteps: 228,925,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 228925916...
Checkpoint 228925916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,897.09335
Policy Entropy: 0.50298
Value Function Loss: 0.11452

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01602
Policy Update Magnitude: 0.01837
Value Function Update Magnitude: 0.02531

Collected Steps per Second: 21,203.28876
Overall Steps per Second: 14,744.62161

Timestep Collection Time: 2.35831
Timestep Consumption Time: 1.03302
PPO Batch Consumption Time: 0.03194
Total Iteration Time: 3.39134

Cumulative Model Updates: 13,717
Cumulative Timesteps: 228,975,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,041.22252
Policy Entropy: 0.50166
Value Function Loss: 0.11417

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.02104
Policy Update Magnitude: 0.01846
Value Function Update Magnitude: 0.02660

Collected Steps per Second: 22,595.31693
Overall Steps per Second: 16,621.71074

Timestep Collection Time: 2.21338
Timestep Consumption Time: 0.79546
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 3.00884

Cumulative Model Updates: 13,720
Cumulative Timesteps: 229,025,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 229025932...
Checkpoint 229025932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,436.90596
Policy Entropy: 0.50062
Value Function Loss: 0.11657

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01880
Policy Update Magnitude: 0.01836
Value Function Update Magnitude: 0.02526

Collected Steps per Second: 19,677.69357
Overall Steps per Second: 14,068.46778

Timestep Collection Time: 2.54176
Timestep Consumption Time: 1.01342
PPO Batch Consumption Time: 0.12435
Total Iteration Time: 3.55518

Cumulative Model Updates: 13,723
Cumulative Timesteps: 229,075,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,707.99717
Policy Entropy: 0.49767
Value Function Loss: 0.10549

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01842
Policy Update Magnitude: 0.01913
Value Function Update Magnitude: 0.02658

Collected Steps per Second: 24,014.97010
Overall Steps per Second: 16,453.69584

Timestep Collection Time: 2.08228
Timestep Consumption Time: 0.95691
PPO Batch Consumption Time: 0.10635
Total Iteration Time: 3.03920

Cumulative Model Updates: 13,726
Cumulative Timesteps: 229,125,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 229125954...
Checkpoint 229125954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,384.07560
Policy Entropy: 0.49860
Value Function Loss: 0.10114

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01499
Policy Update Magnitude: 0.01935
Value Function Update Magnitude: 0.02379

Collected Steps per Second: 23,044.42571
Overall Steps per Second: 16,902.83090

Timestep Collection Time: 2.16981
Timestep Consumption Time: 0.78839
PPO Batch Consumption Time: 0.05856
Total Iteration Time: 2.95820

Cumulative Model Updates: 13,729
Cumulative Timesteps: 229,175,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,168.47787
Policy Entropy: 0.50027
Value Function Loss: 0.09791

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02767
Policy Update Magnitude: 0.01810
Value Function Update Magnitude: 0.02197

Collected Steps per Second: 19,321.77966
Overall Steps per Second: 14,458.03452

Timestep Collection Time: 2.58931
Timestep Consumption Time: 0.87105
PPO Batch Consumption Time: 0.07327
Total Iteration Time: 3.46036

Cumulative Model Updates: 13,732
Cumulative Timesteps: 229,225,986

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 229225986...
Checkpoint 229225986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,745.50761
Policy Entropy: 0.50678
Value Function Loss: 0.09653

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.01936
Value Function Update Magnitude: 0.02138

Collected Steps per Second: 22,353.47359
Overall Steps per Second: 16,062.81672

Timestep Collection Time: 2.23688
Timestep Consumption Time: 0.87603
PPO Batch Consumption Time: 0.10529
Total Iteration Time: 3.11290

Cumulative Model Updates: 13,735
Cumulative Timesteps: 229,275,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,279.08973
Policy Entropy: 0.51001
Value Function Loss: 0.09086

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04305
Policy Update Magnitude: 0.01710
Value Function Update Magnitude: 0.02301

Collected Steps per Second: 21,186.03496
Overall Steps per Second: 15,604.54928

Timestep Collection Time: 2.36033
Timestep Consumption Time: 0.84425
PPO Batch Consumption Time: 0.08903
Total Iteration Time: 3.20458

Cumulative Model Updates: 13,738
Cumulative Timesteps: 229,325,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 229325994...
Checkpoint 229325994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,225.99997
Policy Entropy: 0.50985
Value Function Loss: 0.09771

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03215
Policy Update Magnitude: 0.01871
Value Function Update Magnitude: 0.02855

Collected Steps per Second: 21,483.10737
Overall Steps per Second: 15,967.67296

Timestep Collection Time: 2.32871
Timestep Consumption Time: 0.80437
PPO Batch Consumption Time: 0.06926
Total Iteration Time: 3.13308

Cumulative Model Updates: 13,741
Cumulative Timesteps: 229,376,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,863.55086
Policy Entropy: 0.50445
Value Function Loss: 0.09655

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02241
Policy Update Magnitude: 0.01942
Value Function Update Magnitude: 0.04685

Collected Steps per Second: 23,259.71492
Overall Steps per Second: 16,989.71173

Timestep Collection Time: 2.15093
Timestep Consumption Time: 0.79379
PPO Batch Consumption Time: 0.06510
Total Iteration Time: 2.94472

Cumulative Model Updates: 13,744
Cumulative Timesteps: 229,426,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 229426052...
Checkpoint 229426052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,690.53188
Policy Entropy: 0.50334
Value Function Loss: 0.10530

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01751
Policy Update Magnitude: 0.01963
Value Function Update Magnitude: 0.02768

Collected Steps per Second: 22,643.77760
Overall Steps per Second: 16,532.30110

Timestep Collection Time: 2.20908
Timestep Consumption Time: 0.81663
PPO Batch Consumption Time: 0.06296
Total Iteration Time: 3.02571

Cumulative Model Updates: 13,747
Cumulative Timesteps: 229,476,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,219.52002
Policy Entropy: 0.50535
Value Function Loss: 0.09714

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01988
Policy Update Magnitude: 0.02028
Value Function Update Magnitude: 0.03833

Collected Steps per Second: 22,718.07426
Overall Steps per Second: 16,705.74827

Timestep Collection Time: 2.20195
Timestep Consumption Time: 0.79247
PPO Batch Consumption Time: 0.06565
Total Iteration Time: 2.99442

Cumulative Model Updates: 13,750
Cumulative Timesteps: 229,526,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 229526098...
Checkpoint 229526098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,296.28323
Policy Entropy: 0.51229
Value Function Loss: 0.09295

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02953
Policy Update Magnitude: 0.02222
Value Function Update Magnitude: 0.03109

Collected Steps per Second: 22,498.89854
Overall Steps per Second: 16,558.53045

Timestep Collection Time: 2.22251
Timestep Consumption Time: 0.79732
PPO Batch Consumption Time: 0.05773
Total Iteration Time: 3.01983

Cumulative Model Updates: 13,753
Cumulative Timesteps: 229,576,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,971.46982
Policy Entropy: 0.51399
Value Function Loss: 0.08782

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04901
Policy Update Magnitude: 0.01932
Value Function Update Magnitude: 0.02660

Collected Steps per Second: 19,910.62911
Overall Steps per Second: 15,202.56688

Timestep Collection Time: 2.51162
Timestep Consumption Time: 0.77782
PPO Batch Consumption Time: 0.04760
Total Iteration Time: 3.28944

Cumulative Model Updates: 13,756
Cumulative Timesteps: 229,626,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 229626110...
Checkpoint 229626110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,998.89672
Policy Entropy: 0.51450
Value Function Loss: 0.09753

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03807
Policy Update Magnitude: 0.01773
Value Function Update Magnitude: 0.02575

Collected Steps per Second: 22,911.53353
Overall Steps per Second: 16,582.42133

Timestep Collection Time: 2.18231
Timestep Consumption Time: 0.83293
PPO Batch Consumption Time: 0.06616
Total Iteration Time: 3.01524

Cumulative Model Updates: 13,759
Cumulative Timesteps: 229,676,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,467.18698
Policy Entropy: 0.51269
Value Function Loss: 0.10423

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04445
Policy Update Magnitude: 0.01837
Value Function Update Magnitude: 0.03751

Collected Steps per Second: 22,306.71320
Overall Steps per Second: 16,349.54346

Timestep Collection Time: 2.24255
Timestep Consumption Time: 0.81710
PPO Batch Consumption Time: 0.05844
Total Iteration Time: 3.05966

Cumulative Model Updates: 13,762
Cumulative Timesteps: 229,726,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 229726134...
Checkpoint 229726134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,293.06813
Policy Entropy: 0.50751
Value Function Loss: 0.10250

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.01699
Value Function Update Magnitude: 0.03087

Collected Steps per Second: 20,266.24174
Overall Steps per Second: 14,754.76181

Timestep Collection Time: 2.46854
Timestep Consumption Time: 0.92210
PPO Batch Consumption Time: 0.09428
Total Iteration Time: 3.39063

Cumulative Model Updates: 13,765
Cumulative Timesteps: 229,776,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,267.30694
Policy Entropy: 0.51271
Value Function Loss: 0.08945

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03543
Policy Update Magnitude: 0.01924
Value Function Update Magnitude: 0.04497

Collected Steps per Second: 23,136.63708
Overall Steps per Second: 16,867.89177

Timestep Collection Time: 2.16237
Timestep Consumption Time: 0.80362
PPO Batch Consumption Time: 0.06094
Total Iteration Time: 2.96599

Cumulative Model Updates: 13,768
Cumulative Timesteps: 229,826,192

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 229826192...
Checkpoint 229826192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,562.55999
Policy Entropy: 0.50999
Value Function Loss: 0.08927

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05291
Policy Update Magnitude: 0.01947
Value Function Update Magnitude: 0.03667

Collected Steps per Second: 19,580.78912
Overall Steps per Second: 14,596.24347

Timestep Collection Time: 2.55393
Timestep Consumption Time: 0.87216
PPO Batch Consumption Time: 0.07695
Total Iteration Time: 3.42609

Cumulative Model Updates: 13,771
Cumulative Timesteps: 229,876,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,890.65187
Policy Entropy: 0.51135
Value Function Loss: 0.09281

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04945
Policy Update Magnitude: 0.01762
Value Function Update Magnitude: 0.03462

Collected Steps per Second: 22,941.64525
Overall Steps per Second: 16,724.41128

Timestep Collection Time: 2.18040
Timestep Consumption Time: 0.81056
PPO Batch Consumption Time: 0.05385
Total Iteration Time: 2.99096

Cumulative Model Updates: 13,774
Cumulative Timesteps: 229,926,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 229926222...
Checkpoint 229926222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,571.49210
Policy Entropy: 0.51645
Value Function Loss: 0.09881

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.07002
Policy Update Magnitude: 0.01884
Value Function Update Magnitude: 0.02903

Collected Steps per Second: 20,202.07812
Overall Steps per Second: 14,774.29178

Timestep Collection Time: 2.47658
Timestep Consumption Time: 0.90985
PPO Batch Consumption Time: 0.08611
Total Iteration Time: 3.38642

Cumulative Model Updates: 13,777
Cumulative Timesteps: 229,976,254

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,782.55656
Policy Entropy: 0.50573
Value Function Loss: 0.10669

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06655
Policy Update Magnitude: 0.01773
Value Function Update Magnitude: 0.02787

Collected Steps per Second: 22,583.27640
Overall Steps per Second: 16,530.20787

Timestep Collection Time: 2.21544
Timestep Consumption Time: 0.81126
PPO Batch Consumption Time: 0.06180
Total Iteration Time: 3.02670

Cumulative Model Updates: 13,780
Cumulative Timesteps: 230,026,286

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 230026286...
Checkpoint 230026286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,914.61940
Policy Entropy: 0.50358
Value Function Loss: 0.11135

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05749
Policy Update Magnitude: 0.01692
Value Function Update Magnitude: 0.02591

Collected Steps per Second: 20,641.56980
Overall Steps per Second: 14,950.02581

Timestep Collection Time: 2.42336
Timestep Consumption Time: 0.92259
PPO Batch Consumption Time: 0.08472
Total Iteration Time: 3.34595

Cumulative Model Updates: 13,783
Cumulative Timesteps: 230,076,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,305.44571
Policy Entropy: 0.50523
Value Function Loss: 0.10477

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04837
Policy Update Magnitude: 0.01783
Value Function Update Magnitude: 0.02672

Collected Steps per Second: 22,803.98766
Overall Steps per Second: 17,000.86136

Timestep Collection Time: 2.19313
Timestep Consumption Time: 0.74861
PPO Batch Consumption Time: 0.06750
Total Iteration Time: 2.94173

Cumulative Model Updates: 13,786
Cumulative Timesteps: 230,126,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 230126320...
Checkpoint 230126320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,280.87830
Policy Entropy: 0.51164
Value Function Loss: 0.10576

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04147
Policy Update Magnitude: 0.01717
Value Function Update Magnitude: 0.02533

Collected Steps per Second: 21,824.11774
Overall Steps per Second: 15,595.03437

Timestep Collection Time: 2.29113
Timestep Consumption Time: 0.91514
PPO Batch Consumption Time: 0.11719
Total Iteration Time: 3.20628

Cumulative Model Updates: 13,789
Cumulative Timesteps: 230,176,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,128.39713
Policy Entropy: 0.50778
Value Function Loss: 0.10241

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02433
Policy Update Magnitude: 0.01841
Value Function Update Magnitude: 0.02446

Collected Steps per Second: 22,650.72431
Overall Steps per Second: 17,066.40151

Timestep Collection Time: 2.20841
Timestep Consumption Time: 0.72262
PPO Batch Consumption Time: 0.06235
Total Iteration Time: 2.93102

Cumulative Model Updates: 13,792
Cumulative Timesteps: 230,226,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 230226344...
Checkpoint 230226344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,902.04438
Policy Entropy: 0.51326
Value Function Loss: 0.10264

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04263
Policy Update Magnitude: 0.01852
Value Function Update Magnitude: 0.02296

Collected Steps per Second: 21,594.95167
Overall Steps per Second: 16,302.21409

Timestep Collection Time: 2.31563
Timestep Consumption Time: 0.75180
PPO Batch Consumption Time: 0.05385
Total Iteration Time: 3.06744

Cumulative Model Updates: 13,795
Cumulative Timesteps: 230,276,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,843.57611
Policy Entropy: 0.51280
Value Function Loss: 0.10313

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03909
Policy Update Magnitude: 0.01717
Value Function Update Magnitude: 0.02102

Collected Steps per Second: 19,945.80829
Overall Steps per Second: 14,744.50371

Timestep Collection Time: 2.50810
Timestep Consumption Time: 0.88476
PPO Batch Consumption Time: 0.08525
Total Iteration Time: 3.39286

Cumulative Model Updates: 13,798
Cumulative Timesteps: 230,326,376

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 230326376...
Checkpoint 230326376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,979.65251
Policy Entropy: 0.51960
Value Function Loss: 0.09719

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03573
Policy Update Magnitude: 0.01791
Value Function Update Magnitude: 0.02185

Collected Steps per Second: 22,057.61863
Overall Steps per Second: 16,587.29118

Timestep Collection Time: 2.26770
Timestep Consumption Time: 0.74786
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 3.01556

Cumulative Model Updates: 13,801
Cumulative Timesteps: 230,376,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,947.21649
Policy Entropy: 0.52174
Value Function Loss: 0.09236

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04355
Policy Update Magnitude: 0.01947
Value Function Update Magnitude: 0.02208

Collected Steps per Second: 20,000.92611
Overall Steps per Second: 14,195.27710

Timestep Collection Time: 2.50078
Timestep Consumption Time: 1.02278
PPO Batch Consumption Time: 0.12635
Total Iteration Time: 3.52357

Cumulative Model Updates: 13,804
Cumulative Timesteps: 230,426,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 230426414...
Checkpoint 230426414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,131.63222
Policy Entropy: 0.52351
Value Function Loss: 0.08980

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04803
Policy Update Magnitude: 0.01988
Value Function Update Magnitude: 0.02185

Collected Steps per Second: 22,915.71272
Overall Steps per Second: 15,645.74916

Timestep Collection Time: 2.18304
Timestep Consumption Time: 1.01437
PPO Batch Consumption Time: 0.11363
Total Iteration Time: 3.19742

Cumulative Model Updates: 13,807
Cumulative Timesteps: 230,476,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,750.29491
Policy Entropy: 0.51164
Value Function Loss: 0.10413

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04438
Policy Update Magnitude: 0.02042
Value Function Update Magnitude: 0.02195

Collected Steps per Second: 23,050.09106
Overall Steps per Second: 16,827.91880

Timestep Collection Time: 2.16980
Timestep Consumption Time: 0.80229
PPO Batch Consumption Time: 0.05894
Total Iteration Time: 2.97208

Cumulative Model Updates: 13,810
Cumulative Timesteps: 230,526,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 230526454...
Checkpoint 230526454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,658.16258
Policy Entropy: 0.51445
Value Function Loss: 0.10146

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04985
Policy Update Magnitude: 0.02003
Value Function Update Magnitude: 0.02632

Collected Steps per Second: 20,015.84865
Overall Steps per Second: 14,682.76913

Timestep Collection Time: 2.49952
Timestep Consumption Time: 0.90788
PPO Batch Consumption Time: 0.08463
Total Iteration Time: 3.40740

Cumulative Model Updates: 13,813
Cumulative Timesteps: 230,576,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,410.10994
Policy Entropy: 0.51989
Value Function Loss: 0.10279

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.04711
Policy Update Magnitude: 0.02384
Value Function Update Magnitude: 0.02670

Collected Steps per Second: 23,284.42825
Overall Steps per Second: 16,867.41255

Timestep Collection Time: 2.14976
Timestep Consumption Time: 0.81785
PPO Batch Consumption Time: 0.06223
Total Iteration Time: 2.96762

Cumulative Model Updates: 13,816
Cumulative Timesteps: 230,626,540

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 230626540...
Checkpoint 230626540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,440.06583
Policy Entropy: 0.51727
Value Function Loss: 0.09904

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08603
Policy Update Magnitude: 0.02482
Value Function Update Magnitude: 0.02937

Collected Steps per Second: 20,088.57098
Overall Steps per Second: 14,693.69744

Timestep Collection Time: 2.48908
Timestep Consumption Time: 0.91388
PPO Batch Consumption Time: 0.09405
Total Iteration Time: 3.40296

Cumulative Model Updates: 13,819
Cumulative Timesteps: 230,676,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,617.51798
Policy Entropy: 0.51394
Value Function Loss: 0.10247

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.02319
Value Function Update Magnitude: 0.02574

Collected Steps per Second: 23,382.83524
Overall Steps per Second: 16,987.12868

Timestep Collection Time: 2.13943
Timestep Consumption Time: 0.80550
PPO Batch Consumption Time: 0.06365
Total Iteration Time: 2.94494

Cumulative Model Updates: 13,822
Cumulative Timesteps: 230,726,568

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 230726568...
Checkpoint 230726568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,362.13393
Policy Entropy: 0.51116
Value Function Loss: 0.10401

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.06470
Policy Update Magnitude: 0.01883
Value Function Update Magnitude: 0.02445

Collected Steps per Second: 23,302.46465
Overall Steps per Second: 16,442.55997

Timestep Collection Time: 2.14638
Timestep Consumption Time: 0.89548
PPO Batch Consumption Time: 0.08536
Total Iteration Time: 3.04186

Cumulative Model Updates: 13,825
Cumulative Timesteps: 230,776,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,785.35365
Policy Entropy: 0.50735
Value Function Loss: 0.09777

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05403
Policy Update Magnitude: 0.01861
Value Function Update Magnitude: 0.02602

Collected Steps per Second: 22,748.24571
Overall Steps per Second: 16,527.43987

Timestep Collection Time: 2.19850
Timestep Consumption Time: 0.82750
PPO Batch Consumption Time: 0.06433
Total Iteration Time: 3.02600

Cumulative Model Updates: 13,828
Cumulative Timesteps: 230,826,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 230826596...
Checkpoint 230826596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,973.56643
Policy Entropy: 0.50545
Value Function Loss: 0.09685

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03669
Policy Update Magnitude: 0.01745
Value Function Update Magnitude: 0.02199

Collected Steps per Second: 20,409.64424
Overall Steps per Second: 15,516.73287

Timestep Collection Time: 2.45012
Timestep Consumption Time: 0.77260
PPO Batch Consumption Time: 0.04411
Total Iteration Time: 3.22271

Cumulative Model Updates: 13,831
Cumulative Timesteps: 230,876,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,048.21713
Policy Entropy: 0.50789
Value Function Loss: 0.09424

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02783
Policy Update Magnitude: 0.01886
Value Function Update Magnitude: 0.02102

Collected Steps per Second: 23,282.50438
Overall Steps per Second: 17,460.25777

Timestep Collection Time: 2.14762
Timestep Consumption Time: 0.71614
PPO Batch Consumption Time: 0.02904
Total Iteration Time: 2.86376

Cumulative Model Updates: 13,834
Cumulative Timesteps: 230,926,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 230926604...
Checkpoint 230926604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,829.42482
Policy Entropy: 0.50770
Value Function Loss: 0.09243

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.02018
Value Function Update Magnitude: 0.02197

Collected Steps per Second: 21,855.18830
Overall Steps per Second: 15,504.63500

Timestep Collection Time: 2.28953
Timestep Consumption Time: 0.93777
PPO Batch Consumption Time: 0.09969
Total Iteration Time: 3.22729

Cumulative Model Updates: 13,837
Cumulative Timesteps: 230,976,642

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,197.65820
Policy Entropy: 0.50522
Value Function Loss: 0.09576

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03643
Policy Update Magnitude: 0.01954
Value Function Update Magnitude: 0.01932

Collected Steps per Second: 22,319.05817
Overall Steps per Second: 16,883.46784

Timestep Collection Time: 2.24024
Timestep Consumption Time: 0.72124
PPO Batch Consumption Time: 0.05923
Total Iteration Time: 2.96148

Cumulative Model Updates: 13,840
Cumulative Timesteps: 231,026,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 231026642...
Checkpoint 231026642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,517.03627
Policy Entropy: 0.50801
Value Function Loss: 0.09323

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03541
Policy Update Magnitude: 0.01911
Value Function Update Magnitude: 0.01801

Collected Steps per Second: 20,613.57004
Overall Steps per Second: 15,505.67893

Timestep Collection Time: 2.42627
Timestep Consumption Time: 0.79926
PPO Batch Consumption Time: 0.08093
Total Iteration Time: 3.22553

Cumulative Model Updates: 13,843
Cumulative Timesteps: 231,076,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,458.43518
Policy Entropy: 0.50740
Value Function Loss: 0.09724

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03805
Policy Update Magnitude: 0.01925
Value Function Update Magnitude: 0.02007

Collected Steps per Second: 22,284.26454
Overall Steps per Second: 16,883.17133

Timestep Collection Time: 2.24445
Timestep Consumption Time: 0.71802
PPO Batch Consumption Time: 0.06100
Total Iteration Time: 2.96248

Cumulative Model Updates: 13,846
Cumulative Timesteps: 231,126,672

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 231126672...
Checkpoint 231126672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,161.15000
Policy Entropy: 0.50622
Value Function Loss: 0.09654

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06827
Policy Update Magnitude: 0.01868
Value Function Update Magnitude: 0.01870

Collected Steps per Second: 19,648.69982
Overall Steps per Second: 14,655.20857

Timestep Collection Time: 2.54500
Timestep Consumption Time: 0.86716
PPO Batch Consumption Time: 0.08395
Total Iteration Time: 3.41217

Cumulative Model Updates: 13,849
Cumulative Timesteps: 231,176,678

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,282.22957
Policy Entropy: 0.50082
Value Function Loss: 0.10312

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04792
Policy Update Magnitude: 0.01893
Value Function Update Magnitude: 0.02804

Collected Steps per Second: 23,269.67014
Overall Steps per Second: 17,006.67318

Timestep Collection Time: 2.14932
Timestep Consumption Time: 0.79152
PPO Batch Consumption Time: 0.06255
Total Iteration Time: 2.94085

Cumulative Model Updates: 13,852
Cumulative Timesteps: 231,226,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 231226692...
Checkpoint 231226692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,416.86245
Policy Entropy: 0.49774
Value Function Loss: 0.10636

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.05197
Policy Update Magnitude: 0.01920
Value Function Update Magnitude: 0.02979

Collected Steps per Second: 23,133.64482
Overall Steps per Second: 16,791.46663

Timestep Collection Time: 2.16170
Timestep Consumption Time: 0.81648
PPO Batch Consumption Time: 0.07303
Total Iteration Time: 2.97818

Cumulative Model Updates: 13,855
Cumulative Timesteps: 231,276,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,146.89261
Policy Entropy: 0.49740
Value Function Loss: 0.11175

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03405
Policy Update Magnitude: 0.01915
Value Function Update Magnitude: 0.02741

Collected Steps per Second: 22,658.25281
Overall Steps per Second: 16,753.98407

Timestep Collection Time: 2.20803
Timestep Consumption Time: 0.77813
PPO Batch Consumption Time: 0.06417
Total Iteration Time: 2.98616

Cumulative Model Updates: 13,858
Cumulative Timesteps: 231,326,730

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 231326730...
Checkpoint 231326730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,735.69224
Policy Entropy: 0.49551
Value Function Loss: 0.12040

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.01973
Value Function Update Magnitude: 0.02491

Collected Steps per Second: 22,774.71971
Overall Steps per Second: 16,694.23163

Timestep Collection Time: 2.19542
Timestep Consumption Time: 0.79963
PPO Batch Consumption Time: 0.06009
Total Iteration Time: 2.99505

Cumulative Model Updates: 13,861
Cumulative Timesteps: 231,376,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,900.91902
Policy Entropy: 0.50070
Value Function Loss: 0.11164

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 0.02075
Value Function Update Magnitude: 0.02485

Collected Steps per Second: 20,629.26898
Overall Steps per Second: 15,188.12263

Timestep Collection Time: 2.42539
Timestep Consumption Time: 0.86890
PPO Batch Consumption Time: 0.07984
Total Iteration Time: 3.29428

Cumulative Model Updates: 13,864
Cumulative Timesteps: 231,426,764

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 231426764...
Checkpoint 231426764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,393.21319
Policy Entropy: 0.49932
Value Function Loss: 0.11753

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.03005
Policy Update Magnitude: 0.02003
Value Function Update Magnitude: 0.02390

Collected Steps per Second: 21,821.94433
Overall Steps per Second: 15,107.23610

Timestep Collection Time: 2.29228
Timestep Consumption Time: 1.01885
PPO Batch Consumption Time: 0.12488
Total Iteration Time: 3.31113

Cumulative Model Updates: 13,867
Cumulative Timesteps: 231,476,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,029.59638
Policy Entropy: 0.49837
Value Function Loss: 0.10494

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03661
Policy Update Magnitude: 0.02091
Value Function Update Magnitude: 0.02306

Collected Steps per Second: 22,410.47110
Overall Steps per Second: 16,248.17295

Timestep Collection Time: 2.23271
Timestep Consumption Time: 0.84678
PPO Batch Consumption Time: 0.07408
Total Iteration Time: 3.07948

Cumulative Model Updates: 13,870
Cumulative Timesteps: 231,526,822

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 231526822...
Checkpoint 231526822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,625.76471
Policy Entropy: 0.49268
Value Function Loss: 0.10990

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02906
Policy Update Magnitude: 0.01869
Value Function Update Magnitude: 0.02410

Collected Steps per Second: 21,567.80145
Overall Steps per Second: 15,169.51217

Timestep Collection Time: 2.31827
Timestep Consumption Time: 0.97781
PPO Batch Consumption Time: 0.11001
Total Iteration Time: 3.29608

Cumulative Model Updates: 13,873
Cumulative Timesteps: 231,576,822

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,401.06534
Policy Entropy: 0.50077
Value Function Loss: 0.09575

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02613
Policy Update Magnitude: 0.01980
Value Function Update Magnitude: 0.02410

Collected Steps per Second: 22,708.51080
Overall Steps per Second: 15,869.93754

Timestep Collection Time: 2.20393
Timestep Consumption Time: 0.94970
PPO Batch Consumption Time: 0.10237
Total Iteration Time: 3.15364

Cumulative Model Updates: 13,876
Cumulative Timesteps: 231,626,870

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 231626870...
Checkpoint 231626870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,137.30080
Policy Entropy: 0.50286
Value Function Loss: 0.09502

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04604
Policy Update Magnitude: 0.01891
Value Function Update Magnitude: 0.02215

Collected Steps per Second: 22,888.89187
Overall Steps per Second: 16,699.70363

Timestep Collection Time: 2.18543
Timestep Consumption Time: 0.80996
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 2.99538

Cumulative Model Updates: 13,879
Cumulative Timesteps: 231,676,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,034.15078
Policy Entropy: 0.50510
Value Function Loss: 0.09408

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03677
Policy Update Magnitude: 0.01657
Value Function Update Magnitude: 0.02062

Collected Steps per Second: 20,479.07187
Overall Steps per Second: 14,793.86082

Timestep Collection Time: 2.44201
Timestep Consumption Time: 0.93845
PPO Batch Consumption Time: 0.10219
Total Iteration Time: 3.38046

Cumulative Model Updates: 13,882
Cumulative Timesteps: 231,726,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 231726902...
Checkpoint 231726902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,126.96316
Policy Entropy: 0.49436
Value Function Loss: 0.10336

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03839
Policy Update Magnitude: 0.01671
Value Function Update Magnitude: 0.02182

Collected Steps per Second: 21,873.30892
Overall Steps per Second: 15,707.16714

Timestep Collection Time: 2.28589
Timestep Consumption Time: 0.89737
PPO Batch Consumption Time: 0.09306
Total Iteration Time: 3.18326

Cumulative Model Updates: 13,885
Cumulative Timesteps: 231,776,902

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,786.88194
Policy Entropy: 0.49140
Value Function Loss: 0.10683

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.04083
Policy Update Magnitude: 0.01741
Value Function Update Magnitude: 0.02441

Collected Steps per Second: 21,818.82729
Overall Steps per Second: 16,610.20479

Timestep Collection Time: 2.29178
Timestep Consumption Time: 0.71866
PPO Batch Consumption Time: 0.05770
Total Iteration Time: 3.01044

Cumulative Model Updates: 13,888
Cumulative Timesteps: 231,826,906

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 231826906...
Checkpoint 231826906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,549.57447
Policy Entropy: 0.49195
Value Function Loss: 0.10512

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.01816
Value Function Update Magnitude: 0.02392

Collected Steps per Second: 18,644.55987
Overall Steps per Second: 14,055.09090

Timestep Collection Time: 2.68389
Timestep Consumption Time: 0.87638
PPO Batch Consumption Time: 0.10251
Total Iteration Time: 3.56028

Cumulative Model Updates: 13,891
Cumulative Timesteps: 231,876,946

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,815.94155
Policy Entropy: 0.48600
Value Function Loss: 0.10403

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03591
Policy Update Magnitude: 0.01971
Value Function Update Magnitude: 0.02379

Collected Steps per Second: 21,983.15618
Overall Steps per Second: 16,659.25068

Timestep Collection Time: 2.27520
Timestep Consumption Time: 0.72710
PPO Batch Consumption Time: 0.05943
Total Iteration Time: 3.00230

Cumulative Model Updates: 13,894
Cumulative Timesteps: 231,926,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 231926962...
Checkpoint 231926962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,269.97652
Policy Entropy: 0.48683
Value Function Loss: 0.10973

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02811
Policy Update Magnitude: 0.01998
Value Function Update Magnitude: 0.02470

Collected Steps per Second: 19,264.62737
Overall Steps per Second: 14,027.16788

Timestep Collection Time: 2.59709
Timestep Consumption Time: 0.96970
PPO Batch Consumption Time: 0.11700
Total Iteration Time: 3.56679

Cumulative Model Updates: 13,897
Cumulative Timesteps: 231,976,994

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,640.73036
Policy Entropy: 0.47943
Value Function Loss: 0.12217

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.03011
Policy Update Magnitude: 0.02105
Value Function Update Magnitude: 0.03413

Collected Steps per Second: 23,146.53010
Overall Steps per Second: 16,907.47242

Timestep Collection Time: 2.16024
Timestep Consumption Time: 0.79715
PPO Batch Consumption Time: 0.06449
Total Iteration Time: 2.95739

Cumulative Model Updates: 13,900
Cumulative Timesteps: 232,026,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 232026996...
Checkpoint 232026996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,828.55687
Policy Entropy: 0.48286
Value Function Loss: 0.12267

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04373
Policy Update Magnitude: 0.01955
Value Function Update Magnitude: 0.04921

Collected Steps per Second: 22,171.86045
Overall Steps per Second: 16,243.77610

Timestep Collection Time: 2.25691
Timestep Consumption Time: 0.82365
PPO Batch Consumption Time: 0.06040
Total Iteration Time: 3.08056

Cumulative Model Updates: 13,903
Cumulative Timesteps: 232,077,036

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,720.71403
Policy Entropy: 0.48785
Value Function Loss: 0.11959

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.02142
Value Function Update Magnitude: 0.03000

Collected Steps per Second: 19,958.91933
Overall Steps per Second: 14,907.01179

Timestep Collection Time: 2.50595
Timestep Consumption Time: 0.84925
PPO Batch Consumption Time: 0.07751
Total Iteration Time: 3.35520

Cumulative Model Updates: 13,906
Cumulative Timesteps: 232,127,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 232127052...
Checkpoint 232127052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,823.00867
Policy Entropy: 0.49173
Value Function Loss: 0.11225

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03183
Policy Update Magnitude: 0.02189
Value Function Update Magnitude: 0.04192

Collected Steps per Second: 23,093.24609
Overall Steps per Second: 16,831.77459

Timestep Collection Time: 2.16514
Timestep Consumption Time: 0.80544
PPO Batch Consumption Time: 0.05811
Total Iteration Time: 2.97057

Cumulative Model Updates: 13,909
Cumulative Timesteps: 232,177,052

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,623.40386
Policy Entropy: 0.49275
Value Function Loss: 0.10788

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.03065
Policy Update Magnitude: 0.02110
Value Function Update Magnitude: 0.03509

Collected Steps per Second: 19,890.15251
Overall Steps per Second: 15,250.17056

Timestep Collection Time: 2.51521
Timestep Consumption Time: 0.76527
PPO Batch Consumption Time: 0.04830
Total Iteration Time: 3.28049

Cumulative Model Updates: 13,912
Cumulative Timesteps: 232,227,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 232227080...
Checkpoint 232227080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,055.11397
Policy Entropy: 0.49227
Value Function Loss: 0.10873

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01979
Policy Update Magnitude: 0.02048
Value Function Update Magnitude: 0.03167

Collected Steps per Second: 22,690.94176
Overall Steps per Second: 16,395.36176

Timestep Collection Time: 2.20467
Timestep Consumption Time: 0.84656
PPO Batch Consumption Time: 0.06926
Total Iteration Time: 3.05123

Cumulative Model Updates: 13,915
Cumulative Timesteps: 232,277,106

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,453.81205
Policy Entropy: 0.48936
Value Function Loss: 0.10359

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.02055
Policy Update Magnitude: 0.01998
Value Function Update Magnitude: 0.03006

Collected Steps per Second: 22,652.37332
Overall Steps per Second: 16,526.97197

Timestep Collection Time: 2.20860
Timestep Consumption Time: 0.81857
PPO Batch Consumption Time: 0.06263
Total Iteration Time: 3.02717

Cumulative Model Updates: 13,918
Cumulative Timesteps: 232,327,136

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 232327136...
Checkpoint 232327136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,094.83250
Policy Entropy: 0.48934
Value Function Loss: 0.10891

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02816
Policy Update Magnitude: 0.01884
Value Function Update Magnitude: 0.02980

Collected Steps per Second: 20,175.64441
Overall Steps per Second: 14,777.00860

Timestep Collection Time: 2.47962
Timestep Consumption Time: 0.90591
PPO Batch Consumption Time: 0.08815
Total Iteration Time: 3.38553

Cumulative Model Updates: 13,921
Cumulative Timesteps: 232,377,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,179.77567
Policy Entropy: 0.48715
Value Function Loss: 0.10875

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02143
Policy Update Magnitude: 0.01944
Value Function Update Magnitude: 0.02864

Collected Steps per Second: 22,535.33561
Overall Steps per Second: 16,521.73902

Timestep Collection Time: 2.22007
Timestep Consumption Time: 0.80806
PPO Batch Consumption Time: 0.06003
Total Iteration Time: 3.02813

Cumulative Model Updates: 13,924
Cumulative Timesteps: 232,427,194

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 232427194...
Checkpoint 232427194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,576.64750
Policy Entropy: 0.49119
Value Function Loss: 0.10325

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03999
Policy Update Magnitude: 0.01828
Value Function Update Magnitude: 0.02638

Collected Steps per Second: 20,013.85772
Overall Steps per Second: 14,821.22062

Timestep Collection Time: 2.49897
Timestep Consumption Time: 0.87552
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 3.37449

Cumulative Model Updates: 13,927
Cumulative Timesteps: 232,477,208

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,587.72539
Policy Entropy: 0.49079
Value Function Loss: 0.09787

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02979
Policy Update Magnitude: 0.01713
Value Function Update Magnitude: 0.02502

Collected Steps per Second: 22,311.97329
Overall Steps per Second: 15,813.67171

Timestep Collection Time: 2.24176
Timestep Consumption Time: 0.92120
PPO Batch Consumption Time: 0.09541
Total Iteration Time: 3.16296

Cumulative Model Updates: 13,930
Cumulative Timesteps: 232,527,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 232527226...
Checkpoint 232527226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,880.41008
Policy Entropy: 0.48909
Value Function Loss: 0.09974

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02783
Policy Update Magnitude: 0.01840
Value Function Update Magnitude: 0.02648

Collected Steps per Second: 21,839.28143
Overall Steps per Second: 16,167.40956

Timestep Collection Time: 2.29119
Timestep Consumption Time: 0.80380
PPO Batch Consumption Time: 0.06293
Total Iteration Time: 3.09499

Cumulative Model Updates: 13,933
Cumulative Timesteps: 232,577,264

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,211.83098
Policy Entropy: 0.49072
Value Function Loss: 0.10293

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02525
Policy Update Magnitude: 0.01724
Value Function Update Magnitude: 0.02549

Collected Steps per Second: 22,462.10553
Overall Steps per Second: 16,465.92834

Timestep Collection Time: 2.22597
Timestep Consumption Time: 0.81060
PPO Batch Consumption Time: 0.05924
Total Iteration Time: 3.03657

Cumulative Model Updates: 13,936
Cumulative Timesteps: 232,627,264

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 232627264...
Checkpoint 232627264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,482.07293
Policy Entropy: 0.49814
Value Function Loss: 0.10373

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01412
Policy Update Magnitude: 0.01724
Value Function Update Magnitude: 0.02514

Collected Steps per Second: 21,021.18635
Overall Steps per Second: 15,513.36962

Timestep Collection Time: 2.37941
Timestep Consumption Time: 0.84478
PPO Batch Consumption Time: 0.09996
Total Iteration Time: 3.22419

Cumulative Model Updates: 13,939
Cumulative Timesteps: 232,677,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,093.04539
Policy Entropy: 0.50422
Value Function Loss: 0.09654

Mean KL Divergence: 0.00099
SB3 Clip Fraction: 0.00773
Policy Update Magnitude: 0.01781
Value Function Update Magnitude: 0.02453

Collected Steps per Second: 22,119.07571
Overall Steps per Second: 16,688.50017

Timestep Collection Time: 2.26194
Timestep Consumption Time: 0.73605
PPO Batch Consumption Time: 0.05987
Total Iteration Time: 2.99799

Cumulative Model Updates: 13,942
Cumulative Timesteps: 232,727,314

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 232727314...
Checkpoint 232727314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,567.17215
Policy Entropy: 0.50404
Value Function Loss: 0.09678

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01447
Policy Update Magnitude: 0.01921
Value Function Update Magnitude: 0.02478

Collected Steps per Second: 19,019.35546
Overall Steps per Second: 13,985.47230

Timestep Collection Time: 2.62953
Timestep Consumption Time: 0.94646
PPO Batch Consumption Time: 0.12771
Total Iteration Time: 3.57600

Cumulative Model Updates: 13,945
Cumulative Timesteps: 232,777,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,212.66852
Policy Entropy: 0.49995
Value Function Loss: 0.09630

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01393
Policy Update Magnitude: 0.02031
Value Function Update Magnitude: 0.02719

Collected Steps per Second: 21,649.09810
Overall Steps per Second: 15,725.15236

Timestep Collection Time: 2.30975
Timestep Consumption Time: 0.87012
PPO Batch Consumption Time: 0.09641
Total Iteration Time: 3.17987

Cumulative Model Updates: 13,948
Cumulative Timesteps: 232,827,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 232827330...
Checkpoint 232827330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,245.62126
Policy Entropy: 0.50605
Value Function Loss: 0.09376

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03979
Policy Update Magnitude: 0.01956
Value Function Update Magnitude: 0.02873

Collected Steps per Second: 23,275.00835
Overall Steps per Second: 17,070.32887

Timestep Collection Time: 2.14840
Timestep Consumption Time: 0.78089
PPO Batch Consumption Time: 0.06447
Total Iteration Time: 2.92929

Cumulative Model Updates: 13,951
Cumulative Timesteps: 232,877,334

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,363.01811
Policy Entropy: 0.51103
Value Function Loss: 0.09035

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.04264
Policy Update Magnitude: 0.01757
Value Function Update Magnitude: 0.02334

Collected Steps per Second: 22,658.32348
Overall Steps per Second: 16,614.11588

Timestep Collection Time: 2.20696
Timestep Consumption Time: 0.80289
PPO Batch Consumption Time: 0.06657
Total Iteration Time: 3.00985

Cumulative Model Updates: 13,954
Cumulative Timesteps: 232,927,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 232927340...
Checkpoint 232927340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,315.51200
Policy Entropy: 0.51397
Value Function Loss: 0.08980

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03301
Policy Update Magnitude: 0.01646
Value Function Update Magnitude: 0.02254

Collected Steps per Second: 22,854.65890
Overall Steps per Second: 16,879.64317

Timestep Collection Time: 2.18914
Timestep Consumption Time: 0.77491
PPO Batch Consumption Time: 0.06403
Total Iteration Time: 2.96404

Cumulative Model Updates: 13,957
Cumulative Timesteps: 232,977,372

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,633.18108
Policy Entropy: 0.50948
Value Function Loss: 0.09392

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02502
Policy Update Magnitude: 0.01797
Value Function Update Magnitude: 0.02189

Collected Steps per Second: 23,237.11360
Overall Steps per Second: 16,822.27603

Timestep Collection Time: 2.15268
Timestep Consumption Time: 0.82088
PPO Batch Consumption Time: 0.06888
Total Iteration Time: 2.97356

Cumulative Model Updates: 13,960
Cumulative Timesteps: 233,027,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 233027394...
Checkpoint 233027394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,866.54645
Policy Entropy: 0.50686
Value Function Loss: 0.10555

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.01775
Value Function Update Magnitude: 0.02047

Collected Steps per Second: 22,668.69270
Overall Steps per Second: 16,287.22270

Timestep Collection Time: 2.20569
Timestep Consumption Time: 0.86421
PPO Batch Consumption Time: 0.06018
Total Iteration Time: 3.06989

Cumulative Model Updates: 13,963
Cumulative Timesteps: 233,077,394

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,557.46224
Policy Entropy: 0.50411
Value Function Loss: 0.10940

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02381
Policy Update Magnitude: 0.01982
Value Function Update Magnitude: 0.02429

Collected Steps per Second: 17,879.49107
Overall Steps per Second: 14,116.21951

Timestep Collection Time: 2.79784
Timestep Consumption Time: 0.74588
PPO Batch Consumption Time: 0.04641
Total Iteration Time: 3.54373

Cumulative Model Updates: 13,966
Cumulative Timesteps: 233,127,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 233127418...
Checkpoint 233127418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,362.44724
Policy Entropy: 0.50360
Value Function Loss: 0.11133

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.04039
Policy Update Magnitude: 0.02184
Value Function Update Magnitude: 0.02469

Collected Steps per Second: 21,900.19098
Overall Steps per Second: 15,487.36284

Timestep Collection Time: 2.28382
Timestep Consumption Time: 0.94566
PPO Batch Consumption Time: 0.10204
Total Iteration Time: 3.22947

Cumulative Model Updates: 13,969
Cumulative Timesteps: 233,177,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,410.63656
Policy Entropy: 0.50688
Value Function Loss: 0.10011

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03733
Policy Update Magnitude: 0.02093
Value Function Update Magnitude: 0.02569

Collected Steps per Second: 22,454.58827
Overall Steps per Second: 16,426.29789

Timestep Collection Time: 2.22814
Timestep Consumption Time: 0.81771
PPO Batch Consumption Time: 0.06388
Total Iteration Time: 3.04585

Cumulative Model Updates: 13,972
Cumulative Timesteps: 233,227,466

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 233227466...
Checkpoint 233227466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,159.48249
Policy Entropy: 0.50584
Value Function Loss: 0.10021

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.04016
Policy Update Magnitude: 0.01868
Value Function Update Magnitude: 0.02994

Collected Steps per Second: 20,336.15185
Overall Steps per Second: 14,228.32945

Timestep Collection Time: 2.45976
Timestep Consumption Time: 1.05590
PPO Batch Consumption Time: 0.13104
Total Iteration Time: 3.51566

Cumulative Model Updates: 13,975
Cumulative Timesteps: 233,277,488

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,916.38147
Policy Entropy: 0.50437
Value Function Loss: 0.08831

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03136
Policy Update Magnitude: 0.01724
Value Function Update Magnitude: 0.03124

Collected Steps per Second: 23,687.20652
Overall Steps per Second: 16,972.36650

Timestep Collection Time: 2.11186
Timestep Consumption Time: 0.83552
PPO Batch Consumption Time: 0.07011
Total Iteration Time: 2.94738

Cumulative Model Updates: 13,978
Cumulative Timesteps: 233,327,512

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 233327512...
Checkpoint 233327512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,475.97769
Policy Entropy: 0.50564
Value Function Loss: 0.09384

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03008
Policy Update Magnitude: 0.01670
Value Function Update Magnitude: 0.02751

Collected Steps per Second: 23,062.67407
Overall Steps per Second: 16,701.83328

Timestep Collection Time: 2.16922
Timestep Consumption Time: 0.82614
PPO Batch Consumption Time: 0.06523
Total Iteration Time: 2.99536

Cumulative Model Updates: 13,981
Cumulative Timesteps: 233,377,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,960.25871
Policy Entropy: 0.50193
Value Function Loss: 0.09826

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02952
Policy Update Magnitude: 0.01813
Value Function Update Magnitude: 0.02635

Collected Steps per Second: 22,163.35160
Overall Steps per Second: 15,913.09337

Timestep Collection Time: 2.25625
Timestep Consumption Time: 0.88620
PPO Batch Consumption Time: 0.08368
Total Iteration Time: 3.14244

Cumulative Model Updates: 13,984
Cumulative Timesteps: 233,427,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 233427546...
Checkpoint 233427546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,164.66520
Policy Entropy: 0.49965
Value Function Loss: 0.10172

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02890
Policy Update Magnitude: 0.01794
Value Function Update Magnitude: 0.02451

Collected Steps per Second: 22,770.80726
Overall Steps per Second: 16,595.40455

Timestep Collection Time: 2.19658
Timestep Consumption Time: 0.81738
PPO Batch Consumption Time: 0.06299
Total Iteration Time: 3.01397

Cumulative Model Updates: 13,987
Cumulative Timesteps: 233,477,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,344.08293
Policy Entropy: 0.49892
Value Function Loss: 0.09341

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03863
Policy Update Magnitude: 0.01645
Value Function Update Magnitude: 0.02610

Collected Steps per Second: 23,287.50713
Overall Steps per Second: 16,367.61631

Timestep Collection Time: 2.14785
Timestep Consumption Time: 0.90807
PPO Batch Consumption Time: 0.09007
Total Iteration Time: 3.05591

Cumulative Model Updates: 13,990
Cumulative Timesteps: 233,527,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 233527582...
Checkpoint 233527582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,398.37366
Policy Entropy: 0.49986
Value Function Loss: 0.09362

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02504
Policy Update Magnitude: 0.01723
Value Function Update Magnitude: 0.02513

Collected Steps per Second: 22,725.56307
Overall Steps per Second: 15,885.90751

Timestep Collection Time: 2.20140
Timestep Consumption Time: 0.94781
PPO Batch Consumption Time: 0.10671
Total Iteration Time: 3.14921

Cumulative Model Updates: 13,993
Cumulative Timesteps: 233,577,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,895.01172
Policy Entropy: 0.49798
Value Function Loss: 0.10113

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.04027
Policy Update Magnitude: 0.01684
Value Function Update Magnitude: 0.02128

Collected Steps per Second: 23,300.20510
Overall Steps per Second: 16,816.07699

Timestep Collection Time: 2.14719
Timestep Consumption Time: 0.82794
PPO Batch Consumption Time: 0.06671
Total Iteration Time: 2.97513

Cumulative Model Updates: 13,996
Cumulative Timesteps: 233,627,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 233627640...
Checkpoint 233627640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,209.09512
Policy Entropy: 0.50195
Value Function Loss: 0.09558

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04229
Policy Update Magnitude: 0.01716
Value Function Update Magnitude: 0.02495

Collected Steps per Second: 22,814.78089
Overall Steps per Second: 16,683.79377

Timestep Collection Time: 2.19226
Timestep Consumption Time: 0.80562
PPO Batch Consumption Time: 0.06159
Total Iteration Time: 2.99788

Cumulative Model Updates: 13,999
Cumulative Timesteps: 233,677,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,547.58962
Policy Entropy: 0.49803
Value Function Loss: 0.09441

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05745
Policy Update Magnitude: 0.01781
Value Function Update Magnitude: 0.02379

Collected Steps per Second: 20,710.18572
Overall Steps per Second: 14,646.27624

Timestep Collection Time: 2.41514
Timestep Consumption Time: 0.99993
PPO Batch Consumption Time: 0.11996
Total Iteration Time: 3.41507

Cumulative Model Updates: 14,002
Cumulative Timesteps: 233,727,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 233727674...
Checkpoint 233727674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,595.30852
Policy Entropy: 0.50043
Value Function Loss: 0.08910

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05814
Policy Update Magnitude: 0.01703
Value Function Update Magnitude: 0.02488

Collected Steps per Second: 21,336.39023
Overall Steps per Second: 15,794.11018

Timestep Collection Time: 2.34416
Timestep Consumption Time: 0.82259
PPO Batch Consumption Time: 0.09602
Total Iteration Time: 3.16675

Cumulative Model Updates: 14,005
Cumulative Timesteps: 233,777,690

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,751.42987
Policy Entropy: 0.49110
Value Function Loss: 0.10493

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04863
Policy Update Magnitude: 0.02085
Value Function Update Magnitude: 0.04083

Collected Steps per Second: 22,718.42443
Overall Steps per Second: 17,071.38917

Timestep Collection Time: 2.20253
Timestep Consumption Time: 0.72857
PPO Batch Consumption Time: 0.06503
Total Iteration Time: 2.93110

Cumulative Model Updates: 14,008
Cumulative Timesteps: 233,827,728

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 233827728...
Checkpoint 233827728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,313.22116
Policy Entropy: 0.49545
Value Function Loss: 0.11227

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.02381
Value Function Update Magnitude: 0.05089

Collected Steps per Second: 22,238.13320
Overall Steps per Second: 16,747.55236

Timestep Collection Time: 2.24974
Timestep Consumption Time: 0.73756
PPO Batch Consumption Time: 0.06294
Total Iteration Time: 2.98730

Cumulative Model Updates: 14,011
Cumulative Timesteps: 233,877,758

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,797.76198
Policy Entropy: 0.49369
Value Function Loss: 0.10862

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09329
Policy Update Magnitude: 0.01941
Value Function Update Magnitude: 0.03333

Collected Steps per Second: 22,215.20108
Overall Steps per Second: 16,774.28546

Timestep Collection Time: 2.25161
Timestep Consumption Time: 0.73033
PPO Batch Consumption Time: 0.06246
Total Iteration Time: 2.98195

Cumulative Model Updates: 14,014
Cumulative Timesteps: 233,927,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 233927778...
Checkpoint 233927778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,278.82261
Policy Entropy: 0.49891
Value Function Loss: 0.10425

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07887
Policy Update Magnitude: 0.01718
Value Function Update Magnitude: 0.04810

Collected Steps per Second: 22,828.99186
Overall Steps per Second: 16,771.89823

Timestep Collection Time: 2.19064
Timestep Consumption Time: 0.79114
PPO Batch Consumption Time: 0.06422
Total Iteration Time: 2.98177

Cumulative Model Updates: 14,017
Cumulative Timesteps: 233,977,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,230.97936
Policy Entropy: 0.50669
Value Function Loss: 0.09111

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.01760
Value Function Update Magnitude: 0.04436

Collected Steps per Second: 23,379.19344
Overall Steps per Second: 17,101.91985

Timestep Collection Time: 2.14002
Timestep Consumption Time: 0.78550
PPO Batch Consumption Time: 0.06264
Total Iteration Time: 2.92552

Cumulative Model Updates: 14,020
Cumulative Timesteps: 234,027,820

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 234027820...
Checkpoint 234027820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,257.58474
Policy Entropy: 0.50681
Value Function Loss: 0.08929

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06709
Policy Update Magnitude: 0.01522
Value Function Update Magnitude: 0.03825

Collected Steps per Second: 19,884.08822
Overall Steps per Second: 14,200.19901

Timestep Collection Time: 2.51477
Timestep Consumption Time: 1.00658
PPO Batch Consumption Time: 0.12146
Total Iteration Time: 3.52136

Cumulative Model Updates: 14,023
Cumulative Timesteps: 234,077,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,065.09717
Policy Entropy: 0.50383
Value Function Loss: 0.07487

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05663
Policy Update Magnitude: 0.01595
Value Function Update Magnitude: 0.03643

Collected Steps per Second: 23,397.38772
Overall Steps per Second: 16,613.09075

Timestep Collection Time: 2.13742
Timestep Consumption Time: 0.87286
PPO Batch Consumption Time: 0.07815
Total Iteration Time: 3.01028

Cumulative Model Updates: 14,026
Cumulative Timesteps: 234,127,834

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 234127834...
Checkpoint 234127834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,592.84475
Policy Entropy: 0.49833
Value Function Loss: 0.08123

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05561
Policy Update Magnitude: 0.01607
Value Function Update Magnitude: 0.04391

Collected Steps per Second: 23,044.07050
Overall Steps per Second: 15,760.06399

Timestep Collection Time: 2.17114
Timestep Consumption Time: 1.00346
PPO Batch Consumption Time: 0.12238
Total Iteration Time: 3.17461

Cumulative Model Updates: 14,029
Cumulative Timesteps: 234,177,866

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,175.17370
Policy Entropy: 0.49192
Value Function Loss: 0.08059

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.04075
Policy Update Magnitude: 0.01644
Value Function Update Magnitude: 0.03887

Collected Steps per Second: 23,305.61567
Overall Steps per Second: 16,916.58678

Timestep Collection Time: 2.14609
Timestep Consumption Time: 0.81053
PPO Batch Consumption Time: 0.06278
Total Iteration Time: 2.95662

Cumulative Model Updates: 14,032
Cumulative Timesteps: 234,227,882

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 234227882...
Checkpoint 234227882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,906.84928
Policy Entropy: 0.48733
Value Function Loss: 0.08813

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04679
Policy Update Magnitude: 0.01793
Value Function Update Magnitude: 0.03866

Collected Steps per Second: 23,002.82889
Overall Steps per Second: 16,730.60969

Timestep Collection Time: 2.17460
Timestep Consumption Time: 0.81525
PPO Batch Consumption Time: 0.06473
Total Iteration Time: 2.98985

Cumulative Model Updates: 14,035
Cumulative Timesteps: 234,277,904

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,778.35497
Policy Entropy: 0.49038
Value Function Loss: 0.08830

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.06052
Policy Update Magnitude: 0.01725
Value Function Update Magnitude: 0.03900

Collected Steps per Second: 23,050.73919
Overall Steps per Second: 16,703.43000

Timestep Collection Time: 2.16921
Timestep Consumption Time: 0.82430
PPO Batch Consumption Time: 0.06289
Total Iteration Time: 2.99352

Cumulative Model Updates: 14,038
Cumulative Timesteps: 234,327,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 234327906...
Checkpoint 234327906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,917.93489
Policy Entropy: 0.49659
Value Function Loss: 0.08557

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04369
Policy Update Magnitude: 0.01770
Value Function Update Magnitude: 0.03759

Collected Steps per Second: 22,548.37088
Overall Steps per Second: 16,319.22440

Timestep Collection Time: 2.21746
Timestep Consumption Time: 0.84642
PPO Batch Consumption Time: 0.06092
Total Iteration Time: 3.06387

Cumulative Model Updates: 14,041
Cumulative Timesteps: 234,377,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,011.20228
Policy Entropy: 0.49215
Value Function Loss: 0.08944

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.06023
Policy Update Magnitude: 0.01888
Value Function Update Magnitude: 0.04054

Collected Steps per Second: 19,199.73584
Overall Steps per Second: 14,094.05333

Timestep Collection Time: 2.60451
Timestep Consumption Time: 0.94351
PPO Batch Consumption Time: 0.09832
Total Iteration Time: 3.54802

Cumulative Model Updates: 14,044
Cumulative Timesteps: 234,427,912

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 234427912...
Checkpoint 234427912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,889.09621
Policy Entropy: 0.48762
Value Function Loss: 0.10338

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04928
Policy Update Magnitude: 0.01834
Value Function Update Magnitude: 0.03647

Collected Steps per Second: 23,028.19153
Overall Steps per Second: 16,832.75848

Timestep Collection Time: 2.17143
Timestep Consumption Time: 0.79921
PPO Batch Consumption Time: 0.05965
Total Iteration Time: 2.97064

Cumulative Model Updates: 14,047
Cumulative Timesteps: 234,477,916

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,353.07535
Policy Entropy: 0.48708
Value Function Loss: 0.10491

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.05203
Policy Update Magnitude: 0.01891
Value Function Update Magnitude: 0.04649

Collected Steps per Second: 20,418.47345
Overall Steps per Second: 14,678.47287

Timestep Collection Time: 2.45111
Timestep Consumption Time: 0.95851
PPO Batch Consumption Time: 0.10339
Total Iteration Time: 3.40962

Cumulative Model Updates: 14,050
Cumulative Timesteps: 234,527,964

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 234527964...
Checkpoint 234527964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,609.49016
Policy Entropy: 0.49484
Value Function Loss: 0.10385

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.04303
Policy Update Magnitude: 0.01881
Value Function Update Magnitude: 0.04474

Collected Steps per Second: 22,474.05481
Overall Steps per Second: 15,871.52795

Timestep Collection Time: 2.22550
Timestep Consumption Time: 0.92580
PPO Batch Consumption Time: 0.10496
Total Iteration Time: 3.15130

Cumulative Model Updates: 14,053
Cumulative Timesteps: 234,577,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,697.31236
Policy Entropy: 0.49655
Value Function Loss: 0.08537

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04866
Policy Update Magnitude: 0.01865
Value Function Update Magnitude: 0.04295

Collected Steps per Second: 23,478.31362
Overall Steps per Second: 16,875.38915

Timestep Collection Time: 2.13158
Timestep Consumption Time: 0.83404
PPO Batch Consumption Time: 0.06580
Total Iteration Time: 2.96562

Cumulative Model Updates: 14,056
Cumulative Timesteps: 234,628,026

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 234628026...
Checkpoint 234628026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,513.78964
Policy Entropy: 0.49896
Value Function Loss: 0.08369

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04819
Policy Update Magnitude: 0.01742
Value Function Update Magnitude: 0.03725

Collected Steps per Second: 23,246.92130
Overall Steps per Second: 16,868.11718

Timestep Collection Time: 2.15229
Timestep Consumption Time: 0.81390
PPO Batch Consumption Time: 0.06771
Total Iteration Time: 2.96619

Cumulative Model Updates: 14,059
Cumulative Timesteps: 234,678,060

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,596.07541
Policy Entropy: 0.49783
Value Function Loss: 0.08179

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03767
Policy Update Magnitude: 0.02157
Value Function Update Magnitude: 0.03870

Collected Steps per Second: 22,799.22709
Overall Steps per Second: 16,385.33645

Timestep Collection Time: 2.19306
Timestep Consumption Time: 0.85845
PPO Batch Consumption Time: 0.07309
Total Iteration Time: 3.05151

Cumulative Model Updates: 14,062
Cumulative Timesteps: 234,728,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 234728060...
Checkpoint 234728060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,220.73744
Policy Entropy: 0.48785
Value Function Loss: 0.09044

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04597
Policy Update Magnitude: 0.02097
Value Function Update Magnitude: 0.03496

Collected Steps per Second: 22,556.50289
Overall Steps per Second: 16,973.29409

Timestep Collection Time: 2.21710
Timestep Consumption Time: 0.72929
PPO Batch Consumption Time: 0.06270
Total Iteration Time: 2.94639

Cumulative Model Updates: 14,065
Cumulative Timesteps: 234,778,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,367.56192
Policy Entropy: 0.48404
Value Function Loss: 0.10005

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03597
Policy Update Magnitude: 0.01854
Value Function Update Magnitude: 0.04301

Collected Steps per Second: 22,887.14445
Overall Steps per Second: 17,099.58422

Timestep Collection Time: 2.18533
Timestep Consumption Time: 0.73965
PPO Batch Consumption Time: 0.06560
Total Iteration Time: 2.92498

Cumulative Model Updates: 14,068
Cumulative Timesteps: 234,828,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 234828086...
Checkpoint 234828086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,879.03497
Policy Entropy: 0.48606
Value Function Loss: 0.09757

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02375
Policy Update Magnitude: 0.01856
Value Function Update Magnitude: 0.04236

Collected Steps per Second: 19,632.57249
Overall Steps per Second: 14,332.28615

Timestep Collection Time: 2.54821
Timestep Consumption Time: 0.94237
PPO Batch Consumption Time: 0.12550
Total Iteration Time: 3.49058

Cumulative Model Updates: 14,071
Cumulative Timesteps: 234,878,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,007.84651
Policy Entropy: 0.48299
Value Function Loss: 0.09944

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03535
Policy Update Magnitude: 0.02095
Value Function Update Magnitude: 0.04198

Collected Steps per Second: 22,544.62822
Overall Steps per Second: 16,630.95804

Timestep Collection Time: 2.21836
Timestep Consumption Time: 0.78881
PPO Batch Consumption Time: 0.07720
Total Iteration Time: 3.00716

Cumulative Model Updates: 14,074
Cumulative Timesteps: 234,928,126

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 234928126...
Checkpoint 234928126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,393.85785
Policy Entropy: 0.48445
Value Function Loss: 0.09218

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03537
Policy Update Magnitude: 0.01989
Value Function Update Magnitude: 0.03783

Collected Steps per Second: 22,530.00625
Overall Steps per Second: 16,773.54662

Timestep Collection Time: 2.21953
Timestep Consumption Time: 0.76171
PPO Batch Consumption Time: 0.06098
Total Iteration Time: 2.98124

Cumulative Model Updates: 14,077
Cumulative Timesteps: 234,978,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,970.83691
Policy Entropy: 0.48143
Value Function Loss: 0.09623

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03193
Policy Update Magnitude: 0.01860
Value Function Update Magnitude: 0.03808

Collected Steps per Second: 19,887.30869
Overall Steps per Second: 13,970.28764

Timestep Collection Time: 2.51668
Timestep Consumption Time: 1.06592
PPO Batch Consumption Time: 0.11730
Total Iteration Time: 3.58260

Cumulative Model Updates: 14,080
Cumulative Timesteps: 235,028,182

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 235028182...
Checkpoint 235028182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,268.09440
Policy Entropy: 0.48567
Value Function Loss: 0.08890

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.05499
Policy Update Magnitude: 0.01827
Value Function Update Magnitude: 0.03412

Collected Steps per Second: 22,133.39795
Overall Steps per Second: 16,538.79668

Timestep Collection Time: 2.25984
Timestep Consumption Time: 0.76444
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 3.02428

Cumulative Model Updates: 14,083
Cumulative Timesteps: 235,078,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,009.30847
Policy Entropy: 0.48497
Value Function Loss: 0.10013

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04683
Policy Update Magnitude: 0.01725
Value Function Update Magnitude: 0.03401

Collected Steps per Second: 21,568.59929
Overall Steps per Second: 15,782.53507

Timestep Collection Time: 2.31837
Timestep Consumption Time: 0.84994
PPO Batch Consumption Time: 0.08024
Total Iteration Time: 3.16831

Cumulative Model Updates: 14,086
Cumulative Timesteps: 235,128,204

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 235128204...
Checkpoint 235128204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,553.28028
Policy Entropy: 0.48864
Value Function Loss: 0.09608

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.04037
Policy Update Magnitude: 0.01842
Value Function Update Magnitude: 0.03380

Collected Steps per Second: 22,943.34374
Overall Steps per Second: 16,679.58417

Timestep Collection Time: 2.17989
Timestep Consumption Time: 0.81862
PPO Batch Consumption Time: 0.05992
Total Iteration Time: 2.99852

Cumulative Model Updates: 14,089
Cumulative Timesteps: 235,178,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,637.83138
Policy Entropy: 0.48525
Value Function Loss: 0.09580

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03135
Policy Update Magnitude: 0.01759
Value Function Update Magnitude: 0.04902

Collected Steps per Second: 19,845.90171
Overall Steps per Second: 14,787.45363

Timestep Collection Time: 2.52092
Timestep Consumption Time: 0.86235
PPO Batch Consumption Time: 0.07849
Total Iteration Time: 3.38327

Cumulative Model Updates: 14,092
Cumulative Timesteps: 235,228,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 235228248...
Checkpoint 235228248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,971.40004
Policy Entropy: 0.48009
Value Function Loss: 0.09488

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.02327
Policy Update Magnitude: 0.01839
Value Function Update Magnitude: 0.04682

Collected Steps per Second: 21,224.71259
Overall Steps per Second: 14,874.66238

Timestep Collection Time: 2.35669
Timestep Consumption Time: 1.00608
PPO Batch Consumption Time: 0.12370
Total Iteration Time: 3.36277

Cumulative Model Updates: 14,095
Cumulative Timesteps: 235,278,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,535.10661
Policy Entropy: 0.48249
Value Function Loss: 0.10138

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02638
Policy Update Magnitude: 0.01846
Value Function Update Magnitude: 0.04150

Collected Steps per Second: 21,640.59827
Overall Steps per Second: 15,697.78989

Timestep Collection Time: 2.31112
Timestep Consumption Time: 0.87493
PPO Batch Consumption Time: 0.07216
Total Iteration Time: 3.18605

Cumulative Model Updates: 14,098
Cumulative Timesteps: 235,328,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 235328282...
Checkpoint 235328282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,654.74587
Policy Entropy: 0.48321
Value Function Loss: 0.09695

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02354
Policy Update Magnitude: 0.01767
Value Function Update Magnitude: 0.03307

Collected Steps per Second: 18,360.85944
Overall Steps per Second: 13,979.18147

Timestep Collection Time: 2.72329
Timestep Consumption Time: 0.85360
PPO Batch Consumption Time: 0.06797
Total Iteration Time: 3.57689

Cumulative Model Updates: 14,101
Cumulative Timesteps: 235,378,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,100.93750
Policy Entropy: 0.48869
Value Function Loss: 0.09927

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.02031
Policy Update Magnitude: 0.01775
Value Function Update Magnitude: 0.03799

Collected Steps per Second: 21,950.04101
Overall Steps per Second: 15,604.87712

Timestep Collection Time: 2.27863
Timestep Consumption Time: 0.92652
PPO Batch Consumption Time: 0.09750
Total Iteration Time: 3.20515

Cumulative Model Updates: 14,104
Cumulative Timesteps: 235,428,300

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 235428300...
Checkpoint 235428300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,032.62326
Policy Entropy: 0.48662
Value Function Loss: 0.10712

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01581
Policy Update Magnitude: 0.01836
Value Function Update Magnitude: 0.03611

Collected Steps per Second: 23,008.93350
Overall Steps per Second: 16,050.76995

Timestep Collection Time: 2.17385
Timestep Consumption Time: 0.94239
PPO Batch Consumption Time: 0.09372
Total Iteration Time: 3.11624

Cumulative Model Updates: 14,107
Cumulative Timesteps: 235,478,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,401.15868
Policy Entropy: 0.48951
Value Function Loss: 0.09904

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01955
Policy Update Magnitude: 0.02011
Value Function Update Magnitude: 0.02981

Collected Steps per Second: 19,945.72064
Overall Steps per Second: 15,260.34954

Timestep Collection Time: 2.50710
Timestep Consumption Time: 0.76975
PPO Batch Consumption Time: 0.05073
Total Iteration Time: 3.27686

Cumulative Model Updates: 14,110
Cumulative Timesteps: 235,528,324

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 235528324...
Checkpoint 235528324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,059.00073
Policy Entropy: 0.49461
Value Function Loss: 0.09931

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02630
Policy Update Magnitude: 0.01901
Value Function Update Magnitude: 0.03026

Collected Steps per Second: 21,449.28652
Overall Steps per Second: 14,969.93443

Timestep Collection Time: 2.33201
Timestep Consumption Time: 1.00935
PPO Batch Consumption Time: 0.11837
Total Iteration Time: 3.34136

Cumulative Model Updates: 14,113
Cumulative Timesteps: 235,578,344

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,643.46761
Policy Entropy: 0.49781
Value Function Loss: 0.09214

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.01798
Value Function Update Magnitude: 0.02695

Collected Steps per Second: 23,520.76754
Overall Steps per Second: 16,947.93234

Timestep Collection Time: 2.12587
Timestep Consumption Time: 0.82446
PPO Batch Consumption Time: 0.06547
Total Iteration Time: 2.95033

Cumulative Model Updates: 14,116
Cumulative Timesteps: 235,628,346

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 235628346...
Checkpoint 235628346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,298.40741
Policy Entropy: 0.49530
Value Function Loss: 0.10228

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01917
Policy Update Magnitude: 0.01764
Value Function Update Magnitude: 0.02305

Collected Steps per Second: 22,849.68218
Overall Steps per Second: 16,404.28741

Timestep Collection Time: 2.18839
Timestep Consumption Time: 0.85984
PPO Batch Consumption Time: 0.07605
Total Iteration Time: 3.04823

Cumulative Model Updates: 14,119
Cumulative Timesteps: 235,678,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,429.49037
Policy Entropy: 0.49510
Value Function Loss: 0.10098

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03871
Policy Update Magnitude: 0.01888
Value Function Update Magnitude: 0.02338

Collected Steps per Second: 23,464.08550
Overall Steps per Second: 16,993.68651

Timestep Collection Time: 2.13254
Timestep Consumption Time: 0.81197
PPO Batch Consumption Time: 0.06374
Total Iteration Time: 2.94451

Cumulative Model Updates: 14,122
Cumulative Timesteps: 235,728,388

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 235728388...
Checkpoint 235728388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,211.63150
Policy Entropy: 0.49409
Value Function Loss: 0.09918

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03997
Policy Update Magnitude: 0.01954
Value Function Update Magnitude: 0.02518

Collected Steps per Second: 22,670.60733
Overall Steps per Second: 16,487.16572

Timestep Collection Time: 2.20629
Timestep Consumption Time: 0.82746
PPO Batch Consumption Time: 0.08801
Total Iteration Time: 3.03375

Cumulative Model Updates: 14,125
Cumulative Timesteps: 235,778,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,717.35048
Policy Entropy: 0.49528
Value Function Loss: 0.08985

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03727
Policy Update Magnitude: 0.01899
Value Function Update Magnitude: 0.02520

Collected Steps per Second: 22,240.39771
Overall Steps per Second: 16,814.47912

Timestep Collection Time: 2.24906
Timestep Consumption Time: 0.72576
PPO Batch Consumption Time: 0.05989
Total Iteration Time: 2.97482

Cumulative Model Updates: 14,128
Cumulative Timesteps: 235,828,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 235828426...
Checkpoint 235828426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,422.59396
Policy Entropy: 0.49516
Value Function Loss: 0.08675

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.01824
Value Function Update Magnitude: 0.02457

Collected Steps per Second: 20,011.23226
Overall Steps per Second: 14,739.12338

Timestep Collection Time: 2.49870
Timestep Consumption Time: 0.89377
PPO Batch Consumption Time: 0.10997
Total Iteration Time: 3.39247

Cumulative Model Updates: 14,131
Cumulative Timesteps: 235,878,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,443.53855
Policy Entropy: 0.49652
Value Function Loss: 0.08583

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01972
Policy Update Magnitude: 0.02046
Value Function Update Magnitude: 0.02374

Collected Steps per Second: 23,011.20906
Overall Steps per Second: 17,290.67365

Timestep Collection Time: 2.17407
Timestep Consumption Time: 0.71928
PPO Batch Consumption Time: 0.06172
Total Iteration Time: 2.89335

Cumulative Model Updates: 14,134
Cumulative Timesteps: 235,928,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 235928456...
Checkpoint 235928456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,455.64332
Policy Entropy: 0.49403
Value Function Loss: 0.09077

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01576
Policy Update Magnitude: 0.01926
Value Function Update Magnitude: 0.02136

Collected Steps per Second: 20,771.57583
Overall Steps per Second: 15,208.18114

Timestep Collection Time: 2.40791
Timestep Consumption Time: 0.88085
PPO Batch Consumption Time: 0.08311
Total Iteration Time: 3.28876

Cumulative Model Updates: 14,137
Cumulative Timesteps: 235,978,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,188.59208
Policy Entropy: 0.49100
Value Function Loss: 0.09959

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02397
Policy Update Magnitude: 0.01890
Value Function Update Magnitude: 0.02246

Collected Steps per Second: 23,007.89493
Overall Steps per Second: 16,948.95094

Timestep Collection Time: 2.17386
Timestep Consumption Time: 0.77712
PPO Batch Consumption Time: 0.06164
Total Iteration Time: 2.95098

Cumulative Model Updates: 14,140
Cumulative Timesteps: 236,028,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 236028488...
Checkpoint 236028488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,213.30191
Policy Entropy: 0.48954
Value Function Loss: 0.10026

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.03029
Policy Update Magnitude: 0.01775
Value Function Update Magnitude: 0.02396

Collected Steps per Second: 23,225.90532
Overall Steps per Second: 16,533.55025

Timestep Collection Time: 2.15346
Timestep Consumption Time: 0.87166
PPO Batch Consumption Time: 0.09329
Total Iteration Time: 3.02512

Cumulative Model Updates: 14,143
Cumulative Timesteps: 236,078,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,529.98828
Policy Entropy: 0.49898
Value Function Loss: 0.09870

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.02054
Value Function Update Magnitude: 0.02445

Collected Steps per Second: 23,611.38760
Overall Steps per Second: 17,128.75011

Timestep Collection Time: 2.11830
Timestep Consumption Time: 0.80170
PPO Batch Consumption Time: 0.06256
Total Iteration Time: 2.92000

Cumulative Model Updates: 14,146
Cumulative Timesteps: 236,128,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 236128520...
Checkpoint 236128520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,485.09824
Policy Entropy: 0.50584
Value Function Loss: 0.09023

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.02029
Policy Update Magnitude: 0.02022
Value Function Update Magnitude: 0.02343

Collected Steps per Second: 23,034.99452
Overall Steps per Second: 16,385.47837

Timestep Collection Time: 2.17183
Timestep Consumption Time: 0.88137
PPO Batch Consumption Time: 0.07805
Total Iteration Time: 3.05319

Cumulative Model Updates: 14,149
Cumulative Timesteps: 236,178,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,914.32452
Policy Entropy: 0.51528
Value Function Loss: 0.08754

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03060
Policy Update Magnitude: 0.01877
Value Function Update Magnitude: 0.02032

Collected Steps per Second: 23,452.49730
Overall Steps per Second: 16,948.25339

Timestep Collection Time: 2.13325
Timestep Consumption Time: 0.81868
PPO Batch Consumption Time: 0.06224
Total Iteration Time: 2.95193

Cumulative Model Updates: 14,152
Cumulative Timesteps: 236,228,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 236228578...
Checkpoint 236228578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,743.32351
Policy Entropy: 0.50928
Value Function Loss: 0.08667

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.01846
Value Function Update Magnitude: 0.02496

Collected Steps per Second: 23,415.10391
Overall Steps per Second: 15,621.13503

Timestep Collection Time: 2.13580
Timestep Consumption Time: 1.06563
PPO Batch Consumption Time: 0.12424
Total Iteration Time: 3.20143

Cumulative Model Updates: 14,155
Cumulative Timesteps: 236,278,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,106.58969
Policy Entropy: 0.50967
Value Function Loss: 0.09411

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03647
Policy Update Magnitude: 0.01867
Value Function Update Magnitude: 0.02899

Collected Steps per Second: 23,395.26769
Overall Steps per Second: 16,594.10615

Timestep Collection Time: 2.13821
Timestep Consumption Time: 0.87635
PPO Batch Consumption Time: 0.07636
Total Iteration Time: 3.01456

Cumulative Model Updates: 14,158
Cumulative Timesteps: 236,328,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 236328612...
Checkpoint 236328612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,334.50167
Policy Entropy: 0.51049
Value Function Loss: 0.09063

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.04038
Policy Update Magnitude: 0.01809
Value Function Update Magnitude: 0.03247

Collected Steps per Second: 23,232.78045
Overall Steps per Second: 16,687.57118

Timestep Collection Time: 2.15248
Timestep Consumption Time: 0.84425
PPO Batch Consumption Time: 0.07524
Total Iteration Time: 2.99672

Cumulative Model Updates: 14,161
Cumulative Timesteps: 236,378,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,096.35150
Policy Entropy: 0.51489
Value Function Loss: 0.09395

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02562
Policy Update Magnitude: 0.02031
Value Function Update Magnitude: 0.03021

Collected Steps per Second: 23,440.74641
Overall Steps per Second: 16,551.92887

Timestep Collection Time: 2.13312
Timestep Consumption Time: 0.88779
PPO Batch Consumption Time: 0.08246
Total Iteration Time: 3.02092

Cumulative Model Updates: 14,164
Cumulative Timesteps: 236,428,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 236428622...
Checkpoint 236428622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,166.42426
Policy Entropy: 0.50568
Value Function Loss: 0.09266

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05550
Policy Update Magnitude: 0.02185
Value Function Update Magnitude: 0.03218

Collected Steps per Second: 21,357.92000
Overall Steps per Second: 15,023.23403

Timestep Collection Time: 2.34208
Timestep Consumption Time: 0.98756
PPO Batch Consumption Time: 0.11222
Total Iteration Time: 3.32964

Cumulative Model Updates: 14,167
Cumulative Timesteps: 236,478,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,042.95721
Policy Entropy: 0.50515
Value Function Loss: 0.09762

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04497
Policy Update Magnitude: 0.01974
Value Function Update Magnitude: 0.03344

Collected Steps per Second: 23,220.12105
Overall Steps per Second: 16,882.86710

Timestep Collection Time: 2.15442
Timestep Consumption Time: 0.80870
PPO Batch Consumption Time: 0.06179
Total Iteration Time: 2.96312

Cumulative Model Updates: 14,170
Cumulative Timesteps: 236,528,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 236528670...
Checkpoint 236528670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,731.89577
Policy Entropy: 0.50257
Value Function Loss: 0.09641

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03715
Policy Update Magnitude: 0.02146
Value Function Update Magnitude: 0.02927

Collected Steps per Second: 23,472.97198
Overall Steps per Second: 16,551.33978

Timestep Collection Time: 2.13062
Timestep Consumption Time: 0.89101
PPO Batch Consumption Time: 0.08865
Total Iteration Time: 3.02163

Cumulative Model Updates: 14,173
Cumulative Timesteps: 236,578,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,085.50606
Policy Entropy: 0.51012
Value Function Loss: 0.09354

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.05259
Policy Update Magnitude: 0.01909
Value Function Update Magnitude: 0.02702

Collected Steps per Second: 23,330.41649
Overall Steps per Second: 16,920.99883

Timestep Collection Time: 2.14330
Timestep Consumption Time: 0.81185
PPO Batch Consumption Time: 0.06325
Total Iteration Time: 2.95514

Cumulative Model Updates: 14,176
Cumulative Timesteps: 236,628,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 236628686...
Checkpoint 236628686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,237.66846
Policy Entropy: 0.50300
Value Function Loss: 0.09610

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04925
Policy Update Magnitude: 0.01764
Value Function Update Magnitude: 0.02310

Collected Steps per Second: 22,554.26460
Overall Steps per Second: 15,595.76155

Timestep Collection Time: 2.21741
Timestep Consumption Time: 0.98936
PPO Batch Consumption Time: 0.11561
Total Iteration Time: 3.20677

Cumulative Model Updates: 14,179
Cumulative Timesteps: 236,678,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,537.54065
Policy Entropy: 0.50640
Value Function Loss: 0.10129

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.05141
Policy Update Magnitude: 0.01750
Value Function Update Magnitude: 0.02905

Collected Steps per Second: 23,618.26605
Overall Steps per Second: 16,638.31749

Timestep Collection Time: 2.11802
Timestep Consumption Time: 0.88853
PPO Batch Consumption Time: 0.08619
Total Iteration Time: 3.00655

Cumulative Model Updates: 14,182
Cumulative Timesteps: 236,728,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 236728722...
Checkpoint 236728722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,840.28996
Policy Entropy: 0.50772
Value Function Loss: 0.09423

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03995
Policy Update Magnitude: 0.01760
Value Function Update Magnitude: 0.02614

Collected Steps per Second: 23,350.78814
Overall Steps per Second: 16,517.08756

Timestep Collection Time: 2.14168
Timestep Consumption Time: 0.88609
PPO Batch Consumption Time: 0.08187
Total Iteration Time: 3.02777

Cumulative Model Updates: 14,185
Cumulative Timesteps: 236,778,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,500.22643
Policy Entropy: 0.51237
Value Function Loss: 0.08595

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03687
Policy Update Magnitude: 0.01803
Value Function Update Magnitude: 0.02300

Collected Steps per Second: 21,401.28889
Overall Steps per Second: 15,025.09746

Timestep Collection Time: 2.33687
Timestep Consumption Time: 0.99170
PPO Batch Consumption Time: 0.11964
Total Iteration Time: 3.32856

Cumulative Model Updates: 14,188
Cumulative Timesteps: 236,828,744

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 236828744...
Checkpoint 236828744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,149.78981
Policy Entropy: 0.50800
Value Function Loss: 0.08342

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04799
Policy Update Magnitude: 0.01858
Value Function Update Magnitude: 0.02083

Collected Steps per Second: 23,307.11039
Overall Steps per Second: 16,874.96964

Timestep Collection Time: 2.14621
Timestep Consumption Time: 0.81806
PPO Batch Consumption Time: 0.06239
Total Iteration Time: 2.96427

Cumulative Model Updates: 14,191
Cumulative Timesteps: 236,878,766

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,791.12602
Policy Entropy: 0.50577
Value Function Loss: 0.09548

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04907
Policy Update Magnitude: 0.01777
Value Function Update Magnitude: 0.02059

Collected Steps per Second: 23,511.17446
Overall Steps per Second: 16,471.27031

Timestep Collection Time: 2.12673
Timestep Consumption Time: 0.90898
PPO Batch Consumption Time: 0.08160
Total Iteration Time: 3.03571

Cumulative Model Updates: 14,194
Cumulative Timesteps: 236,928,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 236928768...
Checkpoint 236928768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,823.44764
Policy Entropy: 0.50321
Value Function Loss: 0.09378

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.04301
Policy Update Magnitude: 0.01742
Value Function Update Magnitude: 0.02194

Collected Steps per Second: 22,608.80141
Overall Steps per Second: 16,520.48726

Timestep Collection Time: 2.21179
Timestep Consumption Time: 0.81511
PPO Batch Consumption Time: 0.06262
Total Iteration Time: 3.02691

Cumulative Model Updates: 14,197
Cumulative Timesteps: 236,978,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,748.39766
Policy Entropy: 0.49830
Value Function Loss: 0.09691

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.05287
Policy Update Magnitude: 0.01766
Value Function Update Magnitude: 0.02383

Collected Steps per Second: 19,218.36923
Overall Steps per Second: 14,031.48897

Timestep Collection Time: 2.60282
Timestep Consumption Time: 0.96216
PPO Batch Consumption Time: 0.10631
Total Iteration Time: 3.56498

Cumulative Model Updates: 14,200
Cumulative Timesteps: 237,028,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 237028796...
Checkpoint 237028796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,218.73499
Policy Entropy: 0.50274
Value Function Loss: 0.08471

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.05324
Policy Update Magnitude: 0.01855
Value Function Update Magnitude: 0.02547

Collected Steps per Second: 23,172.36067
Overall Steps per Second: 16,961.83005

Timestep Collection Time: 2.15826
Timestep Consumption Time: 0.79024
PPO Batch Consumption Time: 0.05809
Total Iteration Time: 2.94850

Cumulative Model Updates: 14,203
Cumulative Timesteps: 237,078,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,902.02115
Policy Entropy: 0.50222
Value Function Loss: 0.09292

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.03077
Policy Update Magnitude: 0.01844
Value Function Update Magnitude: 0.02625

Collected Steps per Second: 20,209.55401
Overall Steps per Second: 14,603.48689

Timestep Collection Time: 2.47477
Timestep Consumption Time: 0.95003
PPO Batch Consumption Time: 0.10846
Total Iteration Time: 3.42480

Cumulative Model Updates: 14,206
Cumulative Timesteps: 237,128,822

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 237128822...
Checkpoint 237128822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,069.90040
Policy Entropy: 0.50425
Value Function Loss: 0.09332

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04319
Policy Update Magnitude: 0.01774
Value Function Update Magnitude: 0.02512

Collected Steps per Second: 23,155.98392
Overall Steps per Second: 16,961.35374

Timestep Collection Time: 2.15979
Timestep Consumption Time: 0.78880
PPO Batch Consumption Time: 0.05853
Total Iteration Time: 2.94859

Cumulative Model Updates: 14,209
Cumulative Timesteps: 237,178,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,023.45416
Policy Entropy: 0.50437
Value Function Loss: 0.09687

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02944
Policy Update Magnitude: 0.01753
Value Function Update Magnitude: 0.02391

Collected Steps per Second: 20,776.26754
Overall Steps per Second: 15,611.57171

Timestep Collection Time: 2.40775
Timestep Consumption Time: 0.79654
PPO Batch Consumption Time: 0.08313
Total Iteration Time: 3.20429

Cumulative Model Updates: 14,212
Cumulative Timesteps: 237,228,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 237228858...
Checkpoint 237228858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,313.75993
Policy Entropy: 0.50350
Value Function Loss: 0.08739

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02923
Policy Update Magnitude: 0.02003
Value Function Update Magnitude: 0.02418

Collected Steps per Second: 22,345.96244
Overall Steps per Second: 16,938.34246

Timestep Collection Time: 2.23861
Timestep Consumption Time: 0.71468
PPO Batch Consumption Time: 0.06148
Total Iteration Time: 2.95330

Cumulative Model Updates: 14,215
Cumulative Timesteps: 237,278,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,545.27317
Policy Entropy: 0.50217
Value Function Loss: 0.08709

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03473
Policy Update Magnitude: 0.01780
Value Function Update Magnitude: 0.02263

Collected Steps per Second: 20,065.35601
Overall Steps per Second: 14,674.58828

Timestep Collection Time: 2.49305
Timestep Consumption Time: 0.91583
PPO Batch Consumption Time: 0.11912
Total Iteration Time: 3.40889

Cumulative Model Updates: 14,218
Cumulative Timesteps: 237,328,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 237328906...
Checkpoint 237328906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,485.56733
Policy Entropy: 0.50370
Value Function Loss: 0.08723

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03031
Policy Update Magnitude: 0.01735
Value Function Update Magnitude: 0.02452

Collected Steps per Second: 23,005.26883
Overall Steps per Second: 16,832.89399

Timestep Collection Time: 2.17541
Timestep Consumption Time: 0.79769
PPO Batch Consumption Time: 0.06452
Total Iteration Time: 2.97311

Cumulative Model Updates: 14,221
Cumulative Timesteps: 237,378,952

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,449.42311
Policy Entropy: 0.50728
Value Function Loss: 0.08714

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.01766
Value Function Update Magnitude: 0.02503

Collected Steps per Second: 20,213.38171
Overall Steps per Second: 14,665.16572

Timestep Collection Time: 2.47371
Timestep Consumption Time: 0.93587
PPO Batch Consumption Time: 0.10863
Total Iteration Time: 3.40958

Cumulative Model Updates: 14,224
Cumulative Timesteps: 237,428,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 237428954...
Checkpoint 237428954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,765.13855
Policy Entropy: 0.50754
Value Function Loss: 0.08980

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.04381
Policy Update Magnitude: 0.01866
Value Function Update Magnitude: 0.02380

Collected Steps per Second: 22,959.58773
Overall Steps per Second: 16,479.37212

Timestep Collection Time: 2.17818
Timestep Consumption Time: 0.85653
PPO Batch Consumption Time: 0.08333
Total Iteration Time: 3.03470

Cumulative Model Updates: 14,227
Cumulative Timesteps: 237,478,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,141.40349
Policy Entropy: 0.51020
Value Function Loss: 0.08940

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03487
Policy Update Magnitude: 0.01800
Value Function Update Magnitude: 0.02420

Collected Steps per Second: 22,728.38140
Overall Steps per Second: 15,894.40424

Timestep Collection Time: 2.20165
Timestep Consumption Time: 0.94663
PPO Batch Consumption Time: 0.10058
Total Iteration Time: 3.14828

Cumulative Model Updates: 14,230
Cumulative Timesteps: 237,529,004

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 237529004...
Checkpoint 237529004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,543.18297
Policy Entropy: 0.50922
Value Function Loss: 0.09239

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06355
Policy Update Magnitude: 0.01936
Value Function Update Magnitude: 0.02477

Collected Steps per Second: 23,034.44952
Overall Steps per Second: 16,943.26999

Timestep Collection Time: 2.17127
Timestep Consumption Time: 0.78058
PPO Batch Consumption Time: 0.05876
Total Iteration Time: 2.95185

Cumulative Model Updates: 14,233
Cumulative Timesteps: 237,579,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,075.76607
Policy Entropy: 0.50816
Value Function Loss: 0.08792

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.06366
Policy Update Magnitude: 0.01706
Value Function Update Magnitude: 0.02541

Collected Steps per Second: 20,625.60968
Overall Steps per Second: 14,671.64172

Timestep Collection Time: 2.42524
Timestep Consumption Time: 0.98420
PPO Batch Consumption Time: 0.11624
Total Iteration Time: 3.40943

Cumulative Model Updates: 14,236
Cumulative Timesteps: 237,629,040

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 237629040...
Checkpoint 237629040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,180.30490
Policy Entropy: 0.49847
Value Function Loss: 0.08526

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06824
Policy Update Magnitude: 0.01853
Value Function Update Magnitude: 0.02242

Collected Steps per Second: 23,228.08009
Overall Steps per Second: 16,446.24982

Timestep Collection Time: 2.15394
Timestep Consumption Time: 0.88821
PPO Batch Consumption Time: 0.08476
Total Iteration Time: 3.04215

Cumulative Model Updates: 14,239
Cumulative Timesteps: 237,679,072

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,543.71261
Policy Entropy: 0.50282
Value Function Loss: 0.07844

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07739
Policy Update Magnitude: 0.01848
Value Function Update Magnitude: 0.02233

Collected Steps per Second: 21,836.01145
Overall Steps per Second: 15,884.77138

Timestep Collection Time: 2.29053
Timestep Consumption Time: 0.85815
PPO Batch Consumption Time: 0.07762
Total Iteration Time: 3.14868

Cumulative Model Updates: 14,242
Cumulative Timesteps: 237,729,088

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 237729088...
Checkpoint 237729088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,837.33137
Policy Entropy: 0.50149
Value Function Loss: 0.07598

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07741
Policy Update Magnitude: 0.01726
Value Function Update Magnitude: 0.02113

Collected Steps per Second: 22,740.67139
Overall Steps per Second: 16,555.72868

Timestep Collection Time: 2.19985
Timestep Consumption Time: 0.82183
PPO Batch Consumption Time: 0.06130
Total Iteration Time: 3.02167

Cumulative Model Updates: 14,245
Cumulative Timesteps: 237,779,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,854.51706
Policy Entropy: 0.49752
Value Function Loss: 0.07746

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06981
Policy Update Magnitude: 0.01962
Value Function Update Magnitude: 0.02190

Collected Steps per Second: 20,686.04353
Overall Steps per Second: 14,923.40013

Timestep Collection Time: 2.41709
Timestep Consumption Time: 0.93335
PPO Batch Consumption Time: 0.09841
Total Iteration Time: 3.35044

Cumulative Model Updates: 14,248
Cumulative Timesteps: 237,829,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 237829114...
Checkpoint 237829114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,059.89946
Policy Entropy: 0.48864
Value Function Loss: 0.08737

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.06241
Policy Update Magnitude: 0.01691
Value Function Update Magnitude: 0.02344

Collected Steps per Second: 23,249.36588
Overall Steps per Second: 15,826.07052

Timestep Collection Time: 2.15171
Timestep Consumption Time: 1.00927
PPO Batch Consumption Time: 0.12357
Total Iteration Time: 3.16099

Cumulative Model Updates: 14,251
Cumulative Timesteps: 237,879,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,214.69356
Policy Entropy: 0.48428
Value Function Loss: 0.09043

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.05566
Policy Update Magnitude: 0.01768
Value Function Update Magnitude: 0.02715

Collected Steps per Second: 23,492.14018
Overall Steps per Second: 16,860.20010

Timestep Collection Time: 2.12854
Timestep Consumption Time: 0.83726
PPO Batch Consumption Time: 0.06271
Total Iteration Time: 2.96580

Cumulative Model Updates: 14,254
Cumulative Timesteps: 237,929,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 237929144...
Checkpoint 237929144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,739.77635
Policy Entropy: 0.48308
Value Function Loss: 0.09081

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04541
Policy Update Magnitude: 0.02060
Value Function Update Magnitude: 0.02590

Collected Steps per Second: 23,304.52585
Overall Steps per Second: 16,901.42559

Timestep Collection Time: 2.14594
Timestep Consumption Time: 0.81299
PPO Batch Consumption Time: 0.06488
Total Iteration Time: 2.95892

Cumulative Model Updates: 14,257
Cumulative Timesteps: 237,979,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,259.58239
Policy Entropy: 0.48399
Value Function Loss: 0.09821

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.06754
Policy Update Magnitude: 0.02038
Value Function Update Magnitude: 0.02786

Collected Steps per Second: 23,463.15513
Overall Steps per Second: 17,008.64438

Timestep Collection Time: 2.13143
Timestep Consumption Time: 0.80884
PPO Batch Consumption Time: 0.06390
Total Iteration Time: 2.94027

Cumulative Model Updates: 14,260
Cumulative Timesteps: 238,029,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 238029164...
Checkpoint 238029164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,890.49984
Policy Entropy: 0.48874
Value Function Loss: 0.09686

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06757
Policy Update Magnitude: 0.01966
Value Function Update Magnitude: 0.02847

Collected Steps per Second: 20,058.97628
Overall Steps per Second: 14,155.40524

Timestep Collection Time: 2.49365
Timestep Consumption Time: 1.03999
PPO Batch Consumption Time: 0.11899
Total Iteration Time: 3.53363

Cumulative Model Updates: 14,263
Cumulative Timesteps: 238,079,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,926.15133
Policy Entropy: 0.48861
Value Function Loss: 0.09833

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09057
Policy Update Magnitude: 0.02111
Value Function Update Magnitude: 0.02878

Collected Steps per Second: 23,048.40598
Overall Steps per Second: 16,845.16281

Timestep Collection Time: 2.17074
Timestep Consumption Time: 0.79938
PPO Batch Consumption Time: 0.05949
Total Iteration Time: 2.97011

Cumulative Model Updates: 14,266
Cumulative Timesteps: 238,129,216

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 238129216...
Checkpoint 238129216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,754.01993
Policy Entropy: 0.48673
Value Function Loss: 0.09268

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.02090
Value Function Update Magnitude: 0.02577

Collected Steps per Second: 20,504.09199
Overall Steps per Second: 14,699.77030

Timestep Collection Time: 2.44010
Timestep Consumption Time: 0.96349
PPO Batch Consumption Time: 0.09287
Total Iteration Time: 3.40359

Cumulative Model Updates: 14,269
Cumulative Timesteps: 238,179,248

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,057.61878
Policy Entropy: 0.48547
Value Function Loss: 0.08900

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.01897
Value Function Update Magnitude: 0.03048

Collected Steps per Second: 23,324.80559
Overall Steps per Second: 17,065.14218

Timestep Collection Time: 2.14441
Timestep Consumption Time: 0.78659
PPO Batch Consumption Time: 0.05949
Total Iteration Time: 2.93100

Cumulative Model Updates: 14,272
Cumulative Timesteps: 238,229,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 238229266...
Checkpoint 238229266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,922.40921
Policy Entropy: 0.48528
Value Function Loss: 0.08669

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.01773
Value Function Update Magnitude: 0.02745

Collected Steps per Second: 18,066.70503
Overall Steps per Second: 13,829.92123

Timestep Collection Time: 2.76763
Timestep Consumption Time: 0.84786
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 3.61549

Cumulative Model Updates: 14,275
Cumulative Timesteps: 238,279,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,125.39907
Policy Entropy: 0.47996
Value Function Loss: 0.07881

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.07641
Policy Update Magnitude: 0.01686
Value Function Update Magnitude: 0.02534

Collected Steps per Second: 17,496.62185
Overall Steps per Second: 13,173.91906

Timestep Collection Time: 2.85918
Timestep Consumption Time: 0.93817
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 3.79735

Cumulative Model Updates: 14,278
Cumulative Timesteps: 238,329,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 238329294...
Checkpoint 238329294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,563.48649
Policy Entropy: 0.48366
Value Function Loss: 0.07524

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.01716
Value Function Update Magnitude: 0.02868

Collected Steps per Second: 18,088.15443
Overall Steps per Second: 14,089.45423

Timestep Collection Time: 2.76424
Timestep Consumption Time: 0.78451
PPO Batch Consumption Time: 0.06667
Total Iteration Time: 3.54875

Cumulative Model Updates: 14,281
Cumulative Timesteps: 238,379,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,768.23850
Policy Entropy: 0.47385
Value Function Loss: 0.08247

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.06605
Policy Update Magnitude: 0.01602
Value Function Update Magnitude: 0.02867

Collected Steps per Second: 18,346.12641
Overall Steps per Second: 14,238.60457

Timestep Collection Time: 2.72646
Timestep Consumption Time: 0.78652
PPO Batch Consumption Time: 0.06927
Total Iteration Time: 3.51298

Cumulative Model Updates: 14,284
Cumulative Timesteps: 238,429,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 238429314...
Checkpoint 238429314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,107.49650
Policy Entropy: 0.46789
Value Function Loss: 0.09154

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04953
Policy Update Magnitude: 0.01797
Value Function Update Magnitude: 0.02348

Collected Steps per Second: 20,614.60761
Overall Steps per Second: 15,343.53618

Timestep Collection Time: 2.42624
Timestep Consumption Time: 0.83350
PPO Batch Consumption Time: 0.09898
Total Iteration Time: 3.25974

Cumulative Model Updates: 14,287
Cumulative Timesteps: 238,479,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,424.51316
Policy Entropy: 0.46805
Value Function Loss: 0.09751

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05690
Policy Update Magnitude: 0.02054
Value Function Update Magnitude: 0.02736

Collected Steps per Second: 20,797.21522
Overall Steps per Second: 15,679.24367

Timestep Collection Time: 2.40513
Timestep Consumption Time: 0.78508
PPO Batch Consumption Time: 0.06798
Total Iteration Time: 3.19020

Cumulative Model Updates: 14,290
Cumulative Timesteps: 238,529,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 238529350...
Checkpoint 238529350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,196.42950
Policy Entropy: 0.47013
Value Function Loss: 0.09633

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04509
Policy Update Magnitude: 0.01863
Value Function Update Magnitude: 0.02649

Collected Steps per Second: 18,885.80616
Overall Steps per Second: 14,724.24497

Timestep Collection Time: 2.64834
Timestep Consumption Time: 0.74851
PPO Batch Consumption Time: 0.05023
Total Iteration Time: 3.39685

Cumulative Model Updates: 14,293
Cumulative Timesteps: 238,579,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,003.26440
Policy Entropy: 0.47920
Value Function Loss: 0.08530

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04713
Policy Update Magnitude: 0.01811
Value Function Update Magnitude: 0.02716

Collected Steps per Second: 17,982.15092
Overall Steps per Second: 13,951.85944

Timestep Collection Time: 2.78053
Timestep Consumption Time: 0.80322
PPO Batch Consumption Time: 0.05024
Total Iteration Time: 3.58375

Cumulative Model Updates: 14,296
Cumulative Timesteps: 238,629,366

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 238629366...
Checkpoint 238629366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,127.59335
Policy Entropy: 0.48053
Value Function Loss: 0.09055

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.04219
Policy Update Magnitude: 0.01741
Value Function Update Magnitude: 0.02659

Collected Steps per Second: 18,244.08373
Overall Steps per Second: 13,947.53818

Timestep Collection Time: 2.74116
Timestep Consumption Time: 0.84442
PPO Batch Consumption Time: 0.06626
Total Iteration Time: 3.58558

Cumulative Model Updates: 14,299
Cumulative Timesteps: 238,679,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,928.65774
Policy Entropy: 0.47840
Value Function Loss: 0.09411

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03823
Policy Update Magnitude: 0.01815
Value Function Update Magnitude: 0.02540

Collected Steps per Second: 19,054.39517
Overall Steps per Second: 14,007.51459

Timestep Collection Time: 2.62575
Timestep Consumption Time: 0.94605
PPO Batch Consumption Time: 0.07903
Total Iteration Time: 3.57180

Cumulative Model Updates: 14,302
Cumulative Timesteps: 238,729,408

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 238729408...
Checkpoint 238729408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,574.01486
Policy Entropy: 0.47730
Value Function Loss: 0.10275

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.02034
Policy Update Magnitude: 0.01794
Value Function Update Magnitude: 0.02591

Collected Steps per Second: 19,084.56893
Overall Steps per Second: 14,355.03650

Timestep Collection Time: 2.62002
Timestep Consumption Time: 0.86321
PPO Batch Consumption Time: 0.06689
Total Iteration Time: 3.48324

Cumulative Model Updates: 14,305
Cumulative Timesteps: 238,779,410

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,984.13250
Policy Entropy: 0.47287
Value Function Loss: 0.09814

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01803
Policy Update Magnitude: 0.02179
Value Function Update Magnitude: 0.02468

Collected Steps per Second: 21,694.19032
Overall Steps per Second: 16,114.06584

Timestep Collection Time: 2.30587
Timestep Consumption Time: 0.79850
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 3.10437

Cumulative Model Updates: 14,308
Cumulative Timesteps: 238,829,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 238829434...
Checkpoint 238829434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,246.39065
Policy Entropy: 0.47231
Value Function Loss: 0.09509

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.02061
Policy Update Magnitude: 0.02026
Value Function Update Magnitude: 0.02643

Collected Steps per Second: 21,264.48995
Overall Steps per Second: 15,559.86464

Timestep Collection Time: 2.35143
Timestep Consumption Time: 0.86209
PPO Batch Consumption Time: 0.07775
Total Iteration Time: 3.21352

Cumulative Model Updates: 14,311
Cumulative Timesteps: 238,879,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,661.22721
Policy Entropy: 0.47116
Value Function Loss: 0.08624

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01777
Policy Update Magnitude: 0.02285
Value Function Update Magnitude: 0.02478

Collected Steps per Second: 23,055.56548
Overall Steps per Second: 16,905.00435

Timestep Collection Time: 2.16911
Timestep Consumption Time: 0.78919
PPO Batch Consumption Time: 0.05946
Total Iteration Time: 2.95830

Cumulative Model Updates: 14,314
Cumulative Timesteps: 238,929,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 238929446...
Checkpoint 238929446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,687.83848
Policy Entropy: 0.47777
Value Function Loss: 0.09365

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02335
Policy Update Magnitude: 0.02079
Value Function Update Magnitude: 0.02490

Collected Steps per Second: 20,548.19427
Overall Steps per Second: 14,689.40025

Timestep Collection Time: 2.43379
Timestep Consumption Time: 0.97071
PPO Batch Consumption Time: 0.10757
Total Iteration Time: 3.40450

Cumulative Model Updates: 14,317
Cumulative Timesteps: 238,979,456

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,842.03857
Policy Entropy: 0.47817
Value Function Loss: 0.08499

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.02043
Policy Update Magnitude: 0.01899
Value Function Update Magnitude: 0.02316

Collected Steps per Second: 23,433.69953
Overall Steps per Second: 16,997.65913

Timestep Collection Time: 2.13419
Timestep Consumption Time: 0.80810
PPO Batch Consumption Time: 0.06401
Total Iteration Time: 2.94229

Cumulative Model Updates: 14,320
Cumulative Timesteps: 239,029,468

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 239029468...
Checkpoint 239029468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,447.17817
Policy Entropy: 0.48117
Value Function Loss: 0.09488

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01732
Policy Update Magnitude: 0.01888
Value Function Update Magnitude: 0.02334

Collected Steps per Second: 23,383.47853
Overall Steps per Second: 16,963.37363

Timestep Collection Time: 2.13869
Timestep Consumption Time: 0.80943
PPO Batch Consumption Time: 0.06344
Total Iteration Time: 2.94812

Cumulative Model Updates: 14,323
Cumulative Timesteps: 239,079,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,376.61388
Policy Entropy: 0.47926
Value Function Loss: 0.09547

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01262
Policy Update Magnitude: 0.01919
Value Function Update Magnitude: 0.02239

Collected Steps per Second: 23,337.55725
Overall Steps per Second: 16,899.16080

Timestep Collection Time: 2.14264
Timestep Consumption Time: 0.81632
PPO Batch Consumption Time: 0.06274
Total Iteration Time: 2.95896

Cumulative Model Updates: 14,326
Cumulative Timesteps: 239,129,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 239129482...
Checkpoint 239129482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,960.05794
Policy Entropy: 0.48961
Value Function Loss: 0.09063

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02822
Policy Update Magnitude: 0.02027
Value Function Update Magnitude: 0.02389

Collected Steps per Second: 19,883.27206
Overall Steps per Second: 14,270.77232

Timestep Collection Time: 2.51508
Timestep Consumption Time: 0.98915
PPO Batch Consumption Time: 0.10268
Total Iteration Time: 3.50423

Cumulative Model Updates: 14,329
Cumulative Timesteps: 239,179,490

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,119.33710
Policy Entropy: 0.48843
Value Function Loss: 0.08525

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03543
Policy Update Magnitude: 0.02068
Value Function Update Magnitude: 0.02350

Collected Steps per Second: 22,624.48760
Overall Steps per Second: 16,665.46904

Timestep Collection Time: 2.21114
Timestep Consumption Time: 0.79063
PPO Batch Consumption Time: 0.08252
Total Iteration Time: 3.00178

Cumulative Model Updates: 14,332
Cumulative Timesteps: 239,229,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 239229516...
Checkpoint 239229516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,282.27988
Policy Entropy: 0.49321
Value Function Loss: 0.08573

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03251
Policy Update Magnitude: 0.02115
Value Function Update Magnitude: 0.02261

Collected Steps per Second: 22,482.84631
Overall Steps per Second: 15,879.78342

Timestep Collection Time: 2.22516
Timestep Consumption Time: 0.92526
PPO Batch Consumption Time: 0.12178
Total Iteration Time: 3.15042

Cumulative Model Updates: 14,335
Cumulative Timesteps: 239,279,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,643.57847
Policy Entropy: 0.48827
Value Function Loss: 0.09774

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02689
Policy Update Magnitude: 0.02404
Value Function Update Magnitude: 0.02681

Collected Steps per Second: 22,784.78602
Overall Steps per Second: 17,154.14557

Timestep Collection Time: 2.19471
Timestep Consumption Time: 0.72039
PPO Batch Consumption Time: 0.05999
Total Iteration Time: 2.91510

Cumulative Model Updates: 14,338
Cumulative Timesteps: 239,329,550

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 239329550...
Checkpoint 239329550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,867.01352
Policy Entropy: 0.48526
Value Function Loss: 0.10204

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.03167
Policy Update Magnitude: 0.02375
Value Function Update Magnitude: 0.02644

Collected Steps per Second: 20,823.23921
Overall Steps per Second: 15,258.96388

Timestep Collection Time: 2.40136
Timestep Consumption Time: 0.87567
PPO Batch Consumption Time: 0.10926
Total Iteration Time: 3.27702

Cumulative Model Updates: 14,341
Cumulative Timesteps: 239,379,554

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,987.38721
Policy Entropy: 0.48678
Value Function Loss: 0.10135

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02788
Policy Update Magnitude: 0.02185
Value Function Update Magnitude: 0.02830

Collected Steps per Second: 22,562.99196
Overall Steps per Second: 16,979.34397

Timestep Collection Time: 2.21806
Timestep Consumption Time: 0.72941
PPO Batch Consumption Time: 0.06507
Total Iteration Time: 2.94746

Cumulative Model Updates: 14,344
Cumulative Timesteps: 239,429,600

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 239429600...
Checkpoint 239429600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,973.64447
Policy Entropy: 0.48749
Value Function Loss: 0.10036

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.02015
Policy Update Magnitude: 0.02048
Value Function Update Magnitude: 0.02788

Collected Steps per Second: 21,416.78695
Overall Steps per Second: 15,476.22212

Timestep Collection Time: 2.33546
Timestep Consumption Time: 0.89647
PPO Batch Consumption Time: 0.09612
Total Iteration Time: 3.23193

Cumulative Model Updates: 14,347
Cumulative Timesteps: 239,479,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,330.55150
Policy Entropy: 0.49050
Value Function Loss: 0.09681

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.02072
Policy Update Magnitude: 0.02183
Value Function Update Magnitude: 0.02768

Collected Steps per Second: 23,312.16465
Overall Steps per Second: 16,669.05393

Timestep Collection Time: 2.14558
Timestep Consumption Time: 0.85508
PPO Batch Consumption Time: 0.08022
Total Iteration Time: 3.00065

Cumulative Model Updates: 14,350
Cumulative Timesteps: 239,529,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 239529636...
Checkpoint 239529636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,895.47798
Policy Entropy: 0.49179
Value Function Loss: 0.09318

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01644
Policy Update Magnitude: 0.02345
Value Function Update Magnitude: 0.02912

Collected Steps per Second: 23,155.91483
Overall Steps per Second: 16,694.24010

Timestep Collection Time: 2.16023
Timestep Consumption Time: 0.83614
PPO Batch Consumption Time: 0.07538
Total Iteration Time: 2.99636

Cumulative Model Updates: 14,353
Cumulative Timesteps: 239,579,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,576.65301
Policy Entropy: 0.49689
Value Function Loss: 0.09377

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01715
Policy Update Magnitude: 0.02363
Value Function Update Magnitude: 0.02834

Collected Steps per Second: 23,395.53765
Overall Steps per Second: 16,791.54880

Timestep Collection Time: 2.13836
Timestep Consumption Time: 0.84100
PPO Batch Consumption Time: 0.07447
Total Iteration Time: 2.97936

Cumulative Model Updates: 14,356
Cumulative Timesteps: 239,629,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 239629686...
Checkpoint 239629686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,532.84328
Policy Entropy: 0.50553
Value Function Loss: 0.09734

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01809
Policy Update Magnitude: 0.02565
Value Function Update Magnitude: 0.02657

Collected Steps per Second: 23,237.44820
Overall Steps per Second: 15,851.53511

Timestep Collection Time: 2.15239
Timestep Consumption Time: 1.00289
PPO Batch Consumption Time: 0.11499
Total Iteration Time: 3.15528

Cumulative Model Updates: 14,359
Cumulative Timesteps: 239,679,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,556.60362
Policy Entropy: 0.50794
Value Function Loss: 0.09671

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03167
Policy Update Magnitude: 0.02253
Value Function Update Magnitude: 0.02472

Collected Steps per Second: 23,465.38986
Overall Steps per Second: 17,060.50395

Timestep Collection Time: 2.13199
Timestep Consumption Time: 0.80040
PPO Batch Consumption Time: 0.06285
Total Iteration Time: 2.93239

Cumulative Model Updates: 14,362
Cumulative Timesteps: 239,729,730

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 239729730...
Checkpoint 239729730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,043.69699
Policy Entropy: 0.51025
Value Function Loss: 0.10558

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02637
Policy Update Magnitude: 0.02084
Value Function Update Magnitude: 0.02619

Collected Steps per Second: 23,252.46059
Overall Steps per Second: 16,934.91109

Timestep Collection Time: 2.15126
Timestep Consumption Time: 0.80252
PPO Batch Consumption Time: 0.06271
Total Iteration Time: 2.95378

Cumulative Model Updates: 14,365
Cumulative Timesteps: 239,779,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,881.19348
Policy Entropy: 0.51082
Value Function Loss: 0.09807

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.03277
Policy Update Magnitude: 0.02021
Value Function Update Magnitude: 0.02585

Collected Steps per Second: 20,618.60771
Overall Steps per Second: 15,125.22091

Timestep Collection Time: 2.42519
Timestep Consumption Time: 0.88081
PPO Batch Consumption Time: 0.08578
Total Iteration Time: 3.30600

Cumulative Model Updates: 14,368
Cumulative Timesteps: 239,829,756

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 239829756...
Checkpoint 239829756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,759.73415
Policy Entropy: 0.52177
Value Function Loss: 0.09134

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03323
Policy Update Magnitude: 0.01887
Value Function Update Magnitude: 0.02718

Collected Steps per Second: 23,015.66292
Overall Steps per Second: 16,818.65201

Timestep Collection Time: 2.17322
Timestep Consumption Time: 0.80074
PPO Batch Consumption Time: 0.05870
Total Iteration Time: 2.97396

Cumulative Model Updates: 14,371
Cumulative Timesteps: 239,879,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,741.28581
Policy Entropy: 0.52458
Value Function Loss: 0.07263

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02032
Policy Update Magnitude: 0.01842
Value Function Update Magnitude: 0.02184

Collected Steps per Second: 20,919.38056
Overall Steps per Second: 14,795.31224

Timestep Collection Time: 2.39137
Timestep Consumption Time: 0.98984
PPO Batch Consumption Time: 0.12240
Total Iteration Time: 3.38121

Cumulative Model Updates: 14,374
Cumulative Timesteps: 239,929,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 239929800...
Checkpoint 239929800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,631.02916
Policy Entropy: 0.53023
Value Function Loss: 0.07193

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01754
Policy Update Magnitude: 0.01808
Value Function Update Magnitude: 0.02679

Collected Steps per Second: 22,754.71990
Overall Steps per Second: 16,696.08052

Timestep Collection Time: 2.19761
Timestep Consumption Time: 0.79746
PPO Batch Consumption Time: 0.06075
Total Iteration Time: 2.99507

Cumulative Model Updates: 14,377
Cumulative Timesteps: 239,979,806

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,437.75595
Policy Entropy: 0.52319
Value Function Loss: 0.08018

Mean KL Divergence: 0.00114
SB3 Clip Fraction: 0.00857
Policy Update Magnitude: 0.01898
Value Function Update Magnitude: 0.02691

Collected Steps per Second: 20,988.63363
Overall Steps per Second: 14,756.32155

Timestep Collection Time: 2.38300
Timestep Consumption Time: 1.00646
PPO Batch Consumption Time: 0.11840
Total Iteration Time: 3.38946

Cumulative Model Updates: 14,380
Cumulative Timesteps: 240,029,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 240029822...
Checkpoint 240029822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,874.24751
Policy Entropy: 0.51681
Value Function Loss: 0.08519

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01833
Policy Update Magnitude: 0.01930
Value Function Update Magnitude: 0.02721

Collected Steps per Second: 22,614.90004
Overall Steps per Second: 15,714.21516

Timestep Collection Time: 2.21182
Timestep Consumption Time: 0.97129
PPO Batch Consumption Time: 0.11346
Total Iteration Time: 3.18311

Cumulative Model Updates: 14,383
Cumulative Timesteps: 240,079,842

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,749.67144
Policy Entropy: 0.52137
Value Function Loss: 0.08294

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.01951
Value Function Update Magnitude: 0.02951

Collected Steps per Second: 22,226.82424
Overall Steps per Second: 16,754.20206

Timestep Collection Time: 2.25070
Timestep Consumption Time: 0.73517
PPO Batch Consumption Time: 0.06245
Total Iteration Time: 2.98588

Cumulative Model Updates: 14,386
Cumulative Timesteps: 240,129,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 240129868...
Checkpoint 240129868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,222.53954
Policy Entropy: 0.52009
Value Function Loss: 0.07482

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.03241
Policy Update Magnitude: 0.01985
Value Function Update Magnitude: 0.02476

Collected Steps per Second: 19,730.74249
Overall Steps per Second: 14,714.60972

Timestep Collection Time: 2.53554
Timestep Consumption Time: 0.86435
PPO Batch Consumption Time: 0.10012
Total Iteration Time: 3.39989

Cumulative Model Updates: 14,389
Cumulative Timesteps: 240,179,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,069.75452
Policy Entropy: 0.52815
Value Function Loss: 0.06592

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03279
Policy Update Magnitude: 0.01835
Value Function Update Magnitude: 0.02425

Collected Steps per Second: 22,724.09728
Overall Steps per Second: 16,797.81662

Timestep Collection Time: 2.20084
Timestep Consumption Time: 0.77646
PPO Batch Consumption Time: 0.05989
Total Iteration Time: 2.97729

Cumulative Model Updates: 14,392
Cumulative Timesteps: 240,229,908

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 240229908...
Checkpoint 240229908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,042.35108
Policy Entropy: 0.52547
Value Function Loss: 0.06965

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.03122
Policy Update Magnitude: 0.01720
Value Function Update Magnitude: 0.02324

Collected Steps per Second: 19,738.21800
Overall Steps per Second: 14,724.46883

Timestep Collection Time: 2.53376
Timestep Consumption Time: 0.86276
PPO Batch Consumption Time: 0.07897
Total Iteration Time: 3.39652

Cumulative Model Updates: 14,395
Cumulative Timesteps: 240,279,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,496.09158
Policy Entropy: 0.52629
Value Function Loss: 0.06686

Mean KL Divergence: 0.00100
SB3 Clip Fraction: 0.00899
Policy Update Magnitude: 0.01824
Value Function Update Magnitude: 0.02217

Collected Steps per Second: 22,163.37606
Overall Steps per Second: 16,468.78892

Timestep Collection Time: 2.25715
Timestep Consumption Time: 0.78048
PPO Batch Consumption Time: 0.06105
Total Iteration Time: 3.03762

Cumulative Model Updates: 14,398
Cumulative Timesteps: 240,329,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 240329946...
Checkpoint 240329946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,064.01449
Policy Entropy: 0.52321
Value Function Loss: 0.07299

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01115
Policy Update Magnitude: 0.01820
Value Function Update Magnitude: 0.02133

Collected Steps per Second: 20,279.94022
Overall Steps per Second: 14,982.38738

Timestep Collection Time: 2.46598
Timestep Consumption Time: 0.87194
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 3.33792

Cumulative Model Updates: 14,401
Cumulative Timesteps: 240,379,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,124.44055
Policy Entropy: 0.51646
Value Function Loss: 0.07736

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01985
Policy Update Magnitude: 0.01809
Value Function Update Magnitude: 0.02223

Collected Steps per Second: 21,016.17733
Overall Steps per Second: 15,879.71713

Timestep Collection Time: 2.38055
Timestep Consumption Time: 0.77001
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 3.15056

Cumulative Model Updates: 14,404
Cumulative Timesteps: 240,429,986

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 240429986...
Checkpoint 240429986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,932.13967
Policy Entropy: 0.51558
Value Function Loss: 0.08038

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01960
Policy Update Magnitude: 0.01944
Value Function Update Magnitude: 0.01942

Collected Steps per Second: 20,069.90795
Overall Steps per Second: 14,633.96547

Timestep Collection Time: 2.49159
Timestep Consumption Time: 0.92553
PPO Batch Consumption Time: 0.09130
Total Iteration Time: 3.41712

Cumulative Model Updates: 14,407
Cumulative Timesteps: 240,479,992

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,015.06540
Policy Entropy: 0.51266
Value Function Loss: 0.07466

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02086
Policy Update Magnitude: 0.01916
Value Function Update Magnitude: 0.01939

Collected Steps per Second: 23,981.04766
Overall Steps per Second: 17,334.09075

Timestep Collection Time: 2.08515
Timestep Consumption Time: 0.79957
PPO Batch Consumption Time: 0.06398
Total Iteration Time: 2.88472

Cumulative Model Updates: 14,410
Cumulative Timesteps: 240,529,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 240529996...
Checkpoint 240529996 saved!
