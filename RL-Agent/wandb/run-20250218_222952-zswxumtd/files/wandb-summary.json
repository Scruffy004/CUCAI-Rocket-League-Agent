{"Overall Steps per Second":8360.582406763475,"Timesteps Collected":50010,"PPO Batch Consumption Time":0.3268476724624634,"_runtime":602120.3504717,"Mean KL Divergence":0.0003058950993969726,"Timestep Collection Time":3.2483491999998932,"_timestamp":1.7399364073979354e+09,"Total Iteration Time":5.981640699999957,"_wandb":{"runtime":602120},"x_vel":27.97400188634926,"Cumulative Model Updates":59434,"Policy Update Magnitude":0.3230401873588562,"Value Function Loss":0.00025274038246910396,"y_vel":72.36058604107122,"z_vel":-28.15543239021827,"Collected Steps per Second":15395.512280515175,"_step":251382,"SB3 Clip Fraction":0.0006233333163739493,"Policy Reward":9.399480302984024,"Value Function Update Magnitude":0.2705311179161072,"Cumulative Timesteps":496056074,"Policy Entropy":4.495181401570638,"Timestep Consumption Time":2.733291500000064}