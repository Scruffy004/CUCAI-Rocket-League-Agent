{"PPO Batch Consumption Time":0.34151411056518555,"Cumulative Model Updates":116678,"y_vel":58.54182854552528,"_wandb":{"runtime":105977},"Policy Entropy":2.0206531286239624,"x_vel":9.124350851034443,"Total Iteration Time":4.1841963,"Timestep Collection Time":2.8872227000000006,"z_vel":4.464721802126884,"Policy Reward":4901.496773248031,"Mean KL Divergence":0.00019324814764115628,"Value Function Update Magnitude":0.12169951945543289,"Timesteps Collected":50012,"Cumulative Timesteps":973555410,"Timestep Consumption Time":1.2969735999999994,"SB3 Clip Fraction":0.00026000000070780516,"_step":38922,"Policy Update Magnitude":0.11891994625329971,"Collected Steps per Second":17321.836656382617,"Overall Steps per Second":11952.594097939429,"Value Function Loss":0.05127856321632862,"_timestamp":1.7373450488748455e+09,"_runtime":105977.8159604}