Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,389.04502
Policy Entropy: 2.17886
Value Function Loss: 0.04797

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00409
Policy Update Magnitude: 0.11397
Value Function Update Magnitude: 0.10895

Collected Steps per Second: 18,959.85904
Overall Steps per Second: 12,191.93196

Timestep Collection Time: 2.63947
Timestep Consumption Time: 1.46521
PPO Batch Consumption Time: 0.37808
Total Iteration Time: 4.10468

Cumulative Model Updates: 218,204
Cumulative Timesteps: 1,820,431,464

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,527.17234
Policy Entropy: 2.10528
Value Function Loss: 0.03995

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.03315
Policy Update Magnitude: 0.24365
Value Function Update Magnitude: 0.17191

Collected Steps per Second: 20,060.26502
Overall Steps per Second: 11,251.61710

Timestep Collection Time: 2.49329
Timestep Consumption Time: 1.95194
PPO Batch Consumption Time: 0.30835
Total Iteration Time: 4.44523

Cumulative Model Updates: 218,208
Cumulative Timesteps: 1,820,481,480

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1820481480...
Checkpoint 1820481480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,671.78660
Policy Entropy: 2.06476
Value Function Loss: 0.03773

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07811
Policy Update Magnitude: 0.35126
Value Function Update Magnitude: 0.23297

Collected Steps per Second: 19,240.30231
Overall Steps per Second: 10,047.34396

Timestep Collection Time: 2.59986
Timestep Consumption Time: 2.37877
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.97863

Cumulative Model Updates: 218,214
Cumulative Timesteps: 1,820,531,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,996.09672
Policy Entropy: 2.00474
Value Function Loss: 0.03278

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.32506
Value Function Update Magnitude: 0.26023

Collected Steps per Second: 19,591.85822
Overall Steps per Second: 9,827.27082

Timestep Collection Time: 2.55290
Timestep Consumption Time: 2.53661
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 5.08951

Cumulative Model Updates: 218,220
Cumulative Timesteps: 1,820,581,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1820581518...
Checkpoint 1820581518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,416.17892
Policy Entropy: 1.99435
Value Function Loss: 0.03561

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.07887
Policy Update Magnitude: 0.32176
Value Function Update Magnitude: 0.26417

Collected Steps per Second: 19,513.03391
Overall Steps per Second: 9,553.79853

Timestep Collection Time: 2.56352
Timestep Consumption Time: 2.67231
PPO Batch Consumption Time: 0.31734
Total Iteration Time: 5.23582

Cumulative Model Updates: 218,226
Cumulative Timesteps: 1,820,631,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,774.88428
Policy Entropy: 1.99072
Value Function Loss: 0.03497

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.32253
Value Function Update Magnitude: 0.27595

Collected Steps per Second: 21,620.80280
Overall Steps per Second: 10,487.36557

Timestep Collection Time: 2.31314
Timestep Consumption Time: 2.45564
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.76879

Cumulative Model Updates: 218,232
Cumulative Timesteps: 1,820,681,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1820681552...
Checkpoint 1820681552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,831.69072
Policy Entropy: 1.98595
Value Function Loss: 0.03520

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07768
Policy Update Magnitude: 0.32593
Value Function Update Magnitude: 0.24112

Collected Steps per Second: 21,513.20557
Overall Steps per Second: 10,466.57955

Timestep Collection Time: 2.32490
Timestep Consumption Time: 2.45374
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.77864

Cumulative Model Updates: 218,238
Cumulative Timesteps: 1,820,731,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,786.20222
Policy Entropy: 1.98002
Value Function Loss: 0.03508

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.31881
Value Function Update Magnitude: 0.22576

Collected Steps per Second: 21,924.99703
Overall Steps per Second: 10,444.86874

Timestep Collection Time: 2.28087
Timestep Consumption Time: 2.50694
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.78781

Cumulative Model Updates: 218,244
Cumulative Timesteps: 1,820,781,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1820781576...
Checkpoint 1820781576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,813.24196
Policy Entropy: 1.96629
Value Function Loss: 0.03271

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.30989
Value Function Update Magnitude: 0.27431

Collected Steps per Second: 21,069.54872
Overall Steps per Second: 10,217.23886

Timestep Collection Time: 2.37442
Timestep Consumption Time: 2.52201
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.89643

Cumulative Model Updates: 218,250
Cumulative Timesteps: 1,820,831,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,337.05512
Policy Entropy: 1.95460
Value Function Loss: 0.03199

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08321
Policy Update Magnitude: 0.30602
Value Function Update Magnitude: 0.25299

Collected Steps per Second: 21,871.99126
Overall Steps per Second: 10,448.54212

Timestep Collection Time: 2.28667
Timestep Consumption Time: 2.50003
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.78670

Cumulative Model Updates: 218,256
Cumulative Timesteps: 1,820,881,618

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1820881618...
Checkpoint 1820881618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,087.28439
Policy Entropy: 1.96247
Value Function Loss: 0.03013

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.29662
Value Function Update Magnitude: 0.19982

Collected Steps per Second: 21,507.90180
Overall Steps per Second: 10,361.59368

Timestep Collection Time: 2.32556
Timestep Consumption Time: 2.50169
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.82725

Cumulative Model Updates: 218,262
Cumulative Timesteps: 1,820,931,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,027.12369
Policy Entropy: 1.98642
Value Function Loss: 0.03310

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07271
Policy Update Magnitude: 0.29792
Value Function Update Magnitude: 0.22361

Collected Steps per Second: 21,621.22442
Overall Steps per Second: 10,372.88489

Timestep Collection Time: 2.31347
Timestep Consumption Time: 2.50872
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.82219

Cumulative Model Updates: 218,268
Cumulative Timesteps: 1,820,981,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1820981656...
Checkpoint 1820981656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,158.53269
Policy Entropy: 2.01790
Value Function Loss: 0.03645

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.30800
Value Function Update Magnitude: 0.25992

Collected Steps per Second: 21,169.52888
Overall Steps per Second: 10,285.27937

Timestep Collection Time: 2.36321
Timestep Consumption Time: 2.50083
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.86404

Cumulative Model Updates: 218,274
Cumulative Timesteps: 1,821,031,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,423.07454
Policy Entropy: 2.00979
Value Function Loss: 0.03720

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.08705
Policy Update Magnitude: 0.31524
Value Function Update Magnitude: 0.26607

Collected Steps per Second: 21,970.39758
Overall Steps per Second: 10,462.39096

Timestep Collection Time: 2.27725
Timestep Consumption Time: 2.50483
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.78208

Cumulative Model Updates: 218,280
Cumulative Timesteps: 1,821,081,716

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1821081716...
Checkpoint 1821081716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,934.28657
Policy Entropy: 2.01401
Value Function Loss: 0.03492

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.30601
Value Function Update Magnitude: 0.27041

Collected Steps per Second: 21,839.74446
Overall Steps per Second: 10,470.12362

Timestep Collection Time: 2.29124
Timestep Consumption Time: 2.48808
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.77931

Cumulative Model Updates: 218,286
Cumulative Timesteps: 1,821,131,756

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,708.85926
Policy Entropy: 2.01669
Value Function Loss: 0.02783

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.07702
Policy Update Magnitude: 0.28834
Value Function Update Magnitude: 0.23275

Collected Steps per Second: 22,045.06150
Overall Steps per Second: 10,465.16626

Timestep Collection Time: 2.26935
Timestep Consumption Time: 2.51108
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.78043

Cumulative Model Updates: 218,292
Cumulative Timesteps: 1,821,181,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1821181784...
Checkpoint 1821181784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,486.52459
Policy Entropy: 2.00362
Value Function Loss: 0.02696

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07397
Policy Update Magnitude: 0.28305
Value Function Update Magnitude: 0.23276

Collected Steps per Second: 20,721.08618
Overall Steps per Second: 10,242.15737

Timestep Collection Time: 2.41435
Timestep Consumption Time: 2.47017
PPO Batch Consumption Time: 0.29834
Total Iteration Time: 4.88452

Cumulative Model Updates: 218,298
Cumulative Timesteps: 1,821,231,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,246.25692
Policy Entropy: 1.99211
Value Function Loss: 0.02603

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07499
Policy Update Magnitude: 0.28219
Value Function Update Magnitude: 0.22068

Collected Steps per Second: 21,149.80311
Overall Steps per Second: 10,411.90727

Timestep Collection Time: 2.36513
Timestep Consumption Time: 2.43918
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.80431

Cumulative Model Updates: 218,304
Cumulative Timesteps: 1,821,281,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1821281834...
Checkpoint 1821281834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,884.26040
Policy Entropy: 1.97575
Value Function Loss: 0.02880

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.07971
Policy Update Magnitude: 0.28985
Value Function Update Magnitude: 0.22526

Collected Steps per Second: 20,685.37515
Overall Steps per Second: 10,253.37778

Timestep Collection Time: 2.41717
Timestep Consumption Time: 2.45928
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.87644

Cumulative Model Updates: 218,310
Cumulative Timesteps: 1,821,331,834

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,885.83304
Policy Entropy: 1.97327
Value Function Loss: 0.02941

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.29535
Value Function Update Magnitude: 0.24360

Collected Steps per Second: 21,295.31423
Overall Steps per Second: 10,381.58511

Timestep Collection Time: 2.34869
Timestep Consumption Time: 2.46908
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.81776

Cumulative Model Updates: 218,316
Cumulative Timesteps: 1,821,381,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1821381850...
Checkpoint 1821381850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,204.33287
Policy Entropy: 1.99119
Value Function Loss: 0.03261

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08242
Policy Update Magnitude: 0.29841
Value Function Update Magnitude: 0.28873

Collected Steps per Second: 21,480.99354
Overall Steps per Second: 10,554.45970

Timestep Collection Time: 2.32801
Timestep Consumption Time: 2.41008
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.73809

Cumulative Model Updates: 218,322
Cumulative Timesteps: 1,821,431,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,979.62267
Policy Entropy: 1.98380
Value Function Loss: 0.03441

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.30757
Value Function Update Magnitude: 0.33478

Collected Steps per Second: 21,627.82656
Overall Steps per Second: 10,530.29437

Timestep Collection Time: 2.31202
Timestep Consumption Time: 2.43656
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.74859

Cumulative Model Updates: 218,328
Cumulative Timesteps: 1,821,481,862

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1821481862...
Checkpoint 1821481862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,894.67972
Policy Entropy: 1.98011
Value Function Loss: 0.03392

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.08702
Policy Update Magnitude: 0.30828
Value Function Update Magnitude: 0.36820

Collected Steps per Second: 21,373.51278
Overall Steps per Second: 10,392.39436

Timestep Collection Time: 2.33953
Timestep Consumption Time: 2.47206
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.81160

Cumulative Model Updates: 218,334
Cumulative Timesteps: 1,821,531,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,931.74290
Policy Entropy: 1.94005
Value Function Loss: 0.03072

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.30156
Value Function Update Magnitude: 0.34619

Collected Steps per Second: 21,978.99663
Overall Steps per Second: 10,680.27714

Timestep Collection Time: 2.27526
Timestep Consumption Time: 2.40701
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.68228

Cumulative Model Updates: 218,340
Cumulative Timesteps: 1,821,581,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1821581874...
Checkpoint 1821581874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,430.68811
Policy Entropy: 1.93440
Value Function Loss: 0.03330

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.07860
Policy Update Magnitude: 0.30888
Value Function Update Magnitude: 0.30001

Collected Steps per Second: 21,340.65458
Overall Steps per Second: 10,271.11067

Timestep Collection Time: 2.34379
Timestep Consumption Time: 2.52599
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.86978

Cumulative Model Updates: 218,346
Cumulative Timesteps: 1,821,631,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,872.95441
Policy Entropy: 1.93055
Value Function Loss: 0.03676

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.31539
Value Function Update Magnitude: 0.30280

Collected Steps per Second: 21,913.47738
Overall Steps per Second: 10,401.96195

Timestep Collection Time: 2.28270
Timestep Consumption Time: 2.52620
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.80890

Cumulative Model Updates: 218,352
Cumulative Timesteps: 1,821,681,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1821681914...
Checkpoint 1821681914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,619.15916
Policy Entropy: 1.95652
Value Function Loss: 0.03534

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.31254
Value Function Update Magnitude: 0.33041

Collected Steps per Second: 21,111.01453
Overall Steps per Second: 10,208.26214

Timestep Collection Time: 2.36872
Timestep Consumption Time: 2.52987
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.89858

Cumulative Model Updates: 218,358
Cumulative Timesteps: 1,821,731,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,997.09782
Policy Entropy: 1.95413
Value Function Loss: 0.03249

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.30251
Value Function Update Magnitude: 0.29338

Collected Steps per Second: 21,393.89620
Overall Steps per Second: 10,439.60599

Timestep Collection Time: 2.33833
Timestep Consumption Time: 2.45361
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.79194

Cumulative Model Updates: 218,364
Cumulative Timesteps: 1,821,781,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1821781946...
Checkpoint 1821781946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,052.02748
Policy Entropy: 1.95264
Value Function Loss: 0.02844

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08118
Policy Update Magnitude: 0.29614
Value Function Update Magnitude: 0.25547

Collected Steps per Second: 21,399.42942
Overall Steps per Second: 10,284.58064

Timestep Collection Time: 2.33745
Timestep Consumption Time: 2.52615
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.86359

Cumulative Model Updates: 218,370
Cumulative Timesteps: 1,821,831,966

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,597.46309
Policy Entropy: 1.93937
Value Function Loss: 0.02889

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07703
Policy Update Magnitude: 0.28920
Value Function Update Magnitude: 0.25048

Collected Steps per Second: 21,087.20944
Overall Steps per Second: 9,989.73430

Timestep Collection Time: 2.37243
Timestep Consumption Time: 2.63551
PPO Batch Consumption Time: 0.31075
Total Iteration Time: 5.00794

Cumulative Model Updates: 218,376
Cumulative Timesteps: 1,821,881,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1821881994...
Checkpoint 1821881994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,878.75376
Policy Entropy: 1.94830
Value Function Loss: 0.03014

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07128
Policy Update Magnitude: 0.29190
Value Function Update Magnitude: 0.22694

Collected Steps per Second: 17,999.88253
Overall Steps per Second: 9,311.84730

Timestep Collection Time: 2.77868
Timestep Consumption Time: 2.59254
PPO Batch Consumption Time: 0.30374
Total Iteration Time: 5.37122

Cumulative Model Updates: 218,382
Cumulative Timesteps: 1,821,932,010

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,571.84391
Policy Entropy: 1.95654
Value Function Loss: 0.03307

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07246
Policy Update Magnitude: 0.29528
Value Function Update Magnitude: 0.29840

Collected Steps per Second: 17,465.39001
Overall Steps per Second: 9,181.10986

Timestep Collection Time: 2.86406
Timestep Consumption Time: 2.58430
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 5.44836

Cumulative Model Updates: 218,388
Cumulative Timesteps: 1,821,982,032

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1821982032...
Checkpoint 1821982032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,189.78991
Policy Entropy: 1.95361
Value Function Loss: 0.03291

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07584
Policy Update Magnitude: 0.31127
Value Function Update Magnitude: 0.37465

Collected Steps per Second: 20,402.00898
Overall Steps per Second: 10,036.25543

Timestep Collection Time: 2.45192
Timestep Consumption Time: 2.53241
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.98433

Cumulative Model Updates: 218,394
Cumulative Timesteps: 1,822,032,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,750.24959
Policy Entropy: 1.94988
Value Function Loss: 0.03556

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.31096
Value Function Update Magnitude: 0.41128

Collected Steps per Second: 20,779.27947
Overall Steps per Second: 9,953.30459

Timestep Collection Time: 2.40740
Timestep Consumption Time: 2.61847
PPO Batch Consumption Time: 0.30297
Total Iteration Time: 5.02587

Cumulative Model Updates: 218,400
Cumulative Timesteps: 1,822,082,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1822082080...
Checkpoint 1822082080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,776.67863
Policy Entropy: 1.93723
Value Function Loss: 0.03304

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.29861
Value Function Update Magnitude: 0.38875

Collected Steps per Second: 20,649.37744
Overall Steps per Second: 10,171.09871

Timestep Collection Time: 2.42312
Timestep Consumption Time: 2.49631
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.91943

Cumulative Model Updates: 218,406
Cumulative Timesteps: 1,822,132,116

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,117.08207
Policy Entropy: 1.92735
Value Function Loss: 0.03160

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.29250
Value Function Update Magnitude: 0.36937

Collected Steps per Second: 19,997.50171
Overall Steps per Second: 9,819.54437

Timestep Collection Time: 2.50091
Timestep Consumption Time: 2.59220
PPO Batch Consumption Time: 0.30344
Total Iteration Time: 5.09311

Cumulative Model Updates: 218,412
Cumulative Timesteps: 1,822,182,128

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1822182128...
Checkpoint 1822182128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,777.20558
Policy Entropy: 1.91990
Value Function Loss: 0.02893

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.10241
Policy Update Magnitude: 0.28967
Value Function Update Magnitude: 0.33587

Collected Steps per Second: 20,384.56594
Overall Steps per Second: 10,083.97778

Timestep Collection Time: 2.45401
Timestep Consumption Time: 2.50673
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.96074

Cumulative Model Updates: 218,418
Cumulative Timesteps: 1,822,232,152

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,783.66885
Policy Entropy: 1.92135
Value Function Loss: 0.03131

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.30073
Value Function Update Magnitude: 0.28762

Collected Steps per Second: 20,801.75800
Overall Steps per Second: 10,012.19946

Timestep Collection Time: 2.40364
Timestep Consumption Time: 2.59026
PPO Batch Consumption Time: 0.30119
Total Iteration Time: 4.99391

Cumulative Model Updates: 218,424
Cumulative Timesteps: 1,822,282,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1822282152...
Checkpoint 1822282152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,799.98812
Policy Entropy: 1.93200
Value Function Loss: 0.03305

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.30139
Value Function Update Magnitude: 0.27524

Collected Steps per Second: 19,852.55022
Overall Steps per Second: 9,919.38030

Timestep Collection Time: 2.51947
Timestep Consumption Time: 2.52298
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 5.04245

Cumulative Model Updates: 218,430
Cumulative Timesteps: 1,822,332,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,799.99669
Policy Entropy: 1.93230
Value Function Loss: 0.03430

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.30550
Value Function Update Magnitude: 0.27029

Collected Steps per Second: 21,763.92066
Overall Steps per Second: 10,570.63648

Timestep Collection Time: 2.29894
Timestep Consumption Time: 2.43436
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.73330

Cumulative Model Updates: 218,436
Cumulative Timesteps: 1,822,382,204

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1822382204...
Checkpoint 1822382204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,010.61517
Policy Entropy: 1.92899
Value Function Loss: 0.03496

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.31284
Value Function Update Magnitude: 0.25464

Collected Steps per Second: 20,871.04829
Overall Steps per Second: 10,512.57284

Timestep Collection Time: 2.39643
Timestep Consumption Time: 2.36130
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.75773

Cumulative Model Updates: 218,442
Cumulative Timesteps: 1,822,432,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,537.42088
Policy Entropy: 1.92683
Value Function Loss: 0.03317

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.31167
Value Function Update Magnitude: 0.29581

Collected Steps per Second: 21,086.69393
Overall Steps per Second: 10,453.49352

Timestep Collection Time: 2.37249
Timestep Consumption Time: 2.41328
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.78577

Cumulative Model Updates: 218,448
Cumulative Timesteps: 1,822,482,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1822482248...
Checkpoint 1822482248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,775.08685
Policy Entropy: 1.93525
Value Function Loss: 0.03042

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.30474
Value Function Update Magnitude: 0.33773

Collected Steps per Second: 20,686.72138
Overall Steps per Second: 10,290.35277

Timestep Collection Time: 2.41749
Timestep Consumption Time: 2.44240
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.85989

Cumulative Model Updates: 218,454
Cumulative Timesteps: 1,822,532,258

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,403.47774
Policy Entropy: 1.93625
Value Function Loss: 0.03061

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.30327
Value Function Update Magnitude: 0.33556

Collected Steps per Second: 20,087.78105
Overall Steps per Second: 10,320.95236

Timestep Collection Time: 2.49047
Timestep Consumption Time: 2.35676
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.84723

Cumulative Model Updates: 218,460
Cumulative Timesteps: 1,822,582,286

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1822582286...
Checkpoint 1822582286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,563.29394
Policy Entropy: 1.92938
Value Function Loss: 0.02907

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.29663
Value Function Update Magnitude: 0.31783

Collected Steps per Second: 20,830.92948
Overall Steps per Second: 10,307.24283

Timestep Collection Time: 2.40153
Timestep Consumption Time: 2.45196
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.85348

Cumulative Model Updates: 218,466
Cumulative Timesteps: 1,822,632,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,630.90812
Policy Entropy: 1.92334
Value Function Loss: 0.02751

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07263
Policy Update Magnitude: 0.29304
Value Function Update Magnitude: 0.32402

Collected Steps per Second: 21,276.31707
Overall Steps per Second: 10,485.13336

Timestep Collection Time: 2.35153
Timestep Consumption Time: 2.42017
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.77171

Cumulative Model Updates: 218,472
Cumulative Timesteps: 1,822,682,344

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1822682344...
Checkpoint 1822682344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,617.90662
Policy Entropy: 1.91531
Value Function Loss: 0.02735

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.29335
Value Function Update Magnitude: 0.32931

Collected Steps per Second: 21,723.59235
Overall Steps per Second: 10,577.64043

Timestep Collection Time: 2.30220
Timestep Consumption Time: 2.42589
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.72809

Cumulative Model Updates: 218,478
Cumulative Timesteps: 1,822,732,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,192.32335
Policy Entropy: 1.91485
Value Function Loss: 0.02621

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07629
Policy Update Magnitude: 0.29508
Value Function Update Magnitude: 0.34438

Collected Steps per Second: 20,550.72627
Overall Steps per Second: 10,064.65818

Timestep Collection Time: 2.43427
Timestep Consumption Time: 2.53619
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.97046

Cumulative Model Updates: 218,484
Cumulative Timesteps: 1,822,782,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1822782382...
Checkpoint 1822782382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,215.69151
Policy Entropy: 1.91449
Value Function Loss: 0.02871

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.29584
Value Function Update Magnitude: 0.34668

Collected Steps per Second: 21,247.80904
Overall Steps per Second: 10,366.12188

Timestep Collection Time: 2.35422
Timestep Consumption Time: 2.47131
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.82553

Cumulative Model Updates: 218,490
Cumulative Timesteps: 1,822,832,404

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,123.48574
Policy Entropy: 1.90210
Value Function Loss: 0.02890

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.29740
Value Function Update Magnitude: 0.35013

Collected Steps per Second: 22,113.15816
Overall Steps per Second: 10,624.66620

Timestep Collection Time: 2.26110
Timestep Consumption Time: 2.44493
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.70603

Cumulative Model Updates: 218,496
Cumulative Timesteps: 1,822,882,404

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1822882404...
Checkpoint 1822882404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,238.03876
Policy Entropy: 1.90531
Value Function Loss: 0.02925

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.09063
Policy Update Magnitude: 0.29908
Value Function Update Magnitude: 0.33972

Collected Steps per Second: 21,718.43750
Overall Steps per Second: 10,352.78005

Timestep Collection Time: 2.30293
Timestep Consumption Time: 2.52824
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.83117

Cumulative Model Updates: 218,502
Cumulative Timesteps: 1,822,932,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,662.53199
Policy Entropy: 1.91618
Value Function Loss: 0.02830

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.29404
Value Function Update Magnitude: 0.33244

Collected Steps per Second: 21,592.09185
Overall Steps per Second: 10,382.59723

Timestep Collection Time: 2.31594
Timestep Consumption Time: 2.50039
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.81633

Cumulative Model Updates: 218,508
Cumulative Timesteps: 1,822,982,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1822982426...
Checkpoint 1822982426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,913.49321
Policy Entropy: 1.91968
Value Function Loss: 0.02803

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.28757
Value Function Update Magnitude: 0.30684

Collected Steps per Second: 21,086.04377
Overall Steps per Second: 10,207.32031

Timestep Collection Time: 2.37304
Timestep Consumption Time: 2.52913
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.90217

Cumulative Model Updates: 218,514
Cumulative Timesteps: 1,823,032,464

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,978.34199
Policy Entropy: 1.92742
Value Function Loss: 0.02751

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.28663
Value Function Update Magnitude: 0.24528

Collected Steps per Second: 21,723.19824
Overall Steps per Second: 10,444.63594

Timestep Collection Time: 2.30215
Timestep Consumption Time: 2.48596
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.78810

Cumulative Model Updates: 218,520
Cumulative Timesteps: 1,823,082,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1823082474...
Checkpoint 1823082474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,065.06163
Policy Entropy: 1.92529
Value Function Loss: 0.02822

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.28800
Value Function Update Magnitude: 0.23847

Collected Steps per Second: 21,284.50521
Overall Steps per Second: 10,264.65578

Timestep Collection Time: 2.35054
Timestep Consumption Time: 2.52347
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.87401

Cumulative Model Updates: 218,526
Cumulative Timesteps: 1,823,132,504

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,971.70039
Policy Entropy: 1.93341
Value Function Loss: 0.02890

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07796
Policy Update Magnitude: 0.28733
Value Function Update Magnitude: 0.24767

Collected Steps per Second: 21,821.86525
Overall Steps per Second: 10,259.68997

Timestep Collection Time: 2.29174
Timestep Consumption Time: 2.58268
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.87442

Cumulative Model Updates: 218,532
Cumulative Timesteps: 1,823,182,514

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1823182514...
Checkpoint 1823182514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,646.10992
Policy Entropy: 1.92114
Value Function Loss: 0.03263

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07390
Policy Update Magnitude: 0.29835
Value Function Update Magnitude: 0.28593

Collected Steps per Second: 21,115.80140
Overall Steps per Second: 10,393.38233

Timestep Collection Time: 2.36865
Timestep Consumption Time: 2.44364
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.81229

Cumulative Model Updates: 218,538
Cumulative Timesteps: 1,823,232,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,857.04704
Policy Entropy: 1.92103
Value Function Loss: 0.02994

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07899
Policy Update Magnitude: 0.30258
Value Function Update Magnitude: 0.31002

Collected Steps per Second: 21,748.55929
Overall Steps per Second: 10,387.99670

Timestep Collection Time: 2.29937
Timestep Consumption Time: 2.51465
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.81402

Cumulative Model Updates: 218,544
Cumulative Timesteps: 1,823,282,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1823282538...
Checkpoint 1823282538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,608.58814
Policy Entropy: 1.93308
Value Function Loss: 0.02692

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07619
Policy Update Magnitude: 0.29423
Value Function Update Magnitude: 0.30660

Collected Steps per Second: 21,645.32513
Overall Steps per Second: 10,346.59201

Timestep Collection Time: 2.31080
Timestep Consumption Time: 2.52345
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.83425

Cumulative Model Updates: 218,550
Cumulative Timesteps: 1,823,332,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,167.90103
Policy Entropy: 1.92971
Value Function Loss: 0.02532

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07023
Policy Update Magnitude: 0.29164
Value Function Update Magnitude: 0.30554

Collected Steps per Second: 21,246.67407
Overall Steps per Second: 10,084.23378

Timestep Collection Time: 2.35359
Timestep Consumption Time: 2.60524
PPO Batch Consumption Time: 0.31961
Total Iteration Time: 4.95883

Cumulative Model Updates: 218,556
Cumulative Timesteps: 1,823,382,562

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1823382562...
Checkpoint 1823382562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,619.89049
Policy Entropy: 1.91517
Value Function Loss: 0.02545

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.06909
Policy Update Magnitude: 0.28826
Value Function Update Magnitude: 0.30735

Collected Steps per Second: 21,115.13561
Overall Steps per Second: 10,483.69332

Timestep Collection Time: 2.36930
Timestep Consumption Time: 2.40269
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.77198

Cumulative Model Updates: 218,562
Cumulative Timesteps: 1,823,432,590

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,034.84783
Policy Entropy: 1.91412
Value Function Loss: 0.03189

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.07718
Policy Update Magnitude: 0.29545
Value Function Update Magnitude: 0.27555

Collected Steps per Second: 21,259.69157
Overall Steps per Second: 10,422.51345

Timestep Collection Time: 2.35206
Timestep Consumption Time: 2.44563
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.79769

Cumulative Model Updates: 218,568
Cumulative Timesteps: 1,823,482,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1823482594...
Checkpoint 1823482594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,549.73352
Policy Entropy: 1.92987
Value Function Loss: 0.03482

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.08709
Policy Update Magnitude: 0.30832
Value Function Update Magnitude: 0.25797

Collected Steps per Second: 20,867.72886
Overall Steps per Second: 10,382.55984

Timestep Collection Time: 2.39681
Timestep Consumption Time: 2.42050
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.81731

Cumulative Model Updates: 218,574
Cumulative Timesteps: 1,823,532,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,079.32708
Policy Entropy: 1.93852
Value Function Loss: 0.03377

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.30802
Value Function Update Magnitude: 0.29296

Collected Steps per Second: 21,428.18153
Overall Steps per Second: 10,347.39262

Timestep Collection Time: 2.33394
Timestep Consumption Time: 2.49936
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.83329

Cumulative Model Updates: 218,580
Cumulative Timesteps: 1,823,582,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1823582622...
Checkpoint 1823582622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,670.46565
Policy Entropy: 1.92298
Value Function Loss: 0.03146

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08118
Policy Update Magnitude: 0.30965
Value Function Update Magnitude: 0.32181

Collected Steps per Second: 21,614.77636
Overall Steps per Second: 10,547.06671

Timestep Collection Time: 2.31369
Timestep Consumption Time: 2.42791
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.74160

Cumulative Model Updates: 218,586
Cumulative Timesteps: 1,823,632,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,304.86780
Policy Entropy: 1.92417
Value Function Loss: 0.02864

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.30417
Value Function Update Magnitude: 0.33297

Collected Steps per Second: 21,665.05361
Overall Steps per Second: 10,458.54065

Timestep Collection Time: 2.30897
Timestep Consumption Time: 2.47410
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.78308

Cumulative Model Updates: 218,592
Cumulative Timesteps: 1,823,682,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1823682656...
Checkpoint 1823682656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,304.86780
Policy Entropy: 1.91801
Value Function Loss: 0.02648

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07483
Policy Update Magnitude: 0.29592
Value Function Update Magnitude: 0.32993

Collected Steps per Second: 21,495.99525
Overall Steps per Second: 10,558.13526

Timestep Collection Time: 2.32657
Timestep Consumption Time: 2.41025
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.73682

Cumulative Model Updates: 218,598
Cumulative Timesteps: 1,823,732,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,558.21740
Policy Entropy: 1.92451
Value Function Loss: 0.02508

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07328
Policy Update Magnitude: 0.28514
Value Function Update Magnitude: 0.30536

Collected Steps per Second: 21,367.34798
Overall Steps per Second: 10,406.23329

Timestep Collection Time: 2.34152
Timestep Consumption Time: 2.46637
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.80789

Cumulative Model Updates: 218,604
Cumulative Timesteps: 1,823,782,700

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1823782700...
Checkpoint 1823782700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,270.80354
Policy Entropy: 1.90283
Value Function Loss: 0.02465

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.28650
Value Function Update Magnitude: 0.31640

Collected Steps per Second: 21,038.05339
Overall Steps per Second: 10,403.66620

Timestep Collection Time: 2.37760
Timestep Consumption Time: 2.43032
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.80792

Cumulative Model Updates: 218,610
Cumulative Timesteps: 1,823,832,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,755.16610
Policy Entropy: 1.91470
Value Function Loss: 0.02867

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.07507
Policy Update Magnitude: 0.29277
Value Function Update Magnitude: 0.32538

Collected Steps per Second: 21,812.47254
Overall Steps per Second: 10,375.30631

Timestep Collection Time: 2.29419
Timestep Consumption Time: 2.52899
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.82318

Cumulative Model Updates: 218,616
Cumulative Timesteps: 1,823,882,762

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1823882762...
Checkpoint 1823882762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,692.75347
Policy Entropy: 1.91913
Value Function Loss: 0.02693

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.07593
Policy Update Magnitude: 0.29567
Value Function Update Magnitude: 0.32374

Collected Steps per Second: 21,699.15423
Overall Steps per Second: 10,403.45751

Timestep Collection Time: 2.30507
Timestep Consumption Time: 2.50276
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.80782

Cumulative Model Updates: 218,622
Cumulative Timesteps: 1,823,932,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,204.81595
Policy Entropy: 1.92960
Value Function Loss: 0.02952

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07568
Policy Update Magnitude: 0.29264
Value Function Update Magnitude: 0.30904

Collected Steps per Second: 21,871.02462
Overall Steps per Second: 10,474.02238

Timestep Collection Time: 2.28704
Timestep Consumption Time: 2.48858
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.77562

Cumulative Model Updates: 218,628
Cumulative Timesteps: 1,823,982,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1823982800...
Checkpoint 1823982800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,208.40873
Policy Entropy: 1.92064
Value Function Loss: 0.02868

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07413
Policy Update Magnitude: 0.29527
Value Function Update Magnitude: 0.28301

Collected Steps per Second: 20,866.55341
Overall Steps per Second: 10,379.92888

Timestep Collection Time: 2.39752
Timestep Consumption Time: 2.42217
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.81969

Cumulative Model Updates: 218,634
Cumulative Timesteps: 1,824,032,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,059.72559
Policy Entropy: 1.92483
Value Function Loss: 0.03099

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07612
Policy Update Magnitude: 0.30064
Value Function Update Magnitude: 0.30767

Collected Steps per Second: 21,642.64761
Overall Steps per Second: 10,527.13798

Timestep Collection Time: 2.31035
Timestep Consumption Time: 2.43947
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.74982

Cumulative Model Updates: 218,640
Cumulative Timesteps: 1,824,082,830

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1824082830...
Checkpoint 1824082830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,252.96510
Policy Entropy: 1.92713
Value Function Loss: 0.02828

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07786
Policy Update Magnitude: 0.29999
Value Function Update Magnitude: 0.30779

Collected Steps per Second: 21,338.37398
Overall Steps per Second: 10,295.93622

Timestep Collection Time: 2.34404
Timestep Consumption Time: 2.51399
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.85803

Cumulative Model Updates: 218,646
Cumulative Timesteps: 1,824,132,848

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,649.37189
Policy Entropy: 1.93113
Value Function Loss: 0.02848

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07227
Policy Update Magnitude: 0.29428
Value Function Update Magnitude: 0.31626

Collected Steps per Second: 21,887.76214
Overall Steps per Second: 10,398.29240

Timestep Collection Time: 2.28456
Timestep Consumption Time: 2.52430
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.80887

Cumulative Model Updates: 218,652
Cumulative Timesteps: 1,824,182,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1824182852...
Checkpoint 1824182852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,676.93425
Policy Entropy: 1.92424
Value Function Loss: 0.03032

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07202
Policy Update Magnitude: 0.30159
Value Function Update Magnitude: 0.32939

Collected Steps per Second: 21,443.67122
Overall Steps per Second: 10,490.54113

Timestep Collection Time: 2.33253
Timestep Consumption Time: 2.43538
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.76791

Cumulative Model Updates: 218,658
Cumulative Timesteps: 1,824,232,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,983.71650
Policy Entropy: 1.91667
Value Function Loss: 0.03139

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.30337
Value Function Update Magnitude: 0.34351

Collected Steps per Second: 21,773.02874
Overall Steps per Second: 10,525.45163

Timestep Collection Time: 2.29651
Timestep Consumption Time: 2.45407
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.75058

Cumulative Model Updates: 218,664
Cumulative Timesteps: 1,824,282,872

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1824282872...
Checkpoint 1824282872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,352.51337
Policy Entropy: 1.91215
Value Function Loss: 0.03094

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.07978
Policy Update Magnitude: 0.29991
Value Function Update Magnitude: 0.35962

Collected Steps per Second: 20,920.82935
Overall Steps per Second: 10,523.86472

Timestep Collection Time: 2.39082
Timestep Consumption Time: 2.36199
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.75282

Cumulative Model Updates: 218,670
Cumulative Timesteps: 1,824,332,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,869.17741
Policy Entropy: 1.91900
Value Function Loss: 0.02634

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.29272
Value Function Update Magnitude: 0.33424

Collected Steps per Second: 21,313.01860
Overall Steps per Second: 10,597.27120

Timestep Collection Time: 2.34749
Timestep Consumption Time: 2.37373
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.72122

Cumulative Model Updates: 218,676
Cumulative Timesteps: 1,824,382,922

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1824382922...
Checkpoint 1824382922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,796.61584
Policy Entropy: 1.93113
Value Function Loss: 0.02530

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07538
Policy Update Magnitude: 0.28238
Value Function Update Magnitude: 0.30621

Collected Steps per Second: 20,223.65627
Overall Steps per Second: 10,209.43112

Timestep Collection Time: 2.47314
Timestep Consumption Time: 2.42586
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.89900

Cumulative Model Updates: 218,682
Cumulative Timesteps: 1,824,432,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,430.98013
Policy Entropy: 1.91753
Value Function Loss: 0.02513

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07273
Policy Update Magnitude: 0.28421
Value Function Update Magnitude: 0.32062

Collected Steps per Second: 20,820.94994
Overall Steps per Second: 10,344.10875

Timestep Collection Time: 2.40325
Timestep Consumption Time: 2.43409
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.83734

Cumulative Model Updates: 218,688
Cumulative Timesteps: 1,824,482,976

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1824482976...
Checkpoint 1824482976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,850.79305
Policy Entropy: 1.92140
Value Function Loss: 0.02839

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07229
Policy Update Magnitude: 0.29203
Value Function Update Magnitude: 0.33291

Collected Steps per Second: 21,101.76359
Overall Steps per Second: 10,264.38237

Timestep Collection Time: 2.36947
Timestep Consumption Time: 2.50174
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.87121

Cumulative Model Updates: 218,694
Cumulative Timesteps: 1,824,532,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,975.90338
Policy Entropy: 1.92350
Value Function Loss: 0.03001

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.29782
Value Function Update Magnitude: 0.33693

Collected Steps per Second: 21,815.52133
Overall Steps per Second: 10,486.16296

Timestep Collection Time: 2.29213
Timestep Consumption Time: 2.47644
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.76857

Cumulative Model Updates: 218,700
Cumulative Timesteps: 1,824,582,980

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1824582980...
Checkpoint 1824582980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,016.29892
Policy Entropy: 1.93234
Value Function Loss: 0.02981

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.29419
Value Function Update Magnitude: 0.33294

Collected Steps per Second: 21,575.81276
Overall Steps per Second: 10,448.79084

Timestep Collection Time: 2.31750
Timestep Consumption Time: 2.46793
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.78543

Cumulative Model Updates: 218,706
Cumulative Timesteps: 1,824,632,982

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,684.22310
Policy Entropy: 1.91123
Value Function Loss: 0.02854

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.29232
Value Function Update Magnitude: 0.34602

Collected Steps per Second: 21,811.45133
Overall Steps per Second: 10,554.28127

Timestep Collection Time: 2.29274
Timestep Consumption Time: 2.44543
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.73817

Cumulative Model Updates: 218,712
Cumulative Timesteps: 1,824,682,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1824682990...
Checkpoint 1824682990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,424.09392
Policy Entropy: 1.90224
Value Function Loss: 0.03009

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.29402
Value Function Update Magnitude: 0.33255

Collected Steps per Second: 21,693.75067
Overall Steps per Second: 10,367.28221

Timestep Collection Time: 2.30509
Timestep Consumption Time: 2.51836
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.82344

Cumulative Model Updates: 218,718
Cumulative Timesteps: 1,824,732,996

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,083.86563
Policy Entropy: 1.91080
Value Function Loss: 0.02925

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.09217
Policy Update Magnitude: 0.29860
Value Function Update Magnitude: 0.33163

Collected Steps per Second: 22,080.45903
Overall Steps per Second: 10,419.01388

Timestep Collection Time: 2.26517
Timestep Consumption Time: 2.53528
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.80045

Cumulative Model Updates: 218,724
Cumulative Timesteps: 1,824,783,012

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1824783012...
Checkpoint 1824783012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,657.08550
Policy Entropy: 1.90623
Value Function Loss: 0.03261

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08351
Policy Update Magnitude: 0.30255
Value Function Update Magnitude: 0.34244

Collected Steps per Second: 21,527.24957
Overall Steps per Second: 10,231.27207

Timestep Collection Time: 2.32375
Timestep Consumption Time: 2.56557
PPO Batch Consumption Time: 0.30123
Total Iteration Time: 4.88932

Cumulative Model Updates: 218,730
Cumulative Timesteps: 1,824,833,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,290.15705
Policy Entropy: 1.91066
Value Function Loss: 0.03310

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07714
Policy Update Magnitude: 0.31087
Value Function Update Magnitude: 0.38241

Collected Steps per Second: 21,627.68756
Overall Steps per Second: 10,377.60810

Timestep Collection Time: 2.31296
Timestep Consumption Time: 2.50742
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.82038

Cumulative Model Updates: 218,736
Cumulative Timesteps: 1,824,883,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1824883060...
Checkpoint 1824883060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,145.81319
Policy Entropy: 1.90559
Value Function Loss: 0.03167

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.07763
Policy Update Magnitude: 0.31292
Value Function Update Magnitude: 0.41257

Collected Steps per Second: 21,856.26534
Overall Steps per Second: 10,564.60100

Timestep Collection Time: 2.28841
Timestep Consumption Time: 2.44590
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.73430

Cumulative Model Updates: 218,742
Cumulative Timesteps: 1,824,933,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,826.21894
Policy Entropy: 1.93019
Value Function Loss: 0.02928

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07533
Policy Update Magnitude: 0.30352
Value Function Update Magnitude: 0.38664

Collected Steps per Second: 21,894.65302
Overall Steps per Second: 10,593.49516

Timestep Collection Time: 2.28467
Timestep Consumption Time: 2.43729
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.72195

Cumulative Model Updates: 218,748
Cumulative Timesteps: 1,824,983,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1824983098...
Checkpoint 1824983098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,050.13857
Policy Entropy: 1.94217
Value Function Loss: 0.02750

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07314
Policy Update Magnitude: 0.29533
Value Function Update Magnitude: 0.35162

Collected Steps per Second: 21,635.84119
Overall Steps per Second: 10,524.94975

Timestep Collection Time: 2.31246
Timestep Consumption Time: 2.44120
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.75366

Cumulative Model Updates: 218,754
Cumulative Timesteps: 1,825,033,130

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,963.38023
Policy Entropy: 1.93977
Value Function Loss: 0.02811

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07416
Policy Update Magnitude: 0.29424
Value Function Update Magnitude: 0.33274

Collected Steps per Second: 21,302.59915
Overall Steps per Second: 10,424.45985

Timestep Collection Time: 2.34732
Timestep Consumption Time: 2.44948
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.79680

Cumulative Model Updates: 218,760
Cumulative Timesteps: 1,825,083,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1825083134...
Checkpoint 1825083134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,792.70614
Policy Entropy: 1.94890
Value Function Loss: 0.02759

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.29004
Value Function Update Magnitude: 0.30714

Collected Steps per Second: 21,062.92023
Overall Steps per Second: 10,275.82153

Timestep Collection Time: 2.37441
Timestep Consumption Time: 2.49255
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.86696

Cumulative Model Updates: 218,766
Cumulative Timesteps: 1,825,133,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,362.93424
Policy Entropy: 1.93223
Value Function Loss: 0.02784

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.07785
Policy Update Magnitude: 0.28617
Value Function Update Magnitude: 0.28287

Collected Steps per Second: 21,849.99985
Overall Steps per Second: 10,549.88141

Timestep Collection Time: 2.28934
Timestep Consumption Time: 2.45214
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.74148

Cumulative Model Updates: 218,772
Cumulative Timesteps: 1,825,183,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1825183168...
Checkpoint 1825183168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,948.77295
Policy Entropy: 1.91588
Value Function Loss: 0.02871

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07389
Policy Update Magnitude: 0.28794
Value Function Update Magnitude: 0.26156

Collected Steps per Second: 21,493.49310
Overall Steps per Second: 10,331.57972

Timestep Collection Time: 2.32712
Timestep Consumption Time: 2.51415
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.84127

Cumulative Model Updates: 218,778
Cumulative Timesteps: 1,825,233,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,966.70854
Policy Entropy: 1.90430
Value Function Loss: 0.02857

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07475
Policy Update Magnitude: 0.29087
Value Function Update Magnitude: 0.23634

Collected Steps per Second: 21,429.60954
Overall Steps per Second: 10,297.23441

Timestep Collection Time: 2.33322
Timestep Consumption Time: 2.52245
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.85567

Cumulative Model Updates: 218,784
Cumulative Timesteps: 1,825,283,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1825283186...
Checkpoint 1825283186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,832.82958
Policy Entropy: 1.91173
Value Function Loss: 0.02827

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07394
Policy Update Magnitude: 0.29080
Value Function Update Magnitude: 0.22616

Collected Steps per Second: 21,396.51063
Overall Steps per Second: 10,328.29281

Timestep Collection Time: 2.33833
Timestep Consumption Time: 2.50584
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.84417

Cumulative Model Updates: 218,790
Cumulative Timesteps: 1,825,333,218

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,434.91164
Policy Entropy: 1.90633
Value Function Loss: 0.02725

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.29200
Value Function Update Magnitude: 0.21582

Collected Steps per Second: 20,824.17633
Overall Steps per Second: 10,126.16145

Timestep Collection Time: 2.40230
Timestep Consumption Time: 2.53797
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.94027

Cumulative Model Updates: 218,796
Cumulative Timesteps: 1,825,383,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1825383244...
Checkpoint 1825383244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,311.07620
Policy Entropy: 1.89657
Value Function Loss: 0.02683

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.06588
Policy Update Magnitude: 0.28979
Value Function Update Magnitude: 0.21709

Collected Steps per Second: 19,887.59235
Overall Steps per Second: 9,503.17673

Timestep Collection Time: 2.51463
Timestep Consumption Time: 2.74782
PPO Batch Consumption Time: 0.32659
Total Iteration Time: 5.26245

Cumulative Model Updates: 218,802
Cumulative Timesteps: 1,825,433,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,934.00428
Policy Entropy: 1.88998
Value Function Loss: 0.02582

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.06599
Policy Update Magnitude: 0.28582
Value Function Update Magnitude: 0.23568

Collected Steps per Second: 19,957.49674
Overall Steps per Second: 9,676.39715

Timestep Collection Time: 2.50593
Timestep Consumption Time: 2.66253
PPO Batch Consumption Time: 0.31011
Total Iteration Time: 5.16845

Cumulative Model Updates: 218,808
Cumulative Timesteps: 1,825,483,266

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1825483266...
Checkpoint 1825483266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,953.87009
Policy Entropy: 1.89476
Value Function Loss: 0.02495

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.06927
Policy Update Magnitude: 0.28317
Value Function Update Magnitude: 0.27390

Collected Steps per Second: 17,666.95322
Overall Steps per Second: 9,163.96911

Timestep Collection Time: 2.83263
Timestep Consumption Time: 2.62832
PPO Batch Consumption Time: 0.30299
Total Iteration Time: 5.46095

Cumulative Model Updates: 218,814
Cumulative Timesteps: 1,825,533,310

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,357.57336
Policy Entropy: 1.90804
Value Function Loss: 0.02823

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07036
Policy Update Magnitude: 0.28562
Value Function Update Magnitude: 0.26188

Collected Steps per Second: 20,863.11772
Overall Steps per Second: 10,081.77708

Timestep Collection Time: 2.39667
Timestep Consumption Time: 2.56297
PPO Batch Consumption Time: 0.30080
Total Iteration Time: 4.95964

Cumulative Model Updates: 218,820
Cumulative Timesteps: 1,825,583,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1825583312...
Checkpoint 1825583312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,116.56733
Policy Entropy: 1.91269
Value Function Loss: 0.02947

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07095
Policy Update Magnitude: 0.28899
Value Function Update Magnitude: 0.22343

Collected Steps per Second: 20,460.94706
Overall Steps per Second: 9,731.07366

Timestep Collection Time: 2.44378
Timestep Consumption Time: 2.69461
PPO Batch Consumption Time: 0.31522
Total Iteration Time: 5.13838

Cumulative Model Updates: 218,826
Cumulative Timesteps: 1,825,633,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,019.84530
Policy Entropy: 1.90975
Value Function Loss: 0.02931

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07038
Policy Update Magnitude: 0.28537
Value Function Update Magnitude: 0.22853

Collected Steps per Second: 20,100.46050
Overall Steps per Second: 9,841.51001

Timestep Collection Time: 2.48810
Timestep Consumption Time: 2.59364
PPO Batch Consumption Time: 0.31869
Total Iteration Time: 5.08174

Cumulative Model Updates: 218,832
Cumulative Timesteps: 1,825,683,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1825683326...
Checkpoint 1825683326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,138.38165
Policy Entropy: 1.90264
Value Function Loss: 0.02404

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06935
Policy Update Magnitude: 0.28039
Value Function Update Magnitude: 0.24912

Collected Steps per Second: 18,196.58533
Overall Steps per Second: 9,739.10541

Timestep Collection Time: 2.74898
Timestep Consumption Time: 2.38722
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 5.13620

Cumulative Model Updates: 218,838
Cumulative Timesteps: 1,825,733,348

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,859.42564
Policy Entropy: 1.90462
Value Function Loss: 0.02352

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07078
Policy Update Magnitude: 0.27934
Value Function Update Magnitude: 0.26324

Collected Steps per Second: 20,441.15544
Overall Steps per Second: 10,093.59743

Timestep Collection Time: 2.44702
Timestep Consumption Time: 2.50859
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.95562

Cumulative Model Updates: 218,844
Cumulative Timesteps: 1,825,783,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1825783368...
Checkpoint 1825783368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,619.09560
Policy Entropy: 1.90455
Value Function Loss: 0.02579

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07049
Policy Update Magnitude: 0.28724
Value Function Update Magnitude: 0.29806

Collected Steps per Second: 19,459.40730
Overall Steps per Second: 9,693.95747

Timestep Collection Time: 2.57007
Timestep Consumption Time: 2.58902
PPO Batch Consumption Time: 0.30183
Total Iteration Time: 5.15909

Cumulative Model Updates: 218,850
Cumulative Timesteps: 1,825,833,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,444.56449
Policy Entropy: 1.91429
Value Function Loss: 0.02808

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07088
Policy Update Magnitude: 0.29605
Value Function Update Magnitude: 0.32020

Collected Steps per Second: 20,768.95906
Overall Steps per Second: 10,176.30144

Timestep Collection Time: 2.40754
Timestep Consumption Time: 2.50604
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.91357

Cumulative Model Updates: 218,856
Cumulative Timesteps: 1,825,883,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1825883382...
Checkpoint 1825883382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,069.52369
Policy Entropy: 1.91422
Value Function Loss: 0.02779

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.07203
Policy Update Magnitude: 0.29665
Value Function Update Magnitude: 0.30909

Collected Steps per Second: 20,040.95105
Overall Steps per Second: 9,981.15239

Timestep Collection Time: 2.49669
Timestep Consumption Time: 2.51636
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 5.01305

Cumulative Model Updates: 218,862
Cumulative Timesteps: 1,825,933,418

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,861.46205
Policy Entropy: 1.90761
Value Function Loss: 0.02718

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07521
Policy Update Magnitude: 0.29519
Value Function Update Magnitude: 0.31074

Collected Steps per Second: 19,292.56356
Overall Steps per Second: 9,626.61983

Timestep Collection Time: 2.59188
Timestep Consumption Time: 2.60247
PPO Batch Consumption Time: 0.30384
Total Iteration Time: 5.19435

Cumulative Model Updates: 218,868
Cumulative Timesteps: 1,825,983,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1825983422...
Checkpoint 1825983422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,849.85225
Policy Entropy: 1.90115
Value Function Loss: 0.02726

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07336
Policy Update Magnitude: 0.29928
Value Function Update Magnitude: 0.31042

Collected Steps per Second: 20,306.02173
Overall Steps per Second: 9,753.31541

Timestep Collection Time: 2.46331
Timestep Consumption Time: 2.66520
PPO Batch Consumption Time: 0.30963
Total Iteration Time: 5.12851

Cumulative Model Updates: 218,874
Cumulative Timesteps: 1,826,033,442

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,290.96203
Policy Entropy: 1.90252
Value Function Loss: 0.02683

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07143
Policy Update Magnitude: 0.29377
Value Function Update Magnitude: 0.31779

Collected Steps per Second: 20,944.84241
Overall Steps per Second: 10,052.64856

Timestep Collection Time: 2.38760
Timestep Consumption Time: 2.58700
PPO Batch Consumption Time: 0.29988
Total Iteration Time: 4.97461

Cumulative Model Updates: 218,880
Cumulative Timesteps: 1,826,083,450

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1826083450...
Checkpoint 1826083450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,447.90316
Policy Entropy: 1.91455
Value Function Loss: 0.02567

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.06743
Policy Update Magnitude: 0.28360
Value Function Update Magnitude: 0.32043

Collected Steps per Second: 20,365.96511
Overall Steps per Second: 10,008.33588

Timestep Collection Time: 2.45557
Timestep Consumption Time: 2.54127
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.99683

Cumulative Model Updates: 218,886
Cumulative Timesteps: 1,826,133,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,874.48381
Policy Entropy: 1.90297
Value Function Loss: 0.02576

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07034
Policy Update Magnitude: 0.28104
Value Function Update Magnitude: 0.30807

Collected Steps per Second: 21,494.91480
Overall Steps per Second: 10,213.69580

Timestep Collection Time: 2.32660
Timestep Consumption Time: 2.56977
PPO Batch Consumption Time: 0.29840
Total Iteration Time: 4.89637

Cumulative Model Updates: 218,892
Cumulative Timesteps: 1,826,183,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1826183470...
Checkpoint 1826183470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,930.09905
Policy Entropy: 1.89713
Value Function Loss: 0.02501

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06982
Policy Update Magnitude: 0.28154
Value Function Update Magnitude: 0.28406

Collected Steps per Second: 20,159.86577
Overall Steps per Second: 9,912.96722

Timestep Collection Time: 2.48097
Timestep Consumption Time: 2.56454
PPO Batch Consumption Time: 0.29991
Total Iteration Time: 5.04551

Cumulative Model Updates: 218,898
Cumulative Timesteps: 1,826,233,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,986.29624
Policy Entropy: 1.90041
Value Function Loss: 0.02624

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.06687
Policy Update Magnitude: 0.28349
Value Function Update Magnitude: 0.29595

Collected Steps per Second: 20,173.01514
Overall Steps per Second: 9,955.91467

Timestep Collection Time: 2.47975
Timestep Consumption Time: 2.54480
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 5.02455

Cumulative Model Updates: 218,904
Cumulative Timesteps: 1,826,283,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1826283510...
Checkpoint 1826283510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,144.83686
Policy Entropy: 1.92841
Value Function Loss: 0.02676

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07134
Policy Update Magnitude: 0.28914
Value Function Update Magnitude: 0.31372

Collected Steps per Second: 18,607.55163
Overall Steps per Second: 9,367.27723

Timestep Collection Time: 2.68762
Timestep Consumption Time: 2.65118
PPO Batch Consumption Time: 0.31625
Total Iteration Time: 5.33880

Cumulative Model Updates: 218,910
Cumulative Timesteps: 1,826,333,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,307.37618
Policy Entropy: 1.94179
Value Function Loss: 0.02475

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07536
Policy Update Magnitude: 0.28493
Value Function Update Magnitude: 0.31063

Collected Steps per Second: 20,773.13542
Overall Steps per Second: 10,135.23481

Timestep Collection Time: 2.40782
Timestep Consumption Time: 2.52724
PPO Batch Consumption Time: 0.30461
Total Iteration Time: 4.93506

Cumulative Model Updates: 218,916
Cumulative Timesteps: 1,826,383,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1826383538...
Checkpoint 1826383538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,754.34746
Policy Entropy: 1.93276
Value Function Loss: 0.02528

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07053
Policy Update Magnitude: 0.28284
Value Function Update Magnitude: 0.29469

Collected Steps per Second: 19,130.35928
Overall Steps per Second: 9,682.40234

Timestep Collection Time: 2.61438
Timestep Consumption Time: 2.55108
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 5.16545

Cumulative Model Updates: 218,922
Cumulative Timesteps: 1,826,433,552

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,207.86044
Policy Entropy: 1.92194
Value Function Loss: 0.02762

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07192
Policy Update Magnitude: 0.29077
Value Function Update Magnitude: 0.30604

Collected Steps per Second: 20,073.88332
Overall Steps per Second: 10,070.61046

Timestep Collection Time: 2.49150
Timestep Consumption Time: 2.47484
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.96633

Cumulative Model Updates: 218,928
Cumulative Timesteps: 1,826,483,566

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1826483566...
Checkpoint 1826483566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,157.99232
Policy Entropy: 1.92894
Value Function Loss: 0.02668

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07780
Policy Update Magnitude: 0.29025
Value Function Update Magnitude: 0.32466

Collected Steps per Second: 19,888.17266
Overall Steps per Second: 9,958.50583

Timestep Collection Time: 2.51516
Timestep Consumption Time: 2.50788
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 5.02304

Cumulative Model Updates: 218,934
Cumulative Timesteps: 1,826,533,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,892.84351
Policy Entropy: 1.93807
Value Function Loss: 0.02805

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07795
Policy Update Magnitude: 0.28687
Value Function Update Magnitude: 0.30857

Collected Steps per Second: 20,565.91728
Overall Steps per Second: 9,905.64359

Timestep Collection Time: 2.43121
Timestep Consumption Time: 2.61642
PPO Batch Consumption Time: 0.30927
Total Iteration Time: 5.04763

Cumulative Model Updates: 218,940
Cumulative Timesteps: 1,826,583,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1826583588...
Checkpoint 1826583588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,870.67616
Policy Entropy: 1.93655
Value Function Loss: 0.02529

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07469
Policy Update Magnitude: 0.28857
Value Function Update Magnitude: 0.31085

Collected Steps per Second: 19,433.28434
Overall Steps per Second: 9,838.50310

Timestep Collection Time: 2.57363
Timestep Consumption Time: 2.50987
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 5.08350

Cumulative Model Updates: 218,946
Cumulative Timesteps: 1,826,633,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,243.77879
Policy Entropy: 1.91541
Value Function Loss: 0.02793

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07491
Policy Update Magnitude: 0.29327
Value Function Update Magnitude: 0.33162

Collected Steps per Second: 20,973.62837
Overall Steps per Second: 9,973.15503

Timestep Collection Time: 2.38490
Timestep Consumption Time: 2.63056
PPO Batch Consumption Time: 0.31001
Total Iteration Time: 5.01546

Cumulative Model Updates: 218,952
Cumulative Timesteps: 1,826,683,622

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1826683622...
Checkpoint 1826683622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,743.46708
Policy Entropy: 1.92459
Value Function Loss: 0.02914

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.30475
Value Function Update Magnitude: 0.30706

Collected Steps per Second: 19,335.25119
Overall Steps per Second: 9,841.67501

Timestep Collection Time: 2.58657
Timestep Consumption Time: 2.49508
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 5.08166

Cumulative Model Updates: 218,958
Cumulative Timesteps: 1,826,733,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,917.12389
Policy Entropy: 1.92949
Value Function Loss: 0.03009

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07211
Policy Update Magnitude: 0.30643
Value Function Update Magnitude: 0.34066

Collected Steps per Second: 21,265.11171
Overall Steps per Second: 10,089.81749

Timestep Collection Time: 2.35165
Timestep Consumption Time: 2.60464
PPO Batch Consumption Time: 0.30179
Total Iteration Time: 4.95628

Cumulative Model Updates: 218,964
Cumulative Timesteps: 1,826,783,642

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1826783642...
Checkpoint 1826783642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,024.07487
Policy Entropy: 1.92567
Value Function Loss: 0.02975

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07217
Policy Update Magnitude: 0.30333
Value Function Update Magnitude: 0.35377

Collected Steps per Second: 19,093.40788
Overall Steps per Second: 9,854.69284

Timestep Collection Time: 2.61923
Timestep Consumption Time: 2.45551
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 5.07474

Cumulative Model Updates: 218,970
Cumulative Timesteps: 1,826,833,652

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,565.80506
Policy Entropy: 1.92817
Value Function Loss: 0.02692

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.29582
Value Function Update Magnitude: 0.30293

Collected Steps per Second: 21,109.74027
Overall Steps per Second: 10,061.29851

Timestep Collection Time: 2.37000
Timestep Consumption Time: 2.60252
PPO Batch Consumption Time: 0.30500
Total Iteration Time: 4.97252

Cumulative Model Updates: 218,976
Cumulative Timesteps: 1,826,883,682

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1826883682...
Checkpoint 1826883682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,786.68974
Policy Entropy: 1.92859
Value Function Loss: 0.02785

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07443
Policy Update Magnitude: 0.29774
Value Function Update Magnitude: 0.26970

Collected Steps per Second: 19,993.33875
Overall Steps per Second: 9,925.58431

Timestep Collection Time: 2.50163
Timestep Consumption Time: 2.53747
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 5.03910

Cumulative Model Updates: 218,982
Cumulative Timesteps: 1,826,933,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,194.99735
Policy Entropy: 1.93815
Value Function Loss: 0.02984

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07693
Policy Update Magnitude: 0.30404
Value Function Update Magnitude: 0.23158

Collected Steps per Second: 20,870.24230
Overall Steps per Second: 10,131.58217

Timestep Collection Time: 2.39700
Timestep Consumption Time: 2.54063
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.93763

Cumulative Model Updates: 218,988
Cumulative Timesteps: 1,826,983,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1826983724...
Checkpoint 1826983724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,998.91148
Policy Entropy: 1.92736
Value Function Loss: 0.02946

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.30123
Value Function Update Magnitude: 0.22191

Collected Steps per Second: 19,751.44447
Overall Steps per Second: 10,009.46802

Timestep Collection Time: 2.53176
Timestep Consumption Time: 2.46411
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.99587

Cumulative Model Updates: 218,994
Cumulative Timesteps: 1,827,033,730

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,876.29446
Policy Entropy: 1.92294
Value Function Loss: 0.03055

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.08861
Policy Update Magnitude: 0.30470
Value Function Update Magnitude: 0.21913

Collected Steps per Second: 20,921.57138
Overall Steps per Second: 10,018.17090

Timestep Collection Time: 2.39083
Timestep Consumption Time: 2.60209
PPO Batch Consumption Time: 0.30646
Total Iteration Time: 4.99293

Cumulative Model Updates: 219,000
Cumulative Timesteps: 1,827,083,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1827083750...
Checkpoint 1827083750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,606.44133
Policy Entropy: 1.91004
Value Function Loss: 0.03133

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.30978
Value Function Update Magnitude: 0.18799

Collected Steps per Second: 20,504.62335
Overall Steps per Second: 10,256.77833

Timestep Collection Time: 2.44062
Timestep Consumption Time: 2.43849
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.87911

Cumulative Model Updates: 219,006
Cumulative Timesteps: 1,827,133,794

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,395.45139
Policy Entropy: 1.90243
Value Function Loss: 0.03136

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.08810
Policy Update Magnitude: 0.30484
Value Function Update Magnitude: 0.18713

Collected Steps per Second: 21,953.22499
Overall Steps per Second: 10,450.66000

Timestep Collection Time: 2.27766
Timestep Consumption Time: 2.50692
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.78458

Cumulative Model Updates: 219,012
Cumulative Timesteps: 1,827,183,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1827183796...
Checkpoint 1827183796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,649.83611
Policy Entropy: 1.90611
Value Function Loss: 0.02938

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07840
Policy Update Magnitude: 0.30221
Value Function Update Magnitude: 0.23486

Collected Steps per Second: 19,808.80469
Overall Steps per Second: 10,274.05214

Timestep Collection Time: 2.52585
Timestep Consumption Time: 2.34409
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.86994

Cumulative Model Updates: 219,018
Cumulative Timesteps: 1,827,233,830

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,019.81976
Policy Entropy: 1.91426
Value Function Loss: 0.02675

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.30014
Value Function Update Magnitude: 0.24345

Collected Steps per Second: 21,381.12507
Overall Steps per Second: 10,447.10282

Timestep Collection Time: 2.33879
Timestep Consumption Time: 2.44780
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.78659

Cumulative Model Updates: 219,024
Cumulative Timesteps: 1,827,283,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1827283836...
Checkpoint 1827283836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,476.36320
Policy Entropy: 1.92408
Value Function Loss: 0.02828

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.29525
Value Function Update Magnitude: 0.26072

Collected Steps per Second: 21,021.09964
Overall Steps per Second: 10,552.97888

Timestep Collection Time: 2.37961
Timestep Consumption Time: 2.36047
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.74008

Cumulative Model Updates: 219,030
Cumulative Timesteps: 1,827,333,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,398.45834
Policy Entropy: 1.93780
Value Function Loss: 0.02723

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.28706
Value Function Update Magnitude: 0.24568

Collected Steps per Second: 21,401.61081
Overall Steps per Second: 10,500.28789

Timestep Collection Time: 2.33693
Timestep Consumption Time: 2.42618
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.76311

Cumulative Model Updates: 219,036
Cumulative Timesteps: 1,827,383,872

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1827383872...
Checkpoint 1827383872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,065.23051
Policy Entropy: 1.93877
Value Function Loss: 0.02878

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.28863
Value Function Update Magnitude: 0.23739

Collected Steps per Second: 21,593.89617
Overall Steps per Second: 10,434.76882

Timestep Collection Time: 2.31630
Timestep Consumption Time: 2.47710
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.79340

Cumulative Model Updates: 219,042
Cumulative Timesteps: 1,827,433,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,728.71238
Policy Entropy: 1.93201
Value Function Loss: 0.02561

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08035
Policy Update Magnitude: 0.28942
Value Function Update Magnitude: 0.26417

Collected Steps per Second: 22,035.29047
Overall Steps per Second: 10,672.21628

Timestep Collection Time: 2.27009
Timestep Consumption Time: 2.41704
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.68712

Cumulative Model Updates: 219,048
Cumulative Timesteps: 1,827,483,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1827483912...
Checkpoint 1827483912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,016.49376
Policy Entropy: 1.92216
Value Function Loss: 0.02705

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07581
Policy Update Magnitude: 0.28607
Value Function Update Magnitude: 0.25125

Collected Steps per Second: 21,259.23720
Overall Steps per Second: 10,271.52798

Timestep Collection Time: 2.35239
Timestep Consumption Time: 2.51641
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.86880

Cumulative Model Updates: 219,054
Cumulative Timesteps: 1,827,533,922

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,657.29489
Policy Entropy: 1.91290
Value Function Loss: 0.02708

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07190
Policy Update Magnitude: 0.28771
Value Function Update Magnitude: 0.26272

Collected Steps per Second: 21,600.65108
Overall Steps per Second: 10,398.60314

Timestep Collection Time: 2.31604
Timestep Consumption Time: 2.49499
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.81103

Cumulative Model Updates: 219,060
Cumulative Timesteps: 1,827,583,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1827583950...
Checkpoint 1827583950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,460.94306
Policy Entropy: 1.91959
Value Function Loss: 0.02877

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.30081
Value Function Update Magnitude: 0.32294

Collected Steps per Second: 21,486.23966
Overall Steps per Second: 10,185.29190

Timestep Collection Time: 2.32847
Timestep Consumption Time: 2.58352
PPO Batch Consumption Time: 0.30532
Total Iteration Time: 4.91198

Cumulative Model Updates: 219,066
Cumulative Timesteps: 1,827,633,980

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,135.34233
Policy Entropy: 1.92812
Value Function Loss: 0.02820

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08358
Policy Update Magnitude: 0.30624
Value Function Update Magnitude: 0.35681

Collected Steps per Second: 22,338.41792
Overall Steps per Second: 10,461.76783

Timestep Collection Time: 2.23919
Timestep Consumption Time: 2.54203
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.78122

Cumulative Model Updates: 219,072
Cumulative Timesteps: 1,827,684,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1827684000...
Checkpoint 1827684000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,120.11330
Policy Entropy: 1.91926
Value Function Loss: 0.02746

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.08800
Policy Update Magnitude: 0.29906
Value Function Update Magnitude: 0.31461

Collected Steps per Second: 21,584.66301
Overall Steps per Second: 10,395.58749

Timestep Collection Time: 2.31803
Timestep Consumption Time: 2.49497
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.81300

Cumulative Model Updates: 219,078
Cumulative Timesteps: 1,827,734,034

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,281.71285
Policy Entropy: 1.92149
Value Function Loss: 0.02821

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.30053
Value Function Update Magnitude: 0.29018

Collected Steps per Second: 22,040.53380
Overall Steps per Second: 10,596.41524

Timestep Collection Time: 2.26964
Timestep Consumption Time: 2.45121
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.72084

Cumulative Model Updates: 219,084
Cumulative Timesteps: 1,827,784,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1827784058...
Checkpoint 1827784058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,583.64897
Policy Entropy: 1.92052
Value Function Loss: 0.02976

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07869
Policy Update Magnitude: 0.30392
Value Function Update Magnitude: 0.28056

Collected Steps per Second: 21,512.76679
Overall Steps per Second: 10,324.94949

Timestep Collection Time: 2.32587
Timestep Consumption Time: 2.52025
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.84613

Cumulative Model Updates: 219,090
Cumulative Timesteps: 1,827,834,094

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,333.68094
Policy Entropy: 1.94048
Value Function Loss: 0.03115

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.07648
Policy Update Magnitude: 0.30461
Value Function Update Magnitude: 0.25757

Collected Steps per Second: 21,696.43755
Overall Steps per Second: 10,432.12289

Timestep Collection Time: 2.30499
Timestep Consumption Time: 2.48886
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.79385

Cumulative Model Updates: 219,096
Cumulative Timesteps: 1,827,884,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1827884104...
Checkpoint 1827884104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,002.67377
Policy Entropy: 1.93635
Value Function Loss: 0.03055

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07607
Policy Update Magnitude: 0.30215
Value Function Update Magnitude: 0.29261

Collected Steps per Second: 20,835.82589
Overall Steps per Second: 10,192.18450

Timestep Collection Time: 2.40048
Timestep Consumption Time: 2.50681
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.90729

Cumulative Model Updates: 219,102
Cumulative Timesteps: 1,827,934,120

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,670.52915
Policy Entropy: 1.92288
Value Function Loss: 0.03037

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07735
Policy Update Magnitude: 0.30569
Value Function Update Magnitude: 0.29016

Collected Steps per Second: 21,763.98433
Overall Steps per Second: 10,414.95857

Timestep Collection Time: 2.29848
Timestep Consumption Time: 2.50462
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.80309

Cumulative Model Updates: 219,108
Cumulative Timesteps: 1,827,984,144

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1827984144...
Checkpoint 1827984144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,366.51284
Policy Entropy: 1.91898
Value Function Loss: 0.03318

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.08155
Policy Update Magnitude: 0.31150
Value Function Update Magnitude: 0.30297

Collected Steps per Second: 21,595.60657
Overall Steps per Second: 10,161.08169

Timestep Collection Time: 2.31575
Timestep Consumption Time: 2.60597
PPO Batch Consumption Time: 0.31004
Total Iteration Time: 4.92172

Cumulative Model Updates: 219,114
Cumulative Timesteps: 1,828,034,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,941.54616
Policy Entropy: 1.91518
Value Function Loss: 0.03150

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.31049
Value Function Update Magnitude: 0.34591

Collected Steps per Second: 21,712.66667
Overall Steps per Second: 10,528.24091

Timestep Collection Time: 2.30372
Timestep Consumption Time: 2.44731
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.75103

Cumulative Model Updates: 219,120
Cumulative Timesteps: 1,828,084,174

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1828084174...
Checkpoint 1828084174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,012.52011
Policy Entropy: 1.91321
Value Function Loss: 0.03059

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08127
Policy Update Magnitude: 0.30534
Value Function Update Magnitude: 0.36052

Collected Steps per Second: 21,479.90803
Overall Steps per Second: 10,340.49626

Timestep Collection Time: 2.32859
Timestep Consumption Time: 2.50850
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.83710

Cumulative Model Updates: 219,126
Cumulative Timesteps: 1,828,134,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,448.27339
Policy Entropy: 1.91047
Value Function Loss: 0.02642

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.30124
Value Function Update Magnitude: 0.35252

Collected Steps per Second: 21,944.53772
Overall Steps per Second: 10,464.80787

Timestep Collection Time: 2.27911
Timestep Consumption Time: 2.50015
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.77926

Cumulative Model Updates: 219,132
Cumulative Timesteps: 1,828,184,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1828184206...
Checkpoint 1828184206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,433.29582
Policy Entropy: 1.88698
Value Function Loss: 0.02796

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07293
Policy Update Magnitude: 0.30161
Value Function Update Magnitude: 0.35273

Collected Steps per Second: 20,419.19321
Overall Steps per Second: 10,180.06279

Timestep Collection Time: 2.44936
Timestep Consumption Time: 2.46357
PPO Batch Consumption Time: 0.29788
Total Iteration Time: 4.91294

Cumulative Model Updates: 219,138
Cumulative Timesteps: 1,828,234,220

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,447.71176
Policy Entropy: 1.88347
Value Function Loss: 0.02909

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07530
Policy Update Magnitude: 0.30500
Value Function Update Magnitude: 0.36293

Collected Steps per Second: 20,678.02243
Overall Steps per Second: 10,398.61683

Timestep Collection Time: 2.41803
Timestep Consumption Time: 2.39031
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.80833

Cumulative Model Updates: 219,144
Cumulative Timesteps: 1,828,284,220

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1828284220...
Checkpoint 1828284220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,353.71200
Policy Entropy: 1.88060
Value Function Loss: 0.02801

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07632
Policy Update Magnitude: 0.30445
Value Function Update Magnitude: 0.37873

Collected Steps per Second: 21,063.95375
Overall Steps per Second: 10,576.28419

Timestep Collection Time: 2.37410
Timestep Consumption Time: 2.35421
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.72831

Cumulative Model Updates: 219,150
Cumulative Timesteps: 1,828,334,228

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,364.63685
Policy Entropy: 1.91147
Value Function Loss: 0.02562

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07469
Policy Update Magnitude: 0.29602
Value Function Update Magnitude: 0.36886

Collected Steps per Second: 21,639.38619
Overall Steps per Second: 10,437.67340

Timestep Collection Time: 2.31143
Timestep Consumption Time: 2.48063
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.79206

Cumulative Model Updates: 219,156
Cumulative Timesteps: 1,828,384,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1828384246...
Checkpoint 1828384246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,959.16603
Policy Entropy: 1.91559
Value Function Loss: 0.02503

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07352
Policy Update Magnitude: 0.28990
Value Function Update Magnitude: 0.33920

Collected Steps per Second: 21,309.18854
Overall Steps per Second: 10,346.91078

Timestep Collection Time: 2.34669
Timestep Consumption Time: 2.48625
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.83294

Cumulative Model Updates: 219,162
Cumulative Timesteps: 1,828,434,252

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,736.07053
Policy Entropy: 1.91982
Value Function Loss: 0.02570

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08184
Policy Update Magnitude: 0.29594
Value Function Update Magnitude: 0.33468

Collected Steps per Second: 22,159.19073
Overall Steps per Second: 10,736.09173

Timestep Collection Time: 2.25802
Timestep Consumption Time: 2.40252
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.66054

Cumulative Model Updates: 219,168
Cumulative Timesteps: 1,828,484,288

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1828484288...
Checkpoint 1828484288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,239.17237
Policy Entropy: 1.90878
Value Function Loss: 0.02483

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.29923
Value Function Update Magnitude: 0.33261

Collected Steps per Second: 21,353.41320
Overall Steps per Second: 10,293.78077

Timestep Collection Time: 2.34286
Timestep Consumption Time: 2.51716
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.86002

Cumulative Model Updates: 219,174
Cumulative Timesteps: 1,828,534,316

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,403.86109
Policy Entropy: 1.91643
Value Function Loss: 0.02591

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.30550
Value Function Update Magnitude: 0.31332

Collected Steps per Second: 22,076.02256
Overall Steps per Second: 10,522.41728

Timestep Collection Time: 2.26599
Timestep Consumption Time: 2.48805
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.75404

Cumulative Model Updates: 219,180
Cumulative Timesteps: 1,828,584,340

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1828584340...
Checkpoint 1828584340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,066.17359
Policy Entropy: 1.93025
Value Function Loss: 0.02476

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07549
Policy Update Magnitude: 0.29568
Value Function Update Magnitude: 0.28854

Collected Steps per Second: 21,741.31754
Overall Steps per Second: 10,561.47818

Timestep Collection Time: 2.30004
Timestep Consumption Time: 2.43471
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.73475

Cumulative Model Updates: 219,186
Cumulative Timesteps: 1,828,634,346

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,557.94065
Policy Entropy: 1.94123
Value Function Loss: 0.02670

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07405
Policy Update Magnitude: 0.29706
Value Function Update Magnitude: 0.30061

Collected Steps per Second: 21,062.32967
Overall Steps per Second: 10,405.46901

Timestep Collection Time: 2.37486
Timestep Consumption Time: 2.43223
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.80709

Cumulative Model Updates: 219,192
Cumulative Timesteps: 1,828,684,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1828684366...
Checkpoint 1828684366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,456.67081
Policy Entropy: 1.94311
Value Function Loss: 0.02395

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07265
Policy Update Magnitude: 0.29379
Value Function Update Magnitude: 0.31635

Collected Steps per Second: 21,370.93465
Overall Steps per Second: 10,312.20637

Timestep Collection Time: 2.34066
Timestep Consumption Time: 2.51010
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.85076

Cumulative Model Updates: 219,198
Cumulative Timesteps: 1,828,734,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,315.12475
Policy Entropy: 1.93725
Value Function Loss: 0.02369

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07230
Policy Update Magnitude: 0.28325
Value Function Update Magnitude: 0.31218

Collected Steps per Second: 22,017.14958
Overall Steps per Second: 10,420.75295

Timestep Collection Time: 2.27214
Timestep Consumption Time: 2.52847
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.80061

Cumulative Model Updates: 219,204
Cumulative Timesteps: 1,828,784,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1828784414...
Checkpoint 1828784414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,766.45053
Policy Entropy: 1.93802
Value Function Loss: 0.02319

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07143
Policy Update Magnitude: 0.28357
Value Function Update Magnitude: 0.29560

Collected Steps per Second: 21,607.54969
Overall Steps per Second: 10,524.27426

Timestep Collection Time: 2.31521
Timestep Consumption Time: 2.43818
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.75339

Cumulative Model Updates: 219,210
Cumulative Timesteps: 1,828,834,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,578.30608
Policy Entropy: 1.93867
Value Function Loss: 0.02394

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07290
Policy Update Magnitude: 0.28549
Value Function Update Magnitude: 0.28281

Collected Steps per Second: 19,634.48912
Overall Steps per Second: 9,820.56757

Timestep Collection Time: 2.54705
Timestep Consumption Time: 2.54532
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 5.09237

Cumulative Model Updates: 219,216
Cumulative Timesteps: 1,828,884,450

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1828884450...
Checkpoint 1828884450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,857.66681
Policy Entropy: 1.93923
Value Function Loss: 0.02374

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07250
Policy Update Magnitude: 0.28699
Value Function Update Magnitude: 0.27524

Collected Steps per Second: 20,418.87216
Overall Steps per Second: 10,005.85772

Timestep Collection Time: 2.45018
Timestep Consumption Time: 2.54989
PPO Batch Consumption Time: 0.29693
Total Iteration Time: 5.00007

Cumulative Model Updates: 219,222
Cumulative Timesteps: 1,828,934,480

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,828.14546
Policy Entropy: 1.91653
Value Function Loss: 0.02325

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07309
Policy Update Magnitude: 0.28724
Value Function Update Magnitude: 0.27372

Collected Steps per Second: 20,726.51311
Overall Steps per Second: 10,039.80726

Timestep Collection Time: 2.41256
Timestep Consumption Time: 2.56801
PPO Batch Consumption Time: 0.29954
Total Iteration Time: 4.98057

Cumulative Model Updates: 219,228
Cumulative Timesteps: 1,828,984,484

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1828984484...
Checkpoint 1828984484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,787.30936
Policy Entropy: 1.90655
Value Function Loss: 0.02451

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07461
Policy Update Magnitude: 0.28921
Value Function Update Magnitude: 0.27971

Collected Steps per Second: 20,357.26048
Overall Steps per Second: 10,089.62530

Timestep Collection Time: 2.45731
Timestep Consumption Time: 2.50066
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.95796

Cumulative Model Updates: 219,234
Cumulative Timesteps: 1,829,034,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,472.30271
Policy Entropy: 1.91886
Value Function Loss: 0.02686

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07558
Policy Update Magnitude: 0.29699
Value Function Update Magnitude: 0.29943

Collected Steps per Second: 21,031.11338
Overall Steps per Second: 10,149.80461

Timestep Collection Time: 2.37762
Timestep Consumption Time: 2.54898
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.92660

Cumulative Model Updates: 219,240
Cumulative Timesteps: 1,829,084,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1829084512...
Checkpoint 1829084512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,028.98104
Policy Entropy: 1.93234
Value Function Loss: 0.03210

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.30872
Value Function Update Magnitude: 0.30895

Collected Steps per Second: 20,564.21598
Overall Steps per Second: 10,146.59950

Timestep Collection Time: 2.43238
Timestep Consumption Time: 2.49735
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.92973

Cumulative Model Updates: 219,246
Cumulative Timesteps: 1,829,134,532

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,776.60487
Policy Entropy: 1.94156
Value Function Loss: 0.03100

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08157
Policy Update Magnitude: 0.31182
Value Function Update Magnitude: 0.32364

Collected Steps per Second: 20,340.08955
Overall Steps per Second: 10,108.19366

Timestep Collection Time: 2.45820
Timestep Consumption Time: 2.48828
PPO Batch Consumption Time: 0.30019
Total Iteration Time: 4.94648

Cumulative Model Updates: 219,252
Cumulative Timesteps: 1,829,184,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1829184532...
Checkpoint 1829184532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,524.19579
Policy Entropy: 1.93484
Value Function Loss: 0.03301

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.31668
Value Function Update Magnitude: 0.32006

Collected Steps per Second: 19,982.40973
Overall Steps per Second: 10,139.14980

Timestep Collection Time: 2.50320
Timestep Consumption Time: 2.43015
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.93335

Cumulative Model Updates: 219,258
Cumulative Timesteps: 1,829,234,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,716.73153
Policy Entropy: 1.91176
Value Function Loss: 0.02771

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07844
Policy Update Magnitude: 0.30548
Value Function Update Magnitude: 0.31782

Collected Steps per Second: 20,483.85678
Overall Steps per Second: 10,170.35652

Timestep Collection Time: 2.44153
Timestep Consumption Time: 2.47590
PPO Batch Consumption Time: 0.29923
Total Iteration Time: 4.91743

Cumulative Model Updates: 219,264
Cumulative Timesteps: 1,829,284,564

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1829284564...
Checkpoint 1829284564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,153.71329
Policy Entropy: 1.90795
Value Function Loss: 0.02856

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07272
Policy Update Magnitude: 0.29387
Value Function Update Magnitude: 0.29210

Collected Steps per Second: 19,995.24140
Overall Steps per Second: 10,131.75227

Timestep Collection Time: 2.50200
Timestep Consumption Time: 2.43575
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.93774

Cumulative Model Updates: 219,270
Cumulative Timesteps: 1,829,334,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,220.89708
Policy Entropy: 1.90318
Value Function Loss: 0.02551

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07507
Policy Update Magnitude: 0.29338
Value Function Update Magnitude: 0.28935

Collected Steps per Second: 20,556.17546
Overall Steps per Second: 10,042.95739

Timestep Collection Time: 2.43372
Timestep Consumption Time: 2.54768
PPO Batch Consumption Time: 0.30020
Total Iteration Time: 4.98140

Cumulative Model Updates: 219,276
Cumulative Timesteps: 1,829,384,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1829384620...
Checkpoint 1829384620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,539.29935
Policy Entropy: 1.90580
Value Function Loss: 0.02598

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07336
Policy Update Magnitude: 0.29473
Value Function Update Magnitude: 0.29214

Collected Steps per Second: 20,634.21435
Overall Steps per Second: 10,226.07188

Timestep Collection Time: 2.42403
Timestep Consumption Time: 2.46719
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.89122

Cumulative Model Updates: 219,282
Cumulative Timesteps: 1,829,434,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,208.16232
Policy Entropy: 1.91673
Value Function Loss: 0.02494

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07275
Policy Update Magnitude: 0.29471
Value Function Update Magnitude: 0.28092

Collected Steps per Second: 20,971.60881
Overall Steps per Second: 10,312.25776

Timestep Collection Time: 2.38561
Timestep Consumption Time: 2.46590
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.85151

Cumulative Model Updates: 219,288
Cumulative Timesteps: 1,829,484,668

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1829484668...
Checkpoint 1829484668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,665.06485
Policy Entropy: 1.91764
Value Function Loss: 0.02449

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07401
Policy Update Magnitude: 0.29390
Value Function Update Magnitude: 0.30226

Collected Steps per Second: 20,731.98146
Overall Steps per Second: 10,196.80482

Timestep Collection Time: 2.41241
Timestep Consumption Time: 2.49246
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.90487

Cumulative Model Updates: 219,294
Cumulative Timesteps: 1,829,534,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,895.55500
Policy Entropy: 1.91962
Value Function Loss: 0.02802

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07664
Policy Update Magnitude: 0.29386
Value Function Update Magnitude: 0.32735

Collected Steps per Second: 21,152.73032
Overall Steps per Second: 10,167.27326

Timestep Collection Time: 2.36404
Timestep Consumption Time: 2.55428
PPO Batch Consumption Time: 0.29920
Total Iteration Time: 4.91833

Cumulative Model Updates: 219,300
Cumulative Timesteps: 1,829,584,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1829584688...
Checkpoint 1829584688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,869.36248
Policy Entropy: 1.91280
Value Function Loss: 0.02861

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07568
Policy Update Magnitude: 0.30132
Value Function Update Magnitude: 0.33060

Collected Steps per Second: 20,730.41341
Overall Steps per Second: 10,181.05084

Timestep Collection Time: 2.41413
Timestep Consumption Time: 2.50147
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.91560

Cumulative Model Updates: 219,306
Cumulative Timesteps: 1,829,634,734

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,771.13294
Policy Entropy: 1.91008
Value Function Loss: 0.02813

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.30220
Value Function Update Magnitude: 0.33367

Collected Steps per Second: 21,139.97296
Overall Steps per Second: 10,152.94961

Timestep Collection Time: 2.36632
Timestep Consumption Time: 2.56072
PPO Batch Consumption Time: 0.29884
Total Iteration Time: 4.92704

Cumulative Model Updates: 219,312
Cumulative Timesteps: 1,829,684,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1829684758...
Checkpoint 1829684758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,195.01931
Policy Entropy: 1.89365
Value Function Loss: 0.02654

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07130
Policy Update Magnitude: 0.29411
Value Function Update Magnitude: 0.33012

Collected Steps per Second: 20,763.94775
Overall Steps per Second: 10,107.27090

Timestep Collection Time: 2.40927
Timestep Consumption Time: 2.54023
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.94951

Cumulative Model Updates: 219,318
Cumulative Timesteps: 1,829,734,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,329.58495
Policy Entropy: 1.90140
Value Function Loss: 0.02647

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07241
Policy Update Magnitude: 0.29950
Value Function Update Magnitude: 0.31787

Collected Steps per Second: 21,084.11081
Overall Steps per Second: 10,123.37781

Timestep Collection Time: 2.37202
Timestep Consumption Time: 2.56823
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.94025

Cumulative Model Updates: 219,324
Cumulative Timesteps: 1,829,784,796

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1829784796...
Checkpoint 1829784796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,537.80961
Policy Entropy: 1.88925
Value Function Loss: 0.02748

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07428
Policy Update Magnitude: 0.30273
Value Function Update Magnitude: 0.32328

Collected Steps per Second: 20,662.74268
Overall Steps per Second: 10,092.72092

Timestep Collection Time: 2.42098
Timestep Consumption Time: 2.53547
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.95644

Cumulative Model Updates: 219,330
Cumulative Timesteps: 1,829,834,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,818.19275
Policy Entropy: 1.89797
Value Function Loss: 0.02933

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07739
Policy Update Magnitude: 0.30328
Value Function Update Magnitude: 0.35258

Collected Steps per Second: 20,831.87163
Overall Steps per Second: 9,886.83567

Timestep Collection Time: 2.40017
Timestep Consumption Time: 2.65706
PPO Batch Consumption Time: 0.31164
Total Iteration Time: 5.05723

Cumulative Model Updates: 219,336
Cumulative Timesteps: 1,829,884,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1829884820...
Checkpoint 1829884820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,377.16600
Policy Entropy: 1.88527
Value Function Loss: 0.02735

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07430
Policy Update Magnitude: 0.30513
Value Function Update Magnitude: 0.37649

Collected Steps per Second: 17,170.06819
Overall Steps per Second: 8,887.23079

Timestep Collection Time: 2.91298
Timestep Consumption Time: 2.71487
PPO Batch Consumption Time: 0.32070
Total Iteration Time: 5.62785

Cumulative Model Updates: 219,342
Cumulative Timesteps: 1,829,934,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,424.63609
Policy Entropy: 1.89075
Value Function Loss: 0.02870

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07460
Policy Update Magnitude: 0.30370
Value Function Update Magnitude: 0.37125

Collected Steps per Second: 20,483.89151
Overall Steps per Second: 10,017.65975

Timestep Collection Time: 2.44241
Timestep Consumption Time: 2.55177
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.99418

Cumulative Model Updates: 219,348
Cumulative Timesteps: 1,829,984,866

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1829984866...
Checkpoint 1829984866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,250.01729
Policy Entropy: 1.89959
Value Function Loss: 0.02617

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07488
Policy Update Magnitude: 0.30300
Value Function Update Magnitude: 0.36115

Collected Steps per Second: 20,160.88067
Overall Steps per Second: 9,851.62070

Timestep Collection Time: 2.48045
Timestep Consumption Time: 2.59567
PPO Batch Consumption Time: 0.30180
Total Iteration Time: 5.07612

Cumulative Model Updates: 219,354
Cumulative Timesteps: 1,830,034,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,614.24861
Policy Entropy: 1.89905
Value Function Loss: 0.02456

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07238
Policy Update Magnitude: 0.29448
Value Function Update Magnitude: 0.32741

Collected Steps per Second: 20,616.61577
Overall Steps per Second: 10,044.18889

Timestep Collection Time: 2.42736
Timestep Consumption Time: 2.55502
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.98238

Cumulative Model Updates: 219,360
Cumulative Timesteps: 1,830,084,918

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1830084918...
Checkpoint 1830084918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,685.42000
Policy Entropy: 1.90853
Value Function Loss: 0.02182

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07109
Policy Update Magnitude: 0.28881
Value Function Update Magnitude: 0.28864

Collected Steps per Second: 20,339.93436
Overall Steps per Second: 10,035.42418

Timestep Collection Time: 2.45871
Timestep Consumption Time: 2.52464
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.98335

Cumulative Model Updates: 219,366
Cumulative Timesteps: 1,830,134,928

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,699.89897
Policy Entropy: 1.88448
Value Function Loss: 0.02246

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07061
Policy Update Magnitude: 0.28435
Value Function Update Magnitude: 0.26259

Collected Steps per Second: 20,477.12420
Overall Steps per Second: 10,265.76424

Timestep Collection Time: 2.44312
Timestep Consumption Time: 2.43017
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.87329

Cumulative Model Updates: 219,372
Cumulative Timesteps: 1,830,184,956

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1830184956...
Checkpoint 1830184956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,670.04891
Policy Entropy: 1.89775
Value Function Loss: 0.02586

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07074
Policy Update Magnitude: 0.28772
Value Function Update Magnitude: 0.26409

Collected Steps per Second: 20,115.42202
Overall Steps per Second: 10,211.61838

Timestep Collection Time: 2.48705
Timestep Consumption Time: 2.41208
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.89913

Cumulative Model Updates: 219,378
Cumulative Timesteps: 1,830,234,984

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,666.31291
Policy Entropy: 1.89483
Value Function Loss: 0.02750

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07023
Policy Update Magnitude: 0.29102
Value Function Update Magnitude: 0.30108

Collected Steps per Second: 20,355.63098
Overall Steps per Second: 10,122.14164

Timestep Collection Time: 2.45711
Timestep Consumption Time: 2.48414
PPO Batch Consumption Time: 0.29808
Total Iteration Time: 4.94125

Cumulative Model Updates: 219,384
Cumulative Timesteps: 1,830,285,000

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1830285000...
Checkpoint 1830285000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,303.48229
Policy Entropy: 1.90505
Value Function Loss: 0.02966

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07288
Policy Update Magnitude: 0.29530
Value Function Update Magnitude: 0.29801

Collected Steps per Second: 19,808.46067
Overall Steps per Second: 10,117.57699

Timestep Collection Time: 2.52579
Timestep Consumption Time: 2.41927
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.94506

Cumulative Model Updates: 219,390
Cumulative Timesteps: 1,830,335,032

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,995.24157
Policy Entropy: 1.91334
Value Function Loss: 0.03133

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07661
Policy Update Magnitude: 0.30020
Value Function Update Magnitude: 0.31309

Collected Steps per Second: 20,465.34531
Overall Steps per Second: 10,037.87211

Timestep Collection Time: 2.44511
Timestep Consumption Time: 2.54001
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.98512

Cumulative Model Updates: 219,396
Cumulative Timesteps: 1,830,385,072

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1830385072...
Checkpoint 1830385072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,476.69107
Policy Entropy: 1.91716
Value Function Loss: 0.03029

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07920
Policy Update Magnitude: 0.30367
Value Function Update Magnitude: 0.34714

Collected Steps per Second: 20,594.74565
Overall Steps per Second: 10,218.53702

Timestep Collection Time: 2.42848
Timestep Consumption Time: 2.46595
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.89444

Cumulative Model Updates: 219,402
Cumulative Timesteps: 1,830,435,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,878.21652
Policy Entropy: 1.92683
Value Function Loss: 0.02655

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07318
Policy Update Magnitude: 0.30210
Value Function Update Magnitude: 0.35109

Collected Steps per Second: 20,965.53435
Overall Steps per Second: 10,201.72864

Timestep Collection Time: 2.38620
Timestep Consumption Time: 2.51767
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.90387

Cumulative Model Updates: 219,408
Cumulative Timesteps: 1,830,485,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1830485114...
Checkpoint 1830485114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,808.90876
Policy Entropy: 1.90957
Value Function Loss: 0.02716

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07162
Policy Update Magnitude: 0.30658
Value Function Update Magnitude: 0.35212

Collected Steps per Second: 20,668.66565
Overall Steps per Second: 10,085.53990

Timestep Collection Time: 2.42173
Timestep Consumption Time: 2.54121
PPO Batch Consumption Time: 0.30038
Total Iteration Time: 4.96295

Cumulative Model Updates: 219,414
Cumulative Timesteps: 1,830,535,168

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,873.47040
Policy Entropy: 1.91016
Value Function Loss: 0.02981

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.30997
Value Function Update Magnitude: 0.36817

Collected Steps per Second: 21,154.06739
Overall Steps per Second: 10,288.25482

Timestep Collection Time: 2.36437
Timestep Consumption Time: 2.49710
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.86147

Cumulative Model Updates: 219,420
Cumulative Timesteps: 1,830,585,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1830585184...
Checkpoint 1830585184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,890.45203
Policy Entropy: 1.91395
Value Function Loss: 0.02817

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.08658
Policy Update Magnitude: 0.30773
Value Function Update Magnitude: 0.36121

Collected Steps per Second: 20,811.94805
Overall Steps per Second: 10,210.23483

Timestep Collection Time: 2.40362
Timestep Consumption Time: 2.49578
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.89940

Cumulative Model Updates: 219,426
Cumulative Timesteps: 1,830,635,208

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,328.92802
Policy Entropy: 1.93030
Value Function Loss: 0.02609

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.07935
Policy Update Magnitude: 0.30228
Value Function Update Magnitude: 0.35604

Collected Steps per Second: 21,109.15273
Overall Steps per Second: 10,164.55982

Timestep Collection Time: 2.36930
Timestep Consumption Time: 2.55113
PPO Batch Consumption Time: 0.29656
Total Iteration Time: 4.92043

Cumulative Model Updates: 219,432
Cumulative Timesteps: 1,830,685,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1830685222...
Checkpoint 1830685222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,122.12920
Policy Entropy: 1.91669
Value Function Loss: 0.02381

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.07603
Policy Update Magnitude: 0.29049
Value Function Update Magnitude: 0.34279

Collected Steps per Second: 20,743.18678
Overall Steps per Second: 10,171.29841

Timestep Collection Time: 2.41091
Timestep Consumption Time: 2.50586
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.91678

Cumulative Model Updates: 219,438
Cumulative Timesteps: 1,830,735,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,794.76819
Policy Entropy: 1.90954
Value Function Loss: 0.02557

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07291
Policy Update Magnitude: 0.29191
Value Function Update Magnitude: 0.33782

Collected Steps per Second: 21,000.39233
Overall Steps per Second: 10,078.85840

Timestep Collection Time: 2.38091
Timestep Consumption Time: 2.57997
PPO Batch Consumption Time: 0.30060
Total Iteration Time: 4.96088

Cumulative Model Updates: 219,444
Cumulative Timesteps: 1,830,785,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1830785232...
Checkpoint 1830785232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,030.87652
Policy Entropy: 1.89296
Value Function Loss: 0.02420

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.06832
Policy Update Magnitude: 0.29831
Value Function Update Magnitude: 0.32468

Collected Steps per Second: 20,876.58363
Overall Steps per Second: 10,218.41218

Timestep Collection Time: 2.39608
Timestep Consumption Time: 2.49920
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.89528

Cumulative Model Updates: 219,450
Cumulative Timesteps: 1,830,835,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,977.84352
Policy Entropy: 1.89619
Value Function Loss: 0.02440

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.29738
Value Function Update Magnitude: 0.33431

Collected Steps per Second: 20,759.00076
Overall Steps per Second: 10,041.91460

Timestep Collection Time: 2.41129
Timestep Consumption Time: 2.57342
PPO Batch Consumption Time: 0.30034
Total Iteration Time: 4.98471

Cumulative Model Updates: 219,456
Cumulative Timesteps: 1,830,885,310

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 1830885310...
Checkpoint 1830885310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,477.67659
Policy Entropy: 1.91356
Value Function Loss: 0.02592

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07104
Policy Update Magnitude: 0.29804
Value Function Update Magnitude: 0.30940

Collected Steps per Second: 20,873.63959
Overall Steps per Second: 10,231.46851

Timestep Collection Time: 2.39546
Timestep Consumption Time: 2.49162
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.88708

Cumulative Model Updates: 219,462
Cumulative Timesteps: 1,830,935,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,092.46962
Policy Entropy: 1.91753
Value Function Loss: 0.02622

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07258
Policy Update Magnitude: 0.29494
Value Function Update Magnitude: 0.25556

Collected Steps per Second: 20,474.94337
Overall Steps per Second: 9,973.51177

Timestep Collection Time: 2.44299
Timestep Consumption Time: 2.57230
PPO Batch Consumption Time: 0.29899
Total Iteration Time: 5.01528

Cumulative Model Updates: 219,468
Cumulative Timesteps: 1,830,985,332

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1830985332...
Checkpoint 1830985332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,537.28270
Policy Entropy: 1.91577
Value Function Loss: 0.02694

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06824
Policy Update Magnitude: 0.29576
Value Function Update Magnitude: 0.29006

Collected Steps per Second: 20,749.58584
Overall Steps per Second: 10,171.03644

Timestep Collection Time: 2.41084
Timestep Consumption Time: 2.50744
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.91828

Cumulative Model Updates: 219,474
Cumulative Timesteps: 1,831,035,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,459.91140
Policy Entropy: 1.90900
Value Function Loss: 0.02733

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06498
Policy Update Magnitude: 0.29618
Value Function Update Magnitude: 0.31929

Collected Steps per Second: 21,080.86380
Overall Steps per Second: 10,108.10924

Timestep Collection Time: 2.37258
Timestep Consumption Time: 2.57553
PPO Batch Consumption Time: 0.30060
Total Iteration Time: 4.94811

Cumulative Model Updates: 219,480
Cumulative Timesteps: 1,831,085,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1831085372...
Checkpoint 1831085372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,381.86149
Policy Entropy: 1.91894
Value Function Loss: 0.02834

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.06648
Policy Update Magnitude: 0.30036
Value Function Update Magnitude: 0.29063

Collected Steps per Second: 20,620.80917
Overall Steps per Second: 10,118.04842

Timestep Collection Time: 2.42483
Timestep Consumption Time: 2.51703
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.94186

Cumulative Model Updates: 219,486
Cumulative Timesteps: 1,831,135,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,485.53980
Policy Entropy: 1.92452
Value Function Loss: 0.02798

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07583
Policy Update Magnitude: 0.30102
Value Function Update Magnitude: 0.24277

Collected Steps per Second: 20,751.43588
Overall Steps per Second: 10,090.22113

Timestep Collection Time: 2.40957
Timestep Consumption Time: 2.54592
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.95549

Cumulative Model Updates: 219,492
Cumulative Timesteps: 1,831,185,376

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1831185376...
Checkpoint 1831185376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,654.72745
Policy Entropy: 1.91845
Value Function Loss: 0.02554

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07483
Policy Update Magnitude: 0.29275
Value Function Update Magnitude: 0.24613

Collected Steps per Second: 20,490.06546
Overall Steps per Second: 10,090.64602

Timestep Collection Time: 2.44206
Timestep Consumption Time: 2.51679
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.95885

Cumulative Model Updates: 219,498
Cumulative Timesteps: 1,831,235,414

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,527.50615
Policy Entropy: 1.90534
Value Function Loss: 0.02575

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07269
Policy Update Magnitude: 0.28842
Value Function Update Magnitude: 0.26993

Collected Steps per Second: 21,162.17419
Overall Steps per Second: 10,159.69441

Timestep Collection Time: 2.36393
Timestep Consumption Time: 2.56003
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 4.92397

Cumulative Model Updates: 219,504
Cumulative Timesteps: 1,831,285,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1831285440...
Checkpoint 1831285440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,798.33615
Policy Entropy: 1.90847
Value Function Loss: 0.02537

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07109
Policy Update Magnitude: 0.28883
Value Function Update Magnitude: 0.28001

Collected Steps per Second: 19,631.78276
Overall Steps per Second: 10,211.84806

Timestep Collection Time: 2.54709
Timestep Consumption Time: 2.34957
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.89667

Cumulative Model Updates: 219,510
Cumulative Timesteps: 1,831,335,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,610.45393
Policy Entropy: 1.89686
Value Function Loss: 0.02496

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07776
Policy Update Magnitude: 0.29097
Value Function Update Magnitude: 0.27605

Collected Steps per Second: 20,915.73424
Overall Steps per Second: 10,448.60708

Timestep Collection Time: 2.39093
Timestep Consumption Time: 2.39517
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.78609

Cumulative Model Updates: 219,516
Cumulative Timesteps: 1,831,385,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1831385452...
Checkpoint 1831385452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,936.52563
Policy Entropy: 1.89660
Value Function Loss: 0.02417

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07083
Policy Update Magnitude: 0.29097
Value Function Update Magnitude: 0.29212

Collected Steps per Second: 20,709.56263
Overall Steps per Second: 10,310.69931

Timestep Collection Time: 2.41434
Timestep Consumption Time: 2.43499
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.84933

Cumulative Model Updates: 219,522
Cumulative Timesteps: 1,831,435,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,347.11567
Policy Entropy: 1.90421
Value Function Loss: 0.02568

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.06893
Policy Update Magnitude: 0.29507
Value Function Update Magnitude: 0.29736

Collected Steps per Second: 21,179.82000
Overall Steps per Second: 10,416.82343

Timestep Collection Time: 2.36291
Timestep Consumption Time: 2.44143
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.80434

Cumulative Model Updates: 219,528
Cumulative Timesteps: 1,831,485,498

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1831485498...
Checkpoint 1831485498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,854.71032
Policy Entropy: 1.91293
Value Function Loss: 0.02459

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.06902
Policy Update Magnitude: 0.29734
Value Function Update Magnitude: 0.29028

Collected Steps per Second: 21,161.37426
Overall Steps per Second: 10,323.09496

Timestep Collection Time: 2.36355
Timestep Consumption Time: 2.48151
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.84506

Cumulative Model Updates: 219,534
Cumulative Timesteps: 1,831,535,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,889.24593
Policy Entropy: 1.91359
Value Function Loss: 0.02501

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.07377
Policy Update Magnitude: 0.29159
Value Function Update Magnitude: 0.29978

Collected Steps per Second: 21,837.86368
Overall Steps per Second: 10,491.63908

Timestep Collection Time: 2.29162
Timestep Consumption Time: 2.47828
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.76989

Cumulative Model Updates: 219,540
Cumulative Timesteps: 1,831,585,558

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1831585558...
Checkpoint 1831585558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,012.11072
Policy Entropy: 1.92629
Value Function Loss: 0.02366

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.07661
Policy Update Magnitude: 0.29460
Value Function Update Magnitude: 0.29783

Collected Steps per Second: 21,773.83307
Overall Steps per Second: 10,473.78388

Timestep Collection Time: 2.29734
Timestep Consumption Time: 2.47858
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.77592

Cumulative Model Updates: 219,546
Cumulative Timesteps: 1,831,635,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,013.21330
Policy Entropy: 1.91582
Value Function Loss: 0.02336

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.08361
Policy Update Magnitude: 0.29008
Value Function Update Magnitude: 0.26440

Collected Steps per Second: 21,692.59582
Overall Steps per Second: 10,536.60579

Timestep Collection Time: 2.30576
Timestep Consumption Time: 2.44131
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.74707

Cumulative Model Updates: 219,552
Cumulative Timesteps: 1,831,685,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1831685598...
Checkpoint 1831685598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,747.50402
Policy Entropy: 1.93430
Value Function Loss: 0.02265

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08216
Policy Update Magnitude: 0.28367
Value Function Update Magnitude: 0.27563

Collected Steps per Second: 21,188.81984
Overall Steps per Second: 10,273.64421

Timestep Collection Time: 2.35983
Timestep Consumption Time: 2.50719
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.86702

Cumulative Model Updates: 219,558
Cumulative Timesteps: 1,831,735,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,870.20217
Policy Entropy: 1.91755
Value Function Loss: 0.02512

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07668
Policy Update Magnitude: 0.28860
Value Function Update Magnitude: 0.27850

Collected Steps per Second: 21,878.55765
Overall Steps per Second: 10,408.49342

Timestep Collection Time: 2.28662
Timestep Consumption Time: 2.51984
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.80646

Cumulative Model Updates: 219,564
Cumulative Timesteps: 1,831,785,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1831785628...
Checkpoint 1831785628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,314.65183
Policy Entropy: 1.90881
Value Function Loss: 0.02389

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07537
Policy Update Magnitude: 0.28999
Value Function Update Magnitude: 0.30927

Collected Steps per Second: 21,782.23558
Overall Steps per Second: 10,540.56552

Timestep Collection Time: 2.29545
Timestep Consumption Time: 2.44813
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.74358

Cumulative Model Updates: 219,570
Cumulative Timesteps: 1,831,835,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,362.89573
Policy Entropy: 1.90142
Value Function Loss: 0.02553

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07570
Policy Update Magnitude: 0.29338
Value Function Update Magnitude: 0.31948

Collected Steps per Second: 21,711.33956
Overall Steps per Second: 10,558.66680

Timestep Collection Time: 2.30534
Timestep Consumption Time: 2.43503
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.74037

Cumulative Model Updates: 219,576
Cumulative Timesteps: 1,831,885,680

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1831885680...
Checkpoint 1831885680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,875.62606
Policy Entropy: 1.91974
Value Function Loss: 0.02546

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07524
Policy Update Magnitude: 0.30523
Value Function Update Magnitude: 0.31353

Collected Steps per Second: 21,655.90645
Overall Steps per Second: 10,551.42832

Timestep Collection Time: 2.31050
Timestep Consumption Time: 2.43161
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.74211

Cumulative Model Updates: 219,582
Cumulative Timesteps: 1,831,935,716

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,754.78809
Policy Entropy: 1.92083
Value Function Loss: 0.02656

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07447
Policy Update Magnitude: 0.30444
Value Function Update Magnitude: 0.32704

Collected Steps per Second: 21,569.99926
Overall Steps per Second: 10,495.29042

Timestep Collection Time: 2.31896
Timestep Consumption Time: 2.44699
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.76595

Cumulative Model Updates: 219,588
Cumulative Timesteps: 1,831,985,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1831985736...
Checkpoint 1831985736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,337.96808
Policy Entropy: 1.92024
Value Function Loss: 0.02622

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07847
Policy Update Magnitude: 0.30209
Value Function Update Magnitude: 0.33577

Collected Steps per Second: 21,402.93767
Overall Steps per Second: 10,332.38296

Timestep Collection Time: 2.33818
Timestep Consumption Time: 2.50523
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.84341

Cumulative Model Updates: 219,594
Cumulative Timesteps: 1,832,035,780

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,544.97014
Policy Entropy: 1.90834
Value Function Loss: 0.02896

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.30602
Value Function Update Magnitude: 0.33893

Collected Steps per Second: 21,343.22073
Overall Steps per Second: 10,336.49680

Timestep Collection Time: 2.34351
Timestep Consumption Time: 2.49546
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.83897

Cumulative Model Updates: 219,600
Cumulative Timesteps: 1,832,085,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1832085798...
Checkpoint 1832085798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,194.98099
Policy Entropy: 1.91410
Value Function Loss: 0.03151

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.31710
Value Function Update Magnitude: 0.34514

Collected Steps per Second: 21,288.82568
Overall Steps per Second: 10,313.80111

Timestep Collection Time: 2.35053
Timestep Consumption Time: 2.50122
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.85175

Cumulative Model Updates: 219,606
Cumulative Timesteps: 1,832,135,838

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,155.29189
Policy Entropy: 1.92661
Value Function Loss: 0.03412

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.32481
Value Function Update Magnitude: 0.36270

Collected Steps per Second: 22,014.57032
Overall Steps per Second: 10,481.85137

Timestep Collection Time: 2.27295
Timestep Consumption Time: 2.50083
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.77377

Cumulative Model Updates: 219,612
Cumulative Timesteps: 1,832,185,876

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1832185876...
Checkpoint 1832185876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,767.55869
Policy Entropy: 1.92808
Value Function Loss: 0.03150

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08372
Policy Update Magnitude: 0.32256
Value Function Update Magnitude: 0.38229

Collected Steps per Second: 21,847.94675
Overall Steps per Second: 10,460.23398

Timestep Collection Time: 2.28882
Timestep Consumption Time: 2.49176
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.78058

Cumulative Model Updates: 219,618
Cumulative Timesteps: 1,832,235,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,663.81447
Policy Entropy: 1.92544
Value Function Loss: 0.02885

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.30816
Value Function Update Magnitude: 0.37419

Collected Steps per Second: 21,171.97700
Overall Steps per Second: 10,328.25313

Timestep Collection Time: 2.36331
Timestep Consumption Time: 2.48126
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 4.84458

Cumulative Model Updates: 219,624
Cumulative Timesteps: 1,832,285,918

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1832285918...
Checkpoint 1832285918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,399.49256
Policy Entropy: 1.91500
Value Function Loss: 0.02615

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.29665
Value Function Update Magnitude: 0.33809

Collected Steps per Second: 19,367.81911
Overall Steps per Second: 9,893.43702

Timestep Collection Time: 2.58181
Timestep Consumption Time: 2.47245
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 5.05426

Cumulative Model Updates: 219,630
Cumulative Timesteps: 1,832,335,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,504.76033
Policy Entropy: 1.92681
Value Function Loss: 0.02653

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.29318
Value Function Update Magnitude: 0.30906

Collected Steps per Second: 19,471.28085
Overall Steps per Second: 9,930.70402

Timestep Collection Time: 2.56932
Timestep Consumption Time: 2.46839
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 5.03771

Cumulative Model Updates: 219,636
Cumulative Timesteps: 1,832,385,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1832385950...
Checkpoint 1832385950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,529.90367
Policy Entropy: 1.94016
Value Function Loss: 0.02873

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08020
Policy Update Magnitude: 0.30553
Value Function Update Magnitude: 0.33828

Collected Steps per Second: 19,851.37033
Overall Steps per Second: 9,889.03544

Timestep Collection Time: 2.51952
Timestep Consumption Time: 2.53820
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 5.05772

Cumulative Model Updates: 219,642
Cumulative Timesteps: 1,832,435,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,652.93553
Policy Entropy: 1.93402
Value Function Loss: 0.02688

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08507
Policy Update Magnitude: 0.31054
Value Function Update Magnitude: 0.35812

Collected Steps per Second: 21,184.70461
Overall Steps per Second: 10,353.19661

Timestep Collection Time: 2.36019
Timestep Consumption Time: 2.46923
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.82943

Cumulative Model Updates: 219,648
Cumulative Timesteps: 1,832,485,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1832485966...
Checkpoint 1832485966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,629.94547
Policy Entropy: 1.91490
Value Function Loss: 0.02503

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.07872
Policy Update Magnitude: 0.30174
Value Function Update Magnitude: 0.34485

Collected Steps per Second: 20,459.55059
Overall Steps per Second: 10,011.21108

Timestep Collection Time: 2.44521
Timestep Consumption Time: 2.55198
PPO Batch Consumption Time: 0.30004
Total Iteration Time: 4.99720

Cumulative Model Updates: 219,654
Cumulative Timesteps: 1,832,535,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,651.59807
Policy Entropy: 1.91335
Value Function Loss: 0.02596

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07418
Policy Update Magnitude: 0.29884
Value Function Update Magnitude: 0.31479

Collected Steps per Second: 20,833.85573
Overall Steps per Second: 10,091.66145

Timestep Collection Time: 2.40080
Timestep Consumption Time: 2.55557
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 4.95637

Cumulative Model Updates: 219,660
Cumulative Timesteps: 1,832,586,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1832586012...
Checkpoint 1832586012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,601.81356
Policy Entropy: 1.91758
Value Function Loss: 0.02925

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.29777
Value Function Update Magnitude: 0.30273

Collected Steps per Second: 20,019.16732
Overall Steps per Second: 10,115.62947

Timestep Collection Time: 2.49811
Timestep Consumption Time: 2.44573
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.94383

Cumulative Model Updates: 219,666
Cumulative Timesteps: 1,832,636,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,833.40726
Policy Entropy: 1.91700
Value Function Loss: 0.02980

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07232
Policy Update Magnitude: 0.29951
Value Function Update Magnitude: 0.27319

Collected Steps per Second: 21,697.02762
Overall Steps per Second: 10,438.45869

Timestep Collection Time: 2.30456
Timestep Consumption Time: 2.48562
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.79017

Cumulative Model Updates: 219,672
Cumulative Timesteps: 1,832,686,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1832686024...
Checkpoint 1832686024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,208.64873
Policy Entropy: 1.92648
Value Function Loss: 0.03006

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07634
Policy Update Magnitude: 0.30812
Value Function Update Magnitude: 0.29955

Collected Steps per Second: 21,287.63416
Overall Steps per Second: 10,247.32168

Timestep Collection Time: 2.34963
Timestep Consumption Time: 2.53145
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.88108

Cumulative Model Updates: 219,678
Cumulative Timesteps: 1,832,736,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,990.92750
Policy Entropy: 1.91398
Value Function Loss: 0.02606

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.30470
Value Function Update Magnitude: 0.32910

Collected Steps per Second: 21,857.35210
Overall Steps per Second: 10,399.41836

Timestep Collection Time: 2.28756
Timestep Consumption Time: 2.52040
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.80796

Cumulative Model Updates: 219,684
Cumulative Timesteps: 1,832,786,042

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1832786042...
Checkpoint 1832786042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,490.58416
Policy Entropy: 1.92886
Value Function Loss: 0.02932

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.30469
Value Function Update Magnitude: 0.36424

Collected Steps per Second: 20,429.39041
Overall Steps per Second: 10,069.25714

Timestep Collection Time: 2.44902
Timestep Consumption Time: 2.51977
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.96879

Cumulative Model Updates: 219,690
Cumulative Timesteps: 1,832,836,074

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,905.76250
Policy Entropy: 1.93638
Value Function Loss: 0.03175

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.31065
Value Function Update Magnitude: 0.40163

Collected Steps per Second: 20,939.58786
Overall Steps per Second: 10,146.38463

Timestep Collection Time: 2.39011
Timestep Consumption Time: 2.54248
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.93259

Cumulative Model Updates: 219,696
Cumulative Timesteps: 1,832,886,122

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1832886122...
Checkpoint 1832886122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,450.03705
Policy Entropy: 1.93980
Value Function Loss: 0.03302

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.31781
Value Function Update Magnitude: 0.40392

Collected Steps per Second: 20,280.38561
Overall Steps per Second: 10,096.79099

Timestep Collection Time: 2.46682
Timestep Consumption Time: 2.48802
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.95484

Cumulative Model Updates: 219,702
Cumulative Timesteps: 1,832,936,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,653.30235
Policy Entropy: 1.94187
Value Function Loss: 0.02983

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08039
Policy Update Magnitude: 0.32036
Value Function Update Magnitude: 0.41348

Collected Steps per Second: 21,045.02148
Overall Steps per Second: 10,143.46299

Timestep Collection Time: 2.37662
Timestep Consumption Time: 2.55424
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.93086

Cumulative Model Updates: 219,708
Cumulative Timesteps: 1,832,986,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1832986166...
Checkpoint 1832986166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,657.07941
Policy Entropy: 1.92828
Value Function Loss: 0.02856

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.07810
Policy Update Magnitude: 0.32371
Value Function Update Magnitude: 0.40340

Collected Steps per Second: 20,154.10737
Overall Steps per Second: 9,906.11881

Timestep Collection Time: 2.48207
Timestep Consumption Time: 2.56773
PPO Batch Consumption Time: 0.29902
Total Iteration Time: 5.04981

Cumulative Model Updates: 219,714
Cumulative Timesteps: 1,833,036,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,232.39157
Policy Entropy: 1.92176
Value Function Loss: 0.02838

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.31440
Value Function Update Magnitude: 0.38558

Collected Steps per Second: 20,906.63601
Overall Steps per Second: 10,122.55200

Timestep Collection Time: 2.39273
Timestep Consumption Time: 2.54910
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.94184

Cumulative Model Updates: 219,720
Cumulative Timesteps: 1,833,086,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1833086214...
Checkpoint 1833086214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,674.61142
Policy Entropy: 1.90891
Value Function Loss: 0.02817

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.07618
Policy Update Magnitude: 0.31760
Value Function Update Magnitude: 0.37139

Collected Steps per Second: 20,682.46341
Overall Steps per Second: 10,029.92335

Timestep Collection Time: 2.41857
Timestep Consumption Time: 2.56871
PPO Batch Consumption Time: 0.29927
Total Iteration Time: 4.98728

Cumulative Model Updates: 219,726
Cumulative Timesteps: 1,833,136,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,103.50921
Policy Entropy: 1.90300
Value Function Loss: 0.02655

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.07874
Policy Update Magnitude: 0.30703
Value Function Update Magnitude: 0.37401

Collected Steps per Second: 20,866.47530
Overall Steps per Second: 10,054.77548

Timestep Collection Time: 2.39657
Timestep Consumption Time: 2.57699
PPO Batch Consumption Time: 0.30116
Total Iteration Time: 4.97356

Cumulative Model Updates: 219,732
Cumulative Timesteps: 1,833,186,244

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1833186244...
Checkpoint 1833186244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,326.58984
Policy Entropy: 1.91089
Value Function Loss: 0.02650

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07489
Policy Update Magnitude: 0.30034
Value Function Update Magnitude: 0.34932

Collected Steps per Second: 20,978.51093
Overall Steps per Second: 10,177.46717

Timestep Collection Time: 2.38425
Timestep Consumption Time: 2.53033
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.91458

Cumulative Model Updates: 219,738
Cumulative Timesteps: 1,833,236,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,328.20114
Policy Entropy: 1.91833
Value Function Loss: 0.02962

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07390
Policy Update Magnitude: 0.30474
Value Function Update Magnitude: 0.32187

Collected Steps per Second: 20,565.90669
Overall Steps per Second: 9,871.28205

Timestep Collection Time: 2.43131
Timestep Consumption Time: 2.63410
PPO Batch Consumption Time: 0.30985
Total Iteration Time: 5.06540

Cumulative Model Updates: 219,744
Cumulative Timesteps: 1,833,286,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1833286264...
Checkpoint 1833286264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,214.95567
Policy Entropy: 1.92407
Value Function Loss: 0.03116

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.07826
Policy Update Magnitude: 0.31153
Value Function Update Magnitude: 0.33954

Collected Steps per Second: 20,970.20178
Overall Steps per Second: 10,369.97781

Timestep Collection Time: 2.38672
Timestep Consumption Time: 2.43971
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.82643

Cumulative Model Updates: 219,750
Cumulative Timesteps: 1,833,336,314

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,899.91941
Policy Entropy: 1.91767
Value Function Loss: 0.03154

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.31930
Value Function Update Magnitude: 0.34007

Collected Steps per Second: 19,919.73780
Overall Steps per Second: 9,702.86584

Timestep Collection Time: 2.51007
Timestep Consumption Time: 2.64304
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 5.15312

Cumulative Model Updates: 219,756
Cumulative Timesteps: 1,833,386,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1833386314...
Checkpoint 1833386314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,701.81921
Policy Entropy: 1.92744
Value Function Loss: 0.02804

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.07856
Policy Update Magnitude: 0.31587
Value Function Update Magnitude: 0.29729

Collected Steps per Second: 20,014.79988
Overall Steps per Second: 9,688.27371

Timestep Collection Time: 2.49975
Timestep Consumption Time: 2.66443
PPO Batch Consumption Time: 0.31260
Total Iteration Time: 5.16418

Cumulative Model Updates: 219,762
Cumulative Timesteps: 1,833,436,346

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,876.52027
Policy Entropy: 1.93423
Value Function Loss: 0.02643

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.07797
Policy Update Magnitude: 0.30895
Value Function Update Magnitude: 0.32606

Collected Steps per Second: 20,847.95527
Overall Steps per Second: 10,150.86985

Timestep Collection Time: 2.39851
Timestep Consumption Time: 2.52757
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.92608

Cumulative Model Updates: 219,768
Cumulative Timesteps: 1,833,486,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1833486350...
Checkpoint 1833486350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,412.64832
Policy Entropy: 1.92111
Value Function Loss: 0.02390

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07084
Policy Update Magnitude: 0.29788
Value Function Update Magnitude: 0.33980

Collected Steps per Second: 20,168.72776
Overall Steps per Second: 9,911.37953

Timestep Collection Time: 2.47928
Timestep Consumption Time: 2.56583
PPO Batch Consumption Time: 0.29981
Total Iteration Time: 5.04511

Cumulative Model Updates: 219,774
Cumulative Timesteps: 1,833,536,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,773.60908
Policy Entropy: 1.91332
Value Function Loss: 0.02512

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06765
Policy Update Magnitude: 0.29453
Value Function Update Magnitude: 0.34206

Collected Steps per Second: 20,871.75911
Overall Steps per Second: 10,068.02907

Timestep Collection Time: 2.39558
Timestep Consumption Time: 2.57063
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 4.96622

Cumulative Model Updates: 219,780
Cumulative Timesteps: 1,833,586,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1833586354...
Checkpoint 1833586354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,374.88317
Policy Entropy: 1.91249
Value Function Loss: 0.02560

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.06935
Policy Update Magnitude: 0.29988
Value Function Update Magnitude: 0.33912

Collected Steps per Second: 20,839.44851
Overall Steps per Second: 10,071.22497

Timestep Collection Time: 2.40045
Timestep Consumption Time: 2.56658
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.96702

Cumulative Model Updates: 219,786
Cumulative Timesteps: 1,833,636,378

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,987.98497
Policy Entropy: 1.92934
Value Function Loss: 0.02409

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.06946
Policy Update Magnitude: 0.29837
Value Function Update Magnitude: 0.30660

Collected Steps per Second: 20,954.10365
Overall Steps per Second: 10,059.20085

Timestep Collection Time: 2.38750
Timestep Consumption Time: 2.58585
PPO Batch Consumption Time: 0.29954
Total Iteration Time: 4.97336

Cumulative Model Updates: 219,792
Cumulative Timesteps: 1,833,686,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1833686406...
Checkpoint 1833686406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,443.58018
Policy Entropy: 1.93846
Value Function Loss: 0.02340

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.06959
Policy Update Magnitude: 0.28990
Value Function Update Magnitude: 0.28580

Collected Steps per Second: 20,500.16267
Overall Steps per Second: 10,102.98759

Timestep Collection Time: 2.44057
Timestep Consumption Time: 2.51163
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.95220

Cumulative Model Updates: 219,798
Cumulative Timesteps: 1,833,736,438

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,936.13723
Policy Entropy: 1.94076
Value Function Loss: 0.02382

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06834
Policy Update Magnitude: 0.28446
Value Function Update Magnitude: 0.28455

Collected Steps per Second: 20,689.86877
Overall Steps per Second: 10,113.76572

Timestep Collection Time: 2.41838
Timestep Consumption Time: 2.52893
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.94732

Cumulative Model Updates: 219,804
Cumulative Timesteps: 1,833,786,474

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1833786474...
Checkpoint 1833786474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,703.78886
Policy Entropy: 1.93856
Value Function Loss: 0.02486

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07517
Policy Update Magnitude: 0.28502
Value Function Update Magnitude: 0.29001

Collected Steps per Second: 20,584.94157
Overall Steps per Second: 10,144.65581

Timestep Collection Time: 2.43110
Timestep Consumption Time: 2.50194
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.93304

Cumulative Model Updates: 219,810
Cumulative Timesteps: 1,833,836,518

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,478.00986
Policy Entropy: 1.93150
Value Function Loss: 0.02854

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07459
Policy Update Magnitude: 0.29788
Value Function Update Magnitude: 0.32637

Collected Steps per Second: 20,479.66792
Overall Steps per Second: 10,132.39020

Timestep Collection Time: 2.44223
Timestep Consumption Time: 2.49402
PPO Batch Consumption Time: 0.29992
Total Iteration Time: 4.93625

Cumulative Model Updates: 219,816
Cumulative Timesteps: 1,833,886,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1833886534...
Checkpoint 1833886534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,337.18303
Policy Entropy: 1.92627
Value Function Loss: 0.03135

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07711
Policy Update Magnitude: 0.31003
Value Function Update Magnitude: 0.34205

Collected Steps per Second: 19,617.77005
Overall Steps per Second: 9,956.63280

Timestep Collection Time: 2.54922
Timestep Consumption Time: 2.47356
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 5.02278

Cumulative Model Updates: 219,822
Cumulative Timesteps: 1,833,936,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,726.98388
Policy Entropy: 1.92000
Value Function Loss: 0.03193

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.08833
Policy Update Magnitude: 0.31201
Value Function Update Magnitude: 0.35773

Collected Steps per Second: 18,682.90979
Overall Steps per Second: 9,760.78788

Timestep Collection Time: 2.67635
Timestep Consumption Time: 2.44639
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 5.12274

Cumulative Model Updates: 219,828
Cumulative Timesteps: 1,833,986,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1833986546...
Checkpoint 1833986546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,979.69132
Policy Entropy: 1.93363
Value Function Loss: 0.02917

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.30911
Value Function Update Magnitude: 0.37356

Collected Steps per Second: 19,829.61644
Overall Steps per Second: 9,977.55011

Timestep Collection Time: 2.52209
Timestep Consumption Time: 2.49037
PPO Batch Consumption Time: 0.30024
Total Iteration Time: 5.01245

Cumulative Model Updates: 219,834
Cumulative Timesteps: 1,834,036,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,179.67974
Policy Entropy: 1.92604
Value Function Loss: 0.02815

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07565
Policy Update Magnitude: 0.30423
Value Function Update Magnitude: 0.34378

Collected Steps per Second: 20,360.40415
Overall Steps per Second: 10,279.44035

Timestep Collection Time: 2.45663
Timestep Consumption Time: 2.40920
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.86583

Cumulative Model Updates: 219,840
Cumulative Timesteps: 1,834,086,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1834086576...
Checkpoint 1834086576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,245.89075
Policy Entropy: 1.91841
Value Function Loss: 0.02829

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.30583
Value Function Update Magnitude: 0.36315

Collected Steps per Second: 19,604.71496
Overall Steps per Second: 9,915.83046

Timestep Collection Time: 2.55051
Timestep Consumption Time: 2.49213
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 5.04264

Cumulative Model Updates: 219,846
Cumulative Timesteps: 1,834,136,578

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,620.37750
Policy Entropy: 1.91196
Value Function Loss: 0.03012

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.31176
Value Function Update Magnitude: 0.37411

Collected Steps per Second: 20,658.81501
Overall Steps per Second: 9,861.19269

Timestep Collection Time: 2.42163
Timestep Consumption Time: 2.65159
PPO Batch Consumption Time: 0.31142
Total Iteration Time: 5.07322

Cumulative Model Updates: 219,852
Cumulative Timesteps: 1,834,186,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1834186606...
Checkpoint 1834186606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,498.48691
Policy Entropy: 1.92080
Value Function Loss: 0.03193

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.31776
Value Function Update Magnitude: 0.33994

Collected Steps per Second: 19,854.64933
Overall Steps per Second: 9,902.06369

Timestep Collection Time: 2.51911
Timestep Consumption Time: 2.53196
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 5.05107

Cumulative Model Updates: 219,858
Cumulative Timesteps: 1,834,236,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,671.81239
Policy Entropy: 1.93457
Value Function Loss: 0.03036

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08595
Policy Update Magnitude: 0.31185
Value Function Update Magnitude: 0.31914

Collected Steps per Second: 18,896.56543
Overall Steps per Second: 9,290.16341

Timestep Collection Time: 2.64630
Timestep Consumption Time: 2.73638
PPO Batch Consumption Time: 0.31301
Total Iteration Time: 5.38268

Cumulative Model Updates: 219,864
Cumulative Timesteps: 1,834,286,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1834286628...
Checkpoint 1834286628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,277.98559
Policy Entropy: 1.93983
Value Function Loss: 0.03106

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.31372
Value Function Update Magnitude: 0.33314

Collected Steps per Second: 20,827.06479
Overall Steps per Second: 10,295.74117

Timestep Collection Time: 2.40187
Timestep Consumption Time: 2.45683
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.85871

Cumulative Model Updates: 219,870
Cumulative Timesteps: 1,834,336,652

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,681.23115
Policy Entropy: 1.92887
Value Function Loss: 0.02960

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08184
Policy Update Magnitude: 0.31198
Value Function Update Magnitude: 0.34647

Collected Steps per Second: 19,807.99255
Overall Steps per Second: 9,937.73376

Timestep Collection Time: 2.52615
Timestep Consumption Time: 2.50900
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 5.03515

Cumulative Model Updates: 219,876
Cumulative Timesteps: 1,834,386,690

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1834386690...
Checkpoint 1834386690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,836.62880
Policy Entropy: 1.92945
Value Function Loss: 0.02877

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.08610
Policy Update Magnitude: 0.30576
Value Function Update Magnitude: 0.34610

Collected Steps per Second: 19,781.24733
Overall Steps per Second: 9,951.40448

Timestep Collection Time: 2.52987
Timestep Consumption Time: 2.49897
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 5.02884

Cumulative Model Updates: 219,882
Cumulative Timesteps: 1,834,436,734

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,308.01275
Policy Entropy: 1.92167
Value Function Loss: 0.02859

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.30059
Value Function Update Magnitude: 0.31267

Collected Steps per Second: 19,034.28863
Overall Steps per Second: 9,418.50212

Timestep Collection Time: 2.62757
Timestep Consumption Time: 2.68261
PPO Batch Consumption Time: 0.31505
Total Iteration Time: 5.31019

Cumulative Model Updates: 219,888
Cumulative Timesteps: 1,834,486,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1834486748...
Checkpoint 1834486748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,736.93549
Policy Entropy: 1.93576
Value Function Loss: 0.03149

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08476
Policy Update Magnitude: 0.30482
Value Function Update Magnitude: 0.30467

Collected Steps per Second: 18,859.39106
Overall Steps per Second: 9,671.54136

Timestep Collection Time: 2.65215
Timestep Consumption Time: 2.51951
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 5.17167

Cumulative Model Updates: 219,894
Cumulative Timesteps: 1,834,536,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,541.08107
Policy Entropy: 1.92953
Value Function Loss: 0.03334

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.07882
Policy Update Magnitude: 0.31186
Value Function Update Magnitude: 0.32729

Collected Steps per Second: 20,717.23284
Overall Steps per Second: 10,067.82956

Timestep Collection Time: 2.41490
Timestep Consumption Time: 2.55440
PPO Batch Consumption Time: 0.30034
Total Iteration Time: 4.96929

Cumulative Model Updates: 219,900
Cumulative Timesteps: 1,834,586,796

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1834586796...
Checkpoint 1834586796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,248.74131
Policy Entropy: 1.93969
Value Function Loss: 0.03203

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.31763
Value Function Update Magnitude: 0.33606

Collected Steps per Second: 20,659.86577
Overall Steps per Second: 10,132.95225

Timestep Collection Time: 2.42093
Timestep Consumption Time: 2.51505
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.93598

Cumulative Model Updates: 219,906
Cumulative Timesteps: 1,834,636,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,017.39592
Policy Entropy: 1.92808
Value Function Loss: 0.03024

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.31778
Value Function Update Magnitude: 0.31735

Collected Steps per Second: 20,789.38569
Overall Steps per Second: 9,792.73084

Timestep Collection Time: 2.40604
Timestep Consumption Time: 2.70183
PPO Batch Consumption Time: 0.31882
Total Iteration Time: 5.10787

Cumulative Model Updates: 219,912
Cumulative Timesteps: 1,834,686,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1834686832...
Checkpoint 1834686832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,357.29456
Policy Entropy: 1.93046
Value Function Loss: 0.02664

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08274
Policy Update Magnitude: 0.31684
Value Function Update Magnitude: 0.32039

Collected Steps per Second: 20,772.79791
Overall Steps per Second: 10,130.55538

Timestep Collection Time: 2.40844
Timestep Consumption Time: 2.53009
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.93852

Cumulative Model Updates: 219,918
Cumulative Timesteps: 1,834,736,862

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,541.06883
Policy Entropy: 1.92366
Value Function Loss: 0.02719

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.07721
Policy Update Magnitude: 0.31069
Value Function Update Magnitude: 0.32560

Collected Steps per Second: 20,785.02508
Overall Steps per Second: 10,036.74300

Timestep Collection Time: 2.40664
Timestep Consumption Time: 2.57725
PPO Batch Consumption Time: 0.29956
Total Iteration Time: 4.98389

Cumulative Model Updates: 219,924
Cumulative Timesteps: 1,834,786,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1834786884...
Checkpoint 1834786884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,849.96413
Policy Entropy: 1.92212
Value Function Loss: 0.02676

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07610
Policy Update Magnitude: 0.30753
Value Function Update Magnitude: 0.34036

Collected Steps per Second: 20,569.23290
Overall Steps per Second: 10,121.47736

Timestep Collection Time: 2.43169
Timestep Consumption Time: 2.51008
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.94177

Cumulative Model Updates: 219,930
Cumulative Timesteps: 1,834,836,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,972.48805
Policy Entropy: 1.93508
Value Function Loss: 0.02758

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.07950
Policy Update Magnitude: 0.31009
Value Function Update Magnitude: 0.31552

Collected Steps per Second: 20,701.76792
Overall Steps per Second: 9,800.44378

Timestep Collection Time: 2.41661
Timestep Consumption Time: 2.68806
PPO Batch Consumption Time: 0.31693
Total Iteration Time: 5.10467

Cumulative Model Updates: 219,936
Cumulative Timesteps: 1,834,886,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1834886930...
Checkpoint 1834886930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,385.45917
Policy Entropy: 1.93417
Value Function Loss: 0.02918

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.30775
Value Function Update Magnitude: 0.31245

Collected Steps per Second: 20,248.22272
Overall Steps per Second: 10,066.42857

Timestep Collection Time: 2.46985
Timestep Consumption Time: 2.49815
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.96800

Cumulative Model Updates: 219,942
Cumulative Timesteps: 1,834,936,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,774.78535
Policy Entropy: 1.94027
Value Function Loss: 0.02898

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07669
Policy Update Magnitude: 0.30806
Value Function Update Magnitude: 0.33783

Collected Steps per Second: 20,616.21726
Overall Steps per Second: 10,074.44317

Timestep Collection Time: 2.42634
Timestep Consumption Time: 2.53889
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.96524

Cumulative Model Updates: 219,948
Cumulative Timesteps: 1,834,986,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1834986962...
Checkpoint 1834986962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,685.11755
Policy Entropy: 1.92948
Value Function Loss: 0.02731

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07593
Policy Update Magnitude: 0.29902
Value Function Update Magnitude: 0.33721

Collected Steps per Second: 19,877.39979
Overall Steps per Second: 10,113.65398

Timestep Collection Time: 2.51693
Timestep Consumption Time: 2.42985
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.94678

Cumulative Model Updates: 219,954
Cumulative Timesteps: 1,835,036,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,462.21328
Policy Entropy: 1.94309
Value Function Loss: 0.02712

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.29238
Value Function Update Magnitude: 0.31326

Collected Steps per Second: 20,222.99466
Overall Steps per Second: 9,784.59897

Timestep Collection Time: 2.47362
Timestep Consumption Time: 2.63890
PPO Batch Consumption Time: 0.32258
Total Iteration Time: 5.11252

Cumulative Model Updates: 219,960
Cumulative Timesteps: 1,835,087,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1835087016...
Checkpoint 1835087016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,495.95100
Policy Entropy: 1.91388
Value Function Loss: 0.02538

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.09747
Policy Update Magnitude: 0.28192
Value Function Update Magnitude: 0.31231

Collected Steps per Second: 20,145.49290
Overall Steps per Second: 10,071.84172

Timestep Collection Time: 2.48254
Timestep Consumption Time: 2.48299
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.96553

Cumulative Model Updates: 219,966
Cumulative Timesteps: 1,835,137,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,466.31744
Policy Entropy: 1.91694
Value Function Loss: 0.02665

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.28985
Value Function Update Magnitude: 0.29410

Collected Steps per Second: 20,225.43208
Overall Steps per Second: 10,124.04004

Timestep Collection Time: 2.47263
Timestep Consumption Time: 2.46710
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.93973

Cumulative Model Updates: 219,972
Cumulative Timesteps: 1,835,187,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1835187038...
Checkpoint 1835187038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,258.83548
Policy Entropy: 1.91791
Value Function Loss: 0.02666

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07667
Policy Update Magnitude: 0.30414
Value Function Update Magnitude: 0.29664

Collected Steps per Second: 20,118.41443
Overall Steps per Second: 10,106.08950

Timestep Collection Time: 2.48688
Timestep Consumption Time: 2.46380
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.95068

Cumulative Model Updates: 219,978
Cumulative Timesteps: 1,835,237,070

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,358.62992
Policy Entropy: 1.92295
Value Function Loss: 0.02552

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07567
Policy Update Magnitude: 0.30027
Value Function Update Magnitude: 0.29323

Collected Steps per Second: 20,620.14571
Overall Steps per Second: 9,711.26654

Timestep Collection Time: 2.42646
Timestep Consumption Time: 2.72570
PPO Batch Consumption Time: 0.32422
Total Iteration Time: 5.15216

Cumulative Model Updates: 219,984
Cumulative Timesteps: 1,835,287,104

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1835287104...
Checkpoint 1835287104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,709.59884
Policy Entropy: 1.92467
Value Function Loss: 0.02792

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07105
Policy Update Magnitude: 0.29583
Value Function Update Magnitude: 0.29549

Collected Steps per Second: 20,488.43498
Overall Steps per Second: 10,055.00434

Timestep Collection Time: 2.44079
Timestep Consumption Time: 2.53265
PPO Batch Consumption Time: 0.29581
Total Iteration Time: 4.97344

Cumulative Model Updates: 219,990
Cumulative Timesteps: 1,835,337,112

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,987.44214
Policy Entropy: 1.90140
Value Function Loss: 0.02843

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.07830
Policy Update Magnitude: 0.29976
Value Function Update Magnitude: 0.29502

Collected Steps per Second: 17,304.38702
Overall Steps per Second: 8,936.31559

Timestep Collection Time: 2.89198
Timestep Consumption Time: 2.70809
PPO Batch Consumption Time: 0.32306
Total Iteration Time: 5.60007

Cumulative Model Updates: 219,996
Cumulative Timesteps: 1,835,387,156

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1835387156...
Checkpoint 1835387156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,681.07418
Policy Entropy: 1.92503
Value Function Loss: 0.02985

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.09641
Policy Update Magnitude: 0.30255
Value Function Update Magnitude: 0.29316

Collected Steps per Second: 20,483.89012
Overall Steps per Second: 10,000.62224

Timestep Collection Time: 2.44094
Timestep Consumption Time: 2.55875
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.99969

Cumulative Model Updates: 220,002
Cumulative Timesteps: 1,835,437,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,203.32307
Policy Entropy: 1.94083
Value Function Loss: 0.02714

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.30065
Value Function Update Magnitude: 0.33911

Collected Steps per Second: 20,821.95765
Overall Steps per Second: 9,874.85394

Timestep Collection Time: 2.40150
Timestep Consumption Time: 2.66227
PPO Batch Consumption Time: 0.30207
Total Iteration Time: 5.06377

Cumulative Model Updates: 220,008
Cumulative Timesteps: 1,835,487,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1835487160...
Checkpoint 1835487160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,238.13076
Policy Entropy: 1.94714
Value Function Loss: 0.02679

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.29765
Value Function Update Magnitude: 0.34511

Collected Steps per Second: 20,814.89286
Overall Steps per Second: 10,063.40792

Timestep Collection Time: 2.40357
Timestep Consumption Time: 2.56791
PPO Batch Consumption Time: 0.30042
Total Iteration Time: 4.97148

Cumulative Model Updates: 220,014
Cumulative Timesteps: 1,835,537,190

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,812.85699
Policy Entropy: 1.94407
Value Function Loss: 0.02805

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08527
Policy Update Magnitude: 0.30251
Value Function Update Magnitude: 0.32181

Collected Steps per Second: 20,581.72236
Overall Steps per Second: 9,959.53434

Timestep Collection Time: 2.42983
Timestep Consumption Time: 2.59149
PPO Batch Consumption Time: 0.30251
Total Iteration Time: 5.02132

Cumulative Model Updates: 220,020
Cumulative Timesteps: 1,835,587,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1835587200...
Checkpoint 1835587200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,618.47031
Policy Entropy: 1.94386
Value Function Loss: 0.02902

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.08430
Policy Update Magnitude: 0.30444
Value Function Update Magnitude: 0.30674

Collected Steps per Second: 20,907.96134
Overall Steps per Second: 10,201.41317

Timestep Collection Time: 2.39287
Timestep Consumption Time: 2.51135
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.90422

Cumulative Model Updates: 220,026
Cumulative Timesteps: 1,835,637,230

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,503.72499
Policy Entropy: 1.95425
Value Function Loss: 0.03041

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.30241
Value Function Update Magnitude: 0.31427

Collected Steps per Second: 20,700.48703
Overall Steps per Second: 9,865.81825

Timestep Collection Time: 2.41656
Timestep Consumption Time: 2.65387
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 5.07044

Cumulative Model Updates: 220,032
Cumulative Timesteps: 1,835,687,254

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1835687254...
Checkpoint 1835687254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,393.78615
Policy Entropy: 1.95236
Value Function Loss: 0.03045

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07717
Policy Update Magnitude: 0.30963
Value Function Update Magnitude: 0.34059

Collected Steps per Second: 20,513.83767
Overall Steps per Second: 9,936.53815

Timestep Collection Time: 2.43816
Timestep Consumption Time: 2.59538
PPO Batch Consumption Time: 0.30548
Total Iteration Time: 5.03354

Cumulative Model Updates: 220,038
Cumulative Timesteps: 1,835,737,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,237.08813
Policy Entropy: 1.94469
Value Function Loss: 0.03202

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07478
Policy Update Magnitude: 0.31082
Value Function Update Magnitude: 0.37261

Collected Steps per Second: 20,788.70864
Overall Steps per Second: 10,128.26619

Timestep Collection Time: 2.40515
Timestep Consumption Time: 2.53153
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.93668

Cumulative Model Updates: 220,044
Cumulative Timesteps: 1,835,787,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1835787270...
Checkpoint 1835787270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,551.31818
Policy Entropy: 1.93242
Value Function Loss: 0.02875

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07958
Policy Update Magnitude: 0.30926
Value Function Update Magnitude: 0.37407

Collected Steps per Second: 20,897.14266
Overall Steps per Second: 10,191.50437

Timestep Collection Time: 2.39392
Timestep Consumption Time: 2.51468
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.90860

Cumulative Model Updates: 220,050
Cumulative Timesteps: 1,835,837,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,551.31818
Policy Entropy: 1.92170
Value Function Loss: 0.02598

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.30284
Value Function Update Magnitude: 0.34424

Collected Steps per Second: 20,355.51609
Overall Steps per Second: 9,833.50337

Timestep Collection Time: 2.45663
Timestep Consumption Time: 2.62864
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 5.08527

Cumulative Model Updates: 220,056
Cumulative Timesteps: 1,835,887,302

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1835887302...
Checkpoint 1835887302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,654.23149
Policy Entropy: 1.92014
Value Function Loss: 0.02570

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07163
Policy Update Magnitude: 0.30491
Value Function Update Magnitude: 0.32487

Collected Steps per Second: 21,012.68120
Overall Steps per Second: 10,178.03236

Timestep Collection Time: 2.38085
Timestep Consumption Time: 2.53444
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.91529

Cumulative Model Updates: 220,062
Cumulative Timesteps: 1,835,937,330

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,306.39072
Policy Entropy: 1.91583
Value Function Loss: 0.02744

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07339
Policy Update Magnitude: 0.30887
Value Function Update Magnitude: 0.33346

Collected Steps per Second: 20,777.10475
Overall Steps per Second: 10,163.66966

Timestep Collection Time: 2.40784
Timestep Consumption Time: 2.51440
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.92224

Cumulative Model Updates: 220,068
Cumulative Timesteps: 1,835,987,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1835987358...
Checkpoint 1835987358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,988.29969
Policy Entropy: 1.91769
Value Function Loss: 0.02674

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07329
Policy Update Magnitude: 0.30784
Value Function Update Magnitude: 0.32645

Collected Steps per Second: 20,663.81910
Overall Steps per Second: 10,083.39791

Timestep Collection Time: 2.42153
Timestep Consumption Time: 2.54089
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 4.96241

Cumulative Model Updates: 220,074
Cumulative Timesteps: 1,836,037,396

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,823.54738
Policy Entropy: 1.91604
Value Function Loss: 0.02680

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07831
Policy Update Magnitude: 0.30192
Value Function Update Magnitude: 0.27329

Collected Steps per Second: 20,874.57372
Overall Steps per Second: 9,977.45363

Timestep Collection Time: 2.39717
Timestep Consumption Time: 2.61813
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 5.01531

Cumulative Model Updates: 220,080
Cumulative Timesteps: 1,836,087,436

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1836087436...
Checkpoint 1836087436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,706.19055
Policy Entropy: 1.91561
Value Function Loss: 0.02588

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07363
Policy Update Magnitude: 0.29545
Value Function Update Magnitude: 0.25761

Collected Steps per Second: 20,961.78519
Overall Steps per Second: 10,106.19872

Timestep Collection Time: 2.38672
Timestep Consumption Time: 2.56370
PPO Batch Consumption Time: 0.29982
Total Iteration Time: 4.95043

Cumulative Model Updates: 220,086
Cumulative Timesteps: 1,836,137,466

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,373.66464
Policy Entropy: 1.91500
Value Function Loss: 0.02708

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07697
Policy Update Magnitude: 0.29599
Value Function Update Magnitude: 0.29327

Collected Steps per Second: 20,328.51630
Overall Steps per Second: 10,119.75161

Timestep Collection Time: 2.46009
Timestep Consumption Time: 2.48173
PPO Batch Consumption Time: 0.29947
Total Iteration Time: 4.94182

Cumulative Model Updates: 220,092
Cumulative Timesteps: 1,836,187,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1836187476...
Checkpoint 1836187476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,709.20905
Policy Entropy: 1.90687
Value Function Loss: 0.02790

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08155
Policy Update Magnitude: 0.30132
Value Function Update Magnitude: 0.31139

Collected Steps per Second: 20,391.36631
Overall Steps per Second: 10,031.09209

Timestep Collection Time: 2.45270
Timestep Consumption Time: 2.53319
PPO Batch Consumption Time: 0.30579
Total Iteration Time: 4.98590

Cumulative Model Updates: 220,098
Cumulative Timesteps: 1,836,237,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,647.74397
Policy Entropy: 1.92368
Value Function Loss: 0.02851

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.30486
Value Function Update Magnitude: 0.27730

Collected Steps per Second: 19,683.98731
Overall Steps per Second: 9,849.68575

Timestep Collection Time: 2.54095
Timestep Consumption Time: 2.53698
PPO Batch Consumption Time: 0.29654
Total Iteration Time: 5.07793

Cumulative Model Updates: 220,104
Cumulative Timesteps: 1,836,287,506

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1836287506...
Checkpoint 1836287506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,540.65882
Policy Entropy: 1.93071
Value Function Loss: 0.03230

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.31580
Value Function Update Magnitude: 0.25449

Collected Steps per Second: 19,549.24428
Overall Steps per Second: 9,842.12950

Timestep Collection Time: 2.55897
Timestep Consumption Time: 2.52387
PPO Batch Consumption Time: 0.30323
Total Iteration Time: 5.08284

Cumulative Model Updates: 220,110
Cumulative Timesteps: 1,836,337,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,893.94097
Policy Entropy: 1.93316
Value Function Loss: 0.03182

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.31576
Value Function Update Magnitude: 0.31810

Collected Steps per Second: 19,970.27504
Overall Steps per Second: 9,901.46888

Timestep Collection Time: 2.50382
Timestep Consumption Time: 2.54614
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 5.04996

Cumulative Model Updates: 220,116
Cumulative Timesteps: 1,836,387,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1836387534...
Checkpoint 1836387534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,143.37853
Policy Entropy: 1.95108
Value Function Loss: 0.03380

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.08570
Policy Update Magnitude: 0.31889
Value Function Update Magnitude: 0.39674

Collected Steps per Second: 20,636.34761
Overall Steps per Second: 10,168.56963

Timestep Collection Time: 2.42427
Timestep Consumption Time: 2.49560
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.91987

Cumulative Model Updates: 220,122
Cumulative Timesteps: 1,836,437,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,570.81023
Policy Entropy: 1.96895
Value Function Loss: 0.03228

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.31930
Value Function Update Magnitude: 0.39627

Collected Steps per Second: 19,792.42095
Overall Steps per Second: 9,851.25666

Timestep Collection Time: 2.52723
Timestep Consumption Time: 2.55029
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 5.07752

Cumulative Model Updates: 220,128
Cumulative Timesteps: 1,836,487,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1836487582...
Checkpoint 1836487582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,030.90194
Policy Entropy: 1.97898
Value Function Loss: 0.03176

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.08970
Policy Update Magnitude: 0.31838
Value Function Update Magnitude: 0.37456

Collected Steps per Second: 20,119.15492
Overall Steps per Second: 10,006.30501

Timestep Collection Time: 2.48589
Timestep Consumption Time: 2.51236
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.99825

Cumulative Model Updates: 220,134
Cumulative Timesteps: 1,836,537,596

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,904.45179
Policy Entropy: 1.96102
Value Function Loss: 0.03118

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.31673
Value Function Update Magnitude: 0.36842

Collected Steps per Second: 20,617.72576
Overall Steps per Second: 10,018.72248

Timestep Collection Time: 2.42675
Timestep Consumption Time: 2.56730
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.99405

Cumulative Model Updates: 220,140
Cumulative Timesteps: 1,836,587,630

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1836587630...
Checkpoint 1836587630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,479.30805
Policy Entropy: 1.95261
Value Function Loss: 0.02957

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.30860
Value Function Update Magnitude: 0.34657

Collected Steps per Second: 20,150.88141
Overall Steps per Second: 9,857.23020

Timestep Collection Time: 2.48198
Timestep Consumption Time: 2.59186
PPO Batch Consumption Time: 0.30151
Total Iteration Time: 5.07384

Cumulative Model Updates: 220,146
Cumulative Timesteps: 1,836,637,644

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,424.41755
Policy Entropy: 1.93991
Value Function Loss: 0.02862

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07818
Policy Update Magnitude: 0.30245
Value Function Update Magnitude: 0.29911

Collected Steps per Second: 20,075.22914
Overall Steps per Second: 9,947.42787

Timestep Collection Time: 2.49223
Timestep Consumption Time: 2.53742
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 5.02964

Cumulative Model Updates: 220,152
Cumulative Timesteps: 1,836,687,676

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1836687676...
Checkpoint 1836687676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,854.22069
Policy Entropy: 1.95236
Value Function Loss: 0.02823

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.30828
Value Function Update Magnitude: 0.33880

Collected Steps per Second: 20,427.86577
Overall Steps per Second: 9,948.74897

Timestep Collection Time: 2.44950
Timestep Consumption Time: 2.58008
PPO Batch Consumption Time: 0.30164
Total Iteration Time: 5.02958

Cumulative Model Updates: 220,158
Cumulative Timesteps: 1,836,737,714

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,207.12428
Policy Entropy: 1.96005
Value Function Loss: 0.02834

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.08315
Policy Update Magnitude: 0.31348
Value Function Update Magnitude: 0.33789

Collected Steps per Second: 20,161.56831
Overall Steps per Second: 9,841.57133

Timestep Collection Time: 2.48036
Timestep Consumption Time: 2.60094
PPO Batch Consumption Time: 0.30348
Total Iteration Time: 5.08130

Cumulative Model Updates: 220,164
Cumulative Timesteps: 1,836,787,722

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1836787722...
Checkpoint 1836787722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,095.28524
Policy Entropy: 1.95842
Value Function Loss: 0.03010

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08354
Policy Update Magnitude: 0.31583
Value Function Update Magnitude: 0.31573

Collected Steps per Second: 20,584.78381
Overall Steps per Second: 9,985.85281

Timestep Collection Time: 2.43024
Timestep Consumption Time: 2.57945
PPO Batch Consumption Time: 0.30115
Total Iteration Time: 5.00969

Cumulative Model Updates: 220,170
Cumulative Timesteps: 1,836,837,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,157.31390
Policy Entropy: 1.96197
Value Function Loss: 0.02899

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.30811
Value Function Update Magnitude: 0.31747

Collected Steps per Second: 19,773.96596
Overall Steps per Second: 9,853.52189

Timestep Collection Time: 2.52969
Timestep Consumption Time: 2.54687
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 5.07656

Cumulative Model Updates: 220,176
Cumulative Timesteps: 1,836,887,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1836887770...
Checkpoint 1836887770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,694.25799
Policy Entropy: 1.94737
Value Function Loss: 0.02844

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07749
Policy Update Magnitude: 0.30549
Value Function Update Magnitude: 0.29182

Collected Steps per Second: 20,174.06737
Overall Steps per Second: 9,931.95402

Timestep Collection Time: 2.47972
Timestep Consumption Time: 2.55716
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 5.03687

Cumulative Model Updates: 220,182
Cumulative Timesteps: 1,836,937,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,351.78448
Policy Entropy: 1.97742
Value Function Loss: 0.03066

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.30190
Value Function Update Magnitude: 0.25015

Collected Steps per Second: 20,448.00052
Overall Steps per Second: 9,906.78568

Timestep Collection Time: 2.44679
Timestep Consumption Time: 2.60348
PPO Batch Consumption Time: 0.30031
Total Iteration Time: 5.05028

Cumulative Model Updates: 220,188
Cumulative Timesteps: 1,836,987,828

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1836987828...
Checkpoint 1836987828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,434.70746
Policy Entropy: 1.96499
Value Function Loss: 0.03419

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.31271
Value Function Update Magnitude: 0.28909

Collected Steps per Second: 20,907.65676
Overall Steps per Second: 9,722.15126

Timestep Collection Time: 2.39281
Timestep Consumption Time: 2.75297
PPO Batch Consumption Time: 0.32955
Total Iteration Time: 5.14577

Cumulative Model Updates: 220,194
Cumulative Timesteps: 1,837,037,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,414.76800
Policy Entropy: 1.97269
Value Function Loss: 0.03411

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08092
Policy Update Magnitude: 0.31805
Value Function Update Magnitude: 0.34475

Collected Steps per Second: 19,259.83774
Overall Steps per Second: 9,626.92138

Timestep Collection Time: 2.59711
Timestep Consumption Time: 2.59873
PPO Batch Consumption Time: 0.29983
Total Iteration Time: 5.19585

Cumulative Model Updates: 220,200
Cumulative Timesteps: 1,837,087,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1837087876...
Checkpoint 1837087876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,648.40105
Policy Entropy: 1.96579
Value Function Loss: 0.02915

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.31003
Value Function Update Magnitude: 0.34994

Collected Steps per Second: 20,620.38553
Overall Steps per Second: 10,072.93521

Timestep Collection Time: 2.42508
Timestep Consumption Time: 2.53932
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.96439

Cumulative Model Updates: 220,206
Cumulative Timesteps: 1,837,137,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,124.02574
Policy Entropy: 1.94512
Value Function Loss: 0.02542

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07305
Policy Update Magnitude: 0.29850
Value Function Update Magnitude: 0.34407

Collected Steps per Second: 20,043.96511
Overall Steps per Second: 10,029.94262

Timestep Collection Time: 2.49512
Timestep Consumption Time: 2.49115
PPO Batch Consumption Time: 0.29717
Total Iteration Time: 4.98627

Cumulative Model Updates: 220,212
Cumulative Timesteps: 1,837,187,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1837187894...
Checkpoint 1837187894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,545.14151
Policy Entropy: 1.93764
Value Function Loss: 0.02500

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07587
Policy Update Magnitude: 0.30187
Value Function Update Magnitude: 0.32212

Collected Steps per Second: 19,941.45044
Overall Steps per Second: 10,111.62465

Timestep Collection Time: 2.50864
Timestep Consumption Time: 2.43873
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.94738

Cumulative Model Updates: 220,218
Cumulative Timesteps: 1,837,237,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,143.87083
Policy Entropy: 1.93479
Value Function Loss: 0.02774

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07695
Policy Update Magnitude: 0.30723
Value Function Update Magnitude: 0.30054

Collected Steps per Second: 19,216.53951
Overall Steps per Second: 9,886.84851

Timestep Collection Time: 2.60411
Timestep Consumption Time: 2.45736
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 5.06147

Cumulative Model Updates: 220,224
Cumulative Timesteps: 1,837,287,962

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1837287962...
Checkpoint 1837287962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,671.97195
Policy Entropy: 1.95647
Value Function Loss: 0.02703

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07838
Policy Update Magnitude: 0.30864
Value Function Update Magnitude: 0.31012

Collected Steps per Second: 20,197.80769
Overall Steps per Second: 10,057.38561

Timestep Collection Time: 2.47651
Timestep Consumption Time: 2.49695
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.97346

Cumulative Model Updates: 220,230
Cumulative Timesteps: 1,837,337,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,983.42818
Policy Entropy: 1.95189
Value Function Loss: 0.02684

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07589
Policy Update Magnitude: 0.30789
Value Function Update Magnitude: 0.32907

Collected Steps per Second: 20,690.28634
Overall Steps per Second: 10,067.00918

Timestep Collection Time: 2.41698
Timestep Consumption Time: 2.55053
PPO Batch Consumption Time: 0.30055
Total Iteration Time: 4.96751

Cumulative Model Updates: 220,236
Cumulative Timesteps: 1,837,387,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1837387990...
Checkpoint 1837387990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,754.89010
Policy Entropy: 1.95658
Value Function Loss: 0.02749

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07841
Policy Update Magnitude: 0.30518
Value Function Update Magnitude: 0.32231

Collected Steps per Second: 20,735.35760
Overall Steps per Second: 10,226.13521

Timestep Collection Time: 2.41308
Timestep Consumption Time: 2.47988
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.89295

Cumulative Model Updates: 220,242
Cumulative Timesteps: 1,837,438,026

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,304.90370
Policy Entropy: 1.95513
Value Function Loss: 0.02807

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.07977
Policy Update Magnitude: 0.30355
Value Function Update Magnitude: 0.33194

Collected Steps per Second: 19,917.35370
Overall Steps per Second: 10,006.64221

Timestep Collection Time: 2.51067
Timestep Consumption Time: 2.48661
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.99728

Cumulative Model Updates: 220,248
Cumulative Timesteps: 1,837,488,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1837488032...
Checkpoint 1837488032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,621.05414
Policy Entropy: 1.95865
Value Function Loss: 0.02466

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08111
Policy Update Magnitude: 0.30046
Value Function Update Magnitude: 0.34204

Collected Steps per Second: 20,695.00405
Overall Steps per Second: 10,167.30556

Timestep Collection Time: 2.41662
Timestep Consumption Time: 2.50228
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.91890

Cumulative Model Updates: 220,254
Cumulative Timesteps: 1,837,538,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,803.15809
Policy Entropy: 1.95773
Value Function Loss: 0.02608

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07666
Policy Update Magnitude: 0.29727
Value Function Update Magnitude: 0.32397

Collected Steps per Second: 20,772.98149
Overall Steps per Second: 10,062.94197

Timestep Collection Time: 2.40803
Timestep Consumption Time: 2.56288
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.97091

Cumulative Model Updates: 220,260
Cumulative Timesteps: 1,837,588,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1837588066...
Checkpoint 1837588066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,270.99319
Policy Entropy: 1.96482
Value Function Loss: 0.02430

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07354
Policy Update Magnitude: 0.29324
Value Function Update Magnitude: 0.31410

Collected Steps per Second: 20,680.24951
Overall Steps per Second: 10,136.54185

Timestep Collection Time: 2.41777
Timestep Consumption Time: 2.51488
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.93265

Cumulative Model Updates: 220,266
Cumulative Timesteps: 1,837,638,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,886.26376
Policy Entropy: 1.97232
Value Function Loss: 0.02916

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07453
Policy Update Magnitude: 0.30257
Value Function Update Magnitude: 0.29068

Collected Steps per Second: 19,790.63533
Overall Steps per Second: 9,900.73524

Timestep Collection Time: 2.52847
Timestep Consumption Time: 2.52570
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 5.05417

Cumulative Model Updates: 220,272
Cumulative Timesteps: 1,837,688,106

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1837688106...
Checkpoint 1837688106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,310.15252
Policy Entropy: 1.95858
Value Function Loss: 0.03092

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.07640
Policy Update Magnitude: 0.30501
Value Function Update Magnitude: 0.31021

Collected Steps per Second: 20,660.46126
Overall Steps per Second: 9,994.48646

Timestep Collection Time: 2.42018
Timestep Consumption Time: 2.58278
PPO Batch Consumption Time: 0.30066
Total Iteration Time: 5.00296

Cumulative Model Updates: 220,278
Cumulative Timesteps: 1,837,738,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,642.11083
Policy Entropy: 1.96526
Value Function Loss: 0.03092

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.08461
Policy Update Magnitude: 0.30707
Value Function Update Magnitude: 0.31161

Collected Steps per Second: 19,438.20140
Overall Steps per Second: 9,760.22561

Timestep Collection Time: 2.57380
Timestep Consumption Time: 2.55211
PPO Batch Consumption Time: 0.29849
Total Iteration Time: 5.12591

Cumulative Model Updates: 220,284
Cumulative Timesteps: 1,837,788,138

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1837788138...
Checkpoint 1837788138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,141.32853
Policy Entropy: 1.95848
Value Function Loss: 0.02899

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07687
Policy Update Magnitude: 0.30344
Value Function Update Magnitude: 0.28999

Collected Steps per Second: 20,637.70415
Overall Steps per Second: 10,117.60631

Timestep Collection Time: 2.42459
Timestep Consumption Time: 2.52104
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.94564

Cumulative Model Updates: 220,290
Cumulative Timesteps: 1,837,838,176

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,138.56248
Policy Entropy: 1.96057
Value Function Loss: 0.02993

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07620
Policy Update Magnitude: 0.30491
Value Function Update Magnitude: 0.30838

Collected Steps per Second: 20,075.99032
Overall Steps per Second: 10,055.67570

Timestep Collection Time: 2.49163
Timestep Consumption Time: 2.48287
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.97450

Cumulative Model Updates: 220,296
Cumulative Timesteps: 1,837,888,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1837888198...
Checkpoint 1837888198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,926.06686
Policy Entropy: 1.94470
Value Function Loss: 0.03296

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07930
Policy Update Magnitude: 0.30846
Value Function Update Magnitude: 0.31736

Collected Steps per Second: 20,819.78226
Overall Steps per Second: 10,074.93880

Timestep Collection Time: 2.40233
Timestep Consumption Time: 2.56207
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.96440

Cumulative Model Updates: 220,302
Cumulative Timesteps: 1,837,938,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,373.89170
Policy Entropy: 1.93792
Value Function Loss: 0.03179

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.31091
Value Function Update Magnitude: 0.32784

Collected Steps per Second: 20,421.39004
Overall Steps per Second: 10,060.16545

Timestep Collection Time: 2.44880
Timestep Consumption Time: 2.52209
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.97089

Cumulative Model Updates: 220,308
Cumulative Timesteps: 1,837,988,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1837988222...
Checkpoint 1837988222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,554.18250
Policy Entropy: 1.94505
Value Function Loss: 0.02827

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08115
Policy Update Magnitude: 0.30782
Value Function Update Magnitude: 0.34149

Collected Steps per Second: 20,900.19879
Overall Steps per Second: 10,228.11528

Timestep Collection Time: 2.39290
Timestep Consumption Time: 2.49676
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.88966

Cumulative Model Updates: 220,314
Cumulative Timesteps: 1,838,038,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,780.33709
Policy Entropy: 1.95741
Value Function Loss: 0.02553

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.29721
Value Function Update Magnitude: 0.34394

Collected Steps per Second: 18,864.02697
Overall Steps per Second: 9,567.50958

Timestep Collection Time: 2.65140
Timestep Consumption Time: 2.57630
PPO Batch Consumption Time: 0.31402
Total Iteration Time: 5.22769

Cumulative Model Updates: 220,320
Cumulative Timesteps: 1,838,088,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1838088250...
Checkpoint 1838088250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,111.61513
Policy Entropy: 1.97918
Value Function Loss: 0.02275

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07224
Policy Update Magnitude: 0.29604
Value Function Update Magnitude: 0.34315

Collected Steps per Second: 20,342.78252
Overall Steps per Second: 10,248.77433

Timestep Collection Time: 2.45797
Timestep Consumption Time: 2.42085
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.87883

Cumulative Model Updates: 220,326
Cumulative Timesteps: 1,838,138,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,066.36504
Policy Entropy: 1.96906
Value Function Loss: 0.02479

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07149
Policy Update Magnitude: 0.29226
Value Function Update Magnitude: 0.32689

Collected Steps per Second: 19,480.81262
Overall Steps per Second: 9,366.55344

Timestep Collection Time: 2.56735
Timestep Consumption Time: 2.77229
PPO Batch Consumption Time: 0.34588
Total Iteration Time: 5.33964

Cumulative Model Updates: 220,332
Cumulative Timesteps: 1,838,188,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1838188266...
Checkpoint 1838188266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,477.40451
Policy Entropy: 1.95897
Value Function Loss: 0.02768

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.07637
Policy Update Magnitude: 0.29948
Value Function Update Magnitude: 0.31782

Collected Steps per Second: 19,671.46815
Overall Steps per Second: 9,839.67462

Timestep Collection Time: 2.54185
Timestep Consumption Time: 2.53982
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 5.08167

Cumulative Model Updates: 220,338
Cumulative Timesteps: 1,838,238,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,111.94875
Policy Entropy: 1.92582
Value Function Loss: 0.03201

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08062
Policy Update Magnitude: 0.31623
Value Function Update Magnitude: 0.34679

Collected Steps per Second: 19,767.08346
Overall Steps per Second: 9,982.05943

Timestep Collection Time: 2.53098
Timestep Consumption Time: 2.48102
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 5.01199

Cumulative Model Updates: 220,344
Cumulative Timesteps: 1,838,288,298

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1838288298...
Checkpoint 1838288298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,068.12502
Policy Entropy: 1.92173
Value Function Loss: 0.03288

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.07799
Policy Update Magnitude: 0.32466
Value Function Update Magnitude: 0.35716

Collected Steps per Second: 20,760.25512
Overall Steps per Second: 10,258.47695

Timestep Collection Time: 2.40960
Timestep Consumption Time: 2.46675
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.87636

Cumulative Model Updates: 220,350
Cumulative Timesteps: 1,838,338,322

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,853.65180
Policy Entropy: 1.93096
Value Function Loss: 0.03049

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.08248
Policy Update Magnitude: 0.31940
Value Function Update Magnitude: 0.36980

Collected Steps per Second: 20,624.78782
Overall Steps per Second: 10,051.41478

Timestep Collection Time: 2.42514
Timestep Consumption Time: 2.55107
PPO Batch Consumption Time: 0.30101
Total Iteration Time: 4.97621

Cumulative Model Updates: 220,356
Cumulative Timesteps: 1,838,388,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1838388340...
Checkpoint 1838388340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,508.35951
Policy Entropy: 1.93410
Value Function Loss: 0.02990

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.07512
Policy Update Magnitude: 0.31221
Value Function Update Magnitude: 0.36149

Collected Steps per Second: 20,905.04698
Overall Steps per Second: 10,251.57226

Timestep Collection Time: 2.39349
Timestep Consumption Time: 2.48732
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.88081

Cumulative Model Updates: 220,362
Cumulative Timesteps: 1,838,438,376

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,612.56999
Policy Entropy: 1.93556
Value Function Loss: 0.03460

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08015
Policy Update Magnitude: 0.31811
Value Function Update Magnitude: 0.37107

Collected Steps per Second: 19,978.49920
Overall Steps per Second: 9,984.51603

Timestep Collection Time: 2.50279
Timestep Consumption Time: 2.50516
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 5.00795

Cumulative Model Updates: 220,368
Cumulative Timesteps: 1,838,488,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1838488378...
Checkpoint 1838488378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,226.58332
Policy Entropy: 1.92351
Value Function Loss: 0.03354

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07887
Policy Update Magnitude: 0.32401
Value Function Update Magnitude: 0.38381

Collected Steps per Second: 20,953.92549
Overall Steps per Second: 10,197.46676

Timestep Collection Time: 2.38752
Timestep Consumption Time: 2.51840
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.90592

Cumulative Model Updates: 220,374
Cumulative Timesteps: 1,838,538,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,978.57948
Policy Entropy: 1.92501
Value Function Loss: 0.03346

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.32149
Value Function Update Magnitude: 0.39633

Collected Steps per Second: 20,472.87044
Overall Steps per Second: 10,088.61312

Timestep Collection Time: 2.44382
Timestep Consumption Time: 2.51544
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.95925

Cumulative Model Updates: 220,380
Cumulative Timesteps: 1,838,588,438

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1838588438...
Checkpoint 1838588438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,046.39917
Policy Entropy: 1.93614
Value Function Loss: 0.02919

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07526
Policy Update Magnitude: 0.31338
Value Function Update Magnitude: 0.38513

Collected Steps per Second: 20,903.02454
Overall Steps per Second: 10,177.70964

Timestep Collection Time: 2.39267
Timestep Consumption Time: 2.52140
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.91407

Cumulative Model Updates: 220,386
Cumulative Timesteps: 1,838,638,452

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,768.52435
Policy Entropy: 1.94912
Value Function Loss: 0.02950

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.31323
Value Function Update Magnitude: 0.37227

Collected Steps per Second: 19,875.82238
Overall Steps per Second: 9,929.42670

Timestep Collection Time: 2.51773
Timestep Consumption Time: 2.52203
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 5.03977

Cumulative Model Updates: 220,392
Cumulative Timesteps: 1,838,688,494

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1838688494...
Checkpoint 1838688494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,462.13372
Policy Entropy: 1.96890
Value Function Loss: 0.03116

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.31006
Value Function Update Magnitude: 0.37084

Collected Steps per Second: 20,753.04929
Overall Steps per Second: 10,142.85350

Timestep Collection Time: 2.41063
Timestep Consumption Time: 2.52171
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.93234

Cumulative Model Updates: 220,398
Cumulative Timesteps: 1,838,738,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,146.27165
Policy Entropy: 1.96705
Value Function Loss: 0.03174

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07812
Policy Update Magnitude: 0.30598
Value Function Update Magnitude: 0.34558

Collected Steps per Second: 20,572.61050
Overall Steps per Second: 10,134.31771

Timestep Collection Time: 2.43090
Timestep Consumption Time: 2.50382
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.93472

Cumulative Model Updates: 220,404
Cumulative Timesteps: 1,838,788,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1838788532...
Checkpoint 1838788532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,004.18957
Policy Entropy: 1.96165
Value Function Loss: 0.03286

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07548
Policy Update Magnitude: 0.30758
Value Function Update Magnitude: 0.33369

Collected Steps per Second: 20,546.77845
Overall Steps per Second: 10,047.10974

Timestep Collection Time: 2.43444
Timestep Consumption Time: 2.54410
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.97855

Cumulative Model Updates: 220,410
Cumulative Timesteps: 1,838,838,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,919.93165
Policy Entropy: 1.94710
Value Function Loss: 0.02761

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07725
Policy Update Magnitude: 0.30303
Value Function Update Magnitude: 0.34713

Collected Steps per Second: 19,630.06602
Overall Steps per Second: 9,877.85046

Timestep Collection Time: 2.54834
Timestep Consumption Time: 2.51592
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 5.06426

Cumulative Model Updates: 220,416
Cumulative Timesteps: 1,838,888,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1838888576...
Checkpoint 1838888576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,989.88957
Policy Entropy: 1.93251
Value Function Loss: 0.02708

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.30369
Value Function Update Magnitude: 0.36239

Collected Steps per Second: 20,715.77248
Overall Steps per Second: 10,161.26347

Timestep Collection Time: 2.41391
Timestep Consumption Time: 2.50733
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.92124

Cumulative Model Updates: 220,422
Cumulative Timesteps: 1,838,938,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,179.66698
Policy Entropy: 1.94305
Value Function Loss: 0.02661

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.07568
Policy Update Magnitude: 0.31139
Value Function Update Magnitude: 0.35796

Collected Steps per Second: 20,965.32131
Overall Steps per Second: 10,072.50475

Timestep Collection Time: 2.38508
Timestep Consumption Time: 2.57932
PPO Batch Consumption Time: 0.29946
Total Iteration Time: 4.96441

Cumulative Model Updates: 220,428
Cumulative Timesteps: 1,838,988,586

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1838988586...
Checkpoint 1838988586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,366.61936
Policy Entropy: 1.93789
Value Function Loss: 0.02586

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.07363
Policy Update Magnitude: 0.30320
Value Function Update Magnitude: 0.36234

Collected Steps per Second: 20,927.58814
Overall Steps per Second: 10,259.47528

Timestep Collection Time: 2.39082
Timestep Consumption Time: 2.48604
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.87686

Cumulative Model Updates: 220,434
Cumulative Timesteps: 1,839,038,620

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,321.47586
Policy Entropy: 1.94412
Value Function Loss: 0.02556

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07056
Policy Update Magnitude: 0.29969
Value Function Update Magnitude: 0.32977

Collected Steps per Second: 19,927.62622
Overall Steps per Second: 9,577.06241

Timestep Collection Time: 2.51038
Timestep Consumption Time: 2.71314
PPO Batch Consumption Time: 0.32236
Total Iteration Time: 5.22352

Cumulative Model Updates: 220,440
Cumulative Timesteps: 1,839,088,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1839088646...
Checkpoint 1839088646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,854.86800
Policy Entropy: 1.93091
Value Function Loss: 0.02466

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07310
Policy Update Magnitude: 0.29235
Value Function Update Magnitude: 0.31323

Collected Steps per Second: 19,362.30819
Overall Steps per Second: 9,830.67629

Timestep Collection Time: 2.58471
Timestep Consumption Time: 2.50609
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 5.09080

Cumulative Model Updates: 220,446
Cumulative Timesteps: 1,839,138,692

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,127.55120
Policy Entropy: 1.94794
Value Function Loss: 0.02435

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07514
Policy Update Magnitude: 0.28864
Value Function Update Magnitude: 0.30288

Collected Steps per Second: 20,548.42223
Overall Steps per Second: 9,805.87908

Timestep Collection Time: 2.43376
Timestep Consumption Time: 2.66624
PPO Batch Consumption Time: 0.31357
Total Iteration Time: 5.10000

Cumulative Model Updates: 220,452
Cumulative Timesteps: 1,839,188,702

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1839188702...
Checkpoint 1839188702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,877.16012
Policy Entropy: 1.95195
Value Function Loss: 0.02561

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07254
Policy Update Magnitude: 0.29329
Value Function Update Magnitude: 0.28345

Collected Steps per Second: 20,435.53604
Overall Steps per Second: 9,945.90404

Timestep Collection Time: 2.44828
Timestep Consumption Time: 2.58213
PPO Batch Consumption Time: 0.30244
Total Iteration Time: 5.03041

Cumulative Model Updates: 220,458
Cumulative Timesteps: 1,839,238,734

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,449.55502
Policy Entropy: 1.94226
Value Function Loss: 0.02740

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07291
Policy Update Magnitude: 0.29749
Value Function Update Magnitude: 0.27622

Collected Steps per Second: 19,742.31048
Overall Steps per Second: 9,990.53250

Timestep Collection Time: 2.53395
Timestep Consumption Time: 2.47339
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 5.00734

Cumulative Model Updates: 220,464
Cumulative Timesteps: 1,839,288,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1839288760...
Checkpoint 1839288760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,543.88573
Policy Entropy: 1.93765
Value Function Loss: 0.02845

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07516
Policy Update Magnitude: 0.29983
Value Function Update Magnitude: 0.30829

Collected Steps per Second: 19,370.81128
Overall Steps per Second: 9,875.90106

Timestep Collection Time: 2.58378
Timestep Consumption Time: 2.48411
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 5.06789

Cumulative Model Updates: 220,470
Cumulative Timesteps: 1,839,338,810

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,919.22628
Policy Entropy: 1.92970
Value Function Loss: 0.02992

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07599
Policy Update Magnitude: 0.30587
Value Function Update Magnitude: 0.33352

Collected Steps per Second: 20,418.56591
Overall Steps per Second: 10,186.00118

Timestep Collection Time: 2.45091
Timestep Consumption Time: 2.46211
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.91302

Cumulative Model Updates: 220,476
Cumulative Timesteps: 1,839,388,854

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1839388854...
Checkpoint 1839388854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,940.53168
Policy Entropy: 1.92682
Value Function Loss: 0.02747

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.30429
Value Function Update Magnitude: 0.31749

Collected Steps per Second: 17,483.97041
Overall Steps per Second: 9,069.84192

Timestep Collection Time: 2.86136
Timestep Consumption Time: 2.65450
PPO Batch Consumption Time: 0.31208
Total Iteration Time: 5.51586

Cumulative Model Updates: 220,482
Cumulative Timesteps: 1,839,438,882

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,524.35775
Policy Entropy: 1.92625
Value Function Loss: 0.02966

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07738
Policy Update Magnitude: 0.30677
Value Function Update Magnitude: 0.29396

Collected Steps per Second: 18,456.39515
Overall Steps per Second: 9,537.92376

Timestep Collection Time: 2.71050
Timestep Consumption Time: 2.53446
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 5.24496

Cumulative Model Updates: 220,488
Cumulative Timesteps: 1,839,488,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1839488908...
Checkpoint 1839488908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,667.22346
Policy Entropy: 1.93754
Value Function Loss: 0.02779

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07712
Policy Update Magnitude: 0.30896
Value Function Update Magnitude: 0.33503

Collected Steps per Second: 19,515.35389
Overall Steps per Second: 9,890.86068

Timestep Collection Time: 2.56352
Timestep Consumption Time: 2.49448
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 5.05800

Cumulative Model Updates: 220,494
Cumulative Timesteps: 1,839,538,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,137.44946
Policy Entropy: 1.94064
Value Function Loss: 0.02496

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.07830
Policy Update Magnitude: 0.30202
Value Function Update Magnitude: 0.34279

Collected Steps per Second: 20,483.21010
Overall Steps per Second: 10,119.52382

Timestep Collection Time: 2.44141
Timestep Consumption Time: 2.50032
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.94173

Cumulative Model Updates: 220,500
Cumulative Timesteps: 1,839,588,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1839588944...
Checkpoint 1839588944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,739.49954
Policy Entropy: 1.95424
Value Function Loss: 0.02423

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07536
Policy Update Magnitude: 0.29112
Value Function Update Magnitude: 0.32931

Collected Steps per Second: 20,834.13869
Overall Steps per Second: 9,805.41138

Timestep Collection Time: 2.40058
Timestep Consumption Time: 2.70007
PPO Batch Consumption Time: 0.32054
Total Iteration Time: 5.10065

Cumulative Model Updates: 220,506
Cumulative Timesteps: 1,839,638,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,552.88001
Policy Entropy: 1.95673
Value Function Loss: 0.02079

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07269
Policy Update Magnitude: 0.28114
Value Function Update Magnitude: 0.31061

Collected Steps per Second: 20,966.52889
Overall Steps per Second: 9,771.97055

Timestep Collection Time: 2.38523
Timestep Consumption Time: 2.73247
PPO Batch Consumption Time: 0.32609
Total Iteration Time: 5.11770

Cumulative Model Updates: 220,512
Cumulative Timesteps: 1,839,688,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1839688968...
Checkpoint 1839688968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,638.13131
Policy Entropy: 1.94784
Value Function Loss: 0.02390

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07245
Policy Update Magnitude: 0.28356
Value Function Update Magnitude: 0.29321

Collected Steps per Second: 17,842.77656
Overall Steps per Second: 9,317.20066

Timestep Collection Time: 2.80281
Timestep Consumption Time: 2.56468
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 5.36749

Cumulative Model Updates: 220,518
Cumulative Timesteps: 1,839,738,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,962.29234
Policy Entropy: 1.92812
Value Function Loss: 0.02385

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07917
Policy Update Magnitude: 0.28979
Value Function Update Magnitude: 0.28761

Collected Steps per Second: 20,438.21581
Overall Steps per Second: 10,031.58230

Timestep Collection Time: 2.44728
Timestep Consumption Time: 2.53877
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.98605

Cumulative Model Updates: 220,524
Cumulative Timesteps: 1,839,788,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1839788996...
Checkpoint 1839788996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,620.26111
Policy Entropy: 1.92550
Value Function Loss: 0.02796

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.30019
Value Function Update Magnitude: 0.31159

Collected Steps per Second: 20,876.99059
Overall Steps per Second: 9,902.26303

Timestep Collection Time: 2.39508
Timestep Consumption Time: 2.65448
PPO Batch Consumption Time: 0.30635
Total Iteration Time: 5.04955

Cumulative Model Updates: 220,530
Cumulative Timesteps: 1,839,838,998

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,367.30247
Policy Entropy: 1.92798
Value Function Loss: 0.02818

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07823
Policy Update Magnitude: 0.30351
Value Function Update Magnitude: 0.32938

Collected Steps per Second: 19,670.78599
Overall Steps per Second: 9,994.27021

Timestep Collection Time: 2.54367
Timestep Consumption Time: 2.46280
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 5.00647

Cumulative Model Updates: 220,536
Cumulative Timesteps: 1,839,889,034

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1839889034...
Checkpoint 1839889034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,959.75991
Policy Entropy: 1.93998
Value Function Loss: 0.02909

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07058
Policy Update Magnitude: 0.30256
Value Function Update Magnitude: 0.34510

Collected Steps per Second: 18,853.21401
Overall Steps per Second: 9,494.52513

Timestep Collection Time: 2.65270
Timestep Consumption Time: 2.61475
PPO Batch Consumption Time: 0.30231
Total Iteration Time: 5.26746

Cumulative Model Updates: 220,542
Cumulative Timesteps: 1,839,939,046

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,368.63418
Policy Entropy: 1.92662
Value Function Loss: 0.02713

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07206
Policy Update Magnitude: 0.30037
Value Function Update Magnitude: 0.34618

Collected Steps per Second: 20,774.27790
Overall Steps per Second: 9,638.34084

Timestep Collection Time: 2.40798
Timestep Consumption Time: 2.78213
PPO Batch Consumption Time: 0.33280
Total Iteration Time: 5.19010

Cumulative Model Updates: 220,548
Cumulative Timesteps: 1,839,989,070

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1839989070...
Checkpoint 1839989070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,622.01268
Policy Entropy: 1.91914
Value Function Loss: 0.02596

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07146
Policy Update Magnitude: 0.29920
Value Function Update Magnitude: 0.32892

Collected Steps per Second: 20,469.31844
Overall Steps per Second: 9,983.01232

Timestep Collection Time: 2.44463
Timestep Consumption Time: 2.56788
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 5.01252

Cumulative Model Updates: 220,554
Cumulative Timesteps: 1,840,039,110

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,602.70709
Policy Entropy: 1.92704
Value Function Loss: 0.03039

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.31375
Value Function Update Magnitude: 0.27977

Collected Steps per Second: 20,735.65705
Overall Steps per Second: 10,151.86878

Timestep Collection Time: 2.41294
Timestep Consumption Time: 2.51561
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.92855

Cumulative Model Updates: 220,560
Cumulative Timesteps: 1,840,089,144

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1840089144...
Checkpoint 1840089144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,479.32706
Policy Entropy: 1.93982
Value Function Loss: 0.03063

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.07813
Policy Update Magnitude: 0.31227
Value Function Update Magnitude: 0.22464

Collected Steps per Second: 20,494.51910
Overall Steps per Second: 10,117.95705

Timestep Collection Time: 2.44016
Timestep Consumption Time: 2.50253
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.94270

Cumulative Model Updates: 220,566
Cumulative Timesteps: 1,840,139,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,041.37101
Policy Entropy: 1.93145
Value Function Loss: 0.03231

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.07617
Policy Update Magnitude: 0.31335
Value Function Update Magnitude: 0.25974

Collected Steps per Second: 20,931.59755
Overall Steps per Second: 10,147.99800

Timestep Collection Time: 2.38931
Timestep Consumption Time: 2.53896
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.92826

Cumulative Model Updates: 220,572
Cumulative Timesteps: 1,840,189,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1840189166...
Checkpoint 1840189166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,310.78754
Policy Entropy: 1.91392
Value Function Loss: 0.02757

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.30497
Value Function Update Magnitude: 0.29753

Collected Steps per Second: 18,919.63769
Overall Steps per Second: 8,925.94640

Timestep Collection Time: 2.64339
Timestep Consumption Time: 2.95960
PPO Batch Consumption Time: 0.35483
Total Iteration Time: 5.60299

Cumulative Model Updates: 220,578
Cumulative Timesteps: 1,840,239,178

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,304.74295
Policy Entropy: 1.90297
Value Function Loss: 0.02772

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.07269
Policy Update Magnitude: 0.30490
Value Function Update Magnitude: 0.29699

Collected Steps per Second: 20,514.73721
Overall Steps per Second: 9,999.88923

Timestep Collection Time: 2.43795
Timestep Consumption Time: 2.56350
PPO Batch Consumption Time: 0.29691
Total Iteration Time: 5.00146

Cumulative Model Updates: 220,584
Cumulative Timesteps: 1,840,289,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1840289192...
Checkpoint 1840289192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,914.01429
Policy Entropy: 1.92029
Value Function Loss: 0.02798

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07661
Policy Update Magnitude: 0.30644
Value Function Update Magnitude: 0.29114

Collected Steps per Second: 20,658.65488
Overall Steps per Second: 10,065.20914

Timestep Collection Time: 2.42107
Timestep Consumption Time: 2.54813
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.96920

Cumulative Model Updates: 220,590
Cumulative Timesteps: 1,840,339,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,419.43822
Policy Entropy: 1.93786
Value Function Loss: 0.02954

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.30586
Value Function Update Magnitude: 0.30823

Collected Steps per Second: 20,718.29842
Overall Steps per Second: 10,046.89610

Timestep Collection Time: 2.41390
Timestep Consumption Time: 2.56395
PPO Batch Consumption Time: 0.30053
Total Iteration Time: 4.97786

Cumulative Model Updates: 220,596
Cumulative Timesteps: 1,840,389,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1840389220...
Checkpoint 1840389220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,388.21421
Policy Entropy: 1.94617
Value Function Loss: 0.03222

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.31395
Value Function Update Magnitude: 0.30025

Collected Steps per Second: 18,850.16056
Overall Steps per Second: 9,767.56316

Timestep Collection Time: 2.65366
Timestep Consumption Time: 2.46757
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 5.12124

Cumulative Model Updates: 220,602
Cumulative Timesteps: 1,840,439,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,107.95758
Policy Entropy: 1.92619
Value Function Loss: 0.03213

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.31642
Value Function Update Magnitude: 0.25236

Collected Steps per Second: 20,590.59994
Overall Steps per Second: 10,051.65283

Timestep Collection Time: 2.43004
Timestep Consumption Time: 2.54785
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.97789

Cumulative Model Updates: 220,608
Cumulative Timesteps: 1,840,489,278

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1840489278...
Checkpoint 1840489278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,415.06854
Policy Entropy: 1.91948
Value Function Loss: 0.03067

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.07855
Policy Update Magnitude: 0.31088
Value Function Update Magnitude: 0.30344

Collected Steps per Second: 20,257.29323
Overall Steps per Second: 9,979.86364

Timestep Collection Time: 2.46844
Timestep Consumption Time: 2.54204
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 5.01049

Cumulative Model Updates: 220,614
Cumulative Timesteps: 1,840,539,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,200.09442
Policy Entropy: 1.92503
Value Function Loss: 0.02892

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.30381
Value Function Update Magnitude: 0.33500

Collected Steps per Second: 20,315.33958
Overall Steps per Second: 9,987.90385

Timestep Collection Time: 2.46119
Timestep Consumption Time: 2.54486
PPO Batch Consumption Time: 0.29919
Total Iteration Time: 5.00606

Cumulative Model Updates: 220,620
Cumulative Timesteps: 1,840,589,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1840589282...
Checkpoint 1840589282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,256.51408
Policy Entropy: 1.94889
Value Function Loss: 0.02824

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07811
Policy Update Magnitude: 0.30495
Value Function Update Magnitude: 0.30346

Collected Steps per Second: 19,645.95498
Overall Steps per Second: 9,574.47260

Timestep Collection Time: 2.54648
Timestep Consumption Time: 2.67867
PPO Batch Consumption Time: 0.31457
Total Iteration Time: 5.22514

Cumulative Model Updates: 220,626
Cumulative Timesteps: 1,840,639,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,865.11117
Policy Entropy: 1.95736
Value Function Loss: 0.03105

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07380
Policy Update Magnitude: 0.31131
Value Function Update Magnitude: 0.28421

Collected Steps per Second: 19,868.37844
Overall Steps per Second: 9,981.32346

Timestep Collection Time: 2.51868
Timestep Consumption Time: 2.49489
PPO Batch Consumption Time: 0.29887
Total Iteration Time: 5.01356

Cumulative Model Updates: 220,632
Cumulative Timesteps: 1,840,689,352

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1840689352...
Checkpoint 1840689352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,386.42102
Policy Entropy: 1.94665
Value Function Loss: 0.03066

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08197
Policy Update Magnitude: 0.31475
Value Function Update Magnitude: 0.33791

Collected Steps per Second: 19,990.35737
Overall Steps per Second: 9,950.21589

Timestep Collection Time: 2.50181
Timestep Consumption Time: 2.52442
PPO Batch Consumption Time: 0.30321
Total Iteration Time: 5.02622

Cumulative Model Updates: 220,638
Cumulative Timesteps: 1,840,739,364

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,808.30148
Policy Entropy: 1.95354
Value Function Loss: 0.03030

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08408
Policy Update Magnitude: 0.31489
Value Function Update Magnitude: 0.35067

Collected Steps per Second: 20,180.13891
Overall Steps per Second: 10,112.09199

Timestep Collection Time: 2.47986
Timestep Consumption Time: 2.46906
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.94893

Cumulative Model Updates: 220,644
Cumulative Timesteps: 1,840,789,408

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1840789408...
Checkpoint 1840789408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,858.64885
Policy Entropy: 1.93860
Value Function Loss: 0.02854

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07672
Policy Update Magnitude: 0.31050
Value Function Update Magnitude: 0.34739

Collected Steps per Second: 19,373.31161
Overall Steps per Second: 9,942.33359

Timestep Collection Time: 2.58097
Timestep Consumption Time: 2.44823
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 5.02920

Cumulative Model Updates: 220,650
Cumulative Timesteps: 1,840,839,410

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,228.56158
Policy Entropy: 1.93194
Value Function Loss: 0.02654

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07342
Policy Update Magnitude: 0.30917
Value Function Update Magnitude: 0.31764

Collected Steps per Second: 20,333.19898
Overall Steps per Second: 10,016.93015

Timestep Collection Time: 2.46041
Timestep Consumption Time: 2.53393
PPO Batch Consumption Time: 0.29794
Total Iteration Time: 4.99434

Cumulative Model Updates: 220,656
Cumulative Timesteps: 1,840,889,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1840889438...
Checkpoint 1840889438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,363.82416
Policy Entropy: 1.92243
Value Function Loss: 0.02692

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07158
Policy Update Magnitude: 0.30874
Value Function Update Magnitude: 0.31615

Collected Steps per Second: 20,818.86163
Overall Steps per Second: 10,095.60811

Timestep Collection Time: 2.40224
Timestep Consumption Time: 2.55159
PPO Batch Consumption Time: 0.30214
Total Iteration Time: 4.95384

Cumulative Model Updates: 220,662
Cumulative Timesteps: 1,840,939,450

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,984.76138
Policy Entropy: 1.92623
Value Function Loss: 0.02530

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07135
Policy Update Magnitude: 0.30394
Value Function Update Magnitude: 0.32707

Collected Steps per Second: 20,777.01052
Overall Steps per Second: 10,117.24897

Timestep Collection Time: 2.40766
Timestep Consumption Time: 2.53677
PPO Batch Consumption Time: 0.30027
Total Iteration Time: 4.94443

Cumulative Model Updates: 220,668
Cumulative Timesteps: 1,840,989,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1840989474...
Checkpoint 1840989474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,405.70183
Policy Entropy: 1.94209
Value Function Loss: 0.02684

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07185
Policy Update Magnitude: 0.30448
Value Function Update Magnitude: 0.32221

Collected Steps per Second: 20,012.16984
Overall Steps per Second: 10,017.31549

Timestep Collection Time: 2.50028
Timestep Consumption Time: 2.49467
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.99495

Cumulative Model Updates: 220,674
Cumulative Timesteps: 1,841,039,510

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,705.62509
Policy Entropy: 1.94316
Value Function Loss: 0.02696

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07329
Policy Update Magnitude: 0.30417
Value Function Update Magnitude: 0.32814

Collected Steps per Second: 20,876.56878
Overall Steps per Second: 10,124.91027

Timestep Collection Time: 2.39570
Timestep Consumption Time: 2.54400
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.93970

Cumulative Model Updates: 220,680
Cumulative Timesteps: 1,841,089,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1841089524...
Checkpoint 1841089524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,805.87739
Policy Entropy: 1.94102
Value Function Loss: 0.02806

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07332
Policy Update Magnitude: 0.30150
Value Function Update Magnitude: 0.34150

Collected Steps per Second: 20,790.43563
Overall Steps per Second: 9,975.72292

Timestep Collection Time: 2.40553
Timestep Consumption Time: 2.60784
PPO Batch Consumption Time: 0.30181
Total Iteration Time: 5.01337

Cumulative Model Updates: 220,686
Cumulative Timesteps: 1,841,139,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,337.72950
Policy Entropy: 1.93071
Value Function Loss: 0.02786

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07351
Policy Update Magnitude: 0.30494
Value Function Update Magnitude: 0.32569

Collected Steps per Second: 21,070.78302
Overall Steps per Second: 10,132.83626

Timestep Collection Time: 2.37371
Timestep Consumption Time: 2.56232
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.93603

Cumulative Model Updates: 220,692
Cumulative Timesteps: 1,841,189,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1841189552...
Checkpoint 1841189552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,898.84501
Policy Entropy: 1.93191
Value Function Loss: 0.02821

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07299
Policy Update Magnitude: 0.30392
Value Function Update Magnitude: 0.33734

Collected Steps per Second: 19,769.79308
Overall Steps per Second: 9,969.22077

Timestep Collection Time: 2.52952
Timestep Consumption Time: 2.48672
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 5.01624

Cumulative Model Updates: 220,698
Cumulative Timesteps: 1,841,239,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,729.35586
Policy Entropy: 1.94256
Value Function Loss: 0.02941

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07717
Policy Update Magnitude: 0.30702
Value Function Update Magnitude: 0.34859

Collected Steps per Second: 20,635.17099
Overall Steps per Second: 10,018.27851

Timestep Collection Time: 2.42382
Timestep Consumption Time: 2.56865
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.99247

Cumulative Model Updates: 220,704
Cumulative Timesteps: 1,841,289,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1841289576...
Checkpoint 1841289576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,646.80168
Policy Entropy: 1.93918
Value Function Loss: 0.02899

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.31554
Value Function Update Magnitude: 0.35540

Collected Steps per Second: 20,273.33818
Overall Steps per Second: 9,929.18073

Timestep Collection Time: 2.46669
Timestep Consumption Time: 2.56978
PPO Batch Consumption Time: 0.29821
Total Iteration Time: 5.03647

Cumulative Model Updates: 220,710
Cumulative Timesteps: 1,841,339,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,371.02201
Policy Entropy: 1.92740
Value Function Loss: 0.02643

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.30417
Value Function Update Magnitude: 0.38336

Collected Steps per Second: 19,428.80389
Overall Steps per Second: 9,485.55988

Timestep Collection Time: 2.57473
Timestep Consumption Time: 2.69897
PPO Batch Consumption Time: 0.30766
Total Iteration Time: 5.27370

Cumulative Model Updates: 220,716
Cumulative Timesteps: 1,841,389,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1841389608...
Checkpoint 1841389608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,422.22133
Policy Entropy: 1.91643
Value Function Loss: 0.02409

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.30369
Value Function Update Magnitude: 0.37380

Collected Steps per Second: 19,744.06499
Overall Steps per Second: 9,883.96260

Timestep Collection Time: 2.53443
Timestep Consumption Time: 2.52831
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 5.06275

Cumulative Model Updates: 220,722
Cumulative Timesteps: 1,841,439,648

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,912.02940
Policy Entropy: 1.92261
Value Function Loss: 0.02559

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.30099
Value Function Update Magnitude: 0.32757

Collected Steps per Second: 20,498.42441
Overall Steps per Second: 10,016.94210

Timestep Collection Time: 2.43941
Timestep Consumption Time: 2.55254
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.99194

Cumulative Model Updates: 220,728
Cumulative Timesteps: 1,841,489,652

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1841489652...
Checkpoint 1841489652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,096.04110
Policy Entropy: 1.94424
Value Function Loss: 0.02881

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.30278
Value Function Update Magnitude: 0.32809

Collected Steps per Second: 20,135.52884
Overall Steps per Second: 9,900.17462

Timestep Collection Time: 2.48456
Timestep Consumption Time: 2.56868
PPO Batch Consumption Time: 0.29934
Total Iteration Time: 5.05324

Cumulative Model Updates: 220,734
Cumulative Timesteps: 1,841,539,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,006.84233
Policy Entropy: 1.95307
Value Function Loss: 0.02864

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.30963
Value Function Update Magnitude: 0.34432

Collected Steps per Second: 20,901.80052
Overall Steps per Second: 10,249.38329

Timestep Collection Time: 2.39357
Timestep Consumption Time: 2.48770
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.88127

Cumulative Model Updates: 220,740
Cumulative Timesteps: 1,841,589,710

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1841589710...
Checkpoint 1841589710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,590.69948
Policy Entropy: 1.95331
Value Function Loss: 0.02816

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.30915
Value Function Update Magnitude: 0.35028

Collected Steps per Second: 19,272.28009
Overall Steps per Second: 9,885.48688

Timestep Collection Time: 2.59492
Timestep Consumption Time: 2.46401
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 5.05893

Cumulative Model Updates: 220,746
Cumulative Timesteps: 1,841,639,720

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,620.10541
Policy Entropy: 1.96377
Value Function Loss: 0.02480

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.07812
Policy Update Magnitude: 0.29776
Value Function Update Magnitude: 0.34127

Collected Steps per Second: 19,966.73728
Overall Steps per Second: 9,878.17529

Timestep Collection Time: 2.50467
Timestep Consumption Time: 2.55801
PPO Batch Consumption Time: 0.30603
Total Iteration Time: 5.06268

Cumulative Model Updates: 220,752
Cumulative Timesteps: 1,841,689,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1841689730...
Checkpoint 1841689730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,175.50013
Policy Entropy: 1.97287
Value Function Loss: 0.02666

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07342
Policy Update Magnitude: 0.29223
Value Function Update Magnitude: 0.33340

Collected Steps per Second: 20,194.13342
Overall Steps per Second: 10,046.55466

Timestep Collection Time: 2.47646
Timestep Consumption Time: 2.50136
PPO Batch Consumption Time: 0.30171
Total Iteration Time: 4.97783

Cumulative Model Updates: 220,758
Cumulative Timesteps: 1,841,739,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,662.95305
Policy Entropy: 1.95621
Value Function Loss: 0.02720

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07349
Policy Update Magnitude: 0.29931
Value Function Update Magnitude: 0.31663

Collected Steps per Second: 19,913.00570
Overall Steps per Second: 9,749.39654

Timestep Collection Time: 2.51203
Timestep Consumption Time: 2.61875
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 5.13078

Cumulative Model Updates: 220,764
Cumulative Timesteps: 1,841,789,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1841789762...
Checkpoint 1841789762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,472.18597
Policy Entropy: 1.94610
Value Function Loss: 0.02622

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.07514
Policy Update Magnitude: 0.29716
Value Function Update Magnitude: 0.31571

Collected Steps per Second: 19,670.07512
Overall Steps per Second: 9,973.74424

Timestep Collection Time: 2.54254
Timestep Consumption Time: 2.47182
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 5.01437

Cumulative Model Updates: 220,770
Cumulative Timesteps: 1,841,839,774

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,324.47047
Policy Entropy: 1.95711
Value Function Loss: 0.02621

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07715
Policy Update Magnitude: 0.29988
Value Function Update Magnitude: 0.33285

Collected Steps per Second: 21,068.10560
Overall Steps per Second: 10,164.41302

Timestep Collection Time: 2.37383
Timestep Consumption Time: 2.54648
PPO Batch Consumption Time: 0.29958
Total Iteration Time: 4.92030

Cumulative Model Updates: 220,776
Cumulative Timesteps: 1,841,889,786

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1841889786...
Checkpoint 1841889786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,621.29138
Policy Entropy: 1.96505
Value Function Loss: 0.02626

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07228
Policy Update Magnitude: 0.30146
Value Function Update Magnitude: 0.33842

Collected Steps per Second: 20,343.28625
Overall Steps per Second: 9,935.33019

Timestep Collection Time: 2.45919
Timestep Consumption Time: 2.57617
PPO Batch Consumption Time: 0.30264
Total Iteration Time: 5.03536

Cumulative Model Updates: 220,782
Cumulative Timesteps: 1,841,939,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,872.36643
Policy Entropy: 1.97500
Value Function Loss: 0.02400

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.07539
Policy Update Magnitude: 0.29852
Value Function Update Magnitude: 0.34691

Collected Steps per Second: 19,457.42172
Overall Steps per Second: 9,563.25166

Timestep Collection Time: 2.57095
Timestep Consumption Time: 2.65991
PPO Batch Consumption Time: 0.30399
Total Iteration Time: 5.23086

Cumulative Model Updates: 220,788
Cumulative Timesteps: 1,841,989,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1841989838...
Checkpoint 1841989838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,165.98984
Policy Entropy: 1.95267
Value Function Loss: 0.02362

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.07203
Policy Update Magnitude: 0.28949
Value Function Update Magnitude: 0.32791

Collected Steps per Second: 19,581.94340
Overall Steps per Second: 9,758.42161

Timestep Collection Time: 2.55450
Timestep Consumption Time: 2.57154
PPO Batch Consumption Time: 0.29966
Total Iteration Time: 5.12603

Cumulative Model Updates: 220,794
Cumulative Timesteps: 1,842,039,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,239.36933
Policy Entropy: 1.93640
Value Function Loss: 0.02507

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07135
Policy Update Magnitude: 0.29437
Value Function Update Magnitude: 0.31282

Collected Steps per Second: 20,853.75147
Overall Steps per Second: 9,989.84799

Timestep Collection Time: 2.39871
Timestep Consumption Time: 2.60858
PPO Batch Consumption Time: 0.29876
Total Iteration Time: 5.00728

Cumulative Model Updates: 220,800
Cumulative Timesteps: 1,842,089,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1842089882...
Checkpoint 1842089882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,440.60643
Policy Entropy: 1.92901
Value Function Loss: 0.02948

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07275
Policy Update Magnitude: 0.30665
Value Function Update Magnitude: 0.31039

Collected Steps per Second: 20,336.20316
Overall Steps per Second: 9,931.86472

Timestep Collection Time: 2.45955
Timestep Consumption Time: 2.57656
PPO Batch Consumption Time: 0.29871
Total Iteration Time: 5.03611

Cumulative Model Updates: 220,806
Cumulative Timesteps: 1,842,139,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,235.23440
Policy Entropy: 1.93672
Value Function Loss: 0.03052

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.31385
Value Function Update Magnitude: 0.32812

Collected Steps per Second: 21,115.38336
Overall Steps per Second: 10,124.70521

Timestep Collection Time: 2.36927
Timestep Consumption Time: 2.57191
PPO Batch Consumption Time: 0.30198
Total Iteration Time: 4.94118

Cumulative Model Updates: 220,812
Cumulative Timesteps: 1,842,189,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1842189928...
Checkpoint 1842189928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,591.73359
Policy Entropy: 1.93290
Value Function Loss: 0.02802

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.30642
Value Function Update Magnitude: 0.37274

Collected Steps per Second: 20,404.71306
Overall Steps per Second: 10,017.81258

Timestep Collection Time: 2.45120
Timestep Consumption Time: 2.54151
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.99271

Cumulative Model Updates: 220,818
Cumulative Timesteps: 1,842,239,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,131.80637
Policy Entropy: 1.93879
Value Function Loss: 0.02890

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07580
Policy Update Magnitude: 0.30526
Value Function Update Magnitude: 0.38197

Collected Steps per Second: 21,208.40262
Overall Steps per Second: 10,145.78582

Timestep Collection Time: 2.35973
Timestep Consumption Time: 2.57296
PPO Batch Consumption Time: 0.29880
Total Iteration Time: 4.93269

Cumulative Model Updates: 220,824
Cumulative Timesteps: 1,842,289,990

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1842289990...
Checkpoint 1842289990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,187.87073
Policy Entropy: 1.94269
Value Function Loss: 0.03175

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07525
Policy Update Magnitude: 0.31993
Value Function Update Magnitude: 0.38578

Collected Steps per Second: 20,584.80218
Overall Steps per Second: 10,118.45828

Timestep Collection Time: 2.42937
Timestep Consumption Time: 2.51289
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.94225

Cumulative Model Updates: 220,830
Cumulative Timesteps: 1,842,339,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,570.48126
Policy Entropy: 1.93421
Value Function Loss: 0.03005

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.07338
Policy Update Magnitude: 0.31760
Value Function Update Magnitude: 0.37118

Collected Steps per Second: 19,780.98673
Overall Steps per Second: 9,242.68823

Timestep Collection Time: 2.52808
Timestep Consumption Time: 2.88246
PPO Batch Consumption Time: 0.33901
Total Iteration Time: 5.41055

Cumulative Model Updates: 220,836
Cumulative Timesteps: 1,842,390,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1842390006...
Checkpoint 1842390006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,016.98604
Policy Entropy: 1.94019
Value Function Loss: 0.02963

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.07122
Policy Update Magnitude: 0.30974
Value Function Update Magnitude: 0.35143

Collected Steps per Second: 19,661.86606
Overall Steps per Second: 9,865.95591

Timestep Collection Time: 2.54391
Timestep Consumption Time: 2.52585
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 5.06976

Cumulative Model Updates: 220,842
Cumulative Timesteps: 1,842,440,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,027.45731
Policy Entropy: 1.95376
Value Function Loss: 0.03087

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07356
Policy Update Magnitude: 0.31141
Value Function Update Magnitude: 0.31442

Collected Steps per Second: 21,168.02037
Overall Steps per Second: 10,189.74421

Timestep Collection Time: 2.36290
Timestep Consumption Time: 2.54576
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.90866

Cumulative Model Updates: 220,848
Cumulative Timesteps: 1,842,490,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1842490042...
Checkpoint 1842490042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,832.93586
Policy Entropy: 1.98095
Value Function Loss: 0.02959

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07617
Policy Update Magnitude: 0.31250
Value Function Update Magnitude: 0.28476

Collected Steps per Second: 20,690.59076
Overall Steps per Second: 10,029.18681

Timestep Collection Time: 2.41781
Timestep Consumption Time: 2.57023
PPO Batch Consumption Time: 0.29863
Total Iteration Time: 4.98804

Cumulative Model Updates: 220,854
Cumulative Timesteps: 1,842,540,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,318.70507
Policy Entropy: 1.98438
Value Function Loss: 0.02626

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07419
Policy Update Magnitude: 0.29781
Value Function Update Magnitude: 0.28670

Collected Steps per Second: 21,153.72808
Overall Steps per Second: 9,731.74822

Timestep Collection Time: 2.36497
Timestep Consumption Time: 2.77573
PPO Batch Consumption Time: 0.33350
Total Iteration Time: 5.14070

Cumulative Model Updates: 220,860
Cumulative Timesteps: 1,842,590,096

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1842590096...
Checkpoint 1842590096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,619.34396
Policy Entropy: 1.97951
Value Function Loss: 0.02257

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06732
Policy Update Magnitude: 0.28954
Value Function Update Magnitude: 0.29072

Collected Steps per Second: 19,890.05599
Overall Steps per Second: 9,834.52484

Timestep Collection Time: 2.51503
Timestep Consumption Time: 2.57154
PPO Batch Consumption Time: 0.29864
Total Iteration Time: 5.08657

Cumulative Model Updates: 220,866
Cumulative Timesteps: 1,842,640,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,681.42994
Policy Entropy: 1.96805
Value Function Loss: 0.02410

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.06833
Policy Update Magnitude: 0.28767
Value Function Update Magnitude: 0.27815

Collected Steps per Second: 20,756.17432
Overall Steps per Second: 10,072.16114

Timestep Collection Time: 2.41017
Timestep Consumption Time: 2.55658
PPO Batch Consumption Time: 0.29776
Total Iteration Time: 4.96676

Cumulative Model Updates: 220,872
Cumulative Timesteps: 1,842,690,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1842690146...
Checkpoint 1842690146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,783.98362
Policy Entropy: 1.95869
Value Function Loss: 0.02488

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07238
Policy Update Magnitude: 0.29346
Value Function Update Magnitude: 0.29512

Collected Steps per Second: 20,498.89551
Overall Steps per Second: 10,044.84401

Timestep Collection Time: 2.44062
Timestep Consumption Time: 2.54005
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.98066

Cumulative Model Updates: 220,878
Cumulative Timesteps: 1,842,740,176

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,698.66864
Policy Entropy: 1.95085
Value Function Loss: 0.02651

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.07787
Policy Update Magnitude: 0.29761
Value Function Update Magnitude: 0.31801

Collected Steps per Second: 21,306.38987
Overall Steps per Second: 9,832.78990

Timestep Collection Time: 2.34803
Timestep Consumption Time: 2.73985
PPO Batch Consumption Time: 0.33065
Total Iteration Time: 5.08787

Cumulative Model Updates: 220,884
Cumulative Timesteps: 1,842,790,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1842790204...
Checkpoint 1842790204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,824.76152
Policy Entropy: 1.95936
Value Function Loss: 0.02951

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07451
Policy Update Magnitude: 0.30403
Value Function Update Magnitude: 0.30707

Collected Steps per Second: 20,724.78659
Overall Steps per Second: 10,048.14031

Timestep Collection Time: 2.41334
Timestep Consumption Time: 2.56430
PPO Batch Consumption Time: 0.29882
Total Iteration Time: 4.97764

Cumulative Model Updates: 220,890
Cumulative Timesteps: 1,842,840,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,669.31099
Policy Entropy: 1.97266
Value Function Loss: 0.02636

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07162
Policy Update Magnitude: 0.29986
Value Function Update Magnitude: 0.29953

Collected Steps per Second: 20,418.39045
Overall Steps per Second: 10,132.96924

Timestep Collection Time: 2.44965
Timestep Consumption Time: 2.48651
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 4.93616

Cumulative Model Updates: 220,896
Cumulative Timesteps: 1,842,890,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1842890238...
Checkpoint 1842890238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,233.81800
Policy Entropy: 1.97524
Value Function Loss: 0.02894

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.06797
Policy Update Magnitude: 0.29251
Value Function Update Magnitude: 0.29377

Collected Steps per Second: 19,841.99386
Overall Steps per Second: 10,126.43469

Timestep Collection Time: 2.52122
Timestep Consumption Time: 2.41892
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.94014

Cumulative Model Updates: 220,902
Cumulative Timesteps: 1,842,940,264

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,031.80177
Policy Entropy: 1.97453
Value Function Loss: 0.02916

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07161
Policy Update Magnitude: 0.29725
Value Function Update Magnitude: 0.29061

Collected Steps per Second: 20,253.91139
Overall Steps per Second: 9,681.70275

Timestep Collection Time: 2.46915
Timestep Consumption Time: 2.69626
PPO Batch Consumption Time: 0.33495
Total Iteration Time: 5.16541

Cumulative Model Updates: 220,908
Cumulative Timesteps: 1,842,990,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1842990274...
Checkpoint 1842990274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,534.99199
Policy Entropy: 1.96605
Value Function Loss: 0.02882

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.07429
Policy Update Magnitude: 0.29968
Value Function Update Magnitude: 0.30719

Collected Steps per Second: 19,839.91159
Overall Steps per Second: 9,971.64619

Timestep Collection Time: 2.52279
Timestep Consumption Time: 2.49664
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 5.01943

Cumulative Model Updates: 220,914
Cumulative Timesteps: 1,843,040,326

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,579.19173
Policy Entropy: 1.95850
Value Function Loss: 0.02665

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07159
Policy Update Magnitude: 0.29818
Value Function Update Magnitude: 0.31402

Collected Steps per Second: 20,796.12943
Overall Steps per Second: 10,261.61348

Timestep Collection Time: 2.40449
Timestep Consumption Time: 2.46843
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.87292

Cumulative Model Updates: 220,920
Cumulative Timesteps: 1,843,090,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1843090330...
Checkpoint 1843090330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,127.44854
Policy Entropy: 1.95901
Value Function Loss: 0.02832

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07459
Policy Update Magnitude: 0.30619
Value Function Update Magnitude: 0.33316

Collected Steps per Second: 20,274.69326
Overall Steps per Second: 10,115.02304

Timestep Collection Time: 2.46623
Timestep Consumption Time: 2.47711
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.94334

Cumulative Model Updates: 220,926
Cumulative Timesteps: 1,843,140,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,722.77522
Policy Entropy: 1.95858
Value Function Loss: 0.03120

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.08509
Policy Update Magnitude: 0.30916
Value Function Update Magnitude: 0.31900

Collected Steps per Second: 21,039.06816
Overall Steps per Second: 9,894.02772

Timestep Collection Time: 2.37729
Timestep Consumption Time: 2.67788
PPO Batch Consumption Time: 0.32565
Total Iteration Time: 5.05517

Cumulative Model Updates: 220,932
Cumulative Timesteps: 1,843,190,348

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1843190348...
Checkpoint 1843190348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,880.92075
Policy Entropy: 1.95873
Value Function Loss: 0.02987

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.30862
Value Function Update Magnitude: 0.33167

Collected Steps per Second: 20,675.66629
Overall Steps per Second: 10,023.03326

Timestep Collection Time: 2.41966
Timestep Consumption Time: 2.57165
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 4.99130

Cumulative Model Updates: 220,938
Cumulative Timesteps: 1,843,240,376

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,799.07949
Policy Entropy: 1.95138
Value Function Loss: 0.02791

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08272
Policy Update Magnitude: 0.30357
Value Function Update Magnitude: 0.34622

Collected Steps per Second: 21,074.90437
Overall Steps per Second: 10,141.42576

Timestep Collection Time: 2.37391
Timestep Consumption Time: 2.55932
PPO Batch Consumption Time: 0.29813
Total Iteration Time: 4.93323

Cumulative Model Updates: 220,944
Cumulative Timesteps: 1,843,290,406

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1843290406...
Checkpoint 1843290406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,587.44876
Policy Entropy: 1.94670
Value Function Loss: 0.02694

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.30235
Value Function Update Magnitude: 0.33849

Collected Steps per Second: 20,449.92033
Overall Steps per Second: 10,117.92225

Timestep Collection Time: 2.44549
Timestep Consumption Time: 2.49723
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.94271

Cumulative Model Updates: 220,950
Cumulative Timesteps: 1,843,340,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,772.24882
Policy Entropy: 1.95395
Value Function Loss: 0.02639

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.07798
Policy Update Magnitude: 0.30327
Value Function Update Magnitude: 0.34286

Collected Steps per Second: 20,849.15452
Overall Steps per Second: 9,813.69442

Timestep Collection Time: 2.39895
Timestep Consumption Time: 2.69761
PPO Batch Consumption Time: 0.32090
Total Iteration Time: 5.09655

Cumulative Model Updates: 220,956
Cumulative Timesteps: 1,843,390,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1843390432...
Checkpoint 1843390432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,523.32565
Policy Entropy: 1.95915
Value Function Loss: 0.03047

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.30937
Value Function Update Magnitude: 0.31231

Collected Steps per Second: 20,598.67774
Overall Steps per Second: 9,926.20119

Timestep Collection Time: 2.42841
Timestep Consumption Time: 2.61098
PPO Batch Consumption Time: 0.30727
Total Iteration Time: 5.03939

Cumulative Model Updates: 220,962
Cumulative Timesteps: 1,843,440,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,287.60033
Policy Entropy: 1.96616
Value Function Loss: 0.02985

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.30930
Value Function Update Magnitude: 0.28814

Collected Steps per Second: 20,486.18945
Overall Steps per Second: 10,066.61637

Timestep Collection Time: 2.44164
Timestep Consumption Time: 2.52725
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.96890

Cumulative Model Updates: 220,968
Cumulative Timesteps: 1,843,490,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1843490474...
Checkpoint 1843490474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,681.41283
Policy Entropy: 1.96887
Value Function Loss: 0.02852

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.08377
Policy Update Magnitude: 0.30046
Value Function Update Magnitude: 0.28867

Collected Steps per Second: 20,199.61339
Overall Steps per Second: 9,903.53286

Timestep Collection Time: 2.47529
Timestep Consumption Time: 2.57341
PPO Batch Consumption Time: 0.30142
Total Iteration Time: 5.04870

Cumulative Model Updates: 220,974
Cumulative Timesteps: 1,843,540,474

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,947.75566
Policy Entropy: 1.95899
Value Function Loss: 0.02505

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.29981
Value Function Update Magnitude: 0.27295

Collected Steps per Second: 20,284.47743
Overall Steps per Second: 9,766.36557

Timestep Collection Time: 2.46592
Timestep Consumption Time: 2.65573
PPO Batch Consumption Time: 0.32379
Total Iteration Time: 5.12166

Cumulative Model Updates: 220,980
Cumulative Timesteps: 1,843,590,494

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1843590494...
Checkpoint 1843590494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,126.11559
Policy Entropy: 1.94553
Value Function Loss: 0.02797

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.30353
Value Function Update Magnitude: 0.25421

Collected Steps per Second: 19,433.72563
Overall Steps per Second: 10,037.32311

Timestep Collection Time: 2.57388
Timestep Consumption Time: 2.40952
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.98340

Cumulative Model Updates: 220,986
Cumulative Timesteps: 1,843,640,514

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,598.11728
Policy Entropy: 1.95552
Value Function Loss: 0.02715

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.07958
Policy Update Magnitude: 0.30052
Value Function Update Magnitude: 0.28811

Collected Steps per Second: 20,004.35517
Overall Steps per Second: 10,012.22243

Timestep Collection Time: 2.49956
Timestep Consumption Time: 2.49454
PPO Batch Consumption Time: 0.29894
Total Iteration Time: 4.99410

Cumulative Model Updates: 220,992
Cumulative Timesteps: 1,843,690,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1843690516...
Checkpoint 1843690516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,890.05557
Policy Entropy: 1.94813
Value Function Loss: 0.02529

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.28920
Value Function Update Magnitude: 0.33160

Collected Steps per Second: 19,482.41596
Overall Steps per Second: 9,807.97128

Timestep Collection Time: 2.56765
Timestep Consumption Time: 2.53269
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 5.10034

Cumulative Model Updates: 220,998
Cumulative Timesteps: 1,843,740,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,336.97876
Policy Entropy: 1.95659
Value Function Loss: 0.02390

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.28551
Value Function Update Magnitude: 0.31402

Collected Steps per Second: 20,671.85172
Overall Steps per Second: 9,900.07003

Timestep Collection Time: 2.41913
Timestep Consumption Time: 2.63214
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 5.05128

Cumulative Model Updates: 221,004
Cumulative Timesteps: 1,843,790,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1843790548...
Checkpoint 1843790548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,546.23919
Policy Entropy: 1.95679
Value Function Loss: 0.02758

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.09663
Policy Update Magnitude: 0.29765
Value Function Update Magnitude: 0.31633

Collected Steps per Second: 20,507.30837
Overall Steps per Second: 10,057.67767

Timestep Collection Time: 2.43825
Timestep Consumption Time: 2.53327
PPO Batch Consumption Time: 0.29944
Total Iteration Time: 4.97153

Cumulative Model Updates: 221,010
Cumulative Timesteps: 1,843,840,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,392.69189
Policy Entropy: 1.97241
Value Function Loss: 0.02730

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.08735
Policy Update Magnitude: 0.30397
Value Function Update Magnitude: 0.31924

Collected Steps per Second: 20,782.19966
Overall Steps per Second: 10,206.69829

Timestep Collection Time: 2.40725
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.90149

Cumulative Model Updates: 221,016
Cumulative Timesteps: 1,843,890,578

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1843890578...
Checkpoint 1843890578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,140.04773
Policy Entropy: 1.97307
Value Function Loss: 0.02798

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07818
Policy Update Magnitude: 0.30227
Value Function Update Magnitude: 0.31411

Collected Steps per Second: 20,464.03855
Overall Steps per Second: 9,945.35204

Timestep Collection Time: 2.44546
Timestep Consumption Time: 2.58644
PPO Batch Consumption Time: 0.30267
Total Iteration Time: 5.03190

Cumulative Model Updates: 221,022
Cumulative Timesteps: 1,843,940,622

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,926.75837
Policy Entropy: 1.96715
Value Function Loss: 0.02749

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07428
Policy Update Magnitude: 0.30633
Value Function Update Magnitude: 0.32699

Collected Steps per Second: 20,793.32458
Overall Steps per Second: 9,896.89635

Timestep Collection Time: 2.40510
Timestep Consumption Time: 2.64800
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 5.05310

Cumulative Model Updates: 221,028
Cumulative Timesteps: 1,843,990,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1843990632...
Checkpoint 1843990632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,199.26659
Policy Entropy: 1.96094
Value Function Loss: 0.02698

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07277
Policy Update Magnitude: 0.30760
Value Function Update Magnitude: 0.33246

Collected Steps per Second: 20,344.98348
Overall Steps per Second: 9,917.01682

Timestep Collection Time: 2.45790
Timestep Consumption Time: 2.58454
PPO Batch Consumption Time: 0.30116
Total Iteration Time: 5.04244

Cumulative Model Updates: 221,034
Cumulative Timesteps: 1,844,040,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,442.45879
Policy Entropy: 1.95845
Value Function Loss: 0.02658

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07561
Policy Update Magnitude: 0.30670
Value Function Update Magnitude: 0.32682

Collected Steps per Second: 20,809.69793
Overall Steps per Second: 10,041.70253

Timestep Collection Time: 2.40282
Timestep Consumption Time: 2.57661
PPO Batch Consumption Time: 0.30123
Total Iteration Time: 4.97943

Cumulative Model Updates: 221,040
Cumulative Timesteps: 1,844,090,640

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1844090640...
Checkpoint 1844090640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,449.44781
Policy Entropy: 1.96319
Value Function Loss: 0.02547

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07103
Policy Update Magnitude: 0.29963
Value Function Update Magnitude: 0.31155

Collected Steps per Second: 20,674.85688
Overall Steps per Second: 10,129.82770

Timestep Collection Time: 2.41994
Timestep Consumption Time: 2.51913
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.93908

Cumulative Model Updates: 221,046
Cumulative Timesteps: 1,844,140,672

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,693.01976
Policy Entropy: 1.95915
Value Function Loss: 0.02410

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06874
Policy Update Magnitude: 0.29629
Value Function Update Magnitude: 0.29061

Collected Steps per Second: 20,998.75221
Overall Steps per Second: 10,017.16436

Timestep Collection Time: 2.38205
Timestep Consumption Time: 2.61138
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.99343

Cumulative Model Updates: 221,052
Cumulative Timesteps: 1,844,190,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1844190692...
Checkpoint 1844190692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,132.20257
Policy Entropy: 1.95039
Value Function Loss: 0.02676

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07273
Policy Update Magnitude: 0.29791
Value Function Update Magnitude: 0.27008

Collected Steps per Second: 19,967.09601
Overall Steps per Second: 9,747.11224

Timestep Collection Time: 2.50462
Timestep Consumption Time: 2.62613
PPO Batch Consumption Time: 0.30668
Total Iteration Time: 5.13075

Cumulative Model Updates: 221,058
Cumulative Timesteps: 1,844,240,702

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,707.16389
Policy Entropy: 1.94911
Value Function Loss: 0.03073

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.07473
Policy Update Magnitude: 0.31036
Value Function Update Magnitude: 0.31581

Collected Steps per Second: 21,326.38976
Overall Steps per Second: 10,157.70533

Timestep Collection Time: 2.34592
Timestep Consumption Time: 2.57941
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.92532

Cumulative Model Updates: 221,064
Cumulative Timesteps: 1,844,290,732

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1844290732...
Checkpoint 1844290732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,396.31307
Policy Entropy: 1.95969
Value Function Loss: 0.03068

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07490
Policy Update Magnitude: 0.30994
Value Function Update Magnitude: 0.35425

Collected Steps per Second: 20,461.99723
Overall Steps per Second: 9,998.42894

Timestep Collection Time: 2.44463
Timestep Consumption Time: 2.55836
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 5.00299

Cumulative Model Updates: 221,070
Cumulative Timesteps: 1,844,340,754

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,387.17678
Policy Entropy: 1.96088
Value Function Loss: 0.02871

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07872
Policy Update Magnitude: 0.30152
Value Function Update Magnitude: 0.35094

Collected Steps per Second: 20,824.32802
Overall Steps per Second: 10,047.32139

Timestep Collection Time: 2.40229
Timestep Consumption Time: 2.57675
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.97904

Cumulative Model Updates: 221,076
Cumulative Timesteps: 1,844,390,780

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1844390780...
Checkpoint 1844390780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,486.24389
Policy Entropy: 1.94617
Value Function Loss: 0.02418

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07712
Policy Update Magnitude: 0.29361
Value Function Update Magnitude: 0.31381

Collected Steps per Second: 20,745.08296
Overall Steps per Second: 10,054.54469

Timestep Collection Time: 2.41146
Timestep Consumption Time: 2.56400
PPO Batch Consumption Time: 0.29797
Total Iteration Time: 4.97546

Cumulative Model Updates: 221,082
Cumulative Timesteps: 1,844,440,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,889.02063
Policy Entropy: 1.94382
Value Function Loss: 0.02437

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07057
Policy Update Magnitude: 0.29040
Value Function Update Magnitude: 0.30492

Collected Steps per Second: 21,173.29888
Overall Steps per Second: 10,137.77212

Timestep Collection Time: 2.36146
Timestep Consumption Time: 2.57059
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.93205

Cumulative Model Updates: 221,088
Cumulative Timesteps: 1,844,490,806

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1844490806...
Checkpoint 1844490806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,004.55199
Policy Entropy: 1.94282
Value Function Loss: 0.02186

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06551
Policy Update Magnitude: 0.28921
Value Function Update Magnitude: 0.30156

Collected Steps per Second: 20,664.95346
Overall Steps per Second: 10,110.05988

Timestep Collection Time: 2.42072
Timestep Consumption Time: 2.52723
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.94794

Cumulative Model Updates: 221,094
Cumulative Timesteps: 1,844,540,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,717.20498
Policy Entropy: 1.94395
Value Function Loss: 0.02414

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06683
Policy Update Magnitude: 0.29107
Value Function Update Magnitude: 0.29432

Collected Steps per Second: 20,909.58842
Overall Steps per Second: 10,052.67089

Timestep Collection Time: 2.39173
Timestep Consumption Time: 2.58307
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.97480

Cumulative Model Updates: 221,100
Cumulative Timesteps: 1,844,590,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1844590840...
Checkpoint 1844590840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,409.27686
Policy Entropy: 1.94745
Value Function Loss: 0.02325

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07389
Policy Update Magnitude: 0.29319
Value Function Update Magnitude: 0.28000

Collected Steps per Second: 20,570.14408
Overall Steps per Second: 10,089.70765

Timestep Collection Time: 2.43129
Timestep Consumption Time: 2.52544
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.95673

Cumulative Model Updates: 221,106
Cumulative Timesteps: 1,844,640,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,286.36230
Policy Entropy: 1.93369
Value Function Loss: 0.02527

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.29614
Value Function Update Magnitude: 0.28250

Collected Steps per Second: 20,988.08913
Overall Steps per Second: 10,122.29539

Timestep Collection Time: 2.38335
Timestep Consumption Time: 2.55841
PPO Batch Consumption Time: 0.29605
Total Iteration Time: 4.94176

Cumulative Model Updates: 221,112
Cumulative Timesteps: 1,844,690,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1844690874...
Checkpoint 1844690874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,179.26030
Policy Entropy: 1.94208
Value Function Loss: 0.02357

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07434
Policy Update Magnitude: 0.29380
Value Function Update Magnitude: 0.27114

Collected Steps per Second: 20,459.98930
Overall Steps per Second: 10,101.08702

Timestep Collection Time: 2.44409
Timestep Consumption Time: 2.50647
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.95056

Cumulative Model Updates: 221,118
Cumulative Timesteps: 1,844,740,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,175.09871
Policy Entropy: 1.94078
Value Function Loss: 0.02365

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.28687
Value Function Update Magnitude: 0.27060

Collected Steps per Second: 20,538.36001
Overall Steps per Second: 10,192.54755

Timestep Collection Time: 2.43476
Timestep Consumption Time: 2.47137
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.90613

Cumulative Model Updates: 221,124
Cumulative Timesteps: 1,844,790,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1844790886...
Checkpoint 1844790886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,085.90915
Policy Entropy: 1.94178
Value Function Loss: 0.02613

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07484
Policy Update Magnitude: 0.29523
Value Function Update Magnitude: 0.26458

Collected Steps per Second: 19,525.98522
Overall Steps per Second: 9,923.16146

Timestep Collection Time: 2.56161
Timestep Consumption Time: 2.47892
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 5.04053

Cumulative Model Updates: 221,130
Cumulative Timesteps: 1,844,840,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,949.93212
Policy Entropy: 1.94248
Value Function Loss: 0.02763

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.30262
Value Function Update Magnitude: 0.29735

Collected Steps per Second: 20,402.50695
Overall Steps per Second: 10,254.98438

Timestep Collection Time: 2.45166
Timestep Consumption Time: 2.42597
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.87763

Cumulative Model Updates: 221,136
Cumulative Timesteps: 1,844,890,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1844890924...
Checkpoint 1844890924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,524.43897
Policy Entropy: 1.93634
Value Function Loss: 0.02726

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07874
Policy Update Magnitude: 0.29714
Value Function Update Magnitude: 0.32592

Collected Steps per Second: 19,344.57731
Overall Steps per Second: 9,837.79519

Timestep Collection Time: 2.58532
Timestep Consumption Time: 2.49834
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 5.08366

Cumulative Model Updates: 221,142
Cumulative Timesteps: 1,844,940,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,102.63494
Policy Entropy: 1.92457
Value Function Loss: 0.02410

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07332
Policy Update Magnitude: 0.29409
Value Function Update Magnitude: 0.30105

Collected Steps per Second: 20,234.44501
Overall Steps per Second: 9,950.94404

Timestep Collection Time: 2.47242
Timestep Consumption Time: 2.55504
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 5.02746

Cumulative Model Updates: 221,148
Cumulative Timesteps: 1,844,990,964

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1844990964...
Checkpoint 1844990964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,143.32265
Policy Entropy: 1.91500
Value Function Loss: 0.02314

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07125
Policy Update Magnitude: 0.29012
Value Function Update Magnitude: 0.28968

Collected Steps per Second: 20,373.07797
Overall Steps per Second: 10,025.91119

Timestep Collection Time: 2.45530
Timestep Consumption Time: 2.53397
PPO Batch Consumption Time: 0.29757
Total Iteration Time: 4.98927

Cumulative Model Updates: 221,154
Cumulative Timesteps: 1,845,040,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,444.44060
Policy Entropy: 1.91304
Value Function Loss: 0.02396

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.06994
Policy Update Magnitude: 0.29709
Value Function Update Magnitude: 0.27644

Collected Steps per Second: 21,094.72373
Overall Steps per Second: 10,292.69433

Timestep Collection Time: 2.37159
Timestep Consumption Time: 2.48895
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.86053

Cumulative Model Updates: 221,160
Cumulative Timesteps: 1,845,091,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1845091014...
Checkpoint 1845091014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,917.42378
Policy Entropy: 1.91333
Value Function Loss: 0.02500

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07213
Policy Update Magnitude: 0.29989
Value Function Update Magnitude: 0.28679

Collected Steps per Second: 20,179.22907
Overall Steps per Second: 9,912.88287

Timestep Collection Time: 2.47819
Timestep Consumption Time: 2.56656
PPO Batch Consumption Time: 0.29910
Total Iteration Time: 5.04475

Cumulative Model Updates: 221,166
Cumulative Timesteps: 1,845,141,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,794.38822
Policy Entropy: 1.93566
Value Function Loss: 0.02863

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07669
Policy Update Magnitude: 0.30276
Value Function Update Magnitude: 0.29407

Collected Steps per Second: 20,944.24057
Overall Steps per Second: 10,067.31625

Timestep Collection Time: 2.38891
Timestep Consumption Time: 2.58103
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.96994

Cumulative Model Updates: 221,172
Cumulative Timesteps: 1,845,191,056

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1845191056...
Checkpoint 1845191056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,868.72182
Policy Entropy: 1.94507
Value Function Loss: 0.02918

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08421
Policy Update Magnitude: 0.30826
Value Function Update Magnitude: 0.32000

Collected Steps per Second: 20,803.30871
Overall Steps per Second: 10,087.59191

Timestep Collection Time: 2.40539
Timestep Consumption Time: 2.55516
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.96055

Cumulative Model Updates: 221,178
Cumulative Timesteps: 1,845,241,096

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,144.70191
Policy Entropy: 1.95109
Value Function Loss: 0.02573

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.30299
Value Function Update Magnitude: 0.35472

Collected Steps per Second: 21,149.60038
Overall Steps per Second: 10,149.89055

Timestep Collection Time: 2.36534
Timestep Consumption Time: 2.56338
PPO Batch Consumption Time: 0.29768
Total Iteration Time: 4.92872

Cumulative Model Updates: 221,184
Cumulative Timesteps: 1,845,291,122

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1845291122...
Checkpoint 1845291122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,209.88121
Policy Entropy: 1.93788
Value Function Loss: 0.02342

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.29090
Value Function Update Magnitude: 0.33856

Collected Steps per Second: 20,558.17163
Overall Steps per Second: 10,082.49599

Timestep Collection Time: 2.43212
Timestep Consumption Time: 2.52697
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.95909

Cumulative Model Updates: 221,190
Cumulative Timesteps: 1,845,341,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,056.65894
Policy Entropy: 1.92991
Value Function Loss: 0.02568

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08235
Policy Update Magnitude: 0.28776
Value Function Update Magnitude: 0.30955

Collected Steps per Second: 20,912.63117
Overall Steps per Second: 10,006.73259

Timestep Collection Time: 2.39109
Timestep Consumption Time: 2.60594
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.99704

Cumulative Model Updates: 221,196
Cumulative Timesteps: 1,845,391,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1845391126...
Checkpoint 1845391126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,486.54261
Policy Entropy: 1.94198
Value Function Loss: 0.03071

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.29715
Value Function Update Magnitude: 0.32247

Collected Steps per Second: 20,493.22044
Overall Steps per Second: 10,134.39480

Timestep Collection Time: 2.44081
Timestep Consumption Time: 2.49486
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.93567

Cumulative Model Updates: 221,202
Cumulative Timesteps: 1,845,441,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,318.55115
Policy Entropy: 1.95899
Value Function Loss: 0.03207

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.10280
Policy Update Magnitude: 0.30703
Value Function Update Magnitude: 0.32719

Collected Steps per Second: 20,977.83120
Overall Steps per Second: 9,990.19798

Timestep Collection Time: 2.38395
Timestep Consumption Time: 2.62196
PPO Batch Consumption Time: 0.30691
Total Iteration Time: 5.00591

Cumulative Model Updates: 221,208
Cumulative Timesteps: 1,845,491,156

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1845491156...
Checkpoint 1845491156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,860.43966
Policy Entropy: 1.94400
Value Function Loss: 0.03103

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.10058
Policy Update Magnitude: 0.31324
Value Function Update Magnitude: 0.32800

Collected Steps per Second: 20,763.57881
Overall Steps per Second: 9,957.85991

Timestep Collection Time: 2.40970
Timestep Consumption Time: 2.61487
PPO Batch Consumption Time: 0.30412
Total Iteration Time: 5.02457

Cumulative Model Updates: 221,214
Cumulative Timesteps: 1,845,541,190

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,498.45401
Policy Entropy: 1.94060
Value Function Loss: 0.02759

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.08976
Policy Update Magnitude: 0.30657
Value Function Update Magnitude: 0.29002

Collected Steps per Second: 19,954.81169
Overall Steps per Second: 10,030.43677

Timestep Collection Time: 2.50706
Timestep Consumption Time: 2.48055
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.98762

Cumulative Model Updates: 221,220
Cumulative Timesteps: 1,845,591,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1845591218...
Checkpoint 1845591218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,461.97374
Policy Entropy: 1.90684
Value Function Loss: 0.02565

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07764
Policy Update Magnitude: 0.29784
Value Function Update Magnitude: 0.24185

Collected Steps per Second: 19,698.17768
Overall Steps per Second: 10,088.60040

Timestep Collection Time: 2.53841
Timestep Consumption Time: 2.41788
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.95629

Cumulative Model Updates: 221,226
Cumulative Timesteps: 1,845,641,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,783.66350
Policy Entropy: 1.91519
Value Function Loss: 0.02531

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07543
Policy Update Magnitude: 0.29566
Value Function Update Magnitude: 0.22668

Collected Steps per Second: 20,607.66117
Overall Steps per Second: 10,171.17039

Timestep Collection Time: 2.42793
Timestep Consumption Time: 2.49127
PPO Batch Consumption Time: 0.30009
Total Iteration Time: 4.91920

Cumulative Model Updates: 221,232
Cumulative Timesteps: 1,845,691,254

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1845691254...
Checkpoint 1845691254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,583.22904
Policy Entropy: 1.91865
Value Function Loss: 0.03043

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.07608
Policy Update Magnitude: 0.30930
Value Function Update Magnitude: 0.24540

Collected Steps per Second: 19,741.48083
Overall Steps per Second: 9,802.16835

Timestep Collection Time: 2.53416
Timestep Consumption Time: 2.56961
PPO Batch Consumption Time: 0.30027
Total Iteration Time: 5.10377

Cumulative Model Updates: 221,238
Cumulative Timesteps: 1,845,741,282

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,327.39490
Policy Entropy: 1.94260
Value Function Loss: 0.03535

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.32512
Value Function Update Magnitude: 0.35189

Collected Steps per Second: 20,392.09346
Overall Steps per Second: 10,041.35734

Timestep Collection Time: 2.45193
Timestep Consumption Time: 2.52748
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.97941

Cumulative Model Updates: 221,244
Cumulative Timesteps: 1,845,791,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1845791282...
Checkpoint 1845791282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,755.70682
Policy Entropy: 1.95634
Value Function Loss: 0.03636

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.08708
Policy Update Magnitude: 0.33011
Value Function Update Magnitude: 0.35955

Collected Steps per Second: 20,540.49672
Overall Steps per Second: 10,153.86473

Timestep Collection Time: 2.43490
Timestep Consumption Time: 2.49071
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.92561

Cumulative Model Updates: 221,250
Cumulative Timesteps: 1,845,841,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,998.85639
Policy Entropy: 1.94986
Value Function Loss: 0.03420

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.32375
Value Function Update Magnitude: 0.29204

Collected Steps per Second: 21,099.54975
Overall Steps per Second: 10,197.02296

Timestep Collection Time: 2.37152
Timestep Consumption Time: 2.53560
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.90712

Cumulative Model Updates: 221,256
Cumulative Timesteps: 1,845,891,334

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1845891334...
Checkpoint 1845891334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,136.07258
Policy Entropy: 1.94766
Value Function Loss: 0.02896

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.31174
Value Function Update Magnitude: 0.27284

Collected Steps per Second: 20,549.72823
Overall Steps per Second: 10,072.55972

Timestep Collection Time: 2.43429
Timestep Consumption Time: 2.53207
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.96636

Cumulative Model Updates: 221,262
Cumulative Timesteps: 1,845,941,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,215.63512
Policy Entropy: 1.92068
Value Function Loss: 0.02600

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07815
Policy Update Magnitude: 0.30436
Value Function Update Magnitude: 0.23408

Collected Steps per Second: 20,668.73971
Overall Steps per Second: 10,030.39464

Timestep Collection Time: 2.42124
Timestep Consumption Time: 2.56799
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.98924

Cumulative Model Updates: 221,268
Cumulative Timesteps: 1,845,991,402

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1845991402...
Checkpoint 1845991402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,101.23600
Policy Entropy: 1.92320
Value Function Loss: 0.02654

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08065
Policy Update Magnitude: 0.30586
Value Function Update Magnitude: 0.20112

Collected Steps per Second: 20,554.31570
Overall Steps per Second: 10,133.15951

Timestep Collection Time: 2.43384
Timestep Consumption Time: 2.50302
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.93686

Cumulative Model Updates: 221,274
Cumulative Timesteps: 1,846,041,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,297.64426
Policy Entropy: 1.92509
Value Function Loss: 0.02505

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07619
Policy Update Magnitude: 0.30493
Value Function Update Magnitude: 0.27147

Collected Steps per Second: 20,919.42946
Overall Steps per Second: 10,127.57419

Timestep Collection Time: 2.39117
Timestep Consumption Time: 2.54801
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.93919

Cumulative Model Updates: 221,280
Cumulative Timesteps: 1,846,091,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1846091450...
Checkpoint 1846091450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,181.89571
Policy Entropy: 1.93596
Value Function Loss: 0.02267

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.06701
Policy Update Magnitude: 0.29745
Value Function Update Magnitude: 0.30898

Collected Steps per Second: 20,155.69050
Overall Steps per Second: 9,896.94187

Timestep Collection Time: 2.48208
Timestep Consumption Time: 2.57282
PPO Batch Consumption Time: 0.29962
Total Iteration Time: 5.05489

Cumulative Model Updates: 221,286
Cumulative Timesteps: 1,846,141,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,560.95840
Policy Entropy: 1.93971
Value Function Loss: 0.02120

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06491
Policy Update Magnitude: 0.28747
Value Function Update Magnitude: 0.29946

Collected Steps per Second: 20,256.34027
Overall Steps per Second: 9,982.22902

Timestep Collection Time: 2.46905
Timestep Consumption Time: 2.54125
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 5.01030

Cumulative Model Updates: 221,292
Cumulative Timesteps: 1,846,191,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1846191492...
Checkpoint 1846191492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,936.05973
Policy Entropy: 1.92333
Value Function Loss: 0.02048

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06324
Policy Update Magnitude: 0.28293
Value Function Update Magnitude: 0.27218

Collected Steps per Second: 19,742.61948
Overall Steps per Second: 9,785.57872

Timestep Collection Time: 2.53279
Timestep Consumption Time: 2.57717
PPO Batch Consumption Time: 0.30057
Total Iteration Time: 5.10997

Cumulative Model Updates: 221,298
Cumulative Timesteps: 1,846,241,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,555.18895
Policy Entropy: 1.90427
Value Function Loss: 0.01893

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06426
Policy Update Magnitude: 0.28139
Value Function Update Magnitude: 0.25865

Collected Steps per Second: 21,147.47638
Overall Steps per Second: 10,188.33571

Timestep Collection Time: 2.36510
Timestep Consumption Time: 2.54404
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.90914

Cumulative Model Updates: 221,304
Cumulative Timesteps: 1,846,291,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1846291512...
Checkpoint 1846291512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,729.25220
Policy Entropy: 1.89929
Value Function Loss: 0.02115

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06388
Policy Update Magnitude: 0.27958
Value Function Update Magnitude: 0.27273

Collected Steps per Second: 19,799.70201
Overall Steps per Second: 10,028.24258

Timestep Collection Time: 2.52590
Timestep Consumption Time: 2.46122
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.98712

Cumulative Model Updates: 221,310
Cumulative Timesteps: 1,846,341,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,435.54591
Policy Entropy: 1.91515
Value Function Loss: 0.02105

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06638
Policy Update Magnitude: 0.28210
Value Function Update Magnitude: 0.29801

Collected Steps per Second: 18,877.03744
Overall Steps per Second: 9,693.73150

Timestep Collection Time: 2.64957
Timestep Consumption Time: 2.51005
PPO Batch Consumption Time: 0.30150
Total Iteration Time: 5.15962

Cumulative Model Updates: 221,316
Cumulative Timesteps: 1,846,391,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1846391540...
Checkpoint 1846391540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,835.09385
Policy Entropy: 1.92869
Value Function Loss: 0.02704

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07230
Policy Update Magnitude: 0.29900
Value Function Update Magnitude: 0.32001

Collected Steps per Second: 20,066.65288
Overall Steps per Second: 10,182.07660

Timestep Collection Time: 2.49190
Timestep Consumption Time: 2.41909
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.91098

Cumulative Model Updates: 221,322
Cumulative Timesteps: 1,846,441,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,675.96208
Policy Entropy: 1.93246
Value Function Loss: 0.02537

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07299
Policy Update Magnitude: 0.30163
Value Function Update Magnitude: 0.33250

Collected Steps per Second: 20,388.04645
Overall Steps per Second: 10,023.70477

Timestep Collection Time: 2.45261
Timestep Consumption Time: 2.53596
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.98857

Cumulative Model Updates: 221,328
Cumulative Timesteps: 1,846,491,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1846491548...
Checkpoint 1846491548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,790.33356
Policy Entropy: 1.92485
Value Function Loss: 0.02783

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07681
Policy Update Magnitude: 0.29826
Value Function Update Magnitude: 0.32714

Collected Steps per Second: 20,487.68756
Overall Steps per Second: 10,166.00230

Timestep Collection Time: 2.44166
Timestep Consumption Time: 2.47905
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.92071

Cumulative Model Updates: 221,334
Cumulative Timesteps: 1,846,541,572

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,629.55417
Policy Entropy: 1.92322
Value Function Loss: 0.02774

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07610
Policy Update Magnitude: 0.30275
Value Function Update Magnitude: 0.32290

Collected Steps per Second: 19,791.97452
Overall Steps per Second: 9,990.62385

Timestep Collection Time: 2.52688
Timestep Consumption Time: 2.47901
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 5.00589

Cumulative Model Updates: 221,340
Cumulative Timesteps: 1,846,591,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1846591584...
Checkpoint 1846591584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,750.54552
Policy Entropy: 1.92981
Value Function Loss: 0.02639

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07778
Policy Update Magnitude: 0.30844
Value Function Update Magnitude: 0.30583

Collected Steps per Second: 20,625.01430
Overall Steps per Second: 10,035.65873

Timestep Collection Time: 2.42502
Timestep Consumption Time: 2.55881
PPO Batch Consumption Time: 0.29733
Total Iteration Time: 4.98383

Cumulative Model Updates: 221,346
Cumulative Timesteps: 1,846,641,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,070.74488
Policy Entropy: 1.92910
Value Function Loss: 0.02704

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07656
Policy Update Magnitude: 0.30953
Value Function Update Magnitude: 0.29414

Collected Steps per Second: 21,083.09323
Overall Steps per Second: 10,239.18681

Timestep Collection Time: 2.37261
Timestep Consumption Time: 2.51274
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.88535

Cumulative Model Updates: 221,352
Cumulative Timesteps: 1,846,691,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1846691622...
Checkpoint 1846691622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,928.28569
Policy Entropy: 1.93884
Value Function Loss: 0.02498

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.30952
Value Function Update Magnitude: 0.32063

Collected Steps per Second: 20,415.88019
Overall Steps per Second: 9,863.50003

Timestep Collection Time: 2.44996
Timestep Consumption Time: 2.62106
PPO Batch Consumption Time: 0.30856
Total Iteration Time: 5.07102

Cumulative Model Updates: 221,358
Cumulative Timesteps: 1,846,741,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,754.06600
Policy Entropy: 1.92594
Value Function Loss: 0.02771

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.31106
Value Function Update Magnitude: 0.31348

Collected Steps per Second: 20,108.19250
Overall Steps per Second: 9,940.86580

Timestep Collection Time: 2.48734
Timestep Consumption Time: 2.54401
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 5.03135

Cumulative Model Updates: 221,364
Cumulative Timesteps: 1,846,791,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1846791656...
Checkpoint 1846791656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,622.56231
Policy Entropy: 1.92422
Value Function Loss: 0.02615

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.08898
Policy Update Magnitude: 0.31078
Value Function Update Magnitude: 0.30061

Collected Steps per Second: 20,569.73831
Overall Steps per Second: 10,041.30714

Timestep Collection Time: 2.43114
Timestep Consumption Time: 2.54908
PPO Batch Consumption Time: 0.29767
Total Iteration Time: 4.98023

Cumulative Model Updates: 221,370
Cumulative Timesteps: 1,846,841,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,193.36257
Policy Entropy: 1.91825
Value Function Loss: 0.02734

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.30400
Value Function Update Magnitude: 0.28810

Collected Steps per Second: 21,032.65331
Overall Steps per Second: 10,204.29297

Timestep Collection Time: 2.37764
Timestep Consumption Time: 2.52305
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.90068

Cumulative Model Updates: 221,376
Cumulative Timesteps: 1,846,891,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1846891672...
Checkpoint 1846891672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,303.80528
Policy Entropy: 1.92417
Value Function Loss: 0.02559

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07485
Policy Update Magnitude: 0.30274
Value Function Update Magnitude: 0.26849

Collected Steps per Second: 20,587.85539
Overall Steps per Second: 10,043.94709

Timestep Collection Time: 2.42939
Timestep Consumption Time: 2.55032
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.97972

Cumulative Model Updates: 221,382
Cumulative Timesteps: 1,846,941,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,091.55636
Policy Entropy: 1.92064
Value Function Loss: 0.02525

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.30179
Value Function Update Magnitude: 0.26167

Collected Steps per Second: 19,991.61699
Overall Steps per Second: 9,917.06782

Timestep Collection Time: 2.50125
Timestep Consumption Time: 2.54097
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 5.04222

Cumulative Model Updates: 221,388
Cumulative Timesteps: 1,846,991,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1846991692...
Checkpoint 1846991692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,803.36144
Policy Entropy: 1.92253
Value Function Loss: 0.02736

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07086
Policy Update Magnitude: 0.30402
Value Function Update Magnitude: 0.22262

Collected Steps per Second: 20,634.45336
Overall Steps per Second: 10,150.34458

Timestep Collection Time: 2.42507
Timestep Consumption Time: 2.50481
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.92988

Cumulative Model Updates: 221,394
Cumulative Timesteps: 1,847,041,732

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,580.34803
Policy Entropy: 1.92296
Value Function Loss: 0.02843

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07333
Policy Update Magnitude: 0.30537
Value Function Update Magnitude: 0.27035

Collected Steps per Second: 20,772.91977
Overall Steps per Second: 10,064.84527

Timestep Collection Time: 2.40737
Timestep Consumption Time: 2.56122
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.96858

Cumulative Model Updates: 221,400
Cumulative Timesteps: 1,847,091,740

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1847091740...
Checkpoint 1847091740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,129.41730
Policy Entropy: 1.93077
Value Function Loss: 0.02938

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07579
Policy Update Magnitude: 0.30948
Value Function Update Magnitude: 0.30610

Collected Steps per Second: 20,568.27146
Overall Steps per Second: 10,132.37660

Timestep Collection Time: 2.43268
Timestep Consumption Time: 2.50555
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.93823

Cumulative Model Updates: 221,406
Cumulative Timesteps: 1,847,141,776

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,688.78223
Policy Entropy: 1.91934
Value Function Loss: 0.02873

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07789
Policy Update Magnitude: 0.30669
Value Function Update Magnitude: 0.30271

Collected Steps per Second: 19,442.99195
Overall Steps per Second: 9,745.92458

Timestep Collection Time: 2.57183
Timestep Consumption Time: 2.55893
PPO Batch Consumption Time: 0.30017
Total Iteration Time: 5.13076

Cumulative Model Updates: 221,412
Cumulative Timesteps: 1,847,191,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1847191780...
Checkpoint 1847191780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,443.91945
Policy Entropy: 1.90479
Value Function Loss: 0.02798

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08408
Policy Update Magnitude: 0.30237
Value Function Update Magnitude: 0.32075

Collected Steps per Second: 20,128.51356
Overall Steps per Second: 10,150.17259

Timestep Collection Time: 2.48473
Timestep Consumption Time: 2.44267
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.92740

Cumulative Model Updates: 221,418
Cumulative Timesteps: 1,847,241,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,362.84903
Policy Entropy: 1.91303
Value Function Loss: 0.02825

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07364
Policy Update Magnitude: 0.30377
Value Function Update Magnitude: 0.33645

Collected Steps per Second: 20,298.72402
Overall Steps per Second: 10,061.00685

Timestep Collection Time: 2.46350
Timestep Consumption Time: 2.50677
PPO Batch Consumption Time: 0.30058
Total Iteration Time: 4.97028

Cumulative Model Updates: 221,424
Cumulative Timesteps: 1,847,291,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1847291800...
Checkpoint 1847291800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,965.98923
Policy Entropy: 1.90723
Value Function Loss: 0.02789

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.30646
Value Function Update Magnitude: 0.34761

Collected Steps per Second: 19,819.68547
Overall Steps per Second: 10,104.12586

Timestep Collection Time: 2.52406
Timestep Consumption Time: 2.42699
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.95105

Cumulative Model Updates: 221,430
Cumulative Timesteps: 1,847,341,826

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,187.84623
Policy Entropy: 1.90987
Value Function Loss: 0.02727

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08057
Policy Update Magnitude: 0.30825
Value Function Update Magnitude: 0.34933

Collected Steps per Second: 19,430.58053
Overall Steps per Second: 10,037.71506

Timestep Collection Time: 2.57491
Timestep Consumption Time: 2.40949
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.98440

Cumulative Model Updates: 221,436
Cumulative Timesteps: 1,847,391,858

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1847391858...
Checkpoint 1847391858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,003.72150
Policy Entropy: 1.90796
Value Function Loss: 0.02683

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08122
Policy Update Magnitude: 0.30553
Value Function Update Magnitude: 0.33622

Collected Steps per Second: 20,081.45345
Overall Steps per Second: 9,923.52244

Timestep Collection Time: 2.49016
Timestep Consumption Time: 2.54898
PPO Batch Consumption Time: 0.30069
Total Iteration Time: 5.03914

Cumulative Model Updates: 221,442
Cumulative Timesteps: 1,847,441,864

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,198.64700
Policy Entropy: 1.91480
Value Function Loss: 0.02493

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.07402
Policy Update Magnitude: 0.29998
Value Function Update Magnitude: 0.34110

Collected Steps per Second: 20,876.58266
Overall Steps per Second: 10,118.52549

Timestep Collection Time: 2.39512
Timestep Consumption Time: 2.54651
PPO Batch Consumption Time: 0.29891
Total Iteration Time: 4.94163

Cumulative Model Updates: 221,448
Cumulative Timesteps: 1,847,491,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1847491866...
Checkpoint 1847491866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,503.14152
Policy Entropy: 1.93391
Value Function Loss: 0.02491

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07356
Policy Update Magnitude: 0.29550
Value Function Update Magnitude: 0.34497

Collected Steps per Second: 20,722.80422
Overall Steps per Second: 10,063.87509

Timestep Collection Time: 2.41386
Timestep Consumption Time: 2.55659
PPO Batch Consumption Time: 0.29707
Total Iteration Time: 4.97045

Cumulative Model Updates: 221,454
Cumulative Timesteps: 1,847,541,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,422.51720
Policy Entropy: 1.93412
Value Function Loss: 0.02390

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07049
Policy Update Magnitude: 0.29474
Value Function Update Magnitude: 0.33193

Collected Steps per Second: 19,794.27175
Overall Steps per Second: 9,833.79877

Timestep Collection Time: 2.52699
Timestep Consumption Time: 2.55955
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 5.08654

Cumulative Model Updates: 221,460
Cumulative Timesteps: 1,847,591,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1847591908...
Checkpoint 1847591908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,114.63691
Policy Entropy: 1.94612
Value Function Loss: 0.02396

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07103
Policy Update Magnitude: 0.29430
Value Function Update Magnitude: 0.30157

Collected Steps per Second: 20,831.91641
Overall Steps per Second: 10,057.42836

Timestep Collection Time: 2.40103
Timestep Consumption Time: 2.57221
PPO Batch Consumption Time: 0.30103
Total Iteration Time: 4.97324

Cumulative Model Updates: 221,466
Cumulative Timesteps: 1,847,641,926

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,972.70298
Policy Entropy: 1.94728
Value Function Loss: 0.02408

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07470
Policy Update Magnitude: 0.29956
Value Function Update Magnitude: 0.28897

Collected Steps per Second: 20,723.62176
Overall Steps per Second: 10,017.24190

Timestep Collection Time: 2.41290
Timestep Consumption Time: 2.57889
PPO Batch Consumption Time: 0.29899
Total Iteration Time: 4.99179

Cumulative Model Updates: 221,472
Cumulative Timesteps: 1,847,691,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1847691930...
Checkpoint 1847691930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,427.83262
Policy Entropy: 1.93384
Value Function Loss: 0.02774

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08036
Policy Update Magnitude: 0.30900
Value Function Update Magnitude: 0.32366

Collected Steps per Second: 20,759.40693
Overall Steps per Second: 10,155.22187

Timestep Collection Time: 2.40912
Timestep Consumption Time: 2.51563
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.92476

Cumulative Model Updates: 221,478
Cumulative Timesteps: 1,847,741,942

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,536.00931
Policy Entropy: 1.93456
Value Function Loss: 0.02947

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.31469
Value Function Update Magnitude: 0.33334

Collected Steps per Second: 20,087.92858
Overall Steps per Second: 10,041.84228

Timestep Collection Time: 2.48916
Timestep Consumption Time: 2.49021
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.97937

Cumulative Model Updates: 221,484
Cumulative Timesteps: 1,847,791,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1847791944...
Checkpoint 1847791944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,790.88253
Policy Entropy: 1.92579
Value Function Loss: 0.03392

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.32741
Value Function Update Magnitude: 0.33634

Collected Steps per Second: 20,504.65678
Overall Steps per Second: 10,003.86917

Timestep Collection Time: 2.43906
Timestep Consumption Time: 2.56021
PPO Batch Consumption Time: 0.29830
Total Iteration Time: 4.99927

Cumulative Model Updates: 221,490
Cumulative Timesteps: 1,847,841,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,007.55023
Policy Entropy: 1.93430
Value Function Loss: 0.03539

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.32748
Value Function Update Magnitude: 0.31754

Collected Steps per Second: 20,832.69635
Overall Steps per Second: 10,200.11557

Timestep Collection Time: 2.40065
Timestep Consumption Time: 2.50243
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.90308

Cumulative Model Updates: 221,496
Cumulative Timesteps: 1,847,891,968

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1847891968...
Checkpoint 1847891968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,944.63623
Policy Entropy: 1.94306
Value Function Loss: 0.03299

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.32073
Value Function Update Magnitude: 0.33929

Collected Steps per Second: 20,684.87217
Overall Steps per Second: 10,070.68325

Timestep Collection Time: 2.41790
Timestep Consumption Time: 2.54839
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.96630

Cumulative Model Updates: 221,502
Cumulative Timesteps: 1,847,941,982

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,941.51254
Policy Entropy: 1.93395
Value Function Loss: 0.03035

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.31361
Value Function Update Magnitude: 0.34628

Collected Steps per Second: 20,035.83796
Overall Steps per Second: 9,764.94061

Timestep Collection Time: 2.49663
Timestep Consumption Time: 2.62599
PPO Batch Consumption Time: 0.31283
Total Iteration Time: 5.12261

Cumulative Model Updates: 221,508
Cumulative Timesteps: 1,847,992,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1847992004...
Checkpoint 1847992004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,511.34990
Policy Entropy: 1.93357
Value Function Loss: 0.02784

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07167
Policy Update Magnitude: 0.31289
Value Function Update Magnitude: 0.33332

Collected Steps per Second: 20,427.03665
Overall Steps per Second: 9,893.47521

Timestep Collection Time: 2.44832
Timestep Consumption Time: 2.60672
PPO Batch Consumption Time: 0.30256
Total Iteration Time: 5.05505

Cumulative Model Updates: 221,514
Cumulative Timesteps: 1,848,042,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,045.67709
Policy Entropy: 1.92484
Value Function Loss: 0.02845

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07464
Policy Update Magnitude: 0.31678
Value Function Update Magnitude: 0.32015

Collected Steps per Second: 20,969.87232
Overall Steps per Second: 10,060.26120

Timestep Collection Time: 2.38523
Timestep Consumption Time: 2.58661
PPO Batch Consumption Time: 0.30069
Total Iteration Time: 4.97184

Cumulative Model Updates: 221,520
Cumulative Timesteps: 1,848,092,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1848092034...
Checkpoint 1848092034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,981.99846
Policy Entropy: 1.92287
Value Function Loss: 0.02693

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07580
Policy Update Magnitude: 0.31778
Value Function Update Magnitude: 0.32808

Collected Steps per Second: 20,698.64013
Overall Steps per Second: 10,129.97325

Timestep Collection Time: 2.41707
Timestep Consumption Time: 2.52174
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.93881

Cumulative Model Updates: 221,526
Cumulative Timesteps: 1,848,142,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,343.97287
Policy Entropy: 1.92358
Value Function Loss: 0.02811

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07655
Policy Update Magnitude: 0.31356
Value Function Update Magnitude: 0.31410

Collected Steps per Second: 19,310.20042
Overall Steps per Second: 9,994.81636

Timestep Collection Time: 2.59034
Timestep Consumption Time: 2.41425
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 5.00459

Cumulative Model Updates: 221,532
Cumulative Timesteps: 1,848,192,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1848192084...
Checkpoint 1848192084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,628.17005
Policy Entropy: 1.91555
Value Function Loss: 0.02855

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07454
Policy Update Magnitude: 0.30961
Value Function Update Magnitude: 0.32193

Collected Steps per Second: 20,044.06730
Overall Steps per Second: 10,060.26669

Timestep Collection Time: 2.49600
Timestep Consumption Time: 2.47703
PPO Batch Consumption Time: 0.29733
Total Iteration Time: 4.97303

Cumulative Model Updates: 221,538
Cumulative Timesteps: 1,848,242,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,821.39008
Policy Entropy: 1.91333
Value Function Loss: 0.02814

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07599
Policy Update Magnitude: 0.30587
Value Function Update Magnitude: 0.35654

Collected Steps per Second: 20,439.58550
Overall Steps per Second: 10,242.25041

Timestep Collection Time: 2.44770
Timestep Consumption Time: 2.43697
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.88467

Cumulative Model Updates: 221,544
Cumulative Timesteps: 1,848,292,144

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1848292144...
Checkpoint 1848292144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,904.27755
Policy Entropy: 1.91465
Value Function Loss: 0.02593

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07461
Policy Update Magnitude: 0.30925
Value Function Update Magnitude: 0.35784

Collected Steps per Second: 19,993.73602
Overall Steps per Second: 9,889.47029

Timestep Collection Time: 2.50128
Timestep Consumption Time: 2.55561
PPO Batch Consumption Time: 0.30068
Total Iteration Time: 5.05689

Cumulative Model Updates: 221,550
Cumulative Timesteps: 1,848,342,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,008.53718
Policy Entropy: 1.92009
Value Function Loss: 0.02570

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07432
Policy Update Magnitude: 0.30622
Value Function Update Magnitude: 0.35734

Collected Steps per Second: 19,552.87538
Overall Steps per Second: 9,973.39623

Timestep Collection Time: 2.55758
Timestep Consumption Time: 2.45656
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 5.01414

Cumulative Model Updates: 221,556
Cumulative Timesteps: 1,848,392,162

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1848392162...
Checkpoint 1848392162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,282.81035
Policy Entropy: 1.91111
Value Function Loss: 0.02541

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07753
Policy Update Magnitude: 0.30588
Value Function Update Magnitude: 0.35119

Collected Steps per Second: 20,546.73239
Overall Steps per Second: 10,150.04911

Timestep Collection Time: 2.43406
Timestep Consumption Time: 2.49321
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.92727

Cumulative Model Updates: 221,562
Cumulative Timesteps: 1,848,442,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,627.57782
Policy Entropy: 1.89930
Value Function Loss: 0.02377

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.30182
Value Function Update Magnitude: 0.33641

Collected Steps per Second: 21,127.21328
Overall Steps per Second: 10,108.91946

Timestep Collection Time: 2.36756
Timestep Consumption Time: 2.58054
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.94811

Cumulative Model Updates: 221,568
Cumulative Timesteps: 1,848,492,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1848492194...
Checkpoint 1848492194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,117.34992
Policy Entropy: 1.88955
Value Function Loss: 0.02395

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07345
Policy Update Magnitude: 0.29990
Value Function Update Magnitude: 0.32439

Collected Steps per Second: 20,575.63131
Overall Steps per Second: 10,112.09391

Timestep Collection Time: 2.43025
Timestep Consumption Time: 2.51472
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.94497

Cumulative Model Updates: 221,574
Cumulative Timesteps: 1,848,542,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,871.31809
Policy Entropy: 1.89684
Value Function Loss: 0.02654

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07095
Policy Update Magnitude: 0.30930
Value Function Update Magnitude: 0.33154

Collected Steps per Second: 20,078.99118
Overall Steps per Second: 10,003.20680

Timestep Collection Time: 2.49096
Timestep Consumption Time: 2.50903
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 5.00000

Cumulative Model Updates: 221,580
Cumulative Timesteps: 1,848,592,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1848592214...
Checkpoint 1848592214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,043.90365
Policy Entropy: 1.90270
Value Function Loss: 0.02699

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07600
Policy Update Magnitude: 0.31241
Value Function Update Magnitude: 0.34960

Collected Steps per Second: 19,953.59847
Overall Steps per Second: 9,975.12718

Timestep Collection Time: 2.50742
Timestep Consumption Time: 2.50826
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 5.01568

Cumulative Model Updates: 221,586
Cumulative Timesteps: 1,848,642,246

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,254.95038
Policy Entropy: 1.92430
Value Function Loss: 0.02575

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07710
Policy Update Magnitude: 0.31393
Value Function Update Magnitude: 0.36063

Collected Steps per Second: 20,473.26872
Overall Steps per Second: 10,020.63740

Timestep Collection Time: 2.44426
Timestep Consumption Time: 2.54963
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.99389

Cumulative Model Updates: 221,592
Cumulative Timesteps: 1,848,692,288

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1848692288...
Checkpoint 1848692288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,352.68209
Policy Entropy: 1.92176
Value Function Loss: 0.02350

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07482
Policy Update Magnitude: 0.30740
Value Function Update Magnitude: 0.34763

Collected Steps per Second: 20,803.72279
Overall Steps per Second: 10,153.83468

Timestep Collection Time: 2.40370
Timestep Consumption Time: 2.52113
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.92484

Cumulative Model Updates: 221,598
Cumulative Timesteps: 1,848,742,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,036.68156
Policy Entropy: 1.92769
Value Function Loss: 0.02474

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07772
Policy Update Magnitude: 0.31029
Value Function Update Magnitude: 0.33670

Collected Steps per Second: 20,086.08713
Overall Steps per Second: 10,053.94955

Timestep Collection Time: 2.48938
Timestep Consumption Time: 2.48398
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.97337

Cumulative Model Updates: 221,604
Cumulative Timesteps: 1,848,792,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1848792296...
Checkpoint 1848792296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,289.58178
Policy Entropy: 1.91795
Value Function Loss: 0.02556

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.07679
Policy Update Magnitude: 0.30753
Value Function Update Magnitude: 0.34019

Collected Steps per Second: 20,490.85439
Overall Steps per Second: 9,994.88063

Timestep Collection Time: 2.44031
Timestep Consumption Time: 2.56265
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 5.00296

Cumulative Model Updates: 221,610
Cumulative Timesteps: 1,848,842,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,339.14441
Policy Entropy: 1.92403
Value Function Loss: 0.02532

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07421
Policy Update Magnitude: 0.30025
Value Function Update Magnitude: 0.33504

Collected Steps per Second: 20,915.66066
Overall Steps per Second: 10,171.93490

Timestep Collection Time: 2.39132
Timestep Consumption Time: 2.52574
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.91706

Cumulative Model Updates: 221,616
Cumulative Timesteps: 1,848,892,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1848892316...
Checkpoint 1848892316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,984.59099
Policy Entropy: 1.91482
Value Function Loss: 0.02408

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.30215
Value Function Update Magnitude: 0.32647

Collected Steps per Second: 20,794.29465
Overall Steps per Second: 10,085.75514

Timestep Collection Time: 2.40499
Timestep Consumption Time: 2.55349
PPO Batch Consumption Time: 0.29571
Total Iteration Time: 4.95848

Cumulative Model Updates: 221,622
Cumulative Timesteps: 1,848,942,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,763.83590
Policy Entropy: 1.90088
Value Function Loss: 0.02263

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07681
Policy Update Magnitude: 0.29531
Value Function Update Magnitude: 0.30582

Collected Steps per Second: 20,023.59177
Overall Steps per Second: 9,907.88954

Timestep Collection Time: 2.49875
Timestep Consumption Time: 2.55116
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 5.04992

Cumulative Model Updates: 221,628
Cumulative Timesteps: 1,848,992,360

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1848992360...
Checkpoint 1848992360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,314.36481
Policy Entropy: 1.89828
Value Function Loss: 0.02388

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07258
Policy Update Magnitude: 0.29442
Value Function Update Magnitude: 0.28680

Collected Steps per Second: 20,509.66619
Overall Steps per Second: 10,092.70595

Timestep Collection Time: 2.43865
Timestep Consumption Time: 2.51700
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.95566

Cumulative Model Updates: 221,634
Cumulative Timesteps: 1,849,042,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,969.00235
Policy Entropy: 1.90089
Value Function Loss: 0.02392

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07200
Policy Update Magnitude: 0.30075
Value Function Update Magnitude: 0.28581

Collected Steps per Second: 21,025.56148
Overall Steps per Second: 10,091.57570

Timestep Collection Time: 2.37901
Timestep Consumption Time: 2.57760
PPO Batch Consumption Time: 0.29951
Total Iteration Time: 4.95661

Cumulative Model Updates: 221,640
Cumulative Timesteps: 1,849,092,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1849092396...
Checkpoint 1849092396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,182.23513
Policy Entropy: 1.90940
Value Function Loss: 0.02569

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07419
Policy Update Magnitude: 0.30430
Value Function Update Magnitude: 0.29870

Collected Steps per Second: 20,277.41910
Overall Steps per Second: 9,962.65866

Timestep Collection Time: 2.46629
Timestep Consumption Time: 2.55345
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 5.01974

Cumulative Model Updates: 221,646
Cumulative Timesteps: 1,849,142,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,774.33064
Policy Entropy: 1.90488
Value Function Loss: 0.02821

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.07688
Policy Update Magnitude: 0.30435
Value Function Update Magnitude: 0.31791

Collected Steps per Second: 20,209.19993
Overall Steps per Second: 9,912.78942

Timestep Collection Time: 2.47442
Timestep Consumption Time: 2.57018
PPO Batch Consumption Time: 0.29894
Total Iteration Time: 5.04459

Cumulative Model Updates: 221,652
Cumulative Timesteps: 1,849,192,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1849192412...
Checkpoint 1849192412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,212.61040
Policy Entropy: 1.91378
Value Function Loss: 0.02923

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07453
Policy Update Magnitude: 0.30986
Value Function Update Magnitude: 0.33218

Collected Steps per Second: 20,286.16782
Overall Steps per Second: 9,946.01132

Timestep Collection Time: 2.46592
Timestep Consumption Time: 2.56364
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 5.02955

Cumulative Model Updates: 221,658
Cumulative Timesteps: 1,849,242,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,122.92917
Policy Entropy: 1.90054
Value Function Loss: 0.02685

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07427
Policy Update Magnitude: 0.30565
Value Function Update Magnitude: 0.33714

Collected Steps per Second: 20,554.67283
Overall Steps per Second: 10,130.42394

Timestep Collection Time: 2.43293
Timestep Consumption Time: 2.50349
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.93642

Cumulative Model Updates: 221,664
Cumulative Timesteps: 1,849,292,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1849292444...
Checkpoint 1849292444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,084.24199
Policy Entropy: 1.91146
Value Function Loss: 0.02650

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07915
Policy Update Magnitude: 0.31464
Value Function Update Magnitude: 0.33729

Collected Steps per Second: 19,932.98032
Overall Steps per Second: 9,993.79215

Timestep Collection Time: 2.50861
Timestep Consumption Time: 2.49490
PPO Batch Consumption Time: 0.30045
Total Iteration Time: 5.00351

Cumulative Model Updates: 221,670
Cumulative Timesteps: 1,849,342,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,671.70338
Policy Entropy: 1.91115
Value Function Loss: 0.02473

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08647
Policy Update Magnitude: 0.30600
Value Function Update Magnitude: 0.32921

Collected Steps per Second: 19,344.91138
Overall Steps per Second: 10,033.49084

Timestep Collection Time: 2.58569
Timestep Consumption Time: 2.39961
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.98530

Cumulative Model Updates: 221,676
Cumulative Timesteps: 1,849,392,468

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1849392468...
Checkpoint 1849392468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,827.26634
Policy Entropy: 1.91022
Value Function Loss: 0.02512

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.30078
Value Function Update Magnitude: 0.30305

Collected Steps per Second: 20,065.18537
Overall Steps per Second: 10,166.96934

Timestep Collection Time: 2.49268
Timestep Consumption Time: 2.42678
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.91946

Cumulative Model Updates: 221,682
Cumulative Timesteps: 1,849,442,484

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,879.30505
Policy Entropy: 1.90705
Value Function Loss: 0.02693

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.31296
Value Function Update Magnitude: 0.33276

Collected Steps per Second: 20,554.63992
Overall Steps per Second: 10,022.48315

Timestep Collection Time: 2.43322
Timestep Consumption Time: 2.55696
PPO Batch Consumption Time: 0.29781
Total Iteration Time: 4.99018

Cumulative Model Updates: 221,688
Cumulative Timesteps: 1,849,492,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1849492498...
Checkpoint 1849492498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,941.15247
Policy Entropy: 1.90548
Value Function Loss: 0.02664

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.31989
Value Function Update Magnitude: 0.37661

Collected Steps per Second: 20,325.99942
Overall Steps per Second: 10,136.90023

Timestep Collection Time: 2.46099
Timestep Consumption Time: 2.47366
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.93464

Cumulative Model Updates: 221,694
Cumulative Timesteps: 1,849,542,520

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,727.83263
Policy Entropy: 1.91525
Value Function Loss: 0.02683

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07658
Policy Update Magnitude: 0.32052
Value Function Update Magnitude: 0.37584

Collected Steps per Second: 20,232.14038
Overall Steps per Second: 10,149.06443

Timestep Collection Time: 2.47151
Timestep Consumption Time: 2.45544
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.92696

Cumulative Model Updates: 221,700
Cumulative Timesteps: 1,849,592,524

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1849592524...
Checkpoint 1849592524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,413.33774
Policy Entropy: 1.90907
Value Function Loss: 0.02700

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07751
Policy Update Magnitude: 0.32092
Value Function Update Magnitude: 0.37218

Collected Steps per Second: 20,528.16650
Overall Steps per Second: 10,123.44511

Timestep Collection Time: 2.43665
Timestep Consumption Time: 2.50435
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.94101

Cumulative Model Updates: 221,706
Cumulative Timesteps: 1,849,642,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,568.42117
Policy Entropy: 1.91268
Value Function Loss: 0.02603

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.31131
Value Function Update Magnitude: 0.36451

Collected Steps per Second: 20,887.97560
Overall Steps per Second: 10,099.54682

Timestep Collection Time: 2.39612
Timestep Consumption Time: 2.55955
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.95567

Cumulative Model Updates: 221,712
Cumulative Timesteps: 1,849,692,594

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1849692594...
Checkpoint 1849692594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,359.68982
Policy Entropy: 1.90558
Value Function Loss: 0.02687

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07276
Policy Update Magnitude: 0.30512
Value Function Update Magnitude: 0.33514

Collected Steps per Second: 20,178.36246
Overall Steps per Second: 9,943.09367

Timestep Collection Time: 2.47810
Timestep Consumption Time: 2.55092
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 5.02902

Cumulative Model Updates: 221,718
Cumulative Timesteps: 1,849,742,598

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,215.62030
Policy Entropy: 1.90212
Value Function Loss: 0.02837

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.31455
Value Function Update Magnitude: 0.32676

Collected Steps per Second: 20,299.01299
Overall Steps per Second: 9,962.20809

Timestep Collection Time: 2.46445
Timestep Consumption Time: 2.55712
PPO Batch Consumption Time: 0.29914
Total Iteration Time: 5.02158

Cumulative Model Updates: 221,724
Cumulative Timesteps: 1,849,792,624

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1849792624...
Checkpoint 1849792624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,544.38521
Policy Entropy: 1.89153
Value Function Loss: 0.02841

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07692
Policy Update Magnitude: 0.32013
Value Function Update Magnitude: 0.34775

Collected Steps per Second: 20,462.14609
Overall Steps per Second: 10,093.75044

Timestep Collection Time: 2.44363
Timestep Consumption Time: 2.51012
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.95376

Cumulative Model Updates: 221,730
Cumulative Timesteps: 1,849,842,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,985.13214
Policy Entropy: 1.90572
Value Function Loss: 0.02729

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.31957
Value Function Update Magnitude: 0.34947

Collected Steps per Second: 20,668.10795
Overall Steps per Second: 10,070.47156

Timestep Collection Time: 2.42015
Timestep Consumption Time: 2.54684
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.96700

Cumulative Model Updates: 221,736
Cumulative Timesteps: 1,849,892,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1849892646...
Checkpoint 1849892646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,922.09743
Policy Entropy: 1.91078
Value Function Loss: 0.02601

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.30875
Value Function Update Magnitude: 0.35188

Collected Steps per Second: 20,322.65258
Overall Steps per Second: 9,990.76677

Timestep Collection Time: 2.46149
Timestep Consumption Time: 2.54553
PPO Batch Consumption Time: 0.29642
Total Iteration Time: 5.00702

Cumulative Model Updates: 221,742
Cumulative Timesteps: 1,849,942,670

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,638.32344
Policy Entropy: 1.91238
Value Function Loss: 0.02508

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08717
Policy Update Magnitude: 0.30836
Value Function Update Magnitude: 0.34414

Collected Steps per Second: 20,180.64322
Overall Steps per Second: 9,920.48208

Timestep Collection Time: 2.47921
Timestep Consumption Time: 2.56410
PPO Batch Consumption Time: 0.30020
Total Iteration Time: 5.04330

Cumulative Model Updates: 221,748
Cumulative Timesteps: 1,849,992,702

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1849992702...
Checkpoint 1849992702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,229.88247
Policy Entropy: 1.89857
Value Function Loss: 0.02667

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08361
Policy Update Magnitude: 0.31160
Value Function Update Magnitude: 0.33510

Collected Steps per Second: 20,605.35111
Overall Steps per Second: 10,173.85300

Timestep Collection Time: 2.42665
Timestep Consumption Time: 2.48810
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.91476

Cumulative Model Updates: 221,754
Cumulative Timesteps: 1,850,042,704

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,279.38731
Policy Entropy: 1.89949
Value Function Loss: 0.02548

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08645
Policy Update Magnitude: 0.30966
Value Function Update Magnitude: 0.33263

Collected Steps per Second: 20,770.90110
Overall Steps per Second: 10,035.12172

Timestep Collection Time: 2.40731
Timestep Consumption Time: 2.57539
PPO Batch Consumption Time: 0.30110
Total Iteration Time: 4.98270

Cumulative Model Updates: 221,760
Cumulative Timesteps: 1,850,092,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1850092706...
Checkpoint 1850092706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,860.43832
Policy Entropy: 1.91951
Value Function Loss: 0.02728

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08098
Policy Update Magnitude: 0.30771
Value Function Update Magnitude: 0.32718

Collected Steps per Second: 20,664.45190
Overall Steps per Second: 10,118.17600

Timestep Collection Time: 2.42049
Timestep Consumption Time: 2.52290
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.94338

Cumulative Model Updates: 221,766
Cumulative Timesteps: 1,850,142,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,831.41193
Policy Entropy: 1.95164
Value Function Loss: 0.02865

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07426
Policy Update Magnitude: 0.30888
Value Function Update Magnitude: 0.32699

Collected Steps per Second: 20,282.15941
Overall Steps per Second: 10,108.36938

Timestep Collection Time: 2.46591
Timestep Consumption Time: 2.48187
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.94778

Cumulative Model Updates: 221,772
Cumulative Timesteps: 1,850,192,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1850192738...
Checkpoint 1850192738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,887.49167
Policy Entropy: 1.96242
Value Function Loss: 0.03013

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07517
Policy Update Magnitude: 0.31244
Value Function Update Magnitude: 0.35688

Collected Steps per Second: 20,586.41945
Overall Steps per Second: 10,129.79363

Timestep Collection Time: 2.42927
Timestep Consumption Time: 2.50765
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.93692

Cumulative Model Updates: 221,778
Cumulative Timesteps: 1,850,242,748

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,770.94537
Policy Entropy: 1.96250
Value Function Loss: 0.02874

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08176
Policy Update Magnitude: 0.31421
Value Function Update Magnitude: 0.37909

Collected Steps per Second: 21,081.80451
Overall Steps per Second: 10,122.80903

Timestep Collection Time: 2.37257
Timestep Consumption Time: 2.56855
PPO Batch Consumption Time: 0.30057
Total Iteration Time: 4.94112

Cumulative Model Updates: 221,784
Cumulative Timesteps: 1,850,292,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1850292766...
Checkpoint 1850292766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,329.19387
Policy Entropy: 1.96025
Value Function Loss: 0.02909

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.30886
Value Function Update Magnitude: 0.36502

Collected Steps per Second: 20,590.19433
Overall Steps per Second: 10,133.06501

Timestep Collection Time: 2.42902
Timestep Consumption Time: 2.50670
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.93572

Cumulative Model Updates: 221,790
Cumulative Timesteps: 1,850,342,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,629.47241
Policy Entropy: 1.95285
Value Function Loss: 0.02881

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.31068
Value Function Update Magnitude: 0.35651

Collected Steps per Second: 20,096.08877
Overall Steps per Second: 10,080.62220

Timestep Collection Time: 2.48834
Timestep Consumption Time: 2.47226
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.96061

Cumulative Model Updates: 221,796
Cumulative Timesteps: 1,850,392,786

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1850392786...
Checkpoint 1850392786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,946.83713
Policy Entropy: 1.93757
Value Function Loss: 0.02949

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.31636
Value Function Update Magnitude: 0.35525

Collected Steps per Second: 20,420.05000
Overall Steps per Second: 10,116.20241

Timestep Collection Time: 2.44897
Timestep Consumption Time: 2.49439
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.94336

Cumulative Model Updates: 221,802
Cumulative Timesteps: 1,850,442,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,346.99427
Policy Entropy: 1.91583
Value Function Loss: 0.02816

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.32238
Value Function Update Magnitude: 0.35154

Collected Steps per Second: 20,313.61678
Overall Steps per Second: 10,068.44644

Timestep Collection Time: 2.46327
Timestep Consumption Time: 2.50651
PPO Batch Consumption Time: 0.30199
Total Iteration Time: 4.96978

Cumulative Model Updates: 221,808
Cumulative Timesteps: 1,850,492,832

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1850492832...
Checkpoint 1850492832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,973.51950
Policy Entropy: 1.91566
Value Function Loss: 0.02659

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.08269
Policy Update Magnitude: 0.31673
Value Function Update Magnitude: 0.32717

Collected Steps per Second: 20,032.84130
Overall Steps per Second: 10,018.71680

Timestep Collection Time: 2.49710
Timestep Consumption Time: 2.49596
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 4.99305

Cumulative Model Updates: 221,814
Cumulative Timesteps: 1,850,542,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,586.09525
Policy Entropy: 1.92127
Value Function Loss: 0.02982

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.08113
Policy Update Magnitude: 0.31878
Value Function Update Magnitude: 0.32538

Collected Steps per Second: 19,494.73824
Overall Steps per Second: 9,907.19081

Timestep Collection Time: 2.56521
Timestep Consumption Time: 2.48244
PPO Batch Consumption Time: 0.29800
Total Iteration Time: 5.04765

Cumulative Model Updates: 221,820
Cumulative Timesteps: 1,850,592,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1850592864...
Checkpoint 1850592864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,854.47331
Policy Entropy: 1.93631
Value Function Loss: 0.03456

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.32736
Value Function Update Magnitude: 0.36434

Collected Steps per Second: 20,210.60661
Overall Steps per Second: 10,243.78190

Timestep Collection Time: 2.47514
Timestep Consumption Time: 2.40822
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.88335

Cumulative Model Updates: 221,826
Cumulative Timesteps: 1,850,642,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,347.79159
Policy Entropy: 1.92630
Value Function Loss: 0.03294

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.32851
Value Function Update Magnitude: 0.37573

Collected Steps per Second: 20,298.47670
Overall Steps per Second: 9,975.71052

Timestep Collection Time: 2.46482
Timestep Consumption Time: 2.55057
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 5.01538

Cumulative Model Updates: 221,832
Cumulative Timesteps: 1,850,692,920

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1850692920...
Checkpoint 1850692920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,765.86804
Policy Entropy: 1.92730
Value Function Loss: 0.03093

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.32596
Value Function Update Magnitude: 0.36950

Collected Steps per Second: 20,810.84064
Overall Steps per Second: 10,250.83478

Timestep Collection Time: 2.40365
Timestep Consumption Time: 2.47615
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.87980

Cumulative Model Updates: 221,838
Cumulative Timesteps: 1,850,742,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,861.93245
Policy Entropy: 1.92673
Value Function Loss: 0.02655

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.07871
Policy Update Magnitude: 0.31893
Value Function Update Magnitude: 0.35237

Collected Steps per Second: 20,018.63172
Overall Steps per Second: 10,035.60747

Timestep Collection Time: 2.49907
Timestep Consumption Time: 2.48598
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.98505

Cumulative Model Updates: 221,844
Cumulative Timesteps: 1,850,792,970

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1850792970...
Checkpoint 1850792970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,885.95676
Policy Entropy: 1.92344
Value Function Loss: 0.02584

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07388
Policy Update Magnitude: 0.31427
Value Function Update Magnitude: 0.35181

Collected Steps per Second: 20,673.08058
Overall Steps per Second: 10,146.81781

Timestep Collection Time: 2.41899
Timestep Consumption Time: 2.50945
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.92844

Cumulative Model Updates: 221,850
Cumulative Timesteps: 1,850,842,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,913.50104
Policy Entropy: 1.91124
Value Function Loss: 0.02784

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07467
Policy Update Magnitude: 0.31343
Value Function Update Magnitude: 0.35390

Collected Steps per Second: 20,781.34691
Overall Steps per Second: 10,059.63461

Timestep Collection Time: 2.40764
Timestep Consumption Time: 2.56610
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.97374

Cumulative Model Updates: 221,856
Cumulative Timesteps: 1,850,893,012

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1850893012...
Checkpoint 1850893012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,843.98502
Policy Entropy: 1.90481
Value Function Loss: 0.02725

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07816
Policy Update Magnitude: 0.31708
Value Function Update Magnitude: 0.37411

Collected Steps per Second: 20,761.08564
Overall Steps per Second: 10,155.96492

Timestep Collection Time: 2.40864
Timestep Consumption Time: 2.51516
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.92381

Cumulative Model Updates: 221,862
Cumulative Timesteps: 1,850,943,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,326.43118
Policy Entropy: 1.91303
Value Function Loss: 0.03137

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.32235
Value Function Update Magnitude: 0.38133

Collected Steps per Second: 20,213.62709
Overall Steps per Second: 10,043.83634

Timestep Collection Time: 2.47397
Timestep Consumption Time: 2.50500
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.97897

Cumulative Model Updates: 221,868
Cumulative Timesteps: 1,850,993,026

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1850993026...
Checkpoint 1850993026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,092.92391
Policy Entropy: 1.91880
Value Function Loss: 0.02930

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.32163
Value Function Update Magnitude: 0.39049

Collected Steps per Second: 20,674.47393
Overall Steps per Second: 10,142.74480

Timestep Collection Time: 2.42018
Timestep Consumption Time: 2.51300
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.93318

Cumulative Model Updates: 221,874
Cumulative Timesteps: 1,851,043,062

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,734.08513
Policy Entropy: 1.91548
Value Function Loss: 0.02862

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.31786
Value Function Update Magnitude: 0.38379

Collected Steps per Second: 20,803.39675
Overall Steps per Second: 10,107.18878

Timestep Collection Time: 2.40432
Timestep Consumption Time: 2.54444
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.94875

Cumulative Model Updates: 221,880
Cumulative Timesteps: 1,851,093,080

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1851093080...
Checkpoint 1851093080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,749.06627
Policy Entropy: 1.91362
Value Function Loss: 0.02445

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.30932
Value Function Update Magnitude: 0.32117

Collected Steps per Second: 18,787.46896
Overall Steps per Second: 9,426.98814

Timestep Collection Time: 2.66199
Timestep Consumption Time: 2.64321
PPO Batch Consumption Time: 0.30873
Total Iteration Time: 5.30519

Cumulative Model Updates: 221,886
Cumulative Timesteps: 1,851,143,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,945.96531
Policy Entropy: 1.90778
Value Function Loss: 0.02310

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08030
Policy Update Magnitude: 0.30226
Value Function Update Magnitude: 0.30393

Collected Steps per Second: 18,809.90417
Overall Steps per Second: 9,240.48445

Timestep Collection Time: 2.65977
Timestep Consumption Time: 2.75445
PPO Batch Consumption Time: 0.31965
Total Iteration Time: 5.41422

Cumulative Model Updates: 221,892
Cumulative Timesteps: 1,851,193,122

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1851193122...
Checkpoint 1851193122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,922.36571
Policy Entropy: 1.90610
Value Function Loss: 0.02517

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.30521
Value Function Update Magnitude: 0.31210

Collected Steps per Second: 21,268.96456
Overall Steps per Second: 10,409.39036

Timestep Collection Time: 2.35094
Timestep Consumption Time: 2.45261
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.80355

Cumulative Model Updates: 221,898
Cumulative Timesteps: 1,851,243,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,631.50439
Policy Entropy: 1.92232
Value Function Loss: 0.02797

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07475
Policy Update Magnitude: 0.31111
Value Function Update Magnitude: 0.33961

Collected Steps per Second: 20,911.33946
Overall Steps per Second: 10,021.66631

Timestep Collection Time: 2.39124
Timestep Consumption Time: 2.59835
PPO Batch Consumption Time: 0.30220
Total Iteration Time: 4.98959

Cumulative Model Updates: 221,904
Cumulative Timesteps: 1,851,293,128

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1851293128...
Checkpoint 1851293128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,608.02309
Policy Entropy: 1.95070
Value Function Loss: 0.02767

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07448
Policy Update Magnitude: 0.31112
Value Function Update Magnitude: 0.33224

Collected Steps per Second: 19,462.29238
Overall Steps per Second: 9,388.44624

Timestep Collection Time: 2.56917
Timestep Consumption Time: 2.75673
PPO Batch Consumption Time: 0.32145
Total Iteration Time: 5.32591

Cumulative Model Updates: 221,910
Cumulative Timesteps: 1,851,343,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,027.45817
Policy Entropy: 1.95025
Value Function Loss: 0.02740

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07357
Policy Update Magnitude: 0.31094
Value Function Update Magnitude: 0.32238

Collected Steps per Second: 20,688.66671
Overall Steps per Second: 9,976.00760

Timestep Collection Time: 2.41756
Timestep Consumption Time: 2.59607
PPO Batch Consumption Time: 0.30468
Total Iteration Time: 5.01363

Cumulative Model Updates: 221,916
Cumulative Timesteps: 1,851,393,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1851393146...
Checkpoint 1851393146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,149.89644
Policy Entropy: 1.93368
Value Function Loss: 0.02717

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07571
Policy Update Magnitude: 0.30409
Value Function Update Magnitude: 0.34077

Collected Steps per Second: 20,398.11723
Overall Steps per Second: 10,254.70343

Timestep Collection Time: 2.45238
Timestep Consumption Time: 2.42577
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.87815

Cumulative Model Updates: 221,922
Cumulative Timesteps: 1,851,443,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,789.71637
Policy Entropy: 1.91322
Value Function Loss: 0.02799

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.07631
Policy Update Magnitude: 0.30753
Value Function Update Magnitude: 0.33011

Collected Steps per Second: 18,626.71880
Overall Steps per Second: 9,539.72959

Timestep Collection Time: 2.68603
Timestep Consumption Time: 2.55856
PPO Batch Consumption Time: 0.30713
Total Iteration Time: 5.24459

Cumulative Model Updates: 221,928
Cumulative Timesteps: 1,851,493,202

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1851493202...
Checkpoint 1851493202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,064.03396
Policy Entropy: 1.92338
Value Function Loss: 0.02858

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07616
Policy Update Magnitude: 0.31309
Value Function Update Magnitude: 0.30073

Collected Steps per Second: 18,379.26466
Overall Steps per Second: 9,596.81227

Timestep Collection Time: 2.72198
Timestep Consumption Time: 2.49100
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 5.21298

Cumulative Model Updates: 221,934
Cumulative Timesteps: 1,851,543,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,037.96747
Policy Entropy: 1.91607
Value Function Loss: 0.02714

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.31077
Value Function Update Magnitude: 0.27969

Collected Steps per Second: 16,904.63856
Overall Steps per Second: 9,311.66357

Timestep Collection Time: 2.95931
Timestep Consumption Time: 2.41310
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 5.37240

Cumulative Model Updates: 221,940
Cumulative Timesteps: 1,851,593,256

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1851593256...
Checkpoint 1851593256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,857.91263
Policy Entropy: 1.92702
Value Function Loss: 0.02742

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07730
Policy Update Magnitude: 0.30733
Value Function Update Magnitude: 0.28258

Collected Steps per Second: 19,637.90382
Overall Steps per Second: 9,827.01070

Timestep Collection Time: 2.54681
Timestep Consumption Time: 2.54263
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 5.08944

Cumulative Model Updates: 221,946
Cumulative Timesteps: 1,851,643,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,063.51731
Policy Entropy: 1.92549
Value Function Loss: 0.02501

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.29899
Value Function Update Magnitude: 0.29397

Collected Steps per Second: 20,755.40906
Overall Steps per Second: 10,117.97813

Timestep Collection Time: 2.40920
Timestep Consumption Time: 2.53289
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.94209

Cumulative Model Updates: 221,952
Cumulative Timesteps: 1,851,693,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1851693274...
Checkpoint 1851693274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,064.90289
Policy Entropy: 1.92965
Value Function Loss: 0.02458

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07494
Policy Update Magnitude: 0.29815
Value Function Update Magnitude: 0.31383

Collected Steps per Second: 16,984.39670
Overall Steps per Second: 9,016.04794

Timestep Collection Time: 2.94541
Timestep Consumption Time: 2.60314
PPO Batch Consumption Time: 0.30744
Total Iteration Time: 5.54855

Cumulative Model Updates: 221,958
Cumulative Timesteps: 1,851,743,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,929.99831
Policy Entropy: 1.91999
Value Function Loss: 0.02460

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.30083
Value Function Update Magnitude: 0.32320

Collected Steps per Second: 20,319.44843
Overall Steps per Second: 9,828.24802

Timestep Collection Time: 2.46276
Timestep Consumption Time: 2.62889
PPO Batch Consumption Time: 0.31478
Total Iteration Time: 5.09165

Cumulative Model Updates: 221,964
Cumulative Timesteps: 1,851,793,342

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1851793342...
Checkpoint 1851793342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,344.03019
Policy Entropy: 1.91553
Value Function Loss: 0.02453

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.08421
Policy Update Magnitude: 0.30249
Value Function Update Magnitude: 0.30791

Collected Steps per Second: 19,368.86416
Overall Steps per Second: 9,577.28247

Timestep Collection Time: 2.58291
Timestep Consumption Time: 2.64070
PPO Batch Consumption Time: 0.30335
Total Iteration Time: 5.22361

Cumulative Model Updates: 221,970
Cumulative Timesteps: 1,851,843,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,500.69255
Policy Entropy: 1.91366
Value Function Loss: 0.02483

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.10995
Policy Update Magnitude: 0.29556
Value Function Update Magnitude: 0.29306

Collected Steps per Second: 19,123.48904
Overall Steps per Second: 9,345.60323

Timestep Collection Time: 2.61615
Timestep Consumption Time: 2.73717
PPO Batch Consumption Time: 0.31468
Total Iteration Time: 5.35332

Cumulative Model Updates: 221,976
Cumulative Timesteps: 1,851,893,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1851893400...
Checkpoint 1851893400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,051.12188
Policy Entropy: 1.92855
Value Function Loss: 0.02347

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.29370
Value Function Update Magnitude: 0.29358

Collected Steps per Second: 18,871.52390
Overall Steps per Second: 9,086.20874

Timestep Collection Time: 2.65193
Timestep Consumption Time: 2.85598
PPO Batch Consumption Time: 0.33140
Total Iteration Time: 5.50791

Cumulative Model Updates: 221,982
Cumulative Timesteps: 1,851,943,446

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,909.16331
Policy Entropy: 1.91563
Value Function Loss: 0.02597

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.30135
Value Function Update Magnitude: 0.32967

Collected Steps per Second: 18,411.40224
Overall Steps per Second: 9,109.29424

Timestep Collection Time: 2.71603
Timestep Consumption Time: 2.77352
PPO Batch Consumption Time: 0.31048
Total Iteration Time: 5.48956

Cumulative Model Updates: 221,988
Cumulative Timesteps: 1,851,993,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1851993452...
Checkpoint 1851993452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,039.96008
Policy Entropy: 1.92586
Value Function Loss: 0.02542

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.29949
Value Function Update Magnitude: 0.35127

Collected Steps per Second: 17,794.56620
Overall Steps per Second: 8,997.29155

Timestep Collection Time: 2.81030
Timestep Consumption Time: 2.74782
PPO Batch Consumption Time: 0.31830
Total Iteration Time: 5.55812

Cumulative Model Updates: 221,994
Cumulative Timesteps: 1,852,043,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,758.34547
Policy Entropy: 1.90879
Value Function Loss: 0.02599

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.29507
Value Function Update Magnitude: 0.33917

Collected Steps per Second: 16,614.80769
Overall Steps per Second: 8,923.80013

Timestep Collection Time: 3.00960
Timestep Consumption Time: 2.59384
PPO Batch Consumption Time: 0.30097
Total Iteration Time: 5.60344

Cumulative Model Updates: 222,000
Cumulative Timesteps: 1,852,093,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1852093464...
Checkpoint 1852093464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,228.97220
Policy Entropy: 1.91090
Value Function Loss: 0.02665

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.30169
Value Function Update Magnitude: 0.33931

Collected Steps per Second: 20,255.20014
Overall Steps per Second: 9,979.42141

Timestep Collection Time: 2.46998
Timestep Consumption Time: 2.54333
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 5.01332

Cumulative Model Updates: 222,006
Cumulative Timesteps: 1,852,143,494

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,604.81832
Policy Entropy: 1.90366
Value Function Loss: 0.02606

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08354
Policy Update Magnitude: 0.30444
Value Function Update Magnitude: 0.31802

Collected Steps per Second: 20,867.54205
Overall Steps per Second: 10,195.41802

Timestep Collection Time: 2.39693
Timestep Consumption Time: 2.50900
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.90593

Cumulative Model Updates: 222,012
Cumulative Timesteps: 1,852,193,512

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1852193512...
Checkpoint 1852193512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,738.45713
Policy Entropy: 1.91176
Value Function Loss: 0.02421

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07605
Policy Update Magnitude: 0.29778
Value Function Update Magnitude: 0.28727

Collected Steps per Second: 19,542.78617
Overall Steps per Second: 9,893.94582

Timestep Collection Time: 2.55921
Timestep Consumption Time: 2.49581
PPO Batch Consumption Time: 0.30064
Total Iteration Time: 5.05501

Cumulative Model Updates: 222,018
Cumulative Timesteps: 1,852,243,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,940.62798
Policy Entropy: 1.91544
Value Function Loss: 0.02428

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06742
Policy Update Magnitude: 0.29693
Value Function Update Magnitude: 0.27875

Collected Steps per Second: 19,911.27695
Overall Steps per Second: 10,006.63548

Timestep Collection Time: 2.51224
Timestep Consumption Time: 2.48664
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.99888

Cumulative Model Updates: 222,024
Cumulative Timesteps: 1,852,293,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1852293548...
Checkpoint 1852293548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,964.99586
Policy Entropy: 1.90969
Value Function Loss: 0.02374

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07643
Policy Update Magnitude: 0.29820
Value Function Update Magnitude: 0.30080

Collected Steps per Second: 19,808.11409
Overall Steps per Second: 10,096.14883

Timestep Collection Time: 2.52452
Timestep Consumption Time: 2.42846
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.95298

Cumulative Model Updates: 222,030
Cumulative Timesteps: 1,852,343,554

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,920.62527
Policy Entropy: 1.90635
Value Function Loss: 0.03077

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07287
Policy Update Magnitude: 0.31576
Value Function Update Magnitude: 0.31968

Collected Steps per Second: 20,120.32865
Overall Steps per Second: 10,173.71843

Timestep Collection Time: 2.48654
Timestep Consumption Time: 2.43103
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.91757

Cumulative Model Updates: 222,036
Cumulative Timesteps: 1,852,393,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1852393584...
Checkpoint 1852393584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,597.05118
Policy Entropy: 1.90778
Value Function Loss: 0.03010

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.07752
Policy Update Magnitude: 0.32601
Value Function Update Magnitude: 0.34126

Collected Steps per Second: 19,931.86096
Overall Steps per Second: 10,103.06463

Timestep Collection Time: 2.50975
Timestep Consumption Time: 2.44162
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.95137

Cumulative Model Updates: 222,042
Cumulative Timesteps: 1,852,443,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,314.85177
Policy Entropy: 1.91222
Value Function Loss: 0.03065

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.31811
Value Function Update Magnitude: 0.35273

Collected Steps per Second: 20,208.04808
Overall Steps per Second: 9,693.36142

Timestep Collection Time: 2.47436
Timestep Consumption Time: 2.68401
PPO Batch Consumption Time: 0.31962
Total Iteration Time: 5.15838

Cumulative Model Updates: 222,048
Cumulative Timesteps: 1,852,493,610

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1852493610...
Checkpoint 1852493610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,769.41837
Policy Entropy: 1.91635
Value Function Loss: 0.02968

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07624
Policy Update Magnitude: 0.31355
Value Function Update Magnitude: 0.34177

Collected Steps per Second: 17,570.69289
Overall Steps per Second: 9,245.69132

Timestep Collection Time: 2.84610
Timestep Consumption Time: 2.56269
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 5.40879

Cumulative Model Updates: 222,054
Cumulative Timesteps: 1,852,543,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,353.92483
Policy Entropy: 1.91483
Value Function Loss: 0.02605

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.07866
Policy Update Magnitude: 0.31044
Value Function Update Magnitude: 0.34328

Collected Steps per Second: 18,346.88043
Overall Steps per Second: 9,544.89910

Timestep Collection Time: 2.72689
Timestep Consumption Time: 2.51465
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 5.24154

Cumulative Model Updates: 222,060
Cumulative Timesteps: 1,852,593,648

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1852593648...
Checkpoint 1852593648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,618.84945
Policy Entropy: 1.92289
Value Function Loss: 0.02606

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.07922
Policy Update Magnitude: 0.30723
Value Function Update Magnitude: 0.34972

Collected Steps per Second: 20,421.05640
Overall Steps per Second: 10,085.33803

Timestep Collection Time: 2.44933
Timestep Consumption Time: 2.51014
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.95948

Cumulative Model Updates: 222,066
Cumulative Timesteps: 1,852,643,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,554.98439
Policy Entropy: 1.92935
Value Function Loss: 0.02510

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.30451
Value Function Update Magnitude: 0.33869

Collected Steps per Second: 20,705.47107
Overall Steps per Second: 10,142.94834

Timestep Collection Time: 2.41608
Timestep Consumption Time: 2.51602
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.93210

Cumulative Model Updates: 222,072
Cumulative Timesteps: 1,852,693,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1852693692...
Checkpoint 1852693692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,915.28588
Policy Entropy: 1.91402
Value Function Loss: 0.02670

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.30785
Value Function Update Magnitude: 0.35752

Collected Steps per Second: 20,545.54976
Overall Steps per Second: 10,118.14942

Timestep Collection Time: 2.43527
Timestep Consumption Time: 2.50970
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.94498

Cumulative Model Updates: 222,078
Cumulative Timesteps: 1,852,743,726

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,763.24077
Policy Entropy: 1.90585
Value Function Loss: 0.02488

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.30746
Value Function Update Magnitude: 0.36530

Collected Steps per Second: 20,630.40700
Overall Steps per Second: 10,156.88942

Timestep Collection Time: 2.42458
Timestep Consumption Time: 2.50016
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.92474

Cumulative Model Updates: 222,084
Cumulative Timesteps: 1,852,793,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1852793746...
Checkpoint 1852793746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,756.93865
Policy Entropy: 1.89415
Value Function Loss: 0.02284

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08095
Policy Update Magnitude: 0.29503
Value Function Update Magnitude: 0.31542

Collected Steps per Second: 20,231.75906
Overall Steps per Second: 9,872.56433

Timestep Collection Time: 2.47196
Timestep Consumption Time: 2.59380
PPO Batch Consumption Time: 0.29988
Total Iteration Time: 5.06576

Cumulative Model Updates: 222,090
Cumulative Timesteps: 1,852,843,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,880.41727
Policy Entropy: 1.91275
Value Function Loss: 0.02268

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07117
Policy Update Magnitude: 0.29551
Value Function Update Magnitude: 0.29702

Collected Steps per Second: 20,730.88470
Overall Steps per Second: 10,038.18923

Timestep Collection Time: 2.41302
Timestep Consumption Time: 2.57035
PPO Batch Consumption Time: 0.29999
Total Iteration Time: 4.98337

Cumulative Model Updates: 222,096
Cumulative Timesteps: 1,852,893,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1852893782...
Checkpoint 1852893782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,290.37610
Policy Entropy: 1.91155
Value Function Loss: 0.02289

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07163
Policy Update Magnitude: 0.29303
Value Function Update Magnitude: 0.30648

Collected Steps per Second: 20,798.69916
Overall Steps per Second: 10,110.44524

Timestep Collection Time: 2.40448
Timestep Consumption Time: 2.54189
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.94637

Cumulative Model Updates: 222,102
Cumulative Timesteps: 1,852,943,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,181.59541
Policy Entropy: 1.90608
Value Function Loss: 0.02291

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.29268
Value Function Update Magnitude: 0.29233

Collected Steps per Second: 20,621.89367
Overall Steps per Second: 10,048.80155

Timestep Collection Time: 2.42519
Timestep Consumption Time: 2.55172
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.97691

Cumulative Model Updates: 222,108
Cumulative Timesteps: 1,852,993,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1852993804...
Checkpoint 1852993804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,702.45731
Policy Entropy: 1.90058
Value Function Loss: 0.02435

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08070
Policy Update Magnitude: 0.29442
Value Function Update Magnitude: 0.27378

Collected Steps per Second: 20,707.83460
Overall Steps per Second: 10,144.84663

Timestep Collection Time: 2.41599
Timestep Consumption Time: 2.51557
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.93157

Cumulative Model Updates: 222,114
Cumulative Timesteps: 1,853,043,834

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,918.25157
Policy Entropy: 1.90666
Value Function Loss: 0.02413

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08082
Policy Update Magnitude: 0.29604
Value Function Update Magnitude: 0.25526

Collected Steps per Second: 20,530.17347
Overall Steps per Second: 10,116.49338

Timestep Collection Time: 2.43641
Timestep Consumption Time: 2.50799
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.94440

Cumulative Model Updates: 222,120
Cumulative Timesteps: 1,853,093,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1853093854...
Checkpoint 1853093854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,986.06599
Policy Entropy: 1.93242
Value Function Loss: 0.02393

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07933
Policy Update Magnitude: 0.28928
Value Function Update Magnitude: 0.26276

Collected Steps per Second: 20,507.34442
Overall Steps per Second: 10,092.54866

Timestep Collection Time: 2.43932
Timestep Consumption Time: 2.51721
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.95653

Cumulative Model Updates: 222,126
Cumulative Timesteps: 1,853,143,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,461.64815
Policy Entropy: 1.93632
Value Function Loss: 0.02303

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.28573
Value Function Update Magnitude: 0.28312

Collected Steps per Second: 20,599.23351
Overall Steps per Second: 10,142.59966

Timestep Collection Time: 2.42815
Timestep Consumption Time: 2.50333
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.93148

Cumulative Model Updates: 222,132
Cumulative Timesteps: 1,853,193,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1853193896...
Checkpoint 1853193896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,124.01932
Policy Entropy: 1.93375
Value Function Loss: 0.02272

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07419
Policy Update Magnitude: 0.28515
Value Function Update Magnitude: 0.29456

Collected Steps per Second: 20,885.00763
Overall Steps per Second: 10,209.88346

Timestep Collection Time: 2.39444
Timestep Consumption Time: 2.50355
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.89800

Cumulative Model Updates: 222,138
Cumulative Timesteps: 1,853,243,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,845.67024
Policy Entropy: 1.91914
Value Function Loss: 0.02263

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06930
Policy Update Magnitude: 0.28697
Value Function Update Magnitude: 0.29159

Collected Steps per Second: 20,614.76334
Overall Steps per Second: 10,000.12838

Timestep Collection Time: 2.42583
Timestep Consumption Time: 2.57490
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 5.00074

Cumulative Model Updates: 222,144
Cumulative Timesteps: 1,853,293,912

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1853293912...
Checkpoint 1853293912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,931.70787
Policy Entropy: 1.91544
Value Function Loss: 0.02301

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07201
Policy Update Magnitude: 0.29367
Value Function Update Magnitude: 0.24968

Collected Steps per Second: 20,439.64364
Overall Steps per Second: 10,114.52100

Timestep Collection Time: 2.44642
Timestep Consumption Time: 2.49736
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.94378

Cumulative Model Updates: 222,150
Cumulative Timesteps: 1,853,343,916

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,207.79077
Policy Entropy: 1.92331
Value Function Loss: 0.02468

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07545
Policy Update Magnitude: 0.30194
Value Function Update Magnitude: 0.27439

Collected Steps per Second: 20,437.97170
Overall Steps per Second: 10,154.91026

Timestep Collection Time: 2.44897
Timestep Consumption Time: 2.47988
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.92885

Cumulative Model Updates: 222,156
Cumulative Timesteps: 1,853,393,968

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1853393968...
Checkpoint 1853393968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,014.58378
Policy Entropy: 1.92516
Value Function Loss: 0.02600

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07765
Policy Update Magnitude: 0.30872
Value Function Update Magnitude: 0.32853

Collected Steps per Second: 20,199.42601
Overall Steps per Second: 10,228.36775

Timestep Collection Time: 2.47561
Timestep Consumption Time: 2.41334
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.88895

Cumulative Model Updates: 222,162
Cumulative Timesteps: 1,853,443,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,595.67321
Policy Entropy: 1.90843
Value Function Loss: 0.02488

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08747
Policy Update Magnitude: 0.30628
Value Function Update Magnitude: 0.33944

Collected Steps per Second: 20,193.06556
Overall Steps per Second: 10,055.93476

Timestep Collection Time: 2.47758
Timestep Consumption Time: 2.49759
PPO Batch Consumption Time: 0.30091
Total Iteration Time: 4.97517

Cumulative Model Updates: 222,168
Cumulative Timesteps: 1,853,494,004

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1853494004...
Checkpoint 1853494004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,279.67691
Policy Entropy: 1.91616
Value Function Loss: 0.02454

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.29721
Value Function Update Magnitude: 0.33207

Collected Steps per Second: 20,149.24556
Overall Steps per Second: 10,077.23618

Timestep Collection Time: 2.48267
Timestep Consumption Time: 2.48139
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.96406

Cumulative Model Updates: 222,174
Cumulative Timesteps: 1,853,544,028

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,440.97706
Policy Entropy: 1.90094
Value Function Loss: 0.02438

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07482
Policy Update Magnitude: 0.29901
Value Function Update Magnitude: 0.34249

Collected Steps per Second: 19,897.29806
Overall Steps per Second: 10,016.41283

Timestep Collection Time: 2.51411
Timestep Consumption Time: 2.48009
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.99420

Cumulative Model Updates: 222,180
Cumulative Timesteps: 1,853,594,052

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1853594052...
Checkpoint 1853594052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,622.59326
Policy Entropy: 1.90309
Value Function Loss: 0.02393

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07998
Policy Update Magnitude: 0.29977
Value Function Update Magnitude: 0.35130

Collected Steps per Second: 20,809.74342
Overall Steps per Second: 10,242.03740

Timestep Collection Time: 2.40339
Timestep Consumption Time: 2.47981
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.88321

Cumulative Model Updates: 222,186
Cumulative Timesteps: 1,853,644,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,357.55138
Policy Entropy: 1.88649
Value Function Loss: 0.02237

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07219
Policy Update Magnitude: 0.29556
Value Function Update Magnitude: 0.31618

Collected Steps per Second: 20,691.82703
Overall Steps per Second: 10,139.95090

Timestep Collection Time: 2.41777
Timestep Consumption Time: 2.51599
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.93375

Cumulative Model Updates: 222,192
Cumulative Timesteps: 1,853,694,094

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1853694094...
Checkpoint 1853694094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,885.87421
Policy Entropy: 1.89358
Value Function Loss: 0.02404

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.29516
Value Function Update Magnitude: 0.29449

Collected Steps per Second: 20,835.09233
Overall Steps per Second: 10,178.08888

Timestep Collection Time: 2.40076
Timestep Consumption Time: 2.51372
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.91448

Cumulative Model Updates: 222,198
Cumulative Timesteps: 1,853,744,114

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,385.98821
Policy Entropy: 1.90114
Value Function Loss: 0.02235

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07686
Policy Update Magnitude: 0.29675
Value Function Update Magnitude: 0.27902

Collected Steps per Second: 20,614.51107
Overall Steps per Second: 10,035.54735

Timestep Collection Time: 2.42645
Timestep Consumption Time: 2.55784
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.98428

Cumulative Model Updates: 222,204
Cumulative Timesteps: 1,853,794,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1853794134...
Checkpoint 1853794134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,843.19351
Policy Entropy: 1.91337
Value Function Loss: 0.02124

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.29121
Value Function Update Magnitude: 0.26816

Collected Steps per Second: 20,774.04002
Overall Steps per Second: 10,148.28832

Timestep Collection Time: 2.40791
Timestep Consumption Time: 2.52120
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.92911

Cumulative Model Updates: 222,210
Cumulative Timesteps: 1,853,844,156

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,016.28247
Policy Entropy: 1.90894
Value Function Loss: 0.01915

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07281
Policy Update Magnitude: 0.28404
Value Function Update Magnitude: 0.27951

Collected Steps per Second: 20,563.40372
Overall Steps per Second: 10,118.54131

Timestep Collection Time: 2.43267
Timestep Consumption Time: 2.51112
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.94380

Cumulative Model Updates: 222,216
Cumulative Timesteps: 1,853,894,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1853894180...
Checkpoint 1853894180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,727.29814
Policy Entropy: 1.90237
Value Function Loss: 0.02196

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07727
Policy Update Magnitude: 0.28544
Value Function Update Magnitude: 0.27471

Collected Steps per Second: 20,479.53369
Overall Steps per Second: 10,088.87857

Timestep Collection Time: 2.44273
Timestep Consumption Time: 2.51580
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.95853

Cumulative Model Updates: 222,222
Cumulative Timesteps: 1,853,944,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,354.34086
Policy Entropy: 1.89927
Value Function Loss: 0.02257

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07161
Policy Update Magnitude: 0.28687
Value Function Update Magnitude: 0.29817

Collected Steps per Second: 20,645.81080
Overall Steps per Second: 10,062.19220

Timestep Collection Time: 2.42286
Timestep Consumption Time: 2.54842
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.97128

Cumulative Model Updates: 222,228
Cumulative Timesteps: 1,853,994,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1853994228...
Checkpoint 1853994228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,095.66602
Policy Entropy: 1.91910
Value Function Loss: 0.02474

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07484
Policy Update Magnitude: 0.29113
Value Function Update Magnitude: 0.32727

Collected Steps per Second: 20,164.80486
Overall Steps per Second: 9,882.69441

Timestep Collection Time: 2.48106
Timestep Consumption Time: 2.58133
PPO Batch Consumption Time: 0.30050
Total Iteration Time: 5.06238

Cumulative Model Updates: 222,234
Cumulative Timesteps: 1,854,044,258

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,342.72253
Policy Entropy: 1.91674
Value Function Loss: 0.02385

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07453
Policy Update Magnitude: 0.29616
Value Function Update Magnitude: 0.32806

Collected Steps per Second: 20,650.21372
Overall Steps per Second: 10,032.31100

Timestep Collection Time: 2.42157
Timestep Consumption Time: 2.56292
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 4.98449

Cumulative Model Updates: 222,240
Cumulative Timesteps: 1,854,094,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1854094264...
Checkpoint 1854094264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,993.52283
Policy Entropy: 1.91884
Value Function Loss: 0.02334

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07666
Policy Update Magnitude: 0.29013
Value Function Update Magnitude: 0.30385

Collected Steps per Second: 20,776.54119
Overall Steps per Second: 10,151.94994

Timestep Collection Time: 2.40820
Timestep Consumption Time: 2.52031
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.92851

Cumulative Model Updates: 222,246
Cumulative Timesteps: 1,854,144,298

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,386.09855
Policy Entropy: 1.90603
Value Function Loss: 0.02327

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07137
Policy Update Magnitude: 0.28768
Value Function Update Magnitude: 0.27189

Collected Steps per Second: 20,759.31066
Overall Steps per Second: 10,099.46473

Timestep Collection Time: 2.40942
Timestep Consumption Time: 2.54311
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.95254

Cumulative Model Updates: 222,252
Cumulative Timesteps: 1,854,194,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1854194316...
Checkpoint 1854194316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,527.68133
Policy Entropy: 1.89355
Value Function Loss: 0.02509

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07493
Policy Update Magnitude: 0.29053
Value Function Update Magnitude: 0.22064

Collected Steps per Second: 20,625.14332
Overall Steps per Second: 10,123.92754

Timestep Collection Time: 2.42510
Timestep Consumption Time: 2.51547
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.94057

Cumulative Model Updates: 222,258
Cumulative Timesteps: 1,854,244,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,457.99204
Policy Entropy: 1.90525
Value Function Loss: 0.02730

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07842
Policy Update Magnitude: 0.29671
Value Function Update Magnitude: 0.20541

Collected Steps per Second: 19,074.58846
Overall Steps per Second: 9,771.90393

Timestep Collection Time: 2.62244
Timestep Consumption Time: 2.49652
PPO Batch Consumption Time: 0.30098
Total Iteration Time: 5.11896

Cumulative Model Updates: 222,264
Cumulative Timesteps: 1,854,294,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1854294356...
Checkpoint 1854294356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,821.71173
Policy Entropy: 1.91061
Value Function Loss: 0.02980

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08267
Policy Update Magnitude: 0.30832
Value Function Update Magnitude: 0.24186

Collected Steps per Second: 19,919.97219
Overall Steps per Second: 10,096.04865

Timestep Collection Time: 2.51205
Timestep Consumption Time: 2.44434
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.95639

Cumulative Model Updates: 222,270
Cumulative Timesteps: 1,854,344,396

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,143.77413
Policy Entropy: 1.91156
Value Function Loss: 0.03031

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.31165
Value Function Update Magnitude: 0.31268

Collected Steps per Second: 20,280.67554
Overall Steps per Second: 10,070.36536

Timestep Collection Time: 2.46718
Timestep Consumption Time: 2.50146
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.96864

Cumulative Model Updates: 222,276
Cumulative Timesteps: 1,854,394,432

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1854394432...
Checkpoint 1854394432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,671.03889
Policy Entropy: 1.91556
Value Function Loss: 0.03063

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.31959
Value Function Update Magnitude: 0.31875

Collected Steps per Second: 19,762.84819
Overall Steps per Second: 9,970.95540

Timestep Collection Time: 2.53233
Timestep Consumption Time: 2.48685
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 5.01918

Cumulative Model Updates: 222,282
Cumulative Timesteps: 1,854,444,478

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,810.19992
Policy Entropy: 1.91256
Value Function Loss: 0.02729

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.31735
Value Function Update Magnitude: 0.34905

Collected Steps per Second: 20,363.60854
Overall Steps per Second: 10,224.69706

Timestep Collection Time: 2.45674
Timestep Consumption Time: 2.43612
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.89286

Cumulative Model Updates: 222,288
Cumulative Timesteps: 1,854,494,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1854494506...
Checkpoint 1854494506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,446.80143
Policy Entropy: 1.89966
Value Function Loss: 0.02496

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07645
Policy Update Magnitude: 0.30677
Value Function Update Magnitude: 0.31704

Collected Steps per Second: 19,945.04507
Overall Steps per Second: 9,882.90719

Timestep Collection Time: 2.50809
Timestep Consumption Time: 2.55358
PPO Batch Consumption Time: 0.29829
Total Iteration Time: 5.06167

Cumulative Model Updates: 222,294
Cumulative Timesteps: 1,854,544,530

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,661.62034
Policy Entropy: 1.89508
Value Function Loss: 0.02421

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07674
Policy Update Magnitude: 0.30202
Value Function Update Magnitude: 0.31461

Collected Steps per Second: 20,811.85799
Overall Steps per Second: 10,099.03967

Timestep Collection Time: 2.40373
Timestep Consumption Time: 2.54981
PPO Batch Consumption Time: 0.29974
Total Iteration Time: 4.95354

Cumulative Model Updates: 222,300
Cumulative Timesteps: 1,854,594,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1854594556...
Checkpoint 1854594556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,752.99795
Policy Entropy: 1.90847
Value Function Loss: 0.02374

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07314
Policy Update Magnitude: 0.30019
Value Function Update Magnitude: 0.33939

Collected Steps per Second: 20,396.70931
Overall Steps per Second: 10,123.35103

Timestep Collection Time: 2.45294
Timestep Consumption Time: 2.48929
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.94224

Cumulative Model Updates: 222,306
Cumulative Timesteps: 1,854,644,588

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,992.42417
Policy Entropy: 1.93665
Value Function Loss: 0.02489

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07111
Policy Update Magnitude: 0.30165
Value Function Update Magnitude: 0.34342

Collected Steps per Second: 20,194.04727
Overall Steps per Second: 10,011.55826

Timestep Collection Time: 2.47707
Timestep Consumption Time: 2.51936
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.99643

Cumulative Model Updates: 222,312
Cumulative Timesteps: 1,854,694,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1854694610...
Checkpoint 1854694610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,390.80161
Policy Entropy: 1.94453
Value Function Loss: 0.02498

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07102
Policy Update Magnitude: 0.30106
Value Function Update Magnitude: 0.35272

Collected Steps per Second: 20,528.46007
Overall Steps per Second: 10,025.63104

Timestep Collection Time: 2.43603
Timestep Consumption Time: 2.55198
PPO Batch Consumption Time: 0.29762
Total Iteration Time: 4.98802

Cumulative Model Updates: 222,318
Cumulative Timesteps: 1,854,744,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,099.72167
Policy Entropy: 1.93802
Value Function Loss: 0.02403

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.06977
Policy Update Magnitude: 0.29453
Value Function Update Magnitude: 0.34709

Collected Steps per Second: 20,972.39667
Overall Steps per Second: 10,216.02216

Timestep Collection Time: 2.38494
Timestep Consumption Time: 2.51109
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.89603

Cumulative Model Updates: 222,324
Cumulative Timesteps: 1,854,794,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1854794636...
Checkpoint 1854794636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,637.75155
Policy Entropy: 1.91454
Value Function Loss: 0.02384

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07441
Policy Update Magnitude: 0.29437
Value Function Update Magnitude: 0.33123

Collected Steps per Second: 20,464.09058
Overall Steps per Second: 10,004.63965

Timestep Collection Time: 2.44399
Timestep Consumption Time: 2.55509
PPO Batch Consumption Time: 0.29840
Total Iteration Time: 4.99908

Cumulative Model Updates: 222,330
Cumulative Timesteps: 1,854,844,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,308.84230
Policy Entropy: 1.90711
Value Function Loss: 0.02538

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07895
Policy Update Magnitude: 0.29889
Value Function Update Magnitude: 0.33249

Collected Steps per Second: 20,666.22079
Overall Steps per Second: 9,984.30117

Timestep Collection Time: 2.42037
Timestep Consumption Time: 2.58949
PPO Batch Consumption Time: 0.30014
Total Iteration Time: 5.00986

Cumulative Model Updates: 222,336
Cumulative Timesteps: 1,854,894,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1854894670...
Checkpoint 1854894670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,596.12276
Policy Entropy: 1.91220
Value Function Loss: 0.02510

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07570
Policy Update Magnitude: 0.30294
Value Function Update Magnitude: 0.34947

Collected Steps per Second: 20,386.80816
Overall Steps per Second: 10,096.43849

Timestep Collection Time: 2.45384
Timestep Consumption Time: 2.50097
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.95482

Cumulative Model Updates: 222,342
Cumulative Timesteps: 1,854,944,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,945.06677
Policy Entropy: 1.92687
Value Function Loss: 0.02530

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07665
Policy Update Magnitude: 0.30327
Value Function Update Magnitude: 0.34447

Collected Steps per Second: 20,844.24701
Overall Steps per Second: 10,080.73801

Timestep Collection Time: 2.39970
Timestep Consumption Time: 2.56224
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.96194

Cumulative Model Updates: 222,348
Cumulative Timesteps: 1,854,994,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1854994716...
Checkpoint 1854994716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,797.75547
Policy Entropy: 1.94434
Value Function Loss: 0.02580

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07522
Policy Update Magnitude: 0.30044
Value Function Update Magnitude: 0.32921

Collected Steps per Second: 20,374.61635
Overall Steps per Second: 9,989.01153

Timestep Collection Time: 2.45413
Timestep Consumption Time: 2.55157
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 5.00570

Cumulative Model Updates: 222,354
Cumulative Timesteps: 1,855,044,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,581.15883
Policy Entropy: 1.95026
Value Function Loss: 0.02518

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07322
Policy Update Magnitude: 0.29936
Value Function Update Magnitude: 0.31034

Collected Steps per Second: 20,790.68382
Overall Steps per Second: 10,194.80536

Timestep Collection Time: 2.40502
Timestep Consumption Time: 2.49964
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.90465

Cumulative Model Updates: 222,360
Cumulative Timesteps: 1,855,094,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1855094720...
Checkpoint 1855094720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,430.13345
Policy Entropy: 1.93222
Value Function Loss: 0.02624

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06946
Policy Update Magnitude: 0.29909
Value Function Update Magnitude: 0.29674

Collected Steps per Second: 20,039.14652
Overall Steps per Second: 10,185.49454

Timestep Collection Time: 2.49631
Timestep Consumption Time: 2.41498
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.91130

Cumulative Model Updates: 222,366
Cumulative Timesteps: 1,855,144,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,011.55658
Policy Entropy: 1.91258
Value Function Loss: 0.02394

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07105
Policy Update Magnitude: 0.30130
Value Function Update Magnitude: 0.29799

Collected Steps per Second: 20,218.01550
Overall Steps per Second: 10,131.99981

Timestep Collection Time: 2.47383
Timestep Consumption Time: 2.46261
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.93644

Cumulative Model Updates: 222,372
Cumulative Timesteps: 1,855,194,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1855194760...
Checkpoint 1855194760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,812.81944
Policy Entropy: 1.91559
Value Function Loss: 0.02546

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.07781
Policy Update Magnitude: 0.29829
Value Function Update Magnitude: 0.26058

Collected Steps per Second: 19,782.84911
Overall Steps per Second: 10,091.88886

Timestep Collection Time: 2.52795
Timestep Consumption Time: 2.42752
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.95546

Cumulative Model Updates: 222,378
Cumulative Timesteps: 1,855,244,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,350.05082
Policy Entropy: 1.91052
Value Function Loss: 0.02301

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06918
Policy Update Magnitude: 0.28796
Value Function Update Magnitude: 0.23623

Collected Steps per Second: 20,484.17513
Overall Steps per Second: 10,169.09757

Timestep Collection Time: 2.44296
Timestep Consumption Time: 2.47803
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.92099

Cumulative Model Updates: 222,384
Cumulative Timesteps: 1,855,294,812

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1855294812...
Checkpoint 1855294812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,330.80766
Policy Entropy: 1.89930
Value Function Loss: 0.02749

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.07090
Policy Update Magnitude: 0.29432
Value Function Update Magnitude: 0.23735

Collected Steps per Second: 19,880.88478
Overall Steps per Second: 9,868.61151

Timestep Collection Time: 2.51629
Timestep Consumption Time: 2.55292
PPO Batch Consumption Time: 0.30202
Total Iteration Time: 5.06920

Cumulative Model Updates: 222,390
Cumulative Timesteps: 1,855,344,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,812.38998
Policy Entropy: 1.88697
Value Function Loss: 0.02793

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07159
Policy Update Magnitude: 0.30678
Value Function Update Magnitude: 0.29581

Collected Steps per Second: 20,802.73048
Overall Steps per Second: 10,126.83759

Timestep Collection Time: 2.40392
Timestep Consumption Time: 2.53425
PPO Batch Consumption Time: 0.29745
Total Iteration Time: 4.93817

Cumulative Model Updates: 222,396
Cumulative Timesteps: 1,855,394,846

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1855394846...
Checkpoint 1855394846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,158.95040
Policy Entropy: 1.90600
Value Function Loss: 0.03027

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07665
Policy Update Magnitude: 0.30806
Value Function Update Magnitude: 0.32596

Collected Steps per Second: 20,753.08275
Overall Steps per Second: 10,065.65839

Timestep Collection Time: 2.41034
Timestep Consumption Time: 2.55923
PPO Batch Consumption Time: 0.30133
Total Iteration Time: 4.96957

Cumulative Model Updates: 222,402
Cumulative Timesteps: 1,855,444,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,152.88481
Policy Entropy: 1.91464
Value Function Loss: 0.02788

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07672
Policy Update Magnitude: 0.30748
Value Function Update Magnitude: 0.32569

Collected Steps per Second: 20,877.68593
Overall Steps per Second: 10,035.25138

Timestep Collection Time: 2.39576
Timestep Consumption Time: 2.58847
PPO Batch Consumption Time: 0.30112
Total Iteration Time: 4.98423

Cumulative Model Updates: 222,408
Cumulative Timesteps: 1,855,494,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1855494886...
Checkpoint 1855494886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,859.48516
Policy Entropy: 1.92203
Value Function Loss: 0.02995

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07674
Policy Update Magnitude: 0.30795
Value Function Update Magnitude: 0.29681

Collected Steps per Second: 20,748.02582
Overall Steps per Second: 10,155.36209

Timestep Collection Time: 2.41045
Timestep Consumption Time: 2.51424
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.92469

Cumulative Model Updates: 222,414
Cumulative Timesteps: 1,855,544,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,401.20654
Policy Entropy: 1.91576
Value Function Loss: 0.02639

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07572
Policy Update Magnitude: 0.30217
Value Function Update Magnitude: 0.26563

Collected Steps per Second: 21,017.67156
Overall Steps per Second: 10,076.93015

Timestep Collection Time: 2.38028
Timestep Consumption Time: 2.58432
PPO Batch Consumption Time: 0.29970
Total Iteration Time: 4.96461

Cumulative Model Updates: 222,420
Cumulative Timesteps: 1,855,594,926

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1855594926...
Checkpoint 1855594926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,513.56518
Policy Entropy: 1.91963
Value Function Loss: 0.02561

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.29772
Value Function Update Magnitude: 0.29167

Collected Steps per Second: 20,475.10911
Overall Steps per Second: 10,094.05451

Timestep Collection Time: 2.44404
Timestep Consumption Time: 2.51353
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.95757

Cumulative Model Updates: 222,426
Cumulative Timesteps: 1,855,644,968

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,560.40884
Policy Entropy: 1.91463
Value Function Loss: 0.02565

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07763
Policy Update Magnitude: 0.29327
Value Function Update Magnitude: 0.32157

Collected Steps per Second: 18,353.89516
Overall Steps per Second: 9,784.90766

Timestep Collection Time: 2.72585
Timestep Consumption Time: 2.38712
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 5.11298

Cumulative Model Updates: 222,432
Cumulative Timesteps: 1,855,694,998

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1855694998...
Checkpoint 1855694998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,970.65074
Policy Entropy: 1.91898
Value Function Loss: 0.02562

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07253
Policy Update Magnitude: 0.29437
Value Function Update Magnitude: 0.32815

Collected Steps per Second: 20,203.29582
Overall Steps per Second: 10,011.14045

Timestep Collection Time: 2.47692
Timestep Consumption Time: 2.52171
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.99863

Cumulative Model Updates: 222,438
Cumulative Timesteps: 1,855,745,040

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,500.90531
Policy Entropy: 1.92081
Value Function Loss: 0.02491

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07173
Policy Update Magnitude: 0.29235
Value Function Update Magnitude: 0.32217

Collected Steps per Second: 22,130.08970
Overall Steps per Second: 10,638.44379

Timestep Collection Time: 2.26063
Timestep Consumption Time: 2.44193
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.70257

Cumulative Model Updates: 222,444
Cumulative Timesteps: 1,855,795,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1855795068...
Checkpoint 1855795068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,420.98407
Policy Entropy: 1.91679
Value Function Loss: 0.02438

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07243
Policy Update Magnitude: 0.29197
Value Function Update Magnitude: 0.33467

Collected Steps per Second: 21,132.48893
Overall Steps per Second: 10,235.58779

Timestep Collection Time: 2.36640
Timestep Consumption Time: 2.51930
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.88570

Cumulative Model Updates: 222,450
Cumulative Timesteps: 1,855,845,076

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,690.49172
Policy Entropy: 1.90359
Value Function Loss: 0.02428

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07559
Policy Update Magnitude: 0.29521
Value Function Update Magnitude: 0.35075

Collected Steps per Second: 21,762.10295
Overall Steps per Second: 10,550.95373

Timestep Collection Time: 2.29840
Timestep Consumption Time: 2.44221
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.74061

Cumulative Model Updates: 222,456
Cumulative Timesteps: 1,855,895,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1855895094...
Checkpoint 1855895094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,403.75787
Policy Entropy: 1.90508
Value Function Loss: 0.02620

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07284
Policy Update Magnitude: 0.30104
Value Function Update Magnitude: 0.32454

Collected Steps per Second: 21,344.05420
Overall Steps per Second: 10,336.64194

Timestep Collection Time: 2.34379
Timestep Consumption Time: 2.49589
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.83968

Cumulative Model Updates: 222,462
Cumulative Timesteps: 1,855,945,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,457.11190
Policy Entropy: 1.89545
Value Function Loss: 0.02464

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.07603
Policy Update Magnitude: 0.29795
Value Function Update Magnitude: 0.32413

Collected Steps per Second: 22,180.43339
Overall Steps per Second: 10,635.31830

Timestep Collection Time: 2.25451
Timestep Consumption Time: 2.44737
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.70188

Cumulative Model Updates: 222,468
Cumulative Timesteps: 1,855,995,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1855995126...
Checkpoint 1855995126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,777.99223
Policy Entropy: 1.89943
Value Function Loss: 0.02318

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.29156
Value Function Update Magnitude: 0.33463

Collected Steps per Second: 21,425.09478
Overall Steps per Second: 10,285.28537

Timestep Collection Time: 2.33455
Timestep Consumption Time: 2.52851
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.86306

Cumulative Model Updates: 222,474
Cumulative Timesteps: 1,856,045,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,475.85799
Policy Entropy: 1.89839
Value Function Loss: 0.02409

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08255
Policy Update Magnitude: 0.28782
Value Function Update Magnitude: 0.31977

Collected Steps per Second: 22,061.04774
Overall Steps per Second: 10,443.44881

Timestep Collection Time: 2.26716
Timestep Consumption Time: 2.52206
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.78922

Cumulative Model Updates: 222,480
Cumulative Timesteps: 1,856,095,160

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1856095160...
Checkpoint 1856095160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,237.70100
Policy Entropy: 1.90605
Value Function Loss: 0.02413

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07288
Policy Update Magnitude: 0.29449
Value Function Update Magnitude: 0.32100

Collected Steps per Second: 21,646.96168
Overall Steps per Second: 10,411.20644

Timestep Collection Time: 2.31062
Timestep Consumption Time: 2.49362
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.80425

Cumulative Model Updates: 222,486
Cumulative Timesteps: 1,856,145,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,214.22471
Policy Entropy: 1.91756
Value Function Loss: 0.02523

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07494
Policy Update Magnitude: 0.29494
Value Function Update Magnitude: 0.32586

Collected Steps per Second: 21,578.91663
Overall Steps per Second: 10,370.29188

Timestep Collection Time: 2.31856
Timestep Consumption Time: 2.50599
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.82455

Cumulative Model Updates: 222,492
Cumulative Timesteps: 1,856,195,210

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1856195210...
Checkpoint 1856195210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,451.79469
Policy Entropy: 1.91730
Value Function Loss: 0.02491

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.30063
Value Function Update Magnitude: 0.31770

Collected Steps per Second: 21,498.58833
Overall Steps per Second: 10,480.99918

Timestep Collection Time: 2.32732
Timestep Consumption Time: 2.44647
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.77378

Cumulative Model Updates: 222,498
Cumulative Timesteps: 1,856,245,244

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,616.76919
Policy Entropy: 1.92009
Value Function Loss: 0.02574

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.30855
Value Function Update Magnitude: 0.33708

Collected Steps per Second: 21,796.94704
Overall Steps per Second: 10,367.32396

Timestep Collection Time: 2.29500
Timestep Consumption Time: 2.53016
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.82516

Cumulative Model Updates: 222,504
Cumulative Timesteps: 1,856,295,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1856295268...
Checkpoint 1856295268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,075.12278
Policy Entropy: 1.91675
Value Function Loss: 0.02468

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.07956
Policy Update Magnitude: 0.30961
Value Function Update Magnitude: 0.34640

Collected Steps per Second: 21,361.79796
Overall Steps per Second: 10,344.66515

Timestep Collection Time: 2.34081
Timestep Consumption Time: 2.49298
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.83380

Cumulative Model Updates: 222,510
Cumulative Timesteps: 1,856,345,272

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,555.89411
Policy Entropy: 1.90678
Value Function Loss: 0.02530

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07342
Policy Update Magnitude: 0.30444
Value Function Update Magnitude: 0.34338

Collected Steps per Second: 21,949.06311
Overall Steps per Second: 10,406.51484

Timestep Collection Time: 2.27818
Timestep Consumption Time: 2.52688
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.80507

Cumulative Model Updates: 222,516
Cumulative Timesteps: 1,856,395,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1856395276...
Checkpoint 1856395276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,130.62610
Policy Entropy: 1.90829
Value Function Loss: 0.02130

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07193
Policy Update Magnitude: 0.29915
Value Function Update Magnitude: 0.33417

Collected Steps per Second: 21,240.75621
Overall Steps per Second: 10,253.49135

Timestep Collection Time: 2.35500
Timestep Consumption Time: 2.52353
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.87853

Cumulative Model Updates: 222,522
Cumulative Timesteps: 1,856,445,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,243.18791
Policy Entropy: 1.90500
Value Function Loss: 0.02210

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07257
Policy Update Magnitude: 0.29087
Value Function Update Magnitude: 0.32453

Collected Steps per Second: 21,468.70703
Overall Steps per Second: 10,470.75294

Timestep Collection Time: 2.32916
Timestep Consumption Time: 2.44643
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.77559

Cumulative Model Updates: 222,528
Cumulative Timesteps: 1,856,495,302

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1856495302...
Checkpoint 1856495302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,890.58433
Policy Entropy: 1.91697
Value Function Loss: 0.02246

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.07004
Policy Update Magnitude: 0.29577
Value Function Update Magnitude: 0.31737

Collected Steps per Second: 20,924.60734
Overall Steps per Second: 10,510.73512

Timestep Collection Time: 2.38953
Timestep Consumption Time: 2.36751
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.75704

Cumulative Model Updates: 222,534
Cumulative Timesteps: 1,856,545,302

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,927.46782
Policy Entropy: 1.92209
Value Function Loss: 0.02544

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.30208
Value Function Update Magnitude: 0.33828

Collected Steps per Second: 21,185.00773
Overall Steps per Second: 10,570.10393

Timestep Collection Time: 2.36120
Timestep Consumption Time: 2.37121
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.73240

Cumulative Model Updates: 222,540
Cumulative Timesteps: 1,856,595,324

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1856595324...
Checkpoint 1856595324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,521.01786
Policy Entropy: 1.91401
Value Function Loss: 0.02396

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.30015
Value Function Update Magnitude: 0.35246

Collected Steps per Second: 21,044.22687
Overall Steps per Second: 10,543.29729

Timestep Collection Time: 2.37661
Timestep Consumption Time: 2.36706
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.74368

Cumulative Model Updates: 222,546
Cumulative Timesteps: 1,856,645,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,641.96252
Policy Entropy: 1.91654
Value Function Loss: 0.02258

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.29561
Value Function Update Magnitude: 0.34794

Collected Steps per Second: 21,348.13626
Overall Steps per Second: 10,495.61294

Timestep Collection Time: 2.34231
Timestep Consumption Time: 2.42196
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.76428

Cumulative Model Updates: 222,552
Cumulative Timesteps: 1,856,695,342

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1856695342...
Checkpoint 1856695342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,304.26049
Policy Entropy: 1.90591
Value Function Loss: 0.02351

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.08610
Policy Update Magnitude: 0.29669
Value Function Update Magnitude: 0.33264

Collected Steps per Second: 20,882.06148
Overall Steps per Second: 10,202.38365

Timestep Collection Time: 2.39526
Timestep Consumption Time: 2.50732
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.90258

Cumulative Model Updates: 222,558
Cumulative Timesteps: 1,856,745,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,475.87223
Policy Entropy: 1.91917
Value Function Loss: 0.02228

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.29458
Value Function Update Magnitude: 0.34082

Collected Steps per Second: 21,645.57510
Overall Steps per Second: 10,451.53995

Timestep Collection Time: 2.31133
Timestep Consumption Time: 2.47553
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.78685

Cumulative Model Updates: 222,564
Cumulative Timesteps: 1,856,795,390

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1856795390...
Checkpoint 1856795390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,034.73905
Policy Entropy: 1.89621
Value Function Loss: 0.02261

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07685
Policy Update Magnitude: 0.28709
Value Function Update Magnitude: 0.32731

Collected Steps per Second: 21,502.11209
Overall Steps per Second: 10,558.77696

Timestep Collection Time: 2.32693
Timestep Consumption Time: 2.41168
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.73862

Cumulative Model Updates: 222,570
Cumulative Timesteps: 1,856,845,424

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,487.64273
Policy Entropy: 1.89532
Value Function Loss: 0.02527

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07122
Policy Update Magnitude: 0.29549
Value Function Update Magnitude: 0.31350

Collected Steps per Second: 21,672.20813
Overall Steps per Second: 10,610.11356

Timestep Collection Time: 2.30793
Timestep Consumption Time: 2.40625
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.71418

Cumulative Model Updates: 222,576
Cumulative Timesteps: 1,856,895,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1856895442...
Checkpoint 1856895442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,005.08303
Policy Entropy: 1.88756
Value Function Loss: 0.02663

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.30406
Value Function Update Magnitude: 0.32800

Collected Steps per Second: 21,661.37161
Overall Steps per Second: 10,362.12362

Timestep Collection Time: 2.30973
Timestep Consumption Time: 2.51862
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.82835

Cumulative Model Updates: 222,582
Cumulative Timesteps: 1,856,945,474

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,300.91144
Policy Entropy: 1.90009
Value Function Loss: 0.03156

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08039
Policy Update Magnitude: 0.31263
Value Function Update Magnitude: 0.35208

Collected Steps per Second: 21,951.19146
Overall Steps per Second: 10,569.11655

Timestep Collection Time: 2.27787
Timestep Consumption Time: 2.45308
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.73095

Cumulative Model Updates: 222,588
Cumulative Timesteps: 1,856,995,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1856995476...
Checkpoint 1856995476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,084.04324
Policy Entropy: 1.90669
Value Function Loss: 0.02900

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.31221
Value Function Update Magnitude: 0.38772

Collected Steps per Second: 21,217.95329
Overall Steps per Second: 10,300.59729

Timestep Collection Time: 2.35687
Timestep Consumption Time: 2.49799
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.85486

Cumulative Model Updates: 222,594
Cumulative Timesteps: 1,857,045,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,598.26050
Policy Entropy: 1.90002
Value Function Loss: 0.02740

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.07930
Policy Update Magnitude: 0.30206
Value Function Update Magnitude: 0.38799

Collected Steps per Second: 22,067.19422
Overall Steps per Second: 10,472.32342

Timestep Collection Time: 2.26789
Timestep Consumption Time: 2.51099
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.77888

Cumulative Model Updates: 222,600
Cumulative Timesteps: 1,857,095,530

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1857095530...
Checkpoint 1857095530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,230.73888
Policy Entropy: 1.88635
Value Function Loss: 0.02324

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07401
Policy Update Magnitude: 0.29488
Value Function Update Magnitude: 0.34143

Collected Steps per Second: 21,460.56057
Overall Steps per Second: 10,362.28471

Timestep Collection Time: 2.33088
Timestep Consumption Time: 2.49643
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.82731

Cumulative Model Updates: 222,606
Cumulative Timesteps: 1,857,145,552

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,758.65887
Policy Entropy: 1.88922
Value Function Loss: 0.02328

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06983
Policy Update Magnitude: 0.29233
Value Function Update Magnitude: 0.30640

Collected Steps per Second: 21,999.43226
Overall Steps per Second: 10,486.11727

Timestep Collection Time: 2.27497
Timestep Consumption Time: 2.49782
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.77279

Cumulative Model Updates: 222,612
Cumulative Timesteps: 1,857,195,600

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1857195600...
Checkpoint 1857195600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,262.84200
Policy Entropy: 1.90565
Value Function Loss: 0.02276

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07336
Policy Update Magnitude: 0.29385
Value Function Update Magnitude: 0.30879

Collected Steps per Second: 21,711.82242
Overall Steps per Second: 10,419.98585

Timestep Collection Time: 2.30335
Timestep Consumption Time: 2.49608
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.79943

Cumulative Model Updates: 222,618
Cumulative Timesteps: 1,857,245,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,771.89528
Policy Entropy: 1.91166
Value Function Loss: 0.02530

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.06976
Policy Update Magnitude: 0.29754
Value Function Update Magnitude: 0.32835

Collected Steps per Second: 21,927.61144
Overall Steps per Second: 10,451.53131

Timestep Collection Time: 2.28105
Timestep Consumption Time: 2.50466
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.78571

Cumulative Model Updates: 222,624
Cumulative Timesteps: 1,857,295,628

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1857295628...
Checkpoint 1857295628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,236.09137
Policy Entropy: 1.91013
Value Function Loss: 0.02712

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.30165
Value Function Update Magnitude: 0.35047

Collected Steps per Second: 21,824.08903
Overall Steps per Second: 10,482.84205

Timestep Collection Time: 2.29242
Timestep Consumption Time: 2.48014
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.77256

Cumulative Model Updates: 222,630
Cumulative Timesteps: 1,857,345,658

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,282.76889
Policy Entropy: 1.90072
Value Function Loss: 0.02708

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.30091
Value Function Update Magnitude: 0.35524

Collected Steps per Second: 21,407.68177
Overall Steps per Second: 10,470.98936

Timestep Collection Time: 2.33636
Timestep Consumption Time: 2.44027
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.77663

Cumulative Model Updates: 222,636
Cumulative Timesteps: 1,857,395,674

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1857395674...
Checkpoint 1857395674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,272.20700
Policy Entropy: 1.91655
Value Function Loss: 0.02540

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.29631
Value Function Update Magnitude: 0.34231

Collected Steps per Second: 20,918.13562
Overall Steps per Second: 10,535.09376

Timestep Collection Time: 2.39132
Timestep Consumption Time: 2.35681
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.74813

Cumulative Model Updates: 222,642
Cumulative Timesteps: 1,857,445,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,099.69844
Policy Entropy: 1.91598
Value Function Loss: 0.02574

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.30114
Value Function Update Magnitude: 0.30816

Collected Steps per Second: 21,231.92720
Overall Steps per Second: 10,593.87369

Timestep Collection Time: 2.35579
Timestep Consumption Time: 2.36562
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.72141

Cumulative Model Updates: 222,648
Cumulative Timesteps: 1,857,495,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1857495714...
Checkpoint 1857495714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,574.60518
Policy Entropy: 1.92374
Value Function Loss: 0.02582

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.29803
Value Function Update Magnitude: 0.30216

Collected Steps per Second: 21,012.29952
Overall Steps per Second: 10,290.14032

Timestep Collection Time: 2.38061
Timestep Consumption Time: 2.48055
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.86116

Cumulative Model Updates: 222,654
Cumulative Timesteps: 1,857,545,736

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,560.31469
Policy Entropy: 1.91207
Value Function Loss: 0.02384

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07125
Policy Update Magnitude: 0.28961
Value Function Update Magnitude: 0.30962

Collected Steps per Second: 22,014.87869
Overall Steps per Second: 10,465.01775

Timestep Collection Time: 2.27146
Timestep Consumption Time: 2.50693
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.77840

Cumulative Model Updates: 222,660
Cumulative Timesteps: 1,857,595,742

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1857595742...
Checkpoint 1857595742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,047.83420
Policy Entropy: 1.89335
Value Function Loss: 0.02301

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06830
Policy Update Magnitude: 0.28316
Value Function Update Magnitude: 0.27178

Collected Steps per Second: 21,248.25311
Overall Steps per Second: 10,390.55356

Timestep Collection Time: 2.35455
Timestep Consumption Time: 2.46040
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.81495

Cumulative Model Updates: 222,666
Cumulative Timesteps: 1,857,645,772

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,616.21264
Policy Entropy: 1.87936
Value Function Loss: 0.02387

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07374
Policy Update Magnitude: 0.29182
Value Function Update Magnitude: 0.26842

Collected Steps per Second: 21,815.47718
Overall Steps per Second: 10,548.59213

Timestep Collection Time: 2.29397
Timestep Consumption Time: 2.45017
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.74414

Cumulative Model Updates: 222,672
Cumulative Timesteps: 1,857,695,816

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1857695816...
Checkpoint 1857695816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,515.92570
Policy Entropy: 1.88776
Value Function Loss: 0.02465

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07442
Policy Update Magnitude: 0.29395
Value Function Update Magnitude: 0.26644

Collected Steps per Second: 21,200.37345
Overall Steps per Second: 10,301.73519

Timestep Collection Time: 2.35939
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.85549

Cumulative Model Updates: 222,678
Cumulative Timesteps: 1,857,745,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,924.66796
Policy Entropy: 1.90206
Value Function Loss: 0.02407

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07529
Policy Update Magnitude: 0.28743
Value Function Update Magnitude: 0.27195

Collected Steps per Second: 22,028.96529
Overall Steps per Second: 10,432.81783

Timestep Collection Time: 2.27083
Timestep Consumption Time: 2.52404
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.79487

Cumulative Model Updates: 222,684
Cumulative Timesteps: 1,857,795,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1857795860...
Checkpoint 1857795860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,957.83282
Policy Entropy: 1.90804
Value Function Loss: 0.02282

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07119
Policy Update Magnitude: 0.28537
Value Function Update Magnitude: 0.29830

Collected Steps per Second: 21,759.33364
Overall Steps per Second: 10,525.20637

Timestep Collection Time: 2.29796
Timestep Consumption Time: 2.45273
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.75069

Cumulative Model Updates: 222,690
Cumulative Timesteps: 1,857,845,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,617.46185
Policy Entropy: 1.90019
Value Function Loss: 0.02388

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07010
Policy Update Magnitude: 0.28997
Value Function Update Magnitude: 0.29903

Collected Steps per Second: 21,957.91737
Overall Steps per Second: 10,499.41861

Timestep Collection Time: 2.27808
Timestep Consumption Time: 2.48618
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.76426

Cumulative Model Updates: 222,696
Cumulative Timesteps: 1,857,895,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1857895884...
Checkpoint 1857895884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,549.45111
Policy Entropy: 1.90141
Value Function Loss: 0.02366

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07374
Policy Update Magnitude: 0.29175
Value Function Update Magnitude: 0.32658

Collected Steps per Second: 21,355.01823
Overall Steps per Second: 10,285.67780

Timestep Collection Time: 2.34146
Timestep Consumption Time: 2.51986
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.86132

Cumulative Model Updates: 222,702
Cumulative Timesteps: 1,857,945,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,805.86357
Policy Entropy: 1.90433
Value Function Loss: 0.02283

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.29187
Value Function Update Magnitude: 0.31022

Collected Steps per Second: 21,877.69174
Overall Steps per Second: 10,404.53258

Timestep Collection Time: 2.28616
Timestep Consumption Time: 2.52097
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.80714

Cumulative Model Updates: 222,708
Cumulative Timesteps: 1,857,995,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1857995902...
Checkpoint 1857995902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,480.87966
Policy Entropy: 1.90319
Value Function Loss: 0.02265

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.08589
Policy Update Magnitude: 0.29050
Value Function Update Magnitude: 0.26727

Collected Steps per Second: 21,482.95246
Overall Steps per Second: 10,339.76126

Timestep Collection Time: 2.32845
Timestep Consumption Time: 2.50938
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.83783

Cumulative Model Updates: 222,714
Cumulative Timesteps: 1,858,045,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,733.04480
Policy Entropy: 1.90356
Value Function Loss: 0.02423

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.08872
Policy Update Magnitude: 0.29686
Value Function Update Magnitude: 0.19569

Collected Steps per Second: 22,274.17541
Overall Steps per Second: 10,674.47114

Timestep Collection Time: 2.24574
Timestep Consumption Time: 2.44039
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.68613

Cumulative Model Updates: 222,720
Cumulative Timesteps: 1,858,095,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1858095946...
Checkpoint 1858095946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,328.75735
Policy Entropy: 1.90258
Value Function Loss: 0.02535

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.08910
Policy Update Magnitude: 0.29699
Value Function Update Magnitude: 0.22978

Collected Steps per Second: 21,183.89314
Overall Steps per Second: 10,236.74415

Timestep Collection Time: 2.36104
Timestep Consumption Time: 2.52489
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.88593

Cumulative Model Updates: 222,726
Cumulative Timesteps: 1,858,145,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,343.57824
Policy Entropy: 1.90492
Value Function Loss: 0.02715

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.08870
Policy Update Magnitude: 0.29934
Value Function Update Magnitude: 0.22864

Collected Steps per Second: 21,993.61058
Overall Steps per Second: 10,433.53243

Timestep Collection Time: 2.27357
Timestep Consumption Time: 2.51905
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.79262

Cumulative Model Updates: 222,732
Cumulative Timesteps: 1,858,195,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1858195966...
Checkpoint 1858195966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,970.04057
Policy Entropy: 1.89495
Value Function Loss: 0.02446

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.29604
Value Function Update Magnitude: 0.21966

Collected Steps per Second: 21,582.21526
Overall Steps per Second: 10,263.84233

Timestep Collection Time: 2.31830
Timestep Consumption Time: 2.55648
PPO Batch Consumption Time: 0.30177
Total Iteration Time: 4.87478

Cumulative Model Updates: 222,738
Cumulative Timesteps: 1,858,246,000

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,320.98775
Policy Entropy: 1.89316
Value Function Loss: 0.02262

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.28849
Value Function Update Magnitude: 0.22806

Collected Steps per Second: 21,258.01950
Overall Steps per Second: 10,449.31774

Timestep Collection Time: 2.35384
Timestep Consumption Time: 2.43480
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.78864

Cumulative Model Updates: 222,744
Cumulative Timesteps: 1,858,296,038

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1858296038...
Checkpoint 1858296038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,518.53472
Policy Entropy: 1.89260
Value Function Loss: 0.01962

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07326
Policy Update Magnitude: 0.27892
Value Function Update Magnitude: 0.21587

Collected Steps per Second: 20,599.35361
Overall Steps per Second: 10,319.44018

Timestep Collection Time: 2.42755
Timestep Consumption Time: 2.41825
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.84581

Cumulative Model Updates: 222,750
Cumulative Timesteps: 1,858,346,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,351.29969
Policy Entropy: 1.88573
Value Function Loss: 0.02047

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06578
Policy Update Magnitude: 0.27913
Value Function Update Magnitude: 0.22015

Collected Steps per Second: 21,371.28452
Overall Steps per Second: 10,324.00914

Timestep Collection Time: 2.34165
Timestep Consumption Time: 2.50569
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.84734

Cumulative Model Updates: 222,756
Cumulative Timesteps: 1,858,396,088

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1858396088...
Checkpoint 1858396088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,334.25436
Policy Entropy: 1.87229
Value Function Loss: 0.02105

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06771
Policy Update Magnitude: 0.28113
Value Function Update Magnitude: 0.26944

Collected Steps per Second: 21,397.47784
Overall Steps per Second: 10,518.49357

Timestep Collection Time: 2.33672
Timestep Consumption Time: 2.41681
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.75353

Cumulative Model Updates: 222,762
Cumulative Timesteps: 1,858,446,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,571.77419
Policy Entropy: 1.86864
Value Function Loss: 0.02458

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.29156
Value Function Update Magnitude: 0.30277

Collected Steps per Second: 21,727.30040
Overall Steps per Second: 10,598.46715

Timestep Collection Time: 2.30199
Timestep Consumption Time: 2.41718
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.71917

Cumulative Model Updates: 222,768
Cumulative Timesteps: 1,858,496,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1858496104...
Checkpoint 1858496104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,291.65391
Policy Entropy: 1.87330
Value Function Loss: 0.02498

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07571
Policy Update Magnitude: 0.29839
Value Function Update Magnitude: 0.28124

Collected Steps per Second: 21,561.26911
Overall Steps per Second: 10,558.30855

Timestep Collection Time: 2.32046
Timestep Consumption Time: 2.41818
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.73864

Cumulative Model Updates: 222,774
Cumulative Timesteps: 1,858,546,136

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,174.21106
Policy Entropy: 1.87901
Value Function Loss: 0.02589

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07733
Policy Update Magnitude: 0.30044
Value Function Update Magnitude: 0.29029

Collected Steps per Second: 21,735.02387
Overall Steps per Second: 10,525.38321

Timestep Collection Time: 2.30172
Timestep Consumption Time: 2.45136
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.75308

Cumulative Model Updates: 222,780
Cumulative Timesteps: 1,858,596,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1858596164...
Checkpoint 1858596164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,016.90030
Policy Entropy: 1.88974
Value Function Loss: 0.02546

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.30455
Value Function Update Magnitude: 0.29390

Collected Steps per Second: 21,420.19829
Overall Steps per Second: 10,325.87527

Timestep Collection Time: 2.33527
Timestep Consumption Time: 2.50906
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.84434

Cumulative Model Updates: 222,786
Cumulative Timesteps: 1,858,646,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,132.96383
Policy Entropy: 1.88495
Value Function Loss: 0.02573

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.30363
Value Function Update Magnitude: 0.26672

Collected Steps per Second: 22,067.14804
Overall Steps per Second: 10,625.02947

Timestep Collection Time: 2.26581
Timestep Consumption Time: 2.44006
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.70587

Cumulative Model Updates: 222,792
Cumulative Timesteps: 1,858,696,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1858696186...
Checkpoint 1858696186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,285.17375
Policy Entropy: 1.88172
Value Function Loss: 0.02449

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.29297
Value Function Update Magnitude: 0.23663

Collected Steps per Second: 21,649.34101
Overall Steps per Second: 10,367.86995

Timestep Collection Time: 2.31065
Timestep Consumption Time: 2.51426
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.82491

Cumulative Model Updates: 222,798
Cumulative Timesteps: 1,858,746,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,251.35300
Policy Entropy: 1.86744
Value Function Loss: 0.02343

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07010
Policy Update Magnitude: 0.29134
Value Function Update Magnitude: 0.25564

Collected Steps per Second: 21,813.60210
Overall Steps per Second: 10,348.66122

Timestep Collection Time: 2.29343
Timestep Consumption Time: 2.54082
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.83425

Cumulative Model Updates: 222,804
Cumulative Timesteps: 1,858,796,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1858796238...
Checkpoint 1858796238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,507.73086
Policy Entropy: 1.88127
Value Function Loss: 0.02348

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.06656
Policy Update Magnitude: 0.29067
Value Function Update Magnitude: 0.27221

Collected Steps per Second: 21,160.33379
Overall Steps per Second: 10,205.53818

Timestep Collection Time: 2.36414
Timestep Consumption Time: 2.53771
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.90185

Cumulative Model Updates: 222,810
Cumulative Timesteps: 1,858,846,264

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,000.31705
Policy Entropy: 1.88006
Value Function Loss: 0.02281

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.28592
Value Function Update Magnitude: 0.28962

Collected Steps per Second: 21,949.01807
Overall Steps per Second: 10,351.00681

Timestep Collection Time: 2.28010
Timestep Consumption Time: 2.55479
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.83489

Cumulative Model Updates: 222,816
Cumulative Timesteps: 1,858,896,310

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1858896310...
Checkpoint 1858896310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,625.14355
Policy Entropy: 1.87829
Value Function Loss: 0.02334

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.06980
Policy Update Magnitude: 0.28912
Value Function Update Magnitude: 0.29620

Collected Steps per Second: 21,068.36061
Overall Steps per Second: 10,326.48200

Timestep Collection Time: 2.37456
Timestep Consumption Time: 2.47008
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.84463

Cumulative Model Updates: 222,822
Cumulative Timesteps: 1,858,946,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,013.12340
Policy Entropy: 1.88460
Value Function Loss: 0.02201

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.29127
Value Function Update Magnitude: 0.30918

Collected Steps per Second: 21,707.08707
Overall Steps per Second: 10,425.02545

Timestep Collection Time: 2.30367
Timestep Consumption Time: 2.49306
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.79673

Cumulative Model Updates: 222,828
Cumulative Timesteps: 1,858,996,344

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1858996344...
Checkpoint 1858996344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,604.08434
Policy Entropy: 1.89410
Value Function Loss: 0.02215

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07322
Policy Update Magnitude: 0.29066
Value Function Update Magnitude: 0.31924

Collected Steps per Second: 21,485.24708
Overall Steps per Second: 10,306.83410

Timestep Collection Time: 2.32764
Timestep Consumption Time: 2.52448
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.85212

Cumulative Model Updates: 222,834
Cumulative Timesteps: 1,859,046,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,768.55692
Policy Entropy: 1.89845
Value Function Loss: 0.02202

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.06975
Policy Update Magnitude: 0.29526
Value Function Update Magnitude: 0.29997

Collected Steps per Second: 21,928.12787
Overall Steps per Second: 10,434.85219

Timestep Collection Time: 2.28127
Timestep Consumption Time: 2.51266
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.79393

Cumulative Model Updates: 222,840
Cumulative Timesteps: 1,859,096,378

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1859096378...
Checkpoint 1859096378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,657.23661
Policy Entropy: 1.88049
Value Function Loss: 0.02248

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07058
Policy Update Magnitude: 0.29055
Value Function Update Magnitude: 0.28054

Collected Steps per Second: 21,123.71810
Overall Steps per Second: 10,567.93835

Timestep Collection Time: 2.36720
Timestep Consumption Time: 2.36447
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.73167

Cumulative Model Updates: 222,846
Cumulative Timesteps: 1,859,146,382

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,272.22924
Policy Entropy: 1.89589
Value Function Loss: 0.02220

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.06767
Policy Update Magnitude: 0.28532
Value Function Update Magnitude: 0.28873

Collected Steps per Second: 20,797.93278
Overall Steps per Second: 10,459.93111

Timestep Collection Time: 2.40562
Timestep Consumption Time: 2.37758
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.78321

Cumulative Model Updates: 222,852
Cumulative Timesteps: 1,859,196,414

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1859196414...
Checkpoint 1859196414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,863.05815
Policy Entropy: 1.90138
Value Function Loss: 0.02163

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07126
Policy Update Magnitude: 0.28370
Value Function Update Magnitude: 0.25972

Collected Steps per Second: 21,013.22493
Overall Steps per Second: 10,413.95990

Timestep Collection Time: 2.37945
Timestep Consumption Time: 2.42179
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.80125

Cumulative Model Updates: 222,858
Cumulative Timesteps: 1,859,246,414

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,184.40406
Policy Entropy: 1.89945
Value Function Loss: 0.02208

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07082
Policy Update Magnitude: 0.28960
Value Function Update Magnitude: 0.23846

Collected Steps per Second: 21,418.19540
Overall Steps per Second: 10,677.09003

Timestep Collection Time: 2.33670
Timestep Consumption Time: 2.35071
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.68742

Cumulative Model Updates: 222,864
Cumulative Timesteps: 1,859,296,462

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1859296462...
Checkpoint 1859296462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,923.83428
Policy Entropy: 1.88847
Value Function Loss: 0.02429

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07859
Policy Update Magnitude: 0.29800
Value Function Update Magnitude: 0.28647

Collected Steps per Second: 20,901.69683
Overall Steps per Second: 10,231.78621

Timestep Collection Time: 2.39272
Timestep Consumption Time: 2.49518
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.88791

Cumulative Model Updates: 222,870
Cumulative Timesteps: 1,859,346,474

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,392.60923
Policy Entropy: 1.90056
Value Function Loss: 0.02632

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.08589
Policy Update Magnitude: 0.29747
Value Function Update Magnitude: 0.34052

Collected Steps per Second: 21,594.88988
Overall Steps per Second: 10,495.13280

Timestep Collection Time: 2.31675
Timestep Consumption Time: 2.45022
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.76697

Cumulative Model Updates: 222,876
Cumulative Timesteps: 1,859,396,504

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1859396504...
Checkpoint 1859396504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,017.90688
Policy Entropy: 1.88835
Value Function Loss: 0.02843

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.30436
Value Function Update Magnitude: 0.35897

Collected Steps per Second: 21,828.20349
Overall Steps per Second: 10,596.83158

Timestep Collection Time: 2.29089
Timestep Consumption Time: 2.42807
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.71896

Cumulative Model Updates: 222,882
Cumulative Timesteps: 1,859,446,510

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,658.31064
Policy Entropy: 1.89085
Value Function Loss: 0.02606

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.30819
Value Function Update Magnitude: 0.35330

Collected Steps per Second: 21,956.81613
Overall Steps per Second: 10,481.67932

Timestep Collection Time: 2.27938
Timestep Consumption Time: 2.49542
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.77481

Cumulative Model Updates: 222,888
Cumulative Timesteps: 1,859,496,558

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1859496558...
Checkpoint 1859496558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,996.08324
Policy Entropy: 1.87757
Value Function Loss: 0.02642

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.30576
Value Function Update Magnitude: 0.34223

Collected Steps per Second: 21,542.40539
Overall Steps per Second: 10,224.87907

Timestep Collection Time: 2.32221
Timestep Consumption Time: 2.57037
PPO Batch Consumption Time: 0.30029
Total Iteration Time: 4.89258

Cumulative Model Updates: 222,894
Cumulative Timesteps: 1,859,546,584

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,458.52661
Policy Entropy: 1.89915
Value Function Loss: 0.02620

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.31093
Value Function Update Magnitude: 0.32788

Collected Steps per Second: 21,510.80731
Overall Steps per Second: 10,471.46143

Timestep Collection Time: 2.32637
Timestep Consumption Time: 2.45253
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.77889

Cumulative Model Updates: 222,900
Cumulative Timesteps: 1,859,596,626

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1859596626...
Checkpoint 1859596626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,217.64442
Policy Entropy: 1.89756
Value Function Loss: 0.02591

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.31488
Value Function Update Magnitude: 0.30772

Collected Steps per Second: 21,411.45866
Overall Steps per Second: 10,368.20475

Timestep Collection Time: 2.33623
Timestep Consumption Time: 2.48833
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.82456

Cumulative Model Updates: 222,906
Cumulative Timesteps: 1,859,646,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,895.07905
Policy Entropy: 1.89845
Value Function Loss: 0.02450

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07422
Policy Update Magnitude: 0.31101
Value Function Update Magnitude: 0.32877

Collected Steps per Second: 21,495.81928
Overall Steps per Second: 10,321.02378

Timestep Collection Time: 2.32762
Timestep Consumption Time: 2.52016
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.84777

Cumulative Model Updates: 222,912
Cumulative Timesteps: 1,859,696,682

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1859696682...
Checkpoint 1859696682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,087.13581
Policy Entropy: 1.89026
Value Function Loss: 0.02508

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.07696
Policy Update Magnitude: 0.30677
Value Function Update Magnitude: 0.34569

Collected Steps per Second: 21,644.08561
Overall Steps per Second: 10,498.99885

Timestep Collection Time: 2.31241
Timestep Consumption Time: 2.45471
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.76712

Cumulative Model Updates: 222,918
Cumulative Timesteps: 1,859,746,732

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,985.77496
Policy Entropy: 1.89782
Value Function Loss: 0.02432

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.07816
Policy Update Magnitude: 0.30112
Value Function Update Magnitude: 0.35587

Collected Steps per Second: 21,444.03653
Overall Steps per Second: 10,465.12971

Timestep Collection Time: 2.33212
Timestep Consumption Time: 2.44661
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.77873

Cumulative Model Updates: 222,924
Cumulative Timesteps: 1,859,796,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1859796742...
Checkpoint 1859796742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,507.07380
Policy Entropy: 1.89711
Value Function Loss: 0.02323

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07415
Policy Update Magnitude: 0.29812
Value Function Update Magnitude: 0.33144

Collected Steps per Second: 21,644.72486
Overall Steps per Second: 10,495.00973

Timestep Collection Time: 2.31197
Timestep Consumption Time: 2.45620
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.76817

Cumulative Model Updates: 222,930
Cumulative Timesteps: 1,859,846,784

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,931.50919
Policy Entropy: 1.88396
Value Function Loss: 0.02184

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07066
Policy Update Magnitude: 0.29403
Value Function Update Magnitude: 0.28477

Collected Steps per Second: 21,447.12212
Overall Steps per Second: 10,469.78958

Timestep Collection Time: 2.33253
Timestep Consumption Time: 2.44560
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.77813

Cumulative Model Updates: 222,936
Cumulative Timesteps: 1,859,896,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1859896810...
Checkpoint 1859896810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,590.22855
Policy Entropy: 1.87358
Value Function Loss: 0.02219

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07771
Policy Update Magnitude: 0.29327
Value Function Update Magnitude: 0.28384

Collected Steps per Second: 21,570.94887
Overall Steps per Second: 10,373.09749

Timestep Collection Time: 2.31932
Timestep Consumption Time: 2.50373
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.82305

Cumulative Model Updates: 222,942
Cumulative Timesteps: 1,859,946,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,095.32436
Policy Entropy: 1.87880
Value Function Loss: 0.02339

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07478
Policy Update Magnitude: 0.29532
Value Function Update Magnitude: 0.29221

Collected Steps per Second: 22,072.96898
Overall Steps per Second: 10,435.44321

Timestep Collection Time: 2.26549
Timestep Consumption Time: 2.52645
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.79194

Cumulative Model Updates: 222,948
Cumulative Timesteps: 1,859,996,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1859996846...
Checkpoint 1859996846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,340.71143
Policy Entropy: 1.88074
Value Function Loss: 0.02593

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07489
Policy Update Magnitude: 0.30027
Value Function Update Magnitude: 0.32086

Collected Steps per Second: 21,023.51347
Overall Steps per Second: 10,446.83144

Timestep Collection Time: 2.37848
Timestep Consumption Time: 2.40804
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.78652

Cumulative Model Updates: 222,954
Cumulative Timesteps: 1,860,046,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,447.64165
Policy Entropy: 1.88226
Value Function Loss: 0.02613

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07760
Policy Update Magnitude: 0.30970
Value Function Update Magnitude: 0.34238

Collected Steps per Second: 20,987.39007
Overall Steps per Second: 10,546.42394

Timestep Collection Time: 2.38315
Timestep Consumption Time: 2.35932
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.74246

Cumulative Model Updates: 222,960
Cumulative Timesteps: 1,860,096,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1860096866...
Checkpoint 1860096866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,301.71622
Policy Entropy: 1.88974
Value Function Loss: 0.02481

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.30674
Value Function Update Magnitude: 0.35847

Collected Steps per Second: 20,853.33832
Overall Steps per Second: 10,512.45308

Timestep Collection Time: 2.39846
Timestep Consumption Time: 2.35932
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.75779

Cumulative Model Updates: 222,966
Cumulative Timesteps: 1,860,146,882

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,168.33422
Policy Entropy: 1.88910
Value Function Loss: 0.02258

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.09580
Policy Update Magnitude: 0.29910
Value Function Update Magnitude: 0.35174

Collected Steps per Second: 21,256.18099
Overall Steps per Second: 10,338.23440

Timestep Collection Time: 2.35395
Timestep Consumption Time: 2.48595
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.83990

Cumulative Model Updates: 222,972
Cumulative Timesteps: 1,860,196,918

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1860196918...
Checkpoint 1860196918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,953.30466
Policy Entropy: 1.89090
Value Function Loss: 0.02539

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.30619
Value Function Update Magnitude: 0.33860

Collected Steps per Second: 21,364.31424
Overall Steps per Second: 10,405.50246

Timestep Collection Time: 2.34054
Timestep Consumption Time: 2.46500
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.80553

Cumulative Model Updates: 222,978
Cumulative Timesteps: 1,860,246,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,752.11390
Policy Entropy: 1.87230
Value Function Loss: 0.02564

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.09138
Policy Update Magnitude: 0.30801
Value Function Update Magnitude: 0.35140

Collected Steps per Second: 21,469.56244
Overall Steps per Second: 10,440.05574

Timestep Collection Time: 2.32906
Timestep Consumption Time: 2.46056
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.78963

Cumulative Model Updates: 222,984
Cumulative Timesteps: 1,860,296,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1860296926...
Checkpoint 1860296926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,832.00931
Policy Entropy: 1.88783
Value Function Loss: 0.02728

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.31042
Value Function Update Magnitude: 0.34103

Collected Steps per Second: 21,607.71151
Overall Steps per Second: 10,586.02897

Timestep Collection Time: 2.31556
Timestep Consumption Time: 2.41086
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.72642

Cumulative Model Updates: 222,990
Cumulative Timesteps: 1,860,346,960

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,115.38826
Policy Entropy: 1.88154
Value Function Loss: 0.02735

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.30813
Value Function Update Magnitude: 0.29509

Collected Steps per Second: 21,963.07436
Overall Steps per Second: 10,469.69064

Timestep Collection Time: 2.27755
Timestep Consumption Time: 2.50024
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.77779

Cumulative Model Updates: 222,996
Cumulative Timesteps: 1,860,396,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1860396982...
Checkpoint 1860396982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,899.61710
Policy Entropy: 1.89351
Value Function Loss: 0.02955

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.30754
Value Function Update Magnitude: 0.33092

Collected Steps per Second: 21,619.72947
Overall Steps per Second: 10,369.29391

Timestep Collection Time: 2.31511
Timestep Consumption Time: 2.51184
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.82694

Cumulative Model Updates: 223,002
Cumulative Timesteps: 1,860,447,034

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,068.37148
Policy Entropy: 1.89149
Value Function Loss: 0.02614

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.30787
Value Function Update Magnitude: 0.36551

Collected Steps per Second: 21,838.08049
Overall Steps per Second: 10,402.51620

Timestep Collection Time: 2.29077
Timestep Consumption Time: 2.51826
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.80903

Cumulative Model Updates: 223,008
Cumulative Timesteps: 1,860,497,060

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1860497060...
Checkpoint 1860497060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,249.03947
Policy Entropy: 1.89306
Value Function Loss: 0.02616

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.30962
Value Function Update Magnitude: 0.36342

Collected Steps per Second: 21,676.05794
Overall Steps per Second: 10,541.67218

Timestep Collection Time: 2.30780
Timestep Consumption Time: 2.43756
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.74536

Cumulative Model Updates: 223,014
Cumulative Timesteps: 1,860,547,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,903.92614
Policy Entropy: 1.87595
Value Function Loss: 0.02775

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.07906
Policy Update Magnitude: 0.30466
Value Function Update Magnitude: 0.35687

Collected Steps per Second: 21,721.33571
Overall Steps per Second: 10,529.71021

Timestep Collection Time: 2.30198
Timestep Consumption Time: 2.44668
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.74866

Cumulative Model Updates: 223,020
Cumulative Timesteps: 1,860,597,086

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1860597086...
Checkpoint 1860597086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,651.45029
Policy Entropy: 1.86548
Value Function Loss: 0.02946

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.31240
Value Function Update Magnitude: 0.36677

Collected Steps per Second: 21,502.21954
Overall Steps per Second: 10,512.33350

Timestep Collection Time: 2.32711
Timestep Consumption Time: 2.43282
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.75993

Cumulative Model Updates: 223,026
Cumulative Timesteps: 1,860,647,124

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,906.58199
Policy Entropy: 1.88031
Value Function Loss: 0.02651

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.30846
Value Function Update Magnitude: 0.36515

Collected Steps per Second: 21,487.64875
Overall Steps per Second: 10,471.21712

Timestep Collection Time: 2.32794
Timestep Consumption Time: 2.44915
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.77710

Cumulative Model Updates: 223,032
Cumulative Timesteps: 1,860,697,146

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1860697146...
Checkpoint 1860697146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,238.78489
Policy Entropy: 1.87997
Value Function Loss: 0.02619

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.07880
Policy Update Magnitude: 0.30671
Value Function Update Magnitude: 0.34315

Collected Steps per Second: 21,102.29365
Overall Steps per Second: 10,244.44272

Timestep Collection Time: 2.37055
Timestep Consumption Time: 2.51249
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.88304

Cumulative Model Updates: 223,038
Cumulative Timesteps: 1,860,747,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,368.52759
Policy Entropy: 1.87737
Value Function Loss: 0.02573

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.07448
Policy Update Magnitude: 0.31485
Value Function Update Magnitude: 0.34188

Collected Steps per Second: 21,784.35259
Overall Steps per Second: 10,464.76456

Timestep Collection Time: 2.29596
Timestep Consumption Time: 2.48351
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.77947

Cumulative Model Updates: 223,044
Cumulative Timesteps: 1,860,797,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1860797186...
Checkpoint 1860797186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,131.25701
Policy Entropy: 1.87373
Value Function Loss: 0.02627

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.07974
Policy Update Magnitude: 0.31281
Value Function Update Magnitude: 0.33514

Collected Steps per Second: 21,395.33344
Overall Steps per Second: 10,172.88702

Timestep Collection Time: 2.33827
Timestep Consumption Time: 2.57951
PPO Batch Consumption Time: 0.30079
Total Iteration Time: 4.91778

Cumulative Model Updates: 223,050
Cumulative Timesteps: 1,860,847,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,038.60349
Policy Entropy: 1.86451
Value Function Loss: 0.02670

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.31310
Value Function Update Magnitude: 0.33781

Collected Steps per Second: 21,514.31490
Overall Steps per Second: 10,506.28257

Timestep Collection Time: 2.32459
Timestep Consumption Time: 2.43561
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.76020

Cumulative Model Updates: 223,056
Cumulative Timesteps: 1,860,897,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1860897226...
Checkpoint 1860897226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,005.04001
Policy Entropy: 1.87983
Value Function Loss: 0.02823

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.31674
Value Function Update Magnitude: 0.33812

Collected Steps per Second: 21,448.84798
Overall Steps per Second: 10,351.02629

Timestep Collection Time: 2.33169
Timestep Consumption Time: 2.49991
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.83160

Cumulative Model Updates: 223,062
Cumulative Timesteps: 1,860,947,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,703.24177
Policy Entropy: 1.88947
Value Function Loss: 0.02566

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.30848
Value Function Update Magnitude: 0.31403

Collected Steps per Second: 21,880.23633
Overall Steps per Second: 10,439.56327

Timestep Collection Time: 2.28553
Timestep Consumption Time: 2.50471
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.79024

Cumulative Model Updates: 223,068
Cumulative Timesteps: 1,860,997,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1860997246...
Checkpoint 1860997246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,681.66247
Policy Entropy: 1.90610
Value Function Loss: 0.02632

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.11423
Policy Update Magnitude: 0.29782
Value Function Update Magnitude: 0.29619

Collected Steps per Second: 21,702.04018
Overall Steps per Second: 10,542.99324

Timestep Collection Time: 2.30513
Timestep Consumption Time: 2.43982
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.74495

Cumulative Model Updates: 223,074
Cumulative Timesteps: 1,861,047,272

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,814.99980
Policy Entropy: 1.90040
Value Function Loss: 0.02412

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.29174
Value Function Update Magnitude: 0.29906

Collected Steps per Second: 21,178.49880
Overall Steps per Second: 10,404.55310

Timestep Collection Time: 2.36117
Timestep Consumption Time: 2.44500
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.80617

Cumulative Model Updates: 223,080
Cumulative Timesteps: 1,861,097,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1861097278...
Checkpoint 1861097278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,807.46694
Policy Entropy: 1.89696
Value Function Loss: 0.02588

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.08759
Policy Update Magnitude: 0.30608
Value Function Update Magnitude: 0.30231

Collected Steps per Second: 20,774.62978
Overall Steps per Second: 10,350.00579

Timestep Collection Time: 2.40765
Timestep Consumption Time: 2.42501
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.83265

Cumulative Model Updates: 223,086
Cumulative Timesteps: 1,861,147,296

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,891.57880
Policy Entropy: 1.89987
Value Function Loss: 0.02326

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.08524
Policy Update Magnitude: 0.32212
Value Function Update Magnitude: 0.27226

Collected Steps per Second: 21,214.36914
Overall Steps per Second: 10,297.43390

Timestep Collection Time: 2.35840
Timestep Consumption Time: 2.50028
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.85869

Cumulative Model Updates: 223,092
Cumulative Timesteps: 1,861,197,328

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1861197328...
Checkpoint 1861197328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,685.69133
Policy Entropy: 1.90465
Value Function Loss: 0.02201

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.07862
Policy Update Magnitude: 0.30672
Value Function Update Magnitude: 0.25269

Collected Steps per Second: 21,417.46508
Overall Steps per Second: 10,342.96778

Timestep Collection Time: 2.33464
Timestep Consumption Time: 2.49976
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.83440

Cumulative Model Updates: 223,098
Cumulative Timesteps: 1,861,247,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,491.03711
Policy Entropy: 1.90922
Value Function Loss: 0.02005

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07038
Policy Update Magnitude: 0.28972
Value Function Update Magnitude: 0.26229

Collected Steps per Second: 21,740.29468
Overall Steps per Second: 10,483.03499

Timestep Collection Time: 2.30043
Timestep Consumption Time: 2.47033
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.77076

Cumulative Model Updates: 223,104
Cumulative Timesteps: 1,861,297,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1861297342...
Checkpoint 1861297342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,536.80656
Policy Entropy: 1.91013
Value Function Loss: 0.02166

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06789
Policy Update Magnitude: 0.29019
Value Function Update Magnitude: 0.27508

Collected Steps per Second: 21,383.75179
Overall Steps per Second: 10,459.57131

Timestep Collection Time: 2.33944
Timestep Consumption Time: 2.44336
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.78280

Cumulative Model Updates: 223,110
Cumulative Timesteps: 1,861,347,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,619.54483
Policy Entropy: 1.90308
Value Function Loss: 0.02376

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07352
Policy Update Magnitude: 0.30403
Value Function Update Magnitude: 0.29077

Collected Steps per Second: 21,711.25164
Overall Steps per Second: 10,450.17312

Timestep Collection Time: 2.30314
Timestep Consumption Time: 2.48185
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.78499

Cumulative Model Updates: 223,116
Cumulative Timesteps: 1,861,397,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1861397372...
Checkpoint 1861397372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,972.57215
Policy Entropy: 1.89563
Value Function Loss: 0.02636

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07947
Policy Update Magnitude: 0.30622
Value Function Update Magnitude: 0.28676

Collected Steps per Second: 21,757.35232
Overall Steps per Second: 10,403.04617

Timestep Collection Time: 2.29872
Timestep Consumption Time: 2.50891
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.80763

Cumulative Model Updates: 223,122
Cumulative Timesteps: 1,861,447,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,937.56862
Policy Entropy: 1.88069
Value Function Loss: 0.02527

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.30437
Value Function Update Magnitude: 0.29719

Collected Steps per Second: 22,023.85867
Overall Steps per Second: 10,519.43413

Timestep Collection Time: 2.27108
Timestep Consumption Time: 2.48374
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.75482

Cumulative Model Updates: 223,128
Cumulative Timesteps: 1,861,497,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1861497404...
Checkpoint 1861497404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,296.67518
Policy Entropy: 1.86844
Value Function Loss: 0.02574

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07190
Policy Update Magnitude: 0.30751
Value Function Update Magnitude: 0.29983

Collected Steps per Second: 21,301.23731
Overall Steps per Second: 10,405.56750

Timestep Collection Time: 2.34822
Timestep Consumption Time: 2.45882
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.80704

Cumulative Model Updates: 223,134
Cumulative Timesteps: 1,861,547,424

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,521.08715
Policy Entropy: 1.88273
Value Function Loss: 0.02341

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.07675
Policy Update Magnitude: 0.30134
Value Function Update Magnitude: 0.28178

Collected Steps per Second: 21,861.64990
Overall Steps per Second: 10,412.71022

Timestep Collection Time: 2.28821
Timestep Consumption Time: 2.51592
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.80413

Cumulative Model Updates: 223,140
Cumulative Timesteps: 1,861,597,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1861597448...
Checkpoint 1861597448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,682.42208
Policy Entropy: 1.88294
Value Function Loss: 0.02265

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.07761
Policy Update Magnitude: 0.29218
Value Function Update Magnitude: 0.22408

Collected Steps per Second: 21,792.95525
Overall Steps per Second: 10,553.41258

Timestep Collection Time: 2.29533
Timestep Consumption Time: 2.44456
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.73989

Cumulative Model Updates: 223,146
Cumulative Timesteps: 1,861,647,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,719.72715
Policy Entropy: 1.89510
Value Function Loss: 0.02090

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07026
Policy Update Magnitude: 0.28417
Value Function Update Magnitude: 0.18944

Collected Steps per Second: 18,437.57454
Overall Steps per Second: 9,566.91957

Timestep Collection Time: 2.71413
Timestep Consumption Time: 2.51660
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 5.23073

Cumulative Model Updates: 223,152
Cumulative Timesteps: 1,861,697,512

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1861697512...
Checkpoint 1861697512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,952.61332
Policy Entropy: 1.90590
Value Function Loss: 0.02253

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07358
Policy Update Magnitude: 0.28708
Value Function Update Magnitude: 0.25223

Collected Steps per Second: 21,701.82452
Overall Steps per Second: 10,406.70139

Timestep Collection Time: 2.30451
Timestep Consumption Time: 2.50124
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.80575

Cumulative Model Updates: 223,158
Cumulative Timesteps: 1,861,747,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,603.98496
Policy Entropy: 1.91705
Value Function Loss: 0.02474

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.29350
Value Function Update Magnitude: 0.28475

Collected Steps per Second: 20,513.34547
Overall Steps per Second: 9,877.58454

Timestep Collection Time: 2.43832
Timestep Consumption Time: 2.62547
PPO Batch Consumption Time: 0.30705
Total Iteration Time: 5.06379

Cumulative Model Updates: 223,164
Cumulative Timesteps: 1,861,797,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1861797542...
Checkpoint 1861797542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,302.12392
Policy Entropy: 1.91173
Value Function Loss: 0.02650

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.29595
Value Function Update Magnitude: 0.32781

Collected Steps per Second: 18,699.69327
Overall Steps per Second: 9,564.94070

Timestep Collection Time: 2.67534
Timestep Consumption Time: 2.55501
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 5.23035

Cumulative Model Updates: 223,170
Cumulative Timesteps: 1,861,847,570

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,146.53226
Policy Entropy: 1.90009
Value Function Loss: 0.02543

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.29852
Value Function Update Magnitude: 0.33966

Collected Steps per Second: 17,795.28597
Overall Steps per Second: 9,079.93304

Timestep Collection Time: 2.81052
Timestep Consumption Time: 2.69767
PPO Batch Consumption Time: 0.30922
Total Iteration Time: 5.50819

Cumulative Model Updates: 223,176
Cumulative Timesteps: 1,861,897,584

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1861897584...
Checkpoint 1861897584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,997.76431
Policy Entropy: 1.90154
Value Function Loss: 0.02507

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.30560
Value Function Update Magnitude: 0.33452

Collected Steps per Second: 18,670.80319
Overall Steps per Second: 9,703.11630

Timestep Collection Time: 2.67916
Timestep Consumption Time: 2.47609
PPO Batch Consumption Time: 0.29814
Total Iteration Time: 5.15525

Cumulative Model Updates: 223,182
Cumulative Timesteps: 1,861,947,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,856.52365
Policy Entropy: 1.89851
Value Function Loss: 0.02313

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.30014
Value Function Update Magnitude: 0.28920

Collected Steps per Second: 21,415.60452
Overall Steps per Second: 10,199.43601

Timestep Collection Time: 2.33512
Timestep Consumption Time: 2.56790
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.90302

Cumulative Model Updates: 223,188
Cumulative Timesteps: 1,861,997,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1861997614...
Checkpoint 1861997614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,405.93999
Policy Entropy: 1.90107
Value Function Loss: 0.02641

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.30222
Value Function Update Magnitude: 0.26611

Collected Steps per Second: 20,109.14902
Overall Steps per Second: 9,944.31514

Timestep Collection Time: 2.48673
Timestep Consumption Time: 2.54187
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 5.02860

Cumulative Model Updates: 223,194
Cumulative Timesteps: 1,862,047,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,937.60513
Policy Entropy: 1.89173
Value Function Loss: 0.02714

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 0.30761
Value Function Update Magnitude: 0.26297

Collected Steps per Second: 20,337.19724
Overall Steps per Second: 10,033.11148

Timestep Collection Time: 2.45855
Timestep Consumption Time: 2.52495
PPO Batch Consumption Time: 0.30844
Total Iteration Time: 4.98350

Cumulative Model Updates: 223,200
Cumulative Timesteps: 1,862,097,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1862097620...
Checkpoint 1862097620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,317.54474
Policy Entropy: 1.89628
Value Function Loss: 0.02626

Mean KL Divergence: 0.02338
SB3 Clip Fraction: 0.08270
Policy Update Magnitude: 0.30417
Value Function Update Magnitude: 0.24562

Collected Steps per Second: 19,898.53450
Overall Steps per Second: 10,247.02821

Timestep Collection Time: 2.51315
Timestep Consumption Time: 2.36709
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.88024

Cumulative Model Updates: 223,206
Cumulative Timesteps: 1,862,147,628

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,358.38327
Policy Entropy: 1.89425
Value Function Loss: 0.02677

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.30347
Value Function Update Magnitude: 0.20807

Collected Steps per Second: 20,882.76157
Overall Steps per Second: 10,443.70177

Timestep Collection Time: 2.39518
Timestep Consumption Time: 2.39412
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.78930

Cumulative Model Updates: 223,212
Cumulative Timesteps: 1,862,197,646

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1862197646...
Checkpoint 1862197646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,743.14810
Policy Entropy: 1.87966
Value Function Loss: 0.02608

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08278
Policy Update Magnitude: 0.30237
Value Function Update Magnitude: 0.17581

Collected Steps per Second: 20,432.13396
Overall Steps per Second: 9,990.21069

Timestep Collection Time: 2.44840
Timestep Consumption Time: 2.55910
PPO Batch Consumption Time: 0.31113
Total Iteration Time: 5.00750

Cumulative Model Updates: 223,218
Cumulative Timesteps: 1,862,247,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,058.19813
Policy Entropy: 1.86066
Value Function Loss: 0.02796

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.07724
Policy Update Magnitude: 0.30349
Value Function Update Magnitude: 0.17200

Collected Steps per Second: 20,425.34836
Overall Steps per Second: 10,102.55230

Timestep Collection Time: 2.44813
Timestep Consumption Time: 2.50151
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.94964

Cumulative Model Updates: 223,224
Cumulative Timesteps: 1,862,297,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1862297676...
Checkpoint 1862297676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,957.36103
Policy Entropy: 1.87183
Value Function Loss: 0.02645

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08032
Policy Update Magnitude: 0.30217
Value Function Update Magnitude: 0.25699

Collected Steps per Second: 20,990.79596
Overall Steps per Second: 10,254.96091

Timestep Collection Time: 2.38238
Timestep Consumption Time: 2.49409
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.87647

Cumulative Model Updates: 223,230
Cumulative Timesteps: 1,862,347,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,332.38480
Policy Entropy: 1.88642
Value Function Loss: 0.02660

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.30146
Value Function Update Magnitude: 0.29713

Collected Steps per Second: 18,310.36221
Overall Steps per Second: 9,388.94637

Timestep Collection Time: 2.73146
Timestep Consumption Time: 2.59544
PPO Batch Consumption Time: 0.30511
Total Iteration Time: 5.32690

Cumulative Model Updates: 223,236
Cumulative Timesteps: 1,862,397,698

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1862397698...
Checkpoint 1862397698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,102.45018
Policy Entropy: 1.89925
Value Function Loss: 0.02408

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.29791
Value Function Update Magnitude: 0.29638

Collected Steps per Second: 20,329.96478
Overall Steps per Second: 9,964.68288

Timestep Collection Time: 2.46001
Timestep Consumption Time: 2.55891
PPO Batch Consumption Time: 0.30076
Total Iteration Time: 5.01893

Cumulative Model Updates: 223,242
Cumulative Timesteps: 1,862,447,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,161.85639
Policy Entropy: 1.89718
Value Function Loss: 0.02568

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.29647
Value Function Update Magnitude: 0.27353

Collected Steps per Second: 21,123.65405
Overall Steps per Second: 10,167.10135

Timestep Collection Time: 2.36758
Timestep Consumption Time: 2.55142
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.91900

Cumulative Model Updates: 223,248
Cumulative Timesteps: 1,862,497,722

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1862497722...
Checkpoint 1862497722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,385.70241
Policy Entropy: 1.88884
Value Function Loss: 0.02362

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.29810
Value Function Update Magnitude: 0.28835

Collected Steps per Second: 19,539.74674
Overall Steps per Second: 9,923.69965

Timestep Collection Time: 2.55889
Timestep Consumption Time: 2.47956
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 5.03844

Cumulative Model Updates: 223,254
Cumulative Timesteps: 1,862,547,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,985.53901
Policy Entropy: 1.89615
Value Function Loss: 0.02382

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07806
Policy Update Magnitude: 0.29239
Value Function Update Magnitude: 0.28887

Collected Steps per Second: 21,458.18876
Overall Steps per Second: 10,330.17560

Timestep Collection Time: 2.33039
Timestep Consumption Time: 2.51038
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.84077

Cumulative Model Updates: 223,260
Cumulative Timesteps: 1,862,597,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1862597728...
Checkpoint 1862597728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,335.73933
Policy Entropy: 1.89528
Value Function Loss: 0.02273

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07416
Policy Update Magnitude: 0.29001
Value Function Update Magnitude: 0.28792

Collected Steps per Second: 19,872.86722
Overall Steps per Second: 9,911.32730

Timestep Collection Time: 2.51609
Timestep Consumption Time: 2.52884
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 5.04493

Cumulative Model Updates: 223,266
Cumulative Timesteps: 1,862,647,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,073.53734
Policy Entropy: 1.88848
Value Function Loss: 0.02329

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.29256
Value Function Update Magnitude: 0.31515

Collected Steps per Second: 20,525.30664
Overall Steps per Second: 9,850.54381

Timestep Collection Time: 2.43602
Timestep Consumption Time: 2.63984
PPO Batch Consumption Time: 0.30997
Total Iteration Time: 5.07586

Cumulative Model Updates: 223,272
Cumulative Timesteps: 1,862,697,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1862697730...
Checkpoint 1862697730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,824.87291
Policy Entropy: 1.88269
Value Function Loss: 0.02156

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08270
Policy Update Magnitude: 0.28966
Value Function Update Magnitude: 0.31565

Collected Steps per Second: 20,013.84669
Overall Steps per Second: 10,132.90058

Timestep Collection Time: 2.49937
Timestep Consumption Time: 2.43722
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.93659

Cumulative Model Updates: 223,278
Cumulative Timesteps: 1,862,747,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,801.79942
Policy Entropy: 1.88489
Value Function Loss: 0.02101

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08009
Policy Update Magnitude: 0.28776
Value Function Update Magnitude: 0.30076

Collected Steps per Second: 21,741.82631
Overall Steps per Second: 10,353.84657

Timestep Collection Time: 2.29981
Timestep Consumption Time: 2.52951
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.82932

Cumulative Model Updates: 223,284
Cumulative Timesteps: 1,862,797,754

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1862797754...
Checkpoint 1862797754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,691.80291
Policy Entropy: 1.88538
Value Function Loss: 0.02304

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.29188
Value Function Update Magnitude: 0.30667

Collected Steps per Second: 21,795.22391
Overall Steps per Second: 10,401.37407

Timestep Collection Time: 2.29454
Timestep Consumption Time: 2.51348
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.80802

Cumulative Model Updates: 223,290
Cumulative Timesteps: 1,862,847,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,859.15043
Policy Entropy: 1.88741
Value Function Loss: 0.02275

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07733
Policy Update Magnitude: 0.29582
Value Function Update Magnitude: 0.31355

Collected Steps per Second: 22,009.86088
Overall Steps per Second: 10,292.41481

Timestep Collection Time: 2.27298
Timestep Consumption Time: 2.58769
PPO Batch Consumption Time: 0.30283
Total Iteration Time: 4.86067

Cumulative Model Updates: 223,296
Cumulative Timesteps: 1,862,897,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1862897792...
Checkpoint 1862897792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,986.30667
Policy Entropy: 1.89106
Value Function Loss: 0.02559

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.29890
Value Function Update Magnitude: 0.26407

Collected Steps per Second: 21,454.11971
Overall Steps per Second: 10,267.03592

Timestep Collection Time: 2.33130
Timestep Consumption Time: 2.54021
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.87151

Cumulative Model Updates: 223,302
Cumulative Timesteps: 1,862,947,808

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,363.07335
Policy Entropy: 1.88464
Value Function Loss: 0.02349

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.30408
Value Function Update Magnitude: 0.24192

Collected Steps per Second: 22,020.82354
Overall Steps per Second: 10,425.31170

Timestep Collection Time: 2.27130
Timestep Consumption Time: 2.52625
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.79755

Cumulative Model Updates: 223,308
Cumulative Timesteps: 1,862,997,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1862997824...
Checkpoint 1862997824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,017.93784
Policy Entropy: 1.87239
Value Function Loss: 0.02475

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07498
Policy Update Magnitude: 0.30251
Value Function Update Magnitude: 0.24408

Collected Steps per Second: 21,724.01151
Overall Steps per Second: 10,519.81475

Timestep Collection Time: 2.30261
Timestep Consumption Time: 2.45241
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.75503

Cumulative Model Updates: 223,314
Cumulative Timesteps: 1,863,047,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,656.32084
Policy Entropy: 1.86605
Value Function Loss: 0.02445

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07292
Policy Update Magnitude: 0.30242
Value Function Update Magnitude: 0.22757

Collected Steps per Second: 21,725.74222
Overall Steps per Second: 10,517.94331

Timestep Collection Time: 2.30215
Timestep Consumption Time: 2.45315
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.75530

Cumulative Model Updates: 223,320
Cumulative Timesteps: 1,863,097,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1863097862...
Checkpoint 1863097862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,777.05958
Policy Entropy: 1.88349
Value Function Loss: 0.02397

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07550
Policy Update Magnitude: 0.29643
Value Function Update Magnitude: 0.25320

Collected Steps per Second: 21,576.61497
Overall Steps per Second: 10,378.62689

Timestep Collection Time: 2.31788
Timestep Consumption Time: 2.50087
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.81875

Cumulative Model Updates: 223,326
Cumulative Timesteps: 1,863,147,874

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,683.32170
Policy Entropy: 1.90170
Value Function Loss: 0.02137

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07229
Policy Update Magnitude: 0.28736
Value Function Update Magnitude: 0.23104

Collected Steps per Second: 22,116.73327
Overall Steps per Second: 10,492.11855

Timestep Collection Time: 2.26073
Timestep Consumption Time: 2.50475
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.76548

Cumulative Model Updates: 223,332
Cumulative Timesteps: 1,863,197,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1863197874...
Checkpoint 1863197874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,403.68247
Policy Entropy: 1.90159
Value Function Loss: 0.02115

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.06947
Policy Update Magnitude: 0.28351
Value Function Update Magnitude: 0.20898

Collected Steps per Second: 21,484.55961
Overall Steps per Second: 10,504.10371

Timestep Collection Time: 2.32753
Timestep Consumption Time: 2.43308
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.76062

Cumulative Model Updates: 223,338
Cumulative Timesteps: 1,863,247,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,836.27794
Policy Entropy: 1.89755
Value Function Loss: 0.02107

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07542
Policy Update Magnitude: 0.28323
Value Function Update Magnitude: 0.24842

Collected Steps per Second: 20,659.66590
Overall Steps per Second: 10,007.24980

Timestep Collection Time: 2.42066
Timestep Consumption Time: 2.57672
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 4.99738

Cumulative Model Updates: 223,344
Cumulative Timesteps: 1,863,297,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1863297890...
Checkpoint 1863297890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,164.61223
Policy Entropy: 1.88962
Value Function Loss: 0.02543

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.30032
Value Function Update Magnitude: 0.29611

Collected Steps per Second: 21,186.11413
Overall Steps per Second: 10,123.65779

Timestep Collection Time: 2.36164
Timestep Consumption Time: 2.58064
PPO Batch Consumption Time: 0.30092
Total Iteration Time: 4.94228

Cumulative Model Updates: 223,350
Cumulative Timesteps: 1,863,347,924

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,520.28218
Policy Entropy: 1.88999
Value Function Loss: 0.02590

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.30746
Value Function Update Magnitude: 0.33521

Collected Steps per Second: 20,045.09646
Overall Steps per Second: 9,781.27554

Timestep Collection Time: 2.49487
Timestep Consumption Time: 2.61796
PPO Batch Consumption Time: 0.29962
Total Iteration Time: 5.11283

Cumulative Model Updates: 223,356
Cumulative Timesteps: 1,863,397,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1863397934...
Checkpoint 1863397934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,753.51957
Policy Entropy: 1.89455
Value Function Loss: 0.02369

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.29957
Value Function Update Magnitude: 0.34003

Collected Steps per Second: 19,727.90562
Overall Steps per Second: 10,328.49766

Timestep Collection Time: 2.53448
Timestep Consumption Time: 2.30649
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.84098

Cumulative Model Updates: 223,362
Cumulative Timesteps: 1,863,447,934

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,749.45679
Policy Entropy: 1.90318
Value Function Loss: 0.02264

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.29788
Value Function Update Magnitude: 0.33222

Collected Steps per Second: 18,832.20597
Overall Steps per Second: 9,824.20069

Timestep Collection Time: 2.65641
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 5.09212

Cumulative Model Updates: 223,368
Cumulative Timesteps: 1,863,497,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1863497960...
Checkpoint 1863497960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,158.18291
Policy Entropy: 1.90366
Value Function Loss: 0.02210

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07886
Policy Update Magnitude: 0.29183
Value Function Update Magnitude: 0.31829

Collected Steps per Second: 20,331.17285
Overall Steps per Second: 10,150.87345

Timestep Collection Time: 2.45928
Timestep Consumption Time: 2.46641
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.92568

Cumulative Model Updates: 223,374
Cumulative Timesteps: 1,863,547,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,508.45949
Policy Entropy: 1.90341
Value Function Loss: 0.02428

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07428
Policy Update Magnitude: 0.29615
Value Function Update Magnitude: 0.31870

Collected Steps per Second: 20,224.00305
Overall Steps per Second: 10,203.93382

Timestep Collection Time: 2.47300
Timestep Consumption Time: 2.42844
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.90144

Cumulative Model Updates: 223,380
Cumulative Timesteps: 1,863,597,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1863597974...
Checkpoint 1863597974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,401.08940
Policy Entropy: 1.90401
Value Function Loss: 0.02450

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07739
Policy Update Magnitude: 0.29969
Value Function Update Magnitude: 0.30444

Collected Steps per Second: 20,301.75008
Overall Steps per Second: 10,288.19662

Timestep Collection Time: 2.46383
Timestep Consumption Time: 2.39806
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.86188

Cumulative Model Updates: 223,386
Cumulative Timesteps: 1,863,647,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,844.40935
Policy Entropy: 1.89136
Value Function Loss: 0.02515

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.30021
Value Function Update Magnitude: 0.30751

Collected Steps per Second: 20,584.98400
Overall Steps per Second: 10,182.36740

Timestep Collection Time: 2.42944
Timestep Consumption Time: 2.48199
PPO Batch Consumption Time: 0.29757
Total Iteration Time: 4.91143

Cumulative Model Updates: 223,392
Cumulative Timesteps: 1,863,698,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1863698004...
Checkpoint 1863698004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,388.90799
Policy Entropy: 1.88307
Value Function Loss: 0.02510

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.31298
Value Function Update Magnitude: 0.32587

Collected Steps per Second: 19,617.61879
Overall Steps per Second: 9,826.13821

Timestep Collection Time: 2.54995
Timestep Consumption Time: 2.54096
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 5.09091

Cumulative Model Updates: 223,398
Cumulative Timesteps: 1,863,748,028

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,054.94161
Policy Entropy: 1.88590
Value Function Loss: 0.02384

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.30314
Value Function Update Magnitude: 0.33499

Collected Steps per Second: 20,131.99943
Overall Steps per Second: 9,763.35154

Timestep Collection Time: 2.48460
Timestep Consumption Time: 2.63864
PPO Batch Consumption Time: 0.30896
Total Iteration Time: 5.12324

Cumulative Model Updates: 223,404
Cumulative Timesteps: 1,863,798,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1863798048...
Checkpoint 1863798048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,971.63354
Policy Entropy: 1.88792
Value Function Loss: 0.02210

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.28967
Value Function Update Magnitude: 0.32068

Collected Steps per Second: 19,543.77942
Overall Steps per Second: 9,840.75302

Timestep Collection Time: 2.55867
Timestep Consumption Time: 2.52286
PPO Batch Consumption Time: 0.29619
Total Iteration Time: 5.08152

Cumulative Model Updates: 223,410
Cumulative Timesteps: 1,863,848,054

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,986.71635
Policy Entropy: 1.88517
Value Function Loss: 0.02166

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08033
Policy Update Magnitude: 0.28773
Value Function Update Magnitude: 0.30959

Collected Steps per Second: 20,507.38919
Overall Steps per Second: 10,106.01457

Timestep Collection Time: 2.43941
Timestep Consumption Time: 2.51071
PPO Batch Consumption Time: 0.29848
Total Iteration Time: 4.95012

Cumulative Model Updates: 223,416
Cumulative Timesteps: 1,863,898,080

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1863898080...
Checkpoint 1863898080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,657.63417
Policy Entropy: 1.89298
Value Function Loss: 0.02173

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07637
Policy Update Magnitude: 0.29189
Value Function Update Magnitude: 0.29424

Collected Steps per Second: 21,085.63772
Overall Steps per Second: 10,285.71248

Timestep Collection Time: 2.37327
Timestep Consumption Time: 2.49192
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.86520

Cumulative Model Updates: 223,422
Cumulative Timesteps: 1,863,948,122

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,084.54698
Policy Entropy: 1.87440
Value Function Loss: 0.02174

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07750
Policy Update Magnitude: 0.29027
Value Function Update Magnitude: 0.28469

Collected Steps per Second: 21,451.10789
Overall Steps per Second: 10,144.12295

Timestep Collection Time: 2.33209
Timestep Consumption Time: 2.59943
PPO Batch Consumption Time: 0.29967
Total Iteration Time: 4.93153

Cumulative Model Updates: 223,428
Cumulative Timesteps: 1,863,998,148

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1863998148...
Checkpoint 1863998148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,763.21042
Policy Entropy: 1.86777
Value Function Loss: 0.02264

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06936
Policy Update Magnitude: 0.28887
Value Function Update Magnitude: 0.29061

Collected Steps per Second: 20,570.79070
Overall Steps per Second: 10,242.13053

Timestep Collection Time: 2.43131
Timestep Consumption Time: 2.45185
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.88316

Cumulative Model Updates: 223,434
Cumulative Timesteps: 1,864,048,162

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,581.37600
Policy Entropy: 1.86185
Value Function Loss: 0.02214

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.28986
Value Function Update Magnitude: 0.28309

Collected Steps per Second: 19,751.58222
Overall Steps per Second: 9,785.55931

Timestep Collection Time: 2.53185
Timestep Consumption Time: 2.57854
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 5.11039

Cumulative Model Updates: 223,440
Cumulative Timesteps: 1,864,098,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1864098170...
Checkpoint 1864098170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,900.54805
Policy Entropy: 1.88164
Value Function Loss: 0.02196

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07886
Policy Update Magnitude: 0.29267
Value Function Update Magnitude: 0.29044

Collected Steps per Second: 19,706.85434
Overall Steps per Second: 10,085.45239

Timestep Collection Time: 2.53871
Timestep Consumption Time: 2.42190
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.96061

Cumulative Model Updates: 223,446
Cumulative Timesteps: 1,864,148,200

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,346.35039
Policy Entropy: 1.89332
Value Function Loss: 0.02416

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08330
Policy Update Magnitude: 0.29468
Value Function Update Magnitude: 0.30496

Collected Steps per Second: 20,745.09415
Overall Steps per Second: 9,952.39859

Timestep Collection Time: 2.41030
Timestep Consumption Time: 2.61381
PPO Batch Consumption Time: 0.30783
Total Iteration Time: 5.02412

Cumulative Model Updates: 223,452
Cumulative Timesteps: 1,864,198,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1864198202...
Checkpoint 1864198202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,328.77191
Policy Entropy: 1.88476
Value Function Loss: 0.02649

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.08893
Policy Update Magnitude: 0.28811
Value Function Update Magnitude: 0.29706

Collected Steps per Second: 19,754.56174
Overall Steps per Second: 9,886.35925

Timestep Collection Time: 2.53187
Timestep Consumption Time: 2.52722
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 5.05909

Cumulative Model Updates: 223,458
Cumulative Timesteps: 1,864,248,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,531.65603
Policy Entropy: 1.87494
Value Function Loss: 0.02730

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08315
Policy Update Magnitude: 0.30049
Value Function Update Magnitude: 0.28846

Collected Steps per Second: 20,162.94146
Overall Steps per Second: 10,031.75881

Timestep Collection Time: 2.48119
Timestep Consumption Time: 2.50578
PPO Batch Consumption Time: 0.30284
Total Iteration Time: 4.98696

Cumulative Model Updates: 223,464
Cumulative Timesteps: 1,864,298,246

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1864298246...
Checkpoint 1864298246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,604.40200
Policy Entropy: 1.87929
Value Function Loss: 0.02637

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.07772
Policy Update Magnitude: 0.30044
Value Function Update Magnitude: 0.29193

Collected Steps per Second: 20,345.05169
Overall Steps per Second: 10,174.61756

Timestep Collection Time: 2.45888
Timestep Consumption Time: 2.45787
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.91674

Cumulative Model Updates: 223,470
Cumulative Timesteps: 1,864,348,272

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,967.31304
Policy Entropy: 1.88460
Value Function Loss: 0.02497

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.07759
Policy Update Magnitude: 0.29939
Value Function Update Magnitude: 0.33930

Collected Steps per Second: 19,777.81462
Overall Steps per Second: 10,103.80898

Timestep Collection Time: 2.52991
Timestep Consumption Time: 2.42229
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.95219

Cumulative Model Updates: 223,476
Cumulative Timesteps: 1,864,398,308

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1864398308...
Checkpoint 1864398308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,401.59991
Policy Entropy: 1.90507
Value Function Loss: 0.02148

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.07636
Policy Update Magnitude: 0.29025
Value Function Update Magnitude: 0.32444

Collected Steps per Second: 19,738.14799
Overall Steps per Second: 9,871.77136

Timestep Collection Time: 2.53458
Timestep Consumption Time: 2.53320
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 5.06778

Cumulative Model Updates: 223,482
Cumulative Timesteps: 1,864,448,336

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,294.13808
Policy Entropy: 1.90612
Value Function Loss: 0.02262

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.28690
Value Function Update Magnitude: 0.30060

Collected Steps per Second: 21,096.18596
Overall Steps per Second: 10,411.21489

Timestep Collection Time: 2.37095
Timestep Consumption Time: 2.43329
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.80424

Cumulative Model Updates: 223,488
Cumulative Timesteps: 1,864,498,354

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1864498354...
Checkpoint 1864498354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,851.41513
Policy Entropy: 1.90102
Value Function Loss: 0.02051

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.28756
Value Function Update Magnitude: 0.29174

Collected Steps per Second: 19,464.98080
Overall Steps per Second: 9,769.16872

Timestep Collection Time: 2.56933
Timestep Consumption Time: 2.55004
PPO Batch Consumption Time: 0.30162
Total Iteration Time: 5.11937

Cumulative Model Updates: 223,494
Cumulative Timesteps: 1,864,548,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,745.85830
Policy Entropy: 1.89972
Value Function Loss: 0.02088

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07169
Policy Update Magnitude: 0.28376
Value Function Update Magnitude: 0.28659

Collected Steps per Second: 20,430.81275
Overall Steps per Second: 9,954.31426

Timestep Collection Time: 2.44777
Timestep Consumption Time: 2.57618
PPO Batch Consumption Time: 0.30738
Total Iteration Time: 5.02395

Cumulative Model Updates: 223,500
Cumulative Timesteps: 1,864,598,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1864598376...
Checkpoint 1864598376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,509.52701
Policy Entropy: 1.90941
Value Function Loss: 0.02068

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06325
Policy Update Magnitude: 0.27984
Value Function Update Magnitude: 0.26776

Collected Steps per Second: 20,166.19305
Overall Steps per Second: 9,975.78648

Timestep Collection Time: 2.47969
Timestep Consumption Time: 2.53304
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 5.01274

Cumulative Model Updates: 223,506
Cumulative Timesteps: 1,864,648,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,402.02455
Policy Entropy: 1.90639
Value Function Loss: 0.02253

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06380
Policy Update Magnitude: 0.28562
Value Function Update Magnitude: 0.24001

Collected Steps per Second: 21,011.51991
Overall Steps per Second: 9,909.00132

Timestep Collection Time: 2.38022
Timestep Consumption Time: 2.66691
PPO Batch Consumption Time: 0.31245
Total Iteration Time: 5.04713

Cumulative Model Updates: 223,512
Cumulative Timesteps: 1,864,698,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1864698394...
Checkpoint 1864698394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,337.93429
Policy Entropy: 1.90515
Value Function Loss: 0.02166

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06591
Policy Update Magnitude: 0.28995
Value Function Update Magnitude: 0.18804

Collected Steps per Second: 20,129.50464
Overall Steps per Second: 9,775.08628

Timestep Collection Time: 2.48590
Timestep Consumption Time: 2.63323
PPO Batch Consumption Time: 0.30910
Total Iteration Time: 5.11914

Cumulative Model Updates: 223,518
Cumulative Timesteps: 1,864,748,434

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,224.53730
Policy Entropy: 1.89406
Value Function Loss: 0.02289

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07560
Policy Update Magnitude: 0.29022
Value Function Update Magnitude: 0.20644

Collected Steps per Second: 19,805.31544
Overall Steps per Second: 9,889.68558

Timestep Collection Time: 2.52569
Timestep Consumption Time: 2.53231
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 5.05800

Cumulative Model Updates: 223,524
Cumulative Timesteps: 1,864,798,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1864798456...
Checkpoint 1864798456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,059.32392
Policy Entropy: 1.90330
Value Function Loss: 0.02376

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07980
Policy Update Magnitude: 0.29255
Value Function Update Magnitude: 0.25386

Collected Steps per Second: 19,628.22280
Overall Steps per Second: 9,862.86330

Timestep Collection Time: 2.54868
Timestep Consumption Time: 2.52348
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 5.07216

Cumulative Model Updates: 223,530
Cumulative Timesteps: 1,864,848,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,251.71518
Policy Entropy: 1.91755
Value Function Loss: 0.02332

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.29083
Value Function Update Magnitude: 0.28613

Collected Steps per Second: 20,925.24859
Overall Steps per Second: 9,983.26821

Timestep Collection Time: 2.39022
Timestep Consumption Time: 2.61976
PPO Batch Consumption Time: 0.30317
Total Iteration Time: 5.00998

Cumulative Model Updates: 223,536
Cumulative Timesteps: 1,864,898,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1864898498...
Checkpoint 1864898498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,636.64865
Policy Entropy: 1.91686
Value Function Loss: 0.02440

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.29770
Value Function Update Magnitude: 0.29236

Collected Steps per Second: 19,620.33067
Overall Steps per Second: 10,139.02430

Timestep Collection Time: 2.54858
Timestep Consumption Time: 2.38325
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.93184

Cumulative Model Updates: 223,542
Cumulative Timesteps: 1,864,948,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,972.01645
Policy Entropy: 1.90077
Value Function Loss: 0.02247

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.29918
Value Function Update Magnitude: 0.29188

Collected Steps per Second: 19,769.75529
Overall Steps per Second: 9,951.19378

Timestep Collection Time: 2.52962
Timestep Consumption Time: 2.49591
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 5.02553

Cumulative Model Updates: 223,548
Cumulative Timesteps: 1,864,998,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1864998512...
Checkpoint 1864998512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,800.47723
Policy Entropy: 1.89340
Value Function Loss: 0.02622

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07470
Policy Update Magnitude: 0.30182
Value Function Update Magnitude: 0.30860

Collected Steps per Second: 21,063.86143
Overall Steps per Second: 10,096.05664

Timestep Collection Time: 2.37487
Timestep Consumption Time: 2.57993
PPO Batch Consumption Time: 0.30323
Total Iteration Time: 4.95481

Cumulative Model Updates: 223,554
Cumulative Timesteps: 1,865,048,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,108.14725
Policy Entropy: 1.89236
Value Function Loss: 0.02595

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.30828
Value Function Update Magnitude: 0.32377

Collected Steps per Second: 20,562.13978
Overall Steps per Second: 9,971.36934

Timestep Collection Time: 2.43292
Timestep Consumption Time: 2.58405
PPO Batch Consumption Time: 0.30252
Total Iteration Time: 5.01696

Cumulative Model Updates: 223,560
Cumulative Timesteps: 1,865,098,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1865098562...
Checkpoint 1865098562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,564.22821
Policy Entropy: 1.90188
Value Function Loss: 0.03058

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08265
Policy Update Magnitude: 0.31464
Value Function Update Magnitude: 0.33980

Collected Steps per Second: 20,268.91076
Overall Steps per Second: 10,303.65942

Timestep Collection Time: 2.46910
Timestep Consumption Time: 2.38801
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.85711

Cumulative Model Updates: 223,566
Cumulative Timesteps: 1,865,148,608

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,159.50488
Policy Entropy: 1.89360
Value Function Loss: 0.02720

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08042
Policy Update Magnitude: 0.31711
Value Function Update Magnitude: 0.35640

Collected Steps per Second: 19,451.74264
Overall Steps per Second: 10,009.19800

Timestep Collection Time: 2.57221
Timestep Consumption Time: 2.42659
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.99880

Cumulative Model Updates: 223,572
Cumulative Timesteps: 1,865,198,642

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1865198642...
Checkpoint 1865198642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,544.08363
Policy Entropy: 1.90867
Value Function Loss: 0.02844

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.30994
Value Function Update Magnitude: 0.34175

Collected Steps per Second: 18,981.93761
Overall Steps per Second: 9,691.60832

Timestep Collection Time: 2.63651
Timestep Consumption Time: 2.52734
PPO Batch Consumption Time: 0.30507
Total Iteration Time: 5.16385

Cumulative Model Updates: 223,578
Cumulative Timesteps: 1,865,248,688

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,740.97611
Policy Entropy: 1.89307
Value Function Loss: 0.02795

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.30499
Value Function Update Magnitude: 0.31941

Collected Steps per Second: 19,749.24898
Overall Steps per Second: 10,317.18942

Timestep Collection Time: 2.53255
Timestep Consumption Time: 2.31528
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.84783

Cumulative Model Updates: 223,584
Cumulative Timesteps: 1,865,298,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1865298704...
Checkpoint 1865298704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,369.45718
Policy Entropy: 1.90127
Value Function Loss: 0.02746

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.08726
Policy Update Magnitude: 0.30094
Value Function Update Magnitude: 0.30452

Collected Steps per Second: 19,360.81824
Overall Steps per Second: 9,969.30300

Timestep Collection Time: 2.58409
Timestep Consumption Time: 2.43432
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 5.01840

Cumulative Model Updates: 223,590
Cumulative Timesteps: 1,865,348,734

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,065.19410
Policy Entropy: 1.89132
Value Function Loss: 0.02667

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.30318
Value Function Update Magnitude: 0.32447

Collected Steps per Second: 20,840.11777
Overall Steps per Second: 9,747.13881

Timestep Collection Time: 2.39979
Timestep Consumption Time: 2.73115
PPO Batch Consumption Time: 0.32662
Total Iteration Time: 5.13094

Cumulative Model Updates: 223,596
Cumulative Timesteps: 1,865,398,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1865398746...
Checkpoint 1865398746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,622.20373
Policy Entropy: 1.90624
Value Function Loss: 0.02489

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.30705
Value Function Update Magnitude: 0.33250

Collected Steps per Second: 19,951.36948
Overall Steps per Second: 9,764.63170

Timestep Collection Time: 2.50740
Timestep Consumption Time: 2.61579
PPO Batch Consumption Time: 0.30918
Total Iteration Time: 5.12318

Cumulative Model Updates: 223,602
Cumulative Timesteps: 1,865,448,772

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,520.27045
Policy Entropy: 1.90790
Value Function Loss: 0.02655

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.30279
Value Function Update Magnitude: 0.31430

Collected Steps per Second: 20,216.12261
Overall Steps per Second: 10,024.36783

Timestep Collection Time: 2.47397
Timestep Consumption Time: 2.51528
PPO Batch Consumption Time: 0.30621
Total Iteration Time: 4.98924

Cumulative Model Updates: 223,608
Cumulative Timesteps: 1,865,498,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1865498786...
Checkpoint 1865498786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,700.32061
Policy Entropy: 1.91749
Value Function Loss: 0.02304

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.09582
Policy Update Magnitude: 0.29664
Value Function Update Magnitude: 0.30957

Collected Steps per Second: 19,987.27052
Overall Steps per Second: 9,712.04007

Timestep Collection Time: 2.50379
Timestep Consumption Time: 2.64899
PPO Batch Consumption Time: 0.30535
Total Iteration Time: 5.15278

Cumulative Model Updates: 223,614
Cumulative Timesteps: 1,865,548,830

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,956.56638
Policy Entropy: 1.91102
Value Function Loss: 0.02124

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.08939
Policy Update Magnitude: 0.29459
Value Function Update Magnitude: 0.29385

Collected Steps per Second: 20,182.97031
Overall Steps per Second: 9,922.68810

Timestep Collection Time: 2.47813
Timestep Consumption Time: 2.56244
PPO Batch Consumption Time: 0.29961
Total Iteration Time: 5.04057

Cumulative Model Updates: 223,620
Cumulative Timesteps: 1,865,598,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1865598846...
Checkpoint 1865598846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,926.10241
Policy Entropy: 1.90599
Value Function Loss: 0.02403

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.29844
Value Function Update Magnitude: 0.30740

Collected Steps per Second: 20,534.68024
Overall Steps per Second: 9,990.07764

Timestep Collection Time: 2.43529
Timestep Consumption Time: 2.57047
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 5.00577

Cumulative Model Updates: 223,626
Cumulative Timesteps: 1,865,648,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,247.45952
Policy Entropy: 1.90956
Value Function Loss: 0.02517

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.30840
Value Function Update Magnitude: 0.31332

Collected Steps per Second: 20,639.93795
Overall Steps per Second: 10,088.58996

Timestep Collection Time: 2.42297
Timestep Consumption Time: 2.53411
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.95709

Cumulative Model Updates: 223,632
Cumulative Timesteps: 1,865,698,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1865698864...
Checkpoint 1865698864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,494.07010
Policy Entropy: 1.91179
Value Function Loss: 0.02595

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.31278
Value Function Update Magnitude: 0.33840

Collected Steps per Second: 19,266.08452
Overall Steps per Second: 9,833.68768

Timestep Collection Time: 2.59606
Timestep Consumption Time: 2.49013
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 5.08619

Cumulative Model Updates: 223,638
Cumulative Timesteps: 1,865,748,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,050.47545
Policy Entropy: 1.90772
Value Function Loss: 0.02344

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.08945
Policy Update Magnitude: 0.31130
Value Function Update Magnitude: 0.34191

Collected Steps per Second: 19,592.51794
Overall Steps per Second: 9,671.34709

Timestep Collection Time: 2.55250
Timestep Consumption Time: 2.61844
PPO Batch Consumption Time: 0.30825
Total Iteration Time: 5.17094

Cumulative Model Updates: 223,644
Cumulative Timesteps: 1,865,798,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1865798890...
Checkpoint 1865798890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,582.99993
Policy Entropy: 1.91858
Value Function Loss: 0.02472

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.30747
Value Function Update Magnitude: 0.30875

Collected Steps per Second: 18,973.39240
Overall Steps per Second: 9,560.42960

Timestep Collection Time: 2.63548
Timestep Consumption Time: 2.59483
PPO Batch Consumption Time: 0.30516
Total Iteration Time: 5.23031

Cumulative Model Updates: 223,650
Cumulative Timesteps: 1,865,848,894

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,696.04433
Policy Entropy: 1.91912
Value Function Loss: 0.02274

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07099
Policy Update Magnitude: 0.29984
Value Function Update Magnitude: 0.29272

Collected Steps per Second: 19,122.39526
Overall Steps per Second: 9,546.01136

Timestep Collection Time: 2.61474
Timestep Consumption Time: 2.62305
PPO Batch Consumption Time: 0.30718
Total Iteration Time: 5.23779

Cumulative Model Updates: 223,656
Cumulative Timesteps: 1,865,898,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1865898894...
Checkpoint 1865898894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,869.72765
Policy Entropy: 1.91913
Value Function Loss: 0.02417

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07103
Policy Update Magnitude: 0.29267
Value Function Update Magnitude: 0.28355

Collected Steps per Second: 19,827.43155
Overall Steps per Second: 9,805.49852

Timestep Collection Time: 2.52176
Timestep Consumption Time: 2.57742
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 5.09918

Cumulative Model Updates: 223,662
Cumulative Timesteps: 1,865,948,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,367.61805
Policy Entropy: 1.91816
Value Function Loss: 0.02501

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07434
Policy Update Magnitude: 0.29628
Value Function Update Magnitude: 0.26937

Collected Steps per Second: 20,380.95167
Overall Steps per Second: 10,100.22696

Timestep Collection Time: 2.45514
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.95415

Cumulative Model Updates: 223,668
Cumulative Timesteps: 1,865,998,932

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1865998932...
Checkpoint 1865998932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,940.87956
Policy Entropy: 1.92227
Value Function Loss: 0.02726

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07730
Policy Update Magnitude: 0.31052
Value Function Update Magnitude: 0.27275

Collected Steps per Second: 21,057.35457
Overall Steps per Second: 10,066.04339

Timestep Collection Time: 2.37494
Timestep Consumption Time: 2.59325
PPO Batch Consumption Time: 0.30725
Total Iteration Time: 4.96819

Cumulative Model Updates: 223,674
Cumulative Timesteps: 1,866,048,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,961.72630
Policy Entropy: 1.92529
Value Function Loss: 0.02590

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.30346
Value Function Update Magnitude: 0.26467

Collected Steps per Second: 21,095.00658
Overall Steps per Second: 10,539.97818

Timestep Collection Time: 2.37051
Timestep Consumption Time: 2.37390
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.74441

Cumulative Model Updates: 223,680
Cumulative Timesteps: 1,866,098,948

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1866098948...
Checkpoint 1866098948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,274.30988
Policy Entropy: 1.92066
Value Function Loss: 0.02347

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.07720
Policy Update Magnitude: 0.29318
Value Function Update Magnitude: 0.29513

Collected Steps per Second: 19,210.00680
Overall Steps per Second: 9,798.29848

Timestep Collection Time: 2.60520
Timestep Consumption Time: 2.50242
PPO Batch Consumption Time: 0.30403
Total Iteration Time: 5.10762

Cumulative Model Updates: 223,686
Cumulative Timesteps: 1,866,148,994

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,221.02625
Policy Entropy: 1.90877
Value Function Loss: 0.02173

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06769
Policy Update Magnitude: 0.28968
Value Function Update Magnitude: 0.29405

Collected Steps per Second: 18,195.14864
Overall Steps per Second: 9,549.85975

Timestep Collection Time: 2.74886
Timestep Consumption Time: 2.48849
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 5.23735

Cumulative Model Updates: 223,692
Cumulative Timesteps: 1,866,199,010

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1866199010...
Checkpoint 1866199010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,335.87460
Policy Entropy: 1.90588
Value Function Loss: 0.02199

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.07971
Policy Update Magnitude: 0.28798
Value Function Update Magnitude: 0.30927

Collected Steps per Second: 19,409.77445
Overall Steps per Second: 9,830.17518

Timestep Collection Time: 2.57705
Timestep Consumption Time: 2.51136
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 5.08841

Cumulative Model Updates: 223,698
Cumulative Timesteps: 1,866,249,030

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,653.37721
Policy Entropy: 1.90348
Value Function Loss: 0.02206

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.08315
Policy Update Magnitude: 0.29176
Value Function Update Magnitude: 0.30909

Collected Steps per Second: 21,011.80749
Overall Steps per Second: 9,653.86505

Timestep Collection Time: 2.37971
Timestep Consumption Time: 2.79977
PPO Batch Consumption Time: 0.34291
Total Iteration Time: 5.17948

Cumulative Model Updates: 223,704
Cumulative Timesteps: 1,866,299,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1866299032...
Checkpoint 1866299032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,251.19778
Policy Entropy: 1.91246
Value Function Loss: 0.02279

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.29662
Value Function Update Magnitude: 0.28692

Collected Steps per Second: 19,630.72836
Overall Steps per Second: 9,872.28664

Timestep Collection Time: 2.54835
Timestep Consumption Time: 2.51896
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 5.06732

Cumulative Model Updates: 223,710
Cumulative Timesteps: 1,866,349,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,003.70196
Policy Entropy: 1.91506
Value Function Loss: 0.02624

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.30531
Value Function Update Magnitude: 0.31765

Collected Steps per Second: 19,600.89351
Overall Steps per Second: 9,924.63942

Timestep Collection Time: 2.55141
Timestep Consumption Time: 2.48756
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 5.03897

Cumulative Model Updates: 223,716
Cumulative Timesteps: 1,866,399,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1866399068...
Checkpoint 1866399068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,789.73579
Policy Entropy: 1.90507
Value Function Loss: 0.02581

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.31108
Value Function Update Magnitude: 0.34798

Collected Steps per Second: 21,264.61124
Overall Steps per Second: 10,035.24850

Timestep Collection Time: 2.35339
Timestep Consumption Time: 2.63343
PPO Batch Consumption Time: 0.30070
Total Iteration Time: 4.98682

Cumulative Model Updates: 223,722
Cumulative Timesteps: 1,866,449,112

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,898.91234
Policy Entropy: 1.89781
Value Function Loss: 0.02553

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.07882
Policy Update Magnitude: 0.30923
Value Function Update Magnitude: 0.32778

Collected Steps per Second: 21,101.76104
Overall Steps per Second: 10,165.78274

Timestep Collection Time: 2.37165
Timestep Consumption Time: 2.55134
PPO Batch Consumption Time: 0.29899
Total Iteration Time: 4.92299

Cumulative Model Updates: 223,728
Cumulative Timesteps: 1,866,499,158

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1866499158...
Checkpoint 1866499158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,308.68264
Policy Entropy: 1.89884
Value Function Loss: 0.02465

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.30465
Value Function Update Magnitude: 0.30994

Collected Steps per Second: 19,890.15557
Overall Steps per Second: 9,855.49472

Timestep Collection Time: 2.51461
Timestep Consumption Time: 2.56032
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 5.07494

Cumulative Model Updates: 223,734
Cumulative Timesteps: 1,866,549,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,232.94837
Policy Entropy: 1.91374
Value Function Loss: 0.02479

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08053
Policy Update Magnitude: 0.30081
Value Function Update Magnitude: 0.32851

Collected Steps per Second: 21,873.47494
Overall Steps per Second: 10,565.61439

Timestep Collection Time: 2.28679
Timestep Consumption Time: 2.44744
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.73423

Cumulative Model Updates: 223,740
Cumulative Timesteps: 1,866,599,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1866599194...
Checkpoint 1866599194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,419.05072
Policy Entropy: 1.90644
Value Function Loss: 0.02377

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07312
Policy Update Magnitude: 0.29677
Value Function Update Magnitude: 0.32678

Collected Steps per Second: 20,413.75188
Overall Steps per Second: 10,147.87697

Timestep Collection Time: 2.45178
Timestep Consumption Time: 2.48029
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.93207

Cumulative Model Updates: 223,746
Cumulative Timesteps: 1,866,649,244

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,300.84386
Policy Entropy: 1.90771
Value Function Loss: 0.02460

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07347
Policy Update Magnitude: 0.29627
Value Function Update Magnitude: 0.31649

Collected Steps per Second: 20,698.44444
Overall Steps per Second: 10,162.00832

Timestep Collection Time: 2.41690
Timestep Consumption Time: 2.50595
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.92285

Cumulative Model Updates: 223,752
Cumulative Timesteps: 1,866,699,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1866699270...
Checkpoint 1866699270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,049.59287
Policy Entropy: 1.90185
Value Function Loss: 0.02440

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07491
Policy Update Magnitude: 0.30182
Value Function Update Magnitude: 0.32359

Collected Steps per Second: 21,460.72603
Overall Steps per Second: 9,924.48007

Timestep Collection Time: 2.32984
Timestep Consumption Time: 2.70821
PPO Batch Consumption Time: 0.32557
Total Iteration Time: 5.03805

Cumulative Model Updates: 223,758
Cumulative Timesteps: 1,866,749,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,480.96440
Policy Entropy: 1.91582
Value Function Loss: 0.02285

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07387
Policy Update Magnitude: 0.30391
Value Function Update Magnitude: 0.32731

Collected Steps per Second: 21,877.14893
Overall Steps per Second: 10,408.82201

Timestep Collection Time: 2.28704
Timestep Consumption Time: 2.51984
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.80688

Cumulative Model Updates: 223,764
Cumulative Timesteps: 1,866,799,304

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1866799304...
Checkpoint 1866799304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,331.02754
Policy Entropy: 1.91507
Value Function Loss: 0.02472

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07142
Policy Update Magnitude: 0.30338
Value Function Update Magnitude: 0.30412

Collected Steps per Second: 20,959.04869
Overall Steps per Second: 10,025.55032

Timestep Collection Time: 2.38656
Timestep Consumption Time: 2.60269
PPO Batch Consumption Time: 0.31069
Total Iteration Time: 4.98925

Cumulative Model Updates: 223,770
Cumulative Timesteps: 1,866,849,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,187.72813
Policy Entropy: 1.93354
Value Function Loss: 0.02284

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07440
Policy Update Magnitude: 0.30711
Value Function Update Magnitude: 0.31014

Collected Steps per Second: 21,943.50245
Overall Steps per Second: 10,551.84910

Timestep Collection Time: 2.28022
Timestep Consumption Time: 2.46170
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.74192

Cumulative Model Updates: 223,776
Cumulative Timesteps: 1,866,899,360

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1866899360...
Checkpoint 1866899360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,678.37402
Policy Entropy: 1.93689
Value Function Loss: 0.02779

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08015
Policy Update Magnitude: 0.31438
Value Function Update Magnitude: 0.33404

Collected Steps per Second: 20,442.36794
Overall Steps per Second: 9,988.96000

Timestep Collection Time: 2.44590
Timestep Consumption Time: 2.55963
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 5.00553

Cumulative Model Updates: 223,782
Cumulative Timesteps: 1,866,949,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,309.85053
Policy Entropy: 1.93512
Value Function Loss: 0.03028

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.08429
Policy Update Magnitude: 0.32549
Value Function Update Magnitude: 0.37915

Collected Steps per Second: 19,868.53978
Overall Steps per Second: 9,871.79537

Timestep Collection Time: 2.51694
Timestep Consumption Time: 2.54880
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 5.06575

Cumulative Model Updates: 223,788
Cumulative Timesteps: 1,866,999,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1866999368...
Checkpoint 1866999368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,916.45514
Policy Entropy: 1.91585
Value Function Loss: 0.02811

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.08860
Policy Update Magnitude: 0.31591
Value Function Update Magnitude: 0.37999

Collected Steps per Second: 19,645.18087
Overall Steps per Second: 9,886.74777

Timestep Collection Time: 2.54587
Timestep Consumption Time: 2.51282
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 5.05869

Cumulative Model Updates: 223,794
Cumulative Timesteps: 1,867,049,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,659.70410
Policy Entropy: 1.91877
Value Function Loss: 0.02528

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.08090
Policy Update Magnitude: 0.30847
Value Function Update Magnitude: 0.36162

Collected Steps per Second: 21,875.04278
Overall Steps per Second: 10,376.23003

Timestep Collection Time: 2.28662
Timestep Consumption Time: 2.53401
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.82063

Cumulative Model Updates: 223,800
Cumulative Timesteps: 1,867,099,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1867099402...
Checkpoint 1867099402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,398.73811
Policy Entropy: 1.92776
Value Function Loss: 0.02517

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07799
Policy Update Magnitude: 0.31127
Value Function Update Magnitude: 0.35751

Collected Steps per Second: 21,373.40148
Overall Steps per Second: 10,296.61734

Timestep Collection Time: 2.34057
Timestep Consumption Time: 2.51792
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.85849

Cumulative Model Updates: 223,806
Cumulative Timesteps: 1,867,149,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,098.44045
Policy Entropy: 1.94233
Value Function Loss: 0.02749

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.08248
Policy Update Magnitude: 0.30928
Value Function Update Magnitude: 0.34503

Collected Steps per Second: 21,981.32887
Overall Steps per Second: 10,409.23830

Timestep Collection Time: 2.27630
Timestep Consumption Time: 2.53059
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.80688

Cumulative Model Updates: 223,812
Cumulative Timesteps: 1,867,199,464

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1867199464...
Checkpoint 1867199464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,610.12929
Policy Entropy: 1.93056
Value Function Loss: 0.02722

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.08883
Policy Update Magnitude: 0.31429
Value Function Update Magnitude: 0.34402

Collected Steps per Second: 21,451.42210
Overall Steps per Second: 10,335.52013

Timestep Collection Time: 2.33085
Timestep Consumption Time: 2.50684
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.83769

Cumulative Model Updates: 223,818
Cumulative Timesteps: 1,867,249,464

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,761.73178
Policy Entropy: 1.93511
Value Function Loss: 0.02931

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08591
Policy Update Magnitude: 0.31273
Value Function Update Magnitude: 0.35841

Collected Steps per Second: 21,691.16214
Overall Steps per Second: 10,380.14990

Timestep Collection Time: 2.30592
Timestep Consumption Time: 2.51270
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.81862

Cumulative Model Updates: 223,824
Cumulative Timesteps: 1,867,299,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1867299482...
Checkpoint 1867299482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,174.57894
Policy Entropy: 1.91822
Value Function Loss: 0.02804

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.31733
Value Function Update Magnitude: 0.35091

Collected Steps per Second: 21,014.85108
Overall Steps per Second: 10,213.53689

Timestep Collection Time: 2.37984
Timestep Consumption Time: 2.51680
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.89664

Cumulative Model Updates: 223,830
Cumulative Timesteps: 1,867,349,494

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,340.02305
Policy Entropy: 1.92735
Value Function Loss: 0.02709

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.07871
Policy Update Magnitude: 0.31309
Value Function Update Magnitude: 0.30412

Collected Steps per Second: 22,047.10107
Overall Steps per Second: 10,457.15540

Timestep Collection Time: 2.26814
Timestep Consumption Time: 2.51384
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.78199

Cumulative Model Updates: 223,836
Cumulative Timesteps: 1,867,399,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1867399500...
Checkpoint 1867399500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,760.58621
Policy Entropy: 1.91499
Value Function Loss: 0.02406

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.30223
Value Function Update Magnitude: 0.31520

Collected Steps per Second: 20,356.19806
Overall Steps per Second: 10,185.66036

Timestep Collection Time: 2.45753
Timestep Consumption Time: 2.45388
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.91141

Cumulative Model Updates: 223,842
Cumulative Timesteps: 1,867,449,526

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,470.53747
Policy Entropy: 1.93443
Value Function Loss: 0.02709

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07249
Policy Update Magnitude: 0.31297
Value Function Update Magnitude: 0.35454

Collected Steps per Second: 21,432.55415
Overall Steps per Second: 10,456.99143

Timestep Collection Time: 2.33383
Timestep Consumption Time: 2.44957
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.78340

Cumulative Model Updates: 223,848
Cumulative Timesteps: 1,867,499,546

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1867499546...
Checkpoint 1867499546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,061.90418
Policy Entropy: 1.93484
Value Function Loss: 0.02681

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.30985
Value Function Update Magnitude: 0.37546

Collected Steps per Second: 20,804.19636
Overall Steps per Second: 10,367.25175

Timestep Collection Time: 2.40509
Timestep Consumption Time: 2.42126
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.82635

Cumulative Model Updates: 223,854
Cumulative Timesteps: 1,867,549,582

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,538.13881
Policy Entropy: 1.94025
Value Function Loss: 0.02827

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.07691
Policy Update Magnitude: 0.31054
Value Function Update Magnitude: 0.38130

Collected Steps per Second: 21,246.34520
Overall Steps per Second: 10,299.85519

Timestep Collection Time: 2.35410
Timestep Consumption Time: 2.50189
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.85599

Cumulative Model Updates: 223,860
Cumulative Timesteps: 1,867,599,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1867599598...
Checkpoint 1867599598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,449.54808
Policy Entropy: 1.93202
Value Function Loss: 0.02759

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.08457
Policy Update Magnitude: 0.31184
Value Function Update Magnitude: 0.39198

Collected Steps per Second: 21,636.95951
Overall Steps per Second: 10,576.38283

Timestep Collection Time: 2.31132
Timestep Consumption Time: 2.41714
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.72846

Cumulative Model Updates: 223,866
Cumulative Timesteps: 1,867,649,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,207.72214
Policy Entropy: 1.91070
Value Function Loss: 0.02472

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.30565
Value Function Update Magnitude: 0.38439

Collected Steps per Second: 21,823.43353
Overall Steps per Second: 10,488.01809

Timestep Collection Time: 2.29176
Timestep Consumption Time: 2.47692
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.76868

Cumulative Model Updates: 223,872
Cumulative Timesteps: 1,867,699,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1867699622...
Checkpoint 1867699622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,680.06091
Policy Entropy: 1.91371
Value Function Loss: 0.02366

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.30571
Value Function Update Magnitude: 0.36343

Collected Steps per Second: 21,828.79953
Overall Steps per Second: 10,642.10349

Timestep Collection Time: 2.29229
Timestep Consumption Time: 2.40960
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.70189

Cumulative Model Updates: 223,878
Cumulative Timesteps: 1,867,749,660

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,161.95541
Policy Entropy: 1.90870
Value Function Loss: 0.02564

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.08275
Policy Update Magnitude: 0.31186
Value Function Update Magnitude: 0.36040

Collected Steps per Second: 21,419.79051
Overall Steps per Second: 10,316.88485

Timestep Collection Time: 2.33550
Timestep Consumption Time: 2.51344
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.84894

Cumulative Model Updates: 223,884
Cumulative Timesteps: 1,867,799,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1867799686...
Checkpoint 1867799686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,339.51915
Policy Entropy: 1.92285
Value Function Loss: 0.02805

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.32142
Value Function Update Magnitude: 0.37615

Collected Steps per Second: 19,599.46814
Overall Steps per Second: 9,650.30595

Timestep Collection Time: 2.55242
Timestep Consumption Time: 2.63146
PPO Batch Consumption Time: 0.30389
Total Iteration Time: 5.18388

Cumulative Model Updates: 223,890
Cumulative Timesteps: 1,867,849,712

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,872.31899
Policy Entropy: 1.91857
Value Function Loss: 0.02730

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08163
Policy Update Magnitude: 0.32027
Value Function Update Magnitude: 0.36375

Collected Steps per Second: 20,109.30992
Overall Steps per Second: 9,574.96909

Timestep Collection Time: 2.48900
Timestep Consumption Time: 2.73838
PPO Batch Consumption Time: 0.32248
Total Iteration Time: 5.22738

Cumulative Model Updates: 223,896
Cumulative Timesteps: 1,867,899,764

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1867899764...
Checkpoint 1867899764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,548.44760
Policy Entropy: 1.92835
Value Function Loss: 0.03049

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.31905
Value Function Update Magnitude: 0.31098

Collected Steps per Second: 18,365.89116
Overall Steps per Second: 9,750.30293

Timestep Collection Time: 2.72244
Timestep Consumption Time: 2.40561
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 5.12805

Cumulative Model Updates: 223,902
Cumulative Timesteps: 1,867,949,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,197.18999
Policy Entropy: 1.92290
Value Function Loss: 0.02733

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.07378
Policy Update Magnitude: 0.31262
Value Function Update Magnitude: 0.30940

Collected Steps per Second: 19,656.53328
Overall Steps per Second: 10,041.34568

Timestep Collection Time: 2.54490
Timestep Consumption Time: 2.43690
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.98180

Cumulative Model Updates: 223,908
Cumulative Timesteps: 1,867,999,788

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1867999788...
Checkpoint 1867999788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,560.40235
Policy Entropy: 1.92075
Value Function Loss: 0.02815

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.07404
Policy Update Magnitude: 0.30980
Value Function Update Magnitude: 0.34657

Collected Steps per Second: 19,762.93412
Overall Steps per Second: 9,774.17802

Timestep Collection Time: 2.53009
Timestep Consumption Time: 2.58563
PPO Batch Consumption Time: 0.30178
Total Iteration Time: 5.11572

Cumulative Model Updates: 223,914
Cumulative Timesteps: 1,868,049,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,360.70466
Policy Entropy: 1.89813
Value Function Loss: 0.02314

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07505
Policy Update Magnitude: 0.30778
Value Function Update Magnitude: 0.35974

Collected Steps per Second: 21,995.30054
Overall Steps per Second: 10,438.42098

Timestep Collection Time: 2.27430
Timestep Consumption Time: 2.51799
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.79230

Cumulative Model Updates: 223,920
Cumulative Timesteps: 1,868,099,814

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1868099814...
Checkpoint 1868099814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,274.85864
Policy Entropy: 1.92225
Value Function Loss: 0.02686

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07482
Policy Update Magnitude: 0.31331
Value Function Update Magnitude: 0.36691

Collected Steps per Second: 21,063.58956
Overall Steps per Second: 10,385.74441

Timestep Collection Time: 2.37443
Timestep Consumption Time: 2.44121
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.81564

Cumulative Model Updates: 223,926
Cumulative Timesteps: 1,868,149,828

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,731.47325
Policy Entropy: 1.92379
Value Function Loss: 0.02611

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07884
Policy Update Magnitude: 0.31430
Value Function Update Magnitude: 0.35221

Collected Steps per Second: 22,031.05616
Overall Steps per Second: 10,418.49901

Timestep Collection Time: 2.27007
Timestep Consumption Time: 2.53024
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.80031

Cumulative Model Updates: 223,932
Cumulative Timesteps: 1,868,199,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1868199840...
Checkpoint 1868199840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,042.97698
Policy Entropy: 1.93936
Value Function Loss: 0.02608

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.07781
Policy Update Magnitude: 0.30793
Value Function Update Magnitude: 0.33793

Collected Steps per Second: 21,536.21065
Overall Steps per Second: 10,505.09208

Timestep Collection Time: 2.32195
Timestep Consumption Time: 2.43822
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.76017

Cumulative Model Updates: 223,938
Cumulative Timesteps: 1,868,249,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,650.62510
Policy Entropy: 1.92623
Value Function Loss: 0.02758

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.07627
Policy Update Magnitude: 0.31267
Value Function Update Magnitude: 0.35810

Collected Steps per Second: 21,883.91175
Overall Steps per Second: 10,596.70836

Timestep Collection Time: 2.28561
Timestep Consumption Time: 2.43454
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.72015

Cumulative Model Updates: 223,944
Cumulative Timesteps: 1,868,299,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1868299864...
Checkpoint 1868299864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,233.95359
Policy Entropy: 1.93164
Value Function Loss: 0.02793

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08400
Policy Update Magnitude: 0.32113
Value Function Update Magnitude: 0.34961

Collected Steps per Second: 21,188.25687
Overall Steps per Second: 10,290.22882

Timestep Collection Time: 2.35989
Timestep Consumption Time: 2.49928
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.85917

Cumulative Model Updates: 223,950
Cumulative Timesteps: 1,868,349,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,013.34249
Policy Entropy: 1.92771
Value Function Loss: 0.02881

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.32373
Value Function Update Magnitude: 0.33994

Collected Steps per Second: 21,852.23048
Overall Steps per Second: 10,401.39753

Timestep Collection Time: 2.28983
Timestep Consumption Time: 2.52086
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.81070

Cumulative Model Updates: 223,956
Cumulative Timesteps: 1,868,399,904

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1868399904...
Checkpoint 1868399904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,662.42345
Policy Entropy: 1.91981
Value Function Loss: 0.02677

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.32046
Value Function Update Magnitude: 0.34398

Collected Steps per Second: 21,419.97566
Overall Steps per Second: 10,481.39198

Timestep Collection Time: 2.33520
Timestep Consumption Time: 2.43706
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.77227

Cumulative Model Updates: 223,962
Cumulative Timesteps: 1,868,449,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,002.61653
Policy Entropy: 1.90698
Value Function Loss: 0.02588

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.07636
Policy Update Magnitude: 0.31826
Value Function Update Magnitude: 0.33898

Collected Steps per Second: 21,858.78351
Overall Steps per Second: 10,482.16645

Timestep Collection Time: 2.28741
Timestep Consumption Time: 2.48260
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.77001

Cumulative Model Updates: 223,968
Cumulative Timesteps: 1,868,499,924

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1868499924...
Checkpoint 1868499924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,366.77446
Policy Entropy: 1.92337
Value Function Loss: 0.02721

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.31685
Value Function Update Magnitude: 0.34288

Collected Steps per Second: 19,196.81426
Overall Steps per Second: 9,675.18775

Timestep Collection Time: 2.60481
Timestep Consumption Time: 2.56346
PPO Batch Consumption Time: 0.29888
Total Iteration Time: 5.16827

Cumulative Model Updates: 223,974
Cumulative Timesteps: 1,868,549,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,138.26798
Policy Entropy: 1.94622
Value Function Loss: 0.02903

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.31340
Value Function Update Magnitude: 0.36241

Collected Steps per Second: 17,251.28889
Overall Steps per Second: 9,053.49489

Timestep Collection Time: 2.89915
Timestep Consumption Time: 2.62513
PPO Batch Consumption Time: 0.30960
Total Iteration Time: 5.52428

Cumulative Model Updates: 223,980
Cumulative Timesteps: 1,868,599,942

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1868599942...
Checkpoint 1868599942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,851.15631
Policy Entropy: 1.94276
Value Function Loss: 0.02517

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08016
Policy Update Magnitude: 0.31252
Value Function Update Magnitude: 0.38019

Collected Steps per Second: 17,135.28264
Overall Steps per Second: 9,426.39227

Timestep Collection Time: 2.91889
Timestep Consumption Time: 2.38706
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 5.30595

Cumulative Model Updates: 223,986
Cumulative Timesteps: 1,868,649,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,025.58160
Policy Entropy: 1.93060
Value Function Loss: 0.02289

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07905
Policy Update Magnitude: 0.29733
Value Function Update Magnitude: 0.34834

Collected Steps per Second: 18,098.52089
Overall Steps per Second: 9,137.28586

Timestep Collection Time: 2.76442
Timestep Consumption Time: 2.71116
PPO Batch Consumption Time: 0.32615
Total Iteration Time: 5.47559

Cumulative Model Updates: 223,992
Cumulative Timesteps: 1,868,699,990

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1868699990...
Checkpoint 1868699990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,984.99151
Policy Entropy: 1.90880
Value Function Loss: 0.02079

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07035
Policy Update Magnitude: 0.29309
Value Function Update Magnitude: 0.31308

Collected Steps per Second: 17,396.16603
Overall Steps per Second: 8,560.20246

Timestep Collection Time: 2.87466
Timestep Consumption Time: 2.96726
PPO Batch Consumption Time: 0.35059
Total Iteration Time: 5.84192

Cumulative Model Updates: 223,998
Cumulative Timesteps: 1,868,749,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,574.24495
Policy Entropy: 1.93369
Value Function Loss: 0.02243

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06900
Policy Update Magnitude: 0.29549
Value Function Update Magnitude: 0.30251

Collected Steps per Second: 17,353.58459
Overall Steps per Second: 8,249.81359

Timestep Collection Time: 2.88240
Timestep Consumption Time: 3.18077
PPO Batch Consumption Time: 0.39393
Total Iteration Time: 6.06317

Cumulative Model Updates: 224,004
Cumulative Timesteps: 1,868,800,018

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1868800018...
Checkpoint 1868800018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,374.57832
Policy Entropy: 1.93679
Value Function Loss: 0.02586

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07167
Policy Update Magnitude: 0.30381
Value Function Update Magnitude: 0.31644

Collected Steps per Second: 14,368.19923
Overall Steps per Second: 7,503.98900

Timestep Collection Time: 3.48005
Timestep Consumption Time: 3.18334
PPO Batch Consumption Time: 0.38090
Total Iteration Time: 6.66339

Cumulative Model Updates: 224,010
Cumulative Timesteps: 1,868,850,020

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,912.18932
Policy Entropy: 1.94249
Value Function Loss: 0.02775

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07438
Policy Update Magnitude: 0.31377
Value Function Update Magnitude: 0.34036

Collected Steps per Second: 12,216.71145
Overall Steps per Second: 7,317.96646

Timestep Collection Time: 4.09374
Timestep Consumption Time: 2.74040
PPO Batch Consumption Time: 0.30110
Total Iteration Time: 6.83414

Cumulative Model Updates: 224,016
Cumulative Timesteps: 1,868,900,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1868900032...
Checkpoint 1868900032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,900.47247
Policy Entropy: 1.93807
Value Function Loss: 0.02679

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.31432
Value Function Update Magnitude: 0.37461

Collected Steps per Second: 17,378.35007
Overall Steps per Second: 8,682.57960

Timestep Collection Time: 2.87875
Timestep Consumption Time: 2.88313
PPO Batch Consumption Time: 0.32007
Total Iteration Time: 5.76188

Cumulative Model Updates: 224,022
Cumulative Timesteps: 1,868,950,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,325.43155
Policy Entropy: 1.93859
Value Function Loss: 0.02554

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.30381
Value Function Update Magnitude: 0.38195

Collected Steps per Second: 20,106.34406
Overall Steps per Second: 9,810.01705

Timestep Collection Time: 2.48678
Timestep Consumption Time: 2.61005
PPO Batch Consumption Time: 0.30107
Total Iteration Time: 5.09683

Cumulative Model Updates: 224,028
Cumulative Timesteps: 1,869,000,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1869000060...
Checkpoint 1869000060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,129.99600
Policy Entropy: 1.94738
Value Function Loss: 0.02447

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.29721
Value Function Update Magnitude: 0.35701

Collected Steps per Second: 19,616.73363
Overall Steps per Second: 9,771.62781

Timestep Collection Time: 2.54976
Timestep Consumption Time: 2.56893
PPO Batch Consumption Time: 0.30343
Total Iteration Time: 5.11870

Cumulative Model Updates: 224,034
Cumulative Timesteps: 1,869,050,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,913.82165
Policy Entropy: 1.93623
Value Function Loss: 0.02318

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.29687
Value Function Update Magnitude: 0.32735

Collected Steps per Second: 21,068.97475
Overall Steps per Second: 10,109.37199

Timestep Collection Time: 2.37382
Timestep Consumption Time: 2.57347
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.94729

Cumulative Model Updates: 224,040
Cumulative Timesteps: 1,869,100,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1869100092...
Checkpoint 1869100092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,759.62844
Policy Entropy: 1.94146
Value Function Loss: 0.02520

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.30143
Value Function Update Magnitude: 0.31725

Collected Steps per Second: 20,379.34286
Overall Steps per Second: 10,089.03973

Timestep Collection Time: 2.45503
Timestep Consumption Time: 2.50401
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.95904

Cumulative Model Updates: 224,046
Cumulative Timesteps: 1,869,150,124

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,385.25823
Policy Entropy: 1.94196
Value Function Loss: 0.02560

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.30812
Value Function Update Magnitude: 0.34645

Collected Steps per Second: 20,941.49020
Overall Steps per Second: 10,161.43639

Timestep Collection Time: 2.38808
Timestep Consumption Time: 2.53347
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.92155

Cumulative Model Updates: 224,052
Cumulative Timesteps: 1,869,200,134

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1869200134...
Checkpoint 1869200134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,008.98405
Policy Entropy: 1.95506
Value Function Loss: 0.03030

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.31689
Value Function Update Magnitude: 0.35737

Collected Steps per Second: 20,523.86187
Overall Steps per Second: 10,113.85537

Timestep Collection Time: 2.43746
Timestep Consumption Time: 2.50883
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.94628

Cumulative Model Updates: 224,058
Cumulative Timesteps: 1,869,250,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,123.26368
Policy Entropy: 1.93983
Value Function Loss: 0.03001

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.32487
Value Function Update Magnitude: 0.35941

Collected Steps per Second: 20,005.92617
Overall Steps per Second: 10,163.88425

Timestep Collection Time: 2.49976
Timestep Consumption Time: 2.42060
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.92036

Cumulative Model Updates: 224,064
Cumulative Timesteps: 1,869,300,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1869300170...
Checkpoint 1869300170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,170.62590
Policy Entropy: 1.95589
Value Function Loss: 0.03192

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.32835
Value Function Update Magnitude: 0.34324

Collected Steps per Second: 19,735.16858
Overall Steps per Second: 9,932.58370

Timestep Collection Time: 2.53365
Timestep Consumption Time: 2.50049
PPO Batch Consumption Time: 0.30405
Total Iteration Time: 5.03414

Cumulative Model Updates: 224,070
Cumulative Timesteps: 1,869,350,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,823.19034
Policy Entropy: 1.95818
Value Function Loss: 0.03089

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.33032
Value Function Update Magnitude: 0.31125

Collected Steps per Second: 20,737.94899
Overall Steps per Second: 9,950.65012

Timestep Collection Time: 2.41123
Timestep Consumption Time: 2.61397
PPO Batch Consumption Time: 0.31437
Total Iteration Time: 5.02520

Cumulative Model Updates: 224,076
Cumulative Timesteps: 1,869,400,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1869400176...
Checkpoint 1869400176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,519.15628
Policy Entropy: 1.94041
Value Function Loss: 0.03121

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.32861
Value Function Update Magnitude: 0.24824

Collected Steps per Second: 20,056.06282
Overall Steps per Second: 10,045.35836

Timestep Collection Time: 2.49381
Timestep Consumption Time: 2.48521
PPO Batch Consumption Time: 0.29902
Total Iteration Time: 4.97902

Cumulative Model Updates: 224,082
Cumulative Timesteps: 1,869,450,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,217.63551
Policy Entropy: 1.91884
Value Function Loss: 0.03018

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.32667
Value Function Update Magnitude: 0.21345

Collected Steps per Second: 20,797.54065
Overall Steps per Second: 9,823.90679

Timestep Collection Time: 2.40500
Timestep Consumption Time: 2.68646
PPO Batch Consumption Time: 0.32466
Total Iteration Time: 5.09146

Cumulative Model Updates: 224,088
Cumulative Timesteps: 1,869,500,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1869500210...
Checkpoint 1869500210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,426.84435
Policy Entropy: 1.90748
Value Function Loss: 0.02956

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.09338
Policy Update Magnitude: 0.31782
Value Function Update Magnitude: 0.19247

Collected Steps per Second: 21,888.84297
Overall Steps per Second: 10,248.70063

Timestep Collection Time: 2.28537
Timestep Consumption Time: 2.59564
PPO Batch Consumption Time: 0.31023
Total Iteration Time: 4.88101

Cumulative Model Updates: 224,094
Cumulative Timesteps: 1,869,550,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,682.41218
Policy Entropy: 1.92119
Value Function Loss: 0.02813

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.08722
Policy Update Magnitude: 0.30077
Value Function Update Magnitude: 0.21364

Collected Steps per Second: 20,151.80137
Overall Steps per Second: 9,956.19969

Timestep Collection Time: 2.48166
Timestep Consumption Time: 2.54134
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 5.02300

Cumulative Model Updates: 224,100
Cumulative Timesteps: 1,869,600,244

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1869600244...
Checkpoint 1869600244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,625.13727
Policy Entropy: 1.93498
Value Function Loss: 0.02621

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07882
Policy Update Magnitude: 0.30465
Value Function Update Magnitude: 0.32751

Collected Steps per Second: 20,735.09752
Overall Steps per Second: 10,105.23648

Timestep Collection Time: 2.41176
Timestep Consumption Time: 2.53697
PPO Batch Consumption Time: 0.29888
Total Iteration Time: 4.94872

Cumulative Model Updates: 224,106
Cumulative Timesteps: 1,869,650,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,255.76391
Policy Entropy: 1.96561
Value Function Loss: 0.02604

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07798
Policy Update Magnitude: 0.31231
Value Function Update Magnitude: 0.36779

Collected Steps per Second: 21,441.65153
Overall Steps per Second: 10,184.31273

Timestep Collection Time: 2.33359
Timestep Consumption Time: 2.57946
PPO Batch Consumption Time: 0.30112
Total Iteration Time: 4.91305

Cumulative Model Updates: 224,112
Cumulative Timesteps: 1,869,700,288

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1869700288...
Checkpoint 1869700288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,258.11070
Policy Entropy: 1.96713
Value Function Loss: 0.02827

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.31210
Value Function Update Magnitude: 0.32197

Collected Steps per Second: 21,776.57669
Overall Steps per Second: 10,751.03308

Timestep Collection Time: 2.29715
Timestep Consumption Time: 2.35580
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.65295

Cumulative Model Updates: 224,118
Cumulative Timesteps: 1,869,750,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,774.34263
Policy Entropy: 1.96356
Value Function Loss: 0.02717

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.31173
Value Function Update Magnitude: 0.35888

Collected Steps per Second: 21,833.32450
Overall Steps per Second: 10,143.18551

Timestep Collection Time: 2.29118
Timestep Consumption Time: 2.64061
PPO Batch Consumption Time: 0.31182
Total Iteration Time: 4.93178

Cumulative Model Updates: 224,124
Cumulative Timesteps: 1,869,800,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1869800336...
Checkpoint 1869800336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,173.73244
Policy Entropy: 1.95051
Value Function Loss: 0.02868

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.31488
Value Function Update Magnitude: 0.38905

Collected Steps per Second: 18,760.16580
Overall Steps per Second: 9,618.79625

Timestep Collection Time: 2.66586
Timestep Consumption Time: 2.53354
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 5.19940

Cumulative Model Updates: 224,130
Cumulative Timesteps: 1,869,850,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,899.38520
Policy Entropy: 1.94654
Value Function Loss: 0.02654

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07107
Policy Update Magnitude: 0.31892
Value Function Update Magnitude: 0.38629

Collected Steps per Second: 21,506.01800
Overall Steps per Second: 10,330.00315

Timestep Collection Time: 2.32595
Timestep Consumption Time: 2.51645
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.84240

Cumulative Model Updates: 224,136
Cumulative Timesteps: 1,869,900,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1869900370...
Checkpoint 1869900370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,044.21848
Policy Entropy: 1.95011
Value Function Loss: 0.02729

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.06885
Policy Update Magnitude: 0.31455
Value Function Update Magnitude: 0.39137

Collected Steps per Second: 20,544.10456
Overall Steps per Second: 10,018.82782

Timestep Collection Time: 2.43466
Timestep Consumption Time: 2.55774
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.99240

Cumulative Model Updates: 224,142
Cumulative Timesteps: 1,869,950,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,333.92833
Policy Entropy: 1.94497
Value Function Loss: 0.02418

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.06760
Policy Update Magnitude: 0.30840
Value Function Update Magnitude: 0.37706

Collected Steps per Second: 21,038.44956
Overall Steps per Second: 10,144.31205

Timestep Collection Time: 2.37736
Timestep Consumption Time: 2.55309
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.93045

Cumulative Model Updates: 224,148
Cumulative Timesteps: 1,870,000,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1870000404...
Checkpoint 1870000404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,539.08657
Policy Entropy: 1.93439
Value Function Loss: 0.02531

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07257
Policy Update Magnitude: 0.30897
Value Function Update Magnitude: 0.39704

Collected Steps per Second: 20,112.96740
Overall Steps per Second: 9,969.86761

Timestep Collection Time: 2.48755
Timestep Consumption Time: 2.53077
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 5.01832

Cumulative Model Updates: 224,154
Cumulative Timesteps: 1,870,050,436

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,903.82791
Policy Entropy: 1.92371
Value Function Loss: 0.02680

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07527
Policy Update Magnitude: 0.31704
Value Function Update Magnitude: 0.39379

Collected Steps per Second: 20,817.02083
Overall Steps per Second: 10,376.97771

Timestep Collection Time: 2.40294
Timestep Consumption Time: 2.41754
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.82048

Cumulative Model Updates: 224,160
Cumulative Timesteps: 1,870,100,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1870100458...
Checkpoint 1870100458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,980.73871
Policy Entropy: 1.91768
Value Function Loss: 0.02568

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08108
Policy Update Magnitude: 0.31872
Value Function Update Magnitude: 0.38193

Collected Steps per Second: 20,508.69348
Overall Steps per Second: 10,235.58143

Timestep Collection Time: 2.43945
Timestep Consumption Time: 2.44840
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.88785

Cumulative Model Updates: 224,166
Cumulative Timesteps: 1,870,150,488

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,147.74553
Policy Entropy: 1.92683
Value Function Loss: 0.02464

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08318
Policy Update Magnitude: 0.31093
Value Function Update Magnitude: 0.35340

Collected Steps per Second: 21,105.28872
Overall Steps per Second: 10,390.42453

Timestep Collection Time: 2.36917
Timestep Consumption Time: 2.44315
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.81232

Cumulative Model Updates: 224,172
Cumulative Timesteps: 1,870,200,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1870200490...
Checkpoint 1870200490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,672.31263
Policy Entropy: 1.92710
Value Function Loss: 0.02369

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.30585
Value Function Update Magnitude: 0.31028

Collected Steps per Second: 20,333.45022
Overall Steps per Second: 10,214.36180

Timestep Collection Time: 2.46136
Timestep Consumption Time: 2.43840
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.89977

Cumulative Model Updates: 224,178
Cumulative Timesteps: 1,870,250,538

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,086.93145
Policy Entropy: 1.93653
Value Function Loss: 0.02582

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.30865
Value Function Update Magnitude: 0.32866

Collected Steps per Second: 21,113.93710
Overall Steps per Second: 10,429.04561

Timestep Collection Time: 2.36829
Timestep Consumption Time: 2.42639
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.79469

Cumulative Model Updates: 224,184
Cumulative Timesteps: 1,870,300,542

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1870300542...
Checkpoint 1870300542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,704.69875
Policy Entropy: 1.93639
Value Function Loss: 0.02493

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.30630
Value Function Update Magnitude: 0.31538

Collected Steps per Second: 21,175.68762
Overall Steps per Second: 10,301.25295

Timestep Collection Time: 2.36177
Timestep Consumption Time: 2.49318
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.85494

Cumulative Model Updates: 224,190
Cumulative Timesteps: 1,870,350,554

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,692.28384
Policy Entropy: 1.94990
Value Function Loss: 0.02513

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.09345
Policy Update Magnitude: 0.30489
Value Function Update Magnitude: 0.26679

Collected Steps per Second: 21,858.25015
Overall Steps per Second: 10,444.23471

Timestep Collection Time: 2.28847
Timestep Consumption Time: 2.50096
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.78944

Cumulative Model Updates: 224,196
Cumulative Timesteps: 1,870,400,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1870400576...
Checkpoint 1870400576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,263.20750
Policy Entropy: 1.95430
Value Function Loss: 0.02252

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07885
Policy Update Magnitude: 0.30550
Value Function Update Magnitude: 0.31455

Collected Steps per Second: 20,872.86860
Overall Steps per Second: 10,183.76126

Timestep Collection Time: 2.39670
Timestep Consumption Time: 2.51563
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.91233

Cumulative Model Updates: 224,202
Cumulative Timesteps: 1,870,450,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,535.07088
Policy Entropy: 1.93852
Value Function Loss: 0.02377

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.08171
Policy Update Magnitude: 0.32930
Value Function Update Magnitude: 0.33430

Collected Steps per Second: 21,360.77497
Overall Steps per Second: 10,366.71186

Timestep Collection Time: 2.34186
Timestep Consumption Time: 2.48358
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.82545

Cumulative Model Updates: 224,208
Cumulative Timesteps: 1,870,500,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1870500626...
Checkpoint 1870500626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,266.04997
Policy Entropy: 1.92754
Value Function Loss: 0.02738

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.32580
Value Function Update Magnitude: 0.34261

Collected Steps per Second: 20,871.90650
Overall Steps per Second: 10,181.46071

Timestep Collection Time: 2.39691
Timestep Consumption Time: 2.51673
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.91364

Cumulative Model Updates: 224,214
Cumulative Timesteps: 1,870,550,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,437.08752
Policy Entropy: 1.91534
Value Function Loss: 0.03116

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.07924
Policy Update Magnitude: 0.31828
Value Function Update Magnitude: 0.37212

Collected Steps per Second: 21,194.57741
Overall Steps per Second: 10,172.93274

Timestep Collection Time: 2.35957
Timestep Consumption Time: 2.55642
PPO Batch Consumption Time: 0.29935
Total Iteration Time: 4.91599

Cumulative Model Updates: 224,220
Cumulative Timesteps: 1,870,600,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1870600664...
Checkpoint 1870600664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,370.24558
Policy Entropy: 1.93363
Value Function Loss: 0.02801

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.31139
Value Function Update Magnitude: 0.38514

Collected Steps per Second: 21,416.33695
Overall Steps per Second: 10,235.81778

Timestep Collection Time: 2.33532
Timestep Consumption Time: 2.55086
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.88618

Cumulative Model Updates: 224,226
Cumulative Timesteps: 1,870,650,678

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,168.61748
Policy Entropy: 1.93981
Value Function Loss: 0.02782

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.31202
Value Function Update Magnitude: 0.36673

Collected Steps per Second: 19,595.00394
Overall Steps per Second: 9,831.88990

Timestep Collection Time: 2.55239
Timestep Consumption Time: 2.53453
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 5.08692

Cumulative Model Updates: 224,232
Cumulative Timesteps: 1,870,700,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1870700692...
Checkpoint 1870700692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,886.42264
Policy Entropy: 1.93837
Value Function Loss: 0.02550

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07766
Policy Update Magnitude: 0.31443
Value Function Update Magnitude: 0.33148

Collected Steps per Second: 18,807.15328
Overall Steps per Second: 9,424.20596

Timestep Collection Time: 2.65931
Timestep Consumption Time: 2.64766
PPO Batch Consumption Time: 0.31307
Total Iteration Time: 5.30697

Cumulative Model Updates: 224,238
Cumulative Timesteps: 1,870,750,706

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,194.32481
Policy Entropy: 1.94635
Value Function Loss: 0.03182

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08223
Policy Update Magnitude: 0.32677
Value Function Update Magnitude: 0.29858

Collected Steps per Second: 20,476.00635
Overall Steps per Second: 9,975.48277

Timestep Collection Time: 2.44237
Timestep Consumption Time: 2.57092
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 5.01329

Cumulative Model Updates: 224,244
Cumulative Timesteps: 1,870,800,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1870800716...
Checkpoint 1870800716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,684.84995
Policy Entropy: 1.95720
Value Function Loss: 0.03389

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.33011
Value Function Update Magnitude: 0.34165

Collected Steps per Second: 20,198.83595
Overall Steps per Second: 9,876.69896

Timestep Collection Time: 2.47747
Timestep Consumption Time: 2.58920
PPO Batch Consumption Time: 0.30474
Total Iteration Time: 5.06667

Cumulative Model Updates: 224,250
Cumulative Timesteps: 1,870,850,758

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,106.05082
Policy Entropy: 1.96647
Value Function Loss: 0.03102

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08134
Policy Update Magnitude: 0.32527
Value Function Update Magnitude: 0.39020

Collected Steps per Second: 19,478.66534
Overall Steps per Second: 9,558.84527

Timestep Collection Time: 2.56814
Timestep Consumption Time: 2.66513
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 5.23327

Cumulative Model Updates: 224,256
Cumulative Timesteps: 1,870,900,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1870900782...
Checkpoint 1870900782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,124.56940
Policy Entropy: 1.95295
Value Function Loss: 0.02735

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.31086
Value Function Update Magnitude: 0.36931

Collected Steps per Second: 19,712.07831
Overall Steps per Second: 9,930.71317

Timestep Collection Time: 2.53702
Timestep Consumption Time: 2.49887
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 5.03589

Cumulative Model Updates: 224,262
Cumulative Timesteps: 1,870,950,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,622.24811
Policy Entropy: 1.93945
Value Function Loss: 0.02394

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07910
Policy Update Magnitude: 0.30296
Value Function Update Magnitude: 0.34769

Collected Steps per Second: 20,562.06258
Overall Steps per Second: 10,069.20810

Timestep Collection Time: 2.43361
Timestep Consumption Time: 2.53600
PPO Batch Consumption Time: 0.30687
Total Iteration Time: 4.96961

Cumulative Model Updates: 224,268
Cumulative Timesteps: 1,871,000,832

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1871000832...
Checkpoint 1871000832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,980.97193
Policy Entropy: 1.94206
Value Function Loss: 0.02642

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.30849
Value Function Update Magnitude: 0.36088

Collected Steps per Second: 19,880.36174
Overall Steps per Second: 10,103.94169

Timestep Collection Time: 2.51625
Timestep Consumption Time: 2.43469
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.95094

Cumulative Model Updates: 224,274
Cumulative Timesteps: 1,871,050,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,557.94046
Policy Entropy: 1.94407
Value Function Loss: 0.02944

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.08531
Policy Update Magnitude: 0.33520
Value Function Update Magnitude: 0.38345

Collected Steps per Second: 21,323.30349
Overall Steps per Second: 10,472.41261

Timestep Collection Time: 2.34532
Timestep Consumption Time: 2.43008
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.77540

Cumulative Model Updates: 224,280
Cumulative Timesteps: 1,871,100,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1871100866...
Checkpoint 1871100866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,653.03544
Policy Entropy: 1.95835
Value Function Loss: 0.02944

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.32934
Value Function Update Magnitude: 0.41453

Collected Steps per Second: 21,025.42869
Overall Steps per Second: 10,407.01636

Timestep Collection Time: 2.38017
Timestep Consumption Time: 2.42851
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.80868

Cumulative Model Updates: 224,286
Cumulative Timesteps: 1,871,150,910

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,658.18522
Policy Entropy: 1.96908
Value Function Loss: 0.02713

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.31520
Value Function Update Magnitude: 0.40750

Collected Steps per Second: 21,477.09302
Overall Steps per Second: 10,320.62642

Timestep Collection Time: 2.32927
Timestep Consumption Time: 2.51791
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.84719

Cumulative Model Updates: 224,292
Cumulative Timesteps: 1,871,200,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1871200936...
Checkpoint 1871200936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,504.03790
Policy Entropy: 1.97965
Value Function Loss: 0.02270

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07548
Policy Update Magnitude: 0.30259
Value Function Update Magnitude: 0.37619

Collected Steps per Second: 20,566.30559
Overall Steps per Second: 10,161.34038

Timestep Collection Time: 2.43243
Timestep Consumption Time: 2.49074
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.92317

Cumulative Model Updates: 224,298
Cumulative Timesteps: 1,871,250,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,863.06845
Policy Entropy: 1.95488
Value Function Loss: 0.02291

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07528
Policy Update Magnitude: 0.29638
Value Function Update Magnitude: 0.34121

Collected Steps per Second: 20,912.44051
Overall Steps per Second: 10,167.59017

Timestep Collection Time: 2.39111
Timestep Consumption Time: 2.52687
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.91798

Cumulative Model Updates: 224,304
Cumulative Timesteps: 1,871,300,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1871300966...
Checkpoint 1871300966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,434.65047
Policy Entropy: 1.94094
Value Function Loss: 0.02714

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07841
Policy Update Magnitude: 0.31093
Value Function Update Magnitude: 0.29918

Collected Steps per Second: 18,571.54004
Overall Steps per Second: 9,371.10599

Timestep Collection Time: 2.69272
Timestep Consumption Time: 2.64368
PPO Batch Consumption Time: 0.30831
Total Iteration Time: 5.33640

Cumulative Model Updates: 224,310
Cumulative Timesteps: 1,871,350,974

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,701.20116
Policy Entropy: 1.92855
Value Function Loss: 0.02615

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.08416
Policy Update Magnitude: 0.31463
Value Function Update Magnitude: 0.34391

Collected Steps per Second: 21,090.78147
Overall Steps per Second: 10,170.09980

Timestep Collection Time: 2.37070
Timestep Consumption Time: 2.54567
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.91637

Cumulative Model Updates: 224,316
Cumulative Timesteps: 1,871,400,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1871400974...
Checkpoint 1871400974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,924.81777
Policy Entropy: 1.93079
Value Function Loss: 0.02670

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.30722
Value Function Update Magnitude: 0.35394

Collected Steps per Second: 20,511.39649
Overall Steps per Second: 10,139.02126

Timestep Collection Time: 2.43874
Timestep Consumption Time: 2.49487
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.93361

Cumulative Model Updates: 224,322
Cumulative Timesteps: 1,871,450,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,293.54054
Policy Entropy: 1.93416
Value Function Loss: 0.02536

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.30873
Value Function Update Magnitude: 0.35370

Collected Steps per Second: 20,917.08819
Overall Steps per Second: 10,011.63600

Timestep Collection Time: 2.39116
Timestep Consumption Time: 2.60463
PPO Batch Consumption Time: 0.30121
Total Iteration Time: 4.99579

Cumulative Model Updates: 224,328
Cumulative Timesteps: 1,871,501,012

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1871501012...
Checkpoint 1871501012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,527.90358
Policy Entropy: 1.94371
Value Function Loss: 0.02632

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.31042
Value Function Update Magnitude: 0.36354

Collected Steps per Second: 19,186.32685
Overall Steps per Second: 9,732.23135

Timestep Collection Time: 2.60748
Timestep Consumption Time: 2.53296
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 5.14044

Cumulative Model Updates: 224,334
Cumulative Timesteps: 1,871,551,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,709.02439
Policy Entropy: 1.93848
Value Function Loss: 0.02335

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.29768
Value Function Update Magnitude: 0.36447

Collected Steps per Second: 19,856.23347
Overall Steps per Second: 9,823.88640

Timestep Collection Time: 2.51881
Timestep Consumption Time: 2.57225
PPO Batch Consumption Time: 0.29798
Total Iteration Time: 5.09106

Cumulative Model Updates: 224,340
Cumulative Timesteps: 1,871,601,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1871601054...
Checkpoint 1871601054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,031.10657
Policy Entropy: 1.93283
Value Function Loss: 0.02497

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08092
Policy Update Magnitude: 0.29486
Value Function Update Magnitude: 0.36520

Collected Steps per Second: 20,085.51607
Overall Steps per Second: 9,875.23764

Timestep Collection Time: 2.48975
Timestep Consumption Time: 2.57423
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 5.06398

Cumulative Model Updates: 224,346
Cumulative Timesteps: 1,871,651,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,890.09807
Policy Entropy: 1.94000
Value Function Loss: 0.02460

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07556
Policy Update Magnitude: 0.30003
Value Function Update Magnitude: 0.35094

Collected Steps per Second: 21,063.42056
Overall Steps per Second: 10,245.26293

Timestep Collection Time: 2.37435
Timestep Consumption Time: 2.50712
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.88148

Cumulative Model Updates: 224,352
Cumulative Timesteps: 1,871,701,074

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1871701074...
Checkpoint 1871701074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,354.77481
Policy Entropy: 1.94416
Value Function Loss: 0.02556

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07839
Policy Update Magnitude: 0.30252
Value Function Update Magnitude: 0.33883

Collected Steps per Second: 19,614.00944
Overall Steps per Second: 9,787.48090

Timestep Collection Time: 2.54991
Timestep Consumption Time: 2.56009
PPO Batch Consumption Time: 0.29752
Total Iteration Time: 5.11000

Cumulative Model Updates: 224,358
Cumulative Timesteps: 1,871,751,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,613.63063
Policy Entropy: 1.95043
Value Function Loss: 0.02459

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07666
Policy Update Magnitude: 0.30636
Value Function Update Magnitude: 0.33061

Collected Steps per Second: 19,692.49974
Overall Steps per Second: 9,755.24351

Timestep Collection Time: 2.53914
Timestep Consumption Time: 2.58651
PPO Batch Consumption Time: 0.30215
Total Iteration Time: 5.12565

Cumulative Model Updates: 224,364
Cumulative Timesteps: 1,871,801,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1871801090...
Checkpoint 1871801090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,043.08966
Policy Entropy: 1.96854
Value Function Loss: 0.02636

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07532
Policy Update Magnitude: 0.30308
Value Function Update Magnitude: 0.31935

Collected Steps per Second: 19,265.83318
Overall Steps per Second: 9,637.97331

Timestep Collection Time: 2.59641
Timestep Consumption Time: 2.59369
PPO Batch Consumption Time: 0.30033
Total Iteration Time: 5.19010

Cumulative Model Updates: 224,370
Cumulative Timesteps: 1,871,851,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,447.66465
Policy Entropy: 1.96134
Value Function Loss: 0.02725

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08185
Policy Update Magnitude: 0.30060
Value Function Update Magnitude: 0.31397

Collected Steps per Second: 20,910.32596
Overall Steps per Second: 10,286.77925

Timestep Collection Time: 2.39135
Timestep Consumption Time: 2.46964
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.86100

Cumulative Model Updates: 224,376
Cumulative Timesteps: 1,871,901,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1871901116...
Checkpoint 1871901116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,579.25904
Policy Entropy: 1.96003
Value Function Loss: 0.02824

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08249
Policy Update Magnitude: 0.30681
Value Function Update Magnitude: 0.29753

Collected Steps per Second: 21,280.69234
Overall Steps per Second: 9,904.39708

Timestep Collection Time: 2.34964
Timestep Consumption Time: 2.69882
PPO Batch Consumption Time: 0.32406
Total Iteration Time: 5.04846

Cumulative Model Updates: 224,382
Cumulative Timesteps: 1,871,951,118

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,522.20257
Policy Entropy: 1.94535
Value Function Loss: 0.02722

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.31074
Value Function Update Magnitude: 0.32670

Collected Steps per Second: 21,715.63412
Overall Steps per Second: 10,434.13667

Timestep Collection Time: 2.30249
Timestep Consumption Time: 2.48947
PPO Batch Consumption Time: 0.30168
Total Iteration Time: 4.79196

Cumulative Model Updates: 224,388
Cumulative Timesteps: 1,872,001,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1872001118...
Checkpoint 1872001118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,738.26346
Policy Entropy: 1.95328
Value Function Loss: 0.02749

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08120
Policy Update Magnitude: 0.31564
Value Function Update Magnitude: 0.35517

Collected Steps per Second: 18,967.86075
Overall Steps per Second: 9,914.11428

Timestep Collection Time: 2.63678
Timestep Consumption Time: 2.40795
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 5.04473

Cumulative Model Updates: 224,394
Cumulative Timesteps: 1,872,051,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,227.34616
Policy Entropy: 1.93972
Value Function Loss: 0.02692

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07820
Policy Update Magnitude: 0.31698
Value Function Update Magnitude: 0.36286

Collected Steps per Second: 20,757.10686
Overall Steps per Second: 10,156.86250

Timestep Collection Time: 2.40930
Timestep Consumption Time: 2.51447
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.92376

Cumulative Model Updates: 224,400
Cumulative Timesteps: 1,872,101,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1872101142...
Checkpoint 1872101142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,084.50466
Policy Entropy: 1.93930
Value Function Loss: 0.02702

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.07452
Policy Update Magnitude: 0.31150
Value Function Update Magnitude: 0.34019

Collected Steps per Second: 17,702.41173
Overall Steps per Second: 8,896.53158

Timestep Collection Time: 2.82504
Timestep Consumption Time: 2.79625
PPO Batch Consumption Time: 0.32774
Total Iteration Time: 5.62129

Cumulative Model Updates: 224,406
Cumulative Timesteps: 1,872,151,152

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,648.88485
Policy Entropy: 1.94046
Value Function Loss: 0.02662

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.06903
Policy Update Magnitude: 0.31039
Value Function Update Magnitude: 0.30383

Collected Steps per Second: 17,578.71518
Overall Steps per Second: 8,399.02389

Timestep Collection Time: 2.84674
Timestep Consumption Time: 3.11134
PPO Batch Consumption Time: 0.37678
Total Iteration Time: 5.95807

Cumulative Model Updates: 224,412
Cumulative Timesteps: 1,872,201,194

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1872201194...
Checkpoint 1872201194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,804.41125
Policy Entropy: 1.94643
Value Function Loss: 0.02799

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07322
Policy Update Magnitude: 0.31593
Value Function Update Magnitude: 0.33403

Collected Steps per Second: 17,235.34662
Overall Steps per Second: 8,911.59181

Timestep Collection Time: 2.90229
Timestep Consumption Time: 2.71085
PPO Batch Consumption Time: 0.31169
Total Iteration Time: 5.61314

Cumulative Model Updates: 224,418
Cumulative Timesteps: 1,872,251,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,370.22754
Policy Entropy: 1.95981
Value Function Loss: 0.02801

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.32018
Value Function Update Magnitude: 0.34729

Collected Steps per Second: 17,380.64651
Overall Steps per Second: 9,102.97616

Timestep Collection Time: 2.87814
Timestep Consumption Time: 2.61720
PPO Batch Consumption Time: 0.30906
Total Iteration Time: 5.49535

Cumulative Model Updates: 224,424
Cumulative Timesteps: 1,872,301,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1872301240...
Checkpoint 1872301240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,917.55301
Policy Entropy: 1.96233
Value Function Loss: 0.02937

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.31803
Value Function Update Magnitude: 0.30763

Collected Steps per Second: 16,742.20337
Overall Steps per Second: 8,911.64095

Timestep Collection Time: 2.98802
Timestep Consumption Time: 2.62554
PPO Batch Consumption Time: 0.31634
Total Iteration Time: 5.61356

Cumulative Model Updates: 224,430
Cumulative Timesteps: 1,872,351,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,490.58342
Policy Entropy: 1.94873
Value Function Loss: 0.02903

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.32280
Value Function Update Magnitude: 0.30451

Collected Steps per Second: 17,441.43901
Overall Steps per Second: 9,063.70112

Timestep Collection Time: 2.86800
Timestep Consumption Time: 2.65094
PPO Batch Consumption Time: 0.31333
Total Iteration Time: 5.51894

Cumulative Model Updates: 224,436
Cumulative Timesteps: 1,872,401,288

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1872401288...
Checkpoint 1872401288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,444.80269
Policy Entropy: 1.95485
Value Function Loss: 0.02910

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.32764
Value Function Update Magnitude: 0.34109

Collected Steps per Second: 16,861.83629
Overall Steps per Second: 8,916.63762

Timestep Collection Time: 2.96753
Timestep Consumption Time: 2.64423
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 5.61176

Cumulative Model Updates: 224,442
Cumulative Timesteps: 1,872,451,326

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,105.04885
Policy Entropy: 1.95477
Value Function Loss: 0.02901

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.07775
Policy Update Magnitude: 0.32337
Value Function Update Magnitude: 0.35197

Collected Steps per Second: 20,860.96425
Overall Steps per Second: 10,293.25363

Timestep Collection Time: 2.39836
Timestep Consumption Time: 2.46230
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.86066

Cumulative Model Updates: 224,448
Cumulative Timesteps: 1,872,501,358

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1872501358...
Checkpoint 1872501358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,033.47414
Policy Entropy: 1.96024
Value Function Loss: 0.02745

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.09138
Policy Update Magnitude: 0.31543
Value Function Update Magnitude: 0.36023

Collected Steps per Second: 19,461.48716
Overall Steps per Second: 9,724.03079

Timestep Collection Time: 2.56928
Timestep Consumption Time: 2.57283
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 5.14211

Cumulative Model Updates: 224,454
Cumulative Timesteps: 1,872,551,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,579.40710
Policy Entropy: 1.92903
Value Function Loss: 0.02486

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.30826
Value Function Update Magnitude: 0.36036

Collected Steps per Second: 21,711.03869
Overall Steps per Second: 10,351.67276

Timestep Collection Time: 2.30417
Timestep Consumption Time: 2.52848
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.83265

Cumulative Model Updates: 224,460
Cumulative Timesteps: 1,872,601,386

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1872601386...
Checkpoint 1872601386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,685.92609
Policy Entropy: 1.91713
Value Function Loss: 0.02550

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.09296
Policy Update Magnitude: 0.31564
Value Function Update Magnitude: 0.35598

Collected Steps per Second: 20,212.40039
Overall Steps per Second: 10,023.54436

Timestep Collection Time: 2.47383
Timestep Consumption Time: 2.51463
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.98845

Cumulative Model Updates: 224,466
Cumulative Timesteps: 1,872,651,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,046.74643
Policy Entropy: 1.92880
Value Function Loss: 0.02498

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.31533
Value Function Update Magnitude: 0.35063

Collected Steps per Second: 21,214.41300
Overall Steps per Second: 10,402.78146

Timestep Collection Time: 2.35849
Timestep Consumption Time: 2.45118
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.80968

Cumulative Model Updates: 224,472
Cumulative Timesteps: 1,872,701,422

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1872701422...
Checkpoint 1872701422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,911.58410
Policy Entropy: 1.93631
Value Function Loss: 0.02469

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.30323
Value Function Update Magnitude: 0.34451

Collected Steps per Second: 21,283.06774
Overall Steps per Second: 10,332.67628

Timestep Collection Time: 2.35088
Timestep Consumption Time: 2.49143
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.84231

Cumulative Model Updates: 224,478
Cumulative Timesteps: 1,872,751,456

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,526.95236
Policy Entropy: 1.94156
Value Function Loss: 0.02370

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.29397
Value Function Update Magnitude: 0.33429

Collected Steps per Second: 21,691.97961
Overall Steps per Second: 10,431.80143

Timestep Collection Time: 2.30620
Timestep Consumption Time: 2.48933
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.79553

Cumulative Model Updates: 224,484
Cumulative Timesteps: 1,872,801,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1872801482...
Checkpoint 1872801482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,407.44445
Policy Entropy: 1.92883
Value Function Loss: 0.02432

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08729
Policy Update Magnitude: 0.29948
Value Function Update Magnitude: 0.31056

Collected Steps per Second: 21,703.24139
Overall Steps per Second: 10,573.03950

Timestep Collection Time: 2.30426
Timestep Consumption Time: 2.42569
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.72995

Cumulative Model Updates: 224,490
Cumulative Timesteps: 1,872,851,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,621.71801
Policy Entropy: 1.93691
Value Function Loss: 0.02373

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07942
Policy Update Magnitude: 0.30236
Value Function Update Magnitude: 0.28991

Collected Steps per Second: 21,832.49580
Overall Steps per Second: 10,378.86597

Timestep Collection Time: 2.29035
Timestep Consumption Time: 2.52752
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.81787

Cumulative Model Updates: 224,496
Cumulative Timesteps: 1,872,901,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1872901496...
Checkpoint 1872901496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,705.25225
Policy Entropy: 1.94816
Value Function Loss: 0.02672

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07397
Policy Update Magnitude: 0.29907
Value Function Update Magnitude: 0.30479

Collected Steps per Second: 18,248.13658
Overall Steps per Second: 9,494.28256

Timestep Collection Time: 2.74154
Timestep Consumption Time: 2.52774
PPO Batch Consumption Time: 0.30266
Total Iteration Time: 5.26928

Cumulative Model Updates: 224,502
Cumulative Timesteps: 1,872,951,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,025.67975
Policy Entropy: 1.94457
Value Function Loss: 0.02564

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07059
Policy Update Magnitude: 0.30154
Value Function Update Magnitude: 0.34794

Collected Steps per Second: 19,610.44506
Overall Steps per Second: 9,957.71086

Timestep Collection Time: 2.55242
Timestep Consumption Time: 2.47424
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 5.02666

Cumulative Model Updates: 224,508
Cumulative Timesteps: 1,873,001,578

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1873001578...
Checkpoint 1873001578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,249.45722
Policy Entropy: 1.95510
Value Function Loss: 0.02790

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07556
Policy Update Magnitude: 0.30350
Value Function Update Magnitude: 0.35910

Collected Steps per Second: 18,725.79035
Overall Steps per Second: 9,919.86261

Timestep Collection Time: 2.67086
Timestep Consumption Time: 2.37094
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 5.04180

Cumulative Model Updates: 224,514
Cumulative Timesteps: 1,873,051,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,718.17212
Policy Entropy: 1.95556
Value Function Loss: 0.02584

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.30795
Value Function Update Magnitude: 0.34539

Collected Steps per Second: 21,063.16997
Overall Steps per Second: 10,447.90892

Timestep Collection Time: 2.37448
Timestep Consumption Time: 2.41251
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.78699

Cumulative Model Updates: 224,520
Cumulative Timesteps: 1,873,101,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1873101606...
Checkpoint 1873101606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,974.97929
Policy Entropy: 1.95156
Value Function Loss: 0.02573

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.30904
Value Function Update Magnitude: 0.33204

Collected Steps per Second: 21,006.16506
Overall Steps per Second: 10,119.49136

Timestep Collection Time: 2.38025
Timestep Consumption Time: 2.56071
PPO Batch Consumption Time: 0.30420
Total Iteration Time: 4.94096

Cumulative Model Updates: 224,526
Cumulative Timesteps: 1,873,151,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,513.72714
Policy Entropy: 1.94851
Value Function Loss: 0.02366

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.09311
Policy Update Magnitude: 0.31140
Value Function Update Magnitude: 0.34169

Collected Steps per Second: 20,331.19776
Overall Steps per Second: 10,127.44857

Timestep Collection Time: 2.45957
Timestep Consumption Time: 2.47810
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.93767

Cumulative Model Updates: 224,532
Cumulative Timesteps: 1,873,201,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1873201612...
Checkpoint 1873201612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,777.03390
Policy Entropy: 1.94351
Value Function Loss: 0.02449

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.31155
Value Function Update Magnitude: 0.36251

Collected Steps per Second: 20,550.53352
Overall Steps per Second: 10,185.13568

Timestep Collection Time: 2.43322
Timestep Consumption Time: 2.47629
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.90951

Cumulative Model Updates: 224,538
Cumulative Timesteps: 1,873,251,616

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,586.83258
Policy Entropy: 1.94293
Value Function Loss: 0.02411

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.30803
Value Function Update Magnitude: 0.37177

Collected Steps per Second: 21,357.65188
Overall Steps per Second: 10,448.54225

Timestep Collection Time: 2.34146
Timestep Consumption Time: 2.44467
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.78612

Cumulative Model Updates: 224,544
Cumulative Timesteps: 1,873,301,624

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1873301624...
Checkpoint 1873301624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,750.87345
Policy Entropy: 1.94268
Value Function Loss: 0.02524

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08290
Policy Update Magnitude: 0.30877
Value Function Update Magnitude: 0.36306

Collected Steps per Second: 21,306.76646
Overall Steps per Second: 10,225.31816

Timestep Collection Time: 2.34799
Timestep Consumption Time: 2.54458
PPO Batch Consumption Time: 0.30321
Total Iteration Time: 4.89256

Cumulative Model Updates: 224,550
Cumulative Timesteps: 1,873,351,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,992.71693
Policy Entropy: 1.93999
Value Function Loss: 0.02731

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07532
Policy Update Magnitude: 0.31536
Value Function Update Magnitude: 0.35070

Collected Steps per Second: 21,924.39796
Overall Steps per Second: 10,589.66739

Timestep Collection Time: 2.28084
Timestep Consumption Time: 2.44131
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.72215

Cumulative Model Updates: 224,556
Cumulative Timesteps: 1,873,401,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1873401658...
Checkpoint 1873401658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,312.34231
Policy Entropy: 1.96371
Value Function Loss: 0.02901

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.07885
Policy Update Magnitude: 0.31558
Value Function Update Magnitude: 0.37035

Collected Steps per Second: 21,419.99470
Overall Steps per Second: 10,348.83873

Timestep Collection Time: 2.33464
Timestep Consumption Time: 2.49759
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.83223

Cumulative Model Updates: 224,562
Cumulative Timesteps: 1,873,451,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,029.22081
Policy Entropy: 1.94886
Value Function Loss: 0.02784

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07055
Policy Update Magnitude: 0.31105
Value Function Update Magnitude: 0.38950

Collected Steps per Second: 22,090.75097
Overall Steps per Second: 10,632.46906

Timestep Collection Time: 2.26393
Timestep Consumption Time: 2.43977
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.70371

Cumulative Model Updates: 224,568
Cumulative Timesteps: 1,873,501,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1873501678...
Checkpoint 1873501678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,249.05369
Policy Entropy: 1.94499
Value Function Loss: 0.02666

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07356
Policy Update Magnitude: 0.30570
Value Function Update Magnitude: 0.37296

Collected Steps per Second: 21,221.40134
Overall Steps per Second: 10,146.36368

Timestep Collection Time: 2.35658
Timestep Consumption Time: 2.57228
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.92886

Cumulative Model Updates: 224,574
Cumulative Timesteps: 1,873,551,688

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,828.85729
Policy Entropy: 1.94014
Value Function Loss: 0.02403

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07636
Policy Update Magnitude: 0.30554
Value Function Update Magnitude: 0.34612

Collected Steps per Second: 20,038.06776
Overall Steps per Second: 9,790.51095

Timestep Collection Time: 2.49555
Timestep Consumption Time: 2.61205
PPO Batch Consumption Time: 0.31031
Total Iteration Time: 5.10760

Cumulative Model Updates: 224,580
Cumulative Timesteps: 1,873,601,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1873601694...
Checkpoint 1873601694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,761.18668
Policy Entropy: 1.94315
Value Function Loss: 0.02510

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.30947
Value Function Update Magnitude: 0.34823

Collected Steps per Second: 20,387.91904
Overall Steps per Second: 10,142.72668

Timestep Collection Time: 2.45361
Timestep Consumption Time: 2.47840
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.93201

Cumulative Model Updates: 224,586
Cumulative Timesteps: 1,873,651,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,995.67789
Policy Entropy: 1.95431
Value Function Loss: 0.02620

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.31125
Value Function Update Magnitude: 0.37025

Collected Steps per Second: 21,088.18118
Overall Steps per Second: 10,036.64124

Timestep Collection Time: 2.37213
Timestep Consumption Time: 2.61200
PPO Batch Consumption Time: 0.30759
Total Iteration Time: 4.98414

Cumulative Model Updates: 224,592
Cumulative Timesteps: 1,873,701,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1873701742...
Checkpoint 1873701742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,680.76581
Policy Entropy: 1.95759
Value Function Loss: 0.02658

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07637
Policy Update Magnitude: 0.31692
Value Function Update Magnitude: 0.40065

Collected Steps per Second: 20,584.22947
Overall Steps per Second: 10,214.52337

Timestep Collection Time: 2.42992
Timestep Consumption Time: 2.46683
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.89675

Cumulative Model Updates: 224,598
Cumulative Timesteps: 1,873,751,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,956.90922
Policy Entropy: 1.94847
Value Function Loss: 0.02652

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.08517
Policy Update Magnitude: 0.31655
Value Function Update Magnitude: 0.38670

Collected Steps per Second: 21,569.64331
Overall Steps per Second: 10,424.23450

Timestep Collection Time: 2.31872
Timestep Consumption Time: 2.47914
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.79786

Cumulative Model Updates: 224,604
Cumulative Timesteps: 1,873,801,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1873801774...
Checkpoint 1873801774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,062.49917
Policy Entropy: 1.95874
Value Function Loss: 0.02493

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08371
Policy Update Magnitude: 0.31171
Value Function Update Magnitude: 0.37672

Collected Steps per Second: 20,312.31277
Overall Steps per Second: 9,852.60678

Timestep Collection Time: 2.46274
Timestep Consumption Time: 2.61449
PPO Batch Consumption Time: 0.30535
Total Iteration Time: 5.07723

Cumulative Model Updates: 224,610
Cumulative Timesteps: 1,873,851,798

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,031.02778
Policy Entropy: 1.95107
Value Function Loss: 0.02701

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08511
Policy Update Magnitude: 0.31134
Value Function Update Magnitude: 0.34920

Collected Steps per Second: 20,864.03352
Overall Steps per Second: 10,203.42014

Timestep Collection Time: 2.39819
Timestep Consumption Time: 2.50565
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.90385

Cumulative Model Updates: 224,616
Cumulative Timesteps: 1,873,901,834

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1873901834...
Checkpoint 1873901834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,805.64775
Policy Entropy: 1.95800
Value Function Loss: 0.02613

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.07960
Policy Update Magnitude: 0.30553
Value Function Update Magnitude: 0.30623

Collected Steps per Second: 19,769.89227
Overall Steps per Second: 10,059.47589

Timestep Collection Time: 2.52981
Timestep Consumption Time: 2.44202
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.97183

Cumulative Model Updates: 224,622
Cumulative Timesteps: 1,873,951,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,316.92098
Policy Entropy: 1.95098
Value Function Loss: 0.02673

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.30241
Value Function Update Magnitude: 0.29215

Collected Steps per Second: 19,733.65523
Overall Steps per Second: 10,098.81835

Timestep Collection Time: 2.53445
Timestep Consumption Time: 2.41801
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.95246

Cumulative Model Updates: 224,628
Cumulative Timesteps: 1,874,001,862

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1874001862...
Checkpoint 1874001862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,278.18609
Policy Entropy: 1.95627
Value Function Loss: 0.02258

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07035
Policy Update Magnitude: 0.29823
Value Function Update Magnitude: 0.30456

Collected Steps per Second: 20,200.25397
Overall Steps per Second: 10,170.93234

Timestep Collection Time: 2.47631
Timestep Consumption Time: 2.44183
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.91813

Cumulative Model Updates: 224,634
Cumulative Timesteps: 1,874,051,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,653.26446
Policy Entropy: 1.96174
Value Function Loss: 0.02073

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07106
Policy Update Magnitude: 0.29217
Value Function Update Magnitude: 0.29598

Collected Steps per Second: 19,998.35992
Overall Steps per Second: 10,399.21678

Timestep Collection Time: 2.50111
Timestep Consumption Time: 2.30868
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.80979

Cumulative Model Updates: 224,640
Cumulative Timesteps: 1,874,101,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1874101902...
Checkpoint 1874101902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,308.21099
Policy Entropy: 1.94963
Value Function Loss: 0.02039

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.06874
Policy Update Magnitude: 0.28797
Value Function Update Magnitude: 0.26638

Collected Steps per Second: 20,584.76329
Overall Steps per Second: 10,066.10347

Timestep Collection Time: 2.43054
Timestep Consumption Time: 2.53981
PPO Batch Consumption Time: 0.29991
Total Iteration Time: 4.97034

Cumulative Model Updates: 224,646
Cumulative Timesteps: 1,874,151,934

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,929.73489
Policy Entropy: 1.94491
Value Function Loss: 0.02102

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.06930
Policy Update Magnitude: 0.28970
Value Function Update Magnitude: 0.25043

Collected Steps per Second: 19,317.12190
Overall Steps per Second: 9,701.48710

Timestep Collection Time: 2.58983
Timestep Consumption Time: 2.56691
PPO Batch Consumption Time: 0.30527
Total Iteration Time: 5.15674

Cumulative Model Updates: 224,652
Cumulative Timesteps: 1,874,201,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1874201962...
Checkpoint 1874201962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,621.01189
Policy Entropy: 1.94329
Value Function Loss: 0.02458

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07232
Policy Update Magnitude: 0.30168
Value Function Update Magnitude: 0.27920

Collected Steps per Second: 20,417.20800
Overall Steps per Second: 9,922.46462

Timestep Collection Time: 2.44950
Timestep Consumption Time: 2.59078
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 5.04028

Cumulative Model Updates: 224,658
Cumulative Timesteps: 1,874,251,974

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,756.22591
Policy Entropy: 1.95081
Value Function Loss: 0.02239

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.29837
Value Function Update Magnitude: 0.31423

Collected Steps per Second: 20,927.30671
Overall Steps per Second: 10,157.72499

Timestep Collection Time: 2.39008
Timestep Consumption Time: 2.53405
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.92413

Cumulative Model Updates: 224,664
Cumulative Timesteps: 1,874,301,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1874301992...
Checkpoint 1874301992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,330.57869
Policy Entropy: 1.95577
Value Function Loss: 0.02326

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07782
Policy Update Magnitude: 0.30331
Value Function Update Magnitude: 0.30165

Collected Steps per Second: 20,653.71698
Overall Steps per Second: 9,794.47905

Timestep Collection Time: 2.42184
Timestep Consumption Time: 2.68512
PPO Batch Consumption Time: 0.31532
Total Iteration Time: 5.10696

Cumulative Model Updates: 224,670
Cumulative Timesteps: 1,874,352,012

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,012.87525
Policy Entropy: 1.94755
Value Function Loss: 0.02302

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.30463
Value Function Update Magnitude: 0.28534

Collected Steps per Second: 20,500.54822
Overall Steps per Second: 9,837.02841

Timestep Collection Time: 2.44052
Timestep Consumption Time: 2.64557
PPO Batch Consumption Time: 0.30267
Total Iteration Time: 5.08609

Cumulative Model Updates: 224,676
Cumulative Timesteps: 1,874,402,044

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1874402044...
Checkpoint 1874402044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,121.51860
Policy Entropy: 1.93683
Value Function Loss: 0.02421

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07233
Policy Update Magnitude: 0.30099
Value Function Update Magnitude: 0.30314

Collected Steps per Second: 19,061.05624
Overall Steps per Second: 9,307.81431

Timestep Collection Time: 2.62399
Timestep Consumption Time: 2.74956
PPO Batch Consumption Time: 0.32789
Total Iteration Time: 5.37355

Cumulative Model Updates: 224,682
Cumulative Timesteps: 1,874,452,060

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,595.17238
Policy Entropy: 1.93482
Value Function Loss: 0.02462

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.06890
Policy Update Magnitude: 0.30397
Value Function Update Magnitude: 0.30557

Collected Steps per Second: 19,113.65107
Overall Steps per Second: 9,539.73015

Timestep Collection Time: 2.61593
Timestep Consumption Time: 2.62531
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 5.24124

Cumulative Model Updates: 224,688
Cumulative Timesteps: 1,874,502,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1874502060...
Checkpoint 1874502060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,981.43896
Policy Entropy: 1.92748
Value Function Loss: 0.02467

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07170
Policy Update Magnitude: 0.30943
Value Function Update Magnitude: 0.31690

Collected Steps per Second: 19,696.85677
Overall Steps per Second: 9,874.68491

Timestep Collection Time: 2.53980
Timestep Consumption Time: 2.52629
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 5.06609

Cumulative Model Updates: 224,694
Cumulative Timesteps: 1,874,552,086

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,153.54933
Policy Entropy: 1.94536
Value Function Loss: 0.02506

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.06938
Policy Update Magnitude: 0.31571
Value Function Update Magnitude: 0.33161

Collected Steps per Second: 20,837.88778
Overall Steps per Second: 10,003.35586

Timestep Collection Time: 2.39967
Timestep Consumption Time: 2.59906
PPO Batch Consumption Time: 0.30130
Total Iteration Time: 4.99872

Cumulative Model Updates: 224,700
Cumulative Timesteps: 1,874,602,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1874602090...
Checkpoint 1874602090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,257.39815
Policy Entropy: 1.95234
Value Function Loss: 0.02678

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07688
Policy Update Magnitude: 0.31947
Value Function Update Magnitude: 0.32148

Collected Steps per Second: 19,833.23219
Overall Steps per Second: 9,934.38482

Timestep Collection Time: 2.52112
Timestep Consumption Time: 2.51210
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 5.03323

Cumulative Model Updates: 224,706
Cumulative Timesteps: 1,874,652,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,173.55435
Policy Entropy: 1.96004
Value Function Loss: 0.02557

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07902
Policy Update Magnitude: 0.31775
Value Function Update Magnitude: 0.31289

Collected Steps per Second: 19,805.51447
Overall Steps per Second: 9,681.17216

Timestep Collection Time: 2.52576
Timestep Consumption Time: 2.64138
PPO Batch Consumption Time: 0.30622
Total Iteration Time: 5.16714

Cumulative Model Updates: 224,712
Cumulative Timesteps: 1,874,702,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1874702116...
Checkpoint 1874702116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,044.83482
Policy Entropy: 1.94011
Value Function Loss: 0.02863

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07728
Policy Update Magnitude: 0.31460
Value Function Update Magnitude: 0.32522

Collected Steps per Second: 19,401.00455
Overall Steps per Second: 9,723.73085

Timestep Collection Time: 2.57914
Timestep Consumption Time: 2.56682
PPO Batch Consumption Time: 0.31306
Total Iteration Time: 5.14597

Cumulative Model Updates: 224,718
Cumulative Timesteps: 1,874,752,154

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,053.71497
Policy Entropy: 1.92203
Value Function Loss: 0.02879

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07895
Policy Update Magnitude: 0.31774
Value Function Update Magnitude: 0.33317

Collected Steps per Second: 20,557.37353
Overall Steps per Second: 10,200.46076

Timestep Collection Time: 2.43241
Timestep Consumption Time: 2.46972
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.90213

Cumulative Model Updates: 224,724
Cumulative Timesteps: 1,874,802,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1874802158...
Checkpoint 1874802158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,312.63922
Policy Entropy: 1.90564
Value Function Loss: 0.03011

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08098
Policy Update Magnitude: 0.32213
Value Function Update Magnitude: 0.33985

Collected Steps per Second: 20,402.54735
Overall Steps per Second: 10,251.33644

Timestep Collection Time: 2.45185
Timestep Consumption Time: 2.42790
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.87975

Cumulative Model Updates: 224,730
Cumulative Timesteps: 1,874,852,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,662.95593
Policy Entropy: 1.91141
Value Function Loss: 0.02602

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07779
Policy Update Magnitude: 0.32041
Value Function Update Magnitude: 0.33850

Collected Steps per Second: 20,007.17062
Overall Steps per Second: 9,865.32963

Timestep Collection Time: 2.50020
Timestep Consumption Time: 2.57028
PPO Batch Consumption Time: 0.30204
Total Iteration Time: 5.07048

Cumulative Model Updates: 224,736
Cumulative Timesteps: 1,874,902,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1874902204...
Checkpoint 1874902204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,189.38509
Policy Entropy: 1.92306
Value Function Loss: 0.02343

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07551
Policy Update Magnitude: 0.30698
Value Function Update Magnitude: 0.32514

Collected Steps per Second: 19,120.83095
Overall Steps per Second: 9,829.23377

Timestep Collection Time: 2.61579
Timestep Consumption Time: 2.47271
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 5.08849

Cumulative Model Updates: 224,742
Cumulative Timesteps: 1,874,952,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,671.38272
Policy Entropy: 1.94050
Value Function Loss: 0.02389

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.30760
Value Function Update Magnitude: 0.30308

Collected Steps per Second: 20,645.71566
Overall Steps per Second: 9,986.35195

Timestep Collection Time: 2.42346
Timestep Consumption Time: 2.58678
PPO Batch Consumption Time: 0.30375
Total Iteration Time: 5.01024

Cumulative Model Updates: 224,748
Cumulative Timesteps: 1,875,002,254

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1875002254...
Checkpoint 1875002254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,178.64956
Policy Entropy: 1.96504
Value Function Loss: 0.02754

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07800
Policy Update Magnitude: 0.31028
Value Function Update Magnitude: 0.33042

Collected Steps per Second: 19,105.78057
Overall Steps per Second: 9,625.38803

Timestep Collection Time: 2.61816
Timestep Consumption Time: 2.57872
PPO Batch Consumption Time: 0.30629
Total Iteration Time: 5.19688

Cumulative Model Updates: 224,754
Cumulative Timesteps: 1,875,052,276

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,665.32451
Policy Entropy: 1.95488
Value Function Loss: 0.02873

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07580
Policy Update Magnitude: 0.31698
Value Function Update Magnitude: 0.37323

Collected Steps per Second: 20,318.85726
Overall Steps per Second: 9,598.38367

Timestep Collection Time: 2.46106
Timestep Consumption Time: 2.74877
PPO Batch Consumption Time: 0.33486
Total Iteration Time: 5.20984

Cumulative Model Updates: 224,760
Cumulative Timesteps: 1,875,102,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1875102282...
Checkpoint 1875102282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,041.92902
Policy Entropy: 1.95473
Value Function Loss: 0.02793

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.31978
Value Function Update Magnitude: 0.38309

Collected Steps per Second: 19,746.45299
Overall Steps per Second: 9,993.71507

Timestep Collection Time: 2.53352
Timestep Consumption Time: 2.47243
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 5.00595

Cumulative Model Updates: 224,766
Cumulative Timesteps: 1,875,152,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,113.95364
Policy Entropy: 1.95470
Value Function Loss: 0.02648

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07213
Policy Update Magnitude: 0.31484
Value Function Update Magnitude: 0.36660

Collected Steps per Second: 20,197.50266
Overall Steps per Second: 10,216.68857

Timestep Collection Time: 2.47654
Timestep Consumption Time: 2.41937
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.89591

Cumulative Model Updates: 224,772
Cumulative Timesteps: 1,875,202,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1875202330...
Checkpoint 1875202330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,553.83812
Policy Entropy: 1.95318
Value Function Loss: 0.02741

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.32144
Value Function Update Magnitude: 0.34630

Collected Steps per Second: 19,780.04038
Overall Steps per Second: 9,742.06644

Timestep Collection Time: 2.52861
Timestep Consumption Time: 2.60541
PPO Batch Consumption Time: 0.30033
Total Iteration Time: 5.13402

Cumulative Model Updates: 224,778
Cumulative Timesteps: 1,875,252,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,056.15134
Policy Entropy: 1.94450
Value Function Loss: 0.02674

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07615
Policy Update Magnitude: 0.31833
Value Function Update Magnitude: 0.35489

Collected Steps per Second: 20,220.77628
Overall Steps per Second: 10,078.11963

Timestep Collection Time: 2.47419
Timestep Consumption Time: 2.49003
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.96422

Cumulative Model Updates: 224,784
Cumulative Timesteps: 1,875,302,376

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1875302376...
Checkpoint 1875302376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,518.62547
Policy Entropy: 1.92629
Value Function Loss: 0.02566

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07593
Policy Update Magnitude: 0.31717
Value Function Update Magnitude: 0.34079

Collected Steps per Second: 20,116.73951
Overall Steps per Second: 9,994.74465

Timestep Collection Time: 2.48629
Timestep Consumption Time: 2.51794
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 5.00423

Cumulative Model Updates: 224,790
Cumulative Timesteps: 1,875,352,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,134.60448
Policy Entropy: 1.94955
Value Function Loss: 0.02481

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07459
Policy Update Magnitude: 0.31416
Value Function Update Magnitude: 0.31432

Collected Steps per Second: 19,734.02951
Overall Steps per Second: 9,987.83206

Timestep Collection Time: 2.53582
Timestep Consumption Time: 2.47447
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 5.01030

Cumulative Model Updates: 224,796
Cumulative Timesteps: 1,875,402,434

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1875402434...
Checkpoint 1875402434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,983.23562
Policy Entropy: 1.93799
Value Function Loss: 0.02438

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07230
Policy Update Magnitude: 0.30996
Value Function Update Magnitude: 0.31835

Collected Steps per Second: 20,498.11870
Overall Steps per Second: 10,172.54661

Timestep Collection Time: 2.44100
Timestep Consumption Time: 2.47772
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.91873

Cumulative Model Updates: 224,802
Cumulative Timesteps: 1,875,452,470

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,906.45519
Policy Entropy: 1.95775
Value Function Loss: 0.02903

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07313
Policy Update Magnitude: 0.31822
Value Function Update Magnitude: 0.30671

Collected Steps per Second: 20,551.34534
Overall Steps per Second: 10,109.73406

Timestep Collection Time: 2.43322
Timestep Consumption Time: 2.51310
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.94632

Cumulative Model Updates: 224,808
Cumulative Timesteps: 1,875,502,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1875502476...
Checkpoint 1875502476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,302.38772
Policy Entropy: 1.94854
Value Function Loss: 0.02790

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07902
Policy Update Magnitude: 0.32479
Value Function Update Magnitude: 0.29478

Collected Steps per Second: 18,826.78209
Overall Steps per Second: 10,055.72100

Timestep Collection Time: 2.65685
Timestep Consumption Time: 2.31743
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.97428

Cumulative Model Updates: 224,814
Cumulative Timesteps: 1,875,552,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,913.20852
Policy Entropy: 1.94845
Value Function Loss: 0.03199

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.32806
Value Function Update Magnitude: 0.29134

Collected Steps per Second: 20,443.76329
Overall Steps per Second: 9,731.63599

Timestep Collection Time: 2.44720
Timestep Consumption Time: 2.69376
PPO Batch Consumption Time: 0.33837
Total Iteration Time: 5.14096

Cumulative Model Updates: 224,820
Cumulative Timesteps: 1,875,602,526

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1875602526...
Checkpoint 1875602526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,164.48483
Policy Entropy: 1.94554
Value Function Loss: 0.02947

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07362
Policy Update Magnitude: 0.33136
Value Function Update Magnitude: 0.32763

Collected Steps per Second: 16,394.46339
Overall Steps per Second: 8,960.05268

Timestep Collection Time: 3.05140
Timestep Consumption Time: 2.53183
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 5.58323

Cumulative Model Updates: 224,826
Cumulative Timesteps: 1,875,652,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,210.75423
Policy Entropy: 1.93694
Value Function Loss: 0.02653

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07423
Policy Update Magnitude: 0.31799
Value Function Update Magnitude: 0.33051

Collected Steps per Second: 16,948.88954
Overall Steps per Second: 9,073.47333

Timestep Collection Time: 2.95158
Timestep Consumption Time: 2.56185
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 5.51343

Cumulative Model Updates: 224,832
Cumulative Timesteps: 1,875,702,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1875702578...
Checkpoint 1875702578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,342.59608
Policy Entropy: 1.93871
Value Function Loss: 0.02449

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.31269
Value Function Update Magnitude: 0.28355

Collected Steps per Second: 17,448.01251
Overall Steps per Second: 9,212.51190

Timestep Collection Time: 2.86566
Timestep Consumption Time: 2.56175
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 5.42740

Cumulative Model Updates: 224,838
Cumulative Timesteps: 1,875,752,578

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,358.22442
Policy Entropy: 1.93410
Value Function Loss: 0.02519

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07444
Policy Update Magnitude: 0.31924
Value Function Update Magnitude: 0.26405

Collected Steps per Second: 20,255.00976
Overall Steps per Second: 10,073.67057

Timestep Collection Time: 2.46853
Timestep Consumption Time: 2.49491
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.96343

Cumulative Model Updates: 224,844
Cumulative Timesteps: 1,875,802,578

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1875802578...
Checkpoint 1875802578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,616.78640
Policy Entropy: 1.95361
Value Function Loss: 0.02574

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07809
Policy Update Magnitude: 0.31349
Value Function Update Magnitude: 0.30800

Collected Steps per Second: 20,705.24082
Overall Steps per Second: 9,942.36377

Timestep Collection Time: 2.41717
Timestep Consumption Time: 2.61665
PPO Batch Consumption Time: 0.30605
Total Iteration Time: 5.03381

Cumulative Model Updates: 224,850
Cumulative Timesteps: 1,875,852,626

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,792.96804
Policy Entropy: 1.95367
Value Function Loss: 0.02422

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07457
Policy Update Magnitude: 0.30833
Value Function Update Magnitude: 0.33966

Collected Steps per Second: 20,758.09061
Overall Steps per Second: 10,178.22969

Timestep Collection Time: 2.41014
Timestep Consumption Time: 2.50525
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.91539

Cumulative Model Updates: 224,856
Cumulative Timesteps: 1,875,902,656

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1875902656...
Checkpoint 1875902656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,699.99369
Policy Entropy: 1.94021
Value Function Loss: 0.02307

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07596
Policy Update Magnitude: 0.30583
Value Function Update Magnitude: 0.32385

Collected Steps per Second: 20,259.91885
Overall Steps per Second: 9,736.71715

Timestep Collection Time: 2.46872
Timestep Consumption Time: 2.66813
PPO Batch Consumption Time: 0.31809
Total Iteration Time: 5.13684

Cumulative Model Updates: 224,862
Cumulative Timesteps: 1,875,952,672

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,943.71609
Policy Entropy: 1.92718
Value Function Loss: 0.02521

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08002
Policy Update Magnitude: 0.30952
Value Function Update Magnitude: 0.32224

Collected Steps per Second: 19,995.00764
Overall Steps per Second: 9,830.71770

Timestep Collection Time: 2.50302
Timestep Consumption Time: 2.58796
PPO Batch Consumption Time: 0.30111
Total Iteration Time: 5.09098

Cumulative Model Updates: 224,868
Cumulative Timesteps: 1,876,002,720

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1876002720...
Checkpoint 1876002720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,912.89394
Policy Entropy: 1.94692
Value Function Loss: 0.03014

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08536
Policy Update Magnitude: 0.31666
Value Function Update Magnitude: 0.37374

Collected Steps per Second: 19,874.05760
Overall Steps per Second: 9,913.83938

Timestep Collection Time: 2.51685
Timestep Consumption Time: 2.52862
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 5.04547

Cumulative Model Updates: 224,874
Cumulative Timesteps: 1,876,052,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,456.63074
Policy Entropy: 1.96997
Value Function Loss: 0.03128

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.32930
Value Function Update Magnitude: 0.38357

Collected Steps per Second: 21,403.92590
Overall Steps per Second: 10,252.54621

Timestep Collection Time: 2.33752
Timestep Consumption Time: 2.54244
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.87996

Cumulative Model Updates: 224,880
Cumulative Timesteps: 1,876,102,772

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1876102772...
Checkpoint 1876102772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,951.59252
Policy Entropy: 1.97197
Value Function Loss: 0.03197

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08172
Policy Update Magnitude: 0.33074
Value Function Update Magnitude: 0.32977

Collected Steps per Second: 19,167.09975
Overall Steps per Second: 9,328.22949

Timestep Collection Time: 2.60999
Timestep Consumption Time: 2.75287
PPO Batch Consumption Time: 0.32349
Total Iteration Time: 5.36286

Cumulative Model Updates: 224,886
Cumulative Timesteps: 1,876,152,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,068.04250
Policy Entropy: 1.95249
Value Function Loss: 0.03243

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08062
Policy Update Magnitude: 0.33104
Value Function Update Magnitude: 0.31264

Collected Steps per Second: 21,383.96637
Overall Steps per Second: 10,013.61158

Timestep Collection Time: 2.33867
Timestep Consumption Time: 2.65553
PPO Batch Consumption Time: 0.31867
Total Iteration Time: 4.99420

Cumulative Model Updates: 224,892
Cumulative Timesteps: 1,876,202,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1876202808...
Checkpoint 1876202808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,794.09583
Policy Entropy: 1.94408
Value Function Loss: 0.02884

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07995
Policy Update Magnitude: 0.32365
Value Function Update Magnitude: 0.29151

Collected Steps per Second: 19,646.29985
Overall Steps per Second: 9,773.27701

Timestep Collection Time: 2.54684
Timestep Consumption Time: 2.57283
PPO Batch Consumption Time: 0.30078
Total Iteration Time: 5.11967

Cumulative Model Updates: 224,898
Cumulative Timesteps: 1,876,252,844

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,821.59279
Policy Entropy: 1.96123
Value Function Loss: 0.03334

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07874
Policy Update Magnitude: 0.32636
Value Function Update Magnitude: 0.24992

Collected Steps per Second: 20,187.67244
Overall Steps per Second: 9,998.87357

Timestep Collection Time: 2.47686
Timestep Consumption Time: 2.52391
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 5.00076

Cumulative Model Updates: 224,904
Cumulative Timesteps: 1,876,302,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1876302846...
Checkpoint 1876302846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,770.16336
Policy Entropy: 1.95541
Value Function Loss: 0.03366

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.07775
Policy Update Magnitude: 0.32915
Value Function Update Magnitude: 0.22852

Collected Steps per Second: 20,166.15012
Overall Steps per Second: 10,073.09789

Timestep Collection Time: 2.48168
Timestep Consumption Time: 2.48660
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.96828

Cumulative Model Updates: 224,910
Cumulative Timesteps: 1,876,352,892

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,218.22767
Policy Entropy: 1.97894
Value Function Loss: 0.03424

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.32681
Value Function Update Magnitude: 0.29962

Collected Steps per Second: 20,609.30965
Overall Steps per Second: 10,018.29347

Timestep Collection Time: 2.42619
Timestep Consumption Time: 2.56488
PPO Batch Consumption Time: 0.30384
Total Iteration Time: 4.99107

Cumulative Model Updates: 224,916
Cumulative Timesteps: 1,876,402,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1876402894...
Checkpoint 1876402894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,556.23328
Policy Entropy: 1.96331
Value Function Loss: 0.02742

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07974
Policy Update Magnitude: 0.31439
Value Function Update Magnitude: 0.29578

Collected Steps per Second: 20,089.73619
Overall Steps per Second: 10,266.55602

Timestep Collection Time: 2.48943
Timestep Consumption Time: 2.38192
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.87135

Cumulative Model Updates: 224,922
Cumulative Timesteps: 1,876,452,906

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,779.28431
Policy Entropy: 1.96477
Value Function Loss: 0.02950

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07644
Policy Update Magnitude: 0.31478
Value Function Update Magnitude: 0.32483

Collected Steps per Second: 20,394.59342
Overall Steps per Second: 10,185.02455

Timestep Collection Time: 2.45232
Timestep Consumption Time: 2.45823
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.91054

Cumulative Model Updates: 224,928
Cumulative Timesteps: 1,876,502,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1876502920...
Checkpoint 1876502920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,001.80434
Policy Entropy: 1.97095
Value Function Loss: 0.02540

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.31602
Value Function Update Magnitude: 0.35332

Collected Steps per Second: 20,093.31461
Overall Steps per Second: 9,561.71759

Timestep Collection Time: 2.48939
Timestep Consumption Time: 2.74189
PPO Batch Consumption Time: 0.32775
Total Iteration Time: 5.23128

Cumulative Model Updates: 224,934
Cumulative Timesteps: 1,876,552,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,650.20115
Policy Entropy: 1.98899
Value Function Loss: 0.02979

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07886
Policy Update Magnitude: 0.31741
Value Function Update Magnitude: 0.37130

Collected Steps per Second: 17,561.85253
Overall Steps per Second: 9,111.42880

Timestep Collection Time: 2.84879
Timestep Consumption Time: 2.64212
PPO Batch Consumption Time: 0.31419
Total Iteration Time: 5.49091

Cumulative Model Updates: 224,940
Cumulative Timesteps: 1,876,602,970

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1876602970...
Checkpoint 1876602970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,566.40324
Policy Entropy: 1.98644
Value Function Loss: 0.02756

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07628
Policy Update Magnitude: 0.32228
Value Function Update Magnitude: 0.36786

Collected Steps per Second: 16,853.74994
Overall Steps per Second: 8,740.42746

Timestep Collection Time: 2.96824
Timestep Consumption Time: 2.75528
PPO Batch Consumption Time: 0.31008
Total Iteration Time: 5.72352

Cumulative Model Updates: 224,946
Cumulative Timesteps: 1,876,652,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,458.67768
Policy Entropy: 1.97564
Value Function Loss: 0.02878

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07730
Policy Update Magnitude: 0.31850
Value Function Update Magnitude: 0.31475

Collected Steps per Second: 18,288.90587
Overall Steps per Second: 9,539.68512

Timestep Collection Time: 2.73619
Timestep Consumption Time: 2.50947
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 5.24567

Cumulative Model Updates: 224,952
Cumulative Timesteps: 1,876,703,038

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1876703038...
Checkpoint 1876703038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,034.04718
Policy Entropy: 1.98003
Value Function Loss: 0.02651

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07538
Policy Update Magnitude: 0.31658
Value Function Update Magnitude: 0.32017

Collected Steps per Second: 20,740.13894
Overall Steps per Second: 10,305.88474

Timestep Collection Time: 2.41252
Timestep Consumption Time: 2.44257
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.85509

Cumulative Model Updates: 224,958
Cumulative Timesteps: 1,876,753,074

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,519.06458
Policy Entropy: 1.98394
Value Function Loss: 0.02732

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07579
Policy Update Magnitude: 0.31371
Value Function Update Magnitude: 0.34157

Collected Steps per Second: 19,376.32817
Overall Steps per Second: 9,620.69264

Timestep Collection Time: 2.58119
Timestep Consumption Time: 2.61740
PPO Batch Consumption Time: 0.30969
Total Iteration Time: 5.19859

Cumulative Model Updates: 224,964
Cumulative Timesteps: 1,876,803,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1876803088...
Checkpoint 1876803088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,393.07045
Policy Entropy: 1.98721
Value Function Loss: 0.02511

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07609
Policy Update Magnitude: 0.30931
Value Function Update Magnitude: 0.34136

Collected Steps per Second: 18,534.56638
Overall Steps per Second: 9,234.79045

Timestep Collection Time: 2.69853
Timestep Consumption Time: 2.71752
PPO Batch Consumption Time: 0.32903
Total Iteration Time: 5.41604

Cumulative Model Updates: 224,970
Cumulative Timesteps: 1,876,853,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,329.40488
Policy Entropy: 1.97549
Value Function Loss: 0.02469

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07773
Policy Update Magnitude: 0.30280
Value Function Update Magnitude: 0.33331

Collected Steps per Second: 20,547.31087
Overall Steps per Second: 10,014.07473

Timestep Collection Time: 2.43380
Timestep Consumption Time: 2.55997
PPO Batch Consumption Time: 0.30062
Total Iteration Time: 4.99377

Cumulative Model Updates: 224,976
Cumulative Timesteps: 1,876,903,112

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1876903112...
Checkpoint 1876903112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,061.01359
Policy Entropy: 1.97344
Value Function Loss: 0.02362

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07590
Policy Update Magnitude: 0.30367
Value Function Update Magnitude: 0.31059

Collected Steps per Second: 19,528.75657
Overall Steps per Second: 9,920.93507

Timestep Collection Time: 2.56063
Timestep Consumption Time: 2.47982
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 5.04045

Cumulative Model Updates: 224,982
Cumulative Timesteps: 1,876,953,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,811.85486
Policy Entropy: 1.96365
Value Function Loss: 0.02467

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.30430
Value Function Update Magnitude: 0.27660

Collected Steps per Second: 21,808.29116
Overall Steps per Second: 10,296.89448

Timestep Collection Time: 2.29271
Timestep Consumption Time: 2.56313
PPO Batch Consumption Time: 0.29967
Total Iteration Time: 4.85583

Cumulative Model Updates: 224,988
Cumulative Timesteps: 1,877,003,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1877003118...
Checkpoint 1877003118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,482.00347
Policy Entropy: 1.96291
Value Function Loss: 0.02826

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.31187
Value Function Update Magnitude: 0.24688

Collected Steps per Second: 20,382.36200
Overall Steps per Second: 10,177.39835

Timestep Collection Time: 2.45448
Timestep Consumption Time: 2.46112
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.91560

Cumulative Model Updates: 224,994
Cumulative Timesteps: 1,877,053,146

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,318.54350
Policy Entropy: 1.95539
Value Function Loss: 0.02805

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.31358
Value Function Update Magnitude: 0.24596

Collected Steps per Second: 20,216.15455
Overall Steps per Second: 10,013.06496

Timestep Collection Time: 2.47367
Timestep Consumption Time: 2.52061
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.99428

Cumulative Model Updates: 225,000
Cumulative Timesteps: 1,877,103,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1877103154...
Checkpoint 1877103154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,032.92457
Policy Entropy: 1.96792
Value Function Loss: 0.03020

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08860
Policy Update Magnitude: 0.32365
Value Function Update Magnitude: 0.30165

Collected Steps per Second: 21,162.62493
Overall Steps per Second: 10,265.06439

Timestep Collection Time: 2.36464
Timestep Consumption Time: 2.51034
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.87498

Cumulative Model Updates: 225,006
Cumulative Timesteps: 1,877,153,196

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,856.51212
Policy Entropy: 1.97508
Value Function Loss: 0.03075

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08072
Policy Update Magnitude: 0.32510
Value Function Update Magnitude: 0.29416

Collected Steps per Second: 21,654.66235
Overall Steps per Second: 10,357.53376

Timestep Collection Time: 2.30916
Timestep Consumption Time: 2.51863
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.82779

Cumulative Model Updates: 225,012
Cumulative Timesteps: 1,877,203,200

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1877203200...
Checkpoint 1877203200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,385.91463
Policy Entropy: 1.98926
Value Function Loss: 0.03155

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.08964
Policy Update Magnitude: 0.32122
Value Function Update Magnitude: 0.34020

Collected Steps per Second: 21,214.65276
Overall Steps per Second: 10,214.95585

Timestep Collection Time: 2.35752
Timestep Consumption Time: 2.53863
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.89615

Cumulative Model Updates: 225,018
Cumulative Timesteps: 1,877,253,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,684.35897
Policy Entropy: 1.98087
Value Function Loss: 0.03000

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.08466
Policy Update Magnitude: 0.31591
Value Function Update Magnitude: 0.36606

Collected Steps per Second: 21,552.74809
Overall Steps per Second: 10,490.40329

Timestep Collection Time: 2.32156
Timestep Consumption Time: 2.44813
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.76969

Cumulative Model Updates: 225,024
Cumulative Timesteps: 1,877,303,250

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1877303250...
Checkpoint 1877303250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,485.59301
Policy Entropy: 1.96892
Value Function Loss: 0.02620

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.31233
Value Function Update Magnitude: 0.36683

Collected Steps per Second: 21,296.02186
Overall Steps per Second: 9,861.21126

Timestep Collection Time: 2.34823
Timestep Consumption Time: 2.72295
PPO Batch Consumption Time: 0.32709
Total Iteration Time: 5.07118

Cumulative Model Updates: 225,030
Cumulative Timesteps: 1,877,353,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,193.66386
Policy Entropy: 1.95666
Value Function Loss: 0.02360

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.30893
Value Function Update Magnitude: 0.34625

Collected Steps per Second: 20,406.51808
Overall Steps per Second: 9,517.32203

Timestep Collection Time: 2.45118
Timestep Consumption Time: 2.80450
PPO Batch Consumption Time: 0.34194
Total Iteration Time: 5.25568

Cumulative Model Updates: 225,036
Cumulative Timesteps: 1,877,403,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1877403278...
Checkpoint 1877403278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,844.57255
Policy Entropy: 1.96371
Value Function Loss: 0.02878

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.31381
Value Function Update Magnitude: 0.30390

Collected Steps per Second: 19,248.47126
Overall Steps per Second: 9,817.03555

Timestep Collection Time: 2.59792
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.29758
Total Iteration Time: 5.09380

Cumulative Model Updates: 225,042
Cumulative Timesteps: 1,877,453,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,272.13848
Policy Entropy: 1.96448
Value Function Loss: 0.02747

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.31760
Value Function Update Magnitude: 0.29602

Collected Steps per Second: 20,133.39370
Overall Steps per Second: 9,873.68644

Timestep Collection Time: 2.48354
Timestep Consumption Time: 2.58063
PPO Batch Consumption Time: 0.30270
Total Iteration Time: 5.06417

Cumulative Model Updates: 225,048
Cumulative Timesteps: 1,877,503,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1877503286...
Checkpoint 1877503286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,476.62645
Policy Entropy: 1.95572
Value Function Loss: 0.02727

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.08892
Policy Update Magnitude: 0.31242
Value Function Update Magnitude: 0.31951

Collected Steps per Second: 20,914.27080
Overall Steps per Second: 10,453.52823

Timestep Collection Time: 2.39243
Timestep Consumption Time: 2.39408
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.78652

Cumulative Model Updates: 225,054
Cumulative Timesteps: 1,877,553,322

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,465.04162
Policy Entropy: 1.94823
Value Function Loss: 0.02461

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.10905
Policy Update Magnitude: 0.29795
Value Function Update Magnitude: 0.32316

Collected Steps per Second: 20,874.31081
Overall Steps per Second: 9,926.06605

Timestep Collection Time: 2.39644
Timestep Consumption Time: 2.64322
PPO Batch Consumption Time: 0.31156
Total Iteration Time: 5.03966

Cumulative Model Updates: 225,060
Cumulative Timesteps: 1,877,603,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1877603346...
Checkpoint 1877603346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,845.41544
Policy Entropy: 1.94816
Value Function Loss: 0.02687

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.28343
Value Function Update Magnitude: 0.32382

Collected Steps per Second: 18,748.43446
Overall Steps per Second: 9,763.99147

Timestep Collection Time: 2.66881
Timestep Consumption Time: 2.45573
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 5.12454

Cumulative Model Updates: 225,066
Cumulative Timesteps: 1,877,653,382

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,746.63549
Policy Entropy: 1.94913
Value Function Loss: 0.02693

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.30427
Value Function Update Magnitude: 0.33804

Collected Steps per Second: 20,634.51974
Overall Steps per Second: 10,002.76897

Timestep Collection Time: 2.42312
Timestep Consumption Time: 2.57549
PPO Batch Consumption Time: 0.30319
Total Iteration Time: 4.99862

Cumulative Model Updates: 225,072
Cumulative Timesteps: 1,877,703,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1877703382...
Checkpoint 1877703382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,782.45598
Policy Entropy: 1.94283
Value Function Loss: 0.02699

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.31469
Value Function Update Magnitude: 0.32827

Collected Steps per Second: 19,507.53614
Overall Steps per Second: 10,057.52426

Timestep Collection Time: 2.56352
Timestep Consumption Time: 2.40868
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.97220

Cumulative Model Updates: 225,078
Cumulative Timesteps: 1,877,753,390

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,970.93677
Policy Entropy: 1.95310
Value Function Loss: 0.03002

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.31869
Value Function Update Magnitude: 0.32192

Collected Steps per Second: 20,269.56881
Overall Steps per Second: 9,498.91811

Timestep Collection Time: 2.46784
Timestep Consumption Time: 2.79824
PPO Batch Consumption Time: 0.33910
Total Iteration Time: 5.26607

Cumulative Model Updates: 225,084
Cumulative Timesteps: 1,877,803,412

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1877803412...
Checkpoint 1877803412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,663.07873
Policy Entropy: 1.95019
Value Function Loss: 0.02880

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.11093
Policy Update Magnitude: 0.31750
Value Function Update Magnitude: 0.34866

Collected Steps per Second: 18,893.36223
Overall Steps per Second: 9,488.71752

Timestep Collection Time: 2.64738
Timestep Consumption Time: 2.62393
PPO Batch Consumption Time: 0.31169
Total Iteration Time: 5.27131

Cumulative Model Updates: 225,090
Cumulative Timesteps: 1,877,853,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,192.71461
Policy Entropy: 1.95173
Value Function Loss: 0.03023

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.10595
Policy Update Magnitude: 0.31738
Value Function Update Magnitude: 0.37408

Collected Steps per Second: 20,388.55516
Overall Steps per Second: 10,047.98947

Timestep Collection Time: 2.45265
Timestep Consumption Time: 2.52407
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.97672

Cumulative Model Updates: 225,096
Cumulative Timesteps: 1,877,903,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1877903436...
Checkpoint 1877903436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,617.62701
Policy Entropy: 1.94808
Value Function Loss: 0.02885

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.32437
Value Function Update Magnitude: 0.37798

Collected Steps per Second: 18,863.65007
Overall Steps per Second: 9,595.40256

Timestep Collection Time: 2.65155
Timestep Consumption Time: 2.56115
PPO Batch Consumption Time: 0.31403
Total Iteration Time: 5.21270

Cumulative Model Updates: 225,102
Cumulative Timesteps: 1,877,953,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,820.45520
Policy Entropy: 1.95800
Value Function Loss: 0.03305

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.09044
Policy Update Magnitude: 0.33102
Value Function Update Magnitude: 0.37674

Collected Steps per Second: 20,732.99564
Overall Steps per Second: 10,269.45575

Timestep Collection Time: 2.41200
Timestep Consumption Time: 2.45759
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.86959

Cumulative Model Updates: 225,108
Cumulative Timesteps: 1,878,003,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1878003462...
Checkpoint 1878003462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,955.95321
Policy Entropy: 1.96204
Value Function Loss: 0.03046

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.32999
Value Function Update Magnitude: 0.39753

Collected Steps per Second: 18,786.77703
Overall Steps per Second: 9,402.60767

Timestep Collection Time: 2.66219
Timestep Consumption Time: 2.65697
PPO Batch Consumption Time: 0.31450
Total Iteration Time: 5.31916

Cumulative Model Updates: 225,114
Cumulative Timesteps: 1,878,053,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,299.55569
Policy Entropy: 1.96330
Value Function Loss: 0.02966

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08233
Policy Update Magnitude: 0.31999
Value Function Update Magnitude: 0.37923

Collected Steps per Second: 20,023.48157
Overall Steps per Second: 9,810.21123

Timestep Collection Time: 2.49907
Timestep Consumption Time: 2.60174
PPO Batch Consumption Time: 0.30353
Total Iteration Time: 5.10081

Cumulative Model Updates: 225,120
Cumulative Timesteps: 1,878,103,516

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1878103516...
Checkpoint 1878103516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,434.29438
Policy Entropy: 1.97396
Value Function Loss: 0.02748

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.31568
Value Function Update Magnitude: 0.35078

Collected Steps per Second: 19,934.88877
Overall Steps per Second: 9,973.75090

Timestep Collection Time: 2.50897
Timestep Consumption Time: 2.50580
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 5.01476

Cumulative Model Updates: 225,126
Cumulative Timesteps: 1,878,153,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,249.11088
Policy Entropy: 1.95828
Value Function Loss: 0.02942

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.32110
Value Function Update Magnitude: 0.35929

Collected Steps per Second: 21,158.69700
Overall Steps per Second: 10,208.41545

Timestep Collection Time: 2.36319
Timestep Consumption Time: 2.53493
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.89812

Cumulative Model Updates: 225,132
Cumulative Timesteps: 1,878,203,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1878203534...
Checkpoint 1878203534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,916.53820
Policy Entropy: 1.94654
Value Function Loss: 0.02901

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.09307
Policy Update Magnitude: 0.32393
Value Function Update Magnitude: 0.37557

Collected Steps per Second: 20,959.68172
Overall Steps per Second: 10,256.58818

Timestep Collection Time: 2.38639
Timestep Consumption Time: 2.49028
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.87667

Cumulative Model Updates: 225,138
Cumulative Timesteps: 1,878,253,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,554.13665
Policy Entropy: 1.94447
Value Function Loss: 0.03020

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.08888
Policy Update Magnitude: 0.32187
Value Function Update Magnitude: 0.37554

Collected Steps per Second: 21,069.70653
Overall Steps per Second: 10,359.04687

Timestep Collection Time: 2.37393
Timestep Consumption Time: 2.45451
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.82844

Cumulative Model Updates: 225,144
Cumulative Timesteps: 1,878,303,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1878303570...
Checkpoint 1878303570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,029.50084
Policy Entropy: 1.96208
Value Function Loss: 0.03060

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.32133
Value Function Update Magnitude: 0.35881

Collected Steps per Second: 20,973.23143
Overall Steps per Second: 10,470.62860

Timestep Collection Time: 2.38409
Timestep Consumption Time: 2.39137
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.77545

Cumulative Model Updates: 225,150
Cumulative Timesteps: 1,878,353,572

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,500.63874
Policy Entropy: 1.98729
Value Function Loss: 0.02746

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.32075
Value Function Update Magnitude: 0.35885

Collected Steps per Second: 20,816.87717
Overall Steps per Second: 10,251.74971

Timestep Collection Time: 2.40209
Timestep Consumption Time: 2.47552
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.87761

Cumulative Model Updates: 225,156
Cumulative Timesteps: 1,878,403,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1878403576...
Checkpoint 1878403576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,607.60870
Policy Entropy: 1.97642
Value Function Loss: 0.02524

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07687
Policy Update Magnitude: 0.31327
Value Function Update Magnitude: 0.34901

Collected Steps per Second: 20,440.91545
Overall Steps per Second: 10,162.36223

Timestep Collection Time: 2.44607
Timestep Consumption Time: 2.47404
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.92012

Cumulative Model Updates: 225,162
Cumulative Timesteps: 1,878,453,576

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,936.16208
Policy Entropy: 1.96100
Value Function Loss: 0.02470

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07558
Policy Update Magnitude: 0.31222
Value Function Update Magnitude: 0.33660

Collected Steps per Second: 20,711.24250
Overall Steps per Second: 10,334.47102

Timestep Collection Time: 2.41521
Timestep Consumption Time: 2.42510
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.84031

Cumulative Model Updates: 225,168
Cumulative Timesteps: 1,878,503,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1878503598...
Checkpoint 1878503598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,003.05482
Policy Entropy: 1.95609
Value Function Loss: 0.02838

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07627
Policy Update Magnitude: 0.31069
Value Function Update Magnitude: 0.31978

Collected Steps per Second: 20,497.78953
Overall Steps per Second: 10,324.69810

Timestep Collection Time: 2.44104
Timestep Consumption Time: 2.40520
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.84624

Cumulative Model Updates: 225,174
Cumulative Timesteps: 1,878,553,634

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,827.45658
Policy Entropy: 1.96971
Value Function Loss: 0.02859

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.31962
Value Function Update Magnitude: 0.32874

Collected Steps per Second: 20,860.27901
Overall Steps per Second: 9,984.30149

Timestep Collection Time: 2.39757
Timestep Consumption Time: 2.61169
PPO Batch Consumption Time: 0.30744
Total Iteration Time: 5.00926

Cumulative Model Updates: 225,180
Cumulative Timesteps: 1,878,603,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1878603648...
Checkpoint 1878603648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,055.90705
Policy Entropy: 1.98605
Value Function Loss: 0.02878

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.30909
Value Function Update Magnitude: 0.33277

Collected Steps per Second: 20,537.96640
Overall Steps per Second: 9,876.29292

Timestep Collection Time: 2.43461
Timestep Consumption Time: 2.62822
PPO Batch Consumption Time: 0.31026
Total Iteration Time: 5.06283

Cumulative Model Updates: 225,186
Cumulative Timesteps: 1,878,653,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,502.52563
Policy Entropy: 1.99122
Value Function Loss: 0.02780

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.07901
Policy Update Magnitude: 0.30734
Value Function Update Magnitude: 0.33762

Collected Steps per Second: 21,228.02643
Overall Steps per Second: 10,211.36938

Timestep Collection Time: 2.35566
Timestep Consumption Time: 2.54143
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.89709

Cumulative Model Updates: 225,192
Cumulative Timesteps: 1,878,703,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1878703656...
Checkpoint 1878703656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,708.62602
Policy Entropy: 1.98911
Value Function Loss: 0.02823

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.31449
Value Function Update Magnitude: 0.35689

Collected Steps per Second: 20,484.13547
Overall Steps per Second: 10,062.18888

Timestep Collection Time: 2.44101
Timestep Consumption Time: 2.52829
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.96930

Cumulative Model Updates: 225,198
Cumulative Timesteps: 1,878,753,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,230.68026
Policy Entropy: 1.97276
Value Function Loss: 0.02884

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07738
Policy Update Magnitude: 0.31593
Value Function Update Magnitude: 0.37065

Collected Steps per Second: 21,380.75194
Overall Steps per Second: 10,140.78279

Timestep Collection Time: 2.34080
Timestep Consumption Time: 2.59452
PPO Batch Consumption Time: 0.29966
Total Iteration Time: 4.93532

Cumulative Model Updates: 225,204
Cumulative Timesteps: 1,878,803,706

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1878803706...
Checkpoint 1878803706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,889.19577
Policy Entropy: 1.96826
Value Function Loss: 0.02450

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07445
Policy Update Magnitude: 0.30825
Value Function Update Magnitude: 0.34281

Collected Steps per Second: 19,842.47069
Overall Steps per Second: 9,826.74427

Timestep Collection Time: 2.52136
Timestep Consumption Time: 2.56985
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 5.09121

Cumulative Model Updates: 225,210
Cumulative Timesteps: 1,878,853,736

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,757.90123
Policy Entropy: 1.96552
Value Function Loss: 0.02527

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07097
Policy Update Magnitude: 0.29946
Value Function Update Magnitude: 0.32205

Collected Steps per Second: 19,391.95025
Overall Steps per Second: 9,564.13265

Timestep Collection Time: 2.58056
Timestep Consumption Time: 2.65170
PPO Batch Consumption Time: 0.31645
Total Iteration Time: 5.23226

Cumulative Model Updates: 225,216
Cumulative Timesteps: 1,878,903,778

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1878903778...
Checkpoint 1878903778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,411.38319
Policy Entropy: 1.97163
Value Function Loss: 0.02508

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07648
Policy Update Magnitude: 0.30007
Value Function Update Magnitude: 0.32120

Collected Steps per Second: 19,340.88066
Overall Steps per Second: 9,461.29868

Timestep Collection Time: 2.58665
Timestep Consumption Time: 2.70100
PPO Batch Consumption Time: 0.31623
Total Iteration Time: 5.28765

Cumulative Model Updates: 225,222
Cumulative Timesteps: 1,878,953,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,433.07831
Policy Entropy: 1.97188
Value Function Loss: 0.02731

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.30547
Value Function Update Magnitude: 0.33794

Collected Steps per Second: 18,143.09605
Overall Steps per Second: 9,515.17378

Timestep Collection Time: 2.75675
Timestep Consumption Time: 2.49970
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 5.25645

Cumulative Model Updates: 225,228
Cumulative Timesteps: 1,879,003,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1879003822...
Checkpoint 1879003822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,638.50457
Policy Entropy: 1.97019
Value Function Loss: 0.02488

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.30563
Value Function Update Magnitude: 0.36177

Collected Steps per Second: 19,304.73467
Overall Steps per Second: 9,689.90634

Timestep Collection Time: 2.59087
Timestep Consumption Time: 2.57079
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 5.16166

Cumulative Model Updates: 225,234
Cumulative Timesteps: 1,879,053,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,245.88676
Policy Entropy: 1.96528
Value Function Loss: 0.02536

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07889
Policy Update Magnitude: 0.30600
Value Function Update Magnitude: 0.36358

Collected Steps per Second: 18,629.44205
Overall Steps per Second: 9,499.81939

Timestep Collection Time: 2.68478
Timestep Consumption Time: 2.58016
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 5.26494

Cumulative Model Updates: 225,240
Cumulative Timesteps: 1,879,103,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1879103854...
Checkpoint 1879103854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,699.39195
Policy Entropy: 1.96702
Value Function Loss: 0.02617

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.31086
Value Function Update Magnitude: 0.34061

Collected Steps per Second: 19,938.11824
Overall Steps per Second: 9,761.14947

Timestep Collection Time: 2.50846
Timestep Consumption Time: 2.61532
PPO Batch Consumption Time: 0.29731
Total Iteration Time: 5.12378

Cumulative Model Updates: 225,246
Cumulative Timesteps: 1,879,153,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,938.01815
Policy Entropy: 1.97131
Value Function Loss: 0.02949

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08510
Policy Update Magnitude: 0.31846
Value Function Update Magnitude: 0.35086

Collected Steps per Second: 19,942.65748
Overall Steps per Second: 10,076.54945

Timestep Collection Time: 2.50739
Timestep Consumption Time: 2.45502
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.96241

Cumulative Model Updates: 225,252
Cumulative Timesteps: 1,879,203,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1879203872...
Checkpoint 1879203872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,171.52287
Policy Entropy: 1.97341
Value Function Loss: 0.02937

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.32357
Value Function Update Magnitude: 0.36310

Collected Steps per Second: 18,486.50127
Overall Steps per Second: 9,880.87948

Timestep Collection Time: 2.70468
Timestep Consumption Time: 2.35560
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 5.06028

Cumulative Model Updates: 225,258
Cumulative Timesteps: 1,879,253,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,848.63841
Policy Entropy: 1.97168
Value Function Loss: 0.02672

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.09286
Policy Update Magnitude: 0.31669
Value Function Update Magnitude: 0.33760

Collected Steps per Second: 18,165.58264
Overall Steps per Second: 9,240.01265

Timestep Collection Time: 2.75378
Timestep Consumption Time: 2.66007
PPO Batch Consumption Time: 0.30200
Total Iteration Time: 5.41385

Cumulative Model Updates: 225,264
Cumulative Timesteps: 1,879,303,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1879303896...
Checkpoint 1879303896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,431.93421
Policy Entropy: 1.97912
Value Function Loss: 0.02436

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08702
Policy Update Magnitude: 0.30799
Value Function Update Magnitude: 0.33208

Collected Steps per Second: 19,388.70885
Overall Steps per Second: 9,601.14009

Timestep Collection Time: 2.58037
Timestep Consumption Time: 2.63047
PPO Batch Consumption Time: 0.30858
Total Iteration Time: 5.21084

Cumulative Model Updates: 225,270
Cumulative Timesteps: 1,879,353,926

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,955.18420
Policy Entropy: 1.96687
Value Function Loss: 0.02330

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.30347
Value Function Update Magnitude: 0.30920

Collected Steps per Second: 19,234.40780
Overall Steps per Second: 9,682.47294

Timestep Collection Time: 2.59982
Timestep Consumption Time: 2.56477
PPO Batch Consumption Time: 0.30863
Total Iteration Time: 5.16459

Cumulative Model Updates: 225,276
Cumulative Timesteps: 1,879,403,932

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1879403932...
Checkpoint 1879403932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,341.44375
Policy Entropy: 1.93871
Value Function Loss: 0.02494

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.30436
Value Function Update Magnitude: 0.29880

Collected Steps per Second: 18,748.11118
Overall Steps per Second: 9,934.15771

Timestep Collection Time: 2.66800
Timestep Consumption Time: 2.36715
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 5.03515

Cumulative Model Updates: 225,282
Cumulative Timesteps: 1,879,453,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,504.79998
Policy Entropy: 1.94246
Value Function Loss: 0.02656

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08250
Policy Update Magnitude: 0.30203
Value Function Update Magnitude: 0.32747

Collected Steps per Second: 20,248.47643
Overall Steps per Second: 10,158.77148

Timestep Collection Time: 2.47001
Timestep Consumption Time: 2.45322
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.92323

Cumulative Model Updates: 225,288
Cumulative Timesteps: 1,879,503,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1879503966...
Checkpoint 1879503966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,623.67756
Policy Entropy: 1.97641
Value Function Loss: 0.02522

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.30403
Value Function Update Magnitude: 0.34697

Collected Steps per Second: 20,780.84857
Overall Steps per Second: 10,149.78834

Timestep Collection Time: 2.40625
Timestep Consumption Time: 2.52035
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.92661

Cumulative Model Updates: 225,294
Cumulative Timesteps: 1,879,553,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,897.53557
Policy Entropy: 1.99048
Value Function Loss: 0.02708

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08354
Policy Update Magnitude: 0.30844
Value Function Update Magnitude: 0.35160

Collected Steps per Second: 20,909.47085
Overall Steps per Second: 10,000.57885

Timestep Collection Time: 2.39203
Timestep Consumption Time: 2.60928
PPO Batch Consumption Time: 0.30823
Total Iteration Time: 5.00131

Cumulative Model Updates: 225,300
Cumulative Timesteps: 1,879,603,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1879603986...
Checkpoint 1879603986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,519.81767
Policy Entropy: 1.99219
Value Function Loss: 0.02732

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.31046
Value Function Update Magnitude: 0.36650

Collected Steps per Second: 20,732.23908
Overall Steps per Second: 10,164.03102

Timestep Collection Time: 2.41305
Timestep Consumption Time: 2.50901
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.92206

Cumulative Model Updates: 225,306
Cumulative Timesteps: 1,879,654,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,438.90291
Policy Entropy: 1.96689
Value Function Loss: 0.02793

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.31569
Value Function Update Magnitude: 0.37422

Collected Steps per Second: 20,498.21856
Overall Steps per Second: 10,047.85716

Timestep Collection Time: 2.44070
Timestep Consumption Time: 2.53847
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.97917

Cumulative Model Updates: 225,312
Cumulative Timesteps: 1,879,704,044

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1879704044...
Checkpoint 1879704044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,354.83280
Policy Entropy: 1.95798
Value Function Loss: 0.02525

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.31001
Value Function Update Magnitude: 0.36449

Collected Steps per Second: 21,432.73648
Overall Steps per Second: 10,725.17577

Timestep Collection Time: 2.33353
Timestep Consumption Time: 2.32970
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.66323

Cumulative Model Updates: 225,318
Cumulative Timesteps: 1,879,754,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,947.62016
Policy Entropy: 1.96027
Value Function Loss: 0.02337

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.30435
Value Function Update Magnitude: 0.35576

Collected Steps per Second: 20,997.94535
Overall Steps per Second: 10,375.78428

Timestep Collection Time: 2.38147
Timestep Consumption Time: 2.43802
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.81949

Cumulative Model Updates: 225,324
Cumulative Timesteps: 1,879,804,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1879804064...
Checkpoint 1879804064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,836.36348
Policy Entropy: 1.96145
Value Function Loss: 0.02293

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.30507
Value Function Update Magnitude: 0.34545

Collected Steps per Second: 21,308.40637
Overall Steps per Second: 10,277.47096

Timestep Collection Time: 2.34687
Timestep Consumption Time: 2.51892
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.86579

Cumulative Model Updates: 225,330
Cumulative Timesteps: 1,879,854,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,249.63317
Policy Entropy: 1.97244
Value Function Loss: 0.02355

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.30527
Value Function Update Magnitude: 0.33417

Collected Steps per Second: 20,648.49660
Overall Steps per Second: 10,170.12111

Timestep Collection Time: 2.42148
Timestep Consumption Time: 2.49488
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.91636

Cumulative Model Updates: 225,336
Cumulative Timesteps: 1,879,904,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1879904072...
Checkpoint 1879904072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,387.47781
Policy Entropy: 1.96104
Value Function Loss: 0.02332

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.30135
Value Function Update Magnitude: 0.32869

Collected Steps per Second: 20,805.25558
Overall Steps per Second: 10,142.99921

Timestep Collection Time: 2.40382
Timestep Consumption Time: 2.52688
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.93069

Cumulative Model Updates: 225,342
Cumulative Timesteps: 1,879,954,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,645.47998
Policy Entropy: 1.96478
Value Function Loss: 0.02315

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07166
Policy Update Magnitude: 0.29755
Value Function Update Magnitude: 0.31251

Collected Steps per Second: 20,881.08808
Overall Steps per Second: 10,336.13963

Timestep Collection Time: 2.39566
Timestep Consumption Time: 2.44406
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.83972

Cumulative Model Updates: 225,348
Cumulative Timesteps: 1,880,004,108

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1880004108...
Checkpoint 1880004108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,128.25167
Policy Entropy: 1.95894
Value Function Loss: 0.02552

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07295
Policy Update Magnitude: 0.29538
Value Function Update Magnitude: 0.29722

Collected Steps per Second: 21,097.13718
Overall Steps per Second: 10,242.10944

Timestep Collection Time: 2.37084
Timestep Consumption Time: 2.51272
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.88356

Cumulative Model Updates: 225,354
Cumulative Timesteps: 1,880,054,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,895.41871
Policy Entropy: 1.97531
Value Function Loss: 0.02499

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07669
Policy Update Magnitude: 0.30471
Value Function Update Magnitude: 0.32531

Collected Steps per Second: 21,115.39448
Overall Steps per Second: 10,285.52500

Timestep Collection Time: 2.36898
Timestep Consumption Time: 2.49436
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.86334

Cumulative Model Updates: 225,360
Cumulative Timesteps: 1,880,104,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1880104148...
Checkpoint 1880104148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,353.78839
Policy Entropy: 1.97533
Value Function Loss: 0.02750

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.31221
Value Function Update Magnitude: 0.32240

Collected Steps per Second: 18,919.66976
Overall Steps per Second: 9,584.81781

Timestep Collection Time: 2.64318
Timestep Consumption Time: 2.57424
PPO Batch Consumption Time: 0.30585
Total Iteration Time: 5.21742

Cumulative Model Updates: 225,366
Cumulative Timesteps: 1,880,154,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,379.14735
Policy Entropy: 1.96762
Value Function Loss: 0.02597

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.31306
Value Function Update Magnitude: 0.30526

Collected Steps per Second: 21,127.93859
Overall Steps per Second: 10,252.05553

Timestep Collection Time: 2.36729
Timestep Consumption Time: 2.51134
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.87863

Cumulative Model Updates: 225,372
Cumulative Timesteps: 1,880,204,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1880204172...
Checkpoint 1880204172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,975.50307
Policy Entropy: 1.96058
Value Function Loss: 0.02376

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07541
Policy Update Magnitude: 0.30372
Value Function Update Magnitude: 0.30746

Collected Steps per Second: 20,233.49338
Overall Steps per Second: 9,888.94235

Timestep Collection Time: 2.47214
Timestep Consumption Time: 2.58604
PPO Batch Consumption Time: 0.30309
Total Iteration Time: 5.05817

Cumulative Model Updates: 225,378
Cumulative Timesteps: 1,880,254,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,294.89141
Policy Entropy: 1.94607
Value Function Loss: 0.02374

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07270
Policy Update Magnitude: 0.29557
Value Function Update Magnitude: 0.30151

Collected Steps per Second: 20,372.85586
Overall Steps per Second: 10,195.86585

Timestep Collection Time: 2.45425
Timestep Consumption Time: 2.44970
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.90395

Cumulative Model Updates: 225,384
Cumulative Timesteps: 1,880,304,192

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1880304192...
Checkpoint 1880304192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,854.23479
Policy Entropy: 1.95327
Value Function Loss: 0.02247

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07309
Policy Update Magnitude: 0.29795
Value Function Update Magnitude: 0.30563

Collected Steps per Second: 20,966.84514
Overall Steps per Second: 10,152.29065

Timestep Collection Time: 2.38539
Timestep Consumption Time: 2.54099
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.92638

Cumulative Model Updates: 225,390
Cumulative Timesteps: 1,880,354,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,226.62357
Policy Entropy: 1.95703
Value Function Loss: 0.02457

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.07895
Policy Update Magnitude: 0.29743
Value Function Update Magnitude: 0.29930

Collected Steps per Second: 21,393.06198
Overall Steps per Second: 10,030.53691

Timestep Collection Time: 2.33749
Timestep Consumption Time: 2.64789
PPO Batch Consumption Time: 0.30309
Total Iteration Time: 4.98538

Cumulative Model Updates: 225,396
Cumulative Timesteps: 1,880,404,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1880404212...
Checkpoint 1880404212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,462.13356
Policy Entropy: 1.97803
Value Function Loss: 0.02490

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.29967
Value Function Update Magnitude: 0.31247

Collected Steps per Second: 19,461.11035
Overall Steps per Second: 9,844.05620

Timestep Collection Time: 2.57015
Timestep Consumption Time: 2.51088
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 5.08104

Cumulative Model Updates: 225,402
Cumulative Timesteps: 1,880,454,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,035.31442
Policy Entropy: 1.97648
Value Function Loss: 0.02557

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08216
Policy Update Magnitude: 0.30412
Value Function Update Magnitude: 0.33193

Collected Steps per Second: 21,471.53007
Overall Steps per Second: 10,461.59295

Timestep Collection Time: 2.32932
Timestep Consumption Time: 2.45141
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.78073

Cumulative Model Updates: 225,408
Cumulative Timesteps: 1,880,504,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1880504244...
Checkpoint 1880504244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,334.54472
Policy Entropy: 1.96705
Value Function Loss: 0.02679

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.31251
Value Function Update Magnitude: 0.34180

Collected Steps per Second: 21,297.02730
Overall Steps per Second: 10,136.98246

Timestep Collection Time: 2.34775
Timestep Consumption Time: 2.58469
PPO Batch Consumption Time: 0.30512
Total Iteration Time: 4.93243

Cumulative Model Updates: 225,414
Cumulative Timesteps: 1,880,554,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,759.17086
Policy Entropy: 1.95404
Value Function Loss: 0.02735

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.31798
Value Function Update Magnitude: 0.35118

Collected Steps per Second: 18,721.21713
Overall Steps per Second: 9,603.71402

Timestep Collection Time: 2.67173
Timestep Consumption Time: 2.53647
PPO Batch Consumption Time: 0.29773
Total Iteration Time: 5.20819

Cumulative Model Updates: 225,420
Cumulative Timesteps: 1,880,604,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1880604262...
Checkpoint 1880604262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,065.26185
Policy Entropy: 1.97395
Value Function Loss: 0.03016

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.31848
Value Function Update Magnitude: 0.35487

Collected Steps per Second: 19,692.01031
Overall Steps per Second: 9,608.83059

Timestep Collection Time: 2.53951
Timestep Consumption Time: 2.66487
PPO Batch Consumption Time: 0.30824
Total Iteration Time: 5.20438

Cumulative Model Updates: 225,426
Cumulative Timesteps: 1,880,654,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,638.61529
Policy Entropy: 1.98689
Value Function Loss: 0.02934

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.31571
Value Function Update Magnitude: 0.35610

Collected Steps per Second: 18,931.01697
Overall Steps per Second: 9,678.07882

Timestep Collection Time: 2.64275
Timestep Consumption Time: 2.52666
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 5.16941

Cumulative Model Updates: 225,432
Cumulative Timesteps: 1,880,704,300

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1880704300...
Checkpoint 1880704300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,467.36294
Policy Entropy: 1.99309
Value Function Loss: 0.02929

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.31751
Value Function Update Magnitude: 0.35470

Collected Steps per Second: 21,216.70186
Overall Steps per Second: 10,422.04773

Timestep Collection Time: 2.35814
Timestep Consumption Time: 2.44245
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.80059

Cumulative Model Updates: 225,438
Cumulative Timesteps: 1,880,754,332

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,527.09012
Policy Entropy: 1.98181
Value Function Loss: 0.02688

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08250
Policy Update Magnitude: 0.31366
Value Function Update Magnitude: 0.34717

Collected Steps per Second: 21,101.14368
Overall Steps per Second: 10,223.33882

Timestep Collection Time: 2.37011
Timestep Consumption Time: 2.52184
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.89194

Cumulative Model Updates: 225,444
Cumulative Timesteps: 1,880,804,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1880804344...
Checkpoint 1880804344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,781.41901
Policy Entropy: 1.98134
Value Function Loss: 0.02704

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08117
Policy Update Magnitude: 0.31003
Value Function Update Magnitude: 0.34399

Collected Steps per Second: 21,101.19027
Overall Steps per Second: 10,249.59432

Timestep Collection Time: 2.37096
Timestep Consumption Time: 2.51021
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.88117

Cumulative Model Updates: 225,450
Cumulative Timesteps: 1,880,854,374

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,170.58525
Policy Entropy: 1.98353
Value Function Loss: 0.02353

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07801
Policy Update Magnitude: 0.30681
Value Function Update Magnitude: 0.34032

Collected Steps per Second: 20,536.68503
Overall Steps per Second: 10,000.89242

Timestep Collection Time: 2.43700
Timestep Consumption Time: 2.56735
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 5.00435

Cumulative Model Updates: 225,456
Cumulative Timesteps: 1,880,904,422

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1880904422...
Checkpoint 1880904422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,527.40664
Policy Entropy: 1.98370
Value Function Loss: 0.02506

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07498
Policy Update Magnitude: 0.30787
Value Function Update Magnitude: 0.31827

Collected Steps per Second: 19,501.03226
Overall Steps per Second: 9,760.30611

Timestep Collection Time: 2.56530
Timestep Consumption Time: 2.56015
PPO Batch Consumption Time: 0.29821
Total Iteration Time: 5.12545

Cumulative Model Updates: 225,462
Cumulative Timesteps: 1,880,954,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,686.93012
Policy Entropy: 1.99352
Value Function Loss: 0.02601

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07935
Policy Update Magnitude: 0.30279
Value Function Update Magnitude: 0.32019

Collected Steps per Second: 20,110.72401
Overall Steps per Second: 9,941.17581

Timestep Collection Time: 2.48643
Timestep Consumption Time: 2.54355
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 5.02999

Cumulative Model Updates: 225,468
Cumulative Timesteps: 1,881,004,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1881004452...
Checkpoint 1881004452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,090.18384
Policy Entropy: 1.99497
Value Function Loss: 0.02868

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.31001
Value Function Update Magnitude: 0.32157

Collected Steps per Second: 20,344.44835
Overall Steps per Second: 9,939.47334

Timestep Collection Time: 2.45866
Timestep Consumption Time: 2.57380
PPO Batch Consumption Time: 0.29974
Total Iteration Time: 5.03246

Cumulative Model Updates: 225,474
Cumulative Timesteps: 1,881,054,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,335.66473
Policy Entropy: 1.99442
Value Function Loss: 0.02945

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08201
Policy Update Magnitude: 0.30720
Value Function Update Magnitude: 0.33174

Collected Steps per Second: 18,936.15575
Overall Steps per Second: 9,936.36325

Timestep Collection Time: 2.64130
Timestep Consumption Time: 2.39234
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 5.03363

Cumulative Model Updates: 225,480
Cumulative Timesteps: 1,881,104,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1881104488...
Checkpoint 1881104488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,716.28360
Policy Entropy: 1.99153
Value Function Loss: 0.02792

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08524
Policy Update Magnitude: 0.30946
Value Function Update Magnitude: 0.33080

Collected Steps per Second: 20,363.77435
Overall Steps per Second: 10,224.18907

Timestep Collection Time: 2.45603
Timestep Consumption Time: 2.43570
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.89173

Cumulative Model Updates: 225,486
Cumulative Timesteps: 1,881,154,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,209.77690
Policy Entropy: 1.98239
Value Function Loss: 0.02477

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07622
Policy Update Magnitude: 0.30057
Value Function Update Magnitude: 0.32235

Collected Steps per Second: 20,427.45793
Overall Steps per Second: 10,239.62399

Timestep Collection Time: 2.44818
Timestep Consumption Time: 2.43579
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.88397

Cumulative Model Updates: 225,492
Cumulative Timesteps: 1,881,204,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1881204512...
Checkpoint 1881204512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,907.61272
Policy Entropy: 1.98523
Value Function Loss: 0.02088

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07272
Policy Update Magnitude: 0.29325
Value Function Update Magnitude: 0.29469

Collected Steps per Second: 20,195.19301
Overall Steps per Second: 10,074.23904

Timestep Collection Time: 2.47613
Timestep Consumption Time: 2.48762
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.96375

Cumulative Model Updates: 225,498
Cumulative Timesteps: 1,881,254,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,008.46114
Policy Entropy: 1.97960
Value Function Loss: 0.01947

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06398
Policy Update Magnitude: 0.28872
Value Function Update Magnitude: 0.26310

Collected Steps per Second: 20,928.27021
Overall Steps per Second: 10,136.13377

Timestep Collection Time: 2.38988
Timestep Consumption Time: 2.54455
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.93443

Cumulative Model Updates: 225,504
Cumulative Timesteps: 1,881,304,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1881304534...
Checkpoint 1881304534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,634.53064
Policy Entropy: 1.98555
Value Function Loss: 0.02004

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06817
Policy Update Magnitude: 0.28375
Value Function Update Magnitude: 0.27763

Collected Steps per Second: 20,073.32846
Overall Steps per Second: 9,981.27847

Timestep Collection Time: 2.49137
Timestep Consumption Time: 2.51901
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 5.01038

Cumulative Model Updates: 225,510
Cumulative Timesteps: 1,881,354,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,277.18596
Policy Entropy: 1.99518
Value Function Loss: 0.02418

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06797
Policy Update Magnitude: 0.29450
Value Function Update Magnitude: 0.28787

Collected Steps per Second: 20,295.16635
Overall Steps per Second: 9,777.67526

Timestep Collection Time: 2.46492
Timestep Consumption Time: 2.65143
PPO Batch Consumption Time: 0.31260
Total Iteration Time: 5.11635

Cumulative Model Updates: 225,516
Cumulative Timesteps: 1,881,404,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1881404570...
Checkpoint 1881404570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,201.24974
Policy Entropy: 1.99928
Value Function Loss: 0.02836

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07467
Policy Update Magnitude: 0.31327
Value Function Update Magnitude: 0.30168

Collected Steps per Second: 19,919.04289
Overall Steps per Second: 10,039.77546

Timestep Collection Time: 2.51066
Timestep Consumption Time: 2.47052
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.98119

Cumulative Model Updates: 225,522
Cumulative Timesteps: 1,881,454,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,511.13356
Policy Entropy: 2.00306
Value Function Loss: 0.02891

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07801
Policy Update Magnitude: 0.31009
Value Function Update Magnitude: 0.32467

Collected Steps per Second: 20,751.47447
Overall Steps per Second: 10,177.49447

Timestep Collection Time: 2.41101
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.91594

Cumulative Model Updates: 225,528
Cumulative Timesteps: 1,881,504,612

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1881504612...
Checkpoint 1881504612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,556.28464
Policy Entropy: 1.98491
Value Function Loss: 0.03008

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 0.31497
Value Function Update Magnitude: 0.32631

Collected Steps per Second: 21,064.01974
Overall Steps per Second: 10,188.57790

Timestep Collection Time: 2.37495
Timestep Consumption Time: 2.53506
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 4.91001

Cumulative Model Updates: 225,534
Cumulative Timesteps: 1,881,554,638

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,886.42110
Policy Entropy: 1.98188
Value Function Loss: 0.02616

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07603
Policy Update Magnitude: 0.31237
Value Function Update Magnitude: 0.33529

Collected Steps per Second: 21,651.30357
Overall Steps per Second: 10,506.79558

Timestep Collection Time: 2.31062
Timestep Consumption Time: 2.45087
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.76149

Cumulative Model Updates: 225,540
Cumulative Timesteps: 1,881,604,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1881604666...
Checkpoint 1881604666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,562.82047
Policy Entropy: 1.96359
Value Function Loss: 0.02379

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07052
Policy Update Magnitude: 0.30416
Value Function Update Magnitude: 0.34260

Collected Steps per Second: 19,296.72329
Overall Steps per Second: 9,597.48055

Timestep Collection Time: 2.59184
Timestep Consumption Time: 2.61932
PPO Batch Consumption Time: 0.31200
Total Iteration Time: 5.21116

Cumulative Model Updates: 225,546
Cumulative Timesteps: 1,881,654,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,796.95674
Policy Entropy: 1.98516
Value Function Loss: 0.02118

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06943
Policy Update Magnitude: 0.29663
Value Function Update Magnitude: 0.32445

Collected Steps per Second: 20,695.35550
Overall Steps per Second: 10,043.73314

Timestep Collection Time: 2.41619
Timestep Consumption Time: 2.56243
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.97863

Cumulative Model Updates: 225,552
Cumulative Timesteps: 1,881,704,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1881704684...
Checkpoint 1881704684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,617.91674
Policy Entropy: 1.98969
Value Function Loss: 0.02339

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06847
Policy Update Magnitude: 0.29743
Value Function Update Magnitude: 0.30364

Collected Steps per Second: 20,801.33799
Overall Steps per Second: 10,197.25330

Timestep Collection Time: 2.40504
Timestep Consumption Time: 2.50099
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.90603

Cumulative Model Updates: 225,558
Cumulative Timesteps: 1,881,754,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,503.03100
Policy Entropy: 2.00895
Value Function Loss: 0.02325

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06757
Policy Update Magnitude: 0.29723
Value Function Update Magnitude: 0.30285

Collected Steps per Second: 21,808.86380
Overall Steps per Second: 10,106.06232

Timestep Collection Time: 2.29265
Timestep Consumption Time: 2.65488
PPO Batch Consumption Time: 0.31582
Total Iteration Time: 4.94753

Cumulative Model Updates: 225,564
Cumulative Timesteps: 1,881,804,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1881804712...
Checkpoint 1881804712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,981.48984
Policy Entropy: 1.98668
Value Function Loss: 0.02437

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06789
Policy Update Magnitude: 0.29955
Value Function Update Magnitude: 0.31703

Collected Steps per Second: 19,340.11787
Overall Steps per Second: 9,417.88602

Timestep Collection Time: 2.58571
Timestep Consumption Time: 2.72418
PPO Batch Consumption Time: 0.32143
Total Iteration Time: 5.30990

Cumulative Model Updates: 225,570
Cumulative Timesteps: 1,881,854,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,957.74272
Policy Entropy: 1.98927
Value Function Loss: 0.02397

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06934
Policy Update Magnitude: 0.30219
Value Function Update Magnitude: 0.31551

Collected Steps per Second: 20,008.32827
Overall Steps per Second: 10,032.17318

Timestep Collection Time: 2.49896
Timestep Consumption Time: 2.48501
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.98397

Cumulative Model Updates: 225,576
Cumulative Timesteps: 1,881,904,720

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1881904720...
Checkpoint 1881904720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,524.19230
Policy Entropy: 1.97621
Value Function Loss: 0.02428

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.06905
Policy Update Magnitude: 0.30261
Value Function Update Magnitude: 0.31558

Collected Steps per Second: 20,404.26537
Overall Steps per Second: 9,850.94968

Timestep Collection Time: 2.45135
Timestep Consumption Time: 2.62613
PPO Batch Consumption Time: 0.30832
Total Iteration Time: 5.07748

Cumulative Model Updates: 225,582
Cumulative Timesteps: 1,881,954,738

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,995.25569
Policy Entropy: 1.99276
Value Function Loss: 0.02393

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07109
Policy Update Magnitude: 0.30298
Value Function Update Magnitude: 0.33039

Collected Steps per Second: 19,839.87885
Overall Steps per Second: 9,955.18732

Timestep Collection Time: 2.52048
Timestep Consumption Time: 2.50263
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 5.02311

Cumulative Model Updates: 225,588
Cumulative Timesteps: 1,882,004,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1882004744...
Checkpoint 1882004744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,508.10596
Policy Entropy: 1.99913
Value Function Loss: 0.02463

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06579
Policy Update Magnitude: 0.30506
Value Function Update Magnitude: 0.32741

Collected Steps per Second: 20,613.72285
Overall Steps per Second: 10,090.95420

Timestep Collection Time: 2.42576
Timestep Consumption Time: 2.52957
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.95533

Cumulative Model Updates: 225,594
Cumulative Timesteps: 1,882,054,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,845.46216
Policy Entropy: 2.00141
Value Function Loss: 0.02528

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07294
Policy Update Magnitude: 0.30283
Value Function Update Magnitude: 0.33877

Collected Steps per Second: 20,614.24055
Overall Steps per Second: 9,862.60748

Timestep Collection Time: 2.42580
Timestep Consumption Time: 2.64446
PPO Batch Consumption Time: 0.31421
Total Iteration Time: 5.07026

Cumulative Model Updates: 225,600
Cumulative Timesteps: 1,882,104,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1882104754...
Checkpoint 1882104754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,409.95528
Policy Entropy: 1.99174
Value Function Loss: 0.02492

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.30605
Value Function Update Magnitude: 0.35931

Collected Steps per Second: 19,634.08225
Overall Steps per Second: 9,801.47391

Timestep Collection Time: 2.54761
Timestep Consumption Time: 2.55570
PPO Batch Consumption Time: 0.30016
Total Iteration Time: 5.10331

Cumulative Model Updates: 225,606
Cumulative Timesteps: 1,882,154,774

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,866.84480
Policy Entropy: 1.98887
Value Function Loss: 0.02412

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.06835
Policy Update Magnitude: 0.31542
Value Function Update Magnitude: 0.34524

Collected Steps per Second: 21,297.18530
Overall Steps per Second: 10,268.66912

Timestep Collection Time: 2.34792
Timestep Consumption Time: 2.52165
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.86957

Cumulative Model Updates: 225,612
Cumulative Timesteps: 1,882,204,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1882204778...
Checkpoint 1882204778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,484.97878
Policy Entropy: 1.98435
Value Function Loss: 0.02575

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.31258
Value Function Update Magnitude: 0.33402

Collected Steps per Second: 20,406.22540
Overall Steps per Second: 9,867.97791

Timestep Collection Time: 2.45062
Timestep Consumption Time: 2.61708
PPO Batch Consumption Time: 0.30304
Total Iteration Time: 5.06770

Cumulative Model Updates: 225,618
Cumulative Timesteps: 1,882,254,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,260.41710
Policy Entropy: 1.98256
Value Function Loss: 0.02732

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.31070
Value Function Update Magnitude: 0.31720

Collected Steps per Second: 21,791.31547
Overall Steps per Second: 10,260.86139

Timestep Collection Time: 2.29605
Timestep Consumption Time: 2.58015
PPO Batch Consumption Time: 0.30025
Total Iteration Time: 4.87620

Cumulative Model Updates: 225,624
Cumulative Timesteps: 1,882,304,820

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1882304820...
Checkpoint 1882304820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,154.75149
Policy Entropy: 1.97587
Value Function Loss: 0.02762

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.31026
Value Function Update Magnitude: 0.33250

Collected Steps per Second: 20,271.03542
Overall Steps per Second: 10,196.95907

Timestep Collection Time: 2.46726
Timestep Consumption Time: 2.43753
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.90480

Cumulative Model Updates: 225,630
Cumulative Timesteps: 1,882,354,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,162.17331
Policy Entropy: 1.98155
Value Function Loss: 0.02435

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.30665
Value Function Update Magnitude: 0.32250

Collected Steps per Second: 19,692.38793
Overall Steps per Second: 10,050.54667

Timestep Collection Time: 2.54027
Timestep Consumption Time: 2.43697
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.97724

Cumulative Model Updates: 225,636
Cumulative Timesteps: 1,882,404,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1882404858...
Checkpoint 1882404858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,788.92955
Policy Entropy: 1.97832
Value Function Loss: 0.02526

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.30008
Value Function Update Magnitude: 0.32169

Collected Steps per Second: 20,108.25904
Overall Steps per Second: 9,949.47821

Timestep Collection Time: 2.48803
Timestep Consumption Time: 2.54037
PPO Batch Consumption Time: 0.30931
Total Iteration Time: 5.02840

Cumulative Model Updates: 225,642
Cumulative Timesteps: 1,882,454,888

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,611.70250
Policy Entropy: 1.98514
Value Function Loss: 0.02576

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07161
Policy Update Magnitude: 0.30031
Value Function Update Magnitude: 0.29591

Collected Steps per Second: 19,577.31780
Overall Steps per Second: 9,860.33842

Timestep Collection Time: 2.55500
Timestep Consumption Time: 2.51785
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 5.07285

Cumulative Model Updates: 225,648
Cumulative Timesteps: 1,882,504,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1882504908...
Checkpoint 1882504908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,984.13369
Policy Entropy: 1.97742
Value Function Loss: 0.02656

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07496
Policy Update Magnitude: 0.30092
Value Function Update Magnitude: 0.28138

Collected Steps per Second: 20,631.34251
Overall Steps per Second: 10,186.94620

Timestep Collection Time: 2.42456
Timestep Consumption Time: 2.48584
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.91040

Cumulative Model Updates: 225,654
Cumulative Timesteps: 1,882,554,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,121.43256
Policy Entropy: 1.98171
Value Function Loss: 0.02544

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07179
Policy Update Magnitude: 0.30245
Value Function Update Magnitude: 0.32582

Collected Steps per Second: 19,362.14361
Overall Steps per Second: 9,532.45446

Timestep Collection Time: 2.58236
Timestep Consumption Time: 2.66288
PPO Batch Consumption Time: 0.31867
Total Iteration Time: 5.24524

Cumulative Model Updates: 225,660
Cumulative Timesteps: 1,882,604,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1882604930...
Checkpoint 1882604930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,124.51206
Policy Entropy: 1.98040
Value Function Loss: 0.02846

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07447
Policy Update Magnitude: 0.31695
Value Function Update Magnitude: 0.34802

Collected Steps per Second: 19,517.16350
Overall Steps per Second: 10,021.26176

Timestep Collection Time: 2.56216
Timestep Consumption Time: 2.42784
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.98999

Cumulative Model Updates: 225,666
Cumulative Timesteps: 1,882,654,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,448.20449
Policy Entropy: 1.98538
Value Function Loss: 0.02730

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07385
Policy Update Magnitude: 0.31155
Value Function Update Magnitude: 0.34073

Collected Steps per Second: 20,590.23332
Overall Steps per Second: 9,956.68343

Timestep Collection Time: 2.42902
Timestep Consumption Time: 2.59414
PPO Batch Consumption Time: 0.30643
Total Iteration Time: 5.02316

Cumulative Model Updates: 225,672
Cumulative Timesteps: 1,882,704,950

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1882704950...
Checkpoint 1882704950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,013.24755
Policy Entropy: 1.97962
Value Function Loss: 0.02932

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.07932
Policy Update Magnitude: 0.30806
Value Function Update Magnitude: 0.31489

Collected Steps per Second: 19,420.52418
Overall Steps per Second: 9,499.42315

Timestep Collection Time: 2.57460
Timestep Consumption Time: 2.68888
PPO Batch Consumption Time: 0.31475
Total Iteration Time: 5.26348

Cumulative Model Updates: 225,678
Cumulative Timesteps: 1,882,754,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,032.49669
Policy Entropy: 1.95047
Value Function Loss: 0.02432

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07565
Policy Update Magnitude: 0.30659
Value Function Update Magnitude: 0.32023

Collected Steps per Second: 19,088.35253
Overall Steps per Second: 9,683.35911

Timestep Collection Time: 2.61982
Timestep Consumption Time: 2.54451
PPO Batch Consumption Time: 0.30020
Total Iteration Time: 5.16432

Cumulative Model Updates: 225,684
Cumulative Timesteps: 1,882,804,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1882804958...
Checkpoint 1882804958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,225.71517
Policy Entropy: 1.94966
Value Function Loss: 0.02399

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08095
Policy Update Magnitude: 0.30627
Value Function Update Magnitude: 0.34461

Collected Steps per Second: 20,334.82857
Overall Steps per Second: 9,936.98720

Timestep Collection Time: 2.45943
Timestep Consumption Time: 2.57349
PPO Batch Consumption Time: 0.30126
Total Iteration Time: 5.03291

Cumulative Model Updates: 225,690
Cumulative Timesteps: 1,882,854,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,162.72211
Policy Entropy: 1.94362
Value Function Loss: 0.02546

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08192
Policy Update Magnitude: 0.31645
Value Function Update Magnitude: 0.33267

Collected Steps per Second: 19,467.66400
Overall Steps per Second: 9,426.03209

Timestep Collection Time: 2.56846
Timestep Consumption Time: 2.73621
PPO Batch Consumption Time: 0.32277
Total Iteration Time: 5.30467

Cumulative Model Updates: 225,696
Cumulative Timesteps: 1,882,904,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1882904972...
Checkpoint 1882904972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,031.34471
Policy Entropy: 1.97148
Value Function Loss: 0.02430

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07806
Policy Update Magnitude: 0.31360
Value Function Update Magnitude: 0.31275

Collected Steps per Second: 20,328.66242
Overall Steps per Second: 9,750.77813

Timestep Collection Time: 2.46135
Timestep Consumption Time: 2.67014
PPO Batch Consumption Time: 0.31282
Total Iteration Time: 5.13149

Cumulative Model Updates: 225,702
Cumulative Timesteps: 1,882,955,008

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,256.05941
Policy Entropy: 1.95379
Value Function Loss: 0.02338

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07675
Policy Update Magnitude: 0.30387
Value Function Update Magnitude: 0.28653

Collected Steps per Second: 20,323.33329
Overall Steps per Second: 10,175.72828

Timestep Collection Time: 2.46190
Timestep Consumption Time: 2.45510
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.91699

Cumulative Model Updates: 225,708
Cumulative Timesteps: 1,883,005,042

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1883005042...
Checkpoint 1883005042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,042.47111
Policy Entropy: 1.95758
Value Function Loss: 0.02551

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.30869
Value Function Update Magnitude: 0.28580

Collected Steps per Second: 20,747.83545
Overall Steps per Second: 10,235.64451

Timestep Collection Time: 2.41085
Timestep Consumption Time: 2.47599
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.88684

Cumulative Model Updates: 225,714
Cumulative Timesteps: 1,883,055,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,353.76808
Policy Entropy: 1.96707
Value Function Loss: 0.02657

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.30860
Value Function Update Magnitude: 0.32401

Collected Steps per Second: 20,629.97397
Overall Steps per Second: 10,155.81839

Timestep Collection Time: 2.42443
Timestep Consumption Time: 2.50043
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.92486

Cumulative Model Updates: 225,720
Cumulative Timesteps: 1,883,105,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1883105078...
Checkpoint 1883105078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,433.13118
Policy Entropy: 1.97688
Value Function Loss: 0.02391

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08674
Policy Update Magnitude: 0.30304
Value Function Update Magnitude: 0.34928

Collected Steps per Second: 18,502.09090
Overall Steps per Second: 9,360.29066

Timestep Collection Time: 2.70434
Timestep Consumption Time: 2.64122
PPO Batch Consumption Time: 0.31641
Total Iteration Time: 5.34556

Cumulative Model Updates: 225,726
Cumulative Timesteps: 1,883,155,114

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,875.24065
Policy Entropy: 1.98045
Value Function Loss: 0.02091

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.29146
Value Function Update Magnitude: 0.32916

Collected Steps per Second: 19,296.84238
Overall Steps per Second: 9,673.25877

Timestep Collection Time: 2.59276
Timestep Consumption Time: 2.57944
PPO Batch Consumption Time: 0.30007
Total Iteration Time: 5.17220

Cumulative Model Updates: 225,732
Cumulative Timesteps: 1,883,205,146

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1883205146...
Checkpoint 1883205146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,336.18699
Policy Entropy: 1.98108
Value Function Loss: 0.02092

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07505
Policy Update Magnitude: 0.28690
Value Function Update Magnitude: 0.31013

Collected Steps per Second: 19,878.26609
Overall Steps per Second: 9,903.49616

Timestep Collection Time: 2.51591
Timestep Consumption Time: 2.53402
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 5.04993

Cumulative Model Updates: 225,738
Cumulative Timesteps: 1,883,255,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,748.67383
Policy Entropy: 1.97614
Value Function Loss: 0.02279

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07162
Policy Update Magnitude: 0.29788
Value Function Update Magnitude: 0.32229

Collected Steps per Second: 20,745.23080
Overall Steps per Second: 10,083.53030

Timestep Collection Time: 2.41125
Timestep Consumption Time: 2.54951
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.96076

Cumulative Model Updates: 225,744
Cumulative Timesteps: 1,883,305,180

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1883305180...
Checkpoint 1883305180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,311.36682
Policy Entropy: 1.95752
Value Function Loss: 0.02209

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07398
Policy Update Magnitude: 0.29823
Value Function Update Magnitude: 0.31220

Collected Steps per Second: 19,704.48317
Overall Steps per Second: 9,981.40897

Timestep Collection Time: 2.53871
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 5.01172

Cumulative Model Updates: 225,750
Cumulative Timesteps: 1,883,355,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,474.43685
Policy Entropy: 1.95706
Value Function Loss: 0.02353

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07261
Policy Update Magnitude: 0.30333
Value Function Update Magnitude: 0.32159

Collected Steps per Second: 19,869.80496
Overall Steps per Second: 9,953.33222

Timestep Collection Time: 2.51799
Timestep Consumption Time: 2.50867
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 5.02666

Cumulative Model Updates: 225,756
Cumulative Timesteps: 1,883,405,236

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1883405236...
Checkpoint 1883405236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,907.98643
Policy Entropy: 1.96839
Value Function Loss: 0.02396

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07212
Policy Update Magnitude: 0.30461
Value Function Update Magnitude: 0.31149

Collected Steps per Second: 20,613.23615
Overall Steps per Second: 10,266.55167

Timestep Collection Time: 2.42669
Timestep Consumption Time: 2.44563
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.87233

Cumulative Model Updates: 225,762
Cumulative Timesteps: 1,883,455,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,174.06502
Policy Entropy: 1.98641
Value Function Loss: 0.02257

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.06732
Policy Update Magnitude: 0.30047
Value Function Update Magnitude: 0.30236

Collected Steps per Second: 20,868.18003
Overall Steps per Second: 10,088.27859

Timestep Collection Time: 2.39705
Timestep Consumption Time: 2.56138
PPO Batch Consumption Time: 0.29927
Total Iteration Time: 4.95843

Cumulative Model Updates: 225,768
Cumulative Timesteps: 1,883,505,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1883505280...
Checkpoint 1883505280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,430.49977
Policy Entropy: 1.98275
Value Function Loss: 0.02456

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06843
Policy Update Magnitude: 0.30271
Value Function Update Magnitude: 0.32506

Collected Steps per Second: 19,155.03481
Overall Steps per Second: 9,698.59564

Timestep Collection Time: 2.61049
Timestep Consumption Time: 2.54531
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 5.15580

Cumulative Model Updates: 225,774
Cumulative Timesteps: 1,883,555,284

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,299.36239
Policy Entropy: 1.98046
Value Function Loss: 0.02310

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06959
Policy Update Magnitude: 0.30379
Value Function Update Magnitude: 0.33381

Collected Steps per Second: 19,019.57877
Overall Steps per Second: 9,539.82830

Timestep Collection Time: 2.63003
Timestep Consumption Time: 2.61346
PPO Batch Consumption Time: 0.30161
Total Iteration Time: 5.24349

Cumulative Model Updates: 225,780
Cumulative Timesteps: 1,883,605,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1883605306...
Checkpoint 1883605306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,008.42024
Policy Entropy: 1.97602
Value Function Loss: 0.02596

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06934
Policy Update Magnitude: 0.30405
Value Function Update Magnitude: 0.31985

Collected Steps per Second: 20,128.75609
Overall Steps per Second: 9,800.64502

Timestep Collection Time: 2.48411
Timestep Consumption Time: 2.61780
PPO Batch Consumption Time: 0.30665
Total Iteration Time: 5.10191

Cumulative Model Updates: 225,786
Cumulative Timesteps: 1,883,655,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,605.17048
Policy Entropy: 1.98271
Value Function Loss: 0.02829

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07124
Policy Update Magnitude: 0.31508
Value Function Update Magnitude: 0.32660

Collected Steps per Second: 20,905.08563
Overall Steps per Second: 10,420.66991

Timestep Collection Time: 2.39243
Timestep Consumption Time: 2.40707
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.79950

Cumulative Model Updates: 225,792
Cumulative Timesteps: 1,883,705,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1883705322...
Checkpoint 1883705322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,664.08360
Policy Entropy: 1.98390
Value Function Loss: 0.03017

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07704
Policy Update Magnitude: 0.32125
Value Function Update Magnitude: 0.33935

Collected Steps per Second: 19,905.89881
Overall Steps per Second: 10,060.23128

Timestep Collection Time: 2.51312
Timestep Consumption Time: 2.45952
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.97265

Cumulative Model Updates: 225,798
Cumulative Timesteps: 1,883,755,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,664.08360
Policy Entropy: 1.98403
Value Function Loss: 0.02523

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08122
Policy Update Magnitude: 0.31050
Value Function Update Magnitude: 0.31236

Collected Steps per Second: 20,090.74783
Overall Steps per Second: 10,058.80206

Timestep Collection Time: 2.48921
Timestep Consumption Time: 2.48256
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.97177

Cumulative Model Updates: 225,804
Cumulative Timesteps: 1,883,805,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1883805358...
Checkpoint 1883805358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,391.90982
Policy Entropy: 1.97973
Value Function Loss: 0.02331

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07609
Policy Update Magnitude: 0.29969
Value Function Update Magnitude: 0.25347

Collected Steps per Second: 20,084.00973
Overall Steps per Second: 10,112.73111

Timestep Collection Time: 2.49014
Timestep Consumption Time: 2.45531
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.94545

Cumulative Model Updates: 225,810
Cumulative Timesteps: 1,883,855,370

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,221.71923
Policy Entropy: 1.96665
Value Function Loss: 0.02171

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07150
Policy Update Magnitude: 0.29632
Value Function Update Magnitude: 0.24256

Collected Steps per Second: 20,635.16788
Overall Steps per Second: 10,084.93609

Timestep Collection Time: 2.42353
Timestep Consumption Time: 2.53535
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.95888

Cumulative Model Updates: 225,816
Cumulative Timesteps: 1,883,905,380

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1883905380...
Checkpoint 1883905380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,227.73390
Policy Entropy: 1.96232
Value Function Loss: 0.02160

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07083
Policy Update Magnitude: 0.29218
Value Function Update Magnitude: 0.22866

Collected Steps per Second: 20,291.85623
Overall Steps per Second: 10,129.53623

Timestep Collection Time: 2.46582
Timestep Consumption Time: 2.47380
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.93961

Cumulative Model Updates: 225,822
Cumulative Timesteps: 1,883,955,416

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,068.37885
Policy Entropy: 1.96290
Value Function Loss: 0.02188

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07283
Policy Update Magnitude: 0.29562
Value Function Update Magnitude: 0.25184

Collected Steps per Second: 20,581.04513
Overall Steps per Second: 10,161.37251

Timestep Collection Time: 2.43097
Timestep Consumption Time: 2.49277
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.92374

Cumulative Model Updates: 225,828
Cumulative Timesteps: 1,884,005,448

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1884005448...
Checkpoint 1884005448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,639.18093
Policy Entropy: 1.98111
Value Function Loss: 0.02310

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06834
Policy Update Magnitude: 0.29618
Value Function Update Magnitude: 0.29850

Collected Steps per Second: 20,781.29426
Overall Steps per Second: 10,227.94118

Timestep Collection Time: 2.40765
Timestep Consumption Time: 2.48425
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.89189

Cumulative Model Updates: 225,834
Cumulative Timesteps: 1,884,055,482

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,669.06794
Policy Entropy: 1.98726
Value Function Loss: 0.02399

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07326
Policy Update Magnitude: 0.30455
Value Function Update Magnitude: 0.29906

Collected Steps per Second: 20,549.18361
Overall Steps per Second: 10,064.22840

Timestep Collection Time: 2.43465
Timestep Consumption Time: 2.53643
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.97107

Cumulative Model Updates: 225,840
Cumulative Timesteps: 1,884,105,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1884105512...
Checkpoint 1884105512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,409.18531
Policy Entropy: 1.98478
Value Function Loss: 0.02394

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07460
Policy Update Magnitude: 0.30398
Value Function Update Magnitude: 0.28975

Collected Steps per Second: 20,367.88131
Overall Steps per Second: 10,195.30397

Timestep Collection Time: 2.45504
Timestep Consumption Time: 2.44957
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.90461

Cumulative Model Updates: 225,846
Cumulative Timesteps: 1,884,155,516

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,330.61798
Policy Entropy: 1.98739
Value Function Loss: 0.02519

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.31166
Value Function Update Magnitude: 0.31907

Collected Steps per Second: 20,985.56990
Overall Steps per Second: 10,350.87406

Timestep Collection Time: 2.38335
Timestep Consumption Time: 2.44870
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.83206

Cumulative Model Updates: 225,852
Cumulative Timesteps: 1,884,205,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1884205532...
Checkpoint 1884205532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,862.17799
Policy Entropy: 1.99241
Value Function Loss: 0.02340

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.31140
Value Function Update Magnitude: 0.31734

Collected Steps per Second: 20,064.51273
Overall Steps per Second: 10,020.95321

Timestep Collection Time: 2.49306
Timestep Consumption Time: 2.49868
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.99174

Cumulative Model Updates: 225,858
Cumulative Timesteps: 1,884,255,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,146.11684
Policy Entropy: 1.98682
Value Function Loss: 0.02391

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.29996
Value Function Update Magnitude: 0.25601

Collected Steps per Second: 21,261.15789
Overall Steps per Second: 10,354.69584

Timestep Collection Time: 2.35274
Timestep Consumption Time: 2.47811
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.83085

Cumulative Model Updates: 225,864
Cumulative Timesteps: 1,884,305,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1884305576...
Checkpoint 1884305576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,323.11707
Policy Entropy: 1.97276
Value Function Loss: 0.02120

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07256
Policy Update Magnitude: 0.28951
Value Function Update Magnitude: 0.24340

Collected Steps per Second: 20,912.43057
Overall Steps per Second: 10,198.60208

Timestep Collection Time: 2.39102
Timestep Consumption Time: 2.51181
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.90283

Cumulative Model Updates: 225,870
Cumulative Timesteps: 1,884,355,578

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,106.41121
Policy Entropy: 1.97178
Value Function Loss: 0.02360

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07485
Policy Update Magnitude: 0.29420
Value Function Update Magnitude: 0.23537

Collected Steps per Second: 21,236.58699
Overall Steps per Second: 10,402.43971

Timestep Collection Time: 2.35480
Timestep Consumption Time: 2.45253
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.80733

Cumulative Model Updates: 225,876
Cumulative Timesteps: 1,884,405,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1884405586...
Checkpoint 1884405586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,760.47303
Policy Entropy: 1.98215
Value Function Loss: 0.02352

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07107
Policy Update Magnitude: 0.29479
Value Function Update Magnitude: 0.24785

Collected Steps per Second: 21,377.02387
Overall Steps per Second: 10,310.79961

Timestep Collection Time: 2.34036
Timestep Consumption Time: 2.51183
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.85219

Cumulative Model Updates: 225,882
Cumulative Timesteps: 1,884,455,616

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,387.58711
Policy Entropy: 1.99339
Value Function Loss: 0.02464

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07641
Policy Update Magnitude: 0.29408
Value Function Update Magnitude: 0.26895

Collected Steps per Second: 19,829.32352
Overall Steps per Second: 9,860.40801

Timestep Collection Time: 2.52253
Timestep Consumption Time: 2.55029
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 5.07281

Cumulative Model Updates: 225,888
Cumulative Timesteps: 1,884,505,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1884505636...
Checkpoint 1884505636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,087.77946
Policy Entropy: 1.99290
Value Function Loss: 0.02412

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07059
Policy Update Magnitude: 0.29905
Value Function Update Magnitude: 0.30199

Collected Steps per Second: 20,078.39781
Overall Steps per Second: 10,089.48006

Timestep Collection Time: 2.49193
Timestep Consumption Time: 2.46709
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.95903

Cumulative Model Updates: 225,894
Cumulative Timesteps: 1,884,555,670

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,867.82377
Policy Entropy: 1.98653
Value Function Loss: 0.02324

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07427
Policy Update Magnitude: 0.30081
Value Function Update Magnitude: 0.32075

Collected Steps per Second: 19,382.06965
Overall Steps per Second: 10,002.82322

Timestep Collection Time: 2.58115
Timestep Consumption Time: 2.42024
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 5.00139

Cumulative Model Updates: 225,900
Cumulative Timesteps: 1,884,605,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1884605698...
Checkpoint 1884605698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,138.97065
Policy Entropy: 1.96225
Value Function Loss: 0.02350

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07738
Policy Update Magnitude: 0.30031
Value Function Update Magnitude: 0.29308

Collected Steps per Second: 20,497.29423
Overall Steps per Second: 9,958.62467

Timestep Collection Time: 2.43993
Timestep Consumption Time: 2.58205
PPO Batch Consumption Time: 0.30259
Total Iteration Time: 5.02198

Cumulative Model Updates: 225,906
Cumulative Timesteps: 1,884,655,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,268.34770
Policy Entropy: 1.95109
Value Function Loss: 0.02449

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.07630
Policy Update Magnitude: 0.30341
Value Function Update Magnitude: 0.30679

Collected Steps per Second: 19,922.02281
Overall Steps per Second: 10,121.90150

Timestep Collection Time: 2.50979
Timestep Consumption Time: 2.43000
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.93978

Cumulative Model Updates: 225,912
Cumulative Timesteps: 1,884,705,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1884705710...
Checkpoint 1884705710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,210.67118
Policy Entropy: 1.95413
Value Function Loss: 0.02470

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.06794
Policy Update Magnitude: 0.31255
Value Function Update Magnitude: 0.30806

Collected Steps per Second: 19,418.56517
Overall Steps per Second: 9,849.24852

Timestep Collection Time: 2.57547
Timestep Consumption Time: 2.50227
PPO Batch Consumption Time: 0.30236
Total Iteration Time: 5.07775

Cumulative Model Updates: 225,918
Cumulative Timesteps: 1,884,755,722

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,810.84895
Policy Entropy: 1.97595
Value Function Loss: 0.02456

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07855
Policy Update Magnitude: 0.31500
Value Function Update Magnitude: 0.29090

Collected Steps per Second: 19,238.08032
Overall Steps per Second: 10,011.58590

Timestep Collection Time: 2.59984
Timestep Consumption Time: 2.39597
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.99581

Cumulative Model Updates: 225,924
Cumulative Timesteps: 1,884,805,738

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1884805738...
Checkpoint 1884805738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,627.27259
Policy Entropy: 1.98025
Value Function Loss: 0.02260

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08528
Policy Update Magnitude: 0.30462
Value Function Update Magnitude: 0.27686

Collected Steps per Second: 20,464.43047
Overall Steps per Second: 10,087.13901

Timestep Collection Time: 2.44424
Timestep Consumption Time: 2.51455
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.95879

Cumulative Model Updates: 225,930
Cumulative Timesteps: 1,884,855,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,062.51621
Policy Entropy: 1.96985
Value Function Loss: 0.02132

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.08434
Policy Update Magnitude: 0.29584
Value Function Update Magnitude: 0.24773

Collected Steps per Second: 21,105.83001
Overall Steps per Second: 10,142.24476

Timestep Collection Time: 2.36920
Timestep Consumption Time: 2.56107
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.93027

Cumulative Model Updates: 225,936
Cumulative Timesteps: 1,884,905,762

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1884905762...
Checkpoint 1884905762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,018.18204
Policy Entropy: 1.97196
Value Function Loss: 0.02422

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.29025
Value Function Update Magnitude: 0.20011

Collected Steps per Second: 20,357.17628
Overall Steps per Second: 10,027.66598

Timestep Collection Time: 2.45761
Timestep Consumption Time: 2.53159
PPO Batch Consumption Time: 0.29524
Total Iteration Time: 4.98920

Cumulative Model Updates: 225,942
Cumulative Timesteps: 1,884,955,792

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,667.30614
Policy Entropy: 1.96739
Value Function Loss: 0.02936

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.30735
Value Function Update Magnitude: 0.21268

Collected Steps per Second: 21,446.82210
Overall Steps per Second: 10,290.91518

Timestep Collection Time: 2.33303
Timestep Consumption Time: 2.52913
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.86215

Cumulative Model Updates: 225,948
Cumulative Timesteps: 1,885,005,828

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1885005828...
Checkpoint 1885005828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,097.17282
Policy Entropy: 1.98210
Value Function Loss: 0.02946

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.31495
Value Function Update Magnitude: 0.28782

Collected Steps per Second: 20,562.61154
Overall Steps per Second: 10,096.57375

Timestep Collection Time: 2.43228
Timestep Consumption Time: 2.52128
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.95356

Cumulative Model Updates: 225,954
Cumulative Timesteps: 1,885,055,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,211.89243
Policy Entropy: 1.96614
Value Function Loss: 0.02489

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08376
Policy Update Magnitude: 0.31068
Value Function Update Magnitude: 0.30434

Collected Steps per Second: 20,800.08538
Overall Steps per Second: 10,103.84097

Timestep Collection Time: 2.40422
Timestep Consumption Time: 2.54518
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.94940

Cumulative Model Updates: 225,960
Cumulative Timesteps: 1,885,105,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1885105850...
Checkpoint 1885105850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,427.88917
Policy Entropy: 1.96724
Value Function Loss: 0.02320

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.30599
Value Function Update Magnitude: 0.33103

Collected Steps per Second: 19,865.90376
Overall Steps per Second: 9,976.63656

Timestep Collection Time: 2.51839
Timestep Consumption Time: 2.49633
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 5.01472

Cumulative Model Updates: 225,966
Cumulative Timesteps: 1,885,155,880

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,387.29358
Policy Entropy: 1.97478
Value Function Loss: 0.02674

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08411
Policy Update Magnitude: 0.30730
Value Function Update Magnitude: 0.34580

Collected Steps per Second: 21,566.96058
Overall Steps per Second: 10,298.55241

Timestep Collection Time: 2.31947
Timestep Consumption Time: 2.53791
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.85738

Cumulative Model Updates: 225,972
Cumulative Timesteps: 1,885,205,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1885205904...
Checkpoint 1885205904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,968.20919
Policy Entropy: 1.98018
Value Function Loss: 0.02606

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08032
Policy Update Magnitude: 0.30843
Value Function Update Magnitude: 0.36269

Collected Steps per Second: 21,290.04494
Overall Steps per Second: 10,127.27799

Timestep Collection Time: 2.34927
Timestep Consumption Time: 2.58947
PPO Batch Consumption Time: 0.29828
Total Iteration Time: 4.93874

Cumulative Model Updates: 225,978
Cumulative Timesteps: 1,885,255,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,045.32547
Policy Entropy: 1.98643
Value Function Loss: 0.02490

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.30603
Value Function Update Magnitude: 0.34369

Collected Steps per Second: 20,274.56652
Overall Steps per Second: 9,954.17497

Timestep Collection Time: 2.46664
Timestep Consumption Time: 2.55739
PPO Batch Consumption Time: 0.29967
Total Iteration Time: 5.02402

Cumulative Model Updates: 225,984
Cumulative Timesteps: 1,885,305,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1885305930...
Checkpoint 1885305930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,734.33646
Policy Entropy: 1.96491
Value Function Loss: 0.02512

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08316
Policy Update Magnitude: 0.30819
Value Function Update Magnitude: 0.31363

Collected Steps per Second: 20,510.64864
Overall Steps per Second: 10,107.37913

Timestep Collection Time: 2.43864
Timestep Consumption Time: 2.51003
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.94866

Cumulative Model Updates: 225,990
Cumulative Timesteps: 1,885,355,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,767.81287
Policy Entropy: 1.97739
Value Function Loss: 0.02643

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.31960
Value Function Update Magnitude: 0.31683

Collected Steps per Second: 20,360.43015
Overall Steps per Second: 10,133.89382

Timestep Collection Time: 2.45741
Timestep Consumption Time: 2.47988
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.93729

Cumulative Model Updates: 225,996
Cumulative Timesteps: 1,885,405,982

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1885405982...
Checkpoint 1885405982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,361.27457
Policy Entropy: 1.97150
Value Function Loss: 0.02748

Mean KL Divergence: 0.03298
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.31558
Value Function Update Magnitude: 0.32810

Collected Steps per Second: 20,123.68984
Overall Steps per Second: 9,944.11580

Timestep Collection Time: 2.48533
Timestep Consumption Time: 2.54418
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 5.02951

Cumulative Model Updates: 226,002
Cumulative Timesteps: 1,885,455,996

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,290.36845
Policy Entropy: 1.98880
Value Function Loss: 0.02520

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.31133
Value Function Update Magnitude: 0.31799

Collected Steps per Second: 21,511.25075
Overall Steps per Second: 10,446.04656

Timestep Collection Time: 2.32464
Timestep Consumption Time: 2.46243
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.78707

Cumulative Model Updates: 226,008
Cumulative Timesteps: 1,885,506,002

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1885506002...
Checkpoint 1885506002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,450.27832
Policy Entropy: 1.98224
Value Function Loss: 0.02687

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.31277
Value Function Update Magnitude: 0.30515

Collected Steps per Second: 21,522.31996
Overall Steps per Second: 10,221.80675

Timestep Collection Time: 2.32447
Timestep Consumption Time: 2.56977
PPO Batch Consumption Time: 0.29860
Total Iteration Time: 4.89424

Cumulative Model Updates: 226,014
Cumulative Timesteps: 1,885,556,030

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,716.00717
Policy Entropy: 1.97629
Value Function Loss: 0.02360

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.07862
Policy Update Magnitude: 0.30571
Value Function Update Magnitude: 0.30720

Collected Steps per Second: 21,302.77354
Overall Steps per Second: 10,430.96804

Timestep Collection Time: 2.34721
Timestep Consumption Time: 2.44640
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.79361

Cumulative Model Updates: 226,020
Cumulative Timesteps: 1,885,606,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1885606032...
Checkpoint 1885606032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,016.54011
Policy Entropy: 1.97480
Value Function Loss: 0.02215

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07180
Policy Update Magnitude: 0.29704
Value Function Update Magnitude: 0.31212

Collected Steps per Second: 21,450.57681
Overall Steps per Second: 10,155.06290

Timestep Collection Time: 2.33131
Timestep Consumption Time: 2.59313
PPO Batch Consumption Time: 0.30445
Total Iteration Time: 4.92444

Cumulative Model Updates: 226,026
Cumulative Timesteps: 1,885,656,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,695.32625
Policy Entropy: 1.97572
Value Function Loss: 0.02275

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06863
Policy Update Magnitude: 0.29448
Value Function Update Magnitude: 0.30141

Collected Steps per Second: 21,199.55767
Overall Steps per Second: 10,503.01485

Timestep Collection Time: 2.35995
Timestep Consumption Time: 2.40344
PPO Batch Consumption Time: 0.27645
Total Iteration Time: 4.76339

Cumulative Model Updates: 226,032
Cumulative Timesteps: 1,885,706,070

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1885706070...
Checkpoint 1885706070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,797.21670
Policy Entropy: 1.97740
Value Function Loss: 0.02219

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07642
Policy Update Magnitude: 0.29473
Value Function Update Magnitude: 0.30596

Collected Steps per Second: 21,264.91470
Overall Steps per Second: 10,439.99015

Timestep Collection Time: 2.35242
Timestep Consumption Time: 2.43916
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.79158

Cumulative Model Updates: 226,038
Cumulative Timesteps: 1,885,756,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,196.49790
Policy Entropy: 1.97440
Value Function Loss: 0.02273

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06685
Policy Update Magnitude: 0.29696
Value Function Update Magnitude: 0.30781

Collected Steps per Second: 21,650.38004
Overall Steps per Second: 10,383.56515

Timestep Collection Time: 2.31017
Timestep Consumption Time: 2.50668
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.81684

Cumulative Model Updates: 226,044
Cumulative Timesteps: 1,885,806,110

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1885806110...
Checkpoint 1885806110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,170.61496
Policy Entropy: 1.97729
Value Function Loss: 0.02359

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06648
Policy Update Magnitude: 0.30469
Value Function Update Magnitude: 0.31540

Collected Steps per Second: 20,736.42074
Overall Steps per Second: 10,450.57609

Timestep Collection Time: 2.41180
Timestep Consumption Time: 2.37378
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.78557

Cumulative Model Updates: 226,050
Cumulative Timesteps: 1,885,856,122

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,407.18884
Policy Entropy: 1.99377
Value Function Loss: 0.02553

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.06770
Policy Update Magnitude: 0.30362
Value Function Update Magnitude: 0.32751

Collected Steps per Second: 20,834.75913
Overall Steps per Second: 10,507.37107

Timestep Collection Time: 2.40070
Timestep Consumption Time: 2.35958
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.76028

Cumulative Model Updates: 226,056
Cumulative Timesteps: 1,885,906,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1885906140...
Checkpoint 1885906140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,185.52451
Policy Entropy: 1.99813
Value Function Loss: 0.02597

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06760
Policy Update Magnitude: 0.30446
Value Function Update Magnitude: 0.31029

Collected Steps per Second: 20,171.81848
Overall Steps per Second: 10,179.82161

Timestep Collection Time: 2.48029
Timestep Consumption Time: 2.43453
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.91482

Cumulative Model Updates: 226,062
Cumulative Timesteps: 1,885,956,172

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,706.21422
Policy Entropy: 1.98629
Value Function Loss: 0.02517

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07240
Policy Update Magnitude: 0.30629
Value Function Update Magnitude: 0.32712

Collected Steps per Second: 20,780.09450
Overall Steps per Second: 10,502.93501

Timestep Collection Time: 2.40798
Timestep Consumption Time: 2.35621
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.76419

Cumulative Model Updates: 226,068
Cumulative Timesteps: 1,886,006,210

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1886006210...
Checkpoint 1886006210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,901.53847
Policy Entropy: 1.98242
Value Function Loss: 0.02758

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07870
Policy Update Magnitude: 0.30662
Value Function Update Magnitude: 0.35746

Collected Steps per Second: 20,745.72347
Overall Steps per Second: 10,183.22246

Timestep Collection Time: 2.41052
Timestep Consumption Time: 2.50030
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.91082

Cumulative Model Updates: 226,074
Cumulative Timesteps: 1,886,056,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,973.36443
Policy Entropy: 1.99766
Value Function Loss: 0.02714

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07494
Policy Update Magnitude: 0.30876
Value Function Update Magnitude: 0.36855

Collected Steps per Second: 21,522.53162
Overall Steps per Second: 10,415.91636

Timestep Collection Time: 2.32538
Timestep Consumption Time: 2.47958
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.80495

Cumulative Model Updates: 226,080
Cumulative Timesteps: 1,886,106,266

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1886106266...
Checkpoint 1886106266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,502.47192
Policy Entropy: 2.00589
Value Function Loss: 0.02756

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.30506
Value Function Update Magnitude: 0.35341

Collected Steps per Second: 21,064.68818
Overall Steps per Second: 10,238.42932

Timestep Collection Time: 2.37459
Timestep Consumption Time: 2.51092
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.88551

Cumulative Model Updates: 226,086
Cumulative Timesteps: 1,886,156,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,528.15658
Policy Entropy: 1.99843
Value Function Loss: 0.02250

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07602
Policy Update Magnitude: 0.30134
Value Function Update Magnitude: 0.32724

Collected Steps per Second: 21,399.17505
Overall Steps per Second: 10,417.74417

Timestep Collection Time: 2.33719
Timestep Consumption Time: 2.46365
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.80085

Cumulative Model Updates: 226,092
Cumulative Timesteps: 1,886,206,300

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1886206300...
Checkpoint 1886206300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,060.47307
Policy Entropy: 1.99542
Value Function Loss: 0.02043

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.29391
Value Function Update Magnitude: 0.30826

Collected Steps per Second: 21,036.98664
Overall Steps per Second: 10,283.01978

Timestep Collection Time: 2.37857
Timestep Consumption Time: 2.48751
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.86608

Cumulative Model Updates: 226,098
Cumulative Timesteps: 1,886,256,338

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,924.32490
Policy Entropy: 1.98299
Value Function Loss: 0.01907

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08086
Policy Update Magnitude: 0.28329
Value Function Update Magnitude: 0.29158

Collected Steps per Second: 21,562.26937
Overall Steps per Second: 10,473.14366

Timestep Collection Time: 2.31924
Timestep Consumption Time: 2.45564
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.77488

Cumulative Model Updates: 226,104
Cumulative Timesteps: 1,886,306,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1886306346...
Checkpoint 1886306346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,935.06956
Policy Entropy: 1.99231
Value Function Loss: 0.02008

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.28250
Value Function Update Magnitude: 0.28723

Collected Steps per Second: 21,455.54072
Overall Steps per Second: 10,339.50181

Timestep Collection Time: 2.33059
Timestep Consumption Time: 2.50562
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.83621

Cumulative Model Updates: 226,110
Cumulative Timesteps: 1,886,356,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,305.22745
Policy Entropy: 1.97880
Value Function Loss: 0.02087

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08524
Policy Update Magnitude: 0.28609
Value Function Update Magnitude: 0.29786

Collected Steps per Second: 21,682.79508
Overall Steps per Second: 10,358.52913

Timestep Collection Time: 2.30653
Timestep Consumption Time: 2.52157
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.82810

Cumulative Model Updates: 226,116
Cumulative Timesteps: 1,886,406,362

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1886406362...
Checkpoint 1886406362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,809.44082
Policy Entropy: 1.98231
Value Function Loss: 0.02241

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08283
Policy Update Magnitude: 0.29243
Value Function Update Magnitude: 0.31596

Collected Steps per Second: 21,117.79374
Overall Steps per Second: 10,241.55547

Timestep Collection Time: 2.36938
Timestep Consumption Time: 2.51621
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.88559

Cumulative Model Updates: 226,122
Cumulative Timesteps: 1,886,456,398

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,609.83906
Policy Entropy: 1.98186
Value Function Loss: 0.02074

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.09258
Policy Update Magnitude: 0.28908
Value Function Update Magnitude: 0.31041

Collected Steps per Second: 19,217.37108
Overall Steps per Second: 9,853.42290

Timestep Collection Time: 2.60254
Timestep Consumption Time: 2.47326
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 5.07580

Cumulative Model Updates: 226,128
Cumulative Timesteps: 1,886,506,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1886506412...
Checkpoint 1886506412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,574.88307
Policy Entropy: 1.99252
Value Function Loss: 0.02104

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.28729
Value Function Update Magnitude: 0.28619

Collected Steps per Second: 18,823.99042
Overall Steps per Second: 9,496.47105

Timestep Collection Time: 2.65810
Timestep Consumption Time: 2.61081
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 5.26890

Cumulative Model Updates: 226,134
Cumulative Timesteps: 1,886,556,448

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,383.60268
Policy Entropy: 1.98062
Value Function Loss: 0.02130

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.29076
Value Function Update Magnitude: 0.27297

Collected Steps per Second: 20,804.72905
Overall Steps per Second: 9,922.70720

Timestep Collection Time: 2.40407
Timestep Consumption Time: 2.63649
PPO Batch Consumption Time: 0.30518
Total Iteration Time: 5.04056

Cumulative Model Updates: 226,140
Cumulative Timesteps: 1,886,606,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1886606464...
Checkpoint 1886606464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,246.09072
Policy Entropy: 1.98185
Value Function Loss: 0.02346

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.29458
Value Function Update Magnitude: 0.27172

Collected Steps per Second: 20,156.31923
Overall Steps per Second: 9,929.27786

Timestep Collection Time: 2.48250
Timestep Consumption Time: 2.55694
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 5.03944

Cumulative Model Updates: 226,146
Cumulative Timesteps: 1,886,656,502

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,147.67078
Policy Entropy: 1.97662
Value Function Loss: 0.02305

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07832
Policy Update Magnitude: 0.29543
Value Function Update Magnitude: 0.24501

Collected Steps per Second: 19,613.72223
Overall Steps per Second: 9,636.99682

Timestep Collection Time: 2.54975
Timestep Consumption Time: 2.63963
PPO Batch Consumption Time: 0.30541
Total Iteration Time: 5.18938

Cumulative Model Updates: 226,152
Cumulative Timesteps: 1,886,706,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1886706512...
Checkpoint 1886706512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,794.85593
Policy Entropy: 1.99135
Value Function Loss: 0.02444

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07190
Policy Update Magnitude: 0.29607
Value Function Update Magnitude: 0.24261

Collected Steps per Second: 20,500.46393
Overall Steps per Second: 9,616.86028

Timestep Collection Time: 2.44014
Timestep Consumption Time: 2.76156
PPO Batch Consumption Time: 0.32989
Total Iteration Time: 5.20170

Cumulative Model Updates: 226,158
Cumulative Timesteps: 1,886,756,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,229.57092
Policy Entropy: 1.99519
Value Function Loss: 0.02528

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07675
Policy Update Magnitude: 0.29819
Value Function Update Magnitude: 0.27536

Collected Steps per Second: 17,446.08475
Overall Steps per Second: 9,028.48449

Timestep Collection Time: 2.86700
Timestep Consumption Time: 2.67302
PPO Batch Consumption Time: 0.31676
Total Iteration Time: 5.54002

Cumulative Model Updates: 226,164
Cumulative Timesteps: 1,886,806,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1886806554...
Checkpoint 1886806554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,402.50827
Policy Entropy: 1.98729
Value Function Loss: 0.02777

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.08524
Policy Update Magnitude: 0.30813
Value Function Update Magnitude: 0.32077

Collected Steps per Second: 19,488.30158
Overall Steps per Second: 9,823.08743

Timestep Collection Time: 2.56708
Timestep Consumption Time: 2.52582
PPO Batch Consumption Time: 0.30260
Total Iteration Time: 5.09290

Cumulative Model Updates: 226,170
Cumulative Timesteps: 1,886,856,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,915.29702
Policy Entropy: 1.98778
Value Function Loss: 0.02421

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.30907
Value Function Update Magnitude: 0.33929

Collected Steps per Second: 20,387.46125
Overall Steps per Second: 10,095.77498

Timestep Collection Time: 2.45249
Timestep Consumption Time: 2.50008
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.95257

Cumulative Model Updates: 226,176
Cumulative Timesteps: 1,886,906,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1886906582...
Checkpoint 1886906582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,937.78960
Policy Entropy: 1.99053
Value Function Loss: 0.02509

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.09701
Policy Update Magnitude: 0.30912
Value Function Update Magnitude: 0.36073

Collected Steps per Second: 20,585.99834
Overall Steps per Second: 10,169.22961

Timestep Collection Time: 2.42952
Timestep Consumption Time: 2.48865
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.91817

Cumulative Model Updates: 226,182
Cumulative Timesteps: 1,886,956,596

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,324.27192
Policy Entropy: 1.98437
Value Function Loss: 0.02428

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.09250
Policy Update Magnitude: 0.31084
Value Function Update Magnitude: 0.35210

Collected Steps per Second: 20,793.40858
Overall Steps per Second: 10,120.10727

Timestep Collection Time: 2.40499
Timestep Consumption Time: 2.53646
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.94145

Cumulative Model Updates: 226,188
Cumulative Timesteps: 1,887,006,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1887006604...
Checkpoint 1887006604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,535.89667
Policy Entropy: 1.96472
Value Function Loss: 0.02472

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.31045
Value Function Update Magnitude: 0.34807

Collected Steps per Second: 20,350.44205
Overall Steps per Second: 10,129.08827

Timestep Collection Time: 2.45823
Timestep Consumption Time: 2.48062
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.93885

Cumulative Model Updates: 226,194
Cumulative Timesteps: 1,887,056,630

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,024.40148
Policy Entropy: 1.95049
Value Function Loss: 0.02439

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.30888
Value Function Update Magnitude: 0.34132

Collected Steps per Second: 19,843.82414
Overall Steps per Second: 10,095.51756

Timestep Collection Time: 2.51988
Timestep Consumption Time: 2.43321
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.95309

Cumulative Model Updates: 226,200
Cumulative Timesteps: 1,887,106,634

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1887106634...
Checkpoint 1887106634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,964.11293
Policy Entropy: 1.96085
Value Function Loss: 0.02642

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.31283
Value Function Update Magnitude: 0.31782

Collected Steps per Second: 19,408.09990
Overall Steps per Second: 9,865.97647

Timestep Collection Time: 2.57758
Timestep Consumption Time: 2.49297
PPO Batch Consumption Time: 0.29846
Total Iteration Time: 5.07056

Cumulative Model Updates: 226,206
Cumulative Timesteps: 1,887,156,660

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,075.40592
Policy Entropy: 1.98012
Value Function Loss: 0.02974

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.31542
Value Function Update Magnitude: 0.28550

Collected Steps per Second: 20,142.57284
Overall Steps per Second: 10,100.41175

Timestep Collection Time: 2.48280
Timestep Consumption Time: 2.46848
PPO Batch Consumption Time: 0.29646
Total Iteration Time: 4.95128

Cumulative Model Updates: 226,212
Cumulative Timesteps: 1,887,206,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1887206670...
Checkpoint 1887206670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,485.20765
Policy Entropy: 1.98678
Value Function Loss: 0.02968

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.30983
Value Function Update Magnitude: 0.23481

Collected Steps per Second: 19,373.46274
Overall Steps per Second: 10,033.12694

Timestep Collection Time: 2.58106
Timestep Consumption Time: 2.40283
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.98389

Cumulative Model Updates: 226,218
Cumulative Timesteps: 1,887,256,674

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,423.26539
Policy Entropy: 1.99376
Value Function Loss: 0.02948

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.30721
Value Function Update Magnitude: 0.21071

Collected Steps per Second: 20,123.55242
Overall Steps per Second: 10,086.41706

Timestep Collection Time: 2.48515
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.95815

Cumulative Model Updates: 226,224
Cumulative Timesteps: 1,887,306,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1887306684...
Checkpoint 1887306684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,799.34078
Policy Entropy: 1.98975
Value Function Loss: 0.02394

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07780
Policy Update Magnitude: 0.30282
Value Function Update Magnitude: 0.27135

Collected Steps per Second: 20,484.58781
Overall Steps per Second: 10,178.38677

Timestep Collection Time: 2.44125
Timestep Consumption Time: 2.47191
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.91316

Cumulative Model Updates: 226,230
Cumulative Timesteps: 1,887,356,692

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,324.78487
Policy Entropy: 1.98907
Value Function Loss: 0.02380

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07302
Policy Update Magnitude: 0.30077
Value Function Update Magnitude: 0.30880

Collected Steps per Second: 20,600.47048
Overall Steps per Second: 10,080.03794

Timestep Collection Time: 2.42800
Timestep Consumption Time: 2.53408
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.96208

Cumulative Model Updates: 226,236
Cumulative Timesteps: 1,887,406,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1887406710...
Checkpoint 1887406710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,529.52850
Policy Entropy: 1.98659
Value Function Loss: 0.02249

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07387
Policy Update Magnitude: 0.30069
Value Function Update Magnitude: 0.30815

Collected Steps per Second: 20,305.23508
Overall Steps per Second: 9,960.80075

Timestep Collection Time: 2.46439
Timestep Consumption Time: 2.55930
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 5.02369

Cumulative Model Updates: 226,242
Cumulative Timesteps: 1,887,456,750

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,879.35542
Policy Entropy: 1.99254
Value Function Loss: 0.02421

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07441
Policy Update Magnitude: 0.30123
Value Function Update Magnitude: 0.32506

Collected Steps per Second: 20,934.46486
Overall Steps per Second: 10,242.12158

Timestep Collection Time: 2.38965
Timestep Consumption Time: 2.49469
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.88434

Cumulative Model Updates: 226,248
Cumulative Timesteps: 1,887,506,776

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1887506776...
Checkpoint 1887506776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,455.35767
Policy Entropy: 1.99492
Value Function Loss: 0.02337

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07386
Policy Update Magnitude: 0.30079
Value Function Update Magnitude: 0.28015

Collected Steps per Second: 20,603.43602
Overall Steps per Second: 10,174.95713

Timestep Collection Time: 2.42707
Timestep Consumption Time: 2.48754
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.91462

Cumulative Model Updates: 226,254
Cumulative Timesteps: 1,887,556,782

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,513.57473
Policy Entropy: 1.98984
Value Function Loss: 0.02297

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07127
Policy Update Magnitude: 0.29449
Value Function Update Magnitude: 0.21995

Collected Steps per Second: 20,771.19316
Overall Steps per Second: 10,117.44818

Timestep Collection Time: 2.40766
Timestep Consumption Time: 2.53528
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.94295

Cumulative Model Updates: 226,260
Cumulative Timesteps: 1,887,606,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1887606792...
Checkpoint 1887606792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,011.10649
Policy Entropy: 1.98853
Value Function Loss: 0.02207

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06308
Policy Update Magnitude: 0.29161
Value Function Update Magnitude: 0.23558

Collected Steps per Second: 20,406.07835
Overall Steps per Second: 10,122.88612

Timestep Collection Time: 2.45103
Timestep Consumption Time: 2.48985
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.94088

Cumulative Model Updates: 226,266
Cumulative Timesteps: 1,887,656,808

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,238.70189
Policy Entropy: 1.99522
Value Function Loss: 0.02455

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06709
Policy Update Magnitude: 0.30197
Value Function Update Magnitude: 0.26935

Collected Steps per Second: 20,818.65593
Overall Steps per Second: 10,106.90444

Timestep Collection Time: 2.40208
Timestep Consumption Time: 2.54583
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.94790

Cumulative Model Updates: 226,272
Cumulative Timesteps: 1,887,706,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1887706816...
Checkpoint 1887706816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,707.40718
Policy Entropy: 2.00131
Value Function Loss: 0.02532

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07630
Policy Update Magnitude: 0.30736
Value Function Update Magnitude: 0.30730

Collected Steps per Second: 19,496.37774
Overall Steps per Second: 9,796.54516

Timestep Collection Time: 2.56612
Timestep Consumption Time: 2.54078
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 5.10690

Cumulative Model Updates: 226,278
Cumulative Timesteps: 1,887,756,846

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,319.17614
Policy Entropy: 2.00343
Value Function Loss: 0.02561

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07673
Policy Update Magnitude: 0.30068
Value Function Update Magnitude: 0.31446

Collected Steps per Second: 20,571.55863
Overall Steps per Second: 10,089.62644

Timestep Collection Time: 2.43239
Timestep Consumption Time: 2.52696
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.95935

Cumulative Model Updates: 226,284
Cumulative Timesteps: 1,887,806,884

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1887806884...
Checkpoint 1887806884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,513.04192
Policy Entropy: 1.99219
Value Function Loss: 0.02362

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.29662
Value Function Update Magnitude: 0.30756

Collected Steps per Second: 19,806.15267
Overall Steps per Second: 10,145.97744

Timestep Collection Time: 2.52528
Timestep Consumption Time: 2.40436
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.92964

Cumulative Model Updates: 226,290
Cumulative Timesteps: 1,887,856,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,604.56968
Policy Entropy: 1.98363
Value Function Loss: 0.02523

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.29645
Value Function Update Magnitude: 0.32132

Collected Steps per Second: 20,384.11453
Overall Steps per Second: 10,145.18394

Timestep Collection Time: 2.45505
Timestep Consumption Time: 2.47773
PPO Batch Consumption Time: 0.29810
Total Iteration Time: 4.93278

Cumulative Model Updates: 226,296
Cumulative Timesteps: 1,887,906,944

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1887906944...
Checkpoint 1887906944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,869.42606
Policy Entropy: 1.99025
Value Function Loss: 0.02606

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08376
Policy Update Magnitude: 0.30476
Value Function Update Magnitude: 0.32441

Collected Steps per Second: 19,945.77917
Overall Steps per Second: 10,191.56440

Timestep Collection Time: 2.50690
Timestep Consumption Time: 2.39932
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.90621

Cumulative Model Updates: 226,302
Cumulative Timesteps: 1,887,956,946

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,925.23069
Policy Entropy: 1.98389
Value Function Loss: 0.02717

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07910
Policy Update Magnitude: 0.30954
Value Function Update Magnitude: 0.32650

Collected Steps per Second: 20,380.32486
Overall Steps per Second: 10,183.95168

Timestep Collection Time: 2.45344
Timestep Consumption Time: 2.45644
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.90988

Cumulative Model Updates: 226,308
Cumulative Timesteps: 1,888,006,948

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1888006948...
Checkpoint 1888006948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,985.71935
Policy Entropy: 1.99927
Value Function Loss: 0.02613

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07193
Policy Update Magnitude: 0.31012
Value Function Update Magnitude: 0.31387

Collected Steps per Second: 19,647.86741
Overall Steps per Second: 9,982.66746

Timestep Collection Time: 2.54542
Timestep Consumption Time: 2.46447
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 5.00988

Cumulative Model Updates: 226,314
Cumulative Timesteps: 1,888,056,960

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,242.09356
Policy Entropy: 1.99476
Value Function Loss: 0.02705

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.06926
Policy Update Magnitude: 0.31402
Value Function Update Magnitude: 0.31959

Collected Steps per Second: 21,004.87578
Overall Steps per Second: 10,163.31388

Timestep Collection Time: 2.38040
Timestep Consumption Time: 2.53926
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 4.91966

Cumulative Model Updates: 226,320
Cumulative Timesteps: 1,888,106,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1888106960...
Checkpoint 1888106960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,421.23094
Policy Entropy: 2.01547
Value Function Loss: 0.02657

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07274
Policy Update Magnitude: 0.31388
Value Function Update Magnitude: 0.35287

Collected Steps per Second: 20,549.54254
Overall Steps per Second: 10,127.15232

Timestep Collection Time: 2.43470
Timestep Consumption Time: 2.50568
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.94038

Cumulative Model Updates: 226,326
Cumulative Timesteps: 1,888,156,992

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,572.97885
Policy Entropy: 2.00463
Value Function Loss: 0.02953

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07141
Policy Update Magnitude: 0.31882
Value Function Update Magnitude: 0.35792

Collected Steps per Second: 21,055.61682
Overall Steps per Second: 10,161.73544

Timestep Collection Time: 2.37590
Timestep Consumption Time: 2.54708
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.92298

Cumulative Model Updates: 226,332
Cumulative Timesteps: 1,888,207,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1888207018...
Checkpoint 1888207018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,956.21649
Policy Entropy: 2.00128
Value Function Loss: 0.02789

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07518
Policy Update Magnitude: 0.32308
Value Function Update Magnitude: 0.36108

Collected Steps per Second: 19,394.03077
Overall Steps per Second: 9,740.19493

Timestep Collection Time: 2.57873
Timestep Consumption Time: 2.55587
PPO Batch Consumption Time: 0.29823
Total Iteration Time: 5.13460

Cumulative Model Updates: 226,338
Cumulative Timesteps: 1,888,257,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,648.42670
Policy Entropy: 1.99996
Value Function Loss: 0.02737

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.31684
Value Function Update Magnitude: 0.37441

Collected Steps per Second: 21,142.44890
Overall Steps per Second: 10,312.80760

Timestep Collection Time: 2.36567
Timestep Consumption Time: 2.48422
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.84989

Cumulative Model Updates: 226,344
Cumulative Timesteps: 1,888,307,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1888307046...
Checkpoint 1888307046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,035.57016
Policy Entropy: 2.00175
Value Function Loss: 0.02578

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07561
Policy Update Magnitude: 0.31391
Value Function Update Magnitude: 0.38560

Collected Steps per Second: 20,216.05275
Overall Steps per Second: 9,832.98702

Timestep Collection Time: 2.47477
Timestep Consumption Time: 2.61321
PPO Batch Consumption Time: 0.30739
Total Iteration Time: 5.08798

Cumulative Model Updates: 226,350
Cumulative Timesteps: 1,888,357,076

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,480.99633
Policy Entropy: 2.00280
Value Function Loss: 0.02608

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07686
Policy Update Magnitude: 0.31185
Value Function Update Magnitude: 0.35839

Collected Steps per Second: 21,029.91061
Overall Steps per Second: 10,120.52256

Timestep Collection Time: 2.37833
Timestep Consumption Time: 2.56371
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.94204

Cumulative Model Updates: 226,356
Cumulative Timesteps: 1,888,407,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1888407092...
Checkpoint 1888407092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,850.25288
Policy Entropy: 2.00609
Value Function Loss: 0.02804

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.30969
Value Function Update Magnitude: 0.34953

Collected Steps per Second: 19,925.73151
Overall Steps per Second: 9,965.86474

Timestep Collection Time: 2.50992
Timestep Consumption Time: 2.50841
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 5.01833

Cumulative Model Updates: 226,362
Cumulative Timesteps: 1,888,457,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,029.46732
Policy Entropy: 2.01434
Value Function Loss: 0.02531

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.09104
Policy Update Magnitude: 0.30726
Value Function Update Magnitude: 0.36186

Collected Steps per Second: 21,008.99451
Overall Steps per Second: 10,101.59571

Timestep Collection Time: 2.38108
Timestep Consumption Time: 2.57101
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.95209

Cumulative Model Updates: 226,368
Cumulative Timesteps: 1,888,507,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1888507128...
Checkpoint 1888507128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,488.90629
Policy Entropy: 2.02223
Value Function Loss: 0.02505

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.30578
Value Function Update Magnitude: 0.33905

Collected Steps per Second: 19,682.23361
Overall Steps per Second: 9,827.03854

Timestep Collection Time: 2.54118
Timestep Consumption Time: 2.54846
PPO Batch Consumption Time: 0.30903
Total Iteration Time: 5.08963

Cumulative Model Updates: 226,374
Cumulative Timesteps: 1,888,557,144

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,843.85713
Policy Entropy: 2.00141
Value Function Loss: 0.02209

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.29747
Value Function Update Magnitude: 0.32753

Collected Steps per Second: 18,658.52688
Overall Steps per Second: 9,630.55493

Timestep Collection Time: 2.68135
Timestep Consumption Time: 2.51358
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 5.19492

Cumulative Model Updates: 226,380
Cumulative Timesteps: 1,888,607,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1888607174...
Checkpoint 1888607174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,778.86713
Policy Entropy: 1.99631
Value Function Loss: 0.02441

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.30140
Value Function Update Magnitude: 0.28869

Collected Steps per Second: 20,289.80878
Overall Steps per Second: 10,028.21975

Timestep Collection Time: 2.46685
Timestep Consumption Time: 2.52426
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.99112

Cumulative Model Updates: 226,386
Cumulative Timesteps: 1,888,657,226

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,607.12849
Policy Entropy: 1.98101
Value Function Loss: 0.02343

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08216
Policy Update Magnitude: 0.30352
Value Function Update Magnitude: 0.26245

Collected Steps per Second: 21,565.36150
Overall Steps per Second: 10,494.96531

Timestep Collection Time: 2.31900
Timestep Consumption Time: 2.44615
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.76514

Cumulative Model Updates: 226,392
Cumulative Timesteps: 1,888,707,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1888707236...
Checkpoint 1888707236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,804.02859
Policy Entropy: 1.98819
Value Function Loss: 0.02815

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08782
Policy Update Magnitude: 0.30995
Value Function Update Magnitude: 0.33599

Collected Steps per Second: 21,259.70174
Overall Steps per Second: 10,183.70402

Timestep Collection Time: 2.35196
Timestep Consumption Time: 2.55804
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.91000

Cumulative Model Updates: 226,398
Cumulative Timesteps: 1,888,757,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,915.27605
Policy Entropy: 1.98333
Value Function Loss: 0.02956

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.08536
Policy Update Magnitude: 0.32371
Value Function Update Magnitude: 0.38849

Collected Steps per Second: 21,584.34907
Overall Steps per Second: 10,499.36095

Timestep Collection Time: 2.31649
Timestep Consumption Time: 2.44570
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.76219

Cumulative Model Updates: 226,404
Cumulative Timesteps: 1,888,807,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1888807238...
Checkpoint 1888807238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,355.29727
Policy Entropy: 1.98358
Value Function Loss: 0.02829

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.32295
Value Function Update Magnitude: 0.39703

Collected Steps per Second: 20,317.14931
Overall Steps per Second: 10,102.69069

Timestep Collection Time: 2.46206
Timestep Consumption Time: 2.48930
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.95135

Cumulative Model Updates: 226,410
Cumulative Timesteps: 1,888,857,260

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,378.45659
Policy Entropy: 1.98428
Value Function Loss: 0.02531

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07558
Policy Update Magnitude: 0.31035
Value Function Update Magnitude: 0.36031

Collected Steps per Second: 20,417.80604
Overall Steps per Second: 9,956.29979

Timestep Collection Time: 2.44933
Timestep Consumption Time: 2.57362
PPO Batch Consumption Time: 0.29810
Total Iteration Time: 5.02295

Cumulative Model Updates: 226,416
Cumulative Timesteps: 1,888,907,270

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1888907270...
Checkpoint 1888907270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,039.53470
Policy Entropy: 1.98561
Value Function Loss: 0.02647

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07275
Policy Update Magnitude: 0.31201
Value Function Update Magnitude: 0.33602

Collected Steps per Second: 21,177.42557
Overall Steps per Second: 10,257.24884

Timestep Collection Time: 2.36185
Timestep Consumption Time: 2.51450
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.87636

Cumulative Model Updates: 226,422
Cumulative Timesteps: 1,888,957,288

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,547.02469
Policy Entropy: 1.98525
Value Function Loss: 0.02574

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.31662
Value Function Update Magnitude: 0.35442

Collected Steps per Second: 20,255.45878
Overall Steps per Second: 10,121.17739

Timestep Collection Time: 2.47005
Timestep Consumption Time: 2.47325
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.94330

Cumulative Model Updates: 226,428
Cumulative Timesteps: 1,889,007,320

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1889007320...
Checkpoint 1889007320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,831.23374
Policy Entropy: 1.97741
Value Function Loss: 0.02388

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.30721
Value Function Update Magnitude: 0.34018

Collected Steps per Second: 20,799.21705
Overall Steps per Second: 10,147.31279

Timestep Collection Time: 2.40403
Timestep Consumption Time: 2.52358
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.92761

Cumulative Model Updates: 226,434
Cumulative Timesteps: 1,889,057,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,954.46394
Policy Entropy: 1.98409
Value Function Loss: 0.02428

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.30066
Value Function Update Magnitude: 0.32820

Collected Steps per Second: 20,531.81977
Overall Steps per Second: 10,090.21803

Timestep Collection Time: 2.43680
Timestep Consumption Time: 2.52166
PPO Batch Consumption Time: 0.30443
Total Iteration Time: 4.95847

Cumulative Model Updates: 226,440
Cumulative Timesteps: 1,889,107,354

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1889107354...
Checkpoint 1889107354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,645.33677
Policy Entropy: 1.98700
Value Function Loss: 0.02467

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.30274
Value Function Update Magnitude: 0.32652

Collected Steps per Second: 19,310.32587
Overall Steps per Second: 9,972.43872

Timestep Collection Time: 2.59022
Timestep Consumption Time: 2.42540
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 5.01562

Cumulative Model Updates: 226,446
Cumulative Timesteps: 1,889,157,372

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,678.13355
Policy Entropy: 1.98537
Value Function Loss: 0.02497

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.31131
Value Function Update Magnitude: 0.33894

Collected Steps per Second: 20,219.78548
Overall Steps per Second: 9,950.06588

Timestep Collection Time: 2.47401
Timestep Consumption Time: 2.55349
PPO Batch Consumption Time: 0.30387
Total Iteration Time: 5.02750

Cumulative Model Updates: 226,452
Cumulative Timesteps: 1,889,207,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1889207396...
Checkpoint 1889207396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,465.33932
Policy Entropy: 1.99844
Value Function Loss: 0.02450

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.30796
Value Function Update Magnitude: 0.32564

Collected Steps per Second: 20,084.84085
Overall Steps per Second: 9,929.67470

Timestep Collection Time: 2.49073
Timestep Consumption Time: 2.54730
PPO Batch Consumption Time: 0.31154
Total Iteration Time: 5.03803

Cumulative Model Updates: 226,458
Cumulative Timesteps: 1,889,257,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,323.38490
Policy Entropy: 2.00722
Value Function Loss: 0.02421

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.07924
Policy Update Magnitude: 0.30764
Value Function Update Magnitude: 0.32351

Collected Steps per Second: 20,694.57882
Overall Steps per Second: 10,330.45070

Timestep Collection Time: 2.41677
Timestep Consumption Time: 2.42465
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.84142

Cumulative Model Updates: 226,464
Cumulative Timesteps: 1,889,307,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1889307436...
Checkpoint 1889307436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,309.19792
Policy Entropy: 1.99979
Value Function Loss: 0.02847

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07275
Policy Update Magnitude: 0.31617
Value Function Update Magnitude: 0.33755

Collected Steps per Second: 20,075.95729
Overall Steps per Second: 10,176.48808

Timestep Collection Time: 2.49164
Timestep Consumption Time: 2.42381
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.91545

Cumulative Model Updates: 226,470
Cumulative Timesteps: 1,889,357,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,617.25974
Policy Entropy: 1.97845
Value Function Loss: 0.02783

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07322
Policy Update Magnitude: 0.32133
Value Function Update Magnitude: 0.37268

Collected Steps per Second: 21,208.65063
Overall Steps per Second: 10,217.51070

Timestep Collection Time: 2.35923
Timestep Consumption Time: 2.53786
PPO Batch Consumption Time: 0.30018
Total Iteration Time: 4.89708

Cumulative Model Updates: 226,476
Cumulative Timesteps: 1,889,407,494

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1889407494...
Checkpoint 1889407494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,300.01677
Policy Entropy: 1.99649
Value Function Loss: 0.02922

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.31890
Value Function Update Magnitude: 0.40194

Collected Steps per Second: 19,594.62014
Overall Steps per Second: 9,827.21933

Timestep Collection Time: 2.55274
Timestep Consumption Time: 2.53720
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 5.08994

Cumulative Model Updates: 226,482
Cumulative Timesteps: 1,889,457,514

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,197.69341
Policy Entropy: 1.99300
Value Function Loss: 0.02529

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.31172
Value Function Update Magnitude: 0.38856

Collected Steps per Second: 20,801.23430
Overall Steps per Second: 10,077.63320

Timestep Collection Time: 2.40447
Timestep Consumption Time: 2.55860
PPO Batch Consumption Time: 0.29901
Total Iteration Time: 4.96307

Cumulative Model Updates: 226,488
Cumulative Timesteps: 1,889,507,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1889507530...
Checkpoint 1889507530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,790.37709
Policy Entropy: 2.02131
Value Function Loss: 0.02485

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.30386
Value Function Update Magnitude: 0.34525

Collected Steps per Second: 20,162.90288
Overall Steps per Second: 9,978.34953

Timestep Collection Time: 2.48179
Timestep Consumption Time: 2.53307
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 5.01486

Cumulative Model Updates: 226,494
Cumulative Timesteps: 1,889,557,570

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,041.96078
Policy Entropy: 2.01073
Value Function Loss: 0.02508

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07280
Policy Update Magnitude: 0.30304
Value Function Update Magnitude: 0.29760

Collected Steps per Second: 20,716.65820
Overall Steps per Second: 10,136.57092

Timestep Collection Time: 2.41429
Timestep Consumption Time: 2.51992
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.93421

Cumulative Model Updates: 226,500
Cumulative Timesteps: 1,889,607,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1889607586...
Checkpoint 1889607586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,194.58901
Policy Entropy: 2.02772
Value Function Loss: 0.02491

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07796
Policy Update Magnitude: 0.29992
Value Function Update Magnitude: 0.30350

Collected Steps per Second: 20,756.64284
Overall Steps per Second: 10,124.92287

Timestep Collection Time: 2.41118
Timestep Consumption Time: 2.53187
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.94305

Cumulative Model Updates: 226,506
Cumulative Timesteps: 1,889,657,634

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,721.41089
Policy Entropy: 2.01871
Value Function Loss: 0.02361

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07709
Policy Update Magnitude: 0.29861
Value Function Update Magnitude: 0.32972

Collected Steps per Second: 21,391.60110
Overall Steps per Second: 10,391.32032

Timestep Collection Time: 2.33821
Timestep Consumption Time: 2.47523
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.81344

Cumulative Model Updates: 226,512
Cumulative Timesteps: 1,889,707,652

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1889707652...
Checkpoint 1889707652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,109.62536
Policy Entropy: 2.01140
Value Function Loss: 0.02256

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07695
Policy Update Magnitude: 0.30164
Value Function Update Magnitude: 0.31932

Collected Steps per Second: 20,576.36792
Overall Steps per Second: 10,206.71267

Timestep Collection Time: 2.43017
Timestep Consumption Time: 2.46896
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.89913

Cumulative Model Updates: 226,518
Cumulative Timesteps: 1,889,757,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,079.80082
Policy Entropy: 1.99075
Value Function Loss: 0.02379

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07747
Policy Update Magnitude: 0.29775
Value Function Update Magnitude: 0.30386

Collected Steps per Second: 20,234.00013
Overall Steps per Second: 10,254.54253

Timestep Collection Time: 2.47188
Timestep Consumption Time: 2.40557
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.87745

Cumulative Model Updates: 226,524
Cumulative Timesteps: 1,889,807,672

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1889807672...
Checkpoint 1889807672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,869.38507
Policy Entropy: 1.99212
Value Function Loss: 0.02257

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07561
Policy Update Magnitude: 0.29558
Value Function Update Magnitude: 0.28699

Collected Steps per Second: 19,789.88483
Overall Steps per Second: 9,981.10779

Timestep Collection Time: 2.52695
Timestep Consumption Time: 2.48332
PPO Batch Consumption Time: 0.30072
Total Iteration Time: 5.01027

Cumulative Model Updates: 226,530
Cumulative Timesteps: 1,889,857,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,597.67982
Policy Entropy: 2.00625
Value Function Loss: 0.02271

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07256
Policy Update Magnitude: 0.29625
Value Function Update Magnitude: 0.29181

Collected Steps per Second: 18,383.87865
Overall Steps per Second: 9,586.04975

Timestep Collection Time: 2.72054
Timestep Consumption Time: 2.49684
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 5.21737

Cumulative Model Updates: 226,536
Cumulative Timesteps: 1,889,907,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1889907694...
Checkpoint 1889907694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,597.67982
Policy Entropy: 2.01027
Value Function Loss: 0.02050

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.28885
Value Function Update Magnitude: 0.29224

Collected Steps per Second: 20,286.77919
Overall Steps per Second: 10,146.41305

Timestep Collection Time: 2.46574
Timestep Consumption Time: 2.46427
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.93002

Cumulative Model Updates: 226,542
Cumulative Timesteps: 1,889,957,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,680.57321
Policy Entropy: 2.01859
Value Function Loss: 0.02620

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07409
Policy Update Magnitude: 0.29241
Value Function Update Magnitude: 0.30718

Collected Steps per Second: 19,607.31350
Overall Steps per Second: 9,525.26403

Timestep Collection Time: 2.55078
Timestep Consumption Time: 2.69989
PPO Batch Consumption Time: 0.32336
Total Iteration Time: 5.25067

Cumulative Model Updates: 226,548
Cumulative Timesteps: 1,890,007,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1890007730...
Checkpoint 1890007730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,047.67410
Policy Entropy: 2.00858
Value Function Loss: 0.02526

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07233
Policy Update Magnitude: 0.30156
Value Function Update Magnitude: 0.34206

Collected Steps per Second: 21,424.11014
Overall Steps per Second: 10,492.71149

Timestep Collection Time: 2.33485
Timestep Consumption Time: 2.43246
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.76731

Cumulative Model Updates: 226,554
Cumulative Timesteps: 1,890,057,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,404.25815
Policy Entropy: 2.01003
Value Function Loss: 0.02700

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.29944
Value Function Update Magnitude: 0.36243

Collected Steps per Second: 21,355.03623
Overall Steps per Second: 9,906.78781

Timestep Collection Time: 2.34193
Timestep Consumption Time: 2.70633
PPO Batch Consumption Time: 0.31646
Total Iteration Time: 5.04826

Cumulative Model Updates: 226,560
Cumulative Timesteps: 1,890,107,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1890107764...
Checkpoint 1890107764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,745.75354
Policy Entropy: 1.99782
Value Function Loss: 0.02310

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.29327
Value Function Update Magnitude: 0.33876

Collected Steps per Second: 19,077.24610
Overall Steps per Second: 9,894.02479

Timestep Collection Time: 2.62103
Timestep Consumption Time: 2.43273
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 5.05376

Cumulative Model Updates: 226,566
Cumulative Timesteps: 1,890,157,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,406.28789
Policy Entropy: 2.00390
Value Function Loss: 0.02188

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.29111
Value Function Update Magnitude: 0.32383

Collected Steps per Second: 21,682.65950
Overall Steps per Second: 10,493.64210

Timestep Collection Time: 2.30719
Timestep Consumption Time: 2.46008
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.76727

Cumulative Model Updates: 226,572
Cumulative Timesteps: 1,890,207,792

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1890207792...
Checkpoint 1890207792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,235.82072
Policy Entropy: 1.99489
Value Function Loss: 0.02081

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.29520
Value Function Update Magnitude: 0.30868

Collected Steps per Second: 21,413.66582
Overall Steps per Second: 10,302.40489

Timestep Collection Time: 2.33598
Timestep Consumption Time: 2.51939
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.85537

Cumulative Model Updates: 226,578
Cumulative Timesteps: 1,890,257,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,489.83136
Policy Entropy: 2.00768
Value Function Loss: 0.02282

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08044
Policy Update Magnitude: 0.30190
Value Function Update Magnitude: 0.30781

Collected Steps per Second: 21,906.52463
Overall Steps per Second: 10,394.89827

Timestep Collection Time: 2.28316
Timestep Consumption Time: 2.52844
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.81159

Cumulative Model Updates: 226,584
Cumulative Timesteps: 1,890,307,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1890307830...
Checkpoint 1890307830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,210.43885
Policy Entropy: 2.00099
Value Function Loss: 0.02262

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.06959
Policy Update Magnitude: 0.29669
Value Function Update Magnitude: 0.31278

Collected Steps per Second: 21,400.57803
Overall Steps per Second: 10,344.32358

Timestep Collection Time: 2.33741
Timestep Consumption Time: 2.49828
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.83570

Cumulative Model Updates: 226,590
Cumulative Timesteps: 1,890,357,852

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,859.81880
Policy Entropy: 2.01660
Value Function Loss: 0.02229

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.06665
Policy Update Magnitude: 0.29314
Value Function Update Magnitude: 0.30579

Collected Steps per Second: 21,471.76680
Overall Steps per Second: 10,297.07748

Timestep Collection Time: 2.32864
Timestep Consumption Time: 2.52711
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.85575

Cumulative Model Updates: 226,596
Cumulative Timesteps: 1,890,407,852

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1890407852...
Checkpoint 1890407852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,145.26718
Policy Entropy: 2.02421
Value Function Loss: 0.02177

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.29230
Value Function Update Magnitude: 0.30428

Collected Steps per Second: 21,078.67958
Overall Steps per Second: 10,042.90066

Timestep Collection Time: 2.37311
Timestep Consumption Time: 2.60772
PPO Batch Consumption Time: 0.30717
Total Iteration Time: 4.98083

Cumulative Model Updates: 226,602
Cumulative Timesteps: 1,890,457,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,428.63243
Policy Entropy: 2.02682
Value Function Loss: 0.02163

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07490
Policy Update Magnitude: 0.28919
Value Function Update Magnitude: 0.28578

Collected Steps per Second: 19,494.98346
Overall Steps per Second: 9,804.02338

Timestep Collection Time: 2.56661
Timestep Consumption Time: 2.53701
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 5.10362

Cumulative Model Updates: 226,608
Cumulative Timesteps: 1,890,507,910

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1890507910...
Checkpoint 1890507910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,999.29526
Policy Entropy: 2.02554
Value Function Loss: 0.02015

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07871
Policy Update Magnitude: 0.29055
Value Function Update Magnitude: 0.28921

Collected Steps per Second: 21,382.42351
Overall Steps per Second: 10,207.16114

Timestep Collection Time: 2.34005
Timestep Consumption Time: 2.56200
PPO Batch Consumption Time: 0.29885
Total Iteration Time: 4.90205

Cumulative Model Updates: 226,614
Cumulative Timesteps: 1,890,557,946

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,334.71687
Policy Entropy: 2.02719
Value Function Loss: 0.02085

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07556
Policy Update Magnitude: 0.29142
Value Function Update Magnitude: 0.27674

Collected Steps per Second: 21,434.38970
Overall Steps per Second: 10,172.46508

Timestep Collection Time: 2.33317
Timestep Consumption Time: 2.58305
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.91621

Cumulative Model Updates: 226,620
Cumulative Timesteps: 1,890,607,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1890607956...
Checkpoint 1890607956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,494.30569
Policy Entropy: 2.01944
Value Function Loss: 0.02278

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.29508
Value Function Update Magnitude: 0.22138

Collected Steps per Second: 20,893.01690
Overall Steps per Second: 10,210.41298

Timestep Collection Time: 2.39391
Timestep Consumption Time: 2.50462
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.89853

Cumulative Model Updates: 226,626
Cumulative Timesteps: 1,890,657,972

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,986.66049
Policy Entropy: 1.99979
Value Function Loss: 0.02468

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07507
Policy Update Magnitude: 0.29425
Value Function Update Magnitude: 0.18378

Collected Steps per Second: 21,797.63632
Overall Steps per Second: 10,379.59665

Timestep Collection Time: 2.29557
Timestep Consumption Time: 2.52523
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.82080

Cumulative Model Updates: 226,632
Cumulative Timesteps: 1,890,708,010

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1890708010...
Checkpoint 1890708010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,215.32731
Policy Entropy: 1.98967
Value Function Loss: 0.02445

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.06872
Policy Update Magnitude: 0.29874
Value Function Update Magnitude: 0.18308

Collected Steps per Second: 21,376.99850
Overall Steps per Second: 10,392.24554

Timestep Collection Time: 2.33896
Timestep Consumption Time: 2.47232
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.81128

Cumulative Model Updates: 226,638
Cumulative Timesteps: 1,890,758,010

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,273.35244
Policy Entropy: 1.97974
Value Function Loss: 0.02364

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07285
Policy Update Magnitude: 0.29836
Value Function Update Magnitude: 0.22553

Collected Steps per Second: 21,331.99574
Overall Steps per Second: 10,286.89054

Timestep Collection Time: 2.34530
Timestep Consumption Time: 2.51817
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.86347

Cumulative Model Updates: 226,644
Cumulative Timesteps: 1,890,808,040

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1890808040...
Checkpoint 1890808040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,391.70031
Policy Entropy: 1.99512
Value Function Loss: 0.02788

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08609
Policy Update Magnitude: 0.30525
Value Function Update Magnitude: 0.27959

Collected Steps per Second: 20,812.89987
Overall Steps per Second: 10,056.49924

Timestep Collection Time: 2.40312
Timestep Consumption Time: 2.57038
PPO Batch Consumption Time: 0.30418
Total Iteration Time: 4.97350

Cumulative Model Updates: 226,650
Cumulative Timesteps: 1,890,858,056

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,726.70874
Policy Entropy: 2.01128
Value Function Loss: 0.02798

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.31345
Value Function Update Magnitude: 0.32835

Collected Steps per Second: 21,622.64491
Overall Steps per Second: 10,507.11908

Timestep Collection Time: 2.31369
Timestep Consumption Time: 2.44766
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.76134

Cumulative Model Updates: 226,656
Cumulative Timesteps: 1,890,908,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1890908084...
Checkpoint 1890908084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,696.55814
Policy Entropy: 2.01711
Value Function Loss: 0.02650

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.30855
Value Function Update Magnitude: 0.34349

Collected Steps per Second: 20,725.08710
Overall Steps per Second: 10,299.75212

Timestep Collection Time: 2.41282
Timestep Consumption Time: 2.44224
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.85507

Cumulative Model Updates: 226,662
Cumulative Timesteps: 1,890,958,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,927.00559
Policy Entropy: 2.02405
Value Function Loss: 0.02553

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.30828
Value Function Update Magnitude: 0.34311

Collected Steps per Second: 21,250.12821
Overall Steps per Second: 10,405.94634

Timestep Collection Time: 2.35359
Timestep Consumption Time: 2.45270
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.80629

Cumulative Model Updates: 226,668
Cumulative Timesteps: 1,891,008,104

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1891008104...
Checkpoint 1891008104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,769.39124
Policy Entropy: 2.01772
Value Function Loss: 0.02736

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.31482
Value Function Update Magnitude: 0.36621

Collected Steps per Second: 20,826.47567
Overall Steps per Second: 10,368.68515

Timestep Collection Time: 2.40242
Timestep Consumption Time: 2.42307
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.82549

Cumulative Model Updates: 226,674
Cumulative Timesteps: 1,891,058,138

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,030.07166
Policy Entropy: 2.03348
Value Function Loss: 0.03096

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.32697
Value Function Update Magnitude: 0.38184

Collected Steps per Second: 21,077.83446
Overall Steps per Second: 10,394.51552

Timestep Collection Time: 2.37216
Timestep Consumption Time: 2.43807
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.81023

Cumulative Model Updates: 226,680
Cumulative Timesteps: 1,891,108,138

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1891108138...
Checkpoint 1891108138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,862.91550
Policy Entropy: 2.03771
Value Function Loss: 0.02877

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.08675
Policy Update Magnitude: 0.32245
Value Function Update Magnitude: 0.40192

Collected Steps per Second: 20,503.39390
Overall Steps per Second: 9,968.38827

Timestep Collection Time: 2.43979
Timestep Consumption Time: 2.57847
PPO Batch Consumption Time: 0.30596
Total Iteration Time: 5.01826

Cumulative Model Updates: 226,686
Cumulative Timesteps: 1,891,158,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,736.58004
Policy Entropy: 2.04863
Value Function Loss: 0.02678

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.30331
Value Function Update Magnitude: 0.38288

Collected Steps per Second: 21,697.34136
Overall Steps per Second: 10,571.72882

Timestep Collection Time: 2.30443
Timestep Consumption Time: 2.42517
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.72960

Cumulative Model Updates: 226,692
Cumulative Timesteps: 1,891,208,162

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1891208162...
Checkpoint 1891208162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,167.20297
Policy Entropy: 2.04369
Value Function Loss: 0.02593

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.11048
Policy Update Magnitude: 0.29064
Value Function Update Magnitude: 0.35706

Collected Steps per Second: 20,359.60440
Overall Steps per Second: 10,093.51819

Timestep Collection Time: 2.45702
Timestep Consumption Time: 2.49903
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.95605

Cumulative Model Updates: 226,698
Cumulative Timesteps: 1,891,258,186

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,899.51769
Policy Entropy: 2.01941
Value Function Loss: 0.02724

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.10572
Policy Update Magnitude: 0.30774
Value Function Update Magnitude: 0.35106

Collected Steps per Second: 20,697.71232
Overall Steps per Second: 9,864.06367

Timestep Collection Time: 2.41602
Timestep Consumption Time: 2.65350
PPO Batch Consumption Time: 0.31427
Total Iteration Time: 5.06951

Cumulative Model Updates: 226,704
Cumulative Timesteps: 1,891,308,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1891308192...
Checkpoint 1891308192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,307.12594
Policy Entropy: 1.99742
Value Function Loss: 0.02832

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.32587
Value Function Update Magnitude: 0.36124

Collected Steps per Second: 18,779.16359
Overall Steps per Second: 9,712.81072

Timestep Collection Time: 2.66284
Timestep Consumption Time: 2.48561
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 5.14846

Cumulative Model Updates: 226,710
Cumulative Timesteps: 1,891,358,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,364.14165
Policy Entropy: 1.99886
Value Function Loss: 0.02611

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.32502
Value Function Update Magnitude: 0.36885

Collected Steps per Second: 20,284.98827
Overall Steps per Second: 9,989.88509

Timestep Collection Time: 2.46586
Timestep Consumption Time: 2.54120
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 5.00706

Cumulative Model Updates: 226,716
Cumulative Timesteps: 1,891,408,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1891408218...
Checkpoint 1891408218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,889.45250
Policy Entropy: 2.01158
Value Function Loss: 0.02326

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.31384
Value Function Update Magnitude: 0.33219

Collected Steps per Second: 20,693.37879
Overall Steps per Second: 10,231.32917

Timestep Collection Time: 2.41700
Timestep Consumption Time: 2.47151
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.88851

Cumulative Model Updates: 226,722
Cumulative Timesteps: 1,891,458,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,643.32200
Policy Entropy: 2.01251
Value Function Loss: 0.02221

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07488
Policy Update Magnitude: 0.30573
Value Function Update Magnitude: 0.29315

Collected Steps per Second: 21,373.40680
Overall Steps per Second: 10,335.97350

Timestep Collection Time: 2.33954
Timestep Consumption Time: 2.49832
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.83786

Cumulative Model Updates: 226,728
Cumulative Timesteps: 1,891,508,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1891508238...
Checkpoint 1891508238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,497.72437
Policy Entropy: 2.01257
Value Function Loss: 0.02371

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07322
Policy Update Magnitude: 0.30469
Value Function Update Magnitude: 0.27825

Collected Steps per Second: 20,258.82707
Overall Steps per Second: 10,046.51982

Timestep Collection Time: 2.46954
Timestep Consumption Time: 2.51029
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.97983

Cumulative Model Updates: 226,734
Cumulative Timesteps: 1,891,558,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,172.32878
Policy Entropy: 2.01208
Value Function Loss: 0.02427

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07193
Policy Update Magnitude: 0.30737
Value Function Update Magnitude: 0.28136

Collected Steps per Second: 20,673.30156
Overall Steps per Second: 10,209.93810

Timestep Collection Time: 2.41887
Timestep Consumption Time: 2.47891
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.89778

Cumulative Model Updates: 226,740
Cumulative Timesteps: 1,891,608,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1891608274...
Checkpoint 1891608274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,680.17536
Policy Entropy: 2.00961
Value Function Loss: 0.02667

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07878
Policy Update Magnitude: 0.31736
Value Function Update Magnitude: 0.34328

Collected Steps per Second: 20,795.48857
Overall Steps per Second: 10,202.37152

Timestep Collection Time: 2.40456
Timestep Consumption Time: 2.49665
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.90121

Cumulative Model Updates: 226,746
Cumulative Timesteps: 1,891,658,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,376.46802
Policy Entropy: 2.01810
Value Function Loss: 0.02379

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.31795
Value Function Update Magnitude: 0.38032

Collected Steps per Second: 20,629.25285
Overall Steps per Second: 10,168.30263

Timestep Collection Time: 2.42403
Timestep Consumption Time: 2.49380
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.91783

Cumulative Model Updates: 226,752
Cumulative Timesteps: 1,891,708,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1891708284...
Checkpoint 1891708284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,966.05789
Policy Entropy: 2.01013
Value Function Loss: 0.02248

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.29950
Value Function Update Magnitude: 0.35474

Collected Steps per Second: 21,372.80913
Overall Steps per Second: 10,137.81496

Timestep Collection Time: 2.33970
Timestep Consumption Time: 2.59292
PPO Batch Consumption Time: 0.30558
Total Iteration Time: 4.93262

Cumulative Model Updates: 226,758
Cumulative Timesteps: 1,891,758,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,087.30108
Policy Entropy: 2.02289
Value Function Loss: 0.02055

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.28857
Value Function Update Magnitude: 0.30989

Collected Steps per Second: 20,752.01225
Overall Steps per Second: 10,043.28092

Timestep Collection Time: 2.40940
Timestep Consumption Time: 2.56905
PPO Batch Consumption Time: 0.30228
Total Iteration Time: 4.97845

Cumulative Model Updates: 226,764
Cumulative Timesteps: 1,891,808,290

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1891808290...
Checkpoint 1891808290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,191.31975
Policy Entropy: 2.02286
Value Function Loss: 0.02371

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07827
Policy Update Magnitude: 0.29980
Value Function Update Magnitude: 0.27294

Collected Steps per Second: 20,464.75471
Overall Steps per Second: 10,037.64035

Timestep Collection Time: 2.44362
Timestep Consumption Time: 2.53843
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.98205

Cumulative Model Updates: 226,770
Cumulative Timesteps: 1,891,858,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,990.34052
Policy Entropy: 2.03028
Value Function Loss: 0.02587

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07901
Policy Update Magnitude: 0.30858
Value Function Update Magnitude: 0.25080

Collected Steps per Second: 21,115.66647
Overall Steps per Second: 10,155.18975

Timestep Collection Time: 2.36961
Timestep Consumption Time: 2.55752
PPO Batch Consumption Time: 0.30066
Total Iteration Time: 4.92714

Cumulative Model Updates: 226,776
Cumulative Timesteps: 1,891,908,334

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1891908334...
Checkpoint 1891908334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,133.26998
Policy Entropy: 2.03154
Value Function Loss: 0.02544

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.30493
Value Function Update Magnitude: 0.22728

Collected Steps per Second: 19,710.60990
Overall Steps per Second: 9,774.50190

Timestep Collection Time: 2.53691
Timestep Consumption Time: 2.57885
PPO Batch Consumption Time: 0.31625
Total Iteration Time: 5.11576

Cumulative Model Updates: 226,782
Cumulative Timesteps: 1,891,958,338

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,243.63171
Policy Entropy: 2.03607
Value Function Loss: 0.02383

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08044
Policy Update Magnitude: 0.29348
Value Function Update Magnitude: 0.23021

Collected Steps per Second: 19,190.38551
Overall Steps per Second: 9,732.54134

Timestep Collection Time: 2.60620
Timestep Consumption Time: 2.53264
PPO Batch Consumption Time: 0.29777
Total Iteration Time: 5.13884

Cumulative Model Updates: 226,788
Cumulative Timesteps: 1,892,008,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1892008352...
Checkpoint 1892008352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,036.97964
Policy Entropy: 2.04158
Value Function Loss: 0.02428

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07361
Policy Update Magnitude: 0.29789
Value Function Update Magnitude: 0.23065

Collected Steps per Second: 20,441.71674
Overall Steps per Second: 10,353.93105

Timestep Collection Time: 2.44794
Timestep Consumption Time: 2.38501
PPO Batch Consumption Time: 0.29755
Total Iteration Time: 4.83295

Cumulative Model Updates: 226,794
Cumulative Timesteps: 1,892,058,392

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,628.54322
Policy Entropy: 2.04526
Value Function Loss: 0.02467

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07287
Policy Update Magnitude: 0.30347
Value Function Update Magnitude: 0.24907

Collected Steps per Second: 20,059.57894
Overall Steps per Second: 10,247.68775

Timestep Collection Time: 2.49417
Timestep Consumption Time: 2.38810
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.88227

Cumulative Model Updates: 226,800
Cumulative Timesteps: 1,892,108,424

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1892108424...
Checkpoint 1892108424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,774.06914
Policy Entropy: 2.04068
Value Function Loss: 0.02652

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08190
Policy Update Magnitude: 0.30511
Value Function Update Magnitude: 0.26271

Collected Steps per Second: 20,771.89181
Overall Steps per Second: 10,195.91803

Timestep Collection Time: 2.40710
Timestep Consumption Time: 2.49682
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.90392

Cumulative Model Updates: 226,806
Cumulative Timesteps: 1,892,158,424

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,690.10145
Policy Entropy: 2.04265
Value Function Loss: 0.02337

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07635
Policy Update Magnitude: 0.31053
Value Function Update Magnitude: 0.30501

Collected Steps per Second: 21,476.93613
Overall Steps per Second: 10,731.90148

Timestep Collection Time: 2.32882
Timestep Consumption Time: 2.33167
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.66050

Cumulative Model Updates: 226,812
Cumulative Timesteps: 1,892,208,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1892208440...
Checkpoint 1892208440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,902.62473
Policy Entropy: 2.03797
Value Function Loss: 0.02467

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.30877
Value Function Update Magnitude: 0.29634

Collected Steps per Second: 20,587.01757
Overall Steps per Second: 10,497.82410

Timestep Collection Time: 2.43076
Timestep Consumption Time: 2.33614
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.76689

Cumulative Model Updates: 226,818
Cumulative Timesteps: 1,892,258,482

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,905.20828
Policy Entropy: 2.03384
Value Function Loss: 0.02402

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.30650
Value Function Update Magnitude: 0.28241

Collected Steps per Second: 21,068.34121
Overall Steps per Second: 10,220.23104

Timestep Collection Time: 2.37427
Timestep Consumption Time: 2.52014
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.89441

Cumulative Model Updates: 226,824
Cumulative Timesteps: 1,892,308,504

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1892308504...
Checkpoint 1892308504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,832.37903
Policy Entropy: 2.01782
Value Function Loss: 0.02549

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.31028
Value Function Update Magnitude: 0.26547

Collected Steps per Second: 20,687.25545
Overall Steps per Second: 10,060.12413

Timestep Collection Time: 2.41695
Timestep Consumption Time: 2.55317
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.97012

Cumulative Model Updates: 226,830
Cumulative Timesteps: 1,892,358,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,151.98705
Policy Entropy: 2.03032
Value Function Loss: 0.02586

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08438
Policy Update Magnitude: 0.31333
Value Function Update Magnitude: 0.25449

Collected Steps per Second: 20,054.54416
Overall Steps per Second: 9,987.83291

Timestep Collection Time: 2.49490
Timestep Consumption Time: 2.51460
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 5.00950

Cumulative Model Updates: 226,836
Cumulative Timesteps: 1,892,408,538

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1892408538...
Checkpoint 1892408538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,117.46219
Policy Entropy: 2.03878
Value Function Loss: 0.02674

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08215
Policy Update Magnitude: 0.30685
Value Function Update Magnitude: 0.27251

Collected Steps per Second: 20,651.60582
Overall Steps per Second: 10,025.68907

Timestep Collection Time: 2.42170
Timestep Consumption Time: 2.56669
PPO Batch Consumption Time: 0.29968
Total Iteration Time: 4.98839

Cumulative Model Updates: 226,842
Cumulative Timesteps: 1,892,458,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,344.16757
Policy Entropy: 2.03670
Value Function Loss: 0.02540

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.30452
Value Function Update Magnitude: 0.29176

Collected Steps per Second: 20,409.09830
Overall Steps per Second: 10,020.00215

Timestep Collection Time: 2.45106
Timestep Consumption Time: 2.54135
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.99241

Cumulative Model Updates: 226,848
Cumulative Timesteps: 1,892,508,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1892508574...
Checkpoint 1892508574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,544.15599
Policy Entropy: 2.01692
Value Function Loss: 0.02699

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07521
Policy Update Magnitude: 0.30991
Value Function Update Magnitude: 0.31737

Collected Steps per Second: 20,870.98895
Overall Steps per Second: 10,153.99488

Timestep Collection Time: 2.39567
Timestep Consumption Time: 2.52850
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.92417

Cumulative Model Updates: 226,854
Cumulative Timesteps: 1,892,558,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,538.43550
Policy Entropy: 2.02388
Value Function Loss: 0.02505

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07408
Policy Update Magnitude: 0.30844
Value Function Update Magnitude: 0.32211

Collected Steps per Second: 21,440.29953
Overall Steps per Second: 10,346.20911

Timestep Collection Time: 2.33402
Timestep Consumption Time: 2.50273
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.83675

Cumulative Model Updates: 226,860
Cumulative Timesteps: 1,892,608,616

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1892608616...
Checkpoint 1892608616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,267.85437
Policy Entropy: 2.03186
Value Function Loss: 0.02678

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07617
Policy Update Magnitude: 0.30717
Value Function Update Magnitude: 0.33520

Collected Steps per Second: 20,880.87567
Overall Steps per Second: 10,205.63591

Timestep Collection Time: 2.39501
Timestep Consumption Time: 2.50522
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.90023

Cumulative Model Updates: 226,866
Cumulative Timesteps: 1,892,658,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,906.88243
Policy Entropy: 2.03943
Value Function Loss: 0.02763

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.31480
Value Function Update Magnitude: 0.30236

Collected Steps per Second: 21,645.65108
Overall Steps per Second: 10,425.79493

Timestep Collection Time: 2.31086
Timestep Consumption Time: 2.48686
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.79772

Cumulative Model Updates: 226,872
Cumulative Timesteps: 1,892,708,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1892708646...
Checkpoint 1892708646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,735.16762
Policy Entropy: 2.01350
Value Function Loss: 0.02832

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.11331
Policy Update Magnitude: 0.31402
Value Function Update Magnitude: 0.34373

Collected Steps per Second: 21,223.95280
Overall Steps per Second: 10,530.61889

Timestep Collection Time: 2.35658
Timestep Consumption Time: 2.39300
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.74958

Cumulative Model Updates: 226,878
Cumulative Timesteps: 1,892,758,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,493.55129
Policy Entropy: 2.01269
Value Function Loss: 0.02684

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.10087
Policy Update Magnitude: 0.31629
Value Function Update Magnitude: 0.36280

Collected Steps per Second: 20,834.23941
Overall Steps per Second: 9,868.29306

Timestep Collection Time: 2.40047
Timestep Consumption Time: 2.66748
PPO Batch Consumption Time: 0.31310
Total Iteration Time: 5.06795

Cumulative Model Updates: 226,884
Cumulative Timesteps: 1,892,808,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1892808674...
Checkpoint 1892808674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,771.28618
Policy Entropy: 2.02817
Value Function Loss: 0.02238

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.30834
Value Function Update Magnitude: 0.35957

Collected Steps per Second: 18,935.09054
Overall Steps per Second: 9,757.02565

Timestep Collection Time: 2.64282
Timestep Consumption Time: 2.48600
PPO Batch Consumption Time: 0.29931
Total Iteration Time: 5.12882

Cumulative Model Updates: 226,890
Cumulative Timesteps: 1,892,858,716

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,853.43309
Policy Entropy: 2.02823
Value Function Loss: 0.02358

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07926
Policy Update Magnitude: 0.30809
Value Function Update Magnitude: 0.34067

Collected Steps per Second: 18,893.66071
Overall Steps per Second: 9,924.71631

Timestep Collection Time: 2.64777
Timestep Consumption Time: 2.39278
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 5.04055

Cumulative Model Updates: 226,896
Cumulative Timesteps: 1,892,908,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1892908742...
Checkpoint 1892908742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,670.21460
Policy Entropy: 2.02283
Value Function Loss: 0.02139

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07811
Policy Update Magnitude: 0.30562
Value Function Update Magnitude: 0.32634

Collected Steps per Second: 19,888.48199
Overall Steps per Second: 9,824.81844

Timestep Collection Time: 2.51482
Timestep Consumption Time: 2.57596
PPO Batch Consumption Time: 0.31468
Total Iteration Time: 5.09078

Cumulative Model Updates: 226,902
Cumulative Timesteps: 1,892,958,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,219.91309
Policy Entropy: 2.00743
Value Function Loss: 0.02149

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07506
Policy Update Magnitude: 0.29953
Value Function Update Magnitude: 0.32057

Collected Steps per Second: 20,505.07651
Overall Steps per Second: 10,053.82439

Timestep Collection Time: 2.43881
Timestep Consumption Time: 2.53522
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.97403

Cumulative Model Updates: 226,908
Cumulative Timesteps: 1,893,008,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1893008766...
Checkpoint 1893008766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,520.62675
Policy Entropy: 2.03041
Value Function Loss: 0.02235

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07243
Policy Update Magnitude: 0.29613
Value Function Update Magnitude: 0.32038

Collected Steps per Second: 20,250.24161
Overall Steps per Second: 9,662.74698

Timestep Collection Time: 2.46950
Timestep Consumption Time: 2.70584
PPO Batch Consumption Time: 0.32554
Total Iteration Time: 5.17534

Cumulative Model Updates: 226,914
Cumulative Timesteps: 1,893,058,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,622.74366
Policy Entropy: 2.01804
Value Function Loss: 0.02334

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06579
Policy Update Magnitude: 0.30129
Value Function Update Magnitude: 0.32934

Collected Steps per Second: 20,441.12744
Overall Steps per Second: 10,167.12321

Timestep Collection Time: 2.44644
Timestep Consumption Time: 2.47216
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.91860

Cumulative Model Updates: 226,920
Cumulative Timesteps: 1,893,108,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1893108782...
Checkpoint 1893108782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,680.11792
Policy Entropy: 2.02986
Value Function Loss: 0.02391

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07226
Policy Update Magnitude: 0.30264
Value Function Update Magnitude: 0.32557

Collected Steps per Second: 20,429.11686
Overall Steps per Second: 9,805.12438

Timestep Collection Time: 2.44778
Timestep Consumption Time: 2.65221
PPO Batch Consumption Time: 0.31302
Total Iteration Time: 5.09999

Cumulative Model Updates: 226,926
Cumulative Timesteps: 1,893,158,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,253.42618
Policy Entropy: 2.02177
Value Function Loss: 0.02109

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07185
Policy Update Magnitude: 0.29561
Value Function Update Magnitude: 0.30362

Collected Steps per Second: 19,178.53085
Overall Steps per Second: 9,363.43368

Timestep Collection Time: 2.60750
Timestep Consumption Time: 2.73328
PPO Batch Consumption Time: 0.32498
Total Iteration Time: 5.34078

Cumulative Model Updates: 226,932
Cumulative Timesteps: 1,893,208,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1893208796...
Checkpoint 1893208796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,330.98100
Policy Entropy: 2.02345
Value Function Loss: 0.02274

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07274
Policy Update Magnitude: 0.29255
Value Function Update Magnitude: 0.31181

Collected Steps per Second: 20,213.69514
Overall Steps per Second: 9,974.99194

Timestep Collection Time: 2.47496
Timestep Consumption Time: 2.54039
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 5.01534

Cumulative Model Updates: 226,938
Cumulative Timesteps: 1,893,258,824

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,834.00920
Policy Entropy: 2.02415
Value Function Loss: 0.02061

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07142
Policy Update Magnitude: 0.28930
Value Function Update Magnitude: 0.32918

Collected Steps per Second: 19,816.75150
Overall Steps per Second: 9,873.27800

Timestep Collection Time: 2.52443
Timestep Consumption Time: 2.54238
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 5.06681

Cumulative Model Updates: 226,944
Cumulative Timesteps: 1,893,308,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1893308850...
Checkpoint 1893308850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,472.66244
Policy Entropy: 2.00649
Value Function Loss: 0.02121

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.06855
Policy Update Magnitude: 0.28634
Value Function Update Magnitude: 0.30465

Collected Steps per Second: 18,846.39667
Overall Steps per Second: 9,461.39844

Timestep Collection Time: 2.65483
Timestep Consumption Time: 2.63339
PPO Batch Consumption Time: 0.31659
Total Iteration Time: 5.28822

Cumulative Model Updates: 226,950
Cumulative Timesteps: 1,893,358,884

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,176.81452
Policy Entropy: 2.02050
Value Function Loss: 0.02215

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07218
Policy Update Magnitude: 0.29397
Value Function Update Magnitude: 0.25951

Collected Steps per Second: 20,138.50607
Overall Steps per Second: 9,675.79698

Timestep Collection Time: 2.48430
Timestep Consumption Time: 2.68634
PPO Batch Consumption Time: 0.31827
Total Iteration Time: 5.17063

Cumulative Model Updates: 226,956
Cumulative Timesteps: 1,893,408,914

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1893408914...
Checkpoint 1893408914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,876.39491
Policy Entropy: 2.01695
Value Function Loss: 0.02531

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07273
Policy Update Magnitude: 0.29975
Value Function Update Magnitude: 0.27896

Collected Steps per Second: 18,671.12689
Overall Steps per Second: 9,625.15658

Timestep Collection Time: 2.67879
Timestep Consumption Time: 2.51759
PPO Batch Consumption Time: 0.30020
Total Iteration Time: 5.19638

Cumulative Model Updates: 226,962
Cumulative Timesteps: 1,893,458,930

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,598.64540
Policy Entropy: 2.03822
Value Function Loss: 0.02545

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07343
Policy Update Magnitude: 0.30034
Value Function Update Magnitude: 0.25983

Collected Steps per Second: 19,587.21815
Overall Steps per Second: 10,202.88206

Timestep Collection Time: 2.55401
Timestep Consumption Time: 2.34911
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.90312

Cumulative Model Updates: 226,968
Cumulative Timesteps: 1,893,508,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1893508956...
Checkpoint 1893508956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,013.28840
Policy Entropy: 2.03404
Value Function Loss: 0.02339

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07559
Policy Update Magnitude: 0.29493
Value Function Update Magnitude: 0.26278

Collected Steps per Second: 19,970.38626
Overall Steps per Second: 10,000.47975

Timestep Collection Time: 2.50411
Timestep Consumption Time: 2.49645
PPO Batch Consumption Time: 0.30344
Total Iteration Time: 5.00056

Cumulative Model Updates: 226,974
Cumulative Timesteps: 1,893,558,964

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,876.08537
Policy Entropy: 2.03936
Value Function Loss: 0.02247

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06931
Policy Update Magnitude: 0.28772
Value Function Update Magnitude: 0.28350

Collected Steps per Second: 18,766.38856
Overall Steps per Second: 9,561.98430

Timestep Collection Time: 2.66508
Timestep Consumption Time: 2.56542
PPO Batch Consumption Time: 0.31012
Total Iteration Time: 5.23050

Cumulative Model Updates: 226,980
Cumulative Timesteps: 1,893,608,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1893608978...
Checkpoint 1893608978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,157.30885
Policy Entropy: 2.03007
Value Function Loss: 0.02321

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07203
Policy Update Magnitude: 0.29289
Value Function Update Magnitude: 0.30937

Collected Steps per Second: 18,965.49390
Overall Steps per Second: 9,828.56787

Timestep Collection Time: 2.63679
Timestep Consumption Time: 2.45124
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 5.08803

Cumulative Model Updates: 226,986
Cumulative Timesteps: 1,893,658,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,157.30885
Policy Entropy: 2.02487
Value Function Loss: 0.02098

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07161
Policy Update Magnitude: 0.29234
Value Function Update Magnitude: 0.32235

Collected Steps per Second: 20,739.95450
Overall Steps per Second: 10,261.64781

Timestep Collection Time: 2.41148
Timestep Consumption Time: 2.46240
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.87388

Cumulative Model Updates: 226,992
Cumulative Timesteps: 1,893,709,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1893709000...
Checkpoint 1893709000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,631.82679
Policy Entropy: 2.01047
Value Function Loss: 0.01984

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.06884
Policy Update Magnitude: 0.29111
Value Function Update Magnitude: 0.29471

Collected Steps per Second: 20,851.64817
Overall Steps per Second: 10,244.98425

Timestep Collection Time: 2.39799
Timestep Consumption Time: 2.48264
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.88063

Cumulative Model Updates: 226,998
Cumulative Timesteps: 1,893,759,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,169.26332
Policy Entropy: 2.00079
Value Function Loss: 0.02250

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06903
Policy Update Magnitude: 0.30108
Value Function Update Magnitude: 0.27358

Collected Steps per Second: 20,978.77229
Overall Steps per Second: 10,301.94816

Timestep Collection Time: 2.38451
Timestep Consumption Time: 2.47127
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.85578

Cumulative Model Updates: 227,004
Cumulative Timesteps: 1,893,809,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1893809026...
Checkpoint 1893809026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,780.46889
Policy Entropy: 2.01155
Value Function Loss: 0.02522

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07326
Policy Update Magnitude: 0.31010
Value Function Update Magnitude: 0.30907

Collected Steps per Second: 20,196.17247
Overall Steps per Second: 10,057.03100

Timestep Collection Time: 2.47631
Timestep Consumption Time: 2.49653
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.97284

Cumulative Model Updates: 227,010
Cumulative Timesteps: 1,893,859,038

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,097.90465
Policy Entropy: 2.02276
Value Function Loss: 0.02662

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.06902
Policy Update Magnitude: 0.31392
Value Function Update Magnitude: 0.31781

Collected Steps per Second: 21,695.04704
Overall Steps per Second: 10,322.08305

Timestep Collection Time: 2.30467
Timestep Consumption Time: 2.53931
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.84398

Cumulative Model Updates: 227,016
Cumulative Timesteps: 1,893,909,038

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1893909038...
Checkpoint 1893909038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,035.09453
Policy Entropy: 2.04646
Value Function Loss: 0.02642

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07102
Policy Update Magnitude: 0.31229
Value Function Update Magnitude: 0.33260

Collected Steps per Second: 21,063.67117
Overall Steps per Second: 10,182.75038

Timestep Collection Time: 2.37442
Timestep Consumption Time: 2.53722
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.91164

Cumulative Model Updates: 227,022
Cumulative Timesteps: 1,893,959,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,487.59096
Policy Entropy: 2.04670
Value Function Loss: 0.02775

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.31608
Value Function Update Magnitude: 0.33519

Collected Steps per Second: 21,564.10225
Overall Steps per Second: 10,457.59384

Timestep Collection Time: 2.31969
Timestep Consumption Time: 2.46363
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.78332

Cumulative Model Updates: 227,028
Cumulative Timesteps: 1,894,009,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1894009074...
Checkpoint 1894009074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,116.75056
Policy Entropy: 2.05574
Value Function Loss: 0.02653

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07459
Policy Update Magnitude: 0.31051
Value Function Update Magnitude: 0.33118

Collected Steps per Second: 21,274.16053
Overall Steps per Second: 10,267.71907

Timestep Collection Time: 2.35027
Timestep Consumption Time: 2.51936
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.86963

Cumulative Model Updates: 227,034
Cumulative Timesteps: 1,894,059,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,569.60172
Policy Entropy: 2.03933
Value Function Loss: 0.02469

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07227
Policy Update Magnitude: 0.31202
Value Function Update Magnitude: 0.34934

Collected Steps per Second: 21,660.59636
Overall Steps per Second: 10,375.89868

Timestep Collection Time: 2.30935
Timestep Consumption Time: 2.51163
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.82098

Cumulative Model Updates: 227,040
Cumulative Timesteps: 1,894,109,096

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1894109096...
Checkpoint 1894109096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,163.71402
Policy Entropy: 2.03744
Value Function Loss: 0.02327

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07032
Policy Update Magnitude: 0.31267
Value Function Update Magnitude: 0.34219

Collected Steps per Second: 21,012.72690
Overall Steps per Second: 10,228.31869

Timestep Collection Time: 2.38046
Timestep Consumption Time: 2.50988
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.89034

Cumulative Model Updates: 227,046
Cumulative Timesteps: 1,894,159,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,822.39792
Policy Entropy: 2.04451
Value Function Loss: 0.02348

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07316
Policy Update Magnitude: 0.31145
Value Function Update Magnitude: 0.30179

Collected Steps per Second: 20,932.83905
Overall Steps per Second: 10,503.01122

Timestep Collection Time: 2.38983
Timestep Consumption Time: 2.37318
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.76301

Cumulative Model Updates: 227,052
Cumulative Timesteps: 1,894,209,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1894209142...
Checkpoint 1894209142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,656.80427
Policy Entropy: 2.04707
Value Function Loss: 0.02320

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07530
Policy Update Magnitude: 0.30743
Value Function Update Magnitude: 0.28176

Collected Steps per Second: 20,545.57271
Overall Steps per Second: 10,243.34646

Timestep Collection Time: 2.43400
Timestep Consumption Time: 2.44799
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.88200

Cumulative Model Updates: 227,058
Cumulative Timesteps: 1,894,259,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,052.80473
Policy Entropy: 2.03614
Value Function Loss: 0.02537

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07629
Policy Update Magnitude: 0.30602
Value Function Update Magnitude: 0.28119

Collected Steps per Second: 21,184.79921
Overall Steps per Second: 10,419.85684

Timestep Collection Time: 2.36198
Timestep Consumption Time: 2.44020
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.80218

Cumulative Model Updates: 227,064
Cumulative Timesteps: 1,894,309,188

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1894309188...
Checkpoint 1894309188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,105.41376
Policy Entropy: 2.03043
Value Function Loss: 0.02503

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07885
Policy Update Magnitude: 0.30453
Value Function Update Magnitude: 0.29257

Collected Steps per Second: 20,348.03486
Overall Steps per Second: 10,143.29400

Timestep Collection Time: 2.45862
Timestep Consumption Time: 2.47351
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.93213

Cumulative Model Updates: 227,070
Cumulative Timesteps: 1,894,359,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,667.46076
Policy Entropy: 2.04027
Value Function Loss: 0.02410

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07774
Policy Update Magnitude: 0.30618
Value Function Update Magnitude: 0.31355

Collected Steps per Second: 18,075.49218
Overall Steps per Second: 9,171.12585

Timestep Collection Time: 2.76640
Timestep Consumption Time: 2.68593
PPO Batch Consumption Time: 0.31559
Total Iteration Time: 5.45233

Cumulative Model Updates: 227,076
Cumulative Timesteps: 1,894,409,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1894409220...
Checkpoint 1894409220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,239.18734
Policy Entropy: 2.05115
Value Function Loss: 0.02474

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07750
Policy Update Magnitude: 0.31190
Value Function Update Magnitude: 0.33693

Collected Steps per Second: 18,105.60149
Overall Steps per Second: 9,557.65668

Timestep Collection Time: 2.76368
Timestep Consumption Time: 2.47171
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 5.23538

Cumulative Model Updates: 227,082
Cumulative Timesteps: 1,894,459,258

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,629.76625
Policy Entropy: 2.04575
Value Function Loss: 0.02883

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.32499
Value Function Update Magnitude: 0.33012

Collected Steps per Second: 19,800.32358
Overall Steps per Second: 9,800.07878

Timestep Collection Time: 2.52572
Timestep Consumption Time: 2.57730
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 5.10302

Cumulative Model Updates: 227,088
Cumulative Timesteps: 1,894,509,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1894509268...
Checkpoint 1894509268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,916.06910
Policy Entropy: 2.03664
Value Function Loss: 0.02762

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.32089
Value Function Update Magnitude: 0.33517

Collected Steps per Second: 21,354.98603
Overall Steps per Second: 10,459.32011

Timestep Collection Time: 2.34278
Timestep Consumption Time: 2.44052
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.78329

Cumulative Model Updates: 227,094
Cumulative Timesteps: 1,894,559,298

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,731.47344
Policy Entropy: 2.02436
Value Function Loss: 0.02598

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.31651
Value Function Update Magnitude: 0.33476

Collected Steps per Second: 21,401.04602
Overall Steps per Second: 10,164.77810

Timestep Collection Time: 2.33774
Timestep Consumption Time: 2.58416
PPO Batch Consumption Time: 0.30467
Total Iteration Time: 4.92190

Cumulative Model Updates: 227,100
Cumulative Timesteps: 1,894,609,328

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1894609328...
Checkpoint 1894609328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,110.93958
Policy Entropy: 2.01977
Value Function Loss: 0.02253

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07404
Policy Update Magnitude: 0.30819
Value Function Update Magnitude: 0.31249

Collected Steps per Second: 20,406.80474
Overall Steps per Second: 10,009.92049

Timestep Collection Time: 2.45163
Timestep Consumption Time: 2.54641
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.99804

Cumulative Model Updates: 227,106
Cumulative Timesteps: 1,894,659,358

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,445.61620
Policy Entropy: 2.03614
Value Function Loss: 0.02461

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07783
Policy Update Magnitude: 0.30994
Value Function Update Magnitude: 0.29669

Collected Steps per Second: 21,542.22724
Overall Steps per Second: 10,294.62413

Timestep Collection Time: 2.32177
Timestep Consumption Time: 2.53669
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.85846

Cumulative Model Updates: 227,112
Cumulative Timesteps: 1,894,709,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1894709374...
Checkpoint 1894709374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,574.93162
Policy Entropy: 2.04005
Value Function Loss: 0.02274

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.30590
Value Function Update Magnitude: 0.32341

Collected Steps per Second: 20,636.23636
Overall Steps per Second: 10,029.77323

Timestep Collection Time: 2.42331
Timestep Consumption Time: 2.56265
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.98596

Cumulative Model Updates: 227,118
Cumulative Timesteps: 1,894,759,382

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,155.18014
Policy Entropy: 2.04229
Value Function Loss: 0.02494

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07614
Policy Update Magnitude: 0.30944
Value Function Update Magnitude: 0.34740

Collected Steps per Second: 20,936.29152
Overall Steps per Second: 10,162.20240

Timestep Collection Time: 2.38839
Timestep Consumption Time: 2.53220
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.92059

Cumulative Model Updates: 227,124
Cumulative Timesteps: 1,894,809,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1894809386...
Checkpoint 1894809386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,934.76159
Policy Entropy: 2.02009
Value Function Loss: 0.02315

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07446
Policy Update Magnitude: 0.31424
Value Function Update Magnitude: 0.34421

Collected Steps per Second: 19,947.81083
Overall Steps per Second: 10,010.79935

Timestep Collection Time: 2.50814
Timestep Consumption Time: 2.48966
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.99780

Cumulative Model Updates: 227,130
Cumulative Timesteps: 1,894,859,418

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,109.45546
Policy Entropy: 2.02225
Value Function Loss: 0.02300

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.06862
Policy Update Magnitude: 0.31055
Value Function Update Magnitude: 0.32545

Collected Steps per Second: 21,382.61442
Overall Steps per Second: 10,180.28376

Timestep Collection Time: 2.33891
Timestep Consumption Time: 2.57372
PPO Batch Consumption Time: 0.29875
Total Iteration Time: 4.91263

Cumulative Model Updates: 227,136
Cumulative Timesteps: 1,894,909,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1894909430...
Checkpoint 1894909430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,776.08497
Policy Entropy: 2.03228
Value Function Loss: 0.02040

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.07148
Policy Update Magnitude: 0.30092
Value Function Update Magnitude: 0.30547

Collected Steps per Second: 20,626.34040
Overall Steps per Second: 10,288.95741

Timestep Collection Time: 2.42564
Timestep Consumption Time: 2.43705
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.86269

Cumulative Model Updates: 227,142
Cumulative Timesteps: 1,894,959,462

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,110.05506
Policy Entropy: 2.03025
Value Function Loss: 0.02142

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07246
Policy Update Magnitude: 0.29308
Value Function Update Magnitude: 0.28981

Collected Steps per Second: 21,789.68476
Overall Steps per Second: 10,241.22188

Timestep Collection Time: 2.29577
Timestep Consumption Time: 2.58881
PPO Batch Consumption Time: 0.30170
Total Iteration Time: 4.88457

Cumulative Model Updates: 227,148
Cumulative Timesteps: 1,895,009,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1895009486...
Checkpoint 1895009486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,167.78324
Policy Entropy: 2.03841
Value Function Loss: 0.02039

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07000
Policy Update Magnitude: 0.29080
Value Function Update Magnitude: 0.30528

Collected Steps per Second: 20,705.06951
Overall Steps per Second: 10,130.91673

Timestep Collection Time: 2.41535
Timestep Consumption Time: 2.52102
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.93637

Cumulative Model Updates: 227,154
Cumulative Timesteps: 1,895,059,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,684.68164
Policy Entropy: 2.03651
Value Function Loss: 0.02372

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06906
Policy Update Magnitude: 0.30067
Value Function Update Magnitude: 0.32821

Collected Steps per Second: 18,813.70870
Overall Steps per Second: 9,765.18704

Timestep Collection Time: 2.65849
Timestep Consumption Time: 2.46338
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 5.12187

Cumulative Model Updates: 227,160
Cumulative Timesteps: 1,895,109,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1895109512...
Checkpoint 1895109512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,782.21957
Policy Entropy: 2.02292
Value Function Loss: 0.02379

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.07738
Policy Update Magnitude: 0.31263
Value Function Update Magnitude: 0.32047

Collected Steps per Second: 18,571.79752
Overall Steps per Second: 9,842.62732

Timestep Collection Time: 2.69452
Timestep Consumption Time: 2.38970
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 5.08421

Cumulative Model Updates: 227,166
Cumulative Timesteps: 1,895,159,554

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,084.16713
Policy Entropy: 2.02859
Value Function Loss: 0.02664

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.07874
Policy Update Magnitude: 0.31171
Value Function Update Magnitude: 0.27277

Collected Steps per Second: 19,414.24257
Overall Steps per Second: 10,083.55481

Timestep Collection Time: 2.57646
Timestep Consumption Time: 2.38409
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.96055

Cumulative Model Updates: 227,172
Cumulative Timesteps: 1,895,209,574

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1895209574...
Checkpoint 1895209574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,750.87043
Policy Entropy: 2.03248
Value Function Loss: 0.02596

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.31499
Value Function Update Magnitude: 0.32888

Collected Steps per Second: 20,055.51738
Overall Steps per Second: 10,267.89107

Timestep Collection Time: 2.49378
Timestep Consumption Time: 2.37713
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.87091

Cumulative Model Updates: 227,178
Cumulative Timesteps: 1,895,259,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,781.00979
Policy Entropy: 2.05929
Value Function Loss: 0.02782

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08159
Policy Update Magnitude: 0.32112
Value Function Update Magnitude: 0.31806

Collected Steps per Second: 20,636.86848
Overall Steps per Second: 10,337.22456

Timestep Collection Time: 2.42343
Timestep Consumption Time: 2.41462
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.83805

Cumulative Model Updates: 227,184
Cumulative Timesteps: 1,895,309,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1895309600...
Checkpoint 1895309600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,601.07416
Policy Entropy: 2.05290
Value Function Loss: 0.02662

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07926
Policy Update Magnitude: 0.32459
Value Function Update Magnitude: 0.31406

Collected Steps per Second: 20,625.82201
Overall Steps per Second: 10,263.92195

Timestep Collection Time: 2.42531
Timestep Consumption Time: 2.44846
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.87377

Cumulative Model Updates: 227,190
Cumulative Timesteps: 1,895,359,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,377.07082
Policy Entropy: 2.07261
Value Function Loss: 0.02717

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.32187
Value Function Update Magnitude: 0.34584

Collected Steps per Second: 20,828.59141
Overall Steps per Second: 10,244.77891

Timestep Collection Time: 2.40189
Timestep Consumption Time: 2.48138
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.88327

Cumulative Model Updates: 227,196
Cumulative Timesteps: 1,895,409,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1895409652...
Checkpoint 1895409652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,943.72837
Policy Entropy: 2.06670
Value Function Loss: 0.02454

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.31118
Value Function Update Magnitude: 0.34352

Collected Steps per Second: 21,006.93399
Overall Steps per Second: 10,082.77989

Timestep Collection Time: 2.38055
Timestep Consumption Time: 2.57920
PPO Batch Consumption Time: 0.29946
Total Iteration Time: 4.95974

Cumulative Model Updates: 227,202
Cumulative Timesteps: 1,895,459,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,143.73465
Policy Entropy: 2.06596
Value Function Loss: 0.02728

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.30771
Value Function Update Magnitude: 0.32083

Collected Steps per Second: 21,125.91428
Overall Steps per Second: 10,426.26789

Timestep Collection Time: 2.36828
Timestep Consumption Time: 2.43037
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.79865

Cumulative Model Updates: 227,208
Cumulative Timesteps: 1,895,509,692

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1895509692...
Checkpoint 1895509692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,257.32033
Policy Entropy: 2.06202
Value Function Loss: 0.02442

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07705
Policy Update Magnitude: 0.31169
Value Function Update Magnitude: 0.34763

Collected Steps per Second: 20,807.50311
Overall Steps per Second: 10,062.10319

Timestep Collection Time: 2.40481
Timestep Consumption Time: 2.56811
PPO Batch Consumption Time: 0.31013
Total Iteration Time: 4.97292

Cumulative Model Updates: 227,214
Cumulative Timesteps: 1,895,559,730

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,847.67704
Policy Entropy: 2.04228
Value Function Loss: 0.02452

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07912
Policy Update Magnitude: 0.30318
Value Function Update Magnitude: 0.37178

Collected Steps per Second: 20,070.54944
Overall Steps per Second: 9,655.04316

Timestep Collection Time: 2.49241
Timestep Consumption Time: 2.68872
PPO Batch Consumption Time: 0.31339
Total Iteration Time: 5.18113

Cumulative Model Updates: 227,220
Cumulative Timesteps: 1,895,609,754

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1895609754...
Checkpoint 1895609754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,666.76965
Policy Entropy: 2.02790
Value Function Loss: 0.02243

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07331
Policy Update Magnitude: 0.30206
Value Function Update Magnitude: 0.37567

Collected Steps per Second: 18,729.98859
Overall Steps per Second: 9,127.02267

Timestep Collection Time: 2.67048
Timestep Consumption Time: 2.80973
PPO Batch Consumption Time: 0.34235
Total Iteration Time: 5.48021

Cumulative Model Updates: 227,226
Cumulative Timesteps: 1,895,659,772

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,814.18640
Policy Entropy: 2.02537
Value Function Loss: 0.02422

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07720
Policy Update Magnitude: 0.31035
Value Function Update Magnitude: 0.36433

Collected Steps per Second: 19,619.55964
Overall Steps per Second: 9,672.84195

Timestep Collection Time: 2.55062
Timestep Consumption Time: 2.62284
PPO Batch Consumption Time: 0.30919
Total Iteration Time: 5.17345

Cumulative Model Updates: 227,232
Cumulative Timesteps: 1,895,709,814

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1895709814...
Checkpoint 1895709814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,452.50534
Policy Entropy: 2.03448
Value Function Loss: 0.02565

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.31477
Value Function Update Magnitude: 0.36753

Collected Steps per Second: 18,978.62119
Overall Steps per Second: 9,566.53151

Timestep Collection Time: 2.63475
Timestep Consumption Time: 2.59222
PPO Batch Consumption Time: 0.29881
Total Iteration Time: 5.22697

Cumulative Model Updates: 227,238
Cumulative Timesteps: 1,895,759,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,576.55326
Policy Entropy: 2.05583
Value Function Loss: 0.02548

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.31046
Value Function Update Magnitude: 0.35726

Collected Steps per Second: 20,557.16656
Overall Steps per Second: 9,906.57326

Timestep Collection Time: 2.43234
Timestep Consumption Time: 2.61502
PPO Batch Consumption Time: 0.30406
Total Iteration Time: 5.04736

Cumulative Model Updates: 227,244
Cumulative Timesteps: 1,895,809,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1895809820...
Checkpoint 1895809820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,637.38816
Policy Entropy: 2.05865
Value Function Loss: 0.02379

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08098
Policy Update Magnitude: 0.30002
Value Function Update Magnitude: 0.33384

Collected Steps per Second: 20,204.27229
Overall Steps per Second: 9,895.73167

Timestep Collection Time: 2.47492
Timestep Consumption Time: 2.57817
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 5.05309

Cumulative Model Updates: 227,250
Cumulative Timesteps: 1,895,859,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,934.31650
Policy Entropy: 2.05606
Value Function Loss: 0.02210

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.30174
Value Function Update Magnitude: 0.32660

Collected Steps per Second: 21,031.81520
Overall Steps per Second: 10,205.75603

Timestep Collection Time: 2.37849
Timestep Consumption Time: 2.52306
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.90155

Cumulative Model Updates: 227,256
Cumulative Timesteps: 1,895,909,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1895909848...
Checkpoint 1895909848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,831.88707
Policy Entropy: 2.04419
Value Function Loss: 0.01887

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08055
Policy Update Magnitude: 0.30772
Value Function Update Magnitude: 0.30305

Collected Steps per Second: 19,783.64110
Overall Steps per Second: 9,765.14046

Timestep Collection Time: 2.52785
Timestep Consumption Time: 2.59343
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 5.12128

Cumulative Model Updates: 227,262
Cumulative Timesteps: 1,895,959,858

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,103.43339
Policy Entropy: 2.03954
Value Function Loss: 0.02107

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07613
Policy Update Magnitude: 0.29873
Value Function Update Magnitude: 0.28865

Collected Steps per Second: 20,801.55307
Overall Steps per Second: 10,313.12411

Timestep Collection Time: 2.40597
Timestep Consumption Time: 2.44687
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.85285

Cumulative Model Updates: 227,268
Cumulative Timesteps: 1,896,009,906

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1896009906...
Checkpoint 1896009906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,148.86551
Policy Entropy: 2.02972
Value Function Loss: 0.02249

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07221
Policy Update Magnitude: 0.30093
Value Function Update Magnitude: 0.29036

Collected Steps per Second: 20,387.82786
Overall Steps per Second: 10,206.13473

Timestep Collection Time: 2.45244
Timestep Consumption Time: 2.44657
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.89901

Cumulative Model Updates: 227,274
Cumulative Timesteps: 1,896,059,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,113.72151
Policy Entropy: 2.05063
Value Function Loss: 0.02182

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07130
Policy Update Magnitude: 0.30098
Value Function Update Magnitude: 0.29404

Collected Steps per Second: 20,890.29035
Overall Steps per Second: 10,498.79982

Timestep Collection Time: 2.39461
Timestep Consumption Time: 2.37013
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.76474

Cumulative Model Updates: 227,280
Cumulative Timesteps: 1,896,109,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1896109930...
Checkpoint 1896109930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,049.07918
Policy Entropy: 2.05592
Value Function Loss: 0.02244

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07010
Policy Update Magnitude: 0.29087
Value Function Update Magnitude: 0.28284

Collected Steps per Second: 19,803.54183
Overall Steps per Second: 10,127.94431

Timestep Collection Time: 2.52591
Timestep Consumption Time: 2.41310
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.93901

Cumulative Model Updates: 227,286
Cumulative Timesteps: 1,896,159,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,365.08844
Policy Entropy: 2.06312
Value Function Loss: 0.02294

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07213
Policy Update Magnitude: 0.29601
Value Function Update Magnitude: 0.28793

Collected Steps per Second: 21,006.22126
Overall Steps per Second: 10,538.77502

Timestep Collection Time: 2.38187
Timestep Consumption Time: 2.36574
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.74761

Cumulative Model Updates: 227,292
Cumulative Timesteps: 1,896,209,986

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1896209986...
Checkpoint 1896209986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,263.67154
Policy Entropy: 2.04578
Value Function Loss: 0.02381

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07207
Policy Update Magnitude: 0.30129
Value Function Update Magnitude: 0.32060

Collected Steps per Second: 20,315.97906
Overall Steps per Second: 10,070.25102

Timestep Collection Time: 2.46259
Timestep Consumption Time: 2.50551
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.96810

Cumulative Model Updates: 227,298
Cumulative Timesteps: 1,896,260,016

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,514.30501
Policy Entropy: 2.04595
Value Function Loss: 0.02016

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06771
Policy Update Magnitude: 0.29314
Value Function Update Magnitude: 0.32424

Collected Steps per Second: 20,590.13220
Overall Steps per Second: 9,935.47482

Timestep Collection Time: 2.42980
Timestep Consumption Time: 2.60569
PPO Batch Consumption Time: 0.30006
Total Iteration Time: 5.03549

Cumulative Model Updates: 227,304
Cumulative Timesteps: 1,896,310,046

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1896310046...
Checkpoint 1896310046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,907.22523
Policy Entropy: 2.05300
Value Function Loss: 0.02038

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06578
Policy Update Magnitude: 0.28869
Value Function Update Magnitude: 0.27176

Collected Steps per Second: 20,137.14844
Overall Steps per Second: 9,968.33573

Timestep Collection Time: 2.48347
Timestep Consumption Time: 2.53342
PPO Batch Consumption Time: 0.29783
Total Iteration Time: 5.01689

Cumulative Model Updates: 227,310
Cumulative Timesteps: 1,896,360,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,011.26149
Policy Entropy: 2.05163
Value Function Loss: 0.02197

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06827
Policy Update Magnitude: 0.29535
Value Function Update Magnitude: 0.26440

Collected Steps per Second: 21,068.50967
Overall Steps per Second: 10,203.46290

Timestep Collection Time: 2.37454
Timestep Consumption Time: 2.52850
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.90304

Cumulative Model Updates: 227,316
Cumulative Timesteps: 1,896,410,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1896410084...
Checkpoint 1896410084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,992.99807
Policy Entropy: 2.02580
Value Function Loss: 0.02270

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07337
Policy Update Magnitude: 0.29784
Value Function Update Magnitude: 0.28963

Collected Steps per Second: 21,047.75251
Overall Steps per Second: 10,130.64117

Timestep Collection Time: 2.37707
Timestep Consumption Time: 2.56161
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.93868

Cumulative Model Updates: 227,322
Cumulative Timesteps: 1,896,460,116

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,432.49123
Policy Entropy: 2.02145
Value Function Loss: 0.02345

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07227
Policy Update Magnitude: 0.30266
Value Function Update Magnitude: 0.30226

Collected Steps per Second: 20,026.98677
Overall Steps per Second: 9,720.36210

Timestep Collection Time: 2.49663
Timestep Consumption Time: 2.64721
PPO Batch Consumption Time: 0.31112
Total Iteration Time: 5.14384

Cumulative Model Updates: 227,328
Cumulative Timesteps: 1,896,510,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1896510116...
Checkpoint 1896510116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,274.74187
Policy Entropy: 2.00389
Value Function Loss: 0.02202

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.07884
Policy Update Magnitude: 0.30361
Value Function Update Magnitude: 0.34245

Collected Steps per Second: 20,575.90479
Overall Steps per Second: 10,043.44030

Timestep Collection Time: 2.43032
Timestep Consumption Time: 2.54865
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.97897

Cumulative Model Updates: 227,334
Cumulative Timesteps: 1,896,560,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,901.13898
Policy Entropy: 2.02946
Value Function Loss: 0.02341

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.30142
Value Function Update Magnitude: 0.34702

Collected Steps per Second: 19,774.32945
Overall Steps per Second: 10,020.34859

Timestep Collection Time: 2.52964
Timestep Consumption Time: 2.46240
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.99204

Cumulative Model Updates: 227,340
Cumulative Timesteps: 1,896,610,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1896610144...
Checkpoint 1896610144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,570.87513
Policy Entropy: 2.02754
Value Function Loss: 0.02333

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.29580
Value Function Update Magnitude: 0.33331

Collected Steps per Second: 19,727.76955
Overall Steps per Second: 9,723.98141

Timestep Collection Time: 2.53642
Timestep Consumption Time: 2.60941
PPO Batch Consumption Time: 0.30180
Total Iteration Time: 5.14583

Cumulative Model Updates: 227,346
Cumulative Timesteps: 1,896,660,182

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,854.08548
Policy Entropy: 2.03032
Value Function Loss: 0.02659

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.30241
Value Function Update Magnitude: 0.31354

Collected Steps per Second: 18,511.87207
Overall Steps per Second: 9,627.71401

Timestep Collection Time: 2.70097
Timestep Consumption Time: 2.49237
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 5.19334

Cumulative Model Updates: 227,352
Cumulative Timesteps: 1,896,710,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1896710182...
Checkpoint 1896710182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,924.33122
Policy Entropy: 2.02390
Value Function Loss: 0.02902

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.31949
Value Function Update Magnitude: 0.32994

Collected Steps per Second: 16,841.17737
Overall Steps per Second: 8,964.29406

Timestep Collection Time: 2.97129
Timestep Consumption Time: 2.61086
PPO Batch Consumption Time: 0.32250
Total Iteration Time: 5.58215

Cumulative Model Updates: 227,358
Cumulative Timesteps: 1,896,760,222

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,381.59845
Policy Entropy: 2.02541
Value Function Loss: 0.02703

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.31828
Value Function Update Magnitude: 0.38215

Collected Steps per Second: 19,576.16591
Overall Steps per Second: 10,196.40845

Timestep Collection Time: 2.55556
Timestep Consumption Time: 2.35088
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.90643

Cumulative Model Updates: 227,364
Cumulative Timesteps: 1,896,810,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1896810250...
Checkpoint 1896810250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,040.51410
Policy Entropy: 2.02626
Value Function Loss: 0.02372

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.31169
Value Function Update Magnitude: 0.38178

Collected Steps per Second: 19,997.59022
Overall Steps per Second: 9,837.12443

Timestep Collection Time: 2.50230
Timestep Consumption Time: 2.58455
PPO Batch Consumption Time: 0.30605
Total Iteration Time: 5.08685

Cumulative Model Updates: 227,370
Cumulative Timesteps: 1,896,860,290

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,244.86153
Policy Entropy: 2.02250
Value Function Loss: 0.02169

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.29443
Value Function Update Magnitude: 0.35377

Collected Steps per Second: 19,876.14636
Overall Steps per Second: 9,921.23812

Timestep Collection Time: 2.51699
Timestep Consumption Time: 2.52553
PPO Batch Consumption Time: 0.30998
Total Iteration Time: 5.04252

Cumulative Model Updates: 227,376
Cumulative Timesteps: 1,896,910,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1896910318...
Checkpoint 1896910318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,496.21686
Policy Entropy: 2.01743
Value Function Loss: 0.02478

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.29886
Value Function Update Magnitude: 0.34137

Collected Steps per Second: 16,602.42650
Overall Steps per Second: 8,849.86403

Timestep Collection Time: 3.01185
Timestep Consumption Time: 2.63841
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 5.65026

Cumulative Model Updates: 227,382
Cumulative Timesteps: 1,896,960,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,683.97573
Policy Entropy: 2.02510
Value Function Loss: 0.02521

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.31286
Value Function Update Magnitude: 0.35551

Collected Steps per Second: 19,689.36732
Overall Steps per Second: 9,685.83115

Timestep Collection Time: 2.54025
Timestep Consumption Time: 2.62358
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 5.16383

Cumulative Model Updates: 227,388
Cumulative Timesteps: 1,897,010,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1897010338...
Checkpoint 1897010338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,369.38062
Policy Entropy: 2.01731
Value Function Loss: 0.02609

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.11056
Policy Update Magnitude: 0.31356
Value Function Update Magnitude: 0.38115

Collected Steps per Second: 19,163.96659
Overall Steps per Second: 9,816.77750

Timestep Collection Time: 2.60906
Timestep Consumption Time: 2.48426
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 5.09332

Cumulative Model Updates: 227,394
Cumulative Timesteps: 1,897,060,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,947.48567
Policy Entropy: 2.02116
Value Function Loss: 0.02362

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11882
Policy Update Magnitude: 0.30590
Value Function Update Magnitude: 0.37606

Collected Steps per Second: 18,337.89746
Overall Steps per Second: 9,425.70593

Timestep Collection Time: 2.72790
Timestep Consumption Time: 2.57929
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 5.30719

Cumulative Model Updates: 227,400
Cumulative Timesteps: 1,897,110,362

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1897110362...
Checkpoint 1897110362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,355.78891
Policy Entropy: 2.03702
Value Function Loss: 0.02468

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.29115
Value Function Update Magnitude: 0.34031

Collected Steps per Second: 14,209.64195
Overall Steps per Second: 7,869.96186

Timestep Collection Time: 3.51902
Timestep Consumption Time: 2.83476
PPO Batch Consumption Time: 0.34925
Total Iteration Time: 6.35378

Cumulative Model Updates: 227,406
Cumulative Timesteps: 1,897,160,366

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,696.71523
Policy Entropy: 2.03813
Value Function Loss: 0.02206

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.11255
Policy Update Magnitude: 0.28618
Value Function Update Magnitude: 0.30527

Collected Steps per Second: 13,883.59889
Overall Steps per Second: 6,107.43479

Timestep Collection Time: 3.60166
Timestep Consumption Time: 4.58574
PPO Batch Consumption Time: 0.62478
Total Iteration Time: 8.18740

Cumulative Model Updates: 227,412
Cumulative Timesteps: 1,897,210,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1897210370...
Checkpoint 1897210370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,296.51782
Policy Entropy: 2.02867
Value Function Loss: 0.02525

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.30906
Value Function Update Magnitude: 0.30409

Collected Steps per Second: 14,025.42089
Overall Steps per Second: 6,972.41058

Timestep Collection Time: 3.56524
Timestep Consumption Time: 3.60645
PPO Batch Consumption Time: 0.46909
Total Iteration Time: 7.17169

Cumulative Model Updates: 227,418
Cumulative Timesteps: 1,897,260,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,397.45199
Policy Entropy: 2.02013
Value Function Loss: 0.02607

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.31107
Value Function Update Magnitude: 0.32937

Collected Steps per Second: 15,238.69840
Overall Steps per Second: 7,170.77208

Timestep Collection Time: 3.28427
Timestep Consumption Time: 3.69517
PPO Batch Consumption Time: 0.48407
Total Iteration Time: 6.97944

Cumulative Model Updates: 227,424
Cumulative Timesteps: 1,897,310,422

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1897310422...
Checkpoint 1897310422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,945.27109
Policy Entropy: 2.03762
Value Function Loss: 0.02722

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.11937
Policy Update Magnitude: 0.30128
Value Function Update Magnitude: 0.33980

Collected Steps per Second: 15,146.04130
Overall Steps per Second: 7,276.93218

Timestep Collection Time: 3.30331
Timestep Consumption Time: 3.57212
PPO Batch Consumption Time: 0.46513
Total Iteration Time: 6.87542

Cumulative Model Updates: 227,430
Cumulative Timesteps: 1,897,360,454

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,296.46973
Policy Entropy: 2.05525
Value Function Loss: 0.02429

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.29658
Value Function Update Magnitude: 0.31048

Collected Steps per Second: 15,144.40508
Overall Steps per Second: 7,238.19922

Timestep Collection Time: 3.30155
Timestep Consumption Time: 3.60625
PPO Batch Consumption Time: 0.46887
Total Iteration Time: 6.90780

Cumulative Model Updates: 227,436
Cumulative Timesteps: 1,897,410,454

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1897410454...
Checkpoint 1897410454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,552.17949
Policy Entropy: 2.05281
Value Function Loss: 0.02579

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.09545
Policy Update Magnitude: 0.30658
Value Function Update Magnitude: 0.27978

Collected Steps per Second: 14,753.63649
Overall Steps per Second: 7,092.32110

Timestep Collection Time: 3.38927
Timestep Consumption Time: 3.66118
PPO Batch Consumption Time: 0.47889
Total Iteration Time: 7.05044

Cumulative Model Updates: 227,442
Cumulative Timesteps: 1,897,460,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,996.09569
Policy Entropy: 2.04842
Value Function Loss: 0.02219

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.30356
Value Function Update Magnitude: 0.31391

Collected Steps per Second: 15,344.41484
Overall Steps per Second: 7,350.47930

Timestep Collection Time: 3.26008
Timestep Consumption Time: 3.54546
PPO Batch Consumption Time: 0.46484
Total Iteration Time: 6.80554

Cumulative Model Updates: 227,448
Cumulative Timesteps: 1,897,510,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1897510482...
Checkpoint 1897510482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,977.44977
Policy Entropy: 2.03824
Value Function Loss: 0.02165

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.29790
Value Function Update Magnitude: 0.29141

Collected Steps per Second: 15,241.55219
Overall Steps per Second: 7,052.68343

Timestep Collection Time: 3.28261
Timestep Consumption Time: 3.81143
PPO Batch Consumption Time: 0.50888
Total Iteration Time: 7.09404

Cumulative Model Updates: 227,454
Cumulative Timesteps: 1,897,560,514

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,914.30632
Policy Entropy: 2.02153
Value Function Loss: 0.02108

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08272
Policy Update Magnitude: 0.30206
Value Function Update Magnitude: 0.27919

Collected Steps per Second: 14,898.60245
Overall Steps per Second: 7,356.16907

Timestep Collection Time: 3.35642
Timestep Consumption Time: 3.44141
PPO Batch Consumption Time: 0.45852
Total Iteration Time: 6.79783

Cumulative Model Updates: 227,460
Cumulative Timesteps: 1,897,610,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1897610520...
Checkpoint 1897610520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,245.31825
Policy Entropy: 2.01931
Value Function Loss: 0.02109

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.30259
Value Function Update Magnitude: 0.30230

Collected Steps per Second: 14,687.91858
Overall Steps per Second: 7,332.34846

Timestep Collection Time: 3.40538
Timestep Consumption Time: 3.41617
PPO Batch Consumption Time: 0.45554
Total Iteration Time: 6.82155

Cumulative Model Updates: 227,466
Cumulative Timesteps: 1,897,660,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,668.57851
Policy Entropy: 2.01751
Value Function Loss: 0.02244

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07345
Policy Update Magnitude: 0.30710
Value Function Update Magnitude: 0.31342

Collected Steps per Second: 14,775.59419
Overall Steps per Second: 6,974.61850

Timestep Collection Time: 3.38450
Timestep Consumption Time: 3.78550
PPO Batch Consumption Time: 0.51656
Total Iteration Time: 7.17000

Cumulative Model Updates: 227,472
Cumulative Timesteps: 1,897,710,546

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1897710546...
Checkpoint 1897710546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,590.98294
Policy Entropy: 2.02374
Value Function Loss: 0.02109

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07120
Policy Update Magnitude: 0.30466
Value Function Update Magnitude: 0.32015

Collected Steps per Second: 14,781.46278
Overall Steps per Second: 7,434.32310

Timestep Collection Time: 3.38397
Timestep Consumption Time: 3.34428
PPO Batch Consumption Time: 0.43400
Total Iteration Time: 6.72825

Cumulative Model Updates: 227,478
Cumulative Timesteps: 1,897,760,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,607.68293
Policy Entropy: 2.02041
Value Function Loss: 0.02113

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07038
Policy Update Magnitude: 0.29637
Value Function Update Magnitude: 0.31483

Collected Steps per Second: 15,182.09945
Overall Steps per Second: 6,989.03832

Timestep Collection Time: 3.29467
Timestep Consumption Time: 3.86225
PPO Batch Consumption Time: 0.51719
Total Iteration Time: 7.15692

Cumulative Model Updates: 227,484
Cumulative Timesteps: 1,897,810,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1897810586...
Checkpoint 1897810586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,207.59074
Policy Entropy: 2.02284
Value Function Loss: 0.02116

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07062
Policy Update Magnitude: 0.29549
Value Function Update Magnitude: 0.30377

Collected Steps per Second: 14,199.31239
Overall Steps per Second: 6,706.30763

Timestep Collection Time: 3.52327
Timestep Consumption Time: 3.93657
PPO Batch Consumption Time: 0.52483
Total Iteration Time: 7.45984

Cumulative Model Updates: 227,490
Cumulative Timesteps: 1,897,860,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,440.23681
Policy Entropy: 2.03701
Value Function Loss: 0.02167

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07406
Policy Update Magnitude: 0.29783
Value Function Update Magnitude: 0.29839

Collected Steps per Second: 14,481.43277
Overall Steps per Second: 7,164.63188

Timestep Collection Time: 3.45380
Timestep Consumption Time: 3.52716
PPO Batch Consumption Time: 0.46041
Total Iteration Time: 6.98096

Cumulative Model Updates: 227,496
Cumulative Timesteps: 1,897,910,630

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1897910630...
Checkpoint 1897910630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,513.08885
Policy Entropy: 2.04345
Value Function Loss: 0.02174

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07262
Policy Update Magnitude: 0.29687
Value Function Update Magnitude: 0.28054

Collected Steps per Second: 14,235.29386
Overall Steps per Second: 7,070.52297

Timestep Collection Time: 3.51436
Timestep Consumption Time: 3.56121
PPO Batch Consumption Time: 0.46393
Total Iteration Time: 7.07557

Cumulative Model Updates: 227,502
Cumulative Timesteps: 1,897,960,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,861.41705
Policy Entropy: 2.04191
Value Function Loss: 0.02165

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07627
Policy Update Magnitude: 0.29061
Value Function Update Magnitude: 0.28128

Collected Steps per Second: 15,773.08795
Overall Steps per Second: 7,619.17756

Timestep Collection Time: 3.17211
Timestep Consumption Time: 3.39474
PPO Batch Consumption Time: 0.43606
Total Iteration Time: 6.56685

Cumulative Model Updates: 227,508
Cumulative Timesteps: 1,898,010,692

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1898010692...
Checkpoint 1898010692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,391.30915
Policy Entropy: 2.02283
Value Function Loss: 0.02110

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.29041
Value Function Update Magnitude: 0.27368

Collected Steps per Second: 15,436.56590
Overall Steps per Second: 7,329.35271

Timestep Collection Time: 3.24075
Timestep Consumption Time: 3.58469
PPO Batch Consumption Time: 0.46544
Total Iteration Time: 6.82543

Cumulative Model Updates: 227,514
Cumulative Timesteps: 1,898,060,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,953.09077
Policy Entropy: 2.01370
Value Function Loss: 0.02175

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07910
Policy Update Magnitude: 0.29743
Value Function Update Magnitude: 0.25686

Collected Steps per Second: 15,627.51120
Overall Steps per Second: 7,179.37695

Timestep Collection Time: 3.20128
Timestep Consumption Time: 3.76702
PPO Batch Consumption Time: 0.49777
Total Iteration Time: 6.96829

Cumulative Model Updates: 227,520
Cumulative Timesteps: 1,898,110,746

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1898110746...
Checkpoint 1898110746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,790.30751
Policy Entropy: 2.01576
Value Function Loss: 0.02423

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07642
Policy Update Magnitude: 0.30614
Value Function Update Magnitude: 0.29582

Collected Steps per Second: 14,404.09329
Overall Steps per Second: 7,133.60376

Timestep Collection Time: 3.47151
Timestep Consumption Time: 3.53813
PPO Batch Consumption Time: 0.46001
Total Iteration Time: 7.00964

Cumulative Model Updates: 227,526
Cumulative Timesteps: 1,898,160,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,774.63886
Policy Entropy: 2.00793
Value Function Loss: 0.02474

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07910
Policy Update Magnitude: 0.31593
Value Function Update Magnitude: 0.33193

Collected Steps per Second: 15,645.07899
Overall Steps per Second: 8,757.74377

Timestep Collection Time: 3.19768
Timestep Consumption Time: 2.51475
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 5.71243

Cumulative Model Updates: 227,532
Cumulative Timesteps: 1,898,210,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1898210778...
Checkpoint 1898210778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,536.78061
Policy Entropy: 2.01346
Value Function Loss: 0.02313

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.30857
Value Function Update Magnitude: 0.35576

Collected Steps per Second: 13,592.97235
Overall Steps per Second: 7,935.01215

Timestep Collection Time: 3.68028
Timestep Consumption Time: 2.62418
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 6.30446

Cumulative Model Updates: 227,538
Cumulative Timesteps: 1,898,260,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,829.48848
Policy Entropy: 2.01046
Value Function Loss: 0.02306

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07951
Policy Update Magnitude: 0.31096
Value Function Update Magnitude: 0.34303

Collected Steps per Second: 19,307.33582
Overall Steps per Second: 9,712.73103

Timestep Collection Time: 2.59176
Timestep Consumption Time: 2.56024
PPO Batch Consumption Time: 0.29965
Total Iteration Time: 5.15200

Cumulative Model Updates: 227,544
Cumulative Timesteps: 1,898,310,844

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1898310844...
Checkpoint 1898310844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,263.42941
Policy Entropy: 2.02924
Value Function Loss: 0.02687

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07522
Policy Update Magnitude: 0.32075
Value Function Update Magnitude: 0.32617

Collected Steps per Second: 20,039.92998
Overall Steps per Second: 10,088.80798

Timestep Collection Time: 2.49532
Timestep Consumption Time: 2.46126
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.95658

Cumulative Model Updates: 227,550
Cumulative Timesteps: 1,898,360,850

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,711.40173
Policy Entropy: 2.03428
Value Function Loss: 0.02488

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.31394
Value Function Update Magnitude: 0.33907

Collected Steps per Second: 20,326.80727
Overall Steps per Second: 10,065.62903

Timestep Collection Time: 2.46079
Timestep Consumption Time: 2.50860
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.96939

Cumulative Model Updates: 227,556
Cumulative Timesteps: 1,898,410,870

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1898410870...
Checkpoint 1898410870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,926.07930
Policy Entropy: 2.02948
Value Function Loss: 0.02335

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07438
Policy Update Magnitude: 0.30473
Value Function Update Magnitude: 0.32453

Collected Steps per Second: 20,234.13648
Overall Steps per Second: 10,156.37784

Timestep Collection Time: 2.47176
Timestep Consumption Time: 2.45263
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.92439

Cumulative Model Updates: 227,562
Cumulative Timesteps: 1,898,460,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,812.64505
Policy Entropy: 2.03063
Value Function Loss: 0.02478

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.07922
Policy Update Magnitude: 0.30331
Value Function Update Magnitude: 0.29094

Collected Steps per Second: 20,869.40095
Overall Steps per Second: 10,123.13499

Timestep Collection Time: 2.39700
Timestep Consumption Time: 2.54455
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.94155

Cumulative Model Updates: 227,568
Cumulative Timesteps: 1,898,510,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1898510908...
Checkpoint 1898510908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,687.02013
Policy Entropy: 2.02994
Value Function Loss: 0.02524

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08587
Policy Update Magnitude: 0.30523
Value Function Update Magnitude: 0.24131

Collected Steps per Second: 19,062.06529
Overall Steps per Second: 9,787.09660

Timestep Collection Time: 2.62385
Timestep Consumption Time: 2.48655
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 5.11040

Cumulative Model Updates: 227,574
Cumulative Timesteps: 1,898,560,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,214.27416
Policy Entropy: 2.03465
Value Function Loss: 0.02419

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.30501
Value Function Update Magnitude: 0.25185

Collected Steps per Second: 19,170.66927
Overall Steps per Second: 9,541.03054

Timestep Collection Time: 2.60940
Timestep Consumption Time: 2.63364
PPO Batch Consumption Time: 0.31445
Total Iteration Time: 5.24304

Cumulative Model Updates: 227,580
Cumulative Timesteps: 1,898,610,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1898610948...
Checkpoint 1898610948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,833.23372
Policy Entropy: 2.02521
Value Function Loss: 0.02329

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.11172
Policy Update Magnitude: 0.30325
Value Function Update Magnitude: 0.22696

Collected Steps per Second: 19,444.04753
Overall Steps per Second: 9,925.45627

Timestep Collection Time: 2.57189
Timestep Consumption Time: 2.46647
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 5.03836

Cumulative Model Updates: 227,586
Cumulative Timesteps: 1,898,660,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,398.39382
Policy Entropy: 2.03010
Value Function Loss: 0.02420

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.10332
Policy Update Magnitude: 0.30976
Value Function Update Magnitude: 0.27037

Collected Steps per Second: 19,958.31678
Overall Steps per Second: 9,940.06692

Timestep Collection Time: 2.50652
Timestep Consumption Time: 2.52624
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 5.03276

Cumulative Model Updates: 227,592
Cumulative Timesteps: 1,898,710,982

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1898710982...
Checkpoint 1898710982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,359.97308
Policy Entropy: 2.02596
Value Function Loss: 0.02570

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.31393
Value Function Update Magnitude: 0.33580

Collected Steps per Second: 20,661.59489
Overall Steps per Second: 10,233.82512

Timestep Collection Time: 2.42063
Timestep Consumption Time: 2.46650
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.88713

Cumulative Model Updates: 227,598
Cumulative Timesteps: 1,898,760,996

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,627.54482
Policy Entropy: 2.03677
Value Function Loss: 0.02383

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.09442
Policy Update Magnitude: 0.31587
Value Function Update Magnitude: 0.35634

Collected Steps per Second: 20,902.67251
Overall Steps per Second: 10,124.65324

Timestep Collection Time: 2.39424
Timestep Consumption Time: 2.54874
PPO Batch Consumption Time: 0.29773
Total Iteration Time: 4.94298

Cumulative Model Updates: 227,604
Cumulative Timesteps: 1,898,811,042

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1898811042...
Checkpoint 1898811042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,610.12385
Policy Entropy: 2.02835
Value Function Loss: 0.02492

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08343
Policy Update Magnitude: 0.31813
Value Function Update Magnitude: 0.34861

Collected Steps per Second: 20,008.51530
Overall Steps per Second: 10,011.35685

Timestep Collection Time: 2.49974
Timestep Consumption Time: 2.49619
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.99593

Cumulative Model Updates: 227,610
Cumulative Timesteps: 1,898,861,058

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,060.46607
Policy Entropy: 2.02839
Value Function Loss: 0.02403

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.31502
Value Function Update Magnitude: 0.33968

Collected Steps per Second: 20,263.15859
Overall Steps per Second: 9,660.03311

Timestep Collection Time: 2.46882
Timestep Consumption Time: 2.70984
PPO Batch Consumption Time: 0.31449
Total Iteration Time: 5.17866

Cumulative Model Updates: 227,616
Cumulative Timesteps: 1,898,911,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1898911084...
Checkpoint 1898911084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,908.28787
Policy Entropy: 2.01978
Value Function Loss: 0.02587

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08124
Policy Update Magnitude: 0.31263
Value Function Update Magnitude: 0.34793

Collected Steps per Second: 20,682.19560
Overall Steps per Second: 10,121.41918

Timestep Collection Time: 2.41754
Timestep Consumption Time: 2.52248
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.94002

Cumulative Model Updates: 227,622
Cumulative Timesteps: 1,898,961,084

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,866.72622
Policy Entropy: 2.03062
Value Function Loss: 0.02827

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.31731
Value Function Update Magnitude: 0.34973

Collected Steps per Second: 19,668.03661
Overall Steps per Second: 9,580.37769

Timestep Collection Time: 2.54301
Timestep Consumption Time: 2.67766
PPO Batch Consumption Time: 0.30023
Total Iteration Time: 5.22067

Cumulative Model Updates: 227,628
Cumulative Timesteps: 1,899,011,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1899011100...
Checkpoint 1899011100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,936.99970
Policy Entropy: 2.02030
Value Function Loss: 0.02664

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.31194
Value Function Update Magnitude: 0.33299

Collected Steps per Second: 18,586.96904
Overall Steps per Second: 9,763.84562

Timestep Collection Time: 2.69156
Timestep Consumption Time: 2.43224
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 5.12380

Cumulative Model Updates: 227,634
Cumulative Timesteps: 1,899,061,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,865.81141
Policy Entropy: 2.03680
Value Function Loss: 0.02621

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.08921
Policy Update Magnitude: 0.31135
Value Function Update Magnitude: 0.33958

Collected Steps per Second: 19,912.72232
Overall Steps per Second: 10,024.01952

Timestep Collection Time: 2.51377
Timestep Consumption Time: 2.47984
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.99361

Cumulative Model Updates: 227,640
Cumulative Timesteps: 1,899,111,184

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 1899111184...
Checkpoint 1899111184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,340.58727
Policy Entropy: 2.04507
Value Function Loss: 0.02430

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07799
Policy Update Magnitude: 0.31466
Value Function Update Magnitude: 0.34028

Collected Steps per Second: 19,518.40203
Overall Steps per Second: 9,780.90721

Timestep Collection Time: 2.56394
Timestep Consumption Time: 2.55256
PPO Batch Consumption Time: 0.29960
Total Iteration Time: 5.11650

Cumulative Model Updates: 227,646
Cumulative Timesteps: 1,899,161,228

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,329.59377
Policy Entropy: 2.06654
Value Function Loss: 0.02505

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07691
Policy Update Magnitude: 0.30975
Value Function Update Magnitude: 0.31910

Collected Steps per Second: 20,489.31537
Overall Steps per Second: 9,934.25855

Timestep Collection Time: 2.44049
Timestep Consumption Time: 2.59300
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 5.03349

Cumulative Model Updates: 227,652
Cumulative Timesteps: 1,899,211,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1899211232...
Checkpoint 1899211232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,892.99860
Policy Entropy: 2.05204
Value Function Loss: 0.02530

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07511
Policy Update Magnitude: 0.30240
Value Function Update Magnitude: 0.25109

Collected Steps per Second: 18,339.73000
Overall Steps per Second: 9,499.53693

Timestep Collection Time: 2.72676
Timestep Consumption Time: 2.53750
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 5.26426

Cumulative Model Updates: 227,658
Cumulative Timesteps: 1,899,261,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,485.28145
Policy Entropy: 2.05814
Value Function Loss: 0.02305

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07563
Policy Update Magnitude: 0.29808
Value Function Update Magnitude: 0.21673

Collected Steps per Second: 20,140.07698
Overall Steps per Second: 9,792.71870

Timestep Collection Time: 2.48351
Timestep Consumption Time: 2.62417
PPO Batch Consumption Time: 0.30152
Total Iteration Time: 5.10767

Cumulative Model Updates: 227,664
Cumulative Timesteps: 1,899,311,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1899311258...
Checkpoint 1899311258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,435.84125
Policy Entropy: 2.02730
Value Function Loss: 0.02346

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.29720
Value Function Update Magnitude: 0.25899

Collected Steps per Second: 19,209.28362
Overall Steps per Second: 9,611.57822

Timestep Collection Time: 2.60416
Timestep Consumption Time: 2.60040
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 5.20456

Cumulative Model Updates: 227,670
Cumulative Timesteps: 1,899,361,282

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,641.97525
Policy Entropy: 2.01600
Value Function Loss: 0.02253

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07236
Policy Update Magnitude: 0.30193
Value Function Update Magnitude: 0.30352

Collected Steps per Second: 19,030.91527
Overall Steps per Second: 9,514.10296

Timestep Collection Time: 2.62878
Timestep Consumption Time: 2.62952
PPO Batch Consumption Time: 0.30651
Total Iteration Time: 5.25830

Cumulative Model Updates: 227,676
Cumulative Timesteps: 1,899,411,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1899411310...
Checkpoint 1899411310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,805.63180
Policy Entropy: 2.01042
Value Function Loss: 0.02323

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07294
Policy Update Magnitude: 0.30536
Value Function Update Magnitude: 0.31996

Collected Steps per Second: 18,749.78539
Overall Steps per Second: 9,629.66657

Timestep Collection Time: 2.66766
Timestep Consumption Time: 2.52650
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 5.19416

Cumulative Model Updates: 227,682
Cumulative Timesteps: 1,899,461,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,535.94720
Policy Entropy: 2.02917
Value Function Loss: 0.02315

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07193
Policy Update Magnitude: 0.31115
Value Function Update Magnitude: 0.32510

Collected Steps per Second: 19,703.98114
Overall Steps per Second: 9,969.62212

Timestep Collection Time: 2.53949
Timestep Consumption Time: 2.47956
PPO Batch Consumption Time: 0.29748
Total Iteration Time: 5.01905

Cumulative Model Updates: 227,688
Cumulative Timesteps: 1,899,511,366

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1899511366...
Checkpoint 1899511366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,824.10801
Policy Entropy: 2.03467
Value Function Loss: 0.02022

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07099
Policy Update Magnitude: 0.29935
Value Function Update Magnitude: 0.31546

Collected Steps per Second: 19,573.41760
Overall Steps per Second: 9,750.31689

Timestep Collection Time: 2.55704
Timestep Consumption Time: 2.57613
PPO Batch Consumption Time: 0.29794
Total Iteration Time: 5.13317

Cumulative Model Updates: 227,694
Cumulative Timesteps: 1,899,561,416

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,873.85208
Policy Entropy: 2.04650
Value Function Loss: 0.02553

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.29966
Value Function Update Magnitude: 0.28669

Collected Steps per Second: 20,088.02794
Overall Steps per Second: 9,928.86214

Timestep Collection Time: 2.49094
Timestep Consumption Time: 2.54871
PPO Batch Consumption Time: 0.30289
Total Iteration Time: 5.03965

Cumulative Model Updates: 227,700
Cumulative Timesteps: 1,899,611,454

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1899611454...
Checkpoint 1899611454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,194.99032
Policy Entropy: 2.04421
Value Function Loss: 0.02638

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07227
Policy Update Magnitude: 0.30504
Value Function Update Magnitude: 0.27912

Collected Steps per Second: 20,816.54881
Overall Steps per Second: 10,004.05167

Timestep Collection Time: 2.40251
Timestep Consumption Time: 2.59666
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.99917

Cumulative Model Updates: 227,706
Cumulative Timesteps: 1,899,661,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,100.38884
Policy Entropy: 2.05374
Value Function Loss: 0.02903

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07628
Policy Update Magnitude: 0.30800
Value Function Update Magnitude: 0.30162

Collected Steps per Second: 19,509.29957
Overall Steps per Second: 9,728.64455

Timestep Collection Time: 2.56339
Timestep Consumption Time: 2.57710
PPO Batch Consumption Time: 0.29782
Total Iteration Time: 5.14049

Cumulative Model Updates: 227,712
Cumulative Timesteps: 1,899,711,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1899711476...
Checkpoint 1899711476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,184.96815
Policy Entropy: 2.04742
Value Function Loss: 0.02480

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.30481
Value Function Update Magnitude: 0.31137

Collected Steps per Second: 18,865.01905
Overall Steps per Second: 9,703.24162

Timestep Collection Time: 2.65147
Timestep Consumption Time: 2.50351
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 5.15498

Cumulative Model Updates: 227,718
Cumulative Timesteps: 1,899,761,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,248.64400
Policy Entropy: 2.03352
Value Function Loss: 0.02672

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08633
Policy Update Magnitude: 0.30597
Value Function Update Magnitude: 0.27626

Collected Steps per Second: 21,389.31089
Overall Steps per Second: 10,276.05151

Timestep Collection Time: 2.33930
Timestep Consumption Time: 2.52989
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.86919

Cumulative Model Updates: 227,724
Cumulative Timesteps: 1,899,811,532

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1899811532...
Checkpoint 1899811532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,988.29497
Policy Entropy: 2.01771
Value Function Loss: 0.02655

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.31299
Value Function Update Magnitude: 0.29444

Collected Steps per Second: 20,124.02914
Overall Steps per Second: 9,982.75153

Timestep Collection Time: 2.48648
Timestep Consumption Time: 2.52597
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 5.01245

Cumulative Model Updates: 227,730
Cumulative Timesteps: 1,899,861,570

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,605.47219
Policy Entropy: 2.03299
Value Function Loss: 0.02725

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.31478
Value Function Update Magnitude: 0.31464

Collected Steps per Second: 20,294.94261
Overall Steps per Second: 10,243.56162

Timestep Collection Time: 2.46416
Timestep Consumption Time: 2.41793
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.88209

Cumulative Model Updates: 227,736
Cumulative Timesteps: 1,899,911,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1899911580...
Checkpoint 1899911580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,851.34032
Policy Entropy: 2.04618
Value Function Loss: 0.02500

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.31205
Value Function Update Magnitude: 0.33337

Collected Steps per Second: 18,097.32122
Overall Steps per Second: 9,428.11182

Timestep Collection Time: 2.76417
Timestep Consumption Time: 2.54167
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 5.30583

Cumulative Model Updates: 227,742
Cumulative Timesteps: 1,899,961,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,482.55458
Policy Entropy: 2.05126
Value Function Loss: 0.02306

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.08948
Policy Update Magnitude: 0.29906
Value Function Update Magnitude: 0.33899

Collected Steps per Second: 21,019.56399
Overall Steps per Second: 9,803.06174

Timestep Collection Time: 2.37969
Timestep Consumption Time: 2.72280
PPO Batch Consumption Time: 0.32088
Total Iteration Time: 5.10249

Cumulative Model Updates: 227,748
Cumulative Timesteps: 1,900,011,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1900011624...
Checkpoint 1900011624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,033.66649
Policy Entropy: 2.04852
Value Function Loss: 0.02065

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.29191
Value Function Update Magnitude: 0.27895

Collected Steps per Second: 19,021.99407
Overall Steps per Second: 9,664.22519

Timestep Collection Time: 2.62854
Timestep Consumption Time: 2.54518
PPO Batch Consumption Time: 0.30200
Total Iteration Time: 5.17372

Cumulative Model Updates: 227,754
Cumulative Timesteps: 1,900,061,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,868.50032
Policy Entropy: 2.03457
Value Function Loss: 0.02098

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.29074
Value Function Update Magnitude: 0.27172

Collected Steps per Second: 20,367.28198
Overall Steps per Second: 9,979.03425

Timestep Collection Time: 2.45639
Timestep Consumption Time: 2.55712
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 5.01351

Cumulative Model Updates: 227,760
Cumulative Timesteps: 1,900,111,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1900111654...
Checkpoint 1900111654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,539.40406
Policy Entropy: 2.02743
Value Function Loss: 0.02447

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08280
Policy Update Magnitude: 0.30479
Value Function Update Magnitude: 0.31896

Collected Steps per Second: 19,838.78951
Overall Steps per Second: 9,603.83942

Timestep Collection Time: 2.52142
Timestep Consumption Time: 2.68712
PPO Batch Consumption Time: 0.32324
Total Iteration Time: 5.20854

Cumulative Model Updates: 227,766
Cumulative Timesteps: 1,900,161,676

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,169.96766
Policy Entropy: 2.02455
Value Function Loss: 0.02497

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.30334
Value Function Update Magnitude: 0.35165

Collected Steps per Second: 20,233.27630
Overall Steps per Second: 10,075.02389

Timestep Collection Time: 2.47128
Timestep Consumption Time: 2.49169
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.96297

Cumulative Model Updates: 227,772
Cumulative Timesteps: 1,900,211,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1900211678...
Checkpoint 1900211678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,621.57402
Policy Entropy: 2.03259
Value Function Loss: 0.02416

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.30098
Value Function Update Magnitude: 0.34786

Collected Steps per Second: 19,149.03311
Overall Steps per Second: 9,754.84377

Timestep Collection Time: 2.61183
Timestep Consumption Time: 2.51526
PPO Batch Consumption Time: 0.30149
Total Iteration Time: 5.12709

Cumulative Model Updates: 227,778
Cumulative Timesteps: 1,900,261,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,552.42071
Policy Entropy: 2.02340
Value Function Loss: 0.02668

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08025
Policy Update Magnitude: 0.31328
Value Function Update Magnitude: 0.36091

Collected Steps per Second: 18,984.13474
Overall Steps per Second: 9,538.23137

Timestep Collection Time: 2.63483
Timestep Consumption Time: 2.60933
PPO Batch Consumption Time: 0.30903
Total Iteration Time: 5.24416

Cumulative Model Updates: 227,784
Cumulative Timesteps: 1,900,311,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1900311712...
Checkpoint 1900311712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,682.10111
Policy Entropy: 2.03113
Value Function Loss: 0.02463

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.32232
Value Function Update Magnitude: 0.37672

Collected Steps per Second: 18,615.04317
Overall Steps per Second: 9,793.96276

Timestep Collection Time: 2.68686
Timestep Consumption Time: 2.41996
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 5.10682

Cumulative Model Updates: 227,790
Cumulative Timesteps: 1,900,361,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,222.85052
Policy Entropy: 2.01632
Value Function Loss: 0.02528

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.31816
Value Function Update Magnitude: 0.37435

Collected Steps per Second: 20,371.15910
Overall Steps per Second: 10,066.80964

Timestep Collection Time: 2.45543
Timestep Consumption Time: 2.51337
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.96880

Cumulative Model Updates: 227,796
Cumulative Timesteps: 1,900,411,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1900411748...
Checkpoint 1900411748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,617.69347
Policy Entropy: 2.03692
Value Function Loss: 0.02354

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.08935
Policy Update Magnitude: 0.31100
Value Function Update Magnitude: 0.34479

Collected Steps per Second: 19,838.31303
Overall Steps per Second: 9,934.67160

Timestep Collection Time: 2.52108
Timestep Consumption Time: 2.51321
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 5.03429

Cumulative Model Updates: 227,802
Cumulative Timesteps: 1,900,461,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,829.00969
Policy Entropy: 2.03635
Value Function Loss: 0.02276

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.30132
Value Function Update Magnitude: 0.34645

Collected Steps per Second: 20,091.29081
Overall Steps per Second: 9,809.73393

Timestep Collection Time: 2.48864
Timestep Consumption Time: 2.60834
PPO Batch Consumption Time: 0.30906
Total Iteration Time: 5.09698

Cumulative Model Updates: 227,808
Cumulative Timesteps: 1,900,511,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1900511762...
Checkpoint 1900511762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,534.77569
Policy Entropy: 2.03235
Value Function Loss: 0.02163

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08873
Policy Update Magnitude: 0.29384
Value Function Update Magnitude: 0.33609

Collected Steps per Second: 21,279.92886
Overall Steps per Second: 10,469.12711

Timestep Collection Time: 2.34973
Timestep Consumption Time: 2.42641
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.77614

Cumulative Model Updates: 227,814
Cumulative Timesteps: 1,900,561,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,003.28564
Policy Entropy: 2.02404
Value Function Loss: 0.02257

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.29999
Value Function Update Magnitude: 0.31941

Collected Steps per Second: 21,249.65653
Overall Steps per Second: 10,328.72883

Timestep Collection Time: 2.35392
Timestep Consumption Time: 2.48888
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.84280

Cumulative Model Updates: 227,820
Cumulative Timesteps: 1,900,611,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1900611784...
Checkpoint 1900611784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,528.13488
Policy Entropy: 2.01595
Value Function Loss: 0.02499

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.07929
Policy Update Magnitude: 0.31457
Value Function Update Magnitude: 0.31522

Collected Steps per Second: 20,463.96131
Overall Steps per Second: 10,198.20732

Timestep Collection Time: 2.44508
Timestep Consumption Time: 2.46127
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.90635

Cumulative Model Updates: 227,826
Cumulative Timesteps: 1,900,661,820

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,495.54351
Policy Entropy: 2.02629
Value Function Loss: 0.02434

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08242
Policy Update Magnitude: 0.31210
Value Function Update Magnitude: 0.32136

Collected Steps per Second: 20,751.67625
Overall Steps per Second: 10,068.83774

Timestep Collection Time: 2.41079
Timestep Consumption Time: 2.55780
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.96860

Cumulative Model Updates: 227,832
Cumulative Timesteps: 1,900,711,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1900711848...
Checkpoint 1900711848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,025.42409
Policy Entropy: 2.02622
Value Function Loss: 0.02453

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.30951
Value Function Update Magnitude: 0.32952

Collected Steps per Second: 20,637.47850
Overall Steps per Second: 10,136.70364

Timestep Collection Time: 2.42365
Timestep Consumption Time: 2.51070
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.93435

Cumulative Model Updates: 227,838
Cumulative Timesteps: 1,900,761,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,740.27601
Policy Entropy: 2.02203
Value Function Loss: 0.02659

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07240
Policy Update Magnitude: 0.31002
Value Function Update Magnitude: 0.29609

Collected Steps per Second: 20,676.46113
Overall Steps per Second: 9,952.09478

Timestep Collection Time: 2.41927
Timestep Consumption Time: 2.60701
PPO Batch Consumption Time: 0.30132
Total Iteration Time: 5.02628

Cumulative Model Updates: 227,844
Cumulative Timesteps: 1,900,811,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1900811888...
Checkpoint 1900811888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,763.44274
Policy Entropy: 2.00865
Value Function Loss: 0.02598

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.31464
Value Function Update Magnitude: 0.25889

Collected Steps per Second: 18,323.91175
Overall Steps per Second: 9,257.13766

Timestep Collection Time: 2.72889
Timestep Consumption Time: 2.67278
PPO Batch Consumption Time: 0.31563
Total Iteration Time: 5.40167

Cumulative Model Updates: 227,850
Cumulative Timesteps: 1,900,861,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1900861892...
Checkpoint 1900861892 saved!
