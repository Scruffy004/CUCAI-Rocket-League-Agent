{"x_vel":-0.4677233065280698,"Policy Update Magnitude":1.0429548025131226,"PPO Batch Consumption Time":0.3058517376581828,"Policy Entropy":3.5727852980295816,"Timesteps Collected":50016,"_runtime":803192.9151403,"_timestamp":1.7410710232085052e+09,"Overall Steps per Second":9696.797489937639,"Policy Reward":4194.425734051803,"Timestep Consumption Time":2.585449800000106,"Timestep Collection Time":2.5725417999999536,"Value Function Update Magnitude":0.5027661919593811,"SB3 Clip Fraction":0.17227999617656073,"y_vel":-16.25339900489525,"Total Iteration Time":5.157991600000059,"Mean KL Divergence":0.015429580894609293,"_wandb":{"runtime":803193},"Value Function Loss":0.41651756564776105,"Cumulative Model Updates":152160,"_step":333292,"Cumulative Timesteps":1269002832,"z_vel":1.452379389252497,"Collected Steps per Second":19442.249684728507}