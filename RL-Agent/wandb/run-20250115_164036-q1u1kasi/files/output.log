Created new wandb run! q1u1kasi
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00865
Policy Entropy: 4.49884
Value Function Loss: nan

Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10552
Value Function Update Magnitude: 0.10549

Collected Steps per Second: 14,588.65628
Overall Steps per Second: 7,794.48480

Timestep Collection Time: 3.42828
Timestep Consumption Time: 2.98831
PPO Batch Consumption Time: 2.02051
Total Iteration Time: 6.41659

Cumulative Model Updates: 1
Cumulative Timesteps: 50,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05002
Policy Entropy: 4.49884
Value Function Loss: 0.41219

Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08492
Value Function Update Magnitude: 0.08107

Collected Steps per Second: 22,286.31709
Overall Steps per Second: 14,623.72226

Timestep Collection Time: 2.24362
Timestep Consumption Time: 1.17562
PPO Batch Consumption Time: 0.37632
Total Iteration Time: 3.41924

Cumulative Model Updates: 2
Cumulative Timesteps: 100,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 100016...
Checkpoint 100016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00418
Policy Entropy: 4.49879
Value Function Loss: 0.52473

Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.13551
Value Function Update Magnitude: 0.16039

Collected Steps per Second: 22,429.29027
Overall Steps per Second: 13,555.46362

Timestep Collection Time: 2.22985
Timestep Consumption Time: 1.45973
PPO Batch Consumption Time: 0.36788
Total Iteration Time: 3.68958

Cumulative Model Updates: 4
Cumulative Timesteps: 150,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05578
Policy Entropy: 4.49867
Value Function Loss: 1.02064

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.17426
Value Function Update Magnitude: 0.23823

Collected Steps per Second: 23,448.17704
Overall Steps per Second: 12,337.47821

Timestep Collection Time: 2.13279
Timestep Consumption Time: 1.92071
PPO Batch Consumption Time: 0.37012
Total Iteration Time: 4.05350

Cumulative Model Updates: 7
Cumulative Timesteps: 200,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 200040...
Checkpoint 200040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03566
Policy Entropy: 4.49842
Value Function Loss: 1.15485

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.16272
Value Function Update Magnitude: 0.24185

Collected Steps per Second: 21,194.21069
Overall Steps per Second: 11,699.25529

Timestep Collection Time: 2.35913
Timestep Consumption Time: 1.91464
PPO Batch Consumption Time: 0.36344
Total Iteration Time: 4.27378

Cumulative Model Updates: 10
Cumulative Timesteps: 250,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03399
Policy Entropy: 4.49802
Value Function Loss: 0.88727

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.15797
Value Function Update Magnitude: 0.24429

Collected Steps per Second: 22,033.70003
Overall Steps per Second: 11,846.60613

Timestep Collection Time: 2.27043
Timestep Consumption Time: 1.95238
PPO Batch Consumption Time: 0.36318
Total Iteration Time: 4.22281

Cumulative Model Updates: 13
Cumulative Timesteps: 300,066

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 300066...
Checkpoint 300066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05999
Policy Entropy: 4.49739
Value Function Loss: 0.39788

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.14263
Value Function Update Magnitude: 0.22621

Collected Steps per Second: 24,115.73741
Overall Steps per Second: 12,242.26788

Timestep Collection Time: 2.07433
Timestep Consumption Time: 2.01184
PPO Batch Consumption Time: 0.38501
Total Iteration Time: 4.08617

Cumulative Model Updates: 16
Cumulative Timesteps: 350,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01115
Policy Entropy: 4.49659
Value Function Loss: 0.03098

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11650
Value Function Update Magnitude: 0.15899

Collected Steps per Second: 22,668.52363
Overall Steps per Second: 12,479.84329

Timestep Collection Time: 2.20711
Timestep Consumption Time: 1.80191
PPO Batch Consumption Time: 0.36153
Total Iteration Time: 4.00902

Cumulative Model Updates: 19
Cumulative Timesteps: 400,122

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 400122...
Checkpoint 400122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01761
Policy Entropy: 4.49572
Value Function Loss: 0.02491

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09140
Value Function Update Magnitude: 0.14220

Collected Steps per Second: 23,017.79448
Overall Steps per Second: 12,228.78337

Timestep Collection Time: 2.17423
Timestep Consumption Time: 1.91824
PPO Batch Consumption Time: 0.36144
Total Iteration Time: 4.09248

Cumulative Model Updates: 22
Cumulative Timesteps: 450,168

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00759
Policy Entropy: 4.49487
Value Function Loss: 0.02100

Mean KL Divergence: 0.00017
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07447
Value Function Update Magnitude: 0.14377

Collected Steps per Second: 24,318.17688
Overall Steps per Second: 12,868.14697

Timestep Collection Time: 2.05706
Timestep Consumption Time: 1.83037
PPO Batch Consumption Time: 0.36300
Total Iteration Time: 3.88743

Cumulative Model Updates: 25
Cumulative Timesteps: 500,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 500192...
Checkpoint 500192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04923
Policy Entropy: 4.49407
Value Function Loss: 0.01932

Mean KL Divergence: 0.00013
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06285
Value Function Update Magnitude: 0.13338

Collected Steps per Second: 23,332.80858
Overall Steps per Second: 12,213.90512

Timestep Collection Time: 2.14325
Timestep Consumption Time: 1.95110
PPO Batch Consumption Time: 0.36927
Total Iteration Time: 4.09435

Cumulative Model Updates: 28
Cumulative Timesteps: 550,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00502
Policy Entropy: 4.49333
Value Function Loss: 0.01830

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.11680

Collected Steps per Second: 22,067.76356
Overall Steps per Second: 11,982.24548

Timestep Collection Time: 2.26665
Timestep Consumption Time: 1.90785
PPO Batch Consumption Time: 0.36281
Total Iteration Time: 4.17451

Cumulative Model Updates: 31
Cumulative Timesteps: 600,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 600220...
Checkpoint 600220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00532
Policy Entropy: 4.49271
Value Function Loss: 0.01325

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.09722

Collected Steps per Second: 19,935.16728
Overall Steps per Second: 11,119.16918

Timestep Collection Time: 2.50994
Timestep Consumption Time: 1.99004
PPO Batch Consumption Time: 0.36806
Total Iteration Time: 4.49998

Cumulative Model Updates: 34
Cumulative Timesteps: 650,256

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04294
Policy Entropy: 4.49224
Value Function Loss: 0.02365

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.08568

Collected Steps per Second: 23,338.44558
Overall Steps per Second: 12,324.43944

Timestep Collection Time: 2.14342
Timestep Consumption Time: 1.91551
PPO Batch Consumption Time: 0.36182
Total Iteration Time: 4.05893

Cumulative Model Updates: 37
Cumulative Timesteps: 700,280

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 700280...
Checkpoint 700280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00120
Policy Entropy: 4.49190
Value Function Loss: 0.03162

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.08250

Collected Steps per Second: 23,060.67003
Overall Steps per Second: 12,534.32405

Timestep Collection Time: 2.16906
Timestep Consumption Time: 1.82158
PPO Batch Consumption Time: 0.36130
Total Iteration Time: 3.99064

Cumulative Model Updates: 40
Cumulative Timesteps: 750,300

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04466
Policy Entropy: 4.49158
Value Function Loss: 0.04793

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06668
Value Function Update Magnitude: 0.08633

Collected Steps per Second: 23,802.62301
Overall Steps per Second: 12,408.57928

Timestep Collection Time: 2.10086
Timestep Consumption Time: 1.92909
PPO Batch Consumption Time: 0.36209
Total Iteration Time: 4.02995

Cumulative Model Updates: 43
Cumulative Timesteps: 800,306

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 800306...
Checkpoint 800306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00108
Policy Entropy: 4.49126
Value Function Loss: 0.06940

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07250
Value Function Update Magnitude: 0.10012

Collected Steps per Second: 23,467.99795
Overall Steps per Second: 12,393.55839

Timestep Collection Time: 2.13303
Timestep Consumption Time: 1.90600
PPO Batch Consumption Time: 0.36218
Total Iteration Time: 4.03903

Cumulative Model Updates: 46
Cumulative Timesteps: 850,364

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00964
Policy Entropy: 4.49101
Value Function Loss: 0.09609

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08060
Value Function Update Magnitude: 0.12403

Collected Steps per Second: 25,021.81405
Overall Steps per Second: 12,801.98919

Timestep Collection Time: 1.99906
Timestep Consumption Time: 1.90815
PPO Batch Consumption Time: 0.36226
Total Iteration Time: 3.90721

Cumulative Model Updates: 49
Cumulative Timesteps: 900,384

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 900384...
Checkpoint 900384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11369
Policy Entropy: 4.49068
Value Function Loss: 0.12362

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09557
Value Function Update Magnitude: 0.15347

Collected Steps per Second: 23,883.10270
Overall Steps per Second: 12,201.64075

Timestep Collection Time: 2.09387
Timestep Consumption Time: 2.00460
PPO Batch Consumption Time: 0.37655
Total Iteration Time: 4.09847

Cumulative Model Updates: 52
Cumulative Timesteps: 950,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00778
Policy Entropy: 4.49019
Value Function Loss: 0.08998

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10337
Value Function Update Magnitude: 0.16394

Collected Steps per Second: 22,106.56685
Overall Steps per Second: 12,178.14283

Timestep Collection Time: 2.26385
Timestep Consumption Time: 1.84564
PPO Batch Consumption Time: 0.36461
Total Iteration Time: 4.10949

Cumulative Model Updates: 55
Cumulative Timesteps: 1,000,438

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1000438...
Checkpoint 1000438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00847
Policy Entropy: 4.48929
Value Function Loss: 0.05590

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10360
Value Function Update Magnitude: 0.14124

Collected Steps per Second: 21,578.25516
Overall Steps per Second: 11,664.07238

Timestep Collection Time: 2.31715
Timestep Consumption Time: 1.96952
PPO Batch Consumption Time: 0.36313
Total Iteration Time: 4.28667

Cumulative Model Updates: 58
Cumulative Timesteps: 1,050,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02683
Policy Entropy: 4.48810
Value Function Loss: 0.01532

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08872
Value Function Update Magnitude: 0.09174

Collected Steps per Second: 21,300.57445
Overall Steps per Second: 11,743.54745

Timestep Collection Time: 2.34951
Timestep Consumption Time: 1.91206
PPO Batch Consumption Time: 0.36971
Total Iteration Time: 4.26157

Cumulative Model Updates: 61
Cumulative Timesteps: 1,100,484

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1100484...
Checkpoint 1100484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02352
Policy Entropy: 4.48706
Value Function Loss: 0.01748

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07285
Value Function Update Magnitude: 0.06968

Collected Steps per Second: 24,106.51874
Overall Steps per Second: 12,508.00337

Timestep Collection Time: 2.07620
Timestep Consumption Time: 1.92524
PPO Batch Consumption Time: 0.36703
Total Iteration Time: 4.00144

Cumulative Model Updates: 64
Cumulative Timesteps: 1,150,534

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04122
Policy Entropy: 4.48617
Value Function Loss: 0.01661

Mean KL Divergence: 0.00019
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06315
Value Function Update Magnitude: 0.06495

Collected Steps per Second: 22,834.23196
Overall Steps per Second: 12,286.11806

Timestep Collection Time: 2.19145
Timestep Consumption Time: 1.88144
PPO Batch Consumption Time: 0.35717
Total Iteration Time: 4.07289

Cumulative Model Updates: 67
Cumulative Timesteps: 1,200,574

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1200574...
Checkpoint 1200574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07337
Policy Entropy: 4.48549
Value Function Loss: 0.04875

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06614
Value Function Update Magnitude: 0.05904

Collected Steps per Second: 24,862.54360
Overall Steps per Second: 13,028.00218

Timestep Collection Time: 2.01218
Timestep Consumption Time: 1.82785
PPO Batch Consumption Time: 0.36810
Total Iteration Time: 3.84004

Cumulative Model Updates: 70
Cumulative Timesteps: 1,250,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00266
Policy Entropy: 4.48488
Value Function Loss: 0.04763

Mean KL Divergence: 0.00013
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07634
Value Function Update Magnitude: 0.06216

Collected Steps per Second: 22,839.75540
Overall Steps per Second: 12,104.53095

Timestep Collection Time: 2.18969
Timestep Consumption Time: 1.94199
PPO Batch Consumption Time: 0.36492
Total Iteration Time: 4.13168

Cumulative Model Updates: 73
Cumulative Timesteps: 1,300,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1300614...
Checkpoint 1300614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00586
Policy Entropy: 4.48400
Value Function Loss: 0.04687

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08855
Value Function Update Magnitude: 0.06670

Collected Steps per Second: 19,750.11885
Overall Steps per Second: 11,280.33977

Timestep Collection Time: 2.53173
Timestep Consumption Time: 1.90094
PPO Batch Consumption Time: 0.36150
Total Iteration Time: 4.43267

Cumulative Model Updates: 76
Cumulative Timesteps: 1,350,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06720
Policy Entropy: 4.48299
Value Function Loss: 0.01521

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08830
Value Function Update Magnitude: 0.05834

Collected Steps per Second: 22,534.86575
Overall Steps per Second: 12,100.47529

Timestep Collection Time: 2.22083
Timestep Consumption Time: 1.91505
PPO Batch Consumption Time: 0.36495
Total Iteration Time: 4.13587

Cumulative Model Updates: 79
Cumulative Timesteps: 1,400,662

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1400662...
Checkpoint 1400662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00029
Policy Entropy: 4.48199
Value Function Loss: 0.01526

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07729
Value Function Update Magnitude: 0.05019

Collected Steps per Second: 24,270.36729
Overall Steps per Second: 12,656.41245

Timestep Collection Time: 2.06021
Timestep Consumption Time: 1.89052
PPO Batch Consumption Time: 0.35703
Total Iteration Time: 3.95072

Cumulative Model Updates: 82
Cumulative Timesteps: 1,450,664

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03199
Policy Entropy: 4.48074
Value Function Loss: 0.01636

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07418
Value Function Update Magnitude: 0.05197

Collected Steps per Second: 23,904.77355
Overall Steps per Second: 12,381.28251

Timestep Collection Time: 2.09247
Timestep Consumption Time: 1.94750
PPO Batch Consumption Time: 0.36501
Total Iteration Time: 4.03997

Cumulative Model Updates: 85
Cumulative Timesteps: 1,500,684

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1500684...
Checkpoint 1500684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02166
Policy Entropy: 4.47907
Value Function Loss: 0.01680

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07547
Value Function Update Magnitude: 0.05293

Collected Steps per Second: 19,653.65628
Overall Steps per Second: 11,096.99264

Timestep Collection Time: 2.54456
Timestep Consumption Time: 1.96206
PPO Batch Consumption Time: 0.36087
Total Iteration Time: 4.50663

Cumulative Model Updates: 88
Cumulative Timesteps: 1,550,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00044
Policy Entropy: 4.47710
Value Function Loss: 0.00706

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06999
Value Function Update Magnitude: 0.05413

Collected Steps per Second: 23,626.48558
Overall Steps per Second: 12,692.08604

Timestep Collection Time: 2.11720
Timestep Consumption Time: 1.82400
PPO Batch Consumption Time: 0.36136
Total Iteration Time: 3.94120

Cumulative Model Updates: 91
Cumulative Timesteps: 1,600,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1600716...
Checkpoint 1600716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03118
Policy Entropy: 4.47564
Value Function Loss: 0.03689

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06944
Value Function Update Magnitude: 0.04830

Collected Steps per Second: 24,032.12278
Overall Steps per Second: 12,588.31813

Timestep Collection Time: 2.08121
Timestep Consumption Time: 1.89199
PPO Batch Consumption Time: 0.35543
Total Iteration Time: 3.97321

Cumulative Model Updates: 94
Cumulative Timesteps: 1,650,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00229
Policy Entropy: 4.47547
Value Function Loss: 0.03718

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08340
Value Function Update Magnitude: 0.04757

Collected Steps per Second: 24,452.57879
Overall Steps per Second: 12,741.80461

Timestep Collection Time: 2.04576
Timestep Consumption Time: 1.88022
PPO Batch Consumption Time: 0.36139
Total Iteration Time: 3.92597

Cumulative Model Updates: 97
Cumulative Timesteps: 1,700,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1700756...
Checkpoint 1700756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04983
Policy Entropy: 4.47559
Value Function Loss: 0.06825

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09881
Value Function Update Magnitude: 0.06009

Collected Steps per Second: 22,482.46937
Overall Steps per Second: 12,183.65381

Timestep Collection Time: 2.22458
Timestep Consumption Time: 1.88043
PPO Batch Consumption Time: 0.35917
Total Iteration Time: 4.10501

Cumulative Model Updates: 100
Cumulative Timesteps: 1,750,770

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00771
Policy Entropy: 4.47593
Value Function Loss: 0.03853

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10240
Value Function Update Magnitude: 0.06920

Collected Steps per Second: 23,929.99021
Overall Steps per Second: 12,419.21224

Timestep Collection Time: 2.09035
Timestep Consumption Time: 1.93744
PPO Batch Consumption Time: 0.36046
Total Iteration Time: 4.02779

Cumulative Model Updates: 103
Cumulative Timesteps: 1,800,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1800792...
Checkpoint 1800792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06245
Policy Entropy: 4.47655
Value Function Loss: 0.04910

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10425
Value Function Update Magnitude: 0.07644

Collected Steps per Second: 24,983.78826
Overall Steps per Second: 12,849.83760

Timestep Collection Time: 2.00210
Timestep Consumption Time: 1.89056
PPO Batch Consumption Time: 0.35790
Total Iteration Time: 3.89266

Cumulative Model Updates: 106
Cumulative Timesteps: 1,850,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04572
Policy Entropy: 4.47746
Value Function Loss: 0.04863

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09778
Value Function Update Magnitude: 0.07855

Collected Steps per Second: 24,109.46025
Overall Steps per Second: 12,476.82766

Timestep Collection Time: 2.07446
Timestep Consumption Time: 1.93410
PPO Batch Consumption Time: 0.36171
Total Iteration Time: 4.00855

Cumulative Model Updates: 109
Cumulative Timesteps: 1,900,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1900826...
Checkpoint 1900826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03267
Policy Entropy: 4.47811
Value Function Loss: 0.07776

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10387
Value Function Update Magnitude: 0.09449

Collected Steps per Second: 24,036.71142
Overall Steps per Second: 12,772.14476

Timestep Collection Time: 2.08090
Timestep Consumption Time: 1.83528
PPO Batch Consumption Time: 0.35612
Total Iteration Time: 3.91618

Cumulative Model Updates: 112
Cumulative Timesteps: 1,950,844

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05450
Policy Entropy: 4.47832
Value Function Loss: 0.09641

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11145
Value Function Update Magnitude: 0.11375

Collected Steps per Second: 21,026.72579
Overall Steps per Second: 11,263.12963

Timestep Collection Time: 2.37850
Timestep Consumption Time: 2.06183
PPO Batch Consumption Time: 0.36462
Total Iteration Time: 4.44033

Cumulative Model Updates: 115
Cumulative Timesteps: 2,000,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2000856...
Checkpoint 2000856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05146
Policy Entropy: 4.47742
Value Function Loss: 0.09762

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11840
Value Function Update Magnitude: 0.10578

Collected Steps per Second: 20,766.56611
Overall Steps per Second: 11,444.73251

Timestep Collection Time: 2.40868
Timestep Consumption Time: 1.96189
PPO Batch Consumption Time: 0.36573
Total Iteration Time: 4.37057

Cumulative Model Updates: 118
Cumulative Timesteps: 2,050,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05660
Policy Entropy: 4.47586
Value Function Loss: 0.07992

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.12064
Value Function Update Magnitude: 0.09414

Collected Steps per Second: 25,673.99893
Overall Steps per Second: 13,047.64849

Timestep Collection Time: 1.94820
Timestep Consumption Time: 1.88529
PPO Batch Consumption Time: 0.36267
Total Iteration Time: 3.83349

Cumulative Model Updates: 121
Cumulative Timesteps: 2,100,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2100894...
Checkpoint 2100894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00205
Policy Entropy: 4.47357
Value Function Loss: 0.06071

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11808
Value Function Update Magnitude: 0.08557

Collected Steps per Second: 24,633.35706
Overall Steps per Second: 12,747.86229

Timestep Collection Time: 2.03155
Timestep Consumption Time: 1.89412
PPO Batch Consumption Time: 0.35977
Total Iteration Time: 3.92568

Cumulative Model Updates: 124
Cumulative Timesteps: 2,150,938

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03769
Policy Entropy: 4.47046
Value Function Loss: 0.06167

Mean KL Divergence: 0.00069
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10944
Value Function Update Magnitude: 0.08092

Collected Steps per Second: 22,330.53313
Overall Steps per Second: 12,182.21989

Timestep Collection Time: 2.24034
Timestep Consumption Time: 1.86630
PPO Batch Consumption Time: 0.35881
Total Iteration Time: 4.10664

Cumulative Model Updates: 127
Cumulative Timesteps: 2,200,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2200966...
Checkpoint 2200966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01213
Policy Entropy: 4.46591
Value Function Loss: 0.05981

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10941
Value Function Update Magnitude: 0.07591

Collected Steps per Second: 23,414.49562
Overall Steps per Second: 12,341.97977

Timestep Collection Time: 2.13543
Timestep Consumption Time: 1.91578
PPO Batch Consumption Time: 0.36309
Total Iteration Time: 4.05121

Cumulative Model Updates: 130
Cumulative Timesteps: 2,250,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03164
Policy Entropy: 4.45928
Value Function Loss: 0.07837

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11651
Value Function Update Magnitude: 0.08135

Collected Steps per Second: 23,608.11288
Overall Steps per Second: 12,530.02852

Timestep Collection Time: 2.11842
Timestep Consumption Time: 1.87295
PPO Batch Consumption Time: 0.35793
Total Iteration Time: 3.99137

Cumulative Model Updates: 133
Cumulative Timesteps: 2,300,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2300978...
Checkpoint 2300978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02336
Policy Entropy: 4.45053
Value Function Loss: 0.07623

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.00158
Policy Update Magnitude: 0.12013
Value Function Update Magnitude: 0.07887

Collected Steps per Second: 25,352.65349
Overall Steps per Second: 12,748.57269

Timestep Collection Time: 1.97250
Timestep Consumption Time: 1.95014
PPO Batch Consumption Time: 0.35887
Total Iteration Time: 3.92264

Cumulative Model Updates: 136
Cumulative Timesteps: 2,350,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02412
Policy Entropy: 4.44095
Value Function Loss: 0.08402

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.00567
Policy Update Magnitude: 0.12138
Value Function Update Magnitude: 0.06888

Collected Steps per Second: 24,152.80305
Overall Steps per Second: 12,598.48531

Timestep Collection Time: 2.07156
Timestep Consumption Time: 1.89987
PPO Batch Consumption Time: 0.35636
Total Iteration Time: 3.97143

Cumulative Model Updates: 139
Cumulative Timesteps: 2,401,020

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2401020...
Checkpoint 2401020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05387
Policy Entropy: 4.43200
Value Function Loss: 0.11543

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.00164
Policy Update Magnitude: 0.11492
Value Function Update Magnitude: 0.06539

Collected Steps per Second: 22,360.20013
Overall Steps per Second: 12,364.03847

Timestep Collection Time: 2.23683
Timestep Consumption Time: 1.80845
PPO Batch Consumption Time: 0.35735
Total Iteration Time: 4.04528

Cumulative Model Updates: 142
Cumulative Timesteps: 2,451,036

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04235
Policy Entropy: 4.42332
Value Function Loss: 0.09834

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.00225
Policy Update Magnitude: 0.12337
Value Function Update Magnitude: 0.05559

Collected Steps per Second: 21,907.53001
Overall Steps per Second: 11,921.97108

Timestep Collection Time: 2.28332
Timestep Consumption Time: 1.91246
PPO Batch Consumption Time: 0.36421
Total Iteration Time: 4.19578

Cumulative Model Updates: 145
Cumulative Timesteps: 2,501,058

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2501058...
Checkpoint 2501058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02494
Policy Entropy: 4.41285
Value Function Loss: 0.10151

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.00519
Policy Update Magnitude: 0.13158
Value Function Update Magnitude: 0.05712

Collected Steps per Second: 22,779.08686
Overall Steps per Second: 11,975.69173

Timestep Collection Time: 2.19552
Timestep Consumption Time: 1.98060
PPO Batch Consumption Time: 0.36616
Total Iteration Time: 4.17613

Cumulative Model Updates: 148
Cumulative Timesteps: 2,551,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00438
Policy Entropy: 4.40769
Value Function Loss: 0.06415

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.00483
Policy Update Magnitude: 0.12422
Value Function Update Magnitude: 0.04894

Collected Steps per Second: 22,890.50091
Overall Steps per Second: 12,106.14449

Timestep Collection Time: 2.18457
Timestep Consumption Time: 1.94606
PPO Batch Consumption Time: 0.36218
Total Iteration Time: 4.13063

Cumulative Model Updates: 151
Cumulative Timesteps: 2,601,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2601076...
Checkpoint 2601076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03635
Policy Entropy: 4.40452
Value Function Loss: 0.07090

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.00621
Policy Update Magnitude: 0.11456
Value Function Update Magnitude: 0.05099

Collected Steps per Second: 21,412.47533
Overall Steps per Second: 11,807.36003

Timestep Collection Time: 2.33677
Timestep Consumption Time: 1.90093
PPO Batch Consumption Time: 0.35887
Total Iteration Time: 4.23770

Cumulative Model Updates: 154
Cumulative Timesteps: 2,651,112

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02928
Policy Entropy: 4.40342
Value Function Loss: 0.10082

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.00535
Policy Update Magnitude: 0.11005
Value Function Update Magnitude: 0.04487

Collected Steps per Second: 23,579.73250
Overall Steps per Second: 12,261.86278

Timestep Collection Time: 2.12089
Timestep Consumption Time: 1.95761
PPO Batch Consumption Time: 0.36694
Total Iteration Time: 4.07850

Cumulative Model Updates: 157
Cumulative Timesteps: 2,701,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2701122...
Checkpoint 2701122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03217
Policy Entropy: 4.39909
Value Function Loss: 0.11320

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.00236
Policy Update Magnitude: 0.11498
Value Function Update Magnitude: 0.05239

Collected Steps per Second: 21,704.62372
Overall Steps per Second: 11,626.43498

Timestep Collection Time: 2.30403
Timestep Consumption Time: 1.99721
PPO Batch Consumption Time: 0.36598
Total Iteration Time: 4.30123

Cumulative Model Updates: 160
Cumulative Timesteps: 2,751,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04838
Policy Entropy: 4.39563
Value Function Loss: 0.10794

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.00685
Policy Update Magnitude: 0.12334
Value Function Update Magnitude: 0.04782

Collected Steps per Second: 19,443.61027
Overall Steps per Second: 11,395.58341

Timestep Collection Time: 2.57339
Timestep Consumption Time: 1.81743
PPO Batch Consumption Time: 0.35961
Total Iteration Time: 4.39082

Cumulative Model Updates: 163
Cumulative Timesteps: 2,801,166

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2801166...
Checkpoint 2801166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02111
Policy Entropy: 4.38642
Value Function Loss: 0.09685

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.00587
Policy Update Magnitude: 0.12672
Value Function Update Magnitude: 0.05137

Collected Steps per Second: 22,952.11340
Overall Steps per Second: 12,333.54886

Timestep Collection Time: 2.17976
Timestep Consumption Time: 1.87666
PPO Batch Consumption Time: 0.35506
Total Iteration Time: 4.05642

Cumulative Model Updates: 166
Cumulative Timesteps: 2,851,196

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00312
Policy Entropy: 4.37659
Value Function Loss: 0.08064

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01029
Policy Update Magnitude: 0.12081
Value Function Update Magnitude: 0.04873

Collected Steps per Second: 19,679.45309
Overall Steps per Second: 11,138.22399

Timestep Collection Time: 2.54103
Timestep Consumption Time: 1.94856
PPO Batch Consumption Time: 0.36629
Total Iteration Time: 4.48958

Cumulative Model Updates: 169
Cumulative Timesteps: 2,901,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2901202...
Checkpoint 2901202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01441
Policy Entropy: 4.37182
Value Function Loss: 0.10189

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.00184
Policy Update Magnitude: 0.11871
Value Function Update Magnitude: 0.04657

Collected Steps per Second: 22,860.38225
Overall Steps per Second: 12,495.53089

Timestep Collection Time: 2.18806
Timestep Consumption Time: 1.81497
PPO Batch Consumption Time: 0.35661
Total Iteration Time: 4.00303

Cumulative Model Updates: 172
Cumulative Timesteps: 2,951,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00899
Policy Entropy: 4.36693
Value Function Loss: 0.10377

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.00620
Policy Update Magnitude: 0.11455
Value Function Update Magnitude: 0.05042

Collected Steps per Second: 24,154.06116
Overall Steps per Second: 12,517.25513

Timestep Collection Time: 2.07154
Timestep Consumption Time: 1.92583
PPO Batch Consumption Time: 0.35922
Total Iteration Time: 3.99736

Cumulative Model Updates: 175
Cumulative Timesteps: 3,001,258

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 3001258...
Checkpoint 3001258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00114
Policy Entropy: 4.36021
Value Function Loss: 0.12501

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01154
Policy Update Magnitude: 0.11040
Value Function Update Magnitude: 0.05729

Collected Steps per Second: 23,052.28771
Overall Steps per Second: 12,547.75654

Timestep Collection Time: 2.16968
Timestep Consumption Time: 1.81637
PPO Batch Consumption Time: 0.35776
Total Iteration Time: 3.98605

Cumulative Model Updates: 178
Cumulative Timesteps: 3,051,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02864
Policy Entropy: 4.35947
Value Function Loss: 0.10265

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.00373
Policy Update Magnitude: 0.10882
Value Function Update Magnitude: 0.05707

Collected Steps per Second: 21,048.68404
Overall Steps per Second: 11,426.92465

Timestep Collection Time: 2.37697
Timestep Consumption Time: 2.00147
PPO Batch Consumption Time: 0.35783
Total Iteration Time: 4.37843

Cumulative Model Updates: 181
Cumulative Timesteps: 3,101,306

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3101306...
Checkpoint 3101306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02169
Policy Entropy: 4.36802
Value Function Loss: 0.10072

Mean KL Divergence: 0.00124
SB3 Clip Fraction: 0.00356
Policy Update Magnitude: 0.11730
Value Function Update Magnitude: 0.05086

Collected Steps per Second: 23,580.55289
Overall Steps per Second: 12,555.92656

Timestep Collection Time: 2.12183
Timestep Consumption Time: 1.86306
PPO Batch Consumption Time: 0.35683
Total Iteration Time: 3.98489

Cumulative Model Updates: 184
Cumulative Timesteps: 3,151,340

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01520
Policy Entropy: 4.38177
Value Function Loss: 0.11267

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.00539
Policy Update Magnitude: 0.11625
Value Function Update Magnitude: 0.05556

Collected Steps per Second: 24,815.67118
Overall Steps per Second: 12,761.49760

Timestep Collection Time: 2.01542
Timestep Consumption Time: 1.90371
PPO Batch Consumption Time: 0.36491
Total Iteration Time: 3.91913

Cumulative Model Updates: 187
Cumulative Timesteps: 3,201,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3201354...
Checkpoint 3201354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00590
Policy Entropy: 4.39397
Value Function Loss: 0.09577

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01472
Policy Update Magnitude: 0.11749
Value Function Update Magnitude: 0.05382

Collected Steps per Second: 24,059.23830
Overall Steps per Second: 12,581.85218

Timestep Collection Time: 2.08003
Timestep Consumption Time: 1.89744
PPO Batch Consumption Time: 0.36024
Total Iteration Time: 3.97747

Cumulative Model Updates: 190
Cumulative Timesteps: 3,251,398

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01896
Policy Entropy: 4.39993
Value Function Loss: 0.11299

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.00695
Policy Update Magnitude: 0.11521
Value Function Update Magnitude: 0.05723

Collected Steps per Second: 23,776.51540
Overall Steps per Second: 12,774.72871

Timestep Collection Time: 2.10300
Timestep Consumption Time: 1.81113
PPO Batch Consumption Time: 0.35431
Total Iteration Time: 3.91413

Cumulative Model Updates: 193
Cumulative Timesteps: 3,301,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3301400...
Checkpoint 3301400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04293
Policy Entropy: 4.40603
Value Function Loss: 0.08244

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.00071
Policy Update Magnitude: 0.11372
Value Function Update Magnitude: 0.05155

Collected Steps per Second: 24,078.18621
Overall Steps per Second: 12,479.36484

Timestep Collection Time: 2.07673
Timestep Consumption Time: 1.93020
PPO Batch Consumption Time: 0.36736
Total Iteration Time: 4.00693

Cumulative Model Updates: 196
Cumulative Timesteps: 3,351,404

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01769
Policy Entropy: 4.41072
Value Function Loss: 0.09869

Mean KL Divergence: 0.00128
SB3 Clip Fraction: 0.00020
Policy Update Magnitude: 0.11704
Value Function Update Magnitude: 0.05219

Collected Steps per Second: 23,894.66288
Overall Steps per Second: 12,620.09562

Timestep Collection Time: 2.09369
Timestep Consumption Time: 1.87046
PPO Batch Consumption Time: 0.35540
Total Iteration Time: 3.96415

Cumulative Model Updates: 199
Cumulative Timesteps: 3,401,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3401432...
Checkpoint 3401432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05182
Policy Entropy: 4.41427
Value Function Loss: 0.07385

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.00114
Policy Update Magnitude: 0.11140
Value Function Update Magnitude: 0.05366

Collected Steps per Second: 25,139.19950
Overall Steps per Second: 12,782.35722

Timestep Collection Time: 1.99004
Timestep Consumption Time: 1.92379
PPO Batch Consumption Time: 0.36053
Total Iteration Time: 3.91383

Cumulative Model Updates: 202
Cumulative Timesteps: 3,451,460

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02753
Policy Entropy: 4.41682
Value Function Loss: 0.07193

Mean KL Divergence: 0.00095
SB3 Clip Fraction: 0.00043
Policy Update Magnitude: 0.10489
Value Function Update Magnitude: 0.05278

Collected Steps per Second: 24,086.94143
Overall Steps per Second: 12,519.24032

Timestep Collection Time: 2.07664
Timestep Consumption Time: 1.91881
PPO Batch Consumption Time: 0.36168
Total Iteration Time: 3.99545

Cumulative Model Updates: 205
Cumulative Timesteps: 3,501,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3501480...
Checkpoint 3501480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18404
Policy Entropy: 4.41691
Value Function Loss: 0.06918

Mean KL Divergence: 0.00072
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10031
Value Function Update Magnitude: 0.05493

Collected Steps per Second: 23,447.28223
Overall Steps per Second: 12,439.49788

Timestep Collection Time: 2.13261
Timestep Consumption Time: 1.88716
PPO Batch Consumption Time: 0.36187
Total Iteration Time: 4.01978

Cumulative Model Updates: 208
Cumulative Timesteps: 3,551,484

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04425
Policy Entropy: 4.41705
Value Function Loss: 0.06086

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09664
Value Function Update Magnitude: 0.05336

Collected Steps per Second: 21,453.82403
Overall Steps per Second: 11,695.13394

Timestep Collection Time: 2.33161
Timestep Consumption Time: 1.94555
PPO Batch Consumption Time: 0.35704
Total Iteration Time: 4.27716

Cumulative Model Updates: 211
Cumulative Timesteps: 3,601,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3601506...
Checkpoint 3601506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00892
Policy Entropy: 4.41788
Value Function Loss: 0.07532

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09804
Value Function Update Magnitude: 0.05259

Collected Steps per Second: 23,052.15996
Overall Steps per Second: 12,376.38666

Timestep Collection Time: 2.17125
Timestep Consumption Time: 1.87290
PPO Batch Consumption Time: 0.36159
Total Iteration Time: 4.04415

Cumulative Model Updates: 214
Cumulative Timesteps: 3,651,558

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01683
Policy Entropy: 4.42085
Value Function Loss: 0.07610

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10244
Value Function Update Magnitude: 0.05075

Collected Steps per Second: 24,853.49065
Overall Steps per Second: 12,827.90143

Timestep Collection Time: 2.01276
Timestep Consumption Time: 1.88687
PPO Batch Consumption Time: 0.35951
Total Iteration Time: 3.89962

Cumulative Model Updates: 217
Cumulative Timesteps: 3,701,582

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3701582...
Checkpoint 3701582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01946
Policy Entropy: 4.42593
Value Function Loss: 0.07743

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10285
Value Function Update Magnitude: 0.04877

Collected Steps per Second: 24,095.12830
Overall Steps per Second: 12,515.15223

Timestep Collection Time: 2.07569
Timestep Consumption Time: 1.92059
PPO Batch Consumption Time: 0.35624
Total Iteration Time: 3.99628

Cumulative Model Updates: 220
Cumulative Timesteps: 3,751,596

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03705
Policy Entropy: 4.42803
Value Function Loss: 0.06953

Mean KL Divergence: 0.00072
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10147
Value Function Update Magnitude: 0.04968

Collected Steps per Second: 22,498.15156
Overall Steps per Second: 12,137.96951

Timestep Collection Time: 2.22472
Timestep Consumption Time: 1.89887
PPO Batch Consumption Time: 0.35907
Total Iteration Time: 4.12359

Cumulative Model Updates: 223
Cumulative Timesteps: 3,801,648

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 3801648...
Checkpoint 3801648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06315
Policy Entropy: 4.42599
Value Function Loss: 0.05867

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09876
Value Function Update Magnitude: 0.04890

Collected Steps per Second: 24,014.96471
Overall Steps per Second: 12,521.65739

Timestep Collection Time: 2.08303
Timestep Consumption Time: 1.91196
PPO Batch Consumption Time: 0.36084
Total Iteration Time: 3.99500

Cumulative Model Updates: 226
Cumulative Timesteps: 3,851,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03126
Policy Entropy: 4.42241
Value Function Loss: 0.07115

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09894
Value Function Update Magnitude: 0.04563

Collected Steps per Second: 24,025.81456
Overall Steps per Second: 12,868.19428

Timestep Collection Time: 2.08168
Timestep Consumption Time: 1.80496
PPO Batch Consumption Time: 0.35939
Total Iteration Time: 3.88664

Cumulative Model Updates: 229
Cumulative Timesteps: 3,901,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3901686...
Checkpoint 3901686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01302
Policy Entropy: 4.41642
Value Function Loss: 0.06309

Mean KL Divergence: 0.00075
SB3 Clip Fraction: 0.00021
Policy Update Magnitude: 0.10173
Value Function Update Magnitude: 0.04400

Collected Steps per Second: 24,216.35327
Overall Steps per Second: 12,654.48972

Timestep Collection Time: 2.06662
Timestep Consumption Time: 1.88818
PPO Batch Consumption Time: 0.35808
Total Iteration Time: 3.95480

Cumulative Model Updates: 232
Cumulative Timesteps: 3,951,732

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00763
Policy Entropy: 4.40660
Value Function Loss: 0.07158

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00409
Policy Update Magnitude: 0.10661
Value Function Update Magnitude: 0.05103

Collected Steps per Second: 24,347.87485
Overall Steps per Second: 12,610.51884

Timestep Collection Time: 2.05431
Timestep Consumption Time: 1.91206
PPO Batch Consumption Time: 0.35932
Total Iteration Time: 3.96637

Cumulative Model Updates: 235
Cumulative Timesteps: 4,001,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 4001750...
Checkpoint 4001750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02326
Policy Entropy: 4.39602
Value Function Loss: 0.04747

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.00864
Policy Update Magnitude: 0.10020
Value Function Update Magnitude: 0.05859

Collected Steps per Second: 24,950.54273
Overall Steps per Second: 12,952.07282

Timestep Collection Time: 2.00420
Timestep Consumption Time: 1.85664
PPO Batch Consumption Time: 0.36025
Total Iteration Time: 3.86085

Cumulative Model Updates: 238
Cumulative Timesteps: 4,051,756

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00934
Policy Entropy: 4.39344
Value Function Loss: 0.07159

Mean KL Divergence: 0.00099
SB3 Clip Fraction: 0.00037
Policy Update Magnitude: 0.10263
Value Function Update Magnitude: 0.06780

Collected Steps per Second: 23,889.14566
Overall Steps per Second: 12,587.37311

Timestep Collection Time: 2.09442
Timestep Consumption Time: 1.88051
PPO Batch Consumption Time: 0.35622
Total Iteration Time: 3.97494

Cumulative Model Updates: 241
Cumulative Timesteps: 4,101,790

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 4101790...
Checkpoint 4101790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07588
Policy Entropy: 4.39029
Value Function Loss: 0.08148

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00010
Policy Update Magnitude: 0.10397
Value Function Update Magnitude: 0.06405

Collected Steps per Second: 24,916.17039
Overall Steps per Second: 12,810.68957

Timestep Collection Time: 2.00785
Timestep Consumption Time: 1.89732
PPO Batch Consumption Time: 0.35625
Total Iteration Time: 3.90518

Cumulative Model Updates: 244
Cumulative Timesteps: 4,151,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01913
Policy Entropy: 4.38819
Value Function Loss: 0.08789

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00115
Policy Update Magnitude: 0.11252
Value Function Update Magnitude: 0.06978

Collected Steps per Second: 24,020.81522
Overall Steps per Second: 12,539.36691

Timestep Collection Time: 2.08286
Timestep Consumption Time: 1.90713
PPO Batch Consumption Time: 0.36546
Total Iteration Time: 3.98999

Cumulative Model Updates: 247
Cumulative Timesteps: 4,201,850

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 4201850...
Checkpoint 4201850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02799
Policy Entropy: 4.38882
Value Function Loss: 0.05375

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00027
Policy Update Magnitude: 0.10753
Value Function Update Magnitude: 0.06164

Collected Steps per Second: 23,997.89000
Overall Steps per Second: 12,783.25367

Timestep Collection Time: 2.08493
Timestep Consumption Time: 1.82909
PPO Batch Consumption Time: 0.36306
Total Iteration Time: 3.91403

Cumulative Model Updates: 250
Cumulative Timesteps: 4,251,884

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00131
Policy Entropy: 4.39111
Value Function Loss: 0.04511

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09588
Value Function Update Magnitude: 0.05082

Collected Steps per Second: 24,102.81582
Overall Steps per Second: 12,636.09759

Timestep Collection Time: 2.07602
Timestep Consumption Time: 1.88390
PPO Batch Consumption Time: 0.35585
Total Iteration Time: 3.95993

Cumulative Model Updates: 253
Cumulative Timesteps: 4,301,922

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 4301922...
Checkpoint 4301922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03722
Policy Entropy: 4.39504
Value Function Loss: 0.03684

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.08741
Value Function Update Magnitude: 0.05463

Collected Steps per Second: 24,136.18082
Overall Steps per Second: 12,711.77773

Timestep Collection Time: 2.07266
Timestep Consumption Time: 1.86275
PPO Batch Consumption Time: 0.35744
Total Iteration Time: 3.93541

Cumulative Model Updates: 256
Cumulative Timesteps: 4,351,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00988
Policy Entropy: 4.39980
Value Function Loss: 0.04424

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08427
Value Function Update Magnitude: 0.05181

Collected Steps per Second: 24,336.41726
Overall Steps per Second: 12,603.93282

Timestep Collection Time: 2.05601
Timestep Consumption Time: 1.91386
PPO Batch Consumption Time: 0.36562
Total Iteration Time: 3.96987

Cumulative Model Updates: 259
Cumulative Timesteps: 4,401,984

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 4401984...
Checkpoint 4401984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01914
Policy Entropy: 4.40231
Value Function Loss: 0.04597

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08216
Value Function Update Magnitude: 0.04655

Collected Steps per Second: 24,345.30565
Overall Steps per Second: 12,683.40818

Timestep Collection Time: 2.05485
Timestep Consumption Time: 1.88936
PPO Batch Consumption Time: 0.36609
Total Iteration Time: 3.94421

Cumulative Model Updates: 262
Cumulative Timesteps: 4,452,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02461
Policy Entropy: 4.40415
Value Function Loss: 0.05300

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08810
Value Function Update Magnitude: 0.04020

Collected Steps per Second: 24,005.05503
Overall Steps per Second: 12,537.50251

Timestep Collection Time: 2.08331
Timestep Consumption Time: 1.90552
PPO Batch Consumption Time: 0.36256
Total Iteration Time: 3.98883

Cumulative Model Updates: 265
Cumulative Timesteps: 4,502,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 4502020...
Checkpoint 4502020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01995
Policy Entropy: 4.40464
Value Function Loss: 0.06333

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09362
Value Function Update Magnitude: 0.04074

Collected Steps per Second: 24,088.81608
Overall Steps per Second: 12,561.46106

Timestep Collection Time: 2.07715
Timestep Consumption Time: 1.90615
PPO Batch Consumption Time: 0.35757
Total Iteration Time: 3.98329

Cumulative Model Updates: 268
Cumulative Timesteps: 4,552,056

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03057
Policy Entropy: 4.40460
Value Function Loss: 0.07020

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09894
Value Function Update Magnitude: 0.04886

Collected Steps per Second: 23,326.08584
Overall Steps per Second: 12,671.17202

Timestep Collection Time: 2.14575
Timestep Consumption Time: 1.80432
PPO Batch Consumption Time: 0.35819
Total Iteration Time: 3.95007

Cumulative Model Updates: 271
Cumulative Timesteps: 4,602,108

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 4602108...
Checkpoint 4602108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02135
Policy Entropy: 4.40557
Value Function Loss: 0.06287

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00031
Policy Update Magnitude: 0.09962
Value Function Update Magnitude: 0.05648

Collected Steps per Second: 24,126.14112
Overall Steps per Second: 12,622.27418

Timestep Collection Time: 2.07360
Timestep Consumption Time: 1.88987
PPO Batch Consumption Time: 0.35570
Total Iteration Time: 3.96347

Cumulative Model Updates: 274
Cumulative Timesteps: 4,652,136

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01891
Policy Entropy: 4.40866
Value Function Loss: 0.06396

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00095
Policy Update Magnitude: 0.10334
Value Function Update Magnitude: 0.05928

Collected Steps per Second: 23,887.93035
Overall Steps per Second: 12,671.37923

Timestep Collection Time: 2.09503
Timestep Consumption Time: 1.85450
PPO Batch Consumption Time: 0.36159
Total Iteration Time: 3.94953

Cumulative Model Updates: 277
Cumulative Timesteps: 4,702,182

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 4702182...
Checkpoint 4702182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04200
Policy Entropy: 4.41646
Value Function Loss: 0.05507

Mean KL Divergence: 0.00091
SB3 Clip Fraction: 0.00075
Policy Update Magnitude: 0.09650
Value Function Update Magnitude: 0.05357

Collected Steps per Second: 24,846.63833
Overall Steps per Second: 12,789.69580

Timestep Collection Time: 2.01444
Timestep Consumption Time: 1.89903
PPO Batch Consumption Time: 0.35898
Total Iteration Time: 3.91346

Cumulative Model Updates: 280
Cumulative Timesteps: 4,752,234

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00077
Policy Entropy: 4.42322
Value Function Loss: 0.05421

Mean KL Divergence: 0.00095
SB3 Clip Fraction: 0.00150
Policy Update Magnitude: 0.09855
Value Function Update Magnitude: 0.05049

Collected Steps per Second: 23,022.80496
Overall Steps per Second: 12,152.04916

Timestep Collection Time: 2.17176
Timestep Consumption Time: 1.94277
PPO Batch Consumption Time: 0.36332
Total Iteration Time: 4.11453

Cumulative Model Updates: 283
Cumulative Timesteps: 4,802,234

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 4802234...
Checkpoint 4802234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03561
Policy Entropy: 4.42849
Value Function Loss: 0.05524

Mean KL Divergence: 0.00083
SB3 Clip Fraction: 0.00085
Policy Update Magnitude: 0.09419
Value Function Update Magnitude: 0.04882

Collected Steps per Second: 23,641.40465
Overall Steps per Second: 12,638.96018

Timestep Collection Time: 2.11671
Timestep Consumption Time: 1.84263
PPO Batch Consumption Time: 0.36660
Total Iteration Time: 3.95934

Cumulative Model Updates: 286
Cumulative Timesteps: 4,852,276

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03205
Policy Entropy: 4.43087
Value Function Loss: 0.04608

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08975
Value Function Update Magnitude: 0.05017

Collected Steps per Second: 24,016.87519
Overall Steps per Second: 12,605.66956

Timestep Collection Time: 2.08287
Timestep Consumption Time: 1.88550
PPO Batch Consumption Time: 0.35566
Total Iteration Time: 3.96837

Cumulative Model Updates: 289
Cumulative Timesteps: 4,902,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 4902300...
Checkpoint 4902300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03163
Policy Entropy: 4.42996
Value Function Loss: 0.06488

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09680
Value Function Update Magnitude: 0.05102

Collected Steps per Second: 23,827.55416
Overall Steps per Second: 12,636.12293

Timestep Collection Time: 2.09950
Timestep Consumption Time: 1.85947
PPO Batch Consumption Time: 0.35858
Total Iteration Time: 3.95897

Cumulative Model Updates: 292
Cumulative Timesteps: 4,952,326

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04320
Policy Entropy: 4.42314
Value Function Loss: 0.06277

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11105
Value Function Update Magnitude: 0.05434

Collected Steps per Second: 25,319.71607
Overall Steps per Second: 12,940.39793

Timestep Collection Time: 1.97617
Timestep Consumption Time: 1.89048
PPO Batch Consumption Time: 0.35428
Total Iteration Time: 3.86665

Cumulative Model Updates: 295
Cumulative Timesteps: 5,002,362

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 5002362...
Checkpoint 5002362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02749
Policy Entropy: 4.40767
Value Function Loss: 0.06468

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.00760
Policy Update Magnitude: 0.11548
Value Function Update Magnitude: 0.05619

Collected Steps per Second: 23,014.16133
Overall Steps per Second: 12,267.79762

Timestep Collection Time: 2.17353
Timestep Consumption Time: 1.90397
PPO Batch Consumption Time: 0.35752
Total Iteration Time: 4.07750

Cumulative Model Updates: 298
Cumulative Timesteps: 5,052,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04628
Policy Entropy: 4.39593
Value Function Loss: 0.04775

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01521
Policy Update Magnitude: 0.10420
Value Function Update Magnitude: 0.05686

Collected Steps per Second: 23,757.87875
Overall Steps per Second: 12,746.07440

Timestep Collection Time: 2.10600
Timestep Consumption Time: 1.81945
PPO Batch Consumption Time: 0.35926
Total Iteration Time: 3.92544

Cumulative Model Updates: 301
Cumulative Timesteps: 5,102,418

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 5102418...
Checkpoint 5102418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01468
Policy Entropy: 4.39507
Value Function Loss: 0.04108

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00035
Policy Update Magnitude: 0.10076
Value Function Update Magnitude: 0.05548

Collected Steps per Second: 23,360.82605
Overall Steps per Second: 12,326.93353

Timestep Collection Time: 2.14051
Timestep Consumption Time: 1.91598
PPO Batch Consumption Time: 0.36028
Total Iteration Time: 4.05648

Cumulative Model Updates: 304
Cumulative Timesteps: 5,152,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01628
Policy Entropy: 4.40183
Value Function Loss: 0.06641

Mean KL Divergence: 0.00082
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10050
Value Function Update Magnitude: 0.05234

Collected Steps per Second: 20,760.76148
Overall Steps per Second: 11,544.11304

Timestep Collection Time: 2.40974
Timestep Consumption Time: 1.92390
PPO Batch Consumption Time: 0.36748
Total Iteration Time: 4.33364

Cumulative Model Updates: 307
Cumulative Timesteps: 5,202,450

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 5202450...
Checkpoint 5202450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04367
Policy Entropy: 4.41324
Value Function Loss: 0.07247

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.00140
Policy Update Magnitude: 0.11097
Value Function Update Magnitude: 0.06055

Collected Steps per Second: 22,209.91297
Overall Steps per Second: 12,045.42128

Timestep Collection Time: 2.25323
Timestep Consumption Time: 1.90138
PPO Batch Consumption Time: 0.35976
Total Iteration Time: 4.15461

Cumulative Model Updates: 310
Cumulative Timesteps: 5,252,494

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01182
Policy Entropy: 4.42783
Value Function Loss: 0.06188

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.00819
Policy Update Magnitude: 0.11375
Value Function Update Magnitude: 0.06670

Collected Steps per Second: 23,618.84243
Overall Steps per Second: 12,487.61656

Timestep Collection Time: 2.11763
Timestep Consumption Time: 1.88762
PPO Batch Consumption Time: 0.35904
Total Iteration Time: 4.00525

Cumulative Model Updates: 313
Cumulative Timesteps: 5,302,510

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 5302510...
Checkpoint 5302510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10028
Policy Entropy: 4.43651
Value Function Loss: 0.04328

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.00640
Policy Update Magnitude: 0.09852
Value Function Update Magnitude: 0.06006

Collected Steps per Second: 25,231.13789
Overall Steps per Second: 12,883.87891

Timestep Collection Time: 1.98255
Timestep Consumption Time: 1.89998
PPO Batch Consumption Time: 0.35925
Total Iteration Time: 3.88253

Cumulative Model Updates: 316
Cumulative Timesteps: 5,352,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02652
Policy Entropy: 4.44261
Value Function Loss: 0.04402

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.00018
Policy Update Magnitude: 0.09344
Value Function Update Magnitude: 0.05894

Collected Steps per Second: 24,072.11760
Overall Steps per Second: 12,567.59965

Timestep Collection Time: 2.07801
Timestep Consumption Time: 1.90223
PPO Batch Consumption Time: 0.35643
Total Iteration Time: 3.98023

Cumulative Model Updates: 319
Cumulative Timesteps: 5,402,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 5402554...
Checkpoint 5402554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07179
Policy Entropy: 4.44943
Value Function Loss: 0.06934

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09396
Value Function Update Magnitude: 0.06142

Collected Steps per Second: 23,949.32566
Overall Steps per Second: 12,728.87972

Timestep Collection Time: 2.08899
Timestep Consumption Time: 1.84144
PPO Batch Consumption Time: 0.36617
Total Iteration Time: 3.93043

Cumulative Model Updates: 322
Cumulative Timesteps: 5,452,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01896
Policy Entropy: 4.45308
Value Function Loss: 0.07403

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09648
Value Function Update Magnitude: 0.08538

Collected Steps per Second: 24,491.68017
Overall Steps per Second: 12,665.07722

Timestep Collection Time: 2.04314
Timestep Consumption Time: 1.90788
PPO Batch Consumption Time: 0.36134
Total Iteration Time: 3.95102

Cumulative Model Updates: 325
Cumulative Timesteps: 5,502,624

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 5502624...
Checkpoint 5502624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01632
Policy Entropy: 4.45325
Value Function Loss: 0.06341

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10881
Value Function Update Magnitude: 0.10522

Collected Steps per Second: 23,523.68329
Overall Steps per Second: 12,486.86653

Timestep Collection Time: 2.12560
Timestep Consumption Time: 1.87876
PPO Batch Consumption Time: 0.35859
Total Iteration Time: 4.00437

Cumulative Model Updates: 328
Cumulative Timesteps: 5,552,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01242
Policy Entropy: 4.45189
Value Function Loss: 0.06432

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10696
Value Function Update Magnitude: 0.11694

Collected Steps per Second: 25,297.63960
Overall Steps per Second: 12,889.58755

Timestep Collection Time: 1.97663
Timestep Consumption Time: 1.90278
PPO Batch Consumption Time: 0.35781
Total Iteration Time: 3.87941

Cumulative Model Updates: 331
Cumulative Timesteps: 5,602,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 5602630...
Checkpoint 5602630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00163
Policy Entropy: 4.45191
Value Function Loss: 0.04960

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09990
Value Function Update Magnitude: 0.10316

Collected Steps per Second: 24,114.62604
Overall Steps per Second: 12,530.45883

Timestep Collection Time: 2.07443
Timestep Consumption Time: 1.91777
PPO Batch Consumption Time: 0.36076
Total Iteration Time: 3.99219

Cumulative Model Updates: 334
Cumulative Timesteps: 5,652,654

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03190
Policy Entropy: 4.45476
Value Function Loss: 0.07430

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10852
Value Function Update Magnitude: 0.09605

Collected Steps per Second: 24,147.57771
Overall Steps per Second: 12,824.79689

Timestep Collection Time: 2.07143
Timestep Consumption Time: 1.82883
PPO Batch Consumption Time: 0.36563
Total Iteration Time: 3.90026

Cumulative Model Updates: 337
Cumulative Timesteps: 5,702,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 5702674...
Checkpoint 5702674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00232
Policy Entropy: 4.45784
Value Function Loss: 0.06292

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10671
Value Function Update Magnitude: 0.09581

Collected Steps per Second: 23,702.81298
Overall Steps per Second: 12,436.00805

Timestep Collection Time: 2.11165
Timestep Consumption Time: 1.91312
PPO Batch Consumption Time: 0.36299
Total Iteration Time: 4.02476

Cumulative Model Updates: 340
Cumulative Timesteps: 5,752,726

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01803
Policy Entropy: 4.45858
Value Function Loss: 0.05501

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10334
Value Function Update Magnitude: 0.08731

Collected Steps per Second: 22,869.97325
Overall Steps per Second: 12,497.50082

Timestep Collection Time: 2.18820
Timestep Consumption Time: 1.81612
PPO Batch Consumption Time: 0.36355
Total Iteration Time: 4.00432

Cumulative Model Updates: 343
Cumulative Timesteps: 5,802,770

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 5802770...
Checkpoint 5802770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01561
Policy Entropy: 4.45832
Value Function Loss: 0.04474

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09602
Value Function Update Magnitude: 0.08338

Collected Steps per Second: 23,442.78236
Overall Steps per Second: 12,467.26470

Timestep Collection Time: 2.13328
Timestep Consumption Time: 1.87803
PPO Batch Consumption Time: 0.35771
Total Iteration Time: 4.01130

Cumulative Model Updates: 346
Cumulative Timesteps: 5,852,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06630
Policy Entropy: 4.45770
Value Function Loss: 0.04370

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09151
Value Function Update Magnitude: 0.07971

Collected Steps per Second: 23,790.13212
Overall Steps per Second: 12,091.53428

Timestep Collection Time: 2.10289
Timestep Consumption Time: 2.03455
PPO Batch Consumption Time: 0.41482
Total Iteration Time: 4.13744

Cumulative Model Updates: 349
Cumulative Timesteps: 5,902,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 5902808...
Checkpoint 5902808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03015
Policy Entropy: 4.45863
Value Function Loss: 0.03438

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08812
Value Function Update Magnitude: 0.07972

Collected Steps per Second: 25,224.81977
Overall Steps per Second: 12,723.68358

Timestep Collection Time: 1.98289
Timestep Consumption Time: 1.94821
PPO Batch Consumption Time: 0.36279
Total Iteration Time: 3.93109

Cumulative Model Updates: 352
Cumulative Timesteps: 5,952,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02274
Policy Entropy: 4.46068
Value Function Loss: 0.02848

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08727
Value Function Update Magnitude: 0.08120

Collected Steps per Second: 20,905.71481
Overall Steps per Second: 11,569.33950

Timestep Collection Time: 2.39265
Timestep Consumption Time: 1.93085
PPO Batch Consumption Time: 0.35565
Total Iteration Time: 4.32350

Cumulative Model Updates: 355
Cumulative Timesteps: 6,002,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 6002846...
Checkpoint 6002846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00529
Policy Entropy: 4.46356
Value Function Loss: 0.02472

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07870
Value Function Update Magnitude: 0.08041

Collected Steps per Second: 24,241.07813
Overall Steps per Second: 12,791.02588

Timestep Collection Time: 2.06385
Timestep Consumption Time: 1.84748
PPO Batch Consumption Time: 0.36645
Total Iteration Time: 3.91134

Cumulative Model Updates: 358
Cumulative Timesteps: 6,052,876

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03430
Policy Entropy: 4.46711
Value Function Loss: 0.02574

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07721
Value Function Update Magnitude: 0.08970

Collected Steps per Second: 21,710.57437
Overall Steps per Second: 11,677.89296

Timestep Collection Time: 2.30431
Timestep Consumption Time: 1.97968
PPO Batch Consumption Time: 0.35975
Total Iteration Time: 4.28399

Cumulative Model Updates: 361
Cumulative Timesteps: 6,102,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 6102904...
Checkpoint 6102904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00220
Policy Entropy: 4.47024
Value Function Loss: 0.04244

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07562
Value Function Update Magnitude: 0.07517

Collected Steps per Second: 19,878.00170
Overall Steps per Second: 11,371.61129

Timestep Collection Time: 2.51695
Timestep Consumption Time: 1.88278
PPO Batch Consumption Time: 0.36430
Total Iteration Time: 4.39973

Cumulative Model Updates: 364
Cumulative Timesteps: 6,152,936

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02788
Policy Entropy: 4.47235
Value Function Loss: 0.05651

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07740
Value Function Update Magnitude: 0.06091

Collected Steps per Second: 23,022.98319
Overall Steps per Second: 12,323.63047

Timestep Collection Time: 2.17400
Timestep Consumption Time: 1.88746
PPO Batch Consumption Time: 0.36307
Total Iteration Time: 4.06147

Cumulative Model Updates: 367
Cumulative Timesteps: 6,202,988

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 6202988...
Checkpoint 6202988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03820
Policy Entropy: 4.47328
Value Function Loss: 0.06283

Mean KL Divergence: 0.00017
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08345
Value Function Update Magnitude: 0.07509

Collected Steps per Second: 24,257.56998
Overall Steps per Second: 12,692.70560

Timestep Collection Time: 2.06303
Timestep Consumption Time: 1.87971
PPO Batch Consumption Time: 0.36121
Total Iteration Time: 3.94274

Cumulative Model Updates: 370
Cumulative Timesteps: 6,253,032

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00900
Policy Entropy: 4.47260
Value Function Loss: 0.05226

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08867
Value Function Update Magnitude: 0.09151

Collected Steps per Second: 23,585.01352
Overall Steps per Second: 12,774.18692

Timestep Collection Time: 2.12109
Timestep Consumption Time: 1.79509
PPO Batch Consumption Time: 0.36589
Total Iteration Time: 3.91618

Cumulative Model Updates: 373
Cumulative Timesteps: 6,303,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 6303058...
Checkpoint 6303058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02633
Policy Entropy: 4.47136
Value Function Loss: 0.02828

Mean KL Divergence: 0.00017
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08756
Value Function Update Magnitude: 0.08755

Collected Steps per Second: 24,563.38862
Overall Steps per Second: 12,678.95409

Timestep Collection Time: 2.03604
Timestep Consumption Time: 1.90845
PPO Batch Consumption Time: 0.36489
Total Iteration Time: 3.94449

Cumulative Model Updates: 376
Cumulative Timesteps: 6,353,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03607
Policy Entropy: 4.46920
Value Function Loss: 0.03041

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08075
Value Function Update Magnitude: 0.07943

Collected Steps per Second: 23,840.27994
Overall Steps per Second: 12,702.17220

Timestep Collection Time: 2.09838
Timestep Consumption Time: 1.84000
PPO Batch Consumption Time: 0.36366
Total Iteration Time: 3.93838

Cumulative Model Updates: 379
Cumulative Timesteps: 6,403,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 6403096...
Checkpoint 6403096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02167
Policy Entropy: 4.46686
Value Function Loss: 0.04140

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07878
Value Function Update Magnitude: 0.07808

Collected Steps per Second: 24,085.82219
Overall Steps per Second: 12,609.57403

Timestep Collection Time: 2.07674
Timestep Consumption Time: 1.89009
PPO Batch Consumption Time: 0.35826
Total Iteration Time: 3.96683

Cumulative Model Updates: 382
Cumulative Timesteps: 6,453,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02308
Policy Entropy: 4.46260
Value Function Loss: 0.04898

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08291
Value Function Update Magnitude: 0.07318

Collected Steps per Second: 24,032.38855
Overall Steps per Second: 12,736.61392

Timestep Collection Time: 2.08244
Timestep Consumption Time: 1.84686
PPO Batch Consumption Time: 0.35228
Total Iteration Time: 3.92930

Cumulative Model Updates: 385
Cumulative Timesteps: 6,503,162

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 6503162...
Checkpoint 6503162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05693
Policy Entropy: 4.45798
Value Function Loss: 0.05713

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08817
Value Function Update Magnitude: 0.07185

Collected Steps per Second: 25,001.20083
Overall Steps per Second: 12,759.80241

Timestep Collection Time: 2.00070
Timestep Consumption Time: 1.91942
PPO Batch Consumption Time: 0.36988
Total Iteration Time: 3.92012

Cumulative Model Updates: 388
Cumulative Timesteps: 6,553,182

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01269
Policy Entropy: 4.45343
Value Function Loss: 0.04611

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08779
Value Function Update Magnitude: 0.07504

Collected Steps per Second: 24,073.69110
Overall Steps per Second: 12,610.21745

Timestep Collection Time: 2.07779
Timestep Consumption Time: 1.88884
PPO Batch Consumption Time: 0.36635
Total Iteration Time: 3.96662

Cumulative Model Updates: 391
Cumulative Timesteps: 6,603,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 6603202...
Checkpoint 6603202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06612
Policy Entropy: 4.45062
Value Function Loss: 0.05668

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08830
Value Function Update Magnitude: 0.07693

Collected Steps per Second: 23,802.47088
Overall Steps per Second: 12,784.91162

Timestep Collection Time: 2.10247
Timestep Consumption Time: 1.81183
PPO Batch Consumption Time: 0.35859
Total Iteration Time: 3.91430

Cumulative Model Updates: 394
Cumulative Timesteps: 6,653,246

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00708
Policy Entropy: 4.44717
Value Function Loss: 0.03725

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08951
Value Function Update Magnitude: 0.07676

Collected Steps per Second: 24,055.99129
Overall Steps per Second: 12,141.08741

Timestep Collection Time: 2.07998
Timestep Consumption Time: 2.04123
PPO Batch Consumption Time: 0.36142
Total Iteration Time: 4.12121

Cumulative Model Updates: 397
Cumulative Timesteps: 6,703,282

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 6703282...
Checkpoint 6703282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01858
Policy Entropy: 4.44399
Value Function Loss: 0.06770

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08434
Value Function Update Magnitude: 0.07706

Collected Steps per Second: 20,684.21815
Overall Steps per Second: 11,453.07479

Timestep Collection Time: 2.41740
Timestep Consumption Time: 1.94842
PPO Batch Consumption Time: 0.36037
Total Iteration Time: 4.36581

Cumulative Model Updates: 400
Cumulative Timesteps: 6,753,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03122
Policy Entropy: 4.44156
Value Function Loss: 0.08683

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08965
Value Function Update Magnitude: 0.08443

Collected Steps per Second: 22,144.06375
Overall Steps per Second: 12,012.55354

Timestep Collection Time: 2.25857
Timestep Consumption Time: 1.90490
PPO Batch Consumption Time: 0.36090
Total Iteration Time: 4.16348

Cumulative Model Updates: 403
Cumulative Timesteps: 6,803,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 6803298...
Checkpoint 6803298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01618
Policy Entropy: 4.44339
Value Function Loss: 0.10651

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11701
Value Function Update Magnitude: 0.10250

Collected Steps per Second: 24,291.43033
Overall Steps per Second: 12,687.19118

Timestep Collection Time: 2.05892
Timestep Consumption Time: 1.88317
PPO Batch Consumption Time: 0.36433
Total Iteration Time: 3.94209

Cumulative Model Updates: 406
Cumulative Timesteps: 6,853,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02532
Policy Entropy: 4.44966
Value Function Loss: 0.08502

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.13063
Value Function Update Magnitude: 0.10497

Collected Steps per Second: 23,642.87105
Overall Steps per Second: 12,502.94142

Timestep Collection Time: 2.11675
Timestep Consumption Time: 1.88599
PPO Batch Consumption Time: 0.36047
Total Iteration Time: 4.00274

Cumulative Model Updates: 409
Cumulative Timesteps: 6,903,358

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 6903358...
Checkpoint 6903358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01752
Policy Entropy: 4.45795
Value Function Loss: 0.05028

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.00163
Policy Update Magnitude: 0.12704
Value Function Update Magnitude: 0.10298

Collected Steps per Second: 23,957.64606
Overall Steps per Second: 12,616.73856

Timestep Collection Time: 2.08827
Timestep Consumption Time: 1.87710
PPO Batch Consumption Time: 0.35333
Total Iteration Time: 3.96537

Cumulative Model Updates: 412
Cumulative Timesteps: 6,953,388

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04545
Policy Entropy: 4.46542
Value Function Loss: 0.03963

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.00343
Policy Update Magnitude: 0.11485
Value Function Update Magnitude: 0.09471

Collected Steps per Second: 24,533.19517
Overall Steps per Second: 12,722.26010

Timestep Collection Time: 2.03969
Timestep Consumption Time: 1.89358
PPO Batch Consumption Time: 0.36357
Total Iteration Time: 3.93326

Cumulative Model Updates: 415
Cumulative Timesteps: 7,003,428

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 7003428...
Checkpoint 7003428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00631
Policy Entropy: 4.47079
Value Function Loss: 0.02804

Mean KL Divergence: 0.00105
SB3 Clip Fraction: 0.00158
Policy Update Magnitude: 0.09916
Value Function Update Magnitude: 0.09075

Collected Steps per Second: 25,150.74408
Overall Steps per Second: 12,951.34662

Timestep Collection Time: 1.98897
Timestep Consumption Time: 1.87349
PPO Batch Consumption Time: 0.35791
Total Iteration Time: 3.86246

Cumulative Model Updates: 418
Cumulative Timesteps: 7,053,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07466
Policy Entropy: 4.47440
Value Function Loss: 0.02789

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00029
Policy Update Magnitude: 0.09271
Value Function Update Magnitude: 0.08329

Collected Steps per Second: 23,144.80594
Overall Steps per Second: 12,336.33064

Timestep Collection Time: 2.16161
Timestep Consumption Time: 1.89389
PPO Batch Consumption Time: 0.36706
Total Iteration Time: 4.05550

Cumulative Model Updates: 421
Cumulative Timesteps: 7,103,482

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 7103482...
Checkpoint 7103482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03001
Policy Entropy: 4.47820
Value Function Loss: 0.02657

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.09008
Value Function Update Magnitude: 0.07693

Collected Steps per Second: 21,866.59870
Overall Steps per Second: 12,128.81371

Timestep Collection Time: 2.28678
Timestep Consumption Time: 1.83597
PPO Batch Consumption Time: 0.36453
Total Iteration Time: 4.12274

Cumulative Model Updates: 424
Cumulative Timesteps: 7,153,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04405
Policy Entropy: 4.48139
Value Function Loss: 0.01893

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08710
Value Function Update Magnitude: 0.07605

Collected Steps per Second: 22,886.22146
Overall Steps per Second: 12,237.23586

Timestep Collection Time: 2.18490
Timestep Consumption Time: 1.90132
PPO Batch Consumption Time: 0.34748
Total Iteration Time: 4.08622

Cumulative Model Updates: 427
Cumulative Timesteps: 7,203,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 7203490...
Checkpoint 7203490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00205
Policy Entropy: 4.48330
Value Function Loss: 0.02651

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08872
Value Function Update Magnitude: 0.07402

Collected Steps per Second: 23,076.89894
Overall Steps per Second: 12,400.74069

Timestep Collection Time: 2.16676
Timestep Consumption Time: 1.86542
PPO Batch Consumption Time: 0.36243
Total Iteration Time: 4.03218

Cumulative Model Updates: 430
Cumulative Timesteps: 7,253,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00368
Policy Entropy: 4.48387
Value Function Loss: 0.03119

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09556
Value Function Update Magnitude: 0.07487

Collected Steps per Second: 24,683.68506
Overall Steps per Second: 12,672.40048

Timestep Collection Time: 2.02571
Timestep Consumption Time: 1.92003
PPO Batch Consumption Time: 0.36729
Total Iteration Time: 3.94574

Cumulative Model Updates: 433
Cumulative Timesteps: 7,303,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 7303494...
Checkpoint 7303494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00164
Policy Entropy: 4.48397
Value Function Loss: 0.03264

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10339
Value Function Update Magnitude: 0.08178

Collected Steps per Second: 23,728.36770
Overall Steps per Second: 12,426.65749

Timestep Collection Time: 2.10752
Timestep Consumption Time: 1.91673
PPO Batch Consumption Time: 0.35778
Total Iteration Time: 4.02425

Cumulative Model Updates: 436
Cumulative Timesteps: 7,353,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04501
Policy Entropy: 4.48390
Value Function Loss: 0.03521

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11230
Value Function Update Magnitude: 0.08273

Collected Steps per Second: 24,915.16506
Overall Steps per Second: 12,879.20958

Timestep Collection Time: 2.00769
Timestep Consumption Time: 1.87624
PPO Batch Consumption Time: 0.35510
Total Iteration Time: 3.88393

Cumulative Model Updates: 439
Cumulative Timesteps: 7,403,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 7403524...
Checkpoint 7403524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02287
Policy Entropy: 4.48405
Value Function Loss: 0.02781

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11544
Value Function Update Magnitude: 0.07772

Collected Steps per Second: 24,844.18366
Overall Steps per Second: 12,820.67878

Timestep Collection Time: 2.01319
Timestep Consumption Time: 1.88801
PPO Batch Consumption Time: 0.35572
Total Iteration Time: 3.90120

Cumulative Model Updates: 442
Cumulative Timesteps: 7,453,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00953
Policy Entropy: 4.48448
Value Function Loss: 0.05840

Mean KL Divergence: 0.00013
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.12192
Value Function Update Magnitude: 0.06893

Collected Steps per Second: 24,113.87697
Overall Steps per Second: 12,865.21991

Timestep Collection Time: 2.07441
Timestep Consumption Time: 1.81375
PPO Batch Consumption Time: 0.36552
Total Iteration Time: 3.88816

Cumulative Model Updates: 445
Cumulative Timesteps: 7,503,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 7503562...
Checkpoint 7503562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02890
Policy Entropy: 4.48521
Value Function Loss: 0.05430

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.12827
Value Function Update Magnitude: 0.07590

Collected Steps per Second: 24,146.24219
Overall Steps per Second: 12,655.14212

Timestep Collection Time: 2.07279
Timestep Consumption Time: 1.88213
PPO Batch Consumption Time: 0.35977
Total Iteration Time: 3.95491

Cumulative Model Updates: 448
Cumulative Timesteps: 7,553,612

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03462
Policy Entropy: 4.48584
Value Function Loss: 0.05827

Mean KL Divergence: 0.00017
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.14058
Value Function Update Magnitude: 0.08166

Collected Steps per Second: 24,783.87535
Overall Steps per Second: 12,894.98527

Timestep Collection Time: 2.01905
Timestep Consumption Time: 1.86152
PPO Batch Consumption Time: 0.36040
Total Iteration Time: 3.88058

Cumulative Model Updates: 451
Cumulative Timesteps: 7,603,652

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 7603652...
Checkpoint 7603652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02231
Policy Entropy: 4.48492
Value Function Loss: 0.05746

Mean KL Divergence: 0.00019
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.14789
Value Function Update Magnitude: 0.08162

Collected Steps per Second: 25,184.44760
Overall Steps per Second: 13,016.04944

Timestep Collection Time: 1.98726
Timestep Consumption Time: 1.85784
PPO Batch Consumption Time: 0.35957
Total Iteration Time: 3.84510

Cumulative Model Updates: 454
Cumulative Timesteps: 7,653,700

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00892
Policy Entropy: 4.48142
Value Function Loss: 0.06951

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.15806
Value Function Update Magnitude: 0.08471

Collected Steps per Second: 24,323.55696
Overall Steps per Second: 12,718.02049

Timestep Collection Time: 2.05759
Timestep Consumption Time: 1.87761
PPO Batch Consumption Time: 0.35992
Total Iteration Time: 3.93520

Cumulative Model Updates: 457
Cumulative Timesteps: 7,703,748

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 7703748...
Checkpoint 7703748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00083
Policy Entropy: 4.47501
Value Function Loss: 0.06035

Mean KL Divergence: 0.00108
SB3 Clip Fraction: 0.00473
Policy Update Magnitude: 0.16358
Value Function Update Magnitude: 0.08492

Collected Steps per Second: 25,570.90262
Overall Steps per Second: 12,956.46518

Timestep Collection Time: 1.95715
Timestep Consumption Time: 1.90548
PPO Batch Consumption Time: 0.36075
Total Iteration Time: 3.86263

Cumulative Model Updates: 460
Cumulative Timesteps: 7,753,794

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00114
Policy Entropy: 4.46777
Value Function Loss: 0.03413

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.00823
Policy Update Magnitude: 0.14508
Value Function Update Magnitude: 0.09388

Collected Steps per Second: 24,463.17093
Overall Steps per Second: 12,540.17209

Timestep Collection Time: 2.04528
Timestep Consumption Time: 1.94462
PPO Batch Consumption Time: 0.36901
Total Iteration Time: 3.98990

Cumulative Model Updates: 463
Cumulative Timesteps: 7,803,828

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 7803828...
Checkpoint 7803828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09511
Policy Entropy: 4.46449
Value Function Loss: 0.02429

Mean KL Divergence: 0.00094
SB3 Clip Fraction: 0.00005
Policy Update Magnitude: 0.12421
Value Function Update Magnitude: 0.10291

Collected Steps per Second: 23,386.75367
Overall Steps per Second: 12,310.28679

Timestep Collection Time: 2.13796
Timestep Consumption Time: 1.92368
PPO Batch Consumption Time: 0.36643
Total Iteration Time: 4.06164

Cumulative Model Updates: 466
Cumulative Timesteps: 7,853,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02229
Policy Entropy: 4.46223
Value Function Loss: 0.02363

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11633
Value Function Update Magnitude: 0.09242

Collected Steps per Second: 23,627.30655
Overall Steps per Second: 12,482.15213

Timestep Collection Time: 2.11653
Timestep Consumption Time: 1.88983
PPO Batch Consumption Time: 0.36209
Total Iteration Time: 4.00636

Cumulative Model Updates: 469
Cumulative Timesteps: 7,903,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 7903836...
Checkpoint 7903836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01080
Policy Entropy: 4.45894
Value Function Loss: 0.03276

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11305
Value Function Update Magnitude: 0.07736

Collected Steps per Second: 24,794.13509
Overall Steps per Second: 12,855.25820

Timestep Collection Time: 2.01669
Timestep Consumption Time: 1.87293
PPO Batch Consumption Time: 0.36282
Total Iteration Time: 3.88961

Cumulative Model Updates: 472
Cumulative Timesteps: 7,953,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00649
Policy Entropy: 4.45610
Value Function Loss: 0.03915

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11272
Value Function Update Magnitude: 0.06699

Collected Steps per Second: 22,645.68379
Overall Steps per Second: 12,137.06880

Timestep Collection Time: 2.20863
Timestep Consumption Time: 1.91230
PPO Batch Consumption Time: 0.35661
Total Iteration Time: 4.12093

Cumulative Model Updates: 475
Cumulative Timesteps: 8,003,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 8003854...
Checkpoint 8003854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01136
Policy Entropy: 4.45091
Value Function Loss: 0.03830

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.12130
Value Function Update Magnitude: 0.05880

Collected Steps per Second: 23,183.16051
Overall Steps per Second: 12,425.65085

Timestep Collection Time: 2.15691
Timestep Consumption Time: 1.86735
PPO Batch Consumption Time: 0.35725
Total Iteration Time: 4.02426

Cumulative Model Updates: 478
Cumulative Timesteps: 8,053,858

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02803
Policy Entropy: 4.44402
Value Function Loss: 0.02825

Mean KL Divergence: 0.00084
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.13044
Value Function Update Magnitude: 0.05172

Collected Steps per Second: 19,223.56710
Overall Steps per Second: 11,239.37611

Timestep Collection Time: 2.60233
Timestep Consumption Time: 1.84863
PPO Batch Consumption Time: 0.35868
Total Iteration Time: 4.45096

Cumulative Model Updates: 481
Cumulative Timesteps: 8,103,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 8103884...
Checkpoint 8103884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07100
Policy Entropy: 4.43630
Value Function Loss: 0.01018

Mean KL Divergence: 0.00115
SB3 Clip Fraction: 0.00004
Policy Update Magnitude: 0.11718
Value Function Update Magnitude: 0.04992

Collected Steps per Second: 22,574.02553
Overall Steps per Second: 12,108.10344

Timestep Collection Time: 2.21609
Timestep Consumption Time: 1.91553
PPO Batch Consumption Time: 0.36004
Total Iteration Time: 4.13161

Cumulative Model Updates: 484
Cumulative Timesteps: 8,153,910

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07097
Policy Entropy: 4.43087
Value Function Loss: 0.00869

Mean KL Divergence: 0.00099
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09982
Value Function Update Magnitude: 0.05944

Collected Steps per Second: 22,476.15866
Overall Steps per Second: 12,049.89635

Timestep Collection Time: 2.22680
Timestep Consumption Time: 1.92676
PPO Batch Consumption Time: 0.36597
Total Iteration Time: 4.15356

Cumulative Model Updates: 487
Cumulative Timesteps: 8,203,960

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 8203960...
Checkpoint 8203960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02322
Policy Entropy: 4.42782
Value Function Loss: 0.00793

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08760
Value Function Update Magnitude: 0.06249

Collected Steps per Second: 23,641.56260
Overall Steps per Second: 12,267.32497

Timestep Collection Time: 2.11560
Timestep Consumption Time: 1.96158
PPO Batch Consumption Time: 0.36656
Total Iteration Time: 4.07717

Cumulative Model Updates: 490
Cumulative Timesteps: 8,253,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00926
Policy Entropy: 4.42733
Value Function Loss: 0.00746

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08563
Value Function Update Magnitude: 0.06079

Collected Steps per Second: 21,361.91562
Overall Steps per Second: 11,715.96178

Timestep Collection Time: 2.34230
Timestep Consumption Time: 1.92846
PPO Batch Consumption Time: 0.35443
Total Iteration Time: 4.27075

Cumulative Model Updates: 493
Cumulative Timesteps: 8,304,012

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 8304012...
Checkpoint 8304012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01221
Policy Entropy: 4.42850
Value Function Loss: 0.03815

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09428
Value Function Update Magnitude: 0.04643

Collected Steps per Second: 22,018.60968
Overall Steps per Second: 12,190.00102

Timestep Collection Time: 2.27162
Timestep Consumption Time: 1.83158
PPO Batch Consumption Time: 0.35796
Total Iteration Time: 4.10320

Cumulative Model Updates: 496
Cumulative Timesteps: 8,354,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00235
Policy Entropy: 4.42890
Value Function Loss: 0.04866

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.12103
Value Function Update Magnitude: 0.06013

Collected Steps per Second: 22,747.51190
Overall Steps per Second: 12,096.90587

Timestep Collection Time: 2.19848
Timestep Consumption Time: 1.93563
PPO Batch Consumption Time: 0.36400
Total Iteration Time: 4.13411

Cumulative Model Updates: 499
Cumulative Timesteps: 8,404,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 8404040...
Checkpoint 8404040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01854
Policy Entropy: 4.43208
Value Function Loss: 0.07940

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00013
Policy Update Magnitude: 0.14519
Value Function Update Magnitude: 0.08375

Collected Steps per Second: 22,412.70292
Overall Steps per Second: 12,070.04389

Timestep Collection Time: 2.23231
Timestep Consumption Time: 1.91283
PPO Batch Consumption Time: 0.35781
Total Iteration Time: 4.14514

Cumulative Model Updates: 502
Cumulative Timesteps: 8,454,072

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03086
Policy Entropy: 4.43289
Value Function Loss: 0.05970

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.00199
Policy Update Magnitude: 0.14945
Value Function Update Magnitude: 0.08623

Collected Steps per Second: 22,182.69059
Overall Steps per Second: 12,029.76910

Timestep Collection Time: 2.25608
Timestep Consumption Time: 1.90410
PPO Batch Consumption Time: 0.35729
Total Iteration Time: 4.16018

Cumulative Model Updates: 505
Cumulative Timesteps: 8,504,118

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 8504118...
Checkpoint 8504118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00053
Policy Entropy: 4.43097
Value Function Loss: 0.07498

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.00273
Policy Update Magnitude: 0.15352
Value Function Update Magnitude: 0.10182

Collected Steps per Second: 23,765.87608
Overall Steps per Second: 12,519.65461

Timestep Collection Time: 2.10386
Timestep Consumption Time: 1.88986
PPO Batch Consumption Time: 0.35503
Total Iteration Time: 3.99372

Cumulative Model Updates: 508
Cumulative Timesteps: 8,554,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06590
Policy Entropy: 4.42603
Value Function Loss: 0.09966

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.00095
Policy Update Magnitude: 0.15509
Value Function Update Magnitude: 0.14264

Collected Steps per Second: 25,143.03369
Overall Steps per Second: 12,915.61947

Timestep Collection Time: 1.98862
Timestep Consumption Time: 1.88266
PPO Batch Consumption Time: 0.36523
Total Iteration Time: 3.87128

Cumulative Model Updates: 511
Cumulative Timesteps: 8,604,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 8604118...
Checkpoint 8604118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01317
Policy Entropy: 4.41512
Value Function Loss: 0.08562

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.00501
Policy Update Magnitude: 0.16885
Value Function Update Magnitude: 0.15937

Collected Steps per Second: 23,965.59522
Overall Steps per Second: 12,596.20954

Timestep Collection Time: 2.08783
Timestep Consumption Time: 1.88448
PPO Batch Consumption Time: 0.36175
Total Iteration Time: 3.97231

Cumulative Model Updates: 514
Cumulative Timesteps: 8,654,154

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01331
Policy Entropy: 4.40420
Value Function Loss: 0.06580

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.00553
Policy Update Magnitude: 0.16684
Value Function Update Magnitude: 0.12226

Collected Steps per Second: 25,631.88792
Overall Steps per Second: 13,125.05972

Timestep Collection Time: 1.95218
Timestep Consumption Time: 1.86022
PPO Batch Consumption Time: 0.36025
Total Iteration Time: 3.81240

Cumulative Model Updates: 517
Cumulative Timesteps: 8,704,192

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 8704192...
Checkpoint 8704192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04386
Policy Entropy: 4.40009
Value Function Loss: 0.04485

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.00443
Policy Update Magnitude: 0.14941
Value Function Update Magnitude: 0.11100

Collected Steps per Second: 23,302.49088
Overall Steps per Second: 12,080.92234

Timestep Collection Time: 2.14767
Timestep Consumption Time: 1.99490
PPO Batch Consumption Time: 0.38434
Total Iteration Time: 4.14256

Cumulative Model Updates: 520
Cumulative Timesteps: 8,754,238

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03664
Policy Entropy: 4.38920
Value Function Loss: 0.06145

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.00979
Policy Update Magnitude: 0.14659
Value Function Update Magnitude: 0.10748

Collected Steps per Second: 22,051.17552
Overall Steps per Second: 12,064.44375

Timestep Collection Time: 2.26818
Timestep Consumption Time: 1.87756
PPO Batch Consumption Time: 0.36239
Total Iteration Time: 4.14574

Cumulative Model Updates: 523
Cumulative Timesteps: 8,804,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 8804254...
Checkpoint 8804254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03299
Policy Entropy: 4.37468
Value Function Loss: 0.07493

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01831
Policy Update Magnitude: 0.15256
Value Function Update Magnitude: 0.10425

Collected Steps per Second: 22,377.87708
Overall Steps per Second: 11,970.66799

Timestep Collection Time: 2.23596
Timestep Consumption Time: 1.94393
PPO Batch Consumption Time: 0.35338
Total Iteration Time: 4.17988

Cumulative Model Updates: 526
Cumulative Timesteps: 8,854,290

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02138
Policy Entropy: 4.37369
Value Function Loss: 0.05155

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.00993
Policy Update Magnitude: 0.14475
Value Function Update Magnitude: 0.10326

Collected Steps per Second: 20,565.47615
Overall Steps per Second: 11,429.65243

Timestep Collection Time: 2.43136
Timestep Consumption Time: 1.94340
PPO Batch Consumption Time: 0.35891
Total Iteration Time: 4.37476

Cumulative Model Updates: 529
Cumulative Timesteps: 8,904,292

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 8904292...
Checkpoint 8904292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09350
Policy Entropy: 4.38416
Value Function Loss: 0.04509

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.00881
Policy Update Magnitude: 0.13067
Value Function Update Magnitude: 0.10996

Collected Steps per Second: 25,084.27635
Overall Steps per Second: 12,704.88823

Timestep Collection Time: 1.99368
Timestep Consumption Time: 1.94260
PPO Batch Consumption Time: 0.36378
Total Iteration Time: 3.93628

Cumulative Model Updates: 532
Cumulative Timesteps: 8,954,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01548
Policy Entropy: 4.39165
Value Function Loss: 0.02565

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.00419
Policy Update Magnitude: 0.11924
Value Function Update Magnitude: 0.12293

Collected Steps per Second: 24,237.50957
Overall Steps per Second: 12,790.05647

Timestep Collection Time: 2.06432
Timestep Consumption Time: 1.84762
PPO Batch Consumption Time: 0.35414
Total Iteration Time: 3.91195

Cumulative Model Updates: 535
Cumulative Timesteps: 9,004,336

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 9004336...
Checkpoint 9004336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02083
Policy Entropy: 4.38657
Value Function Loss: 0.05126

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00063
Policy Update Magnitude: 0.11923
Value Function Update Magnitude: 0.09499

Collected Steps per Second: 23,799.50124
Overall Steps per Second: 12,809.27830

Timestep Collection Time: 2.10240
Timestep Consumption Time: 1.80383
PPO Batch Consumption Time: 0.35842
Total Iteration Time: 3.90623

Cumulative Model Updates: 538
Cumulative Timesteps: 9,054,372

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01622
Policy Entropy: 4.37610
Value Function Loss: 0.06830

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.00932
Policy Update Magnitude: 0.11833
Value Function Update Magnitude: 0.08826

Collected Steps per Second: 24,110.86892
Overall Steps per Second: 12,621.07341

Timestep Collection Time: 2.07417
Timestep Consumption Time: 1.88825
PPO Batch Consumption Time: 0.35903
Total Iteration Time: 3.96242

Cumulative Model Updates: 541
Cumulative Timesteps: 9,104,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 9104382...
Checkpoint 9104382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01797
Policy Entropy: 4.37499
Value Function Loss: 0.08441

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.00952
Policy Update Magnitude: 0.13103
Value Function Update Magnitude: 0.09494

Collected Steps per Second: 24,134.72845
Overall Steps per Second: 12,805.61524

Timestep Collection Time: 2.07311
Timestep Consumption Time: 1.83408
PPO Batch Consumption Time: 0.35884
Total Iteration Time: 3.90719

Cumulative Model Updates: 544
Cumulative Timesteps: 9,154,416

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02973
Policy Entropy: 4.38131
Value Function Loss: 0.07837

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.00193
Policy Update Magnitude: 0.13979
Value Function Update Magnitude: 0.10988

Collected Steps per Second: 22,181.92631
Overall Steps per Second: 12,056.51052

Timestep Collection Time: 2.25427
Timestep Consumption Time: 1.89320
PPO Batch Consumption Time: 0.36200
Total Iteration Time: 4.14747

Cumulative Model Updates: 547
Cumulative Timesteps: 9,204,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 9204420...
Checkpoint 9204420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01622
Policy Entropy: 4.38571
Value Function Loss: 0.08344

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.00187
Policy Update Magnitude: 0.13985
Value Function Update Magnitude: 0.11263

Collected Steps per Second: 24,247.70937
Overall Steps per Second: 12,737.41116

Timestep Collection Time: 2.06411
Timestep Consumption Time: 1.86526
PPO Batch Consumption Time: 0.35715
Total Iteration Time: 3.92937

Cumulative Model Updates: 550
Cumulative Timesteps: 9,254,470

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02513
Policy Entropy: 4.37175
Value Function Loss: 0.07590

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01305
Policy Update Magnitude: 0.14603
Value Function Update Magnitude: 0.11310

Collected Steps per Second: 24,820.40509
Overall Steps per Second: 12,611.66908

Timestep Collection Time: 2.01544
Timestep Consumption Time: 1.95105
PPO Batch Consumption Time: 0.35670
Total Iteration Time: 3.96649

Cumulative Model Updates: 553
Cumulative Timesteps: 9,304,494

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 9304494...
Checkpoint 9304494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00442
Policy Entropy: 4.34649
Value Function Loss: 0.07448

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04269
Policy Update Magnitude: 0.13482
Value Function Update Magnitude: 0.11960

Collected Steps per Second: 23,858.17503
Overall Steps per Second: 12,513.73709

Timestep Collection Time: 2.09656
Timestep Consumption Time: 1.90065
PPO Batch Consumption Time: 0.36222
Total Iteration Time: 3.99721

Cumulative Model Updates: 556
Cumulative Timesteps: 9,354,514

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01666
Policy Entropy: 4.33217
Value Function Loss: 0.06161

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03960
Policy Update Magnitude: 0.11941
Value Function Update Magnitude: 0.12751

Collected Steps per Second: 24,275.13646
Overall Steps per Second: 12,973.00762

Timestep Collection Time: 2.06087
Timestep Consumption Time: 1.79544
PPO Batch Consumption Time: 0.35234
Total Iteration Time: 3.85631

Cumulative Model Updates: 559
Cumulative Timesteps: 9,404,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 9404542...
Checkpoint 9404542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02421
Policy Entropy: 4.33883
Value Function Loss: 0.06284

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.00135
Policy Update Magnitude: 0.12388
Value Function Update Magnitude: 0.11980

Collected Steps per Second: 24,470.55130
Overall Steps per Second: 12,664.04935

Timestep Collection Time: 2.04376
Timestep Consumption Time: 1.90537
PPO Batch Consumption Time: 0.35645
Total Iteration Time: 3.94913

Cumulative Model Updates: 562
Cumulative Timesteps: 9,454,554

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01273
Policy Entropy: 4.33731
Value Function Loss: 0.04746

Mean KL Divergence: 0.00124
SB3 Clip Fraction: 0.00188
Policy Update Magnitude: 0.12750
Value Function Update Magnitude: 0.12275

Collected Steps per Second: 24,047.72264
Overall Steps per Second: 12,670.72018

Timestep Collection Time: 2.07937
Timestep Consumption Time: 1.86706
PPO Batch Consumption Time: 0.35963
Total Iteration Time: 3.94642

Cumulative Model Updates: 565
Cumulative Timesteps: 9,504,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 9504558...
Checkpoint 9504558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01422
Policy Entropy: 4.33354
Value Function Loss: 0.04707

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.00079
Policy Update Magnitude: 0.11662
Value Function Update Magnitude: 0.10532

Collected Steps per Second: 24,590.73241
Overall Steps per Second: 12,705.75036

Timestep Collection Time: 2.03451
Timestep Consumption Time: 1.90308
PPO Batch Consumption Time: 0.35761
Total Iteration Time: 3.93759

Cumulative Model Updates: 568
Cumulative Timesteps: 9,554,588

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00296
Policy Entropy: 4.33127
Value Function Loss: 0.05594

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.00121
Policy Update Magnitude: 0.11190
Value Function Update Magnitude: 0.08907

Collected Steps per Second: 22,995.59368
Overall Steps per Second: 12,227.33412

Timestep Collection Time: 2.17433
Timestep Consumption Time: 1.91487
PPO Batch Consumption Time: 0.36283
Total Iteration Time: 4.08920

Cumulative Model Updates: 571
Cumulative Timesteps: 9,604,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 9604588...
Checkpoint 9604588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02482
Policy Entropy: 4.33341
Value Function Loss: 0.07792

Mean KL Divergence: 0.00124
SB3 Clip Fraction: 0.00050
Policy Update Magnitude: 0.11361
Value Function Update Magnitude: 0.08829

Collected Steps per Second: 22,922.69808
Overall Steps per Second: 12,520.43575

Timestep Collection Time: 2.18229
Timestep Consumption Time: 1.81310
PPO Batch Consumption Time: 0.35809
Total Iteration Time: 3.99539

Cumulative Model Updates: 574
Cumulative Timesteps: 9,654,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00858
Policy Entropy: 4.34624
Value Function Loss: 0.07087

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.00332
Policy Update Magnitude: 0.13183
Value Function Update Magnitude: 0.09173

Collected Steps per Second: 23,971.80760
Overall Steps per Second: 12,514.42605

Timestep Collection Time: 2.08587
Timestep Consumption Time: 1.90968
PPO Batch Consumption Time: 0.36298
Total Iteration Time: 3.99555

Cumulative Model Updates: 577
Cumulative Timesteps: 9,704,614

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 9704614...
Checkpoint 9704614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00225
Policy Entropy: 4.36746
Value Function Loss: 0.05825

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01201
Policy Update Magnitude: 0.12601
Value Function Update Magnitude: 0.09091

Collected Steps per Second: 24,201.40096
Overall Steps per Second: 12,796.26816

Timestep Collection Time: 2.06600
Timestep Consumption Time: 1.84139
PPO Batch Consumption Time: 0.36089
Total Iteration Time: 3.90739

Cumulative Model Updates: 580
Cumulative Timesteps: 9,754,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04234
Policy Entropy: 4.37807
Value Function Loss: 0.06808

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.00845
Policy Update Magnitude: 0.11359
Value Function Update Magnitude: 0.09292

Collected Steps per Second: 23,504.38751
Overall Steps per Second: 12,329.98616

Timestep Collection Time: 2.12735
Timestep Consumption Time: 1.92797
PPO Batch Consumption Time: 0.35907
Total Iteration Time: 4.05532

Cumulative Model Updates: 583
Cumulative Timesteps: 9,804,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 9804616...
Checkpoint 9804616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12171
Policy Entropy: 4.39000
Value Function Loss: 0.06435

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.00111
Policy Update Magnitude: 0.10952
Value Function Update Magnitude: 0.09540

Collected Steps per Second: 24,198.23697
Overall Steps per Second: 12,698.90601

Timestep Collection Time: 2.06817
Timestep Consumption Time: 1.87280
PPO Batch Consumption Time: 0.35618
Total Iteration Time: 3.94097

Cumulative Model Updates: 586
Cumulative Timesteps: 9,854,662

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00942
Policy Entropy: 4.39729
Value Function Loss: 0.06347

Mean KL Divergence: 0.00105
SB3 Clip Fraction: 0.00030
Policy Update Magnitude: 0.11412
Value Function Update Magnitude: 0.10631

Collected Steps per Second: 23,740.82272
Overall Steps per Second: 12,497.58701

Timestep Collection Time: 2.10633
Timestep Consumption Time: 1.89492
PPO Batch Consumption Time: 0.35984
Total Iteration Time: 4.00125

Cumulative Model Updates: 589
Cumulative Timesteps: 9,904,668

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 9904668...
Checkpoint 9904668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00741
Policy Entropy: 4.39660
Value Function Loss: 0.03584

Mean KL Divergence: 0.00064
SB3 Clip Fraction: 0.00017
Policy Update Magnitude: 0.10838
Value Function Update Magnitude: 0.10956

Collected Steps per Second: 24,188.93471
Overall Steps per Second: 12,556.66204

Timestep Collection Time: 2.06731
Timestep Consumption Time: 1.91512
PPO Batch Consumption Time: 0.35979
Total Iteration Time: 3.98243

Cumulative Model Updates: 592
Cumulative Timesteps: 9,954,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01983
Policy Entropy: 4.38646
Value Function Loss: 0.04519

Mean KL Divergence: 0.00072
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10097
Value Function Update Magnitude: 0.10255

Collected Steps per Second: 25,203.56122
Overall Steps per Second: 13,008.09743

Timestep Collection Time: 1.98424
Timestep Consumption Time: 1.86028
PPO Batch Consumption Time: 0.35660
Total Iteration Time: 3.84453

Cumulative Model Updates: 595
Cumulative Timesteps: 10,004,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 10004684...
Checkpoint 10004684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04404
Policy Entropy: 4.38302
Value Function Loss: 0.03984

Mean KL Divergence: 0.00069
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10308
Value Function Update Magnitude: 0.09168

Collected Steps per Second: 24,126.69931
Overall Steps per Second: 12,628.78350

Timestep Collection Time: 2.07405
Timestep Consumption Time: 1.88833
PPO Batch Consumption Time: 0.35595
Total Iteration Time: 3.96238

Cumulative Model Updates: 598
Cumulative Timesteps: 10,054,724

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00786
Policy Entropy: 4.39330
Value Function Loss: 0.04436

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11463
Value Function Update Magnitude: 0.08805

Collected Steps per Second: 25,204.80924
Overall Steps per Second: 12,906.35214

Timestep Collection Time: 1.98407
Timestep Consumption Time: 1.89062
PPO Batch Consumption Time: 0.35696
Total Iteration Time: 3.87468

Cumulative Model Updates: 601
Cumulative Timesteps: 10,104,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 10104732...
Checkpoint 10104732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03271
Policy Entropy: 4.41343
Value Function Loss: 0.05511

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.00911
Policy Update Magnitude: 0.11805
Value Function Update Magnitude: 0.08981

Collected Steps per Second: 20,837.69967
Overall Steps per Second: 11,665.45281

Timestep Collection Time: 2.40190
Timestep Consumption Time: 1.88855
PPO Batch Consumption Time: 0.35207
Total Iteration Time: 4.29045

Cumulative Model Updates: 604
Cumulative Timesteps: 10,154,782

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03250
Policy Entropy: 4.42968
Value Function Loss: 0.06047

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03341
Policy Update Magnitude: 0.11043
Value Function Update Magnitude: 0.09238

Collected Steps per Second: 24,087.49534
Overall Steps per Second: 12,827.06056

Timestep Collection Time: 2.07701
Timestep Consumption Time: 1.82334
PPO Batch Consumption Time: 0.35814
Total Iteration Time: 3.90035

Cumulative Model Updates: 607
Cumulative Timesteps: 10,204,812

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 10204812...
Checkpoint 10204812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02061
Policy Entropy: 4.43059
Value Function Loss: 0.05450

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.00033
Policy Update Magnitude: 0.11896
Value Function Update Magnitude: 0.09595

Collected Steps per Second: 24,126.19956
Overall Steps per Second: 12,643.43830

Timestep Collection Time: 2.07285
Timestep Consumption Time: 1.88256
PPO Batch Consumption Time: 0.35681
Total Iteration Time: 3.95541

Cumulative Model Updates: 610
Cumulative Timesteps: 10,254,822

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01878
Policy Entropy: 4.43081
Value Function Loss: 0.05713

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11369
Value Function Update Magnitude: 0.09583

Collected Steps per Second: 23,853.49408
Overall Steps per Second: 12,549.18912

Timestep Collection Time: 2.09823
Timestep Consumption Time: 1.89008
PPO Batch Consumption Time: 0.35963
Total Iteration Time: 3.98831

Cumulative Model Updates: 613
Cumulative Timesteps: 10,304,872

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 10304872...
Checkpoint 10304872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00047
Policy Entropy: 4.43079
Value Function Loss: 0.06208

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11380
Value Function Update Magnitude: 0.10199

Collected Steps per Second: 25,201.67635
Overall Steps per Second: 12,942.56928

Timestep Collection Time: 1.98598
Timestep Consumption Time: 1.88110
PPO Batch Consumption Time: 0.35538
Total Iteration Time: 3.86708

Cumulative Model Updates: 616
Cumulative Timesteps: 10,354,922

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05120
Policy Entropy: 4.43047
Value Function Loss: 0.07595

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11971
Value Function Update Magnitude: 0.11315

Collected Steps per Second: 23,660.12885
Overall Steps per Second: 12,480.69010

Timestep Collection Time: 2.11427
Timestep Consumption Time: 1.89384
PPO Batch Consumption Time: 0.35975
Total Iteration Time: 4.00811

Cumulative Model Updates: 619
Cumulative Timesteps: 10,404,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 10404946...
Checkpoint 10404946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00295
Policy Entropy: 4.42678
Value Function Loss: 0.05921

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.11667
Value Function Update Magnitude: 0.11929

Collected Steps per Second: 22,292.55220
Overall Steps per Second: 12,274.12510

Timestep Collection Time: 2.24371
Timestep Consumption Time: 1.83137
PPO Batch Consumption Time: 0.36015
Total Iteration Time: 4.07508

Cumulative Model Updates: 622
Cumulative Timesteps: 10,454,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02355
Policy Entropy: 4.42334
Value Function Loss: 0.05741

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00017
Policy Update Magnitude: 0.11924
Value Function Update Magnitude: 0.12122

Collected Steps per Second: 24,075.28231
Overall Steps per Second: 12,620.45548

Timestep Collection Time: 2.07757
Timestep Consumption Time: 1.88568
PPO Batch Consumption Time: 0.35416
Total Iteration Time: 3.96325

Cumulative Model Updates: 625
Cumulative Timesteps: 10,504,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 10504982...
Checkpoint 10504982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02193
Policy Entropy: 4.42776
Value Function Loss: 0.04495

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.11917
Value Function Update Magnitude: 0.09644

Collected Steps per Second: 23,342.32673
Overall Steps per Second: 12,532.23288

Timestep Collection Time: 2.14357
Timestep Consumption Time: 1.84901
PPO Batch Consumption Time: 0.36314
Total Iteration Time: 3.99258

Cumulative Model Updates: 628
Cumulative Timesteps: 10,555,018

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00367
Policy Entropy: 4.43586
Value Function Loss: 0.04831

Mean KL Divergence: 0.00094
SB3 Clip Fraction: 0.00043
Policy Update Magnitude: 0.11402
Value Function Update Magnitude: 0.09960

Collected Steps per Second: 24,225.24922
Overall Steps per Second: 12,611.34274

Timestep Collection Time: 2.06586
Timestep Consumption Time: 1.90247
PPO Batch Consumption Time: 0.35386
Total Iteration Time: 3.96833

Cumulative Model Updates: 631
Cumulative Timesteps: 10,605,064

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 10605064...
Checkpoint 10605064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02992
Policy Entropy: 4.44253
Value Function Loss: 0.04890

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00045
Policy Update Magnitude: 0.10951
Value Function Update Magnitude: 0.10035

Collected Steps per Second: 23,040.64026
Overall Steps per Second: 12,302.49526

Timestep Collection Time: 2.17051
Timestep Consumption Time: 1.89452
PPO Batch Consumption Time: 0.35987
Total Iteration Time: 4.06503

Cumulative Model Updates: 634
Cumulative Timesteps: 10,655,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04036
Policy Entropy: 4.44557
Value Function Loss: 0.03829

Mean KL Divergence: 0.00079
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.11113
Value Function Update Magnitude: 0.09740

Collected Steps per Second: 25,005.76439
Overall Steps per Second: 12,803.68751

Timestep Collection Time: 1.99978
Timestep Consumption Time: 1.90581
PPO Batch Consumption Time: 0.36125
Total Iteration Time: 3.90559

Cumulative Model Updates: 637
Cumulative Timesteps: 10,705,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 10705080...
Checkpoint 10705080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00934
Policy Entropy: 4.44467
Value Function Loss: 0.02983

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.10420
Value Function Update Magnitude: 0.09361

Collected Steps per Second: 23,880.48023
Overall Steps per Second: 12,507.13387

Timestep Collection Time: 2.09602
Timestep Consumption Time: 1.90601
PPO Batch Consumption Time: 0.35843
Total Iteration Time: 4.00204

Cumulative Model Updates: 640
Cumulative Timesteps: 10,755,134

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00148
Policy Entropy: 4.44422
Value Function Loss: 0.02551

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.09703
Value Function Update Magnitude: 0.08533

Collected Steps per Second: 24,042.72374
Overall Steps per Second: 12,827.30344

Timestep Collection Time: 2.08113
Timestep Consumption Time: 1.81961
PPO Batch Consumption Time: 0.36274
Total Iteration Time: 3.90074

Cumulative Model Updates: 643
Cumulative Timesteps: 10,805,170

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 10805170...
Checkpoint 10805170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03948
Policy Entropy: 4.44324
Value Function Loss: 0.05318

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10454
Value Function Update Magnitude: 0.09262

Collected Steps per Second: 24,389.38016
Overall Steps per Second: 12,651.46044

Timestep Collection Time: 2.05007
Timestep Consumption Time: 1.90204
PPO Batch Consumption Time: 0.36095
Total Iteration Time: 3.95211

Cumulative Model Updates: 646
Cumulative Timesteps: 10,855,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03038
Policy Entropy: 4.44183
Value Function Loss: 0.06141

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11398
Value Function Update Magnitude: 0.10939

Collected Steps per Second: 23,875.41883
Overall Steps per Second: 12,595.99502

Timestep Collection Time: 2.09420
Timestep Consumption Time: 1.87531
PPO Batch Consumption Time: 0.35872
Total Iteration Time: 3.96952

Cumulative Model Updates: 649
Cumulative Timesteps: 10,905,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 10905170...
Checkpoint 10905170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03623
Policy Entropy: 4.43705
Value Function Loss: 0.06092

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.12852
Value Function Update Magnitude: 0.11754

Collected Steps per Second: 24,638.22764
Overall Steps per Second: 12,750.54709

Timestep Collection Time: 2.02985
Timestep Consumption Time: 1.89249
PPO Batch Consumption Time: 0.35816
Total Iteration Time: 3.92234

Cumulative Model Updates: 652
Cumulative Timesteps: 10,955,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01073
Policy Entropy: 4.42778
Value Function Loss: 0.04630

Mean KL Divergence: 0.00100
SB3 Clip Fraction: 0.00026
Policy Update Magnitude: 0.12947
Value Function Update Magnitude: 0.11351

Collected Steps per Second: 21,647.50723
Overall Steps per Second: 11,895.05419

Timestep Collection Time: 2.31029
Timestep Consumption Time: 1.89415
PPO Batch Consumption Time: 0.36421
Total Iteration Time: 4.20444

Cumulative Model Updates: 655
Cumulative Timesteps: 11,005,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 11005194...
Checkpoint 11005194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00386
Policy Entropy: 4.41819
Value Function Loss: 0.02847

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.00141
Policy Update Magnitude: 0.11805
Value Function Update Magnitude: 0.10847

Collected Steps per Second: 23,960.55988
Overall Steps per Second: 12,789.34945

Timestep Collection Time: 2.08843
Timestep Consumption Time: 1.82420
PPO Batch Consumption Time: 0.36295
Total Iteration Time: 3.91263

Cumulative Model Updates: 658
Cumulative Timesteps: 11,055,234

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01028
Policy Entropy: 4.41131
Value Function Loss: 0.03633

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.00061
Policy Update Magnitude: 0.10947
Value Function Update Magnitude: 0.09737

Collected Steps per Second: 23,574.52812
Overall Steps per Second: 12,393.30104

Timestep Collection Time: 2.12178
Timestep Consumption Time: 1.91427
PPO Batch Consumption Time: 0.35815
Total Iteration Time: 4.03605

Cumulative Model Updates: 661
Cumulative Timesteps: 11,105,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 11105254...
Checkpoint 11105254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00449
Policy Entropy: 4.40022
Value Function Loss: 0.03507

Mean KL Divergence: 0.00115
SB3 Clip Fraction: 0.00042
Policy Update Magnitude: 0.11285
Value Function Update Magnitude: 0.08111

Collected Steps per Second: 22,862.69466
Overall Steps per Second: 12,508.83734

Timestep Collection Time: 2.18863
Timestep Consumption Time: 1.81158
PPO Batch Consumption Time: 0.35524
Total Iteration Time: 4.00021

Cumulative Model Updates: 664
Cumulative Timesteps: 11,155,292

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04230
Policy Entropy: 4.38427
Value Function Loss: 0.05851

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.00473
Policy Update Magnitude: 0.11957
Value Function Update Magnitude: 0.08824

Collected Steps per Second: 24,012.35300
Overall Steps per Second: 12,534.89695

Timestep Collection Time: 2.08293
Timestep Consumption Time: 1.90721
PPO Batch Consumption Time: 0.35875
Total Iteration Time: 3.99014

Cumulative Model Updates: 667
Cumulative Timesteps: 11,205,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 11205308...
Checkpoint 11205308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02138
Policy Entropy: 4.36704
Value Function Loss: 0.06552

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01297
Policy Update Magnitude: 0.12726
Value Function Update Magnitude: 0.09508

Collected Steps per Second: 24,138.09395
Overall Steps per Second: 12,556.47659

Timestep Collection Time: 2.07216
Timestep Consumption Time: 1.91128
PPO Batch Consumption Time: 0.36462
Total Iteration Time: 3.98344

Cumulative Model Updates: 670
Cumulative Timesteps: 11,255,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00761
Policy Entropy: 4.35181
Value Function Loss: 0.07116

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01262
Policy Update Magnitude: 0.13414
Value Function Update Magnitude: 0.10347

Collected Steps per Second: 25,454.56859
Overall Steps per Second: 13,026.60212

Timestep Collection Time: 1.96436
Timestep Consumption Time: 1.87409
PPO Batch Consumption Time: 0.35503
Total Iteration Time: 3.83845

Cumulative Model Updates: 673
Cumulative Timesteps: 11,305,328

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 11305328...
Checkpoint 11305328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00715
Policy Entropy: 4.34657
Value Function Loss: 0.06385

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.00653
Policy Update Magnitude: 0.13973
Value Function Update Magnitude: 0.11216

Collected Steps per Second: 24,322.99774
Overall Steps per Second: 12,669.48121

Timestep Collection Time: 2.05731
Timestep Consumption Time: 1.89234
PPO Batch Consumption Time: 0.35909
Total Iteration Time: 3.94965

Cumulative Model Updates: 676
Cumulative Timesteps: 11,355,368

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00988
Policy Entropy: 4.32573
Value Function Loss: 0.05419

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01710
Policy Update Magnitude: 0.14048
Value Function Update Magnitude: 0.11855

Collected Steps per Second: 24,999.17776
Overall Steps per Second: 12,816.29711

Timestep Collection Time: 2.00063
Timestep Consumption Time: 1.90175
PPO Batch Consumption Time: 0.36556
Total Iteration Time: 3.90238

Cumulative Model Updates: 679
Cumulative Timesteps: 11,405,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 11405382...
Checkpoint 11405382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04530
Policy Entropy: 4.30084
Value Function Loss: 0.06284

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02249
Policy Update Magnitude: 0.13471
Value Function Update Magnitude: 0.12133

Collected Steps per Second: 23,728.05249
Overall Steps per Second: 12,546.64720

Timestep Collection Time: 2.10898
Timestep Consumption Time: 1.87950
PPO Batch Consumption Time: 0.35692
Total Iteration Time: 3.98848

Cumulative Model Updates: 682
Cumulative Timesteps: 11,455,424

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04012
Policy Entropy: 4.28826
Value Function Loss: 0.07228

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.01705
Policy Update Magnitude: 0.13827
Value Function Update Magnitude: 0.13096

Collected Steps per Second: 25,061.66972
Overall Steps per Second: 12,842.04287

Timestep Collection Time: 1.99604
Timestep Consumption Time: 1.89929
PPO Batch Consumption Time: 0.35681
Total Iteration Time: 3.89533

Cumulative Model Updates: 685
Cumulative Timesteps: 11,505,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 11505448...
Checkpoint 11505448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03431
Policy Entropy: 4.29257
Value Function Loss: 0.07072

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01284
Policy Update Magnitude: 0.14657
Value Function Update Magnitude: 0.14467

Collected Steps per Second: 24,241.98010
Overall Steps per Second: 12,564.49522

Timestep Collection Time: 2.06320
Timestep Consumption Time: 1.91754
PPO Batch Consumption Time: 0.36228
Total Iteration Time: 3.98074

Cumulative Model Updates: 688
Cumulative Timesteps: 11,555,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02908
Policy Entropy: 4.30272
Value Function Loss: 0.07477

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01835
Policy Update Magnitude: 0.14633
Value Function Update Magnitude: 0.14369

Collected Steps per Second: 23,474.49120
Overall Steps per Second: 12,780.02344

Timestep Collection Time: 2.13133
Timestep Consumption Time: 1.78353
PPO Batch Consumption Time: 0.35397
Total Iteration Time: 3.91486

Cumulative Model Updates: 691
Cumulative Timesteps: 11,605,496

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 11605496...
Checkpoint 11605496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05235
Policy Entropy: 4.31816
Value Function Loss: 0.05659

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02313
Policy Update Magnitude: 0.14241
Value Function Update Magnitude: 0.13458

Collected Steps per Second: 23,817.67574
Overall Steps per Second: 12,499.73146

Timestep Collection Time: 2.10088
Timestep Consumption Time: 1.90225
PPO Batch Consumption Time: 0.35603
Total Iteration Time: 4.00313

Cumulative Model Updates: 694
Cumulative Timesteps: 11,655,534

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02460
Policy Entropy: 4.33405
Value Function Loss: 0.05088

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02179
Policy Update Magnitude: 0.12965
Value Function Update Magnitude: 0.12978

Collected Steps per Second: 23,678.29675
Overall Steps per Second: 12,586.81055

Timestep Collection Time: 2.11206
Timestep Consumption Time: 1.86115
PPO Batch Consumption Time: 0.35691
Total Iteration Time: 3.97321

Cumulative Model Updates: 697
Cumulative Timesteps: 11,705,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 11705544...
Checkpoint 11705544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00199
Policy Entropy: 4.33042
Value Function Loss: 0.03463

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.00233
Policy Update Magnitude: 0.11474
Value Function Update Magnitude: 0.12165

Collected Steps per Second: 25,007.56469
Overall Steps per Second: 12,863.55969

Timestep Collection Time: 2.00107
Timestep Consumption Time: 1.88914
PPO Batch Consumption Time: 0.35643
Total Iteration Time: 3.89021

Cumulative Model Updates: 700
Cumulative Timesteps: 11,755,586

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01922
Policy Entropy: 4.31956
Value Function Loss: 0.03530

Mean KL Divergence: 0.00108
SB3 Clip Fraction: 0.00033
Policy Update Magnitude: 0.10935
Value Function Update Magnitude: 0.12677

Collected Steps per Second: 24,311.34624
Overall Steps per Second: 12,784.49463

Timestep Collection Time: 2.05706
Timestep Consumption Time: 1.85471
PPO Batch Consumption Time: 0.35395
Total Iteration Time: 3.91177

Cumulative Model Updates: 703
Cumulative Timesteps: 11,805,596

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 11805596...
Checkpoint 11805596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02680
Policy Entropy: 4.31464
Value Function Loss: 0.04838

Mean KL Divergence: 0.00103
SB3 Clip Fraction: 0.00083
Policy Update Magnitude: 0.10891
Value Function Update Magnitude: 0.11051

Collected Steps per Second: 23,806.29127
Overall Steps per Second: 12,736.20087

Timestep Collection Time: 2.10213
Timestep Consumption Time: 1.82714
PPO Batch Consumption Time: 0.36492
Total Iteration Time: 3.92927

Cumulative Model Updates: 706
Cumulative Timesteps: 11,855,640

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04130
Policy Entropy: 4.30740
Value Function Loss: 0.05309

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.00141
Policy Update Magnitude: 0.11726
Value Function Update Magnitude: 0.11402

Collected Steps per Second: 23,693.40970
Overall Steps per Second: 12,038.61012

Timestep Collection Time: 2.11063
Timestep Consumption Time: 2.04334
PPO Batch Consumption Time: 0.36503
Total Iteration Time: 4.15397

Cumulative Model Updates: 709
Cumulative Timesteps: 11,905,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 11905648...
Checkpoint 11905648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01548
Policy Entropy: 4.29435
Value Function Loss: 0.07673

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.00579
Policy Update Magnitude: 0.12808
Value Function Update Magnitude: 0.14797

Collected Steps per Second: 23,794.79089
Overall Steps per Second: 12,595.89009

Timestep Collection Time: 2.10349
Timestep Consumption Time: 1.87019
PPO Batch Consumption Time: 0.35693
Total Iteration Time: 3.97368

Cumulative Model Updates: 712
Cumulative Timesteps: 11,955,700

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02945
Policy Entropy: 4.29385
Value Function Loss: 0.06618

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.00249
Policy Update Magnitude: 0.13714
Value Function Update Magnitude: 0.15103

Collected Steps per Second: 24,935.23705
Overall Steps per Second: 12,889.04875

Timestep Collection Time: 2.00527
Timestep Consumption Time: 1.87414
PPO Batch Consumption Time: 0.35556
Total Iteration Time: 3.87942

Cumulative Model Updates: 715
Cumulative Timesteps: 12,005,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 12005702...
Checkpoint 12005702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02756
Policy Entropy: 4.30378
Value Function Loss: 0.06726

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.00983
Policy Update Magnitude: 0.13888
Value Function Update Magnitude: 0.15963

Collected Steps per Second: 24,300.21397
Overall Steps per Second: 12,677.84199

Timestep Collection Time: 2.05867
Timestep Consumption Time: 1.88727
PPO Batch Consumption Time: 0.35785
Total Iteration Time: 3.94594

Cumulative Model Updates: 718
Cumulative Timesteps: 12,055,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00455
Policy Entropy: 4.30101
Value Function Loss: 0.04835

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.01201
Policy Update Magnitude: 0.13167
Value Function Update Magnitude: 0.14910

Collected Steps per Second: 23,951.03735
Overall Steps per Second: 12,699.26468

Timestep Collection Time: 2.08868
Timestep Consumption Time: 1.85061
PPO Batch Consumption Time: 0.35891
Total Iteration Time: 3.93928

Cumulative Model Updates: 721
Cumulative Timesteps: 12,105,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 12105754...
Checkpoint 12105754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02324
Policy Entropy: 4.28991
Value Function Loss: 0.05422

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.00967
Policy Update Magnitude: 0.12070
Value Function Update Magnitude: 0.13369

Collected Steps per Second: 23,850.65623
Overall Steps per Second: 12,569.11437

Timestep Collection Time: 2.09839
Timestep Consumption Time: 1.88343
PPO Batch Consumption Time: 0.35141
Total Iteration Time: 3.98182

Cumulative Model Updates: 724
Cumulative Timesteps: 12,155,802

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01350
Policy Entropy: 4.29006
Value Function Loss: 0.06045

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.00138
Policy Update Magnitude: 0.12203
Value Function Update Magnitude: 0.12820

Collected Steps per Second: 23,801.28755
Overall Steps per Second: 12,532.66339

Timestep Collection Time: 2.10249
Timestep Consumption Time: 1.89043
PPO Batch Consumption Time: 0.36024
Total Iteration Time: 3.99293

Cumulative Model Updates: 727
Cumulative Timesteps: 12,205,844

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 12205844...
Checkpoint 12205844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04242
Policy Entropy: 4.30958
Value Function Loss: 0.05917

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.00467
Policy Update Magnitude: 0.13565
Value Function Update Magnitude: 0.13920

Collected Steps per Second: 25,195.04603
Overall Steps per Second: 12,916.97642

Timestep Collection Time: 1.98539
Timestep Consumption Time: 1.88719
PPO Batch Consumption Time: 0.35786
Total Iteration Time: 3.87258

Cumulative Model Updates: 730
Cumulative Timesteps: 12,255,866

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01249
Policy Entropy: 4.33552
Value Function Loss: 0.05417

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02231
Policy Update Magnitude: 0.12526
Value Function Update Magnitude: 0.12067

Collected Steps per Second: 24,052.14844
Overall Steps per Second: 12,632.11923

Timestep Collection Time: 2.07965
Timestep Consumption Time: 1.88010
PPO Batch Consumption Time: 0.35968
Total Iteration Time: 3.95975

Cumulative Model Updates: 733
Cumulative Timesteps: 12,305,886

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 12305886...
Checkpoint 12305886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02789
Policy Entropy: 4.33927
Value Function Loss: 0.03798

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.00857
Policy Update Magnitude: 0.12053
Value Function Update Magnitude: 0.09439

Collected Steps per Second: 23,739.28427
Overall Steps per Second: 12,728.32693

Timestep Collection Time: 2.10663
Timestep Consumption Time: 1.82240
PPO Batch Consumption Time: 0.35962
Total Iteration Time: 3.92903

Cumulative Model Updates: 736
Cumulative Timesteps: 12,355,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02363
Policy Entropy: 4.34188
Value Function Loss: 0.06474

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.00279
Policy Update Magnitude: 0.11458
Value Function Update Magnitude: 0.09226

Collected Steps per Second: 24,491.85112
Overall Steps per Second: 12,501.77911

Timestep Collection Time: 2.04280
Timestep Consumption Time: 1.95919
PPO Batch Consumption Time: 0.36561
Total Iteration Time: 4.00199

Cumulative Model Updates: 739
Cumulative Timesteps: 12,405,928

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 12405928...
Checkpoint 12405928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03438
Policy Entropy: 4.34959
Value Function Loss: 0.05749

Mean KL Divergence: 0.00093
SB3 Clip Fraction: 0.00105
Policy Update Magnitude: 0.11155
Value Function Update Magnitude: 0.08236

Collected Steps per Second: 24,230.61102
Overall Steps per Second: 12,664.17187

Timestep Collection Time: 2.06466
Timestep Consumption Time: 1.88570
PPO Batch Consumption Time: 0.36231
Total Iteration Time: 3.95036

Cumulative Model Updates: 742
Cumulative Timesteps: 12,455,956

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01003
Policy Entropy: 4.35640
Value Function Loss: 0.06249

Mean KL Divergence: 0.00083
SB3 Clip Fraction: 0.00014
Policy Update Magnitude: 0.12488
Value Function Update Magnitude: 0.08585

Collected Steps per Second: 24,828.36692
Overall Steps per Second: 12,844.79858

Timestep Collection Time: 2.01479
Timestep Consumption Time: 1.87970
PPO Batch Consumption Time: 0.35776
Total Iteration Time: 3.89449

Cumulative Model Updates: 745
Cumulative Timesteps: 12,505,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 12505980...
Checkpoint 12505980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01100
Policy Entropy: 4.36280
Value Function Loss: 0.06327

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.12969
Value Function Update Magnitude: 0.08188

Collected Steps per Second: 23,403.49986
Overall Steps per Second: 12,347.19062

Timestep Collection Time: 2.13763
Timestep Consumption Time: 1.91414
PPO Batch Consumption Time: 0.35551
Total Iteration Time: 4.05177

Cumulative Model Updates: 748
Cumulative Timesteps: 12,556,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05668
Policy Entropy: 4.36809
Value Function Loss: 0.08085

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00006
Policy Update Magnitude: 0.13077
Value Function Update Magnitude: 0.09010

Collected Steps per Second: 24,737.59858
Overall Steps per Second: 12,811.76850

Timestep Collection Time: 2.02324
Timestep Consumption Time: 1.88333
PPO Batch Consumption Time: 0.36084
Total Iteration Time: 3.90656

Cumulative Model Updates: 751
Cumulative Timesteps: 12,606,058

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 12606058...
Checkpoint 12606058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00821
Policy Entropy: 4.37471
Value Function Loss: 0.08129

Mean KL Divergence: 0.00095
SB3 Clip Fraction: 0.00065
Policy Update Magnitude: 0.14499
Value Function Update Magnitude: 0.11863

Collected Steps per Second: 22,825.08908
Overall Steps per Second: 12,141.03029

Timestep Collection Time: 2.19075
Timestep Consumption Time: 1.92785
PPO Batch Consumption Time: 0.35984
Total Iteration Time: 4.11860

Cumulative Model Updates: 754
Cumulative Timesteps: 12,656,062

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04138
Policy Entropy: 4.37806
Value Function Loss: 0.07632

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.00122
Policy Update Magnitude: 0.15097
Value Function Update Magnitude: 0.09954

Collected Steps per Second: 21,995.45301
Overall Steps per Second: 12,279.92803

Timestep Collection Time: 2.27320
Timestep Consumption Time: 1.79849
PPO Batch Consumption Time: 0.35597
Total Iteration Time: 4.07169

Cumulative Model Updates: 757
Cumulative Timesteps: 12,706,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 12706062...
Checkpoint 12706062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00077
Policy Entropy: 4.38682
Value Function Loss: 0.07375

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.00144
Policy Update Magnitude: 0.15003
Value Function Update Magnitude: 0.09484

Collected Steps per Second: 23,632.56145
Overall Steps per Second: 12,455.31460

Timestep Collection Time: 2.11615
Timestep Consumption Time: 1.89901
PPO Batch Consumption Time: 0.35793
Total Iteration Time: 4.01515

Cumulative Model Updates: 760
Cumulative Timesteps: 12,756,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01655
Policy Entropy: 4.39670
Value Function Loss: 0.07663

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.00153
Policy Update Magnitude: 0.15377
Value Function Update Magnitude: 0.09650

Collected Steps per Second: 23,797.71656
Overall Steps per Second: 12,562.41091

Timestep Collection Time: 2.10222
Timestep Consumption Time: 1.88014
PPO Batch Consumption Time: 0.36128
Total Iteration Time: 3.98236

Cumulative Model Updates: 763
Cumulative Timesteps: 12,806,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 12806100...
Checkpoint 12806100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03691
Policy Entropy: 4.39728
Value Function Loss: 0.08543

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00142
Policy Update Magnitude: 0.15584
Value Function Update Magnitude: 0.09284

Collected Steps per Second: 23,669.71155
Overall Steps per Second: 12,793.25100

Timestep Collection Time: 2.11418
Timestep Consumption Time: 1.79741
PPO Batch Consumption Time: 0.35994
Total Iteration Time: 3.91159

Cumulative Model Updates: 766
Cumulative Timesteps: 12,856,142

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01338
Policy Entropy: 4.38459
Value Function Loss: 0.07856

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00463
Policy Update Magnitude: 0.15205
Value Function Update Magnitude: 0.09593

Collected Steps per Second: 24,385.19817
Overall Steps per Second: 12,356.23469

Timestep Collection Time: 2.05100
Timestep Consumption Time: 1.99667
PPO Batch Consumption Time: 0.35962
Total Iteration Time: 4.04767

Cumulative Model Updates: 769
Cumulative Timesteps: 12,906,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 12906156...
Checkpoint 12906156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05728
Policy Entropy: 4.37781
Value Function Loss: 0.08366

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00460
Policy Update Magnitude: 0.15192
Value Function Update Magnitude: 0.08480

Collected Steps per Second: 22,209.63288
Overall Steps per Second: 12,094.90871

Timestep Collection Time: 2.25182
Timestep Consumption Time: 1.88315
PPO Batch Consumption Time: 0.35704
Total Iteration Time: 4.13496

Cumulative Model Updates: 772
Cumulative Timesteps: 12,956,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03018
Policy Entropy: 4.37258
Value Function Loss: 0.06265

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.00401
Policy Update Magnitude: 0.15763
Value Function Update Magnitude: 0.08423

Collected Steps per Second: 20,723.79729
Overall Steps per Second: 11,364.26639

Timestep Collection Time: 2.41336
Timestep Consumption Time: 1.98763
PPO Batch Consumption Time: 0.36283
Total Iteration Time: 4.40099

Cumulative Model Updates: 775
Cumulative Timesteps: 13,006,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 13006182...
Checkpoint 13006182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00411
Policy Entropy: 4.36936
Value Function Loss: 0.05929

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.00387
Policy Update Magnitude: 0.15457
Value Function Update Magnitude: 0.08372

Collected Steps per Second: 22,264.07183
Overall Steps per Second: 12,118.33308

Timestep Collection Time: 2.24667
Timestep Consumption Time: 1.88096
PPO Batch Consumption Time: 0.35748
Total Iteration Time: 4.12763

Cumulative Model Updates: 778
Cumulative Timesteps: 13,056,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01147
Policy Entropy: 4.38819
Value Function Loss: 0.05980

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.00319
Policy Update Magnitude: 0.14826
Value Function Update Magnitude: 0.08864

Collected Steps per Second: 23,905.96230
Overall Steps per Second: 12,590.46646

Timestep Collection Time: 2.09312
Timestep Consumption Time: 1.88116
PPO Batch Consumption Time: 0.35802
Total Iteration Time: 3.97428

Cumulative Model Updates: 781
Cumulative Timesteps: 13,106,240

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 13106240...
Checkpoint 13106240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00540
Policy Entropy: 4.41161
Value Function Loss: 0.07048

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 0.13421
Value Function Update Magnitude: 0.07767

Collected Steps per Second: 23,875.48431
Overall Steps per Second: 12,405.64433

Timestep Collection Time: 2.09487
Timestep Consumption Time: 1.93684
PPO Batch Consumption Time: 0.36585
Total Iteration Time: 4.03171

Cumulative Model Updates: 784
Cumulative Timesteps: 13,156,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01174
Policy Entropy: 4.41297
Value Function Loss: 0.06541

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.00507
Policy Update Magnitude: 0.13043
Value Function Update Magnitude: 0.09589

Collected Steps per Second: 23,739.92002
Overall Steps per Second: 12,870.56743

Timestep Collection Time: 2.10624
Timestep Consumption Time: 1.77875
PPO Batch Consumption Time: 0.35435
Total Iteration Time: 3.88499

Cumulative Model Updates: 787
Cumulative Timesteps: 13,206,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 13206258...
Checkpoint 13206258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02691
Policy Entropy: 4.41792
Value Function Loss: 0.03963

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00020
Policy Update Magnitude: 0.13750
Value Function Update Magnitude: 0.08652

Collected Steps per Second: 24,119.86156
Overall Steps per Second: 12,553.32251

Timestep Collection Time: 2.07389
Timestep Consumption Time: 1.91087
PPO Batch Consumption Time: 0.35818
Total Iteration Time: 3.98476

Cumulative Model Updates: 790
Cumulative Timesteps: 13,256,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00193
Policy Entropy: 4.43166
Value Function Loss: 0.03247

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.00046
Policy Update Magnitude: 0.13681
Value Function Update Magnitude: 0.09820

Collected Steps per Second: 20,882.20886
Overall Steps per Second: 11,808.95243

Timestep Collection Time: 2.39678
Timestep Consumption Time: 1.84153
PPO Batch Consumption Time: 0.36123
Total Iteration Time: 4.23831

Cumulative Model Updates: 793
Cumulative Timesteps: 13,306,330

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 13306330...
Checkpoint 13306330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00808
Policy Entropy: 4.44691
Value Function Loss: 0.05812

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01654
Policy Update Magnitude: 0.12186
Value Function Update Magnitude: 0.07537

Collected Steps per Second: 22,195.20533
Overall Steps per Second: 11,842.05004

Timestep Collection Time: 2.25283
Timestep Consumption Time: 1.96958
PPO Batch Consumption Time: 0.36021
Total Iteration Time: 4.22241

Cumulative Model Updates: 796
Cumulative Timesteps: 13,356,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01272
Policy Entropy: 4.45222
Value Function Loss: 0.07166

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.00770
Policy Update Magnitude: 0.12615
Value Function Update Magnitude: 0.09383

Collected Steps per Second: 23,383.33975
Overall Steps per Second: 12,248.05321

Timestep Collection Time: 2.13845
Timestep Consumption Time: 1.94416
PPO Batch Consumption Time: 0.36055
Total Iteration Time: 4.08261

Cumulative Model Updates: 799
Cumulative Timesteps: 13,406,336

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 13406336...
Checkpoint 13406336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05075
Policy Entropy: 4.45281
Value Function Loss: 0.06624

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00014
Policy Update Magnitude: 0.13674
Value Function Update Magnitude: 0.09015

Collected Steps per Second: 24,602.01879
Overall Steps per Second: 12,739.59964

Timestep Collection Time: 2.03430
Timestep Consumption Time: 1.89423
PPO Batch Consumption Time: 0.35859
Total Iteration Time: 3.92854

Cumulative Model Updates: 802
Cumulative Timesteps: 13,456,384

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02796
Policy Entropy: 4.45564
Value Function Loss: 0.03706

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00004
Policy Update Magnitude: 0.12761
Value Function Update Magnitude: 0.09591

Collected Steps per Second: 23,365.03622
Overall Steps per Second: 12,518.04614

Timestep Collection Time: 2.14012
Timestep Consumption Time: 1.85443
PPO Batch Consumption Time: 0.35521
Total Iteration Time: 3.99455

Cumulative Model Updates: 805
Cumulative Timesteps: 13,506,388

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 13506388...
Checkpoint 13506388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08300
Policy Entropy: 4.45907
Value Function Loss: 0.04380

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00007
Policy Update Magnitude: 0.11552
Value Function Update Magnitude: 0.08529

Collected Steps per Second: 23,172.82880
Overall Steps per Second: 12,482.62773

Timestep Collection Time: 2.15822
Timestep Consumption Time: 1.84831
PPO Batch Consumption Time: 0.36268
Total Iteration Time: 4.00653

Cumulative Model Updates: 808
Cumulative Timesteps: 13,556,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06204
Policy Entropy: 4.46244
Value Function Loss: 0.04607

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11532
Value Function Update Magnitude: 0.09284

Collected Steps per Second: 23,611.14764
Overall Steps per Second: 12,471.00403

Timestep Collection Time: 2.11790
Timestep Consumption Time: 1.89188
PPO Batch Consumption Time: 0.35829
Total Iteration Time: 4.00978

Cumulative Model Updates: 811
Cumulative Timesteps: 13,606,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 13606406...
Checkpoint 13606406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02061
Policy Entropy: 4.45780
Value Function Loss: 0.06177

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.13196
Value Function Update Magnitude: 0.09605

Collected Steps per Second: 22,972.96106
Overall Steps per Second: 12,228.28754

Timestep Collection Time: 2.17778
Timestep Consumption Time: 1.91356
PPO Batch Consumption Time: 0.36613
Total Iteration Time: 4.09133

Cumulative Model Updates: 814
Cumulative Timesteps: 13,656,436

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00389
Policy Entropy: 4.44796
Value Function Loss: 0.06834

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00064
Policy Update Magnitude: 0.13949
Value Function Update Magnitude: 0.11040

Collected Steps per Second: 25,076.21621
Overall Steps per Second: 12,759.89022

Timestep Collection Time: 1.99584
Timestep Consumption Time: 1.92646
PPO Batch Consumption Time: 0.36244
Total Iteration Time: 3.92229

Cumulative Model Updates: 817
Cumulative Timesteps: 13,706,484

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 13706484...
Checkpoint 13706484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02114
Policy Entropy: 4.43729
Value Function Loss: 0.07466

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.00674
Policy Update Magnitude: 0.14430
Value Function Update Magnitude: 0.09639

Collected Steps per Second: 23,962.53747
Overall Steps per Second: 12,537.81321

Timestep Collection Time: 2.08676
Timestep Consumption Time: 1.90150
PPO Batch Consumption Time: 0.35761
Total Iteration Time: 3.98826

Cumulative Model Updates: 820
Cumulative Timesteps: 13,756,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03582
Policy Entropy: 4.43427
Value Function Loss: 0.07515

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00030
Policy Update Magnitude: 0.14503
Value Function Update Magnitude: 0.09696

Collected Steps per Second: 25,035.61562
Overall Steps per Second: 12,845.59631

Timestep Collection Time: 1.99891
Timestep Consumption Time: 1.89690
PPO Batch Consumption Time: 0.35802
Total Iteration Time: 3.89581

Cumulative Model Updates: 823
Cumulative Timesteps: 13,806,532

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 13806532...
Checkpoint 13806532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06266
Policy Entropy: 4.43410
Value Function Loss: 0.07729

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.14357
Value Function Update Magnitude: 0.08353

Collected Steps per Second: 23,604.37237
Overall Steps per Second: 12,452.92771

Timestep Collection Time: 2.11876
Timestep Consumption Time: 1.89732
PPO Batch Consumption Time: 0.35905
Total Iteration Time: 4.01608

Cumulative Model Updates: 826
Cumulative Timesteps: 13,856,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04103
Policy Entropy: 4.43949
Value Function Loss: 0.08363

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00005
Policy Update Magnitude: 0.14020
Value Function Update Magnitude: 0.10000

Collected Steps per Second: 23,636.10568
Overall Steps per Second: 12,679.94547

Timestep Collection Time: 2.11592
Timestep Consumption Time: 1.82827
PPO Batch Consumption Time: 0.35395
Total Iteration Time: 3.94418

Cumulative Model Updates: 829
Cumulative Timesteps: 13,906,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 13906556...
Checkpoint 13906556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00730
Policy Entropy: 4.44768
Value Function Loss: 0.07743

Mean KL Divergence: 0.00105
SB3 Clip Fraction: 0.00231
Policy Update Magnitude: 0.14173
Value Function Update Magnitude: 0.11498

Collected Steps per Second: 24,213.79922
Overall Steps per Second: 12,630.55888

Timestep Collection Time: 2.06634
Timestep Consumption Time: 1.89500
PPO Batch Consumption Time: 0.35903
Total Iteration Time: 3.96134

Cumulative Model Updates: 832
Cumulative Timesteps: 13,956,590

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00799
Policy Entropy: 4.45358
Value Function Loss: 0.05722

Mean KL Divergence: 0.00101
SB3 Clip Fraction: 0.00268
Policy Update Magnitude: 0.13392
Value Function Update Magnitude: 0.13210

Collected Steps per Second: 23,869.94244
Overall Steps per Second: 12,655.48567

Timestep Collection Time: 2.09644
Timestep Consumption Time: 1.85773
PPO Batch Consumption Time: 0.35857
Total Iteration Time: 3.95417

Cumulative Model Updates: 835
Cumulative Timesteps: 14,006,632

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 14006632...
Checkpoint 14006632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00789
Policy Entropy: 4.45522
Value Function Loss: 0.04299

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00020
Policy Update Magnitude: 0.12512
Value Function Update Magnitude: 0.10892

Collected Steps per Second: 23,849.12259
Overall Steps per Second: 12,520.46301

Timestep Collection Time: 2.09861
Timestep Consumption Time: 1.89885
PPO Batch Consumption Time: 0.36365
Total Iteration Time: 3.99746

Cumulative Model Updates: 838
Cumulative Timesteps: 14,056,682

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06008
Policy Entropy: 4.45695
Value Function Loss: 0.03631

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11627
Value Function Update Magnitude: 0.09032

Collected Steps per Second: 20,851.32113
Overall Steps per Second: 11,454.37419

Timestep Collection Time: 2.39908
Timestep Consumption Time: 1.96816
PPO Batch Consumption Time: 0.37161
Total Iteration Time: 4.36724

Cumulative Model Updates: 841
Cumulative Timesteps: 14,106,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 14106706...
Checkpoint 14106706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04505
Policy Entropy: 4.45852
Value Function Loss: 0.03161

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11333
Value Function Update Magnitude: 0.07565

Collected Steps per Second: 21,088.09422
Overall Steps per Second: 11,614.82671

Timestep Collection Time: 2.37148
Timestep Consumption Time: 1.93422
PPO Batch Consumption Time: 0.36883
Total Iteration Time: 4.30570

Cumulative Model Updates: 844
Cumulative Timesteps: 14,156,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03028
Policy Entropy: 4.45774
Value Function Loss: 0.02733

Mean KL Divergence: 0.00019
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10642
Value Function Update Magnitude: 0.07333

Collected Steps per Second: 24,801.77292
Overall Steps per Second: 12,753.86994

Timestep Collection Time: 2.01760
Timestep Consumption Time: 1.90592
PPO Batch Consumption Time: 0.36701
Total Iteration Time: 3.92351

Cumulative Model Updates: 847
Cumulative Timesteps: 14,206,756

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 14206756...
Checkpoint 14206756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03572
Policy Entropy: 4.45531
Value Function Loss: 0.02115

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10544
Value Function Update Magnitude: 0.08222

Collected Steps per Second: 24,207.90048
Overall Steps per Second: 12,971.04508

Timestep Collection Time: 2.06635
Timestep Consumption Time: 1.79009
PPO Batch Consumption Time: 0.35829
Total Iteration Time: 3.85644

Cumulative Model Updates: 850
Cumulative Timesteps: 14,256,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01068
Policy Entropy: 4.44938
Value Function Loss: 0.03960

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11143
Value Function Update Magnitude: 0.08793

Collected Steps per Second: 23,945.06538
Overall Steps per Second: 12,580.32040

Timestep Collection Time: 2.08878
Timestep Consumption Time: 1.88695
PPO Batch Consumption Time: 0.35906
Total Iteration Time: 3.97573

Cumulative Model Updates: 853
Cumulative Timesteps: 14,306,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 14306794...
Checkpoint 14306794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14496
Policy Entropy: 4.44161
Value Function Loss: 0.04240

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.11170
Value Function Update Magnitude: 0.10248

Collected Steps per Second: 23,900.65744
Overall Steps per Second: 12,952.13413

Timestep Collection Time: 2.09266
Timestep Consumption Time: 1.76894
PPO Batch Consumption Time: 0.35771
Total Iteration Time: 3.86160

Cumulative Model Updates: 856
Cumulative Timesteps: 14,356,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01217
Policy Entropy: 4.43926
Value Function Loss: 0.04606

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.12070
Value Function Update Magnitude: 0.09972

Collected Steps per Second: 24,761.90137
Overall Steps per Second: 12,772.89792

Timestep Collection Time: 2.01988
Timestep Consumption Time: 1.89591
PPO Batch Consumption Time: 0.36540
Total Iteration Time: 3.91579

Cumulative Model Updates: 859
Cumulative Timesteps: 14,406,826

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 14406826...
Checkpoint 14406826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02188
Policy Entropy: 4.44294
Value Function Loss: 0.03784

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.12627
Value Function Update Magnitude: 0.11328

Collected Steps per Second: 24,844.73531
Overall Steps per Second: 12,921.82536

Timestep Collection Time: 2.01306
Timestep Consumption Time: 1.85744
PPO Batch Consumption Time: 0.35424
Total Iteration Time: 3.87051

Cumulative Model Updates: 862
Cumulative Timesteps: 14,456,840

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03806
Policy Entropy: 4.44796
Value Function Loss: 0.03770

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.12435
Value Function Update Magnitude: 0.10851

Collected Steps per Second: 25,284.72476
Overall Steps per Second: 13,006.04207

Timestep Collection Time: 1.97898
Timestep Consumption Time: 1.86831
PPO Batch Consumption Time: 0.36097
Total Iteration Time: 3.84729

Cumulative Model Updates: 865
Cumulative Timesteps: 14,506,878

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 14506878...
Checkpoint 14506878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02415
Policy Entropy: 4.45233
Value Function Loss: 0.03528

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00012
Policy Update Magnitude: 0.12951
Value Function Update Magnitude: 0.09221

Collected Steps per Second: 24,399.26838
Overall Steps per Second: 12,761.43067

Timestep Collection Time: 2.04998
Timestep Consumption Time: 1.86949
PPO Batch Consumption Time: 0.35391
Total Iteration Time: 3.91947

Cumulative Model Updates: 868
Cumulative Timesteps: 14,556,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02865
Policy Entropy: 4.45558
Value Function Loss: 0.03236

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00015
Policy Update Magnitude: 0.12674
Value Function Update Magnitude: 0.08808

Collected Steps per Second: 24,975.77084
Overall Steps per Second: 13,058.04799

Timestep Collection Time: 2.00306
Timestep Consumption Time: 1.82814
PPO Batch Consumption Time: 0.36496
Total Iteration Time: 3.83120

Cumulative Model Updates: 871
Cumulative Timesteps: 14,606,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 14606924...
Checkpoint 14606924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04324
Policy Entropy: 4.45924
Value Function Loss: 0.02028

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00011
Policy Update Magnitude: 0.11832
Value Function Update Magnitude: 0.08001

Collected Steps per Second: 24,770.34291
Overall Steps per Second: 12,851.44251

Timestep Collection Time: 2.02008
Timestep Consumption Time: 1.87349
PPO Batch Consumption Time: 0.36321
Total Iteration Time: 3.89357

Cumulative Model Updates: 874
Cumulative Timesteps: 14,656,962

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01945
Policy Entropy: 4.46210
Value Function Loss: 0.03347

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00007
Policy Update Magnitude: 0.11351
Value Function Update Magnitude: 0.07926

Collected Steps per Second: 24,196.25971
Overall Steps per Second: 12,765.70748

Timestep Collection Time: 2.06660
Timestep Consumption Time: 1.85046
PPO Batch Consumption Time: 0.35699
Total Iteration Time: 3.91706

Cumulative Model Updates: 877
Cumulative Timesteps: 14,706,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 14706966...
Checkpoint 14706966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00773
Policy Entropy: 4.46473
Value Function Loss: 0.03528

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.11344
Value Function Update Magnitude: 0.09688

Collected Steps per Second: 25,564.87063
Overall Steps per Second: 13,002.31570

Timestep Collection Time: 1.95643
Timestep Consumption Time: 1.89026
PPO Batch Consumption Time: 0.35452
Total Iteration Time: 3.84670

Cumulative Model Updates: 880
Cumulative Timesteps: 14,756,982

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06788
Policy Entropy: 4.46793
Value Function Loss: 0.04591

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00015
Policy Update Magnitude: 0.12360
Value Function Update Magnitude: 0.07459

Collected Steps per Second: 25,059.80294
Overall Steps per Second: 12,976.74331

Timestep Collection Time: 1.99539
Timestep Consumption Time: 1.85797
PPO Batch Consumption Time: 0.35718
Total Iteration Time: 3.85336

Cumulative Model Updates: 883
Cumulative Timesteps: 14,806,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 14806986...
Checkpoint 14806986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04094
Policy Entropy: 4.47128
Value Function Loss: 0.05134

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00037
Policy Update Magnitude: 0.12470
Value Function Update Magnitude: 0.08827

Collected Steps per Second: 24,638.84338
Overall Steps per Second: 13,128.88742

Timestep Collection Time: 2.02972
Timestep Consumption Time: 1.77944
PPO Batch Consumption Time: 0.35478
Total Iteration Time: 3.80916

Cumulative Model Updates: 886
Cumulative Timesteps: 14,856,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01065
Policy Entropy: 4.47244
Value Function Loss: 0.05452

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00009
Policy Update Magnitude: 0.12861
Value Function Update Magnitude: 0.09757

Collected Steps per Second: 24,433.27282
Overall Steps per Second: 12,804.38596

Timestep Collection Time: 2.04803
Timestep Consumption Time: 1.86001
PPO Batch Consumption Time: 0.35298
Total Iteration Time: 3.90804

Cumulative Model Updates: 889
Cumulative Timesteps: 14,907,036

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 14907036...
Checkpoint 14907036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08641
Policy Entropy: 4.47178
Value Function Loss: 0.07717

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.13977
Value Function Update Magnitude: 0.10860

Collected Steps per Second: 24,685.84677
Overall Steps per Second: 12,753.42051

Timestep Collection Time: 2.02683
Timestep Consumption Time: 1.89635
PPO Batch Consumption Time: 0.36149
Total Iteration Time: 3.92318

Cumulative Model Updates: 892
Cumulative Timesteps: 14,957,070

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04774
Policy Entropy: 4.47157
Value Function Loss: 0.10488

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.15414
Value Function Update Magnitude: 0.10674

Collected Steps per Second: 25,815.24354
Overall Steps per Second: 13,100.45155

Timestep Collection Time: 1.93785
Timestep Consumption Time: 1.88080
PPO Batch Consumption Time: 0.36236
Total Iteration Time: 3.81865

Cumulative Model Updates: 895
Cumulative Timesteps: 15,007,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 15007096...
Checkpoint 15007096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02370
Policy Entropy: 4.47315
Value Function Loss: 0.10698

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.16910
Value Function Update Magnitude: 0.10367

Collected Steps per Second: 24,765.76191
Overall Steps per Second: 12,922.86326

Timestep Collection Time: 2.02094
Timestep Consumption Time: 1.85205
PPO Batch Consumption Time: 0.36051
Total Iteration Time: 3.87298

Cumulative Model Updates: 898
Cumulative Timesteps: 15,057,146

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07275
Policy Entropy: 4.47530
Value Function Loss: 0.08393

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00038
Policy Update Magnitude: 0.17274
Value Function Update Magnitude: 0.09173

Collected Steps per Second: 23,942.30941
Overall Steps per Second: 12,755.76966

Timestep Collection Time: 2.08869
Timestep Consumption Time: 1.83173
PPO Batch Consumption Time: 0.37044
Total Iteration Time: 3.92042

Cumulative Model Updates: 901
Cumulative Timesteps: 15,107,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 15107154...
Checkpoint 15107154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04079
Policy Entropy: 4.47532
Value Function Loss: 0.05212

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00037
Policy Update Magnitude: 0.15972
Value Function Update Magnitude: 0.08206

Collected Steps per Second: 25,165.89550
Overall Steps per Second: 12,760.96186

Timestep Collection Time: 1.98841
Timestep Consumption Time: 1.93293
PPO Batch Consumption Time: 0.36489
Total Iteration Time: 3.92133

Cumulative Model Updates: 904
Cumulative Timesteps: 15,157,194

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04704
Policy Entropy: 4.47250
Value Function Loss: 0.04362

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.15174
Value Function Update Magnitude: 0.09263

Collected Steps per Second: 24,782.04879
Overall Steps per Second: 12,894.96500

Timestep Collection Time: 2.01888
Timestep Consumption Time: 1.86108
PPO Batch Consumption Time: 0.35989
Total Iteration Time: 3.87996

Cumulative Model Updates: 907
Cumulative Timesteps: 15,207,226

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 15207226...
Checkpoint 15207226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02428
Policy Entropy: 4.46660
Value Function Loss: 0.06330

Mean KL Divergence: 0.00092
SB3 Clip Fraction: 0.00089
Policy Update Magnitude: 0.15447
Value Function Update Magnitude: 0.08081

Collected Steps per Second: 25,594.38550
Overall Steps per Second: 13,087.35794

Timestep Collection Time: 1.95551
Timestep Consumption Time: 1.86879
PPO Batch Consumption Time: 0.35620
Total Iteration Time: 3.82430

Cumulative Model Updates: 910
Cumulative Timesteps: 15,257,276

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03801
Policy Entropy: 4.45574
Value Function Loss: 0.05349

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01185
Policy Update Magnitude: 0.15437
Value Function Update Magnitude: 0.07710

Collected Steps per Second: 24,149.18046
Overall Steps per Second: 12,719.40853

Timestep Collection Time: 2.07253
Timestep Consumption Time: 1.86240
PPO Batch Consumption Time: 0.36584
Total Iteration Time: 3.93493

Cumulative Model Updates: 913
Cumulative Timesteps: 15,307,326

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 15307326...
Checkpoint 15307326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01487
Policy Entropy: 4.44408
Value Function Loss: 0.07440

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.01882
Policy Update Magnitude: 0.14506
Value Function Update Magnitude: 0.07096

Collected Steps per Second: 24,849.14280
Overall Steps per Second: 12,995.13650

Timestep Collection Time: 2.01238
Timestep Consumption Time: 1.83567
PPO Batch Consumption Time: 0.35665
Total Iteration Time: 3.84805

Cumulative Model Updates: 916
Cumulative Timesteps: 15,357,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00019
Policy Entropy: 4.43778
Value Function Loss: 0.05632

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.00359
Policy Update Magnitude: 0.14068
Value Function Update Magnitude: 0.08679

Collected Steps per Second: 24,827.56321
Overall Steps per Second: 12,826.64702

Timestep Collection Time: 2.01526
Timestep Consumption Time: 1.88553
PPO Batch Consumption Time: 0.36001
Total Iteration Time: 3.90079

Cumulative Model Updates: 919
Cumulative Timesteps: 15,407,366

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 15407366...
Checkpoint 15407366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06291
Policy Entropy: 4.43474
Value Function Loss: 0.05498

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00043
Policy Update Magnitude: 0.13642
Value Function Update Magnitude: 0.10747

Collected Steps per Second: 25,064.81732
Overall Steps per Second: 13,003.01274

Timestep Collection Time: 1.99626
Timestep Consumption Time: 1.85177
PPO Batch Consumption Time: 0.36210
Total Iteration Time: 3.84803

Cumulative Model Updates: 922
Cumulative Timesteps: 15,457,402

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02384
Policy Entropy: 4.43164
Value Function Loss: 0.05024

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.13389
Value Function Update Magnitude: 0.09912

Collected Steps per Second: 25,247.50474
Overall Steps per Second: 12,967.54128

Timestep Collection Time: 1.98127
Timestep Consumption Time: 1.87621
PPO Batch Consumption Time: 0.35903
Total Iteration Time: 3.85748

Cumulative Model Updates: 925
Cumulative Timesteps: 15,507,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 15507424...
Checkpoint 15507424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00692
Policy Entropy: 4.42982
Value Function Loss: 0.05594

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.13634
Value Function Update Magnitude: 0.11263

Collected Steps per Second: 24,333.83476
Overall Steps per Second: 12,470.58818

Timestep Collection Time: 2.05541
Timestep Consumption Time: 1.95531
PPO Batch Consumption Time: 0.36802
Total Iteration Time: 4.01072

Cumulative Model Updates: 928
Cumulative Timesteps: 15,557,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03094
Policy Entropy: 4.43061
Value Function Loss: 0.05674

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00004
Policy Update Magnitude: 0.14838
Value Function Update Magnitude: 0.11437

Collected Steps per Second: 25,767.27765
Overall Steps per Second: 13,104.91385

Timestep Collection Time: 1.94184
Timestep Consumption Time: 1.87627
PPO Batch Consumption Time: 0.36227
Total Iteration Time: 3.81811

Cumulative Model Updates: 931
Cumulative Timesteps: 15,607,476

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 15607476...
Checkpoint 15607476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02229
Policy Entropy: 4.43224
Value Function Loss: 0.04886

Mean KL Divergence: 0.00094
SB3 Clip Fraction: 0.00120
Policy Update Magnitude: 0.14892
Value Function Update Magnitude: 0.11643

Collected Steps per Second: 23,947.44547
Overall Steps per Second: 12,688.56759

Timestep Collection Time: 2.08857
Timestep Consumption Time: 1.85324
PPO Batch Consumption Time: 0.35792
Total Iteration Time: 3.94182

Cumulative Model Updates: 934
Cumulative Timesteps: 15,657,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01906
Policy Entropy: 4.43165
Value Function Loss: 0.05115

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.00306
Policy Update Magnitude: 0.13983
Value Function Update Magnitude: 0.12000

Collected Steps per Second: 24,875.72081
Overall Steps per Second: 12,893.86299

Timestep Collection Time: 2.01184
Timestep Consumption Time: 1.86954
PPO Batch Consumption Time: 0.35205
Total Iteration Time: 3.88138

Cumulative Model Updates: 937
Cumulative Timesteps: 15,707,538

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 15707538...
Checkpoint 15707538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00774
Policy Entropy: 4.42572
Value Function Loss: 0.04966

Mean KL Divergence: 0.00100
SB3 Clip Fraction: 0.00173
Policy Update Magnitude: 0.14035
Value Function Update Magnitude: 0.12267

Collected Steps per Second: 24,805.00824
Overall Steps per Second: 12,687.52938

Timestep Collection Time: 2.01693
Timestep Consumption Time: 1.92631
PPO Batch Consumption Time: 0.36184
Total Iteration Time: 3.94324

Cumulative Model Updates: 940
Cumulative Timesteps: 15,757,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02620
Policy Entropy: 4.41691
Value Function Loss: 0.04025

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.00550
Policy Update Magnitude: 0.13798
Value Function Update Magnitude: 0.12370

Collected Steps per Second: 23,749.70865
Overall Steps per Second: 12,856.75801

Timestep Collection Time: 2.10613
Timestep Consumption Time: 1.78443
PPO Batch Consumption Time: 0.35355
Total Iteration Time: 3.89056

Cumulative Model Updates: 943
Cumulative Timesteps: 15,807,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 15807588...
Checkpoint 15807588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09287
Policy Entropy: 4.40690
Value Function Loss: 0.03693

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.00849
Policy Update Magnitude: 0.12666
Value Function Update Magnitude: 0.11340

Collected Steps per Second: 24,516.63728
Overall Steps per Second: 12,837.12400

Timestep Collection Time: 2.04017
Timestep Consumption Time: 1.85619
PPO Batch Consumption Time: 0.35510
Total Iteration Time: 3.89636

Cumulative Model Updates: 946
Cumulative Timesteps: 15,857,606

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00362
Policy Entropy: 4.39810
Value Function Loss: 0.04429

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01001
Policy Update Magnitude: 0.12952
Value Function Update Magnitude: 0.11194

Collected Steps per Second: 23,790.64838
Overall Steps per Second: 12,689.51440

Timestep Collection Time: 2.10326
Timestep Consumption Time: 1.83999
PPO Batch Consumption Time: 0.35681
Total Iteration Time: 3.94326

Cumulative Model Updates: 949
Cumulative Timesteps: 15,907,644

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 15907644...
Checkpoint 15907644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00987
Policy Entropy: 4.38956
Value Function Loss: 0.05753

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01162
Policy Update Magnitude: 0.13541
Value Function Update Magnitude: 0.11989

Collected Steps per Second: 25,244.63439
Overall Steps per Second: 12,921.97852

Timestep Collection Time: 1.98062
Timestep Consumption Time: 1.88876
PPO Batch Consumption Time: 0.35787
Total Iteration Time: 3.86938

Cumulative Model Updates: 952
Cumulative Timesteps: 15,957,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01195
Policy Entropy: 4.37732
Value Function Loss: 0.06074

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01686
Policy Update Magnitude: 0.13478
Value Function Update Magnitude: 0.11572

Collected Steps per Second: 24,715.64407
Overall Steps per Second: 12,859.87132

Timestep Collection Time: 2.02341
Timestep Consumption Time: 1.86543
PPO Batch Consumption Time: 0.36481
Total Iteration Time: 3.88884

Cumulative Model Updates: 955
Cumulative Timesteps: 16,007,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 16007654...
Checkpoint 16007654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00814
Policy Entropy: 4.37330
Value Function Loss: 0.07784

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.00472
Policy Update Magnitude: 0.14541
Value Function Update Magnitude: 0.12676

Collected Steps per Second: 24,788.98963
Overall Steps per Second: 13,157.74145

Timestep Collection Time: 2.01840
Timestep Consumption Time: 1.78423
PPO Batch Consumption Time: 0.35396
Total Iteration Time: 3.80263

Cumulative Model Updates: 958
Cumulative Timesteps: 16,057,688

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03826
Policy Entropy: 4.37403
Value Function Loss: 0.07157

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.00517
Policy Update Magnitude: 0.16023
Value Function Update Magnitude: 0.13229

Collected Steps per Second: 24,464.94850
Overall Steps per Second: 12,779.14089

Timestep Collection Time: 2.04399
Timestep Consumption Time: 1.86911
PPO Batch Consumption Time: 0.36289
Total Iteration Time: 3.91310

Cumulative Model Updates: 961
Cumulative Timesteps: 16,107,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 16107694...
Checkpoint 16107694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00418
Policy Entropy: 4.37255
Value Function Loss: 0.06477

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01031
Policy Update Magnitude: 0.16334
Value Function Update Magnitude: 0.12681

Collected Steps per Second: 24,213.38317
Overall Steps per Second: 12,898.05549

Timestep Collection Time: 2.06679
Timestep Consumption Time: 1.81317
PPO Batch Consumption Time: 0.36265
Total Iteration Time: 3.87996

Cumulative Model Updates: 964
Cumulative Timesteps: 16,157,738

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01266
Policy Entropy: 4.36526
Value Function Loss: 0.06717

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01426
Policy Update Magnitude: 0.15226
Value Function Update Magnitude: 0.10650

Collected Steps per Second: 24,493.78211
Overall Steps per Second: 12,693.11238

Timestep Collection Time: 2.04133
Timestep Consumption Time: 1.89781
PPO Batch Consumption Time: 0.36173
Total Iteration Time: 3.93914

Cumulative Model Updates: 967
Cumulative Timesteps: 16,207,738

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 16207738...
Checkpoint 16207738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01198
Policy Entropy: 4.36357
Value Function Loss: 0.07622

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01108
Policy Update Magnitude: 0.15325
Value Function Update Magnitude: 0.10423

Collected Steps per Second: 24,766.72504
Overall Steps per Second: 12,839.49076

Timestep Collection Time: 2.01948
Timestep Consumption Time: 1.87600
PPO Batch Consumption Time: 0.35932
Total Iteration Time: 3.89548

Cumulative Model Updates: 970
Cumulative Timesteps: 16,257,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00559
Policy Entropy: 4.36822
Value Function Loss: 0.08581

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01551
Policy Update Magnitude: 0.15786
Value Function Update Magnitude: 0.10057

Collected Steps per Second: 24,831.39019
Overall Steps per Second: 12,874.62107

Timestep Collection Time: 2.01567
Timestep Consumption Time: 1.87197
PPO Batch Consumption Time: 0.35534
Total Iteration Time: 3.88765

Cumulative Model Updates: 973
Cumulative Timesteps: 16,307,806

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 16307806...
Checkpoint 16307806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03231
Policy Entropy: 4.36677
Value Function Loss: 0.07115

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01600
Policy Update Magnitude: 0.15304
Value Function Update Magnitude: 0.10570

Collected Steps per Second: 23,757.47124
Overall Steps per Second: 12,557.53612

Timestep Collection Time: 2.10511
Timestep Consumption Time: 1.87752
PPO Batch Consumption Time: 0.35480
Total Iteration Time: 3.98263

Cumulative Model Updates: 976
Cumulative Timesteps: 16,357,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00515
Policy Entropy: 4.36931
Value Function Loss: 0.05476

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01089
Policy Update Magnitude: 0.14781
Value Function Update Magnitude: 0.10304

Collected Steps per Second: 24,447.79304
Overall Steps per Second: 12,871.94947

Timestep Collection Time: 2.04657
Timestep Consumption Time: 1.84049
PPO Batch Consumption Time: 0.35959
Total Iteration Time: 3.88706

Cumulative Model Updates: 979
Cumulative Timesteps: 16,407,852

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 16407852...
Checkpoint 16407852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02478
Policy Entropy: 4.37999
Value Function Loss: 0.03890

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.00783
Policy Update Magnitude: 0.13934
Value Function Update Magnitude: 0.10370

Collected Steps per Second: 24,490.96737
Overall Steps per Second: 12,831.37951

Timestep Collection Time: 2.04247
Timestep Consumption Time: 1.85594
PPO Batch Consumption Time: 0.35719
Total Iteration Time: 3.89841

Cumulative Model Updates: 982
Cumulative Timesteps: 16,457,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00082
Policy Entropy: 4.39209
Value Function Loss: 0.05167

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.00827
Policy Update Magnitude: 0.12995
Value Function Update Magnitude: 0.08935

Collected Steps per Second: 24,491.24580
Overall Steps per Second: 12,895.61756

Timestep Collection Time: 2.04155
Timestep Consumption Time: 1.83574
PPO Batch Consumption Time: 0.35744
Total Iteration Time: 3.87729

Cumulative Model Updates: 985
Cumulative Timesteps: 16,507,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 16507874...
Checkpoint 16507874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04698
Policy Entropy: 4.40446
Value Function Loss: 0.05766

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.00713
Policy Update Magnitude: 0.12866
Value Function Update Magnitude: 0.09724

Collected Steps per Second: 25,276.73884
Overall Steps per Second: 13,013.84115

Timestep Collection Time: 1.97850
Timestep Consumption Time: 1.86433
PPO Batch Consumption Time: 0.35669
Total Iteration Time: 3.84283

Cumulative Model Updates: 988
Cumulative Timesteps: 16,557,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04958
Policy Entropy: 4.41085
Value Function Loss: 0.07689

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.00517
Policy Update Magnitude: 0.13812
Value Function Update Magnitude: 0.09543

Collected Steps per Second: 25,045.51396
Overall Steps per Second: 12,904.82501

Timestep Collection Time: 1.99637
Timestep Consumption Time: 1.87815
PPO Batch Consumption Time: 0.36041
Total Iteration Time: 3.87452

Cumulative Model Updates: 991
Cumulative Timesteps: 16,607,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 16607884...
Checkpoint 16607884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01713
Policy Entropy: 4.41547
Value Function Loss: 0.05561

Mean KL Divergence: 0.00121
SB3 Clip Fraction: 0.00127
Policy Update Magnitude: 0.13530
Value Function Update Magnitude: 0.10474

Collected Steps per Second: 24,200.42074
Overall Steps per Second: 12,920.85273

Timestep Collection Time: 2.06707
Timestep Consumption Time: 1.80450
PPO Batch Consumption Time: 0.35844
Total Iteration Time: 3.87157

Cumulative Model Updates: 994
Cumulative Timesteps: 16,657,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02981
Policy Entropy: 4.42071
Value Function Loss: 0.07785

Mean KL Divergence: 0.00108
SB3 Clip Fraction: 0.00060
Policy Update Magnitude: 0.13981
Value Function Update Magnitude: 0.08841

Collected Steps per Second: 24,120.12271
Overall Steps per Second: 12,664.48624

Timestep Collection Time: 2.07321
Timestep Consumption Time: 1.87532
PPO Batch Consumption Time: 0.35658
Total Iteration Time: 3.94852

Cumulative Model Updates: 997
Cumulative Timesteps: 16,707,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 16707914...
Checkpoint 16707914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03851
Policy Entropy: 4.42559
Value Function Loss: 0.05561

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00112
Policy Update Magnitude: 0.14264
Value Function Update Magnitude: 0.09900

Collected Steps per Second: 24,593.74239
Overall Steps per Second: 12,799.63241

Timestep Collection Time: 2.03426
Timestep Consumption Time: 1.87445
PPO Batch Consumption Time: 0.35704
Total Iteration Time: 3.90871

Cumulative Model Updates: 1,000
Cumulative Timesteps: 16,757,944

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02948
Policy Entropy: 4.42569
Value Function Loss: 0.05416

Mean KL Divergence: 0.00103
SB3 Clip Fraction: 0.00037
Policy Update Magnitude: 0.14460
Value Function Update Magnitude: 0.09519

Collected Steps per Second: 25,998.60449
Overall Steps per Second: 13,053.35323

Timestep Collection Time: 1.92503
Timestep Consumption Time: 1.90908
PPO Batch Consumption Time: 0.37611
Total Iteration Time: 3.83411

Cumulative Model Updates: 1,003
Cumulative Timesteps: 16,807,992

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 16807992...
Checkpoint 16807992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03094
Policy Entropy: 4.41835
Value Function Loss: 0.02336

Mean KL Divergence: 0.00123
SB3 Clip Fraction: 0.00149
Policy Update Magnitude: 0.13057
Value Function Update Magnitude: 0.09049

Collected Steps per Second: 23,251.39290
Overall Steps per Second: 12,439.12014

Timestep Collection Time: 2.15144
Timestep Consumption Time: 1.87007
PPO Batch Consumption Time: 0.35402
Total Iteration Time: 4.02151

Cumulative Model Updates: 1,006
Cumulative Timesteps: 16,858,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01371
Policy Entropy: 4.40986
Value Function Loss: 0.03001

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.00363
Policy Update Magnitude: 0.11885
Value Function Update Magnitude: 0.07875

Collected Steps per Second: 25,009.77773
Overall Steps per Second: 12,909.82339

Timestep Collection Time: 1.99970
Timestep Consumption Time: 1.87425
PPO Batch Consumption Time: 0.35795
Total Iteration Time: 3.87395

Cumulative Model Updates: 1,009
Cumulative Timesteps: 16,908,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 16908028...
Checkpoint 16908028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05388
Policy Entropy: 4.39993
Value Function Loss: 0.03953

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.00131
Policy Update Magnitude: 0.11616
Value Function Update Magnitude: 0.07777

Collected Steps per Second: 24,814.02632
Overall Steps per Second: 12,678.56684

Timestep Collection Time: 2.01499
Timestep Consumption Time: 1.92867
PPO Batch Consumption Time: 0.36832
Total Iteration Time: 3.94366

Cumulative Model Updates: 1,012
Cumulative Timesteps: 16,958,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04076
Policy Entropy: 4.39592
Value Function Loss: 0.04599

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.00131
Policy Update Magnitude: 0.12225
Value Function Update Magnitude: 0.07597

Collected Steps per Second: 25,155.60753
Overall Steps per Second: 13,016.45920

Timestep Collection Time: 1.98914
Timestep Consumption Time: 1.85507
PPO Batch Consumption Time: 0.37767
Total Iteration Time: 3.84421

Cumulative Model Updates: 1,015
Cumulative Timesteps: 17,008,066

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 17008066...
Checkpoint 17008066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03408
Policy Entropy: 4.39893
Value Function Loss: 0.05149

Mean KL Divergence: 0.00094
SB3 Clip Fraction: 0.00108
Policy Update Magnitude: 0.12297
Value Function Update Magnitude: 0.07809

Collected Steps per Second: 24,474.11392
Overall Steps per Second: 12,815.60351

Timestep Collection Time: 2.04477
Timestep Consumption Time: 1.86015
PPO Batch Consumption Time: 0.35894
Total Iteration Time: 3.90493

Cumulative Model Updates: 1,018
Cumulative Timesteps: 17,058,110

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07737
Policy Entropy: 4.40521
Value Function Loss: 0.04537

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.00154
Policy Update Magnitude: 0.12202
Value Function Update Magnitude: 0.07302

Collected Steps per Second: 24,028.55353
Overall Steps per Second: 12,724.19032

Timestep Collection Time: 2.08310
Timestep Consumption Time: 1.85066
PPO Batch Consumption Time: 0.35611
Total Iteration Time: 3.93377

Cumulative Model Updates: 1,021
Cumulative Timesteps: 17,108,164

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 17108164...
Checkpoint 17108164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02404
Policy Entropy: 4.40740
Value Function Loss: 0.07368

Mean KL Divergence: 0.00092
SB3 Clip Fraction: 0.00017
Policy Update Magnitude: 0.12152
Value Function Update Magnitude: 0.07792

Collected Steps per Second: 25,117.00312
Overall Steps per Second: 12,848.38635

Timestep Collection Time: 1.99228
Timestep Consumption Time: 1.90238
PPO Batch Consumption Time: 0.36624
Total Iteration Time: 3.89465

Cumulative Model Updates: 1,024
Cumulative Timesteps: 17,158,204

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02489
Policy Entropy: 4.40347
Value Function Loss: 0.07300

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.13354
Value Function Update Magnitude: 0.06509

Collected Steps per Second: 23,215.41750
Overall Steps per Second: 12,072.81713

Timestep Collection Time: 2.15383
Timestep Consumption Time: 1.98787
PPO Batch Consumption Time: 0.37885
Total Iteration Time: 4.14170

Cumulative Model Updates: 1,027
Cumulative Timesteps: 17,208,206

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 17208206...
Checkpoint 17208206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05598
Policy Entropy: 4.39115
Value Function Loss: 0.06865

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.00678
Policy Update Magnitude: 0.15005
Value Function Update Magnitude: 0.06587

Collected Steps per Second: 21,117.68468
Overall Steps per Second: 11,915.66872

Timestep Collection Time: 2.36892
Timestep Consumption Time: 1.82942
PPO Batch Consumption Time: 0.36311
Total Iteration Time: 4.19834

Cumulative Model Updates: 1,030
Cumulative Timesteps: 17,258,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01494
Policy Entropy: 4.37549
Value Function Loss: 0.04349

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01283
Policy Update Magnitude: 0.14105
Value Function Update Magnitude: 0.08051

Collected Steps per Second: 20,967.00058
Overall Steps per Second: 11,402.66234

Timestep Collection Time: 2.38708
Timestep Consumption Time: 2.00224
PPO Batch Consumption Time: 0.36786
Total Iteration Time: 4.38933

Cumulative Model Updates: 1,033
Cumulative Timesteps: 17,308,282

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 17308282...
Checkpoint 17308282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01820
Policy Entropy: 4.37035
Value Function Loss: 0.05403

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.00284
Policy Update Magnitude: 0.12832
Value Function Update Magnitude: 0.05239

Collected Steps per Second: 21,191.56147
Overall Steps per Second: 11,802.33773

Timestep Collection Time: 2.35952
Timestep Consumption Time: 1.87709
PPO Batch Consumption Time: 0.36114
Total Iteration Time: 4.23662

Cumulative Model Updates: 1,036
Cumulative Timesteps: 17,358,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02340
Policy Entropy: 4.37327
Value Function Loss: 0.05530

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00033
Policy Update Magnitude: 0.12836
Value Function Update Magnitude: 0.04801

Collected Steps per Second: 25,131.91896
Overall Steps per Second: 12,910.39474

Timestep Collection Time: 1.99022
Timestep Consumption Time: 1.88402
PPO Batch Consumption Time: 0.36009
Total Iteration Time: 3.87424

Cumulative Model Updates: 1,039
Cumulative Timesteps: 17,408,302

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 17408302...
Checkpoint 17408302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10574
Policy Entropy: 4.37804
Value Function Loss: 0.06795

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.00103
Policy Update Magnitude: 0.13133
Value Function Update Magnitude: 0.06180

Collected Steps per Second: 24,988.25727
Overall Steps per Second: 12,880.95488

Timestep Collection Time: 2.00294
Timestep Consumption Time: 1.88264
PPO Batch Consumption Time: 0.37423
Total Iteration Time: 3.88558

Cumulative Model Updates: 1,042
Cumulative Timesteps: 17,458,352

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00964
Policy Entropy: 4.38003
Value Function Loss: 0.07145

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.00260
Policy Update Magnitude: 0.14139
Value Function Update Magnitude: 0.05531

Collected Steps per Second: 23,346.70662
Overall Steps per Second: 12,625.99081

Timestep Collection Time: 2.14283
Timestep Consumption Time: 1.81947
PPO Batch Consumption Time: 0.36259
Total Iteration Time: 3.96230

Cumulative Model Updates: 1,045
Cumulative Timesteps: 17,508,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 17508380...
Checkpoint 17508380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06101
Policy Entropy: 4.37898
Value Function Loss: 0.06750

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.00128
Policy Update Magnitude: 0.13942
Value Function Update Magnitude: 0.06071

Collected Steps per Second: 23,841.64328
Overall Steps per Second: 12,595.17781

Timestep Collection Time: 2.09767
Timestep Consumption Time: 1.87305
PPO Batch Consumption Time: 0.35724
Total Iteration Time: 3.97073

Cumulative Model Updates: 1,048
Cumulative Timesteps: 17,558,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04008
Policy Entropy: 4.37239
Value Function Loss: 0.05596

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.00456
Policy Update Magnitude: 0.13697
Value Function Update Magnitude: 0.05330

Collected Steps per Second: 24,179.82208
Overall Steps per Second: 12,660.17834

Timestep Collection Time: 2.06867
Timestep Consumption Time: 1.88230
PPO Batch Consumption Time: 0.35806
Total Iteration Time: 3.95097

Cumulative Model Updates: 1,051
Cumulative Timesteps: 17,608,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 17608412...
Checkpoint 17608412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07315
Policy Entropy: 4.36375
Value Function Loss: 0.05254

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.00429
Policy Update Magnitude: 0.12530
Value Function Update Magnitude: 0.05126

Collected Steps per Second: 25,575.11924
Overall Steps per Second: 12,788.23364

Timestep Collection Time: 1.95518
Timestep Consumption Time: 1.95498
PPO Batch Consumption Time: 0.36699
Total Iteration Time: 3.91016

Cumulative Model Updates: 1,054
Cumulative Timesteps: 17,658,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02079
Policy Entropy: 4.35755
Value Function Loss: 0.05108

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.00163
Policy Update Magnitude: 0.12503
Value Function Update Magnitude: 0.05490

Collected Steps per Second: 24,713.48406
Overall Steps per Second: 12,648.46115

Timestep Collection Time: 2.02521
Timestep Consumption Time: 1.93179
PPO Batch Consumption Time: 0.36577
Total Iteration Time: 3.95700

Cumulative Model Updates: 1,057
Cumulative Timesteps: 17,708,466

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 17708466...
Checkpoint 17708466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00745
Policy Entropy: 4.34462
Value Function Loss: 0.04330

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.00247
Policy Update Magnitude: 0.13687
Value Function Update Magnitude: 0.05434

Collected Steps per Second: 25,489.45350
Overall Steps per Second: 13,027.05468

Timestep Collection Time: 1.96269
Timestep Consumption Time: 1.87762
PPO Batch Consumption Time: 0.35867
Total Iteration Time: 3.84032

Cumulative Model Updates: 1,060
Cumulative Timesteps: 17,758,494

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01455
Policy Entropy: 4.32454
Value Function Loss: 0.02692

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01377
Policy Update Magnitude: 0.12862
Value Function Update Magnitude: 0.05421

Collected Steps per Second: 24,063.67079
Overall Steps per Second: 12,695.93661

Timestep Collection Time: 2.07990
Timestep Consumption Time: 1.86231
PPO Batch Consumption Time: 0.35376
Total Iteration Time: 3.94221

Cumulative Model Updates: 1,063
Cumulative Timesteps: 17,808,544

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 17808544...
Checkpoint 17808544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02495
Policy Entropy: 4.31271
Value Function Loss: 0.03859

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01167
Policy Update Magnitude: 0.11398
Value Function Update Magnitude: 0.05244

Collected Steps per Second: 24,715.66485
Overall Steps per Second: 13,037.65469

Timestep Collection Time: 2.02382
Timestep Consumption Time: 1.81276
PPO Batch Consumption Time: 0.36003
Total Iteration Time: 3.83658

Cumulative Model Updates: 1,066
Cumulative Timesteps: 17,858,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01466
Policy Entropy: 4.31256
Value Function Loss: 0.04563

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.00053
Policy Update Magnitude: 0.11612
Value Function Update Magnitude: 0.05624

Collected Steps per Second: 25,380.83691
Overall Steps per Second: 12,964.47512

Timestep Collection Time: 1.97015
Timestep Consumption Time: 1.88685
PPO Batch Consumption Time: 0.36299
Total Iteration Time: 3.85700

Cumulative Model Updates: 1,069
Cumulative Timesteps: 17,908,568

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 17908568...
Checkpoint 17908568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02320
Policy Entropy: 4.31994
Value Function Loss: 0.07202

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00186
Policy Update Magnitude: 0.13033
Value Function Update Magnitude: 0.07084

Collected Steps per Second: 23,921.81244
Overall Steps per Second: 12,614.36115

Timestep Collection Time: 2.09115
Timestep Consumption Time: 1.87449
PPO Batch Consumption Time: 0.36355
Total Iteration Time: 3.96564

Cumulative Model Updates: 1,072
Cumulative Timesteps: 17,958,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01579
Policy Entropy: 4.33173
Value Function Loss: 0.05716

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.00217
Policy Update Magnitude: 0.14200
Value Function Update Magnitude: 0.06557

Collected Steps per Second: 22,749.98336
Overall Steps per Second: 12,262.82024

Timestep Collection Time: 2.19921
Timestep Consumption Time: 1.88076
PPO Batch Consumption Time: 0.36322
Total Iteration Time: 4.07998

Cumulative Model Updates: 1,075
Cumulative Timesteps: 18,008,624

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 18008624...
Checkpoint 18008624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03027
Policy Entropy: 4.34667
Value Function Loss: 0.05688

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.01221
Policy Update Magnitude: 0.14259
Value Function Update Magnitude: 0.07689

Collected Steps per Second: 24,922.94383
Overall Steps per Second: 12,870.95770

Timestep Collection Time: 2.00626
Timestep Consumption Time: 1.87861
PPO Batch Consumption Time: 0.35778
Total Iteration Time: 3.88487

Cumulative Model Updates: 1,078
Cumulative Timesteps: 18,058,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02949
Policy Entropy: 4.34702
Value Function Loss: 0.05478

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01380
Policy Update Magnitude: 0.13479
Value Function Update Magnitude: 0.07991

Collected Steps per Second: 24,953.67653
Overall Steps per Second: 12,877.26512

Timestep Collection Time: 2.00411
Timestep Consumption Time: 1.87948
PPO Batch Consumption Time: 0.35553
Total Iteration Time: 3.88359

Cumulative Model Updates: 1,081
Cumulative Timesteps: 18,108,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 18108636...
Checkpoint 18108636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01089
Policy Entropy: 4.34336
Value Function Loss: 0.05504

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.00395
Policy Update Magnitude: 0.13273
Value Function Update Magnitude: 0.07325

Collected Steps per Second: 24,555.34077
Overall Steps per Second: 12,760.60547

Timestep Collection Time: 2.03654
Timestep Consumption Time: 1.88239
PPO Batch Consumption Time: 0.36261
Total Iteration Time: 3.91894

Cumulative Model Updates: 1,084
Cumulative Timesteps: 18,158,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01755
Policy Entropy: 4.34205
Value Function Loss: 0.06753

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.00303
Policy Update Magnitude: 0.13689
Value Function Update Magnitude: 0.08416

Collected Steps per Second: 24,063.48930
Overall Steps per Second: 12,982.35396

Timestep Collection Time: 2.08000
Timestep Consumption Time: 1.77539
PPO Batch Consumption Time: 0.35281
Total Iteration Time: 3.85539

Cumulative Model Updates: 1,087
Cumulative Timesteps: 18,208,696

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 18208696...
Checkpoint 18208696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01582
Policy Entropy: 4.34997
Value Function Loss: 0.07521

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.00232
Policy Update Magnitude: 0.14104
Value Function Update Magnitude: 0.07198

Collected Steps per Second: 24,802.17923
Overall Steps per Second: 12,741.97708

Timestep Collection Time: 2.01789
Timestep Consumption Time: 1.90992
PPO Batch Consumption Time: 0.36238
Total Iteration Time: 3.92780

Cumulative Model Updates: 1,090
Cumulative Timesteps: 18,258,744

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01426
Policy Entropy: 4.35920
Value Function Loss: 0.07646

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.00534
Policy Update Magnitude: 0.13850
Value Function Update Magnitude: 0.06185

Collected Steps per Second: 24,866.18786
Overall Steps per Second: 13,037.29980

Timestep Collection Time: 2.01108
Timestep Consumption Time: 1.82468
PPO Batch Consumption Time: 0.35003
Total Iteration Time: 3.83576

Cumulative Model Updates: 1,093
Cumulative Timesteps: 18,308,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 18308752...
Checkpoint 18308752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14880
Policy Entropy: 4.35664
Value Function Loss: 0.07106

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00107
Policy Update Magnitude: 0.13932
Value Function Update Magnitude: 0.06454

Collected Steps per Second: 24,913.91166
Overall Steps per Second: 12,854.38023

Timestep Collection Time: 2.00747
Timestep Consumption Time: 1.88334
PPO Batch Consumption Time: 0.35970
Total Iteration Time: 3.89081

Cumulative Model Updates: 1,096
Cumulative Timesteps: 18,358,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03177
Policy Entropy: 4.34751
Value Function Loss: 0.06787

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.00331
Policy Update Magnitude: 0.14027
Value Function Update Magnitude: 0.06456

Collected Steps per Second: 24,150.98028
Overall Steps per Second: 12,720.10150

Timestep Collection Time: 2.07072
Timestep Consumption Time: 1.86085
PPO Batch Consumption Time: 0.35756
Total Iteration Time: 3.93157

Cumulative Model Updates: 1,099
Cumulative Timesteps: 18,408,776

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 18408776...
Checkpoint 18408776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01288
Policy Entropy: 4.33992
Value Function Loss: 0.05919

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.00092
Policy Update Magnitude: 0.14623
Value Function Update Magnitude: 0.06558

Collected Steps per Second: 24,713.82529
Overall Steps per Second: 13,144.04942

Timestep Collection Time: 2.02445
Timestep Consumption Time: 1.78198
PPO Batch Consumption Time: 0.35684
Total Iteration Time: 3.80644

Cumulative Model Updates: 1,102
Cumulative Timesteps: 18,458,808

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03122
Policy Entropy: 4.33668
Value Function Loss: 0.07283

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.00507
Policy Update Magnitude: 0.14273
Value Function Update Magnitude: 0.05859

Collected Steps per Second: 24,570.21649
Overall Steps per Second: 12,757.48136

Timestep Collection Time: 2.03555
Timestep Consumption Time: 1.88481
PPO Batch Consumption Time: 0.36308
Total Iteration Time: 3.92037

Cumulative Model Updates: 1,105
Cumulative Timesteps: 18,508,822

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 18508822...
Checkpoint 18508822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01174
Policy Entropy: 4.33344
Value Function Loss: 0.06501

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01137
Policy Update Magnitude: 0.14461
Value Function Update Magnitude: 0.06674

Collected Steps per Second: 24,478.08622
Overall Steps per Second: 12,780.96440

Timestep Collection Time: 2.04338
Timestep Consumption Time: 1.87010
PPO Batch Consumption Time: 0.35660
Total Iteration Time: 3.91348

Cumulative Model Updates: 1,108
Cumulative Timesteps: 18,558,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07805
Policy Entropy: 4.33271
Value Function Loss: 0.07988

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.00845
Policy Update Magnitude: 0.15894
Value Function Update Magnitude: 0.07644

Collected Steps per Second: 25,209.94975
Overall Steps per Second: 12,995.08252

Timestep Collection Time: 1.98382
Timestep Consumption Time: 1.86471
PPO Batch Consumption Time: 0.35694
Total Iteration Time: 3.84853

Cumulative Model Updates: 1,111
Cumulative Timesteps: 18,608,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 18608852...
Checkpoint 18608852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00189
Policy Entropy: 4.33734
Value Function Loss: 0.06376

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03410
Policy Update Magnitude: 0.14727
Value Function Update Magnitude: 0.08023

Collected Steps per Second: 24,872.15438
Overall Steps per Second: 12,976.25834

Timestep Collection Time: 2.01157
Timestep Consumption Time: 1.84409
PPO Batch Consumption Time: 0.35832
Total Iteration Time: 3.85566

Cumulative Model Updates: 1,114
Cumulative Timesteps: 18,658,884

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00489
Policy Entropy: 4.34442
Value Function Loss: 0.06046

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02146
Policy Update Magnitude: 0.14675
Value Function Update Magnitude: 0.06268

Collected Steps per Second: 24,455.10277
Overall Steps per Second: 12,820.78497

Timestep Collection Time: 2.04489
Timestep Consumption Time: 1.85565
PPO Batch Consumption Time: 0.36290
Total Iteration Time: 3.90054

Cumulative Model Updates: 1,117
Cumulative Timesteps: 18,708,892

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 18708892...
Checkpoint 18708892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01597
Policy Entropy: 4.35115
Value Function Loss: 0.05072

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.00240
Policy Update Magnitude: 0.13964
Value Function Update Magnitude: 0.05589

Collected Steps per Second: 24,392.95265
Overall Steps per Second: 12,774.36683

Timestep Collection Time: 2.05117
Timestep Consumption Time: 1.86558
PPO Batch Consumption Time: 0.35436
Total Iteration Time: 3.91675

Cumulative Model Updates: 1,120
Cumulative Timesteps: 18,758,926

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04677
Policy Entropy: 4.35498
Value Function Loss: 0.06155

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00156
Policy Update Magnitude: 0.13202
Value Function Update Magnitude: 0.05563

Collected Steps per Second: 24,335.70033
Overall Steps per Second: 12,804.52177

Timestep Collection Time: 2.05542
Timestep Consumption Time: 1.85102
PPO Batch Consumption Time: 0.35734
Total Iteration Time: 3.90643

Cumulative Model Updates: 1,123
Cumulative Timesteps: 18,808,946

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 18808946...
Checkpoint 18808946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03846
Policy Entropy: 4.35300
Value Function Loss: 0.07991

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00006
Policy Update Magnitude: 0.13694
Value Function Update Magnitude: 0.05645

Collected Steps per Second: 25,813.59748
Overall Steps per Second: 13,145.82782

Timestep Collection Time: 1.93751
Timestep Consumption Time: 1.86705
PPO Batch Consumption Time: 0.35983
Total Iteration Time: 3.80455

Cumulative Model Updates: 1,126
Cumulative Timesteps: 18,858,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01928
Policy Entropy: 4.34197
Value Function Loss: 0.08149

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.00347
Policy Update Magnitude: 0.15524
Value Function Update Magnitude: 0.08050

Collected Steps per Second: 24,763.72238
Overall Steps per Second: 12,824.55556

Timestep Collection Time: 2.02054
Timestep Consumption Time: 1.88104
PPO Batch Consumption Time: 0.36372
Total Iteration Time: 3.90158

Cumulative Model Updates: 1,129
Cumulative Timesteps: 18,908,996

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 18908996...
Checkpoint 18908996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02965
Policy Entropy: 4.32791
Value Function Loss: 0.09020

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.00610
Policy Update Magnitude: 0.16266
Value Function Update Magnitude: 0.07534

Collected Steps per Second: 24,118.88950
Overall Steps per Second: 13,025.53817

Timestep Collection Time: 2.07514
Timestep Consumption Time: 1.76731
PPO Batch Consumption Time: 0.35472
Total Iteration Time: 3.84245

Cumulative Model Updates: 1,132
Cumulative Timesteps: 18,959,046

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00268
Policy Entropy: 4.32246
Value Function Loss: 0.06944

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.00908
Policy Update Magnitude: 0.15941
Value Function Update Magnitude: 0.07722

Collected Steps per Second: 24,222.65273
Overall Steps per Second: 12,669.83994

Timestep Collection Time: 2.06468
Timestep Consumption Time: 1.88265
PPO Batch Consumption Time: 0.36704
Total Iteration Time: 3.94733

Cumulative Model Updates: 1,135
Cumulative Timesteps: 19,009,058

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 19009058...
Checkpoint 19009058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03079
Policy Entropy: 4.31261
Value Function Loss: 0.07035

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.00983
Policy Update Magnitude: 0.16191
Value Function Update Magnitude: 0.07171

Collected Steps per Second: 24,769.05484
Overall Steps per Second: 12,925.80746

Timestep Collection Time: 2.01921
Timestep Consumption Time: 1.85010
PPO Batch Consumption Time: 0.35608
Total Iteration Time: 3.86931

Cumulative Model Updates: 1,138
Cumulative Timesteps: 19,059,072

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04182
Policy Entropy: 4.29202
Value Function Loss: 0.04804

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02580
Policy Update Magnitude: 0.15267
Value Function Update Magnitude: 0.07103

Collected Steps per Second: 25,464.61001
Overall Steps per Second: 13,057.67718

Timestep Collection Time: 1.96437
Timestep Consumption Time: 1.86648
PPO Batch Consumption Time: 0.35615
Total Iteration Time: 3.83085

Cumulative Model Updates: 1,141
Cumulative Timesteps: 19,109,094

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 19109094...
Checkpoint 19109094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04023
Policy Entropy: 4.28873
Value Function Loss: 0.04282

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01443
Policy Update Magnitude: 0.14493
Value Function Update Magnitude: 0.06270

Collected Steps per Second: 24,384.09817
Overall Steps per Second: 12,755.71702

Timestep Collection Time: 2.05060
Timestep Consumption Time: 1.86937
PPO Batch Consumption Time: 0.35796
Total Iteration Time: 3.91997

Cumulative Model Updates: 1,144
Cumulative Timesteps: 19,159,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01284
Policy Entropy: 4.29686
Value Function Loss: 0.04142

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.00570
Policy Update Magnitude: 0.12437
Value Function Update Magnitude: 0.06512

Collected Steps per Second: 24,221.74706
Overall Steps per Second: 12,947.45573

Timestep Collection Time: 2.06476
Timestep Consumption Time: 1.79793
PPO Batch Consumption Time: 0.35672
Total Iteration Time: 3.86269

Cumulative Model Updates: 1,147
Cumulative Timesteps: 19,209,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 19209108...
Checkpoint 19209108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00731
Policy Entropy: 4.29305
Value Function Loss: 0.04958

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.00733
Policy Update Magnitude: 0.12357
Value Function Update Magnitude: 0.06292

Collected Steps per Second: 24,950.32792
Overall Steps per Second: 12,885.21842

Timestep Collection Time: 2.00591
Timestep Consumption Time: 1.87824
PPO Batch Consumption Time: 0.35885
Total Iteration Time: 3.88414

Cumulative Model Updates: 1,150
Cumulative Timesteps: 19,259,156

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04893
Policy Entropy: 4.27139
Value Function Loss: 0.05072

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.00158
Policy Update Magnitude: 0.13270
Value Function Update Magnitude: 0.06744

Collected Steps per Second: 25,062.78978
Overall Steps per Second: 13,182.67772

Timestep Collection Time: 1.99539
Timestep Consumption Time: 1.79823
PPO Batch Consumption Time: 0.36147
Total Iteration Time: 3.79361

Cumulative Model Updates: 1,153
Cumulative Timesteps: 19,309,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 19309166...
Checkpoint 19309166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05868
Policy Entropy: 4.25627
Value Function Loss: 0.03965

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.00988
Policy Update Magnitude: 0.12824
Value Function Update Magnitude: 0.06289

Collected Steps per Second: 24,481.13380
Overall Steps per Second: 12,743.33582

Timestep Collection Time: 2.04361
Timestep Consumption Time: 1.88236
PPO Batch Consumption Time: 0.35977
Total Iteration Time: 3.92597

Cumulative Model Updates: 1,156
Cumulative Timesteps: 19,359,196

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00499
Policy Entropy: 4.25962
Value Function Loss: 0.04322

Mean KL Divergence: 0.00123
SB3 Clip Fraction: 0.00109
Policy Update Magnitude: 0.12887
Value Function Update Magnitude: 0.05999

Collected Steps per Second: 24,339.51028
Overall Steps per Second: 12,783.06527

Timestep Collection Time: 2.05526
Timestep Consumption Time: 1.85804
PPO Batch Consumption Time: 0.35891
Total Iteration Time: 3.91330

Cumulative Model Updates: 1,159
Cumulative Timesteps: 19,409,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 19409220...
Checkpoint 19409220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02854
Policy Entropy: 4.28042
Value Function Loss: 0.04640

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01039
Policy Update Magnitude: 0.12274
Value Function Update Magnitude: 0.06273

Collected Steps per Second: 25,127.01267
Overall Steps per Second: 13,090.85736

Timestep Collection Time: 1.99077
Timestep Consumption Time: 1.83037
PPO Batch Consumption Time: 0.36742
Total Iteration Time: 3.82114

Cumulative Model Updates: 1,162
Cumulative Timesteps: 19,459,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02695
Policy Entropy: 4.28486
Value Function Loss: 0.05696

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01991
Policy Update Magnitude: 0.11907
Value Function Update Magnitude: 0.06314

Collected Steps per Second: 25,298.22777
Overall Steps per Second: 12,993.11900

Timestep Collection Time: 1.97721
Timestep Consumption Time: 1.87252
PPO Batch Consumption Time: 0.36390
Total Iteration Time: 3.84973

Cumulative Model Updates: 1,165
Cumulative Timesteps: 19,509,262

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 19509262...
Checkpoint 19509262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03852
Policy Entropy: 4.28782
Value Function Loss: 0.05449

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00127
Policy Update Magnitude: 0.12033
Value Function Update Magnitude: 0.08362

Collected Steps per Second: 24,368.75892
Overall Steps per Second: 13,151.51145

Timestep Collection Time: 2.05271
Timestep Consumption Time: 1.75081
PPO Batch Consumption Time: 0.35468
Total Iteration Time: 3.80352

Cumulative Model Updates: 1,168
Cumulative Timesteps: 19,559,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01872
Policy Entropy: 4.29881
Value Function Loss: 0.07858

Mean KL Divergence: 0.00108
SB3 Clip Fraction: 0.00056
Policy Update Magnitude: 0.13540
Value Function Update Magnitude: 0.08387

Collected Steps per Second: 25,134.86609
Overall Steps per Second: 12,780.66567

Timestep Collection Time: 1.98983
Timestep Consumption Time: 1.92343
PPO Batch Consumption Time: 0.35992
Total Iteration Time: 3.91325

Cumulative Model Updates: 1,171
Cumulative Timesteps: 19,609,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 19609298...
Checkpoint 19609298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00158
Policy Entropy: 4.32449
Value Function Loss: 0.07124

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01429
Policy Update Magnitude: 0.13923
Value Function Update Magnitude: 0.08725

Collected Steps per Second: 24,787.99674
Overall Steps per Second: 12,852.36747

Timestep Collection Time: 2.01872
Timestep Consumption Time: 1.87473
PPO Batch Consumption Time: 0.36060
Total Iteration Time: 3.89345

Cumulative Model Updates: 1,174
Cumulative Timesteps: 19,659,338

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01402
Policy Entropy: 4.32413
Value Function Loss: 0.07612

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01055
Policy Update Magnitude: 0.14047
Value Function Update Magnitude: 0.09504

Collected Steps per Second: 25,730.41570
Overall Steps per Second: 13,139.81063

Timestep Collection Time: 1.94509
Timestep Consumption Time: 1.86379
PPO Batch Consumption Time: 0.36013
Total Iteration Time: 3.80888

Cumulative Model Updates: 1,177
Cumulative Timesteps: 19,709,386

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 19709386...
Checkpoint 19709386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04825
Policy Entropy: 4.31095
Value Function Loss: 0.04834

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.00647
Policy Update Magnitude: 0.14121
Value Function Update Magnitude: 0.07664

Collected Steps per Second: 24,260.86128
Overall Steps per Second: 12,785.42029

Timestep Collection Time: 2.06225
Timestep Consumption Time: 1.85096
PPO Batch Consumption Time: 0.35863
Total Iteration Time: 3.91321

Cumulative Model Updates: 1,180
Cumulative Timesteps: 19,759,418

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02705
Policy Entropy: 4.29452
Value Function Loss: 0.05010

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02626
Policy Update Magnitude: 0.14025
Value Function Update Magnitude: 0.07182

Collected Steps per Second: 24,984.31241
Overall Steps per Second: 13,090.39769

Timestep Collection Time: 2.00302
Timestep Consumption Time: 1.81994
PPO Batch Consumption Time: 0.35993
Total Iteration Time: 3.82295

Cumulative Model Updates: 1,183
Cumulative Timesteps: 19,809,462

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 19809462...
Checkpoint 19809462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11742
Policy Entropy: 4.28638
Value Function Loss: 0.06047

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02829
Policy Update Magnitude: 0.12690
Value Function Update Magnitude: 0.07075

Collected Steps per Second: 25,144.35186
Overall Steps per Second: 12,815.60791

Timestep Collection Time: 1.98979
Timestep Consumption Time: 1.91420
PPO Batch Consumption Time: 0.36774
Total Iteration Time: 3.90399

Cumulative Model Updates: 1,186
Cumulative Timesteps: 19,859,494

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01207
Policy Entropy: 4.28132
Value Function Loss: 0.05712

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.00430
Policy Update Magnitude: 0.13097
Value Function Update Magnitude: 0.07752

Collected Steps per Second: 24,618.44512
Overall Steps per Second: 12,827.78004

Timestep Collection Time: 2.03124
Timestep Consumption Time: 1.86702
PPO Batch Consumption Time: 0.35953
Total Iteration Time: 3.89826

Cumulative Model Updates: 1,189
Cumulative Timesteps: 19,909,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 19909500...
Checkpoint 19909500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03123
Policy Entropy: 4.29002
Value Function Loss: 0.06227

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.00121
Policy Update Magnitude: 0.14507
Value Function Update Magnitude: 0.07916

Collected Steps per Second: 25,190.35931
Overall Steps per Second: 12,939.34022

Timestep Collection Time: 1.98552
Timestep Consumption Time: 1.87990
PPO Batch Consumption Time: 0.35734
Total Iteration Time: 3.86542

Cumulative Model Updates: 1,192
Cumulative Timesteps: 19,959,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02482
Policy Entropy: 4.30461
Value Function Loss: 0.05647

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01645
Policy Update Magnitude: 0.14268
Value Function Update Magnitude: 0.07669

Collected Steps per Second: 24,851.87782
Overall Steps per Second: 12,856.81940

Timestep Collection Time: 2.01297
Timestep Consumption Time: 1.87804
PPO Batch Consumption Time: 0.35756
Total Iteration Time: 3.89101

Cumulative Model Updates: 1,195
Cumulative Timesteps: 20,009,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 20009542...
Checkpoint 20009542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00280
Policy Entropy: 4.30997
Value Function Loss: 0.06634

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02899
Policy Update Magnitude: 0.13025
Value Function Update Magnitude: 0.08893

Collected Steps per Second: 24,702.60302
Overall Steps per Second: 13,073.25588

Timestep Collection Time: 2.02537
Timestep Consumption Time: 1.80168
PPO Batch Consumption Time: 0.35900
Total Iteration Time: 3.82705

Cumulative Model Updates: 1,198
Cumulative Timesteps: 20,059,574

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01034
Policy Entropy: 4.30311
Value Function Loss: 0.05778

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.00254
Policy Update Magnitude: 0.12774
Value Function Update Magnitude: 0.08070

Collected Steps per Second: 24,827.22676
Overall Steps per Second: 12,765.56548

Timestep Collection Time: 2.01456
Timestep Consumption Time: 1.90348
PPO Batch Consumption Time: 0.36376
Total Iteration Time: 3.91804

Cumulative Model Updates: 1,201
Cumulative Timesteps: 20,109,590

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 20109590...
Checkpoint 20109590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01220
Policy Entropy: 4.31022
Value Function Loss: 0.05662

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00186
Policy Update Magnitude: 0.12666
Value Function Update Magnitude: 0.07207

Collected Steps per Second: 23,868.86991
Overall Steps per Second: 12,554.04426

Timestep Collection Time: 2.09562
Timestep Consumption Time: 1.88876
PPO Batch Consumption Time: 0.36209
Total Iteration Time: 3.98437

Cumulative Model Updates: 1,204
Cumulative Timesteps: 20,159,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04014
Policy Entropy: 4.33065
Value Function Loss: 0.04440

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01116
Policy Update Magnitude: 0.12100
Value Function Update Magnitude: 0.06213

Collected Steps per Second: 25,867.40511
Overall Steps per Second: 12,922.92669

Timestep Collection Time: 1.93378
Timestep Consumption Time: 1.93701
PPO Batch Consumption Time: 0.36321
Total Iteration Time: 3.87080

Cumulative Model Updates: 1,207
Cumulative Timesteps: 20,209,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 20209632...
Checkpoint 20209632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01393
Policy Entropy: 4.34901
Value Function Loss: 0.04285

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.01418
Policy Update Magnitude: 0.10887
Value Function Update Magnitude: 0.06088

Collected Steps per Second: 24,916.03103
Overall Steps per Second: 12,859.26817

Timestep Collection Time: 2.00794
Timestep Consumption Time: 1.88263
PPO Batch Consumption Time: 0.35947
Total Iteration Time: 3.89058

Cumulative Model Updates: 1,210
Cumulative Timesteps: 20,259,662

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02839
Policy Entropy: 4.35331
Value Function Loss: 0.03025

Mean KL Divergence: 0.00124
SB3 Clip Fraction: 0.00427
Policy Update Magnitude: 0.10618
Value Function Update Magnitude: 0.05818

Collected Steps per Second: 25,523.01618
Overall Steps per Second: 12,997.79737

Timestep Collection Time: 1.95964
Timestep Consumption Time: 1.88839
PPO Batch Consumption Time: 0.35983
Total Iteration Time: 3.84804

Cumulative Model Updates: 1,213
Cumulative Timesteps: 20,309,678

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 20309678...
Checkpoint 20309678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01681
Policy Entropy: 4.35157
Value Function Loss: 0.04369

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00059
Policy Update Magnitude: 0.10456
Value Function Update Magnitude: 0.06937

Collected Steps per Second: 24,210.57977
Overall Steps per Second: 12,795.32033

Timestep Collection Time: 2.06587
Timestep Consumption Time: 1.84306
PPO Batch Consumption Time: 0.35895
Total Iteration Time: 3.90893

Cumulative Model Updates: 1,216
Cumulative Timesteps: 20,359,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00342
Policy Entropy: 4.34768
Value Function Loss: 0.05867

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00013
Policy Update Magnitude: 0.11332
Value Function Update Magnitude: 0.06891

Collected Steps per Second: 24,491.08384
Overall Steps per Second: 12,908.25459

Timestep Collection Time: 2.04221
Timestep Consumption Time: 1.83252
PPO Batch Consumption Time: 0.36175
Total Iteration Time: 3.87473

Cumulative Model Updates: 1,219
Cumulative Timesteps: 20,409,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 20409710...
Checkpoint 20409710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03258
Policy Entropy: 4.34184
Value Function Loss: 0.05256

Mean KL Divergence: 0.00096
SB3 Clip Fraction: 0.00289
Policy Update Magnitude: 0.12985
Value Function Update Magnitude: 0.06815

Collected Steps per Second: 24,809.21795
Overall Steps per Second: 12,886.52225

Timestep Collection Time: 2.01627
Timestep Consumption Time: 1.86546
PPO Batch Consumption Time: 0.36442
Total Iteration Time: 3.88173

Cumulative Model Updates: 1,222
Cumulative Timesteps: 20,459,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03373
Policy Entropy: 4.34087
Value Function Loss: 0.05207

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.00689
Policy Update Magnitude: 0.12998
Value Function Update Magnitude: 0.08489

Collected Steps per Second: 25,037.71254
Overall Steps per Second: 13,035.86309

Timestep Collection Time: 1.99715
Timestep Consumption Time: 1.83873
PPO Batch Consumption Time: 0.35729
Total Iteration Time: 3.83588

Cumulative Model Updates: 1,225
Cumulative Timesteps: 20,509,736

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 20509736...
Checkpoint 20509736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06921
Policy Entropy: 4.35379
Value Function Loss: 0.04027

Mean KL Divergence: 0.00100
SB3 Clip Fraction: 0.00212
Policy Update Magnitude: 0.13029
Value Function Update Magnitude: 0.07268

Collected Steps per Second: 23,774.77831
Overall Steps per Second: 12,808.00451

Timestep Collection Time: 2.10332
Timestep Consumption Time: 1.80096
PPO Batch Consumption Time: 0.36235
Total Iteration Time: 3.90428

Cumulative Model Updates: 1,228
Cumulative Timesteps: 20,559,742

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04052
Policy Entropy: 4.36905
Value Function Loss: 0.05474

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01715
Policy Update Magnitude: 0.12311
Value Function Update Magnitude: 0.07594

Collected Steps per Second: 25,166.46737
Overall Steps per Second: 12,821.11254

Timestep Collection Time: 1.98868
Timestep Consumption Time: 1.91488
PPO Batch Consumption Time: 0.35769
Total Iteration Time: 3.90356

Cumulative Model Updates: 1,231
Cumulative Timesteps: 20,609,790

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 20609790...
Checkpoint 20609790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07369
Policy Entropy: 4.37562
Value Function Loss: 0.05693

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.00875
Policy Update Magnitude: 0.12002
Value Function Update Magnitude: 0.06702

Collected Steps per Second: 24,536.32389
Overall Steps per Second: 12,933.98063

Timestep Collection Time: 2.03934
Timestep Consumption Time: 1.82938
PPO Batch Consumption Time: 0.36793
Total Iteration Time: 3.86872

Cumulative Model Updates: 1,234
Cumulative Timesteps: 20,659,828

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02766
Policy Entropy: 4.38027
Value Function Loss: 0.05999

Mean KL Divergence: 0.00084
SB3 Clip Fraction: 0.00067
Policy Update Magnitude: 0.12831
Value Function Update Magnitude: 0.07162

Collected Steps per Second: 24,952.87861
Overall Steps per Second: 12,866.11857

Timestep Collection Time: 2.00530
Timestep Consumption Time: 1.88383
PPO Batch Consumption Time: 0.36365
Total Iteration Time: 3.88913

Cumulative Model Updates: 1,237
Cumulative Timesteps: 20,709,866

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 20709866...
Checkpoint 20709866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02072
Policy Entropy: 4.39001
Value Function Loss: 0.04916

Mean KL Divergence: 0.00115
SB3 Clip Fraction: 0.00223
Policy Update Magnitude: 0.13059
Value Function Update Magnitude: 0.06816

Collected Steps per Second: 24,051.17532
Overall Steps per Second: 12,685.81844

Timestep Collection Time: 2.07982
Timestep Consumption Time: 1.86333
PPO Batch Consumption Time: 0.36177
Total Iteration Time: 3.94314

Cumulative Model Updates: 1,240
Cumulative Timesteps: 20,759,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03258
Policy Entropy: 4.40355
Value Function Loss: 0.04954

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.00435
Policy Update Magnitude: 0.12874
Value Function Update Magnitude: 0.07743

Collected Steps per Second: 25,515.77541
Overall Steps per Second: 13,023.59962

Timestep Collection Time: 1.96020
Timestep Consumption Time: 1.88021
PPO Batch Consumption Time: 0.35652
Total Iteration Time: 3.84041

Cumulative Model Updates: 1,243
Cumulative Timesteps: 20,809,904

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 20809904...
Checkpoint 20809904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00972
Policy Entropy: 4.41819
Value Function Loss: 0.04429

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.00854
Policy Update Magnitude: 0.12646
Value Function Update Magnitude: 0.07050

Collected Steps per Second: 24,491.64724
Overall Steps per Second: 12,919.47444

Timestep Collection Time: 2.04200
Timestep Consumption Time: 1.82905
PPO Batch Consumption Time: 0.35635
Total Iteration Time: 3.87106

Cumulative Model Updates: 1,246
Cumulative Timesteps: 20,859,916

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08418
Policy Entropy: 4.43124
Value Function Loss: 0.04807

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.00907
Policy Update Magnitude: 0.11731
Value Function Update Magnitude: 0.06689

Collected Steps per Second: 24,845.53349
Overall Steps per Second: 12,991.57430

Timestep Collection Time: 2.01388
Timestep Consumption Time: 1.83754
PPO Batch Consumption Time: 0.37053
Total Iteration Time: 3.85142

Cumulative Model Updates: 1,249
Cumulative Timesteps: 20,909,952

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 20909952...
Checkpoint 20909952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03587
Policy Entropy: 4.43875
Value Function Loss: 0.05148

Mean KL Divergence: 0.00126
SB3 Clip Fraction: 0.00362
Policy Update Magnitude: 0.11135
Value Function Update Magnitude: 0.06353

Collected Steps per Second: 24,238.46147
Overall Steps per Second: 12,706.25137

Timestep Collection Time: 2.06284
Timestep Consumption Time: 1.87223
PPO Batch Consumption Time: 0.35854
Total Iteration Time: 3.93507

Cumulative Model Updates: 1,252
Cumulative Timesteps: 20,959,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00379
Policy Entropy: 4.44568
Value Function Loss: 0.05420

Mean KL Divergence: 0.00103
SB3 Clip Fraction: 0.00239
Policy Update Magnitude: 0.11380
Value Function Update Magnitude: 0.06466

Collected Steps per Second: 24,822.80009
Overall Steps per Second: 12,711.71117

Timestep Collection Time: 2.01508
Timestep Consumption Time: 1.91987
PPO Batch Consumption Time: 0.36610
Total Iteration Time: 3.93495

Cumulative Model Updates: 1,255
Cumulative Timesteps: 21,009,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 21009972...
Checkpoint 21009972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05274
Policy Entropy: 4.44719
Value Function Loss: 0.08193

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.00278
Policy Update Magnitude: 0.11848
Value Function Update Magnitude: 0.06996

Collected Steps per Second: 21,183.49018
Overall Steps per Second: 11,329.38153

Timestep Collection Time: 2.36099
Timestep Consumption Time: 2.05355
PPO Batch Consumption Time: 0.38676
Total Iteration Time: 4.41454

Cumulative Model Updates: 1,258
Cumulative Timesteps: 21,059,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00750
Policy Entropy: 4.44552
Value Function Loss: 0.07864

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01177
Policy Update Magnitude: 0.13135
Value Function Update Magnitude: 0.06913

Collected Steps per Second: 23,450.82457
Overall Steps per Second: 12,522.46304

Timestep Collection Time: 2.13263
Timestep Consumption Time: 1.86115
PPO Batch Consumption Time: 0.35797
Total Iteration Time: 3.99378

Cumulative Model Updates: 1,261
Cumulative Timesteps: 21,109,998

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 21109998...
Checkpoint 21109998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00873
Policy Entropy: 4.43987
Value Function Loss: 0.08650

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01432
Policy Update Magnitude: 0.13154
Value Function Update Magnitude: 0.07313

Collected Steps per Second: 25,990.30273
Overall Steps per Second: 13,022.64238

Timestep Collection Time: 1.92403
Timestep Consumption Time: 1.91590
PPO Batch Consumption Time: 0.36165
Total Iteration Time: 3.83993

Cumulative Model Updates: 1,264
Cumulative Timesteps: 21,160,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06660
Policy Entropy: 4.43570
Value Function Loss: 0.09066

Mean KL Divergence: 0.00128
SB3 Clip Fraction: 0.00620
Policy Update Magnitude: 0.12828
Value Function Update Magnitude: 0.07673

Collected Steps per Second: 24,355.63629
Overall Steps per Second: 12,578.72576

Timestep Collection Time: 2.05439
Timestep Consumption Time: 1.92344
PPO Batch Consumption Time: 0.36688
Total Iteration Time: 3.97783

Cumulative Model Updates: 1,267
Cumulative Timesteps: 21,210,040

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 21210040...
Checkpoint 21210040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01485
Policy Entropy: 4.43075
Value Function Loss: 0.09410

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00008
Policy Update Magnitude: 0.13744
Value Function Update Magnitude: 0.08082

Collected Steps per Second: 24,699.71190
Overall Steps per Second: 13,041.63175

Timestep Collection Time: 2.02464
Timestep Consumption Time: 1.80985
PPO Batch Consumption Time: 0.35944
Total Iteration Time: 3.83449

Cumulative Model Updates: 1,270
Cumulative Timesteps: 21,260,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01034
Policy Entropy: 4.42134
Value Function Loss: 0.07219

Mean KL Divergence: 0.00095
SB3 Clip Fraction: 0.00118
Policy Update Magnitude: 0.14068
Value Function Update Magnitude: 0.08915

Collected Steps per Second: 24,419.87662
Overall Steps per Second: 12,819.31838

Timestep Collection Time: 2.04874
Timestep Consumption Time: 1.85396
PPO Batch Consumption Time: 0.35467
Total Iteration Time: 3.90270

Cumulative Model Updates: 1,273
Cumulative Timesteps: 21,310,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 21310078...
Checkpoint 21310078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02143
Policy Entropy: 4.40617
Value Function Loss: 0.06935

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01109
Policy Update Magnitude: 0.13560
Value Function Update Magnitude: 0.07551

Collected Steps per Second: 24,612.22678
Overall Steps per Second: 12,784.80775

Timestep Collection Time: 2.03216
Timestep Consumption Time: 1.87998
PPO Batch Consumption Time: 0.36269
Total Iteration Time: 3.91214

Cumulative Model Updates: 1,276
Cumulative Timesteps: 21,360,094

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04894
Policy Entropy: 4.39366
Value Function Loss: 0.06393

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01721
Policy Update Magnitude: 0.12315
Value Function Update Magnitude: 0.07803

Collected Steps per Second: 24,961.49557
Overall Steps per Second: 12,850.86038

Timestep Collection Time: 2.00341
Timestep Consumption Time: 1.88801
PPO Batch Consumption Time: 0.36559
Total Iteration Time: 3.89141

Cumulative Model Updates: 1,279
Cumulative Timesteps: 21,410,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 21410102...
Checkpoint 21410102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01074
Policy Entropy: 4.39340
Value Function Loss: 0.08134

Mean KL Divergence: 0.00098
SB3 Clip Fraction: 0.00636
Policy Update Magnitude: 0.13430
Value Function Update Magnitude: 0.07690

Collected Steps per Second: 24,537.55245
Overall Steps per Second: 12,661.17019

Timestep Collection Time: 2.03826
Timestep Consumption Time: 1.91192
PPO Batch Consumption Time: 0.36280
Total Iteration Time: 3.95019

Cumulative Model Updates: 1,282
Cumulative Timesteps: 21,460,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00317
Policy Entropy: 4.39884
Value Function Loss: 0.07312

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00093
Policy Update Magnitude: 0.13236
Value Function Update Magnitude: 0.07586

Collected Steps per Second: 24,783.18062
Overall Steps per Second: 12,643.09331

Timestep Collection Time: 2.01814
Timestep Consumption Time: 1.93785
PPO Batch Consumption Time: 0.36687
Total Iteration Time: 3.95599

Cumulative Model Updates: 1,285
Cumulative Timesteps: 21,510,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 21510132...
Checkpoint 21510132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01436
Policy Entropy: 4.40425
Value Function Loss: 0.08560

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00114
Policy Update Magnitude: 0.12889
Value Function Update Magnitude: 0.07683

Collected Steps per Second: 24,115.51001
Overall Steps per Second: 12,448.44783

Timestep Collection Time: 2.07493
Timestep Consumption Time: 1.94469
PPO Batch Consumption Time: 0.36103
Total Iteration Time: 4.01962

Cumulative Model Updates: 1,288
Cumulative Timesteps: 21,560,170

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01292
Policy Entropy: 4.40182
Value Function Loss: 0.07050

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00049
Policy Update Magnitude: 0.13129
Value Function Update Magnitude: 0.07762

Collected Steps per Second: 24,350.40476
Overall Steps per Second: 12,797.55564

Timestep Collection Time: 2.05418
Timestep Consumption Time: 1.85438
PPO Batch Consumption Time: 0.36803
Total Iteration Time: 3.90856

Cumulative Model Updates: 1,291
Cumulative Timesteps: 21,610,190

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 21610190...
Checkpoint 21610190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02824
Policy Entropy: 4.39797
Value Function Loss: 0.05428

Mean KL Divergence: 0.00075
SB3 Clip Fraction: 0.00121
Policy Update Magnitude: 0.12880
Value Function Update Magnitude: 0.07469

Collected Steps per Second: 24,731.93973
Overall Steps per Second: 12,810.74528

Timestep Collection Time: 2.02402
Timestep Consumption Time: 1.88348
PPO Batch Consumption Time: 0.36363
Total Iteration Time: 3.90750

Cumulative Model Updates: 1,294
Cumulative Timesteps: 21,660,248

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04894
Policy Entropy: 4.39270
Value Function Loss: 0.06163

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00277
Policy Update Magnitude: 0.12092
Value Function Update Magnitude: 0.08248

Collected Steps per Second: 23,917.85916
Overall Steps per Second: 12,665.99969

Timestep Collection Time: 2.09091
Timestep Consumption Time: 1.85746
PPO Batch Consumption Time: 0.36457
Total Iteration Time: 3.94837

Cumulative Model Updates: 1,297
Cumulative Timesteps: 21,710,258

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 21710258...
Checkpoint 21710258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01139
Policy Entropy: 4.38659
Value Function Loss: 0.07275

Mean KL Divergence: 0.00085
SB3 Clip Fraction: 0.00311
Policy Update Magnitude: 0.12379
Value Function Update Magnitude: 0.07939

Collected Steps per Second: 25,415.12238
Overall Steps per Second: 12,858.88095

Timestep Collection Time: 1.96906
Timestep Consumption Time: 1.92272
PPO Batch Consumption Time: 0.36405
Total Iteration Time: 3.89179

Cumulative Model Updates: 1,300
Cumulative Timesteps: 21,760,302

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01471
Policy Entropy: 4.37605
Value Function Loss: 0.10518

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.00762
Policy Update Magnitude: 0.13121
Value Function Update Magnitude: 0.07874

Collected Steps per Second: 24,546.11869
Overall Steps per Second: 12,821.81763

Timestep Collection Time: 2.03706
Timestep Consumption Time: 1.86270
PPO Batch Consumption Time: 0.35806
Total Iteration Time: 3.89976

Cumulative Model Updates: 1,303
Cumulative Timesteps: 21,810,304

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 21810304...
Checkpoint 21810304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04697
Policy Entropy: 4.37489
Value Function Loss: 0.09469

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00201
Policy Update Magnitude: 0.14332
Value Function Update Magnitude: 0.07559

Collected Steps per Second: 24,343.31769
Overall Steps per Second: 13,029.84823

Timestep Collection Time: 2.05444
Timestep Consumption Time: 1.78382
PPO Batch Consumption Time: 0.36552
Total Iteration Time: 3.83826

Cumulative Model Updates: 1,306
Cumulative Timesteps: 21,860,316

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00184
Policy Entropy: 4.37515
Value Function Loss: 0.11113

Mean KL Divergence: 0.00099
SB3 Clip Fraction: 0.00219
Policy Update Magnitude: 0.15157
Value Function Update Magnitude: 0.08369

Collected Steps per Second: 24,320.79932
Overall Steps per Second: 12,948.77358

Timestep Collection Time: 2.05758
Timestep Consumption Time: 1.80703
PPO Batch Consumption Time: 0.35959
Total Iteration Time: 3.86461

Cumulative Model Updates: 1,309
Cumulative Timesteps: 21,910,358

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 21910358...
Checkpoint 21910358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04994
Policy Entropy: 4.38375
Value Function Loss: 0.08974

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01224
Policy Update Magnitude: 0.15425
Value Function Update Magnitude: 0.08877

Collected Steps per Second: 23,802.86801
Overall Steps per Second: 12,918.39040

Timestep Collection Time: 2.10092
Timestep Consumption Time: 1.77015
PPO Batch Consumption Time: 0.35555
Total Iteration Time: 3.87107

Cumulative Model Updates: 1,312
Cumulative Timesteps: 21,960,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00791
Policy Entropy: 4.38078
Value Function Loss: 0.07433

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00639
Policy Update Magnitude: 0.15866
Value Function Update Magnitude: 0.09207

Collected Steps per Second: 25,088.95874
Overall Steps per Second: 13,249.07879

Timestep Collection Time: 1.99323
Timestep Consumption Time: 1.78122
PPO Batch Consumption Time: 0.36421
Total Iteration Time: 3.77445

Cumulative Model Updates: 1,315
Cumulative Timesteps: 22,010,374

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 22010374...
Checkpoint 22010374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03599
Policy Entropy: 4.38012
Value Function Loss: 0.04772

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00192
Policy Update Magnitude: 0.14715
Value Function Update Magnitude: 0.08826

Collected Steps per Second: 24,780.57851
Overall Steps per Second: 13,357.48927

Timestep Collection Time: 2.01819
Timestep Consumption Time: 1.72592
PPO Batch Consumption Time: 0.36277
Total Iteration Time: 3.74412

Cumulative Model Updates: 1,318
Cumulative Timesteps: 22,060,386

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01679
Policy Entropy: 4.39344
Value Function Loss: 0.03882

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.00587
Policy Update Magnitude: 0.13556
Value Function Update Magnitude: 0.08313

Collected Steps per Second: 24,072.63174
Overall Steps per Second: 13,224.75678

Timestep Collection Time: 2.07713
Timestep Consumption Time: 1.70381
PPO Batch Consumption Time: 0.36093
Total Iteration Time: 3.78094

Cumulative Model Updates: 1,321
Cumulative Timesteps: 22,110,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 22110388...
Checkpoint 22110388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01020
Policy Entropy: 4.40651
Value Function Loss: 0.04373

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02805
Policy Update Magnitude: 0.11616
Value Function Update Magnitude: 0.06963

Collected Steps per Second: 24,756.15935
Overall Steps per Second: 13,135.55129

Timestep Collection Time: 2.02099
Timestep Consumption Time: 1.78791
PPO Batch Consumption Time: 0.36324
Total Iteration Time: 3.80890

Cumulative Model Updates: 1,324
Cumulative Timesteps: 22,160,420

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02570
Policy Entropy: 4.39434
Value Function Loss: 0.04442

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.00418
Policy Update Magnitude: 0.13260
Value Function Update Magnitude: 0.08252

Collected Steps per Second: 24,654.40277
Overall Steps per Second: 13,350.39273

Timestep Collection Time: 2.02828
Timestep Consumption Time: 1.71738
PPO Batch Consumption Time: 0.35585
Total Iteration Time: 3.74566

Cumulative Model Updates: 1,327
Cumulative Timesteps: 22,210,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 22210426...
Checkpoint 22210426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02960
Policy Entropy: 4.37581
Value Function Loss: 0.03936

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.00564
Policy Update Magnitude: 0.12232
Value Function Update Magnitude: 0.08274

Collected Steps per Second: 25,090.67462
Overall Steps per Second: 13,265.59436

Timestep Collection Time: 1.99317
Timestep Consumption Time: 1.77673
PPO Batch Consumption Time: 0.36107
Total Iteration Time: 3.76990

Cumulative Model Updates: 1,330
Cumulative Timesteps: 22,260,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02986
Policy Entropy: 4.37754
Value Function Loss: 0.04300

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00131
Policy Update Magnitude: 0.11414
Value Function Update Magnitude: 0.08249

Collected Steps per Second: 24,306.57320
Overall Steps per Second: 13,028.32615

Timestep Collection Time: 2.05813
Timestep Consumption Time: 1.78166
PPO Batch Consumption Time: 0.36583
Total Iteration Time: 3.83979

Cumulative Model Updates: 1,333
Cumulative Timesteps: 22,310,462

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 22310462...
Checkpoint 22310462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03573
Policy Entropy: 4.38805
Value Function Loss: 0.05781

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00006
Policy Update Magnitude: 0.12114
Value Function Update Magnitude: 0.09383

Collected Steps per Second: 25,286.39211
Overall Steps per Second: 13,416.63192

Timestep Collection Time: 1.97766
Timestep Consumption Time: 1.74965
PPO Batch Consumption Time: 0.35899
Total Iteration Time: 3.72731

Cumulative Model Updates: 1,336
Cumulative Timesteps: 22,360,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01743
Policy Entropy: 4.39799
Value Function Loss: 0.08664

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.00308
Policy Update Magnitude: 0.13417
Value Function Update Magnitude: 0.08810

Collected Steps per Second: 24,258.54782
Overall Steps per Second: 12,917.17511

Timestep Collection Time: 2.06195
Timestep Consumption Time: 1.81041
PPO Batch Consumption Time: 0.36478
Total Iteration Time: 3.87236

Cumulative Model Updates: 1,339
Cumulative Timesteps: 22,410,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 22410490...
Checkpoint 22410490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04105
Policy Entropy: 4.40354
Value Function Loss: 0.08021

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.00739
Policy Update Magnitude: 0.14378
Value Function Update Magnitude: 0.09126

Collected Steps per Second: 23,329.70983
Overall Steps per Second: 13,120.28895

Timestep Collection Time: 2.14516
Timestep Consumption Time: 1.66924
PPO Batch Consumption Time: 0.35764
Total Iteration Time: 3.81440

Cumulative Model Updates: 1,342
Cumulative Timesteps: 22,460,536

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12371
Policy Entropy: 4.41131
Value Function Loss: 0.07170

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.00559
Policy Update Magnitude: 0.15176
Value Function Update Magnitude: 0.09201

Collected Steps per Second: 24,408.57047
Overall Steps per Second: 13,104.10937

Timestep Collection Time: 2.04994
Timestep Consumption Time: 1.76841
PPO Batch Consumption Time: 0.36232
Total Iteration Time: 3.81834

Cumulative Model Updates: 1,345
Cumulative Timesteps: 22,510,572

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 22510572...
Checkpoint 22510572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00768
Policy Entropy: 4.41513
Value Function Loss: 0.05945

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.00379
Policy Update Magnitude: 0.13839
Value Function Update Magnitude: 0.09334

Collected Steps per Second: 24,706.15102
Overall Steps per Second: 13,233.84914

Timestep Collection Time: 2.02565
Timestep Consumption Time: 1.75602
PPO Batch Consumption Time: 0.35960
Total Iteration Time: 3.78167

Cumulative Model Updates: 1,348
Cumulative Timesteps: 22,560,618

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02969
Policy Entropy: 4.41448
Value Function Loss: 0.05724

Mean KL Divergence: 0.00094
SB3 Clip Fraction: 0.00125
Policy Update Magnitude: 0.12990
Value Function Update Magnitude: 0.11177

Collected Steps per Second: 24,337.04974
Overall Steps per Second: 13,357.07747

Timestep Collection Time: 2.05465
Timestep Consumption Time: 1.68899
PPO Batch Consumption Time: 0.36551
Total Iteration Time: 3.74363

Cumulative Model Updates: 1,351
Cumulative Timesteps: 22,610,622

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 22610622...
Checkpoint 22610622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00374
Policy Entropy: 4.41234
Value Function Loss: 0.06498

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00084
Policy Update Magnitude: 0.13889
Value Function Update Magnitude: 0.12075

Collected Steps per Second: 24,213.46296
Overall Steps per Second: 13,008.74434

Timestep Collection Time: 2.06612
Timestep Consumption Time: 1.77960
PPO Batch Consumption Time: 0.36706
Total Iteration Time: 3.84572

Cumulative Model Updates: 1,354
Cumulative Timesteps: 22,660,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03574
Policy Entropy: 4.41104
Value Function Loss: 0.06151

Mean KL Divergence: 0.00072
SB3 Clip Fraction: 0.00214
Policy Update Magnitude: 0.14692
Value Function Update Magnitude: 0.10955

Collected Steps per Second: 24,829.26223
Overall Steps per Second: 13,476.96483

Timestep Collection Time: 2.01561
Timestep Consumption Time: 1.69784
PPO Batch Consumption Time: 0.35987
Total Iteration Time: 3.71345

Cumulative Model Updates: 1,357
Cumulative Timesteps: 22,710,696

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 22710696...
Checkpoint 22710696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03812
Policy Entropy: 4.41261
Value Function Loss: 0.08272

Mean KL Divergence: 0.00075
SB3 Clip Fraction: 0.00203
Policy Update Magnitude: 0.14623
Value Function Update Magnitude: 0.10123

Collected Steps per Second: 24,709.48650
Overall Steps per Second: 13,096.38057

Timestep Collection Time: 2.02505
Timestep Consumption Time: 1.79570
PPO Batch Consumption Time: 0.36630
Total Iteration Time: 3.82075

Cumulative Model Updates: 1,360
Cumulative Timesteps: 22,760,734

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06439
Policy Entropy: 4.42489
Value Function Loss: 0.08193

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.00540
Policy Update Magnitude: 0.15512
Value Function Update Magnitude: 0.11583

Collected Steps per Second: 24,460.07429
Overall Steps per Second: 13,211.57000

Timestep Collection Time: 2.04537
Timestep Consumption Time: 1.74146
PPO Batch Consumption Time: 0.35802
Total Iteration Time: 3.78683

Cumulative Model Updates: 1,363
Cumulative Timesteps: 22,810,764

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 22810764...
Checkpoint 22810764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02092
Policy Entropy: 4.43311
Value Function Loss: 0.06655

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01559
Policy Update Magnitude: 0.14663
Value Function Update Magnitude: 0.12933

Collected Steps per Second: 25,282.66533
Overall Steps per Second: 13,292.70025

Timestep Collection Time: 1.97914
Timestep Consumption Time: 1.78518
PPO Batch Consumption Time: 0.36339
Total Iteration Time: 3.76432

Cumulative Model Updates: 1,366
Cumulative Timesteps: 22,860,802

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00280
Policy Entropy: 4.42709
Value Function Loss: 0.04212

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00102
Policy Update Magnitude: 0.14154
Value Function Update Magnitude: 0.12378

Collected Steps per Second: 25,050.80476
Overall Steps per Second: 13,232.99315

Timestep Collection Time: 1.99602
Timestep Consumption Time: 1.78256
PPO Batch Consumption Time: 0.36707
Total Iteration Time: 3.77859

Cumulative Model Updates: 1,369
Cumulative Timesteps: 22,910,804

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 22910804...
Checkpoint 22910804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01257
Policy Entropy: 4.42161
Value Function Loss: 0.03889

Mean KL Divergence: 0.00075
SB3 Clip Fraction: 0.00081
Policy Update Magnitude: 0.12814
Value Function Update Magnitude: 0.11545

Collected Steps per Second: 24,746.59242
Overall Steps per Second: 13,439.05461

Timestep Collection Time: 2.02048
Timestep Consumption Time: 1.70002
PPO Batch Consumption Time: 0.36071
Total Iteration Time: 3.72050

Cumulative Model Updates: 1,372
Cumulative Timesteps: 22,960,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06479
Policy Entropy: 4.42354
Value Function Loss: 0.04707

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00017
Policy Update Magnitude: 0.12258
Value Function Update Magnitude: 0.11455

Collected Steps per Second: 24,114.71641
Overall Steps per Second: 13,054.88309

Timestep Collection Time: 2.07458
Timestep Consumption Time: 1.75755
PPO Batch Consumption Time: 0.35547
Total Iteration Time: 3.83213

Cumulative Model Updates: 1,375
Cumulative Timesteps: 23,010,832

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 23010832...
Checkpoint 23010832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02064
Policy Entropy: 4.42714
Value Function Loss: 0.06163

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00011
Policy Update Magnitude: 0.12793
Value Function Update Magnitude: 0.12014

Collected Steps per Second: 24,167.52335
Overall Steps per Second: 13,097.81982

Timestep Collection Time: 2.06922
Timestep Consumption Time: 1.74882
PPO Batch Consumption Time: 0.36689
Total Iteration Time: 3.81804

Cumulative Model Updates: 1,378
Cumulative Timesteps: 23,060,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03821
Policy Entropy: 4.42612
Value Function Loss: 0.06317

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00011
Policy Update Magnitude: 0.13208
Value Function Update Magnitude: 0.13001

Collected Steps per Second: 25,874.78866
Overall Steps per Second: 13,397.87157

Timestep Collection Time: 1.93292
Timestep Consumption Time: 1.80006
PPO Batch Consumption Time: 0.37296
Total Iteration Time: 3.73298

Cumulative Model Updates: 1,381
Cumulative Timesteps: 23,110,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 23110854...
Checkpoint 23110854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06107
Policy Entropy: 4.42533
Value Function Loss: 0.07088

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00017
Policy Update Magnitude: 0.13800
Value Function Update Magnitude: 0.13341

Collected Steps per Second: 25,013.66661
Overall Steps per Second: 13,325.50662

Timestep Collection Time: 1.99995
Timestep Consumption Time: 1.75421
PPO Batch Consumption Time: 0.35569
Total Iteration Time: 3.75415

Cumulative Model Updates: 1,384
Cumulative Timesteps: 23,160,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04086
Policy Entropy: 4.42531
Value Function Loss: 0.08829

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00216
Policy Update Magnitude: 0.14068
Value Function Update Magnitude: 0.13302

Collected Steps per Second: 23,607.21156
Overall Steps per Second: 13,153.04318

Timestep Collection Time: 2.11944
Timestep Consumption Time: 1.68455
PPO Batch Consumption Time: 0.36009
Total Iteration Time: 3.80399

Cumulative Model Updates: 1,387
Cumulative Timesteps: 23,210,914

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 23210914...
Checkpoint 23210914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01360
Policy Entropy: 4.42393
Value Function Loss: 0.07612

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01091
Policy Update Magnitude: 0.13852
Value Function Update Magnitude: 0.13309

Collected Steps per Second: 25,155.09898
Overall Steps per Second: 13,170.12008

Timestep Collection Time: 1.98902
Timestep Consumption Time: 1.81003
PPO Batch Consumption Time: 0.35938
Total Iteration Time: 3.79905

Cumulative Model Updates: 1,390
Cumulative Timesteps: 23,260,948

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01906
Policy Entropy: 4.42116
Value Function Loss: 0.06637

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.00551
Policy Update Magnitude: 0.13701
Value Function Update Magnitude: 0.12503

Collected Steps per Second: 24,762.58582
Overall Steps per Second: 13,329.14282

Timestep Collection Time: 2.01926
Timestep Consumption Time: 1.73207
PPO Batch Consumption Time: 0.35744
Total Iteration Time: 3.75133

Cumulative Model Updates: 1,393
Cumulative Timesteps: 23,310,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 23310950...
Checkpoint 23310950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03577
Policy Entropy: 4.42212
Value Function Loss: 0.06501

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00058
Policy Update Magnitude: 0.13692
Value Function Update Magnitude: 0.11573

Collected Steps per Second: 25,270.50581
Overall Steps per Second: 13,318.60396

Timestep Collection Time: 1.98025
Timestep Consumption Time: 1.77705
PPO Batch Consumption Time: 0.35991
Total Iteration Time: 3.75730

Cumulative Model Updates: 1,396
Cumulative Timesteps: 23,360,992

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08315
Policy Entropy: 4.41843
Value Function Loss: 0.07261

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.00990
Policy Update Magnitude: 0.13116
Value Function Update Magnitude: 0.11457

Collected Steps per Second: 22,251.31304
Overall Steps per Second: 12,559.23744

Timestep Collection Time: 2.24760
Timestep Consumption Time: 1.73449
PPO Batch Consumption Time: 0.35813
Total Iteration Time: 3.98209

Cumulative Model Updates: 1,399
Cumulative Timesteps: 23,411,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 23411004...
Checkpoint 23411004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03811
Policy Entropy: 4.41239
Value Function Loss: 0.07412

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01643
Policy Update Magnitude: 0.12355
Value Function Update Magnitude: 0.10791

Collected Steps per Second: 24,791.99812
Overall Steps per Second: 13,327.88472

Timestep Collection Time: 2.01751
Timestep Consumption Time: 1.73538
PPO Batch Consumption Time: 0.36987
Total Iteration Time: 3.75288

Cumulative Model Updates: 1,402
Cumulative Timesteps: 23,461,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00967
Policy Entropy: 4.40847
Value Function Loss: 0.05813

Mean KL Divergence: 0.00108
SB3 Clip Fraction: 0.00653
Policy Update Magnitude: 0.11739
Value Function Update Magnitude: 0.11085

Collected Steps per Second: 24,751.66788
Overall Steps per Second: 13,057.82868

Timestep Collection Time: 2.02039
Timestep Consumption Time: 1.80934
PPO Batch Consumption Time: 0.36530
Total Iteration Time: 3.82973

Cumulative Model Updates: 1,405
Cumulative Timesteps: 23,511,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 23511030...
Checkpoint 23511030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10874
Policy Entropy: 4.40740
Value Function Loss: 0.05146

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00180
Policy Update Magnitude: 0.11250
Value Function Update Magnitude: 0.11134

Collected Steps per Second: 23,965.93139
Overall Steps per Second: 13,059.07432

Timestep Collection Time: 2.08713
Timestep Consumption Time: 1.74316
PPO Batch Consumption Time: 0.36124
Total Iteration Time: 3.83029

Cumulative Model Updates: 1,408
Cumulative Timesteps: 23,561,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03971
Policy Entropy: 4.40816
Value Function Loss: 0.04161

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00041
Policy Update Magnitude: 0.11186
Value Function Update Magnitude: 0.10932

Collected Steps per Second: 25,036.00746
Overall Steps per Second: 13,246.01505

Timestep Collection Time: 1.99896
Timestep Consumption Time: 1.77923
PPO Batch Consumption Time: 0.35645
Total Iteration Time: 3.77819

Cumulative Model Updates: 1,411
Cumulative Timesteps: 23,611,096

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 23611096...
Checkpoint 23611096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05752
Policy Entropy: 4.40919
Value Function Loss: 0.04011

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00011
Policy Update Magnitude: 0.10199
Value Function Update Magnitude: 0.10378

Collected Steps per Second: 24,764.55857
Overall Steps per Second: 13,223.18189

Timestep Collection Time: 2.02103
Timestep Consumption Time: 1.76399
PPO Batch Consumption Time: 0.35908
Total Iteration Time: 3.78502

Cumulative Model Updates: 1,414
Cumulative Timesteps: 23,661,146

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10341
Policy Entropy: 4.41116
Value Function Loss: 0.05588

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00011
Policy Update Magnitude: 0.10017
Value Function Update Magnitude: 0.10214

Collected Steps per Second: 25,387.80123
Overall Steps per Second: 13,407.72191

Timestep Collection Time: 1.97016
Timestep Consumption Time: 1.76038
PPO Batch Consumption Time: 0.35904
Total Iteration Time: 3.73054

Cumulative Model Updates: 1,417
Cumulative Timesteps: 23,711,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 23711164...
Checkpoint 23711164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02148
Policy Entropy: 4.40831
Value Function Loss: 0.06355

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00015
Policy Update Magnitude: 0.10802
Value Function Update Magnitude: 0.10766

Collected Steps per Second: 24,438.59900
Overall Steps per Second: 13,096.59949

Timestep Collection Time: 2.04725
Timestep Consumption Time: 1.77298
PPO Batch Consumption Time: 0.36135
Total Iteration Time: 3.82023

Cumulative Model Updates: 1,420
Cumulative Timesteps: 23,761,196

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01958
Policy Entropy: 4.40375
Value Function Loss: 0.07291

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00121
Policy Update Magnitude: 0.11711
Value Function Update Magnitude: 0.11049

Collected Steps per Second: 24,354.33351
Overall Steps per Second: 13,301.36958

Timestep Collection Time: 2.05491
Timestep Consumption Time: 1.70756
PPO Batch Consumption Time: 0.35483
Total Iteration Time: 3.76247

Cumulative Model Updates: 1,423
Cumulative Timesteps: 23,811,242

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 23811242...
Checkpoint 23811242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00147
Policy Entropy: 4.40116
Value Function Loss: 0.05372

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00231
Policy Update Magnitude: 0.11576
Value Function Update Magnitude: 0.11610

Collected Steps per Second: 24,640.93393
Overall Steps per Second: 13,060.11768

Timestep Collection Time: 2.02931
Timestep Consumption Time: 1.79945
PPO Batch Consumption Time: 0.36171
Total Iteration Time: 3.82876

Cumulative Model Updates: 1,426
Cumulative Timesteps: 23,861,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04070
Policy Entropy: 4.41194
Value Function Loss: 0.05769

Mean KL Divergence: 0.00105
SB3 Clip Fraction: 0.00476
Policy Update Magnitude: 0.11323
Value Function Update Magnitude: 0.12222

Collected Steps per Second: 24,035.56918
Overall Steps per Second: 13,072.38790

Timestep Collection Time: 2.08025
Timestep Consumption Time: 1.74461
PPO Batch Consumption Time: 0.35411
Total Iteration Time: 3.82486

Cumulative Model Updates: 1,429
Cumulative Timesteps: 23,911,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 23911246...
Checkpoint 23911246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00446
Policy Entropy: 4.42396
Value Function Loss: 0.05697

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02758
Policy Update Magnitude: 0.09772
Value Function Update Magnitude: 0.12084

Collected Steps per Second: 24,847.57211
Overall Steps per Second: 13,230.57887

Timestep Collection Time: 2.01259
Timestep Consumption Time: 1.76714
PPO Batch Consumption Time: 0.35788
Total Iteration Time: 3.77973

Cumulative Model Updates: 1,432
Cumulative Timesteps: 23,961,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05565
Policy Entropy: 4.42078
Value Function Loss: 0.07195

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00705
Policy Update Magnitude: 0.10068
Value Function Update Magnitude: 0.11939

Collected Steps per Second: 23,964.74538
Overall Steps per Second: 12,935.95468

Timestep Collection Time: 2.08665
Timestep Consumption Time: 1.77901
PPO Batch Consumption Time: 0.35973
Total Iteration Time: 3.86566

Cumulative Model Updates: 1,435
Cumulative Timesteps: 24,011,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 24011260...
Checkpoint 24011260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00758
Policy Entropy: 4.41370
Value Function Loss: 0.09018

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00213
Policy Update Magnitude: 0.10982
Value Function Update Magnitude: 0.11325

Collected Steps per Second: 24,645.26987
Overall Steps per Second: 13,100.74699

Timestep Collection Time: 2.03025
Timestep Consumption Time: 1.78908
PPO Batch Consumption Time: 0.36220
Total Iteration Time: 3.81932

Cumulative Model Updates: 1,438
Cumulative Timesteps: 24,061,296

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00533
Policy Entropy: 4.40972
Value Function Loss: 0.09015

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00545
Policy Update Magnitude: 0.11842
Value Function Update Magnitude: 0.13354

Collected Steps per Second: 23,707.19580
Overall Steps per Second: 12,898.90600

Timestep Collection Time: 2.11016
Timestep Consumption Time: 1.76815
PPO Batch Consumption Time: 0.35899
Total Iteration Time: 3.87831

Cumulative Model Updates: 1,441
Cumulative Timesteps: 24,111,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 24111322...
Checkpoint 24111322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02941
Policy Entropy: 4.40875
Value Function Loss: 0.09148

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00340
Policy Update Magnitude: 0.12233
Value Function Update Magnitude: 0.14143

Collected Steps per Second: 24,171.75490
Overall Steps per Second: 13,352.43436

Timestep Collection Time: 2.07035
Timestep Consumption Time: 1.67758
PPO Batch Consumption Time: 0.35857
Total Iteration Time: 3.74793

Cumulative Model Updates: 1,444
Cumulative Timesteps: 24,161,366

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00945
Policy Entropy: 4.39746
Value Function Loss: 0.08543

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.00781
Policy Update Magnitude: 0.11985
Value Function Update Magnitude: 0.12918

Collected Steps per Second: 24,561.65275
Overall Steps per Second: 13,201.00596

Timestep Collection Time: 2.03708
Timestep Consumption Time: 1.75309
PPO Batch Consumption Time: 0.36148
Total Iteration Time: 3.79017

Cumulative Model Updates: 1,447
Cumulative Timesteps: 24,211,400

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 24211400...
Checkpoint 24211400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00899
Policy Entropy: 4.39976
Value Function Loss: 0.08417

Mean KL Divergence: 0.00098
SB3 Clip Fraction: 0.00363
Policy Update Magnitude: 0.11444
Value Function Update Magnitude: 0.12757

Collected Steps per Second: 24,564.09899
Overall Steps per Second: 13,438.78268

Timestep Collection Time: 2.03590
Timestep Consumption Time: 1.68542
PPO Batch Consumption Time: 0.35904
Total Iteration Time: 3.72132

Cumulative Model Updates: 1,450
Cumulative Timesteps: 24,261,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02565
Policy Entropy: 4.40989
Value Function Loss: 0.07091

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00011
Policy Update Magnitude: 0.11490
Value Function Update Magnitude: 0.13441

Collected Steps per Second: 23,333.30178
Overall Steps per Second: 12,690.48375

Timestep Collection Time: 2.14440
Timestep Consumption Time: 1.79839
PPO Batch Consumption Time: 0.36419
Total Iteration Time: 3.94280

Cumulative Model Updates: 1,453
Cumulative Timesteps: 24,311,446

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 24311446...
Checkpoint 24311446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09971
Policy Entropy: 4.41821
Value Function Loss: 0.07705

Mean KL Divergence: 0.00097
SB3 Clip Fraction: 0.00214
Policy Update Magnitude: 0.11187
Value Function Update Magnitude: 0.13810

Collected Steps per Second: 24,713.45928
Overall Steps per Second: 13,200.20928

Timestep Collection Time: 2.02424
Timestep Consumption Time: 1.76555
PPO Batch Consumption Time: 0.35855
Total Iteration Time: 3.78979

Cumulative Model Updates: 1,456
Cumulative Timesteps: 24,361,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01112
Policy Entropy: 4.42035
Value Function Loss: 0.07915

Mean KL Divergence: 0.00083
SB3 Clip Fraction: 0.00171
Policy Update Magnitude: 0.11218
Value Function Update Magnitude: 0.14449

Collected Steps per Second: 25,237.68471
Overall Steps per Second: 13,281.55394

Timestep Collection Time: 1.98235
Timestep Consumption Time: 1.78453
PPO Batch Consumption Time: 0.36309
Total Iteration Time: 3.76688

Cumulative Model Updates: 1,459
Cumulative Timesteps: 24,411,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 24411502...
Checkpoint 24411502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00367
Policy Entropy: 4.42395
Value Function Loss: 0.06982

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00045
Policy Update Magnitude: 0.11443
Value Function Update Magnitude: 0.13669

Collected Steps per Second: 24,637.60125
Overall Steps per Second: 13,158.63295

Timestep Collection Time: 2.02958
Timestep Consumption Time: 1.77051
PPO Batch Consumption Time: 0.35669
Total Iteration Time: 3.80009

Cumulative Model Updates: 1,462
Cumulative Timesteps: 24,461,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04653
Policy Entropy: 4.43005
Value Function Loss: 0.05985

Mean KL Divergence: 0.00092
SB3 Clip Fraction: 0.00245
Policy Update Magnitude: 0.11074
Value Function Update Magnitude: 0.12216

Collected Steps per Second: 24,134.22951
Overall Steps per Second: 13,371.14401

Timestep Collection Time: 2.07249
Timestep Consumption Time: 1.66825
PPO Batch Consumption Time: 0.36085
Total Iteration Time: 3.74074

Cumulative Model Updates: 1,465
Cumulative Timesteps: 24,511,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 24511524...
Checkpoint 24511524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07878
Policy Entropy: 4.43416
Value Function Loss: 0.05053

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.00459
Policy Update Magnitude: 0.10123
Value Function Update Magnitude: 0.12153

Collected Steps per Second: 25,105.05220
Overall Steps per Second: 13,329.29570

Timestep Collection Time: 1.99299
Timestep Consumption Time: 1.76070
PPO Batch Consumption Time: 0.36111
Total Iteration Time: 3.75369

Cumulative Model Updates: 1,468
Cumulative Timesteps: 24,561,558

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01233
Policy Entropy: 4.43281
Value Function Loss: 0.06187

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00055
Policy Update Magnitude: 0.10308
Value Function Update Magnitude: 0.13056

Collected Steps per Second: 24,922.80372
Overall Steps per Second: 13,275.83373

Timestep Collection Time: 2.00732
Timestep Consumption Time: 1.76103
PPO Batch Consumption Time: 0.36400
Total Iteration Time: 3.76835

Cumulative Model Updates: 1,471
Cumulative Timesteps: 24,611,586

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 24611586...
Checkpoint 24611586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00882
Policy Entropy: 4.42425
Value Function Loss: 0.06173

Mean KL Divergence: 0.00073
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.10780
Value Function Update Magnitude: 0.14348

Collected Steps per Second: 23,884.68598
Overall Steps per Second: 12,931.13496

Timestep Collection Time: 2.09490
Timestep Consumption Time: 1.77452
PPO Batch Consumption Time: 0.35942
Total Iteration Time: 3.86942

Cumulative Model Updates: 1,474
Cumulative Timesteps: 24,661,622

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04005
Policy Entropy: 4.41336
Value Function Loss: 0.08063

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.00315
Policy Update Magnitude: 0.12104
Value Function Update Magnitude: 0.14313

Collected Steps per Second: 23,608.30464
Overall Steps per Second: 12,750.68332

Timestep Collection Time: 2.11951
Timestep Consumption Time: 1.80483
PPO Batch Consumption Time: 0.36445
Total Iteration Time: 3.92434

Cumulative Model Updates: 1,477
Cumulative Timesteps: 24,711,660

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 24711660...
Checkpoint 24711660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01358
Policy Entropy: 4.39990
Value Function Loss: 0.06899

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01035
Policy Update Magnitude: 0.11863
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 24,796.48298
Overall Steps per Second: 13,408.03784

Timestep Collection Time: 2.01714
Timestep Consumption Time: 1.71331
PPO Batch Consumption Time: 0.36225
Total Iteration Time: 3.73045

Cumulative Model Updates: 1,480
Cumulative Timesteps: 24,761,678

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03167
Policy Entropy: 4.39239
Value Function Loss: 0.07868

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01271
Policy Update Magnitude: 0.11725
Value Function Update Magnitude: 0.12183

Collected Steps per Second: 24,625.90669
Overall Steps per Second: 13,112.83231

Timestep Collection Time: 2.03201
Timestep Consumption Time: 1.78410
PPO Batch Consumption Time: 0.36319
Total Iteration Time: 3.81611

Cumulative Model Updates: 1,483
Cumulative Timesteps: 24,811,718

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 24811718...
Checkpoint 24811718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02156
Policy Entropy: 4.38750
Value Function Loss: 0.06022

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.00081
Policy Update Magnitude: 0.11891
Value Function Update Magnitude: 0.11320

Collected Steps per Second: 24,074.07211
Overall Steps per Second: 13,173.69057

Timestep Collection Time: 2.07817
Timestep Consumption Time: 1.71955
PPO Batch Consumption Time: 0.36174
Total Iteration Time: 3.79772

Cumulative Model Updates: 1,486
Cumulative Timesteps: 24,861,748

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01186
Policy Entropy: 4.37967
Value Function Loss: 0.06686

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.00140
Policy Update Magnitude: 0.12369
Value Function Update Magnitude: 0.10069

Collected Steps per Second: 25,892.17534
Overall Steps per Second: 13,325.84345

Timestep Collection Time: 1.93263
Timestep Consumption Time: 1.82248
PPO Batch Consumption Time: 0.36327
Total Iteration Time: 3.75511

Cumulative Model Updates: 1,489
Cumulative Timesteps: 24,911,788

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 24911788...
Checkpoint 24911788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02039
Policy Entropy: 4.37022
Value Function Loss: 0.06232

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.00616
Policy Update Magnitude: 0.11657
Value Function Update Magnitude: 0.09194

Collected Steps per Second: 25,360.75370
Overall Steps per Second: 13,408.44336

Timestep Collection Time: 1.97163
Timestep Consumption Time: 1.75751
PPO Batch Consumption Time: 0.36243
Total Iteration Time: 3.72914

Cumulative Model Updates: 1,492
Cumulative Timesteps: 24,961,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01004
Policy Entropy: 4.37179
Value Function Loss: 0.04896

Mean KL Divergence: 0.00103
SB3 Clip Fraction: 0.00238
Policy Update Magnitude: 0.11426
Value Function Update Magnitude: 0.09464

Collected Steps per Second: 24,641.38729
Overall Steps per Second: 13,389.47367

Timestep Collection Time: 2.03032
Timestep Consumption Time: 1.70619
PPO Batch Consumption Time: 0.36167
Total Iteration Time: 3.73652

Cumulative Model Updates: 1,495
Cumulative Timesteps: 25,011,820

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 25011820...
Checkpoint 25011820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03107
Policy Entropy: 4.37496
Value Function Loss: 0.06134

Mean KL Divergence: 0.00093
SB3 Clip Fraction: 0.00202
Policy Update Magnitude: 0.11345
Value Function Update Magnitude: 0.08930

Collected Steps per Second: 24,528.67850
Overall Steps per Second: 13,123.84203

Timestep Collection Time: 2.03900
Timestep Consumption Time: 1.77193
PPO Batch Consumption Time: 0.36784
Total Iteration Time: 3.81093

Cumulative Model Updates: 1,498
Cumulative Timesteps: 25,061,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03236
Policy Entropy: 4.37948
Value Function Loss: 0.05352

Mean KL Divergence: 0.00098
SB3 Clip Fraction: 0.00161
Policy Update Magnitude: 0.11654
Value Function Update Magnitude: 0.11291

Collected Steps per Second: 24,846.52782
Overall Steps per Second: 13,245.28326

Timestep Collection Time: 2.01251
Timestep Consumption Time: 1.76272
PPO Batch Consumption Time: 0.36854
Total Iteration Time: 3.77523

Cumulative Model Updates: 1,501
Cumulative Timesteps: 25,111,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 25111838...
Checkpoint 25111838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01638
Policy Entropy: 4.38244
Value Function Loss: 0.06049

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.00531
Policy Update Magnitude: 0.12285
Value Function Update Magnitude: 0.10758

Collected Steps per Second: 24,427.51638
Overall Steps per Second: 13,086.59314

Timestep Collection Time: 2.04892
Timestep Consumption Time: 1.77561
PPO Batch Consumption Time: 0.35615
Total Iteration Time: 3.82452

Cumulative Model Updates: 1,504
Cumulative Timesteps: 25,161,888

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12370
Policy Entropy: 4.39176
Value Function Loss: 0.06542

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.00432
Policy Update Magnitude: 0.12075
Value Function Update Magnitude: 0.10965

Collected Steps per Second: 23,807.82348
Overall Steps per Second: 13,089.12917

Timestep Collection Time: 2.10183
Timestep Consumption Time: 1.72119
PPO Batch Consumption Time: 0.35025
Total Iteration Time: 3.82302

Cumulative Model Updates: 1,507
Cumulative Timesteps: 25,211,928

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 25211928...
Checkpoint 25211928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00934
Policy Entropy: 4.39951
Value Function Loss: 0.06958

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00073
Policy Update Magnitude: 0.11448
Value Function Update Magnitude: 0.11010

Collected Steps per Second: 25,189.81864
Overall Steps per Second: 13,126.68866

Timestep Collection Time: 1.98604
Timestep Consumption Time: 1.82513
PPO Batch Consumption Time: 0.36929
Total Iteration Time: 3.81117

Cumulative Model Updates: 1,510
Cumulative Timesteps: 25,261,956

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04101
Policy Entropy: 4.40465
Value Function Loss: 0.07951

Mean KL Divergence: 0.00126
SB3 Clip Fraction: 0.00805
Policy Update Magnitude: 0.11802
Value Function Update Magnitude: 0.12004

Collected Steps per Second: 25,093.28442
Overall Steps per Second: 13,349.40451

Timestep Collection Time: 1.99288
Timestep Consumption Time: 1.75320
PPO Batch Consumption Time: 0.35796
Total Iteration Time: 3.74608

Cumulative Model Updates: 1,513
Cumulative Timesteps: 25,311,964

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 25311964...
Checkpoint 25311964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06257
Policy Entropy: 4.40392
Value Function Loss: 0.07936

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.00680
Policy Update Magnitude: 0.11318
Value Function Update Magnitude: 0.10730

Collected Steps per Second: 24,657.15641
Overall Steps per Second: 13,442.52581

Timestep Collection Time: 2.02813
Timestep Consumption Time: 1.69200
PPO Batch Consumption Time: 0.36338
Total Iteration Time: 3.72013

Cumulative Model Updates: 1,516
Cumulative Timesteps: 25,361,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00245
Policy Entropy: 4.40216
Value Function Loss: 0.07004

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00493
Policy Update Magnitude: 0.11052
Value Function Update Magnitude: 0.10810

Collected Steps per Second: 24,483.10388
Overall Steps per Second: 13,110.41143

Timestep Collection Time: 2.04312
Timestep Consumption Time: 1.77232
PPO Batch Consumption Time: 0.35879
Total Iteration Time: 3.81544

Cumulative Model Updates: 1,519
Cumulative Timesteps: 25,411,994

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 25411994...
Checkpoint 25411994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01810
Policy Entropy: 4.40142
Value Function Loss: 0.07100

Mean KL Divergence: 0.00099
SB3 Clip Fraction: 0.00301
Policy Update Magnitude: 0.10640
Value Function Update Magnitude: 0.10574

Collected Steps per Second: 24,708.16242
Overall Steps per Second: 13,509.93375

Timestep Collection Time: 2.02548
Timestep Consumption Time: 1.67890
PPO Batch Consumption Time: 0.35868
Total Iteration Time: 3.70439

Cumulative Model Updates: 1,522
Cumulative Timesteps: 25,462,040

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00286
Policy Entropy: 4.40170
Value Function Loss: 0.05186

Mean KL Divergence: 0.00089
SB3 Clip Fraction: 0.00197
Policy Update Magnitude: 0.09874
Value Function Update Magnitude: 0.09948

Collected Steps per Second: 25,136.58237
Overall Steps per Second: 13,287.93797

Timestep Collection Time: 1.99001
Timestep Consumption Time: 1.77446
PPO Batch Consumption Time: 0.36158
Total Iteration Time: 3.76447

Cumulative Model Updates: 1,525
Cumulative Timesteps: 25,512,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 25512062...
Checkpoint 25512062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02959
Policy Entropy: 4.40055
Value Function Loss: 0.05457

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00011
Policy Update Magnitude: 0.09813
Value Function Update Magnitude: 0.08907

Collected Steps per Second: 24,841.83757
Overall Steps per Second: 13,331.92470

Timestep Collection Time: 2.01314
Timestep Consumption Time: 1.73801
PPO Batch Consumption Time: 0.35448
Total Iteration Time: 3.75115

Cumulative Model Updates: 1,528
Cumulative Timesteps: 25,562,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02725
Policy Entropy: 4.39310
Value Function Loss: 0.04069

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00015
Policy Update Magnitude: 0.09738
Value Function Update Magnitude: 0.08472

Collected Steps per Second: 24,744.14563
Overall Steps per Second: 13,277.26081

Timestep Collection Time: 2.02189
Timestep Consumption Time: 1.74620
PPO Batch Consumption Time: 0.35401
Total Iteration Time: 3.76810

Cumulative Model Updates: 1,531
Cumulative Timesteps: 25,612,102

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 25612102...
Checkpoint 25612102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05440
Policy Entropy: 4.38079
Value Function Loss: 0.03273

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00157
Policy Update Magnitude: 0.09680
Value Function Update Magnitude: 0.08212

Collected Steps per Second: 24,619.55282
Overall Steps per Second: 13,119.08090

Timestep Collection Time: 2.03091
Timestep Consumption Time: 1.78034
PPO Batch Consumption Time: 0.36132
Total Iteration Time: 3.81124

Cumulative Model Updates: 1,534
Cumulative Timesteps: 25,662,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00028
Policy Entropy: 4.36903
Value Function Loss: 0.04405

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.00244
Policy Update Magnitude: 0.08868
Value Function Update Magnitude: 0.08119

Collected Steps per Second: 24,918.86606
Overall Steps per Second: 13,437.64405

Timestep Collection Time: 2.00844
Timestep Consumption Time: 1.71602
PPO Batch Consumption Time: 0.36677
Total Iteration Time: 3.72446

Cumulative Model Updates: 1,537
Cumulative Timesteps: 25,712,150

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 25712150...
Checkpoint 25712150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00311
Policy Entropy: 4.36693
Value Function Loss: 0.05624

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00010
Policy Update Magnitude: 0.09234
Value Function Update Magnitude: 0.08201

Collected Steps per Second: 23,025.07016
Overall Steps per Second: 12,669.19446

Timestep Collection Time: 2.17233
Timestep Consumption Time: 1.77567
PPO Batch Consumption Time: 0.35901
Total Iteration Time: 3.94800

Cumulative Model Updates: 1,540
Cumulative Timesteps: 25,762,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01704
Policy Entropy: 4.36799
Value Function Loss: 0.07765

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00037
Policy Update Magnitude: 0.10359
Value Function Update Magnitude: 0.09819

Collected Steps per Second: 22,198.19181
Overall Steps per Second: 12,510.87697

Timestep Collection Time: 2.25289
Timestep Consumption Time: 1.74444
PPO Batch Consumption Time: 0.35942
Total Iteration Time: 3.99732

Cumulative Model Updates: 1,543
Cumulative Timesteps: 25,812,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 25812178...
Checkpoint 25812178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02387
Policy Entropy: 4.37039
Value Function Loss: 0.06050

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.00603
Policy Update Magnitude: 0.10834
Value Function Update Magnitude: 0.09219

Collected Steps per Second: 25,768.12256
Overall Steps per Second: 13,615.72554

Timestep Collection Time: 1.94061
Timestep Consumption Time: 1.73205
PPO Batch Consumption Time: 0.35413
Total Iteration Time: 3.67267

Cumulative Model Updates: 1,546
Cumulative Timesteps: 25,862,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04219
Policy Entropy: 4.37319
Value Function Loss: 0.05756

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.00392
Policy Update Magnitude: 0.10453
Value Function Update Magnitude: 0.08869

Collected Steps per Second: 25,143.38258
Overall Steps per Second: 13,323.20317

Timestep Collection Time: 1.98931
Timestep Consumption Time: 1.76489
PPO Batch Consumption Time: 0.35924
Total Iteration Time: 3.75420

Cumulative Model Updates: 1,549
Cumulative Timesteps: 25,912,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 25912202...
Checkpoint 25912202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01707
Policy Entropy: 4.37553
Value Function Loss: 0.05246

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.00433
Policy Update Magnitude: 0.10723
Value Function Update Magnitude: 0.08153

Collected Steps per Second: 15,226.30285
Overall Steps per Second: 9,844.93392

Timestep Collection Time: 3.28419
Timestep Consumption Time: 1.79518
PPO Batch Consumption Time: 0.36770
Total Iteration Time: 5.07936

Cumulative Model Updates: 1,552
Cumulative Timesteps: 25,962,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05586
Policy Entropy: 4.37862
Value Function Loss: 0.06847

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01346
Policy Update Magnitude: 0.10272
Value Function Update Magnitude: 0.07325

Collected Steps per Second: 15,626.60427
Overall Steps per Second: 9,753.44450

Timestep Collection Time: 3.20044
Timestep Consumption Time: 1.92719
PPO Batch Consumption Time: 0.36826
Total Iteration Time: 5.12762

Cumulative Model Updates: 1,555
Cumulative Timesteps: 26,012,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 26012220...
Checkpoint 26012220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02714
Policy Entropy: 4.39501
Value Function Loss: 0.07095

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.00543
Policy Update Magnitude: 0.10639
Value Function Update Magnitude: 0.08266

Collected Steps per Second: 20,984.08028
Overall Steps per Second: 12,083.35987

Timestep Collection Time: 2.38362
Timestep Consumption Time: 1.75580
PPO Batch Consumption Time: 0.36324
Total Iteration Time: 4.13941

Cumulative Model Updates: 1,558
Cumulative Timesteps: 26,062,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 26062238...
Checkpoint 26062238 saved!
