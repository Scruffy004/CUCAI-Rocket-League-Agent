Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.51122
Policy Entropy: 4.20587
Value Function Loss: 0.08657

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00555
Policy Update Magnitude: 0.21457
Value Function Update Magnitude: 0.18639

Collected Steps per Second: 19,961.99638
Overall Steps per Second: 12,858.98999

Timestep Collection Time: 2.50576
Timestep Consumption Time: 1.38412
PPO Batch Consumption Time: 0.34387
Total Iteration Time: 3.88989

Cumulative Model Updates: 164,450
Cumulative Timesteps: 1,371,347,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.62095
Policy Entropy: 4.05690
Value Function Loss: 0.11192

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05758
Policy Update Magnitude: 0.59322
Value Function Update Magnitude: 0.35270

Collected Steps per Second: 22,276.74558
Overall Steps per Second: 12,001.53708

Timestep Collection Time: 2.24503
Timestep Consumption Time: 1.92210
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.16713

Cumulative Model Updates: 164,454
Cumulative Timesteps: 1,371,397,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1371397736...
Checkpoint 1371397736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,404.01673
Policy Entropy: 3.95520
Value Function Loss: 0.10787

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10860
Policy Update Magnitude: 0.68892
Value Function Update Magnitude: 0.64784

Collected Steps per Second: 18,709.55039
Overall Steps per Second: 9,474.39350

Timestep Collection Time: 2.67393
Timestep Consumption Time: 2.60641
PPO Batch Consumption Time: 0.29923
Total Iteration Time: 5.28034

Cumulative Model Updates: 164,460
Cumulative Timesteps: 1,371,447,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,013.81476
Policy Entropy: 3.84337
Value Function Loss: 0.11902

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.62280
Value Function Update Magnitude: 0.66227

Collected Steps per Second: 19,923.70506
Overall Steps per Second: 9,949.90002

Timestep Collection Time: 2.51068
Timestep Consumption Time: 2.51671
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 5.02739

Cumulative Model Updates: 164,466
Cumulative Timesteps: 1,371,497,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1371497786...
Checkpoint 1371497786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,174.33629
Policy Entropy: 3.80972
Value Function Loss: 0.11846

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.75390
Value Function Update Magnitude: 0.63920

Collected Steps per Second: 20,372.31499
Overall Steps per Second: 10,150.03759

Timestep Collection Time: 2.45559
Timestep Consumption Time: 2.47306
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.92865

Cumulative Model Updates: 164,472
Cumulative Timesteps: 1,371,547,812

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.42846
Policy Entropy: 3.80882
Value Function Loss: 0.12827

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.12063
Policy Update Magnitude: 0.85931
Value Function Update Magnitude: 0.56041

Collected Steps per Second: 21,597.71355
Overall Steps per Second: 10,337.34671

Timestep Collection Time: 2.31608
Timestep Consumption Time: 2.52288
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.83896

Cumulative Model Updates: 164,478
Cumulative Timesteps: 1,371,597,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1371597834...
Checkpoint 1371597834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,761.56385
Policy Entropy: 3.73906
Value Function Loss: 0.14139

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.90783
Value Function Update Magnitude: 0.47412

Collected Steps per Second: 21,992.83213
Overall Steps per Second: 10,363.20071

Timestep Collection Time: 2.27465
Timestep Consumption Time: 2.55262
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.82727

Cumulative Model Updates: 164,484
Cumulative Timesteps: 1,371,647,860

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.27895
Policy Entropy: 3.72825
Value Function Loss: 0.14805

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.18408
Policy Update Magnitude: 0.90171
Value Function Update Magnitude: 0.43197

Collected Steps per Second: 19,945.64071
Overall Steps per Second: 9,858.35726

Timestep Collection Time: 2.50802
Timestep Consumption Time: 2.56626
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 5.07427

Cumulative Model Updates: 164,490
Cumulative Timesteps: 1,371,697,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1371697884...
Checkpoint 1371697884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,643.60953
Policy Entropy: 3.69875
Value Function Loss: 0.16372

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.18126
Policy Update Magnitude: 0.75017
Value Function Update Magnitude: 0.43653

Collected Steps per Second: 20,757.03687
Overall Steps per Second: 10,076.63828

Timestep Collection Time: 2.41017
Timestep Consumption Time: 2.55458
PPO Batch Consumption Time: 0.29916
Total Iteration Time: 4.96475

Cumulative Model Updates: 164,496
Cumulative Timesteps: 1,371,747,912

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,713.57115
Policy Entropy: 3.72975
Value Function Loss: 0.17540

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.14964
Policy Update Magnitude: 0.66531
Value Function Update Magnitude: 0.43847

Collected Steps per Second: 21,265.30703
Overall Steps per Second: 10,367.86470

Timestep Collection Time: 2.35125
Timestep Consumption Time: 2.47135
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.82259

Cumulative Model Updates: 164,502
Cumulative Timesteps: 1,371,797,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1371797912...
Checkpoint 1371797912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.39683
Policy Entropy: 3.73821
Value Function Loss: 0.17880

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.14518
Policy Update Magnitude: 0.65339
Value Function Update Magnitude: 0.44024

Collected Steps per Second: 21,347.02083
Overall Steps per Second: 10,146.91463

Timestep Collection Time: 2.34328
Timestep Consumption Time: 2.58650
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.92977

Cumulative Model Updates: 164,508
Cumulative Timesteps: 1,371,847,934

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,681.48914
Policy Entropy: 3.74645
Value Function Loss: 0.18928

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.63216
Value Function Update Magnitude: 0.44941

Collected Steps per Second: 20,893.89243
Overall Steps per Second: 10,088.94097

Timestep Collection Time: 2.39343
Timestep Consumption Time: 2.56329
PPO Batch Consumption Time: 0.30471
Total Iteration Time: 4.95671

Cumulative Model Updates: 164,514
Cumulative Timesteps: 1,371,897,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1371897942...
Checkpoint 1371897942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,645.28456
Policy Entropy: 3.72491
Value Function Loss: 0.18345

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.61585
Value Function Update Magnitude: 0.48819

Collected Steps per Second: 19,744.60523
Overall Steps per Second: 9,764.98584

Timestep Collection Time: 2.53365
Timestep Consumption Time: 2.58934
PPO Batch Consumption Time: 0.30213
Total Iteration Time: 5.12300

Cumulative Model Updates: 164,520
Cumulative Timesteps: 1,371,947,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.23129
Policy Entropy: 3.67557
Value Function Loss: 0.16845

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.55603
Value Function Update Magnitude: 0.50873

Collected Steps per Second: 20,880.65618
Overall Steps per Second: 9,845.61881

Timestep Collection Time: 2.39600
Timestep Consumption Time: 2.68545
PPO Batch Consumption Time: 0.31228
Total Iteration Time: 5.08145

Cumulative Model Updates: 164,526
Cumulative Timesteps: 1,371,997,998

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1371997998...
Checkpoint 1371997998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 898.32943
Policy Entropy: 3.64673
Value Function Loss: 0.14976

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.15278
Policy Update Magnitude: 0.52492
Value Function Update Magnitude: 0.42517

Collected Steps per Second: 21,119.56402
Overall Steps per Second: 10,182.93934

Timestep Collection Time: 2.36870
Timestep Consumption Time: 2.54402
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.91273

Cumulative Model Updates: 164,532
Cumulative Timesteps: 1,372,048,024

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,556.92725
Policy Entropy: 3.58927
Value Function Loss: 0.14473

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.16898
Policy Update Magnitude: 0.47088
Value Function Update Magnitude: 0.36208

Collected Steps per Second: 20,135.99324
Overall Steps per Second: 9,908.58257

Timestep Collection Time: 2.48371
Timestep Consumption Time: 2.56363
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 5.04734

Cumulative Model Updates: 164,538
Cumulative Timesteps: 1,372,098,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1372098036...
Checkpoint 1372098036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,992.51135
Policy Entropy: 3.58728
Value Function Loss: 0.13911

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.15756
Policy Update Magnitude: 0.51315
Value Function Update Magnitude: 0.46057

Collected Steps per Second: 21,564.01252
Overall Steps per Second: 10,466.89696

Timestep Collection Time: 2.31979
Timestep Consumption Time: 2.45947
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.77926

Cumulative Model Updates: 164,544
Cumulative Timesteps: 1,372,148,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,177.85481
Policy Entropy: 3.57356
Value Function Loss: 0.15581

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.15689
Policy Update Magnitude: 0.57518
Value Function Update Magnitude: 0.58336

Collected Steps per Second: 21,926.38325
Overall Steps per Second: 10,397.76569

Timestep Collection Time: 2.28072
Timestep Consumption Time: 2.52877
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.80949

Cumulative Model Updates: 164,550
Cumulative Timesteps: 1,372,198,068

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1372198068...
Checkpoint 1372198068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,583.43896
Policy Entropy: 3.57396
Value Function Loss: 0.17638

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.16056
Policy Update Magnitude: 0.62283
Value Function Update Magnitude: 0.61153

Collected Steps per Second: 21,110.30334
Overall Steps per Second: 10,131.84487

Timestep Collection Time: 2.36880
Timestep Consumption Time: 2.56673
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.93553

Cumulative Model Updates: 164,556
Cumulative Timesteps: 1,372,248,074

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,398.27980
Policy Entropy: 3.57044
Value Function Loss: 0.18067

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.15570
Policy Update Magnitude: 0.68634
Value Function Update Magnitude: 0.47829

Collected Steps per Second: 21,852.02607
Overall Steps per Second: 10,441.37616

Timestep Collection Time: 2.28830
Timestep Consumption Time: 2.50072
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.78902

Cumulative Model Updates: 164,562
Cumulative Timesteps: 1,372,298,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1372298078...
Checkpoint 1372298078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,576.07690
Policy Entropy: 3.57273
Value Function Loss: 0.18614

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.72282
Value Function Update Magnitude: 0.39678

Collected Steps per Second: 21,424.97497
Overall Steps per Second: 10,330.12864

Timestep Collection Time: 2.33503
Timestep Consumption Time: 2.50789
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.84292

Cumulative Model Updates: 164,568
Cumulative Timesteps: 1,372,348,106

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,403.33526
Policy Entropy: 3.59632
Value Function Loss: 0.17534

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.16846
Policy Update Magnitude: 0.87823
Value Function Update Magnitude: 0.37084

Collected Steps per Second: 21,716.21456
Overall Steps per Second: 10,529.95248

Timestep Collection Time: 2.30427
Timestep Consumption Time: 2.44789
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.75216

Cumulative Model Updates: 164,574
Cumulative Timesteps: 1,372,398,146

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1372398146...
Checkpoint 1372398146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,075.80432
Policy Entropy: 3.57967
Value Function Loss: 0.14897

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.16250
Policy Update Magnitude: 0.71181
Value Function Update Magnitude: 0.34094

Collected Steps per Second: 21,671.33966
Overall Steps per Second: 10,604.92328

Timestep Collection Time: 2.30719
Timestep Consumption Time: 2.40760
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.71479

Cumulative Model Updates: 164,580
Cumulative Timesteps: 1,372,448,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,075.80432
Policy Entropy: 3.57755
Value Function Loss: 0.12274

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.19717
Policy Update Magnitude: 0.69175
Value Function Update Magnitude: 0.42320

Collected Steps per Second: 22,156.50472
Overall Steps per Second: 10,429.11201

Timestep Collection Time: 2.25676
Timestep Consumption Time: 2.53770
PPO Batch Consumption Time: 0.29928
Total Iteration Time: 4.79446

Cumulative Model Updates: 164,586
Cumulative Timesteps: 1,372,498,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1372498148...
Checkpoint 1372498148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,849.20710
Policy Entropy: 3.57698
Value Function Loss: 0.11926

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.22947
Policy Update Magnitude: 0.58130
Value Function Update Magnitude: 0.45503

Collected Steps per Second: 20,330.48437
Overall Steps per Second: 10,255.76890

Timestep Collection Time: 2.46044
Timestep Consumption Time: 2.41701
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.87745

Cumulative Model Updates: 164,592
Cumulative Timesteps: 1,372,548,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,447.84287
Policy Entropy: 3.53726
Value Function Loss: 0.12744

Mean KL Divergence: 0.03459
SB3 Clip Fraction: 0.30354
Policy Update Magnitude: 0.49262
Value Function Update Magnitude: 0.51971

Collected Steps per Second: 21,114.55992
Overall Steps per Second: 10,361.57461

Timestep Collection Time: 2.36803
Timestep Consumption Time: 2.45749
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.82552

Cumulative Model Updates: 164,598
Cumulative Timesteps: 1,372,598,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1372598170...
Checkpoint 1372598170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,817.51603
Policy Entropy: 3.55097
Value Function Loss: 0.14531

Mean KL Divergence: 0.05006
SB3 Clip Fraction: 0.37503
Policy Update Magnitude: 0.44597
Value Function Update Magnitude: 0.67309

Collected Steps per Second: 21,789.93194
Overall Steps per Second: 10,361.69764

Timestep Collection Time: 2.29611
Timestep Consumption Time: 2.53245
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.82855

Cumulative Model Updates: 164,604
Cumulative Timesteps: 1,372,648,202

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,525.05651
Policy Entropy: 3.52356
Value Function Loss: 0.17505

Mean KL Divergence: 0.03668
SB3 Clip Fraction: 0.31935
Policy Update Magnitude: 0.41351
Value Function Update Magnitude: 0.76574

Collected Steps per Second: 22,671.70232
Overall Steps per Second: 10,692.03833

Timestep Collection Time: 2.20539
Timestep Consumption Time: 2.47098
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.67638

Cumulative Model Updates: 164,610
Cumulative Timesteps: 1,372,698,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1372698202...
Checkpoint 1372698202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,016.35434
Policy Entropy: 3.57951
Value Function Loss: 0.18554

Mean KL Divergence: 0.04255
SB3 Clip Fraction: 0.32844
Policy Update Magnitude: 0.46887
Value Function Update Magnitude: 0.62772

Collected Steps per Second: 22,380.77620
Overall Steps per Second: 10,708.82585

Timestep Collection Time: 2.23629
Timestep Consumption Time: 2.43742
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.67371

Cumulative Model Updates: 164,616
Cumulative Timesteps: 1,372,748,252

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,265.75424
Policy Entropy: 3.56296
Value Function Loss: 0.20033

Mean KL Divergence: 0.02855
SB3 Clip Fraction: 0.27810
Policy Update Magnitude: 0.48502
Value Function Update Magnitude: 0.52810

Collected Steps per Second: 22,936.72254
Overall Steps per Second: 10,654.36079

Timestep Collection Time: 2.17991
Timestep Consumption Time: 2.51300
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.69291

Cumulative Model Updates: 164,622
Cumulative Timesteps: 1,372,798,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1372798252...
Checkpoint 1372798252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,300.58015
Policy Entropy: 3.57016
Value Function Loss: 0.20602

Mean KL Divergence: 0.02459
SB3 Clip Fraction: 0.25648
Policy Update Magnitude: 0.44303
Value Function Update Magnitude: 0.48761

Collected Steps per Second: 22,048.16191
Overall Steps per Second: 10,435.32076

Timestep Collection Time: 2.26831
Timestep Consumption Time: 2.52426
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.79257

Cumulative Model Updates: 164,628
Cumulative Timesteps: 1,372,848,264

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,021.23783
Policy Entropy: 3.53229
Value Function Loss: 0.22576

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.22547
Policy Update Magnitude: 0.45109
Value Function Update Magnitude: 0.46011

Collected Steps per Second: 22,711.36898
Overall Steps per Second: 10,598.88735

Timestep Collection Time: 2.20260
Timestep Consumption Time: 2.51714
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.71974

Cumulative Model Updates: 164,634
Cumulative Timesteps: 1,372,898,288

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1372898288...
Checkpoint 1372898288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,021.23783
Policy Entropy: 3.48550
Value Function Loss: 0.22474

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.22092
Policy Update Magnitude: 0.48006
Value Function Update Magnitude: 0.47629

Collected Steps per Second: 22,542.16841
Overall Steps per Second: 10,561.75278

Timestep Collection Time: 2.21833
Timestep Consumption Time: 2.51630
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.73463

Cumulative Model Updates: 164,640
Cumulative Timesteps: 1,372,948,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,021.23783
Policy Entropy: 3.46115
Value Function Loss: 0.21481

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.22165
Policy Update Magnitude: 0.51258
Value Function Update Magnitude: 0.45402

Collected Steps per Second: 23,081.38631
Overall Steps per Second: 10,810.88748

Timestep Collection Time: 2.16625
Timestep Consumption Time: 2.45872
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.62497

Cumulative Model Updates: 164,646
Cumulative Timesteps: 1,372,998,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1372998294...
Checkpoint 1372998294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,762.02769
Policy Entropy: 3.46493
Value Function Loss: 0.20861

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.21930
Policy Update Magnitude: 0.53603
Value Function Update Magnitude: 0.43712

Collected Steps per Second: 22,568.54202
Overall Steps per Second: 10,756.36847

Timestep Collection Time: 2.21547
Timestep Consumption Time: 2.43294
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.64841

Cumulative Model Updates: 164,652
Cumulative Timesteps: 1,373,048,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,762.02769
Policy Entropy: 3.45937
Value Function Loss: 0.21403

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.20813
Policy Update Magnitude: 0.50089
Value Function Update Magnitude: 0.47387

Collected Steps per Second: 22,190.35327
Overall Steps per Second: 10,793.03844

Timestep Collection Time: 2.25395
Timestep Consumption Time: 2.38015
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.63410

Cumulative Model Updates: 164,658
Cumulative Timesteps: 1,373,098,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1373098310...
Checkpoint 1373098310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,357.78468
Policy Entropy: 3.46758
Value Function Loss: 0.20813

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.21300
Policy Update Magnitude: 0.48355
Value Function Update Magnitude: 0.42737

Collected Steps per Second: 21,692.90358
Overall Steps per Second: 10,702.79841

Timestep Collection Time: 2.30545
Timestep Consumption Time: 2.36734
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.67280

Cumulative Model Updates: 164,664
Cumulative Timesteps: 1,373,148,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,672.63714
Policy Entropy: 3.47863
Value Function Loss: 0.20864

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.20601
Policy Update Magnitude: 0.49092
Value Function Update Magnitude: 0.38568

Collected Steps per Second: 21,545.66934
Overall Steps per Second: 10,461.99881

Timestep Collection Time: 2.32112
Timestep Consumption Time: 2.45904
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.78016

Cumulative Model Updates: 164,670
Cumulative Timesteps: 1,373,198,332

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1373198332...
Checkpoint 1373198332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,807.39981
Policy Entropy: 3.49994
Value Function Loss: 0.20508

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.22142
Policy Update Magnitude: 0.50004
Value Function Update Magnitude: 0.40222

Collected Steps per Second: 21,800.50822
Overall Steps per Second: 10,608.38833

Timestep Collection Time: 2.29417
Timestep Consumption Time: 2.42040
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.71457

Cumulative Model Updates: 164,676
Cumulative Timesteps: 1,373,248,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,021.26584
Policy Entropy: 3.52043
Value Function Loss: 0.20336

Mean KL Divergence: 0.02177
SB3 Clip Fraction: 0.21403
Policy Update Magnitude: 0.51350
Value Function Update Magnitude: 0.40891

Collected Steps per Second: 22,955.73570
Overall Steps per Second: 10,682.36951

Timestep Collection Time: 2.17889
Timestep Consumption Time: 2.50341
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.68229

Cumulative Model Updates: 164,682
Cumulative Timesteps: 1,373,298,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1373298364...
Checkpoint 1373298364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,092.11102
Policy Entropy: 3.51187
Value Function Loss: 0.19254

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.21537
Policy Update Magnitude: 0.49535
Value Function Update Magnitude: 0.39672

Collected Steps per Second: 22,591.79889
Overall Steps per Second: 10,687.25818

Timestep Collection Time: 2.21381
Timestep Consumption Time: 2.46597
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.67978

Cumulative Model Updates: 164,688
Cumulative Timesteps: 1,373,348,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,152.44554
Policy Entropy: 3.51224
Value Function Loss: 0.19726

Mean KL Divergence: 0.02208
SB3 Clip Fraction: 0.21630
Policy Update Magnitude: 0.49218
Value Function Update Magnitude: 0.37681

Collected Steps per Second: 22,964.88390
Overall Steps per Second: 10,717.17889

Timestep Collection Time: 2.17741
Timestep Consumption Time: 2.48837
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.66578

Cumulative Model Updates: 164,694
Cumulative Timesteps: 1,373,398,382

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1373398382...
Checkpoint 1373398382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,519.45596
Policy Entropy: 3.51326
Value Function Loss: 0.19778

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.20791
Policy Update Magnitude: 0.48224
Value Function Update Magnitude: 0.37565

Collected Steps per Second: 22,340.69633
Overall Steps per Second: 10,687.47650

Timestep Collection Time: 2.23843
Timestep Consumption Time: 2.44070
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.67912

Cumulative Model Updates: 164,700
Cumulative Timesteps: 1,373,448,390

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,661.06987
Policy Entropy: 3.53478
Value Function Loss: 0.20733

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.20242
Policy Update Magnitude: 0.46865
Value Function Update Magnitude: 0.39165

Collected Steps per Second: 22,714.29361
Overall Steps per Second: 10,726.37298

Timestep Collection Time: 2.20231
Timestep Consumption Time: 2.46133
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.66365

Cumulative Model Updates: 164,706
Cumulative Timesteps: 1,373,498,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1373498414...
Checkpoint 1373498414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,728.40787
Policy Entropy: 3.54177
Value Function Loss: 0.19732

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.19897
Policy Update Magnitude: 0.46901
Value Function Update Magnitude: 0.38741

Collected Steps per Second: 22,397.63480
Overall Steps per Second: 10,706.49583

Timestep Collection Time: 2.23372
Timestep Consumption Time: 2.43915
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.67286

Cumulative Model Updates: 164,712
Cumulative Timesteps: 1,373,548,444

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,630.89052
Policy Entropy: 3.53169
Value Function Loss: 0.19528

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.19847
Policy Update Magnitude: 0.48976
Value Function Update Magnitude: 0.38035

Collected Steps per Second: 23,183.35680
Overall Steps per Second: 10,881.81432

Timestep Collection Time: 2.15810
Timestep Consumption Time: 2.43966
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.59776

Cumulative Model Updates: 164,718
Cumulative Timesteps: 1,373,598,476

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1373598476...
Checkpoint 1373598476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,132.86478
Policy Entropy: 3.50696
Value Function Loss: 0.18395

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.20340
Policy Update Magnitude: 0.49005
Value Function Update Magnitude: 0.34946

Collected Steps per Second: 22,827.11642
Overall Steps per Second: 10,757.81733

Timestep Collection Time: 2.19152
Timestep Consumption Time: 2.45868
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.65020

Cumulative Model Updates: 164,724
Cumulative Timesteps: 1,373,648,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,909.60783
Policy Entropy: 3.49936
Value Function Loss: 0.18213

Mean KL Divergence: 0.02189
SB3 Clip Fraction: 0.21522
Policy Update Magnitude: 0.52596
Value Function Update Magnitude: 0.32240

Collected Steps per Second: 23,283.50252
Overall Steps per Second: 10,886.28295

Timestep Collection Time: 2.14882
Timestep Consumption Time: 2.44706
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.59588

Cumulative Model Updates: 164,730
Cumulative Timesteps: 1,373,698,534

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1373698534...
Checkpoint 1373698534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,909.60783
Policy Entropy: 3.50547
Value Function Loss: 0.18613

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.21772
Policy Update Magnitude: 0.51526
Value Function Update Magnitude: 0.33907

Collected Steps per Second: 22,602.50018
Overall Steps per Second: 10,674.02333

Timestep Collection Time: 2.21312
Timestep Consumption Time: 2.47321
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.68633

Cumulative Model Updates: 164,736
Cumulative Timesteps: 1,373,748,556

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,699.44124
Policy Entropy: 3.51225
Value Function Loss: 0.18701

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.23315
Policy Update Magnitude: 0.47253
Value Function Update Magnitude: 0.36007

Collected Steps per Second: 22,749.26634
Overall Steps per Second: 10,882.66742

Timestep Collection Time: 2.19919
Timestep Consumption Time: 2.39803
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.59722

Cumulative Model Updates: 164,742
Cumulative Timesteps: 1,373,798,586

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1373798586...
Checkpoint 1373798586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,363.39566
Policy Entropy: 3.51261
Value Function Loss: 0.17777

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.22425
Policy Update Magnitude: 0.42137
Value Function Update Magnitude: 0.34568

Collected Steps per Second: 21,741.12785
Overall Steps per Second: 10,677.69783

Timestep Collection Time: 2.30080
Timestep Consumption Time: 2.38392
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.68472

Cumulative Model Updates: 164,748
Cumulative Timesteps: 1,373,848,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,670.32221
Policy Entropy: 3.50368
Value Function Loss: 0.18126

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.19929
Policy Update Magnitude: 0.40587
Value Function Update Magnitude: 0.35249

Collected Steps per Second: 22,539.32120
Overall Steps per Second: 10,942.13640

Timestep Collection Time: 2.22039
Timestep Consumption Time: 2.35331
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.57370

Cumulative Model Updates: 164,754
Cumulative Timesteps: 1,373,898,654

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1373898654...
Checkpoint 1373898654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,670.72521
Policy Entropy: 3.50712
Value Function Loss: 0.17226

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.18992
Policy Update Magnitude: 0.43815
Value Function Update Magnitude: 0.38778

Collected Steps per Second: 21,650.80365
Overall Steps per Second: 10,562.26848

Timestep Collection Time: 2.31012
Timestep Consumption Time: 2.42522
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.73535

Cumulative Model Updates: 164,760
Cumulative Timesteps: 1,373,948,670

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,205.10672
Policy Entropy: 3.51117
Value Function Loss: 0.17832

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.17841
Policy Update Magnitude: 0.47947
Value Function Update Magnitude: 0.41836

Collected Steps per Second: 22,963.08635
Overall Steps per Second: 10,884.89355

Timestep Collection Time: 2.17871
Timestep Consumption Time: 2.41756
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.59628

Cumulative Model Updates: 164,766
Cumulative Timesteps: 1,373,998,700

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1373998700...
Checkpoint 1373998700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,626.06918
Policy Entropy: 3.52331
Value Function Loss: 0.16900

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.18338
Policy Update Magnitude: 0.50758
Value Function Update Magnitude: 0.42920

Collected Steps per Second: 22,544.55620
Overall Steps per Second: 10,702.90758

Timestep Collection Time: 2.21845
Timestep Consumption Time: 2.45448
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.67294

Cumulative Model Updates: 164,772
Cumulative Timesteps: 1,374,048,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,588.61112
Policy Entropy: 3.53700
Value Function Loss: 0.15775

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.19711
Policy Update Magnitude: 0.54021
Value Function Update Magnitude: 0.40858

Collected Steps per Second: 23,095.84601
Overall Steps per Second: 10,860.99760

Timestep Collection Time: 2.16628
Timestep Consumption Time: 2.44030
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.60658

Cumulative Model Updates: 164,778
Cumulative Timesteps: 1,374,098,746

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1374098746...
Checkpoint 1374098746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,168.43979
Policy Entropy: 3.53824
Value Function Loss: 0.15442

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.20233
Policy Update Magnitude: 0.54519
Value Function Update Magnitude: 0.41410

Collected Steps per Second: 22,558.35409
Overall Steps per Second: 10,762.70097

Timestep Collection Time: 2.21683
Timestep Consumption Time: 2.42959
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.64642

Cumulative Model Updates: 164,784
Cumulative Timesteps: 1,374,148,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,686.07414
Policy Entropy: 3.52799
Value Function Loss: 0.15472

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.20921
Policy Update Magnitude: 0.50801
Value Function Update Magnitude: 0.40736

Collected Steps per Second: 22,894.00308
Overall Steps per Second: 10,813.10544

Timestep Collection Time: 2.18407
Timestep Consumption Time: 2.44014
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.62420

Cumulative Model Updates: 164,790
Cumulative Timesteps: 1,374,198,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1374198756...
Checkpoint 1374198756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,252.83405
Policy Entropy: 3.51805
Value Function Loss: 0.15416

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.20828
Policy Update Magnitude: 0.49744
Value Function Update Magnitude: 0.40640

Collected Steps per Second: 22,596.74409
Overall Steps per Second: 10,672.63668

Timestep Collection Time: 2.21315
Timestep Consumption Time: 2.47266
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.68581

Cumulative Model Updates: 164,796
Cumulative Timesteps: 1,374,248,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,313.14902
Policy Entropy: 3.52317
Value Function Loss: 0.15475

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.19772
Policy Update Magnitude: 0.46168
Value Function Update Magnitude: 0.38648

Collected Steps per Second: 23,210.03130
Overall Steps per Second: 10,882.22785

Timestep Collection Time: 2.15553
Timestep Consumption Time: 2.44187
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.59740

Cumulative Model Updates: 164,802
Cumulative Timesteps: 1,374,298,796

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1374298796...
Checkpoint 1374298796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,068.93396
Policy Entropy: 3.53748
Value Function Loss: 0.15466

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.19639
Policy Update Magnitude: 0.47957
Value Function Update Magnitude: 0.38857

Collected Steps per Second: 22,626.21751
Overall Steps per Second: 10,703.86231

Timestep Collection Time: 2.21027
Timestep Consumption Time: 2.46188
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.67215

Cumulative Model Updates: 164,808
Cumulative Timesteps: 1,374,348,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,894.15436
Policy Entropy: 3.55630
Value Function Loss: 0.15306

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.18588
Policy Update Magnitude: 0.51420
Value Function Update Magnitude: 0.40419

Collected Steps per Second: 22,496.14630
Overall Steps per Second: 10,864.85601

Timestep Collection Time: 2.22260
Timestep Consumption Time: 2.37939
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.60199

Cumulative Model Updates: 164,814
Cumulative Timesteps: 1,374,398,806

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1374398806...
Checkpoint 1374398806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,576.21623
Policy Entropy: 3.56676
Value Function Loss: 0.15480

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.18273
Policy Update Magnitude: 0.57311
Value Function Update Magnitude: 0.45230

Collected Steps per Second: 21,986.08225
Overall Steps per Second: 10,680.03139

Timestep Collection Time: 2.27517
Timestep Consumption Time: 2.40853
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.68369

Cumulative Model Updates: 164,820
Cumulative Timesteps: 1,374,448,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,139.07201
Policy Entropy: 3.58951
Value Function Loss: 0.15526

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.18744
Policy Update Magnitude: 0.56412
Value Function Update Magnitude: 0.45354

Collected Steps per Second: 22,375.86087
Overall Steps per Second: 10,881.56562

Timestep Collection Time: 2.23553
Timestep Consumption Time: 2.36141
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.59695

Cumulative Model Updates: 164,826
Cumulative Timesteps: 1,374,498,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1374498850...
Checkpoint 1374498850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,164.62712
Policy Entropy: 3.61361
Value Function Loss: 0.14733

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.19084
Policy Update Magnitude: 0.61425
Value Function Update Magnitude: 0.41382

Collected Steps per Second: 21,961.69347
Overall Steps per Second: 10,672.96263

Timestep Collection Time: 2.27715
Timestep Consumption Time: 2.40852
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.68567

Cumulative Model Updates: 164,832
Cumulative Timesteps: 1,374,548,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,164.62712
Policy Entropy: 3.62860
Value Function Loss: 0.13457

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.17605
Policy Update Magnitude: 0.60828
Value Function Update Magnitude: 0.36906

Collected Steps per Second: 22,260.16686
Overall Steps per Second: 10,591.33351

Timestep Collection Time: 2.24760
Timestep Consumption Time: 2.47626
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.72386

Cumulative Model Updates: 164,838
Cumulative Timesteps: 1,374,598,892

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1374598892...
Checkpoint 1374598892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,069.92942
Policy Entropy: 3.60009
Value Function Loss: 0.14501

Mean KL Divergence: 0.03143
SB3 Clip Fraction: 0.28695
Policy Update Magnitude: 0.48505
Value Function Update Magnitude: 0.32199

Collected Steps per Second: 22,574.57377
Overall Steps per Second: 10,707.37659

Timestep Collection Time: 2.21568
Timestep Consumption Time: 2.45568
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.67136

Cumulative Model Updates: 164,844
Cumulative Timesteps: 1,374,648,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,503.36375
Policy Entropy: 3.58907
Value Function Loss: 0.14031

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.20355
Policy Update Magnitude: 0.46711
Value Function Update Magnitude: 0.27424

Collected Steps per Second: 23,405.77968
Overall Steps per Second: 10,849.23163

Timestep Collection Time: 2.13622
Timestep Consumption Time: 2.47240
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.60862

Cumulative Model Updates: 164,850
Cumulative Timesteps: 1,374,698,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1374698910...
Checkpoint 1374698910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,503.36375
Policy Entropy: 3.60288
Value Function Loss: 0.19826

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.21462
Policy Update Magnitude: 0.55994
Value Function Update Magnitude: 0.22849

Collected Steps per Second: 22,857.16375
Overall Steps per Second: 10,683.43460

Timestep Collection Time: 2.18837
Timestep Consumption Time: 2.49364
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.68201

Cumulative Model Updates: 164,856
Cumulative Timesteps: 1,374,748,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,803.70888
Policy Entropy: 3.61327
Value Function Loss: 0.15749

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.18573
Policy Update Magnitude: 0.59827
Value Function Update Magnitude: 0.23774

Collected Steps per Second: 23,068.05394
Overall Steps per Second: 10,719.98731

Timestep Collection Time: 2.16863
Timestep Consumption Time: 2.49798
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.66661

Cumulative Model Updates: 164,862
Cumulative Timesteps: 1,374,798,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1374798956...
Checkpoint 1374798956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,803.70888
Policy Entropy: 3.61855
Value Function Loss: 0.13069

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.23922
Policy Update Magnitude: 0.74719
Value Function Update Magnitude: 0.35071

Collected Steps per Second: 22,883.59142
Overall Steps per Second: 10,470.22788

Timestep Collection Time: 2.18620
Timestep Consumption Time: 2.59192
PPO Batch Consumption Time: 0.30781
Total Iteration Time: 4.77812

Cumulative Model Updates: 164,868
Cumulative Timesteps: 1,374,848,984

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,803.70888
Policy Entropy: 3.61645
Value Function Loss: 0.13006

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.17448
Policy Update Magnitude: 0.64880
Value Function Update Magnitude: 0.42470

Collected Steps per Second: 22,755.80487
Overall Steps per Second: 10,627.17458

Timestep Collection Time: 2.19768
Timestep Consumption Time: 2.50818
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.70586

Cumulative Model Updates: 164,874
Cumulative Timesteps: 1,374,898,994

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1374898994...
Checkpoint 1374898994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,347.80464
Policy Entropy: 3.62048
Value Function Loss: 0.12368

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.15895
Policy Update Magnitude: 0.88205
Value Function Update Magnitude: 0.43391

Collected Steps per Second: 21,991.23630
Overall Steps per Second: 10,618.67627

Timestep Collection Time: 2.27509
Timestep Consumption Time: 2.43661
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.71170

Cumulative Model Updates: 164,880
Cumulative Timesteps: 1,374,949,026

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,347.80464
Policy Entropy: 3.63111
Value Function Loss: 0.11509

Mean KL Divergence: 0.03205
SB3 Clip Fraction: 0.28951
Policy Update Magnitude: 0.73306
Value Function Update Magnitude: 0.51820

Collected Steps per Second: 22,829.55173
Overall Steps per Second: 10,645.11916

Timestep Collection Time: 2.19093
Timestep Consumption Time: 2.50775
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.69868

Cumulative Model Updates: 164,886
Cumulative Timesteps: 1,374,999,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1374999044...
Checkpoint 1374999044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,347.80464
Policy Entropy: 3.64690
Value Function Loss: 0.11313

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.24952
Policy Update Magnitude: 0.56547
Value Function Update Magnitude: 0.53287

Collected Steps per Second: 22,387.57940
Overall Steps per Second: 10,524.67925

Timestep Collection Time: 2.23427
Timestep Consumption Time: 2.51836
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.75264

Cumulative Model Updates: 164,892
Cumulative Timesteps: 1,375,049,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168,878.76734
Policy Entropy: 3.61628
Value Function Loss: 0.12120

Mean KL Divergence: 0.03470
SB3 Clip Fraction: 0.32178
Policy Update Magnitude: 0.48610
Value Function Update Magnitude: 0.45793

Collected Steps per Second: 22,408.16622
Overall Steps per Second: 10,845.81982

Timestep Collection Time: 2.23285
Timestep Consumption Time: 2.38036
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.61321

Cumulative Model Updates: 164,898
Cumulative Timesteps: 1,375,099,098

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1375099098...
Checkpoint 1375099098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,518.46637
Policy Entropy: 3.61174
Value Function Loss: 0.13441

Mean KL Divergence: 0.03361
SB3 Clip Fraction: 0.30397
Policy Update Magnitude: 0.39485
Value Function Update Magnitude: 0.47103

Collected Steps per Second: 22,000.70772
Overall Steps per Second: 10,685.25786

Timestep Collection Time: 2.27320
Timestep Consumption Time: 2.40727
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.68047

Cumulative Model Updates: 164,904
Cumulative Timesteps: 1,375,149,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,226.23071
Policy Entropy: 3.57883
Value Function Loss: 0.15246

Mean KL Divergence: 0.02661
SB3 Clip Fraction: 0.24333
Policy Update Magnitude: 0.39277
Value Function Update Magnitude: 0.45479

Collected Steps per Second: 22,473.11363
Overall Steps per Second: 10,855.75742

Timestep Collection Time: 2.22568
Timestep Consumption Time: 2.38183
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.60751

Cumulative Model Updates: 164,910
Cumulative Timesteps: 1,375,199,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1375199128...
Checkpoint 1375199128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,237.95691
Policy Entropy: 3.59184
Value Function Loss: 0.14828

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.20616
Policy Update Magnitude: 0.48341
Value Function Update Magnitude: 0.46119

Collected Steps per Second: 21,926.33847
Overall Steps per Second: 10,666.13399

Timestep Collection Time: 2.28036
Timestep Consumption Time: 2.40737
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.68773

Cumulative Model Updates: 164,916
Cumulative Timesteps: 1,375,249,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,542.21337
Policy Entropy: 3.62423
Value Function Loss: 0.14991

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.17857
Policy Update Magnitude: 0.57379
Value Function Update Magnitude: 0.50179

Collected Steps per Second: 22,437.47935
Overall Steps per Second: 10,874.40089

Timestep Collection Time: 2.22913
Timestep Consumption Time: 2.37030
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.59943

Cumulative Model Updates: 164,922
Cumulative Timesteps: 1,375,299,144

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1375299144...
Checkpoint 1375299144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,718.35466
Policy Entropy: 3.66142
Value Function Loss: 0.14296

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.17347
Policy Update Magnitude: 0.63102
Value Function Update Magnitude: 0.51120

Collected Steps per Second: 21,673.42638
Overall Steps per Second: 10,717.28114

Timestep Collection Time: 2.30725
Timestep Consumption Time: 2.35867
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.66592

Cumulative Model Updates: 164,928
Cumulative Timesteps: 1,375,349,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.51910
Policy Entropy: 3.64784
Value Function Loss: 0.14944

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.16941
Policy Update Magnitude: 0.64867
Value Function Update Magnitude: 0.54300

Collected Steps per Second: 22,328.64876
Overall Steps per Second: 10,840.42020

Timestep Collection Time: 2.23981
Timestep Consumption Time: 2.37366
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.61347

Cumulative Model Updates: 164,934
Cumulative Timesteps: 1,375,399,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1375399162...
Checkpoint 1375399162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,449.27466
Policy Entropy: 3.65362
Value Function Loss: 0.14398

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.17297
Policy Update Magnitude: 0.64708
Value Function Update Magnitude: 0.50553

Collected Steps per Second: 21,578.91155
Overall Steps per Second: 10,691.45434

Timestep Collection Time: 2.31717
Timestep Consumption Time: 2.35965
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.67682

Cumulative Model Updates: 164,940
Cumulative Timesteps: 1,375,449,164

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,927.65551
Policy Entropy: 3.62710
Value Function Loss: 0.14718

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.18181
Policy Update Magnitude: 0.68328
Value Function Update Magnitude: 0.51479

Collected Steps per Second: 22,087.88926
Overall Steps per Second: 10,817.56054

Timestep Collection Time: 2.26477
Timestep Consumption Time: 2.35956
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.62433

Cumulative Model Updates: 164,946
Cumulative Timesteps: 1,375,499,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1375499188...
Checkpoint 1375499188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,750.13890
Policy Entropy: 3.62468
Value Function Loss: 0.15030

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.17965
Policy Update Magnitude: 0.67826
Value Function Update Magnitude: 0.50909

Collected Steps per Second: 21,231.17022
Overall Steps per Second: 10,327.44491

Timestep Collection Time: 2.35635
Timestep Consumption Time: 2.48783
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.84418

Cumulative Model Updates: 164,952
Cumulative Timesteps: 1,375,549,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,144.26224
Policy Entropy: 3.59537
Value Function Loss: 0.13836

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.18596
Policy Update Magnitude: 0.66759
Value Function Update Magnitude: 0.48995

Collected Steps per Second: 22,984.01500
Overall Steps per Second: 10,860.42225

Timestep Collection Time: 2.17612
Timestep Consumption Time: 2.42922
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.60535

Cumulative Model Updates: 164,958
Cumulative Timesteps: 1,375,599,232

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1375599232...
Checkpoint 1375599232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,673.88011
Policy Entropy: 3.58444
Value Function Loss: 0.12423

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.17288
Policy Update Magnitude: 0.67739
Value Function Update Magnitude: 0.72361

Collected Steps per Second: 22,432.87000
Overall Steps per Second: 10,658.36826

Timestep Collection Time: 2.23003
Timestep Consumption Time: 2.46356
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.69359

Cumulative Model Updates: 164,964
Cumulative Timesteps: 1,375,649,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,538.62978
Policy Entropy: 3.60267
Value Function Loss: 0.11921

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.17003
Policy Update Magnitude: 0.73427
Value Function Update Magnitude: 0.86488

Collected Steps per Second: 22,702.71301
Overall Steps per Second: 10,817.19260

Timestep Collection Time: 2.20335
Timestep Consumption Time: 2.42096
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.62431

Cumulative Model Updates: 164,970
Cumulative Timesteps: 1,375,699,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1375699280...
Checkpoint 1375699280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,684.97049
Policy Entropy: 3.63304
Value Function Loss: 0.12037

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.17302
Policy Update Magnitude: 0.83822
Value Function Update Magnitude: 0.75124

Collected Steps per Second: 22,188.68355
Overall Steps per Second: 10,469.57067

Timestep Collection Time: 2.25484
Timestep Consumption Time: 2.52396
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.77880

Cumulative Model Updates: 164,976
Cumulative Timesteps: 1,375,749,312

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,860.66894
Policy Entropy: 3.67267
Value Function Loss: 0.10360

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.17343
Policy Update Magnitude: 0.90962
Value Function Update Magnitude: 0.67807

Collected Steps per Second: 23,115.10306
Overall Steps per Second: 10,722.18145

Timestep Collection Time: 2.16378
Timestep Consumption Time: 2.50094
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.66472

Cumulative Model Updates: 164,982
Cumulative Timesteps: 1,375,799,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1375799328...
Checkpoint 1375799328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,281.81232
Policy Entropy: 3.70736
Value Function Loss: 0.09358

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.16034
Policy Update Magnitude: 0.91787
Value Function Update Magnitude: 0.69099

Collected Steps per Second: 22,458.82317
Overall Steps per Second: 10,622.95658

Timestep Collection Time: 2.22745
Timestep Consumption Time: 2.48178
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.70924

Cumulative Model Updates: 164,988
Cumulative Timesteps: 1,375,849,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,023.05020
Policy Entropy: 3.72357
Value Function Loss: 0.08675

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.14402
Policy Update Magnitude: 0.94349
Value Function Update Magnitude: 0.85664

Collected Steps per Second: 20,816.53437
Overall Steps per Second: 10,249.30453

Timestep Collection Time: 2.40280
Timestep Consumption Time: 2.47733
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.88014

Cumulative Model Updates: 164,994
Cumulative Timesteps: 1,375,899,372

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1375899372...
Checkpoint 1375899372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,081.88774
Policy Entropy: 3.71733
Value Function Loss: 0.08628

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.98990
Value Function Update Magnitude: 0.77950

Collected Steps per Second: 19,896.55573
Overall Steps per Second: 9,935.73834

Timestep Collection Time: 2.51370
Timestep Consumption Time: 2.52005
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 5.03375

Cumulative Model Updates: 165,000
Cumulative Timesteps: 1,375,949,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,568.72256
Policy Entropy: 3.73861
Value Function Loss: 0.07495

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.13623
Policy Update Magnitude: 1.00382
Value Function Update Magnitude: 0.95581

Collected Steps per Second: 19,756.29140
Overall Steps per Second: 9,919.68058

Timestep Collection Time: 2.53094
Timestep Consumption Time: 2.50975
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 5.04069

Cumulative Model Updates: 165,006
Cumulative Timesteps: 1,375,999,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1375999388...
Checkpoint 1375999388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,324.46551
Policy Entropy: 3.74582
Value Function Loss: 0.06847

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.15123
Policy Update Magnitude: 1.12327
Value Function Update Magnitude: 1.21080

Collected Steps per Second: 21,651.58599
Overall Steps per Second: 10,435.58631

Timestep Collection Time: 2.31013
Timestep Consumption Time: 2.48289
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.79302

Cumulative Model Updates: 165,012
Cumulative Timesteps: 1,376,049,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,575.43526
Policy Entropy: 3.78468
Value Function Loss: 0.06499

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 1.21287
Value Function Update Magnitude: 1.27450

Collected Steps per Second: 22,242.69033
Overall Steps per Second: 10,458.56092

Timestep Collection Time: 2.24892
Timestep Consumption Time: 2.53396
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.78288

Cumulative Model Updates: 165,018
Cumulative Timesteps: 1,376,099,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1376099428...
Checkpoint 1376099428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,458.83437
Policy Entropy: 3.81078
Value Function Loss: 0.05986

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.12342
Policy Update Magnitude: 1.42666
Value Function Update Magnitude: 1.28439

Collected Steps per Second: 22,072.74011
Overall Steps per Second: 10,671.18051

Timestep Collection Time: 2.26560
Timestep Consumption Time: 2.42067
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.68627

Cumulative Model Updates: 165,024
Cumulative Timesteps: 1,376,149,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413.45668
Policy Entropy: 3.83194
Value Function Loss: 0.06033

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11756
Policy Update Magnitude: 1.54505
Value Function Update Magnitude: 1.39052

Collected Steps per Second: 22,288.33963
Overall Steps per Second: 10,541.97746

Timestep Collection Time: 2.24449
Timestep Consumption Time: 2.50092
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.74541

Cumulative Model Updates: 165,030
Cumulative Timesteps: 1,376,199,462

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1376199462...
Checkpoint 1376199462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 811.78134
Policy Entropy: 3.84998
Value Function Loss: 0.05964

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 1.51483
Value Function Update Magnitude: 1.42929

Collected Steps per Second: 22,155.66838
Overall Steps per Second: 10,510.57281

Timestep Collection Time: 2.25712
Timestep Consumption Time: 2.50076
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.75788

Cumulative Model Updates: 165,036
Cumulative Timesteps: 1,376,249,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,701.82006
Policy Entropy: 3.82402
Value Function Loss: 0.06391

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 1.43152
Value Function Update Magnitude: 1.27154

Collected Steps per Second: 22,421.16278
Overall Steps per Second: 10,583.68303

Timestep Collection Time: 2.23048
Timestep Consumption Time: 2.49472
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.72520

Cumulative Model Updates: 165,042
Cumulative Timesteps: 1,376,299,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1376299480...
Checkpoint 1376299480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,183.35625
Policy Entropy: 3.83352
Value Function Loss: 0.06429

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 1.39375
Value Function Update Magnitude: 1.09185

Collected Steps per Second: 21,619.52123
Overall Steps per Second: 10,548.11999

Timestep Collection Time: 2.31411
Timestep Consumption Time: 2.42891
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.74303

Cumulative Model Updates: 165,048
Cumulative Timesteps: 1,376,349,510

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,463.35868
Policy Entropy: 3.83044
Value Function Loss: 0.06587

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 1.33160
Value Function Update Magnitude: 1.32167

Collected Steps per Second: 22,166.67796
Overall Steps per Second: 10,519.08278

Timestep Collection Time: 2.25582
Timestep Consumption Time: 2.49783
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.75365

Cumulative Model Updates: 165,054
Cumulative Timesteps: 1,376,399,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1376399514...
Checkpoint 1376399514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.12073
Policy Entropy: 3.87266
Value Function Loss: 0.06567

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 1.30860
Value Function Update Magnitude: 1.35006

Collected Steps per Second: 21,923.63891
Overall Steps per Second: 10,537.16985

Timestep Collection Time: 2.28174
Timestep Consumption Time: 2.46565
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.74738

Cumulative Model Updates: 165,060
Cumulative Timesteps: 1,376,449,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,951.93377
Policy Entropy: 3.88546
Value Function Loss: 0.07034

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 1.29446
Value Function Update Magnitude: 1.18581

Collected Steps per Second: 22,401.29803
Overall Steps per Second: 10,865.07548

Timestep Collection Time: 2.23255
Timestep Consumption Time: 2.37046
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.60301

Cumulative Model Updates: 165,066
Cumulative Timesteps: 1,376,499,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1376499550...
Checkpoint 1376499550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.66924
Policy Entropy: 3.87738
Value Function Loss: 0.08292

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.10513
Policy Update Magnitude: 1.22638
Value Function Update Magnitude: 0.97071

Collected Steps per Second: 21,358.21868
Overall Steps per Second: 10,601.21100

Timestep Collection Time: 2.34102
Timestep Consumption Time: 2.37542
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.71644

Cumulative Model Updates: 165,072
Cumulative Timesteps: 1,376,549,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,448.20116
Policy Entropy: 3.83419
Value Function Loss: 0.10199

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.92146
Value Function Update Magnitude: 0.91799

Collected Steps per Second: 21,476.47410
Overall Steps per Second: 10,552.14998

Timestep Collection Time: 2.32850
Timestep Consumption Time: 2.41063
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.73913

Cumulative Model Updates: 165,078
Cumulative Timesteps: 1,376,599,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1376599558...
Checkpoint 1376599558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 971.95495
Policy Entropy: 3.78147
Value Function Loss: 0.11635

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.13406
Policy Update Magnitude: 0.69349
Value Function Update Magnitude: 0.73295

Collected Steps per Second: 21,431.91029
Overall Steps per Second: 10,629.19057

Timestep Collection Time: 2.33334
Timestep Consumption Time: 2.37144
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.70478

Cumulative Model Updates: 165,084
Cumulative Timesteps: 1,376,649,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.32207
Policy Entropy: 3.77813
Value Function Loss: 0.12715

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.62823
Value Function Update Magnitude: 0.57187

Collected Steps per Second: 21,597.46579
Overall Steps per Second: 10,502.39698

Timestep Collection Time: 2.31694
Timestep Consumption Time: 2.44769
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.76463

Cumulative Model Updates: 165,090
Cumulative Timesteps: 1,376,699,606

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1376699606...
Checkpoint 1376699606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,534.85158
Policy Entropy: 3.74852
Value Function Loss: 0.14051

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.58787
Value Function Update Magnitude: 0.48203

Collected Steps per Second: 21,392.57793
Overall Steps per Second: 10,593.58166

Timestep Collection Time: 2.33745
Timestep Consumption Time: 2.38277
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.72022

Cumulative Model Updates: 165,096
Cumulative Timesteps: 1,376,749,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,405.27334
Policy Entropy: 3.75426
Value Function Loss: 0.14367

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.58763
Value Function Update Magnitude: 0.46166

Collected Steps per Second: 22,090.26273
Overall Steps per Second: 10,649.80552

Timestep Collection Time: 2.26389
Timestep Consumption Time: 2.43197
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.69586

Cumulative Model Updates: 165,102
Cumulative Timesteps: 1,376,799,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1376799620...
Checkpoint 1376799620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,868.69851
Policy Entropy: 3.73214
Value Function Loss: 0.14204

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.52407
Value Function Update Magnitude: 0.49218

Collected Steps per Second: 21,889.50126
Overall Steps per Second: 10,595.10575

Timestep Collection Time: 2.28493
Timestep Consumption Time: 2.43574
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.72067

Cumulative Model Updates: 165,108
Cumulative Timesteps: 1,376,849,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,222.34600
Policy Entropy: 3.75163
Value Function Loss: 0.13721

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.15225
Policy Update Magnitude: 0.47019
Value Function Update Magnitude: 0.55732

Collected Steps per Second: 22,088.12121
Overall Steps per Second: 10,743.74860

Timestep Collection Time: 2.26393
Timestep Consumption Time: 2.39050
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.65443

Cumulative Model Updates: 165,114
Cumulative Timesteps: 1,376,899,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1376899642...
Checkpoint 1376899642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,073.63172
Policy Entropy: 3.74801
Value Function Loss: 0.13506

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.15740
Policy Update Magnitude: 0.47706
Value Function Update Magnitude: 0.61779

Collected Steps per Second: 21,593.44294
Overall Steps per Second: 10,666.89729

Timestep Collection Time: 2.31672
Timestep Consumption Time: 2.37311
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.68984

Cumulative Model Updates: 165,120
Cumulative Timesteps: 1,376,949,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.30069
Policy Entropy: 3.74788
Value Function Loss: 0.14806

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.14691
Policy Update Magnitude: 0.48104
Value Function Update Magnitude: 0.55003

Collected Steps per Second: 22,117.91748
Overall Steps per Second: 10,658.99898

Timestep Collection Time: 2.26188
Timestep Consumption Time: 2.43162
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.69350

Cumulative Model Updates: 165,126
Cumulative Timesteps: 1,376,999,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1376999696...
Checkpoint 1376999696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,039.24803
Policy Entropy: 3.72835
Value Function Loss: 0.15735

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.14755
Policy Update Magnitude: 0.46788
Value Function Update Magnitude: 0.47643

Collected Steps per Second: 21,519.89508
Overall Steps per Second: 10,498.71962

Timestep Collection Time: 2.32417
Timestep Consumption Time: 2.43983
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.76401

Cumulative Model Updates: 165,132
Cumulative Timesteps: 1,377,049,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,853.48134
Policy Entropy: 3.72424
Value Function Loss: 0.15076

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.46858
Value Function Update Magnitude: 0.47608

Collected Steps per Second: 21,584.42358
Overall Steps per Second: 10,388.49912

Timestep Collection Time: 2.31695
Timestep Consumption Time: 2.49703
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.81398

Cumulative Model Updates: 165,138
Cumulative Timesteps: 1,377,099,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1377099722...
Checkpoint 1377099722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,532.83419
Policy Entropy: 3.71314
Value Function Loss: 0.14644

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.48157
Value Function Update Magnitude: 0.54060

Collected Steps per Second: 21,869.81353
Overall Steps per Second: 10,616.92682

Timestep Collection Time: 2.28726
Timestep Consumption Time: 2.42427
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.71153

Cumulative Model Updates: 165,144
Cumulative Timesteps: 1,377,149,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,692.86334
Policy Entropy: 3.70826
Value Function Loss: 0.14068

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13991
Policy Update Magnitude: 0.50530
Value Function Update Magnitude: 0.65336

Collected Steps per Second: 22,279.54523
Overall Steps per Second: 10,517.99573

Timestep Collection Time: 2.24529
Timestep Consumption Time: 2.51075
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.75604

Cumulative Model Updates: 165,150
Cumulative Timesteps: 1,377,199,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1377199768...
Checkpoint 1377199768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,186.47479
Policy Entropy: 3.66984
Value Function Loss: 0.13763

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.14632
Policy Update Magnitude: 0.48723
Value Function Update Magnitude: 0.60546

Collected Steps per Second: 21,677.95147
Overall Steps per Second: 10,539.83869

Timestep Collection Time: 2.30695
Timestep Consumption Time: 2.43790
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.74485

Cumulative Model Updates: 165,156
Cumulative Timesteps: 1,377,249,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,847.98559
Policy Entropy: 3.65487
Value Function Loss: 0.12552

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.14775
Policy Update Magnitude: 0.46485
Value Function Update Magnitude: 0.58331

Collected Steps per Second: 22,232.91675
Overall Steps per Second: 10,544.59390

Timestep Collection Time: 2.24892
Timestep Consumption Time: 2.49285
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.74177

Cumulative Model Updates: 165,162
Cumulative Timesteps: 1,377,299,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1377299778...
Checkpoint 1377299778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,175.71016
Policy Entropy: 3.65037
Value Function Loss: 0.12659

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.14895
Policy Update Magnitude: 0.45420
Value Function Update Magnitude: 0.61453

Collected Steps per Second: 21,787.61528
Overall Steps per Second: 10,544.60653

Timestep Collection Time: 2.29525
Timestep Consumption Time: 2.44727
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.74252

Cumulative Model Updates: 165,168
Cumulative Timesteps: 1,377,349,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,431.78883
Policy Entropy: 3.65607
Value Function Loss: 0.12678

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.14943
Policy Update Magnitude: 0.50472
Value Function Update Magnitude: 0.54801

Collected Steps per Second: 22,113.95546
Overall Steps per Second: 10,497.04911

Timestep Collection Time: 2.26129
Timestep Consumption Time: 2.50253
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.76382

Cumulative Model Updates: 165,174
Cumulative Timesteps: 1,377,399,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1377399792...
Checkpoint 1377399792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,431.78883
Policy Entropy: 3.65028
Value Function Loss: 0.12191

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.17035
Policy Update Magnitude: 0.55604
Value Function Update Magnitude: 0.50644

Collected Steps per Second: 21,766.59185
Overall Steps per Second: 10,394.62858

Timestep Collection Time: 2.29737
Timestep Consumption Time: 2.51338
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.81075

Cumulative Model Updates: 165,180
Cumulative Timesteps: 1,377,449,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,526.60023
Policy Entropy: 3.64760
Value Function Loss: 0.12776

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.17426
Policy Update Magnitude: 0.59788
Value Function Update Magnitude: 0.53484

Collected Steps per Second: 22,265.07937
Overall Steps per Second: 10,656.23553

Timestep Collection Time: 2.24612
Timestep Consumption Time: 2.44691
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.69303

Cumulative Model Updates: 165,186
Cumulative Timesteps: 1,377,499,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1377499808...
Checkpoint 1377499808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,046.90080
Policy Entropy: 3.64894
Value Function Loss: 0.13765

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.15350
Policy Update Magnitude: 0.60885
Value Function Update Magnitude: 0.55958

Collected Steps per Second: 21,799.47249
Overall Steps per Second: 10,429.98659

Timestep Collection Time: 2.29428
Timestep Consumption Time: 2.50094
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.79521

Cumulative Model Updates: 165,192
Cumulative Timesteps: 1,377,549,822

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,516.41829
Policy Entropy: 3.66672
Value Function Loss: 0.14225

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.15913
Policy Update Magnitude: 0.67782
Value Function Update Magnitude: 0.52275

Collected Steps per Second: 22,330.43407
Overall Steps per Second: 10,664.27120

Timestep Collection Time: 2.23945
Timestep Consumption Time: 2.44985
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.68930

Cumulative Model Updates: 165,198
Cumulative Timesteps: 1,377,599,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1377599830...
Checkpoint 1377599830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,861.17364
Policy Entropy: 3.66241
Value Function Loss: 0.13956

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.18545
Policy Update Magnitude: 0.71462
Value Function Update Magnitude: 0.62110

Collected Steps per Second: 22,006.43398
Overall Steps per Second: 10,609.40913

Timestep Collection Time: 2.27206
Timestep Consumption Time: 2.44074
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.71280

Cumulative Model Updates: 165,204
Cumulative Timesteps: 1,377,649,830

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,125.59475
Policy Entropy: 3.65718
Value Function Loss: 0.13058

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.15519
Policy Update Magnitude: 0.65599
Value Function Update Magnitude: 0.66375

Collected Steps per Second: 21,157.61024
Overall Steps per Second: 10,530.30719

Timestep Collection Time: 2.36435
Timestep Consumption Time: 2.38613
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.75048

Cumulative Model Updates: 165,210
Cumulative Timesteps: 1,377,699,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1377699854...
Checkpoint 1377699854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,868.27195
Policy Entropy: 3.65830
Value Function Loss: 0.12595

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.15127
Policy Update Magnitude: 0.66547
Value Function Update Magnitude: 0.62154

Collected Steps per Second: 21,237.26410
Overall Steps per Second: 10,577.52052

Timestep Collection Time: 2.35445
Timestep Consumption Time: 2.37275
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.72719

Cumulative Model Updates: 165,216
Cumulative Timesteps: 1,377,749,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,718.39531
Policy Entropy: 3.66837
Value Function Loss: 0.12093

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.80302
Value Function Update Magnitude: 0.77348

Collected Steps per Second: 21,493.24685
Overall Steps per Second: 10,554.63078

Timestep Collection Time: 2.32668
Timestep Consumption Time: 2.41133
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.73802

Cumulative Model Updates: 165,222
Cumulative Timesteps: 1,377,799,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1377799864...
Checkpoint 1377799864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,909.86323
Policy Entropy: 3.65926
Value Function Loss: 0.11724

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.19298
Policy Update Magnitude: 0.74773
Value Function Update Magnitude: 0.75638

Collected Steps per Second: 21,217.83520
Overall Steps per Second: 10,550.27763

Timestep Collection Time: 2.35764
Timestep Consumption Time: 2.38385
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.74149

Cumulative Model Updates: 165,228
Cumulative Timesteps: 1,377,849,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,514.39956
Policy Entropy: 3.65558
Value Function Loss: 0.12386

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.18019
Policy Update Magnitude: 0.63837
Value Function Update Magnitude: 0.69471

Collected Steps per Second: 21,748.80238
Overall Steps per Second: 10,533.23735

Timestep Collection Time: 2.29935
Timestep Consumption Time: 2.44829
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.74764

Cumulative Model Updates: 165,234
Cumulative Timesteps: 1,377,899,896

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1377899896...
Checkpoint 1377899896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,072.29068
Policy Entropy: 3.64026
Value Function Loss: 0.13554

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.17181
Policy Update Magnitude: 0.64689
Value Function Update Magnitude: 0.52944

Collected Steps per Second: 21,726.15873
Overall Steps per Second: 10,557.46765

Timestep Collection Time: 2.30183
Timestep Consumption Time: 2.43510
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.73693

Cumulative Model Updates: 165,240
Cumulative Timesteps: 1,377,949,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,432.80199
Policy Entropy: 3.63861
Value Function Loss: 0.13538

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.16425
Policy Update Magnitude: 0.67098
Value Function Update Magnitude: 0.49301

Collected Steps per Second: 22,178.81370
Overall Steps per Second: 10,540.16857

Timestep Collection Time: 2.25522
Timestep Consumption Time: 2.49025
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.74546

Cumulative Model Updates: 165,246
Cumulative Timesteps: 1,377,999,924

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1377999924...
Checkpoint 1377999924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,033.91966
Policy Entropy: 3.63027
Value Function Loss: 0.13401

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.15798
Policy Update Magnitude: 0.69160
Value Function Update Magnitude: 0.47368

Collected Steps per Second: 22,142.75434
Overall Steps per Second: 10,591.26006

Timestep Collection Time: 2.25808
Timestep Consumption Time: 2.46280
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.72087

Cumulative Model Updates: 165,252
Cumulative Timesteps: 1,378,049,924

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,029.85666
Policy Entropy: 3.61864
Value Function Loss: 0.12082

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.17660
Policy Update Magnitude: 0.67212
Value Function Update Magnitude: 0.53178

Collected Steps per Second: 22,268.78249
Overall Steps per Second: 10,488.02910

Timestep Collection Time: 2.24583
Timestep Consumption Time: 2.52265
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.76848

Cumulative Model Updates: 165,258
Cumulative Timesteps: 1,378,099,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1378099936...
Checkpoint 1378099936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,237.75088
Policy Entropy: 3.62046
Value Function Loss: 0.12024

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.17260
Policy Update Magnitude: 0.68394
Value Function Update Magnitude: 0.68571

Collected Steps per Second: 22,176.32455
Overall Steps per Second: 10,597.24827

Timestep Collection Time: 2.25700
Timestep Consumption Time: 2.46611
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.72311

Cumulative Model Updates: 165,264
Cumulative Timesteps: 1,378,149,988

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,538.93731
Policy Entropy: 3.62520
Value Function Loss: 0.11380

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.14578
Policy Update Magnitude: 0.67605
Value Function Update Magnitude: 0.57931

Collected Steps per Second: 22,075.26266
Overall Steps per Second: 10,514.06330

Timestep Collection Time: 2.26634
Timestep Consumption Time: 2.49205
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.75839

Cumulative Model Updates: 165,270
Cumulative Timesteps: 1,378,200,018

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1378200018...
Checkpoint 1378200018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,538.93731
Policy Entropy: 3.61774
Value Function Loss: 0.11433

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.16568
Policy Update Magnitude: 0.63562
Value Function Update Magnitude: 0.46612

Collected Steps per Second: 22,402.49895
Overall Steps per Second: 10,684.53885

Timestep Collection Time: 2.23288
Timestep Consumption Time: 2.44884
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.68172

Cumulative Model Updates: 165,276
Cumulative Timesteps: 1,378,250,040

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,988.69273
Policy Entropy: 3.60285
Value Function Loss: 0.11028

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.14493
Policy Update Magnitude: 0.58844
Value Function Update Magnitude: 0.41982

Collected Steps per Second: 22,345.33217
Overall Steps per Second: 10,496.66541

Timestep Collection Time: 2.23778
Timestep Consumption Time: 2.52602
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.76380

Cumulative Model Updates: 165,282
Cumulative Timesteps: 1,378,300,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1378300044...
Checkpoint 1378300044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,728.60239
Policy Entropy: 3.57971
Value Function Loss: 0.11492

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.23089
Policy Update Magnitude: 0.48115
Value Function Update Magnitude: 0.43375

Collected Steps per Second: 22,675.65573
Overall Steps per Second: 10,578.32514

Timestep Collection Time: 2.20518
Timestep Consumption Time: 2.52184
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.72702

Cumulative Model Updates: 165,288
Cumulative Timesteps: 1,378,350,048

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,806.88661
Policy Entropy: 3.57208
Value Function Loss: 0.13206

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.15698
Policy Update Magnitude: 0.62793
Value Function Update Magnitude: 0.38822

Collected Steps per Second: 22,770.99171
Overall Steps per Second: 10,616.19067

Timestep Collection Time: 2.19683
Timestep Consumption Time: 2.51522
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.71205

Cumulative Model Updates: 165,294
Cumulative Timesteps: 1,378,400,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1378400072...
Checkpoint 1378400072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,962.94815
Policy Entropy: 3.56978
Value Function Loss: 0.14009

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.16766
Policy Update Magnitude: 0.66245
Value Function Update Magnitude: 0.35120

Collected Steps per Second: 22,771.58463
Overall Steps per Second: 10,615.81173

Timestep Collection Time: 2.19677
Timestep Consumption Time: 2.51544
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.71222

Cumulative Model Updates: 165,300
Cumulative Timesteps: 1,378,450,096

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,962.94815
Policy Entropy: 3.57939
Value Function Loss: 0.16198

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.23580
Policy Update Magnitude: 0.61066
Value Function Update Magnitude: 0.28150

Collected Steps per Second: 22,847.60342
Overall Steps per Second: 10,766.10663

Timestep Collection Time: 2.18929
Timestep Consumption Time: 2.45677
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.64606

Cumulative Model Updates: 165,306
Cumulative Timesteps: 1,378,500,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1378500116...
Checkpoint 1378500116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,962.94815
Policy Entropy: 3.58944
Value Function Loss: 0.13586

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.26452
Policy Update Magnitude: 0.53118
Value Function Update Magnitude: 0.21074

Collected Steps per Second: 22,074.01663
Overall Steps per Second: 10,618.27730

Timestep Collection Time: 2.26583
Timestep Consumption Time: 2.44454
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.71037

Cumulative Model Updates: 165,312
Cumulative Timesteps: 1,378,550,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,962.94815
Policy Entropy: 3.57851
Value Function Loss: 0.11014

Mean KL Divergence: 0.03090
SB3 Clip Fraction: 0.29298
Policy Update Magnitude: 0.41259
Value Function Update Magnitude: 0.17681

Collected Steps per Second: 22,211.81702
Overall Steps per Second: 10,474.66737

Timestep Collection Time: 2.25186
Timestep Consumption Time: 2.52328
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.77514

Cumulative Model Updates: 165,318
Cumulative Timesteps: 1,378,600,150

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1378600150...
Checkpoint 1378600150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,962.94815
Policy Entropy: 3.57911
Value Function Loss: 0.09275

Mean KL Divergence: 0.03241
SB3 Clip Fraction: 0.29569
Policy Update Magnitude: 0.35673
Value Function Update Magnitude: 0.23437

Collected Steps per Second: 22,428.89254
Overall Steps per Second: 10,691.87872

Timestep Collection Time: 2.22971
Timestep Consumption Time: 2.44767
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.67738

Cumulative Model Updates: 165,324
Cumulative Timesteps: 1,378,650,160

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,962.94815
Policy Entropy: 3.58145
Value Function Loss: 0.09954

Mean KL Divergence: 0.03094
SB3 Clip Fraction: 0.27524
Policy Update Magnitude: 0.34609
Value Function Update Magnitude: 0.31913

Collected Steps per Second: 22,711.51420
Overall Steps per Second: 10,767.94495

Timestep Collection Time: 2.20285
Timestep Consumption Time: 2.44335
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.64620

Cumulative Model Updates: 165,330
Cumulative Timesteps: 1,378,700,190

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1378700190...
Checkpoint 1378700190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,962.94815
Policy Entropy: 3.59354
Value Function Loss: 0.10005

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.19004
Policy Update Magnitude: 0.39864
Value Function Update Magnitude: 0.38824

Collected Steps per Second: 22,352.39142
Overall Steps per Second: 10,673.67927

Timestep Collection Time: 2.23734
Timestep Consumption Time: 2.44801
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.68536

Cumulative Model Updates: 165,336
Cumulative Timesteps: 1,378,750,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,962.94815
Policy Entropy: 3.59298
Value Function Loss: 0.10436

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.18560
Policy Update Magnitude: 0.44560
Value Function Update Magnitude: 0.38879

Collected Steps per Second: 21,785.80426
Overall Steps per Second: 10,528.74521

Timestep Collection Time: 2.29544
Timestep Consumption Time: 2.45422
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.74966

Cumulative Model Updates: 165,342
Cumulative Timesteps: 1,378,800,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1378800208...
Checkpoint 1378800208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,962.94815
Policy Entropy: 3.58652
Value Function Loss: 0.10253

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.15691
Policy Update Magnitude: 0.60986
Value Function Update Magnitude: 0.37909

Collected Steps per Second: 21,654.75465
Overall Steps per Second: 10,673.16366

Timestep Collection Time: 2.30905
Timestep Consumption Time: 2.37578
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.68483

Cumulative Model Updates: 165,348
Cumulative Timesteps: 1,378,850,210

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,962.94815
Policy Entropy: 3.59522
Value Function Loss: 0.09864

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.66042
Value Function Update Magnitude: 0.35434

Collected Steps per Second: 21,753.52736
Overall Steps per Second: 10,410.89274

Timestep Collection Time: 2.29986
Timestep Consumption Time: 2.50569
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.80554

Cumulative Model Updates: 165,354
Cumulative Timesteps: 1,378,900,240

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1378900240...
Checkpoint 1378900240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,175.74060
Policy Entropy: 3.57967
Value Function Loss: 0.10329

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.63048
Value Function Update Magnitude: 0.32142

Collected Steps per Second: 22,355.83570
Overall Steps per Second: 10,654.62361

Timestep Collection Time: 2.23700
Timestep Consumption Time: 2.45674
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.69374

Cumulative Model Updates: 165,360
Cumulative Timesteps: 1,378,950,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,059.94830
Policy Entropy: 3.56559
Value Function Loss: 0.08941

Mean KL Divergence: 0.02442
SB3 Clip Fraction: 0.24656
Policy Update Magnitude: 0.56398
Value Function Update Magnitude: 0.35918

Collected Steps per Second: 22,775.55326
Overall Steps per Second: 10,787.59981

Timestep Collection Time: 2.19630
Timestep Consumption Time: 2.44069
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.63699

Cumulative Model Updates: 165,366
Cumulative Timesteps: 1,379,000,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1379000272...
Checkpoint 1379000272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,059.94830
Policy Entropy: 3.51948
Value Function Loss: 0.11874

Mean KL Divergence: 0.03417
SB3 Clip Fraction: 0.28701
Policy Update Magnitude: 0.40912
Value Function Update Magnitude: 0.45894

Collected Steps per Second: 22,504.13758
Overall Steps per Second: 10,691.62419

Timestep Collection Time: 2.22261
Timestep Consumption Time: 2.45563
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.67824

Cumulative Model Updates: 165,372
Cumulative Timesteps: 1,379,050,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,573.82992
Policy Entropy: 3.48024
Value Function Loss: 0.15473

Mean KL Divergence: 0.02625
SB3 Clip Fraction: 0.25064
Policy Update Magnitude: 0.45829
Value Function Update Magnitude: 0.40990

Collected Steps per Second: 22,070.17831
Overall Steps per Second: 10,561.43556

Timestep Collection Time: 2.26550
Timestep Consumption Time: 2.46870
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.73420

Cumulative Model Updates: 165,378
Cumulative Timesteps: 1,379,100,290

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1379100290...
Checkpoint 1379100290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,101.53348
Policy Entropy: 3.49860
Value Function Loss: 0.16331

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.23494
Policy Update Magnitude: 0.47332
Value Function Update Magnitude: 0.34418

Collected Steps per Second: 22,495.06176
Overall Steps per Second: 10,597.34668

Timestep Collection Time: 2.22422
Timestep Consumption Time: 2.49715
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.72137

Cumulative Model Updates: 165,384
Cumulative Timesteps: 1,379,150,324

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.53394
Value Function Loss: 0.15337

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.17355
Policy Update Magnitude: 0.44726
Value Function Update Magnitude: 0.36920

Collected Steps per Second: 22,582.56961
Overall Steps per Second: 10,531.93384

Timestep Collection Time: 2.21463
Timestep Consumption Time: 2.53398
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.74861

Cumulative Model Updates: 165,390
Cumulative Timesteps: 1,379,200,336

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1379200336...
Checkpoint 1379200336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.57286
Value Function Loss: 0.12524

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.19820
Policy Update Magnitude: 0.48938
Value Function Update Magnitude: 0.34151

Collected Steps per Second: 22,230.43003
Overall Steps per Second: 10,578.90649

Timestep Collection Time: 2.24962
Timestep Consumption Time: 2.47771
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.72733

Cumulative Model Updates: 165,396
Cumulative Timesteps: 1,379,250,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.57473
Value Function Loss: 0.10506

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.17350
Policy Update Magnitude: 0.39730
Value Function Update Magnitude: 0.29248

Collected Steps per Second: 22,346.54248
Overall Steps per Second: 10,503.63307

Timestep Collection Time: 2.23766
Timestep Consumption Time: 2.52298
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.76064

Cumulative Model Updates: 165,402
Cumulative Timesteps: 1,379,300,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1379300350...
Checkpoint 1379300350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.58765
Value Function Loss: 0.09789

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.15868
Policy Update Magnitude: 0.35068
Value Function Update Magnitude: 0.32931

Collected Steps per Second: 22,263.45513
Overall Steps per Second: 10,591.79449

Timestep Collection Time: 2.24583
Timestep Consumption Time: 2.47480
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.72064

Cumulative Model Updates: 165,408
Cumulative Timesteps: 1,379,350,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.59585
Value Function Loss: 0.09946

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.16011
Policy Update Magnitude: 0.34556
Value Function Update Magnitude: 0.33754

Collected Steps per Second: 22,532.53740
Overall Steps per Second: 10,584.07643

Timestep Collection Time: 2.22034
Timestep Consumption Time: 2.50657
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.72691

Cumulative Model Updates: 165,414
Cumulative Timesteps: 1,379,400,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1379400380...
Checkpoint 1379400380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.58985
Value Function Loss: 0.08978

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.15837
Policy Update Magnitude: 0.36375
Value Function Update Magnitude: 0.32908

Collected Steps per Second: 21,622.03012
Overall Steps per Second: 10,501.64594

Timestep Collection Time: 2.31301
Timestep Consumption Time: 2.44929
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.76230

Cumulative Model Updates: 165,420
Cumulative Timesteps: 1,379,450,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.60151
Value Function Loss: 0.07047

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.33744
Value Function Update Magnitude: 0.29412

Collected Steps per Second: 21,334.75173
Overall Steps per Second: 10,450.25774

Timestep Collection Time: 2.34406
Timestep Consumption Time: 2.44147
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.78553

Cumulative Model Updates: 165,426
Cumulative Timesteps: 1,379,500,402

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1379500402...
Checkpoint 1379500402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.58671
Value Function Loss: 0.06467

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.14851
Policy Update Magnitude: 0.27921
Value Function Update Magnitude: 0.25462

Collected Steps per Second: 21,745.26092
Overall Steps per Second: 10,584.31130

Timestep Collection Time: 2.29963
Timestep Consumption Time: 2.42491
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.72454

Cumulative Model Updates: 165,432
Cumulative Timesteps: 1,379,550,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.59709
Value Function Loss: 0.05993

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.25335
Value Function Update Magnitude: 0.24063

Collected Steps per Second: 22,675.17886
Overall Steps per Second: 10,654.31454

Timestep Collection Time: 2.20620
Timestep Consumption Time: 2.48917
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.69537

Cumulative Model Updates: 165,438
Cumulative Timesteps: 1,379,600,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1379600434...
Checkpoint 1379600434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.60011
Value Function Loss: 0.06786

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.14924
Policy Update Magnitude: 0.24667
Value Function Update Magnitude: 0.25966

Collected Steps per Second: 22,477.80202
Overall Steps per Second: 10,521.86507

Timestep Collection Time: 2.22548
Timestep Consumption Time: 2.52881
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.75429

Cumulative Model Updates: 165,444
Cumulative Timesteps: 1,379,650,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.60562
Value Function Loss: 0.06262

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13966
Policy Update Magnitude: 0.25391
Value Function Update Magnitude: 0.24557

Collected Steps per Second: 22,585.10064
Overall Steps per Second: 10,606.26676

Timestep Collection Time: 2.21518
Timestep Consumption Time: 2.50185
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.71702

Cumulative Model Updates: 165,450
Cumulative Timesteps: 1,379,700,488

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1379700488...
Checkpoint 1379700488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.60327
Value Function Loss: 0.06193

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14109
Policy Update Magnitude: 0.23934
Value Function Update Magnitude: 0.21060

Collected Steps per Second: 22,471.38494
Overall Steps per Second: 10,549.47043

Timestep Collection Time: 2.22505
Timestep Consumption Time: 2.51452
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.73957

Cumulative Model Updates: 165,456
Cumulative Timesteps: 1,379,750,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.60858
Value Function Loss: 0.04919

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.22650
Value Function Update Magnitude: 0.19888

Collected Steps per Second: 22,854.43088
Overall Steps per Second: 10,772.72903

Timestep Collection Time: 2.18881
Timestep Consumption Time: 2.45477
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.64358

Cumulative Model Updates: 165,462
Cumulative Timesteps: 1,379,800,512

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1379800512...
Checkpoint 1379800512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.60426
Value Function Loss: 0.05289

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.22262
Value Function Update Magnitude: 0.23298

Collected Steps per Second: 22,555.11470
Overall Steps per Second: 10,718.03829

Timestep Collection Time: 2.21803
Timestep Consumption Time: 2.44961
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.66765

Cumulative Model Updates: 165,468
Cumulative Timesteps: 1,379,850,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.60294
Value Function Loss: 0.05113

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.23257
Value Function Update Magnitude: 0.25053

Collected Steps per Second: 22,632.24494
Overall Steps per Second: 10,597.99776

Timestep Collection Time: 2.20986
Timestep Consumption Time: 2.50934
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.71919

Cumulative Model Updates: 165,474
Cumulative Timesteps: 1,379,900,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1379900554...
Checkpoint 1379900554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.59035
Value Function Loss: 0.05925

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.23987
Value Function Update Magnitude: 0.21586

Collected Steps per Second: 22,523.93804
Overall Steps per Second: 10,584.93161

Timestep Collection Time: 2.22119
Timestep Consumption Time: 2.50534
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.72653

Cumulative Model Updates: 165,480
Cumulative Timesteps: 1,379,950,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.60114
Value Function Loss: 0.04644

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13823
Policy Update Magnitude: 0.23039
Value Function Update Magnitude: 0.21213

Collected Steps per Second: 21,954.89937
Overall Steps per Second: 10,744.06404

Timestep Collection Time: 2.27740
Timestep Consumption Time: 2.37634
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.65373

Cumulative Model Updates: 165,486
Cumulative Timesteps: 1,380,000,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1380000584...
Checkpoint 1380000584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.59169
Value Function Loss: 0.04998

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.23319
Value Function Update Magnitude: 0.26330

Collected Steps per Second: 20,700.73841
Overall Steps per Second: 9,896.87351

Timestep Collection Time: 2.41682
Timestep Consumption Time: 2.63831
PPO Batch Consumption Time: 0.32383
Total Iteration Time: 5.05513

Cumulative Model Updates: 165,492
Cumulative Timesteps: 1,380,050,614

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.59070
Value Function Loss: 0.04806

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.27239
Value Function Update Magnitude: 0.32795

Collected Steps per Second: 19,707.20665
Overall Steps per Second: 10,040.42527

Timestep Collection Time: 2.53806
Timestep Consumption Time: 2.44361
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.98166

Cumulative Model Updates: 165,498
Cumulative Timesteps: 1,380,100,632

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1380100632...
Checkpoint 1380100632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.57922
Value Function Loss: 0.05069

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.28398
Value Function Update Magnitude: 0.38621

Collected Steps per Second: 21,124.13094
Overall Steps per Second: 10,102.61160

Timestep Collection Time: 2.36819
Timestep Consumption Time: 2.58360
PPO Batch Consumption Time: 0.30152
Total Iteration Time: 4.95179

Cumulative Model Updates: 165,504
Cumulative Timesteps: 1,380,150,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.59402
Value Function Loss: 0.04589

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.28879
Value Function Update Magnitude: 0.36824

Collected Steps per Second: 22,580.62317
Overall Steps per Second: 10,955.18764

Timestep Collection Time: 2.21544
Timestep Consumption Time: 2.35098
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.56642

Cumulative Model Updates: 165,510
Cumulative Timesteps: 1,380,200,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1380200684...
Checkpoint 1380200684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,444.13725
Policy Entropy: 3.58714
Value Function Loss: 0.04537

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.26358
Value Function Update Magnitude: 0.27263

Collected Steps per Second: 22,513.12962
Overall Steps per Second: 10,698.73108

Timestep Collection Time: 2.22110
Timestep Consumption Time: 2.45272
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.67383

Cumulative Model Updates: 165,516
Cumulative Timesteps: 1,380,250,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231,127.72864
Policy Entropy: 3.59411
Value Function Loss: 0.04590

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.26229
Value Function Update Magnitude: 0.26250

Collected Steps per Second: 22,673.75252
Overall Steps per Second: 10,590.56281

Timestep Collection Time: 2.20537
Timestep Consumption Time: 2.51619
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.72156

Cumulative Model Updates: 165,522
Cumulative Timesteps: 1,380,300,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1380300692...
Checkpoint 1380300692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231,127.72864
Policy Entropy: 3.58895
Value Function Loss: 0.05001

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13598
Policy Update Magnitude: 0.26918
Value Function Update Magnitude: 0.32121

Collected Steps per Second: 22,500.26526
Overall Steps per Second: 10,540.81524

Timestep Collection Time: 2.22237
Timestep Consumption Time: 2.52147
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.74385

Cumulative Model Updates: 165,528
Cumulative Timesteps: 1,380,350,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231,127.72864
Policy Entropy: 3.59653
Value Function Loss: 0.04713

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.27577
Value Function Update Magnitude: 0.33795

Collected Steps per Second: 22,610.08880
Overall Steps per Second: 10,711.59371

Timestep Collection Time: 2.21220
Timestep Consumption Time: 2.45732
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.66952

Cumulative Model Updates: 165,534
Cumulative Timesteps: 1,380,400,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1380400714...
Checkpoint 1380400714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231,127.72864
Policy Entropy: 3.58898
Value Function Loss: 0.04902

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.29892
Value Function Update Magnitude: 0.30078

Collected Steps per Second: 22,329.31644
Overall Steps per Second: 10,669.43699

Timestep Collection Time: 2.24010
Timestep Consumption Time: 2.44805
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.68816

Cumulative Model Updates: 165,540
Cumulative Timesteps: 1,380,450,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231,127.72864
Policy Entropy: 3.60147
Value Function Loss: 0.04502

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12690
Policy Update Magnitude: 0.30149
Value Function Update Magnitude: 0.39189

Collected Steps per Second: 22,182.81509
Overall Steps per Second: 10,535.53280

Timestep Collection Time: 2.25436
Timestep Consumption Time: 2.49225
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.74660

Cumulative Model Updates: 165,546
Cumulative Timesteps: 1,380,500,742

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1380500742...
Checkpoint 1380500742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231,127.72864
Policy Entropy: 3.59624
Value Function Loss: 0.05075

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.31941
Value Function Update Magnitude: 0.41746

Collected Steps per Second: 21,592.67521
Overall Steps per Second: 10,676.33493

Timestep Collection Time: 2.31653
Timestep Consumption Time: 2.36860
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.68513

Cumulative Model Updates: 165,552
Cumulative Timesteps: 1,380,550,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231,127.72864
Policy Entropy: 3.59750
Value Function Loss: 0.04738

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.32618
Value Function Update Magnitude: 0.47774

Collected Steps per Second: 21,897.23240
Overall Steps per Second: 10,576.41169

Timestep Collection Time: 2.28394
Timestep Consumption Time: 2.44469
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.72864

Cumulative Model Updates: 165,558
Cumulative Timesteps: 1,380,600,774

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1380600774...
Checkpoint 1380600774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,022.23670
Policy Entropy: 3.61557
Value Function Loss: 0.04908

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.35474
Value Function Update Magnitude: 0.51136

Collected Steps per Second: 21,980.04011
Overall Steps per Second: 10,493.93484

Timestep Collection Time: 2.27607
Timestep Consumption Time: 2.49126
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.76733

Cumulative Model Updates: 165,564
Cumulative Timesteps: 1,380,650,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,022.23670
Policy Entropy: 3.61516
Value Function Loss: 0.04418

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.34534
Value Function Update Magnitude: 0.50438

Collected Steps per Second: 21,066.78740
Overall Steps per Second: 10,599.47233

Timestep Collection Time: 2.37388
Timestep Consumption Time: 2.34428
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.71816

Cumulative Model Updates: 165,570
Cumulative Timesteps: 1,380,700,812

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1380700812...
Checkpoint 1380700812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,022.23670
Policy Entropy: 3.63022
Value Function Loss: 0.04066

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13936
Policy Update Magnitude: 0.32374
Value Function Update Magnitude: 0.48065

Collected Steps per Second: 21,653.28905
Overall Steps per Second: 10,414.65348

Timestep Collection Time: 2.31023
Timestep Consumption Time: 2.49301
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.80323

Cumulative Model Updates: 165,576
Cumulative Timesteps: 1,380,750,836

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,022.23670
Policy Entropy: 3.61594
Value Function Loss: 0.03904

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13945
Policy Update Magnitude: 0.28281
Value Function Update Magnitude: 0.33977

Collected Steps per Second: 22,751.13414
Overall Steps per Second: 10,632.27059

Timestep Collection Time: 2.19954
Timestep Consumption Time: 2.50708
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.70661

Cumulative Model Updates: 165,582
Cumulative Timesteps: 1,380,800,878

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1380800878...
Checkpoint 1380800878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,022.23670
Policy Entropy: 3.62336
Value Function Loss: 0.04038

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.26202
Value Function Update Magnitude: 0.28206

Collected Steps per Second: 23,010.48494
Overall Steps per Second: 10,697.84457

Timestep Collection Time: 2.17405
Timestep Consumption Time: 2.50222
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.67627

Cumulative Model Updates: 165,588
Cumulative Timesteps: 1,380,850,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,022.23670
Policy Entropy: 3.61178
Value Function Loss: 0.04489

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.31547
Value Function Update Magnitude: 0.35150

Collected Steps per Second: 22,296.18312
Overall Steps per Second: 10,595.29091

Timestep Collection Time: 2.24254
Timestep Consumption Time: 2.47654
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.71908

Cumulative Model Updates: 165,594
Cumulative Timesteps: 1,380,900,904

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1380900904...
Checkpoint 1380900904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,022.23670
Policy Entropy: 3.61941
Value Function Loss: 0.04259

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.34255
Value Function Update Magnitude: 0.39894

Collected Steps per Second: 22,373.71764
Overall Steps per Second: 10,334.91320

Timestep Collection Time: 2.23620
Timestep Consumption Time: 2.60487
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.84107

Cumulative Model Updates: 165,600
Cumulative Timesteps: 1,380,950,936

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,022.23670
Policy Entropy: 3.62661
Value Function Loss: 0.04375

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.34372
Value Function Update Magnitude: 0.60407

Collected Steps per Second: 22,775.84904
Overall Steps per Second: 10,621.32299

Timestep Collection Time: 2.19715
Timestep Consumption Time: 2.51431
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.71147

Cumulative Model Updates: 165,606
Cumulative Timesteps: 1,381,000,978

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1381000978...
Checkpoint 1381000978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281,123.42486
Policy Entropy: 3.63978
Value Function Loss: 0.05086

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.38951
Value Function Update Magnitude: 0.75947

Collected Steps per Second: 22,534.23306
Overall Steps per Second: 10,544.37591

Timestep Collection Time: 2.21965
Timestep Consumption Time: 2.52393
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.74357

Cumulative Model Updates: 165,612
Cumulative Timesteps: 1,381,050,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281,123.42486
Policy Entropy: 3.63829
Value Function Loss: 0.05254

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.43510
Value Function Update Magnitude: 0.89772

Collected Steps per Second: 22,245.04716
Overall Steps per Second: 10,466.68538

Timestep Collection Time: 2.24832
Timestep Consumption Time: 2.53008
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.77840

Cumulative Model Updates: 165,618
Cumulative Timesteps: 1,381,101,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1381101010...
Checkpoint 1381101010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281,123.42486
Policy Entropy: 3.62525
Value Function Loss: 0.05279

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.44262
Value Function Update Magnitude: 0.77321

Collected Steps per Second: 22,480.02616
Overall Steps per Second: 10,556.50517

Timestep Collection Time: 2.22420
Timestep Consumption Time: 2.51222
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.73642

Cumulative Model Updates: 165,624
Cumulative Timesteps: 1,381,151,010

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281,123.42486
Policy Entropy: 3.62322
Value Function Loss: 0.05096

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.41017
Value Function Update Magnitude: 0.62315

Collected Steps per Second: 22,726.30590
Overall Steps per Second: 10,613.38078

Timestep Collection Time: 2.20027
Timestep Consumption Time: 2.51114
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.71141

Cumulative Model Updates: 165,630
Cumulative Timesteps: 1,381,201,014

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1381201014...
Checkpoint 1381201014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,265.31187
Policy Entropy: 3.62620
Value Function Loss: 0.05010

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.38634
Value Function Update Magnitude: 0.47938

Collected Steps per Second: 19,209.47785
Overall Steps per Second: 10,065.71400

Timestep Collection Time: 2.60299
Timestep Consumption Time: 2.36457
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.96756

Cumulative Model Updates: 165,636
Cumulative Timesteps: 1,381,251,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,265.31187
Policy Entropy: 3.62953
Value Function Loss: 0.04046

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.36459
Value Function Update Magnitude: 0.71005

Collected Steps per Second: 21,193.47268
Overall Steps per Second: 10,564.40686

Timestep Collection Time: 2.35997
Timestep Consumption Time: 2.37442
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.73439

Cumulative Model Updates: 165,642
Cumulative Timesteps: 1,381,301,032

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1381301032...
Checkpoint 1381301032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334,925.12891
Policy Entropy: 3.62210
Value Function Loss: 0.05272

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.36490
Value Function Update Magnitude: 0.50275

Collected Steps per Second: 21,740.05075
Overall Steps per Second: 10,569.96024

Timestep Collection Time: 2.30073
Timestep Consumption Time: 2.43136
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.73209

Cumulative Model Updates: 165,648
Cumulative Timesteps: 1,381,351,050

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,298.40972
Policy Entropy: 3.61181
Value Function Loss: 0.04941

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12941
Policy Update Magnitude: 0.39558
Value Function Update Magnitude: 0.47529

Collected Steps per Second: 22,740.53438
Overall Steps per Second: 10,674.57480

Timestep Collection Time: 2.20012
Timestep Consumption Time: 2.48690
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.68703

Cumulative Model Updates: 165,654
Cumulative Timesteps: 1,381,401,082

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1381401082...
Checkpoint 1381401082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271,298.40972
Policy Entropy: 3.61344
Value Function Loss: 0.05111

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.41398
Value Function Update Magnitude: 0.53092

Collected Steps per Second: 22,444.37567
Overall Steps per Second: 10,646.17507

Timestep Collection Time: 2.22871
Timestep Consumption Time: 2.46988
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.69859

Cumulative Model Updates: 165,660
Cumulative Timesteps: 1,381,451,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.62053
Value Function Loss: 0.05139

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13823
Policy Update Magnitude: 0.41966
Value Function Update Magnitude: 0.55532

Collected Steps per Second: 22,728.43137
Overall Steps per Second: 10,753.45769

Timestep Collection Time: 2.20086
Timestep Consumption Time: 2.45086
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.65171

Cumulative Model Updates: 165,666
Cumulative Timesteps: 1,381,501,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1381501126...
Checkpoint 1381501126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.62863
Value Function Loss: 0.04978

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.38206
Value Function Update Magnitude: 0.58316

Collected Steps per Second: 22,326.69532
Overall Steps per Second: 10,591.73653

Timestep Collection Time: 2.24073
Timestep Consumption Time: 2.48258
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.72330

Cumulative Model Updates: 165,672
Cumulative Timesteps: 1,381,551,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.63088
Value Function Loss: 0.05240

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13456
Policy Update Magnitude: 0.37902
Value Function Update Magnitude: 0.57683

Collected Steps per Second: 22,753.72372
Overall Steps per Second: 10,606.88932

Timestep Collection Time: 2.19823
Timestep Consumption Time: 2.51738
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.71561

Cumulative Model Updates: 165,678
Cumulative Timesteps: 1,381,601,172

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1381601172...
Checkpoint 1381601172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.62577
Value Function Loss: 0.04929

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.40569
Value Function Update Magnitude: 0.59307

Collected Steps per Second: 22,571.12166
Overall Steps per Second: 10,548.30255

Timestep Collection Time: 2.21628
Timestep Consumption Time: 2.52609
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.74237

Cumulative Model Updates: 165,684
Cumulative Timesteps: 1,381,651,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.62522
Value Function Loss: 0.04809

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.40298
Value Function Update Magnitude: 0.58876

Collected Steps per Second: 22,669.40982
Overall Steps per Second: 10,729.29627

Timestep Collection Time: 2.20588
Timestep Consumption Time: 2.45482
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.66070

Cumulative Model Updates: 165,690
Cumulative Timesteps: 1,381,701,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1381701202...
Checkpoint 1381701202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.62415
Value Function Loss: 0.05116

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.39735
Value Function Update Magnitude: 0.54370

Collected Steps per Second: 22,197.98792
Overall Steps per Second: 10,640.57532

Timestep Collection Time: 2.25255
Timestep Consumption Time: 2.44664
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.69918

Cumulative Model Updates: 165,696
Cumulative Timesteps: 1,381,751,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.63354
Value Function Loss: 0.05163

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.40683
Value Function Update Magnitude: 0.57911

Collected Steps per Second: 22,795.20243
Overall Steps per Second: 10,575.27598

Timestep Collection Time: 2.19344
Timestep Consumption Time: 2.53456
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.72801

Cumulative Model Updates: 165,702
Cumulative Timesteps: 1,381,801,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1381801204...
Checkpoint 1381801204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.63582
Value Function Loss: 0.04607

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.38477
Value Function Update Magnitude: 0.50853

Collected Steps per Second: 22,391.55008
Overall Steps per Second: 10,685.84880

Timestep Collection Time: 2.23343
Timestep Consumption Time: 2.44659
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.68002

Cumulative Model Updates: 165,708
Cumulative Timesteps: 1,381,851,214

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.64139
Value Function Loss: 0.04231

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.37821
Value Function Update Magnitude: 0.43481

Collected Steps per Second: 22,635.21833
Overall Steps per Second: 10,630.87543

Timestep Collection Time: 2.21001
Timestep Consumption Time: 2.49553
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.70554

Cumulative Model Updates: 165,714
Cumulative Timesteps: 1,381,901,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1381901238...
Checkpoint 1381901238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.62653
Value Function Loss: 0.04009

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.35250
Value Function Update Magnitude: 0.39049

Collected Steps per Second: 22,457.22140
Overall Steps per Second: 10,562.70298

Timestep Collection Time: 2.22735
Timestep Consumption Time: 2.50818
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.73553

Cumulative Model Updates: 165,720
Cumulative Timesteps: 1,381,951,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.63616
Value Function Loss: 0.04146

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.31223
Value Function Update Magnitude: 0.38732

Collected Steps per Second: 22,194.71000
Overall Steps per Second: 10,758.11470

Timestep Collection Time: 2.25306
Timestep Consumption Time: 2.39515
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.64821

Cumulative Model Updates: 165,726
Cumulative Timesteps: 1,382,001,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1382001264...
Checkpoint 1382001264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.62567
Value Function Loss: 0.04243

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14341
Policy Update Magnitude: 0.30302
Value Function Update Magnitude: 0.43402

Collected Steps per Second: 21,798.45726
Overall Steps per Second: 10,619.08925

Timestep Collection Time: 2.29484
Timestep Consumption Time: 2.41592
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.71076

Cumulative Model Updates: 165,732
Cumulative Timesteps: 1,382,051,288

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.62592
Value Function Loss: 0.04424

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.32434
Value Function Update Magnitude: 0.46064

Collected Steps per Second: 21,920.64651
Overall Steps per Second: 10,474.86604

Timestep Collection Time: 2.28114
Timestep Consumption Time: 2.49258
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.77371

Cumulative Model Updates: 165,738
Cumulative Timesteps: 1,382,101,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1382101292...
Checkpoint 1382101292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.62049
Value Function Loss: 0.04081

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.33446
Value Function Update Magnitude: 0.41163

Collected Steps per Second: 22,541.25275
Overall Steps per Second: 10,637.88843

Timestep Collection Time: 2.21940
Timestep Consumption Time: 2.48342
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.70281

Cumulative Model Updates: 165,744
Cumulative Timesteps: 1,382,151,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.63594
Value Function Loss: 0.03612

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.31015
Value Function Update Magnitude: 0.30081

Collected Steps per Second: 22,768.23943
Overall Steps per Second: 10,799.90706

Timestep Collection Time: 2.19718
Timestep Consumption Time: 2.43489
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.63208

Cumulative Model Updates: 165,750
Cumulative Timesteps: 1,382,201,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1382201346...
Checkpoint 1382201346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.64375
Value Function Loss: 0.03357

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.26599
Value Function Update Magnitude: 0.20984

Collected Steps per Second: 22,605.11605
Overall Steps per Second: 10,709.42365

Timestep Collection Time: 2.21322
Timestep Consumption Time: 2.45837
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.67159

Cumulative Model Updates: 165,756
Cumulative Timesteps: 1,382,251,376

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.64691
Value Function Loss: 0.03441

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.25093
Value Function Update Magnitude: 0.19918

Collected Steps per Second: 22,769.60396
Overall Steps per Second: 10,604.17504

Timestep Collection Time: 2.19626
Timestep Consumption Time: 2.51962
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.71588

Cumulative Model Updates: 165,762
Cumulative Timesteps: 1,382,301,384

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1382301384...
Checkpoint 1382301384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,930.81700
Policy Entropy: 3.64475
Value Function Loss: 0.03470

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13803
Policy Update Magnitude: 0.26754
Value Function Update Magnitude: 0.29333

Collected Steps per Second: 22,637.82998
Overall Steps per Second: 10,568.89205

Timestep Collection Time: 2.20931
Timestep Consumption Time: 2.52288
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.73219

Cumulative Model Updates: 165,768
Cumulative Timesteps: 1,382,351,398

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757,250.60455
Policy Entropy: 3.63722
Value Function Loss: 0.04215

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.30742
Value Function Update Magnitude: 0.40212

Collected Steps per Second: 22,595.65842
Overall Steps per Second: 10,527.84648

Timestep Collection Time: 2.21370
Timestep Consumption Time: 2.53751
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.75121

Cumulative Model Updates: 165,774
Cumulative Timesteps: 1,382,401,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1382401418...
Checkpoint 1382401418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709,533.95230
Policy Entropy: 3.63816
Value Function Loss: 0.04989

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.41719
Value Function Update Magnitude: 0.62871

Collected Steps per Second: 22,551.48464
Overall Steps per Second: 10,518.22803

Timestep Collection Time: 2.21733
Timestep Consumption Time: 2.53671
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.75403

Cumulative Model Updates: 165,780
Cumulative Timesteps: 1,382,451,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305,461.70071
Policy Entropy: 3.63718
Value Function Loss: 0.05316

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.47458
Value Function Update Magnitude: 0.73088

Collected Steps per Second: 22,450.87256
Overall Steps per Second: 10,517.77477

Timestep Collection Time: 2.22780
Timestep Consumption Time: 2.52758
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.75538

Cumulative Model Updates: 165,786
Cumulative Timesteps: 1,382,501,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1382501438...
Checkpoint 1382501438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305,461.70071
Policy Entropy: 3.64413
Value Function Loss: 0.04916

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.47213
Value Function Update Magnitude: 0.65450

Collected Steps per Second: 22,425.59747
Overall Steps per Second: 10,588.03601

Timestep Collection Time: 2.22960
Timestep Consumption Time: 2.49272
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.72231

Cumulative Model Updates: 165,792
Cumulative Timesteps: 1,382,551,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305,461.70071
Policy Entropy: 3.63686
Value Function Loss: 0.04800

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.45382
Value Function Update Magnitude: 0.46173

Collected Steps per Second: 22,246.69567
Overall Steps per Second: 10,474.92131

Timestep Collection Time: 2.24851
Timestep Consumption Time: 2.52689
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.77541

Cumulative Model Updates: 165,798
Cumulative Timesteps: 1,382,601,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1382601460...
Checkpoint 1382601460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728,746.96816
Policy Entropy: 3.62035
Value Function Loss: 0.04663

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.44049
Value Function Update Magnitude: 0.45396

Collected Steps per Second: 21,609.46168
Overall Steps per Second: 10,615.48575

Timestep Collection Time: 2.31491
Timestep Consumption Time: 2.39745
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.71236

Cumulative Model Updates: 165,804
Cumulative Timesteps: 1,382,651,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728,746.96816
Policy Entropy: 3.63443
Value Function Loss: 0.04587

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.50603
Value Function Update Magnitude: 0.47536

Collected Steps per Second: 21,701.44915
Overall Steps per Second: 10,548.57882

Timestep Collection Time: 2.30492
Timestep Consumption Time: 2.43696
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.74187

Cumulative Model Updates: 165,810
Cumulative Timesteps: 1,382,701,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1382701504...
Checkpoint 1382701504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019,608.48739
Policy Entropy: 3.63868
Value Function Loss: 0.04935

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.50996
Value Function Update Magnitude: 0.43309

Collected Steps per Second: 21,897.11246
Overall Steps per Second: 10,541.63342

Timestep Collection Time: 2.28468
Timestep Consumption Time: 2.46107
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.74575

Cumulative Model Updates: 165,816
Cumulative Timesteps: 1,382,751,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019,608.48739
Policy Entropy: 3.63573
Value Function Loss: 0.04624

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.18103
Policy Update Magnitude: 0.45130
Value Function Update Magnitude: 0.49678

Collected Steps per Second: 22,667.55071
Overall Steps per Second: 10,820.79645

Timestep Collection Time: 2.20712
Timestep Consumption Time: 2.41638
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.62350

Cumulative Model Updates: 165,822
Cumulative Timesteps: 1,382,801,562

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1382801562...
Checkpoint 1382801562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.62981
Value Function Loss: 0.05268

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.16311
Policy Update Magnitude: 0.47839
Value Function Update Magnitude: 0.48591

Collected Steps per Second: 22,181.45325
Overall Steps per Second: 10,688.21324

Timestep Collection Time: 2.25504
Timestep Consumption Time: 2.42488
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.67992

Cumulative Model Updates: 165,828
Cumulative Timesteps: 1,382,851,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.62248
Value Function Loss: 0.05145

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.57860
Value Function Update Magnitude: 0.55508

Collected Steps per Second: 22,580.48892
Overall Steps per Second: 10,537.08906

Timestep Collection Time: 2.21536
Timestep Consumption Time: 2.53206
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.74742

Cumulative Model Updates: 165,834
Cumulative Timesteps: 1,382,901,606

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1382901606...
Checkpoint 1382901606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.64664
Value Function Loss: 0.04809

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.62901
Value Function Update Magnitude: 0.48790

Collected Steps per Second: 22,276.99428
Overall Steps per Second: 10,577.82182

Timestep Collection Time: 2.24474
Timestep Consumption Time: 2.48270
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.72744

Cumulative Model Updates: 165,840
Cumulative Timesteps: 1,382,951,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.67052
Value Function Loss: 0.04068

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.15849
Policy Update Magnitude: 0.52410
Value Function Update Magnitude: 0.46389

Collected Steps per Second: 22,697.56668
Overall Steps per Second: 10,373.32414

Timestep Collection Time: 2.20341
Timestep Consumption Time: 2.61780
PPO Batch Consumption Time: 0.30712
Total Iteration Time: 4.82121

Cumulative Model Updates: 165,846
Cumulative Timesteps: 1,383,001,624

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1383001624...
Checkpoint 1383001624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.68965
Value Function Loss: 0.03505

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.22914
Policy Update Magnitude: 0.37726
Value Function Update Magnitude: 0.36190

Collected Steps per Second: 19,353.04154
Overall Steps per Second: 9,643.30958

Timestep Collection Time: 2.58399
Timestep Consumption Time: 2.60178
PPO Batch Consumption Time: 0.29798
Total Iteration Time: 5.18577

Cumulative Model Updates: 165,852
Cumulative Timesteps: 1,383,051,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.69818
Value Function Loss: 0.04634

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.15637
Policy Update Magnitude: 0.28638
Value Function Update Magnitude: 0.26568

Collected Steps per Second: 22,883.61442
Overall Steps per Second: 10,822.00799

Timestep Collection Time: 2.18637
Timestep Consumption Time: 2.43680
PPO Batch Consumption Time: 0.27688
Total Iteration Time: 4.62317

Cumulative Model Updates: 165,858
Cumulative Timesteps: 1,383,101,664

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1383101664...
Checkpoint 1383101664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.68357
Value Function Loss: 0.05057

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.18484
Policy Update Magnitude: 0.27202
Value Function Update Magnitude: 0.20694

Collected Steps per Second: 21,864.20158
Overall Steps per Second: 10,618.27038

Timestep Collection Time: 2.28812
Timestep Consumption Time: 2.42338
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.71150

Cumulative Model Updates: 165,864
Cumulative Timesteps: 1,383,151,692

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.69126
Value Function Loss: 0.06368

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.16649
Policy Update Magnitude: 0.27401
Value Function Update Magnitude: 0.21854

Collected Steps per Second: 22,176.20020
Overall Steps per Second: 10,403.74348

Timestep Collection Time: 2.25467
Timestep Consumption Time: 2.55129
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.80596

Cumulative Model Updates: 165,870
Cumulative Timesteps: 1,383,201,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1383201692...
Checkpoint 1383201692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.68077
Value Function Loss: 0.05225

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.15346
Policy Update Magnitude: 0.26325
Value Function Update Magnitude: 0.19502

Collected Steps per Second: 21,504.93710
Overall Steps per Second: 10,297.22924

Timestep Collection Time: 2.32561
Timestep Consumption Time: 2.53123
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.85684

Cumulative Model Updates: 165,876
Cumulative Timesteps: 1,383,251,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.68012
Value Function Loss: 0.05173

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.14682
Policy Update Magnitude: 0.39493
Value Function Update Magnitude: 0.23944

Collected Steps per Second: 22,401.79293
Overall Steps per Second: 10,528.13291

Timestep Collection Time: 2.23241
Timestep Consumption Time: 2.51772
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.75013

Cumulative Model Updates: 165,882
Cumulative Timesteps: 1,383,301,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1383301714...
Checkpoint 1383301714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.70496
Value Function Loss: 0.06394

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.18029
Policy Update Magnitude: 0.49704
Value Function Update Magnitude: 0.36365

Collected Steps per Second: 21,974.01836
Overall Steps per Second: 10,544.16133

Timestep Collection Time: 2.27596
Timestep Consumption Time: 2.46714
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.74310

Cumulative Model Updates: 165,888
Cumulative Timesteps: 1,383,351,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.68546
Value Function Loss: 0.06268

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.16120
Policy Update Magnitude: 0.64939
Value Function Update Magnitude: 0.38620

Collected Steps per Second: 22,959.74114
Overall Steps per Second: 10,799.32865

Timestep Collection Time: 2.17868
Timestep Consumption Time: 2.45327
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.63195

Cumulative Model Updates: 165,894
Cumulative Timesteps: 1,383,401,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1383401748...
Checkpoint 1383401748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.68371
Value Function Loss: 0.05323

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.20738
Policy Update Magnitude: 0.57941
Value Function Update Magnitude: 0.41980

Collected Steps per Second: 21,629.16352
Overall Steps per Second: 10,668.06098

Timestep Collection Time: 2.31299
Timestep Consumption Time: 2.37652
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.68951

Cumulative Model Updates: 165,900
Cumulative Timesteps: 1,383,451,776

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.69998
Value Function Loss: 0.03862

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.23919
Policy Update Magnitude: 0.42586
Value Function Update Magnitude: 0.37578

Collected Steps per Second: 22,042.49147
Overall Steps per Second: 10,628.11971

Timestep Collection Time: 2.27071
Timestep Consumption Time: 2.43869
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.70939

Cumulative Model Updates: 165,906
Cumulative Timesteps: 1,383,501,828

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1383501828...
Checkpoint 1383501828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.68950
Value Function Loss: 0.03354

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.17446
Policy Update Magnitude: 0.37631
Value Function Update Magnitude: 0.35397

Collected Steps per Second: 21,774.94638
Overall Steps per Second: 10,597.58598

Timestep Collection Time: 2.29658
Timestep Consumption Time: 2.42223
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.71881

Cumulative Model Updates: 165,912
Cumulative Timesteps: 1,383,551,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.68709
Value Function Loss: 0.03773

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.17734
Policy Update Magnitude: 0.41074
Value Function Update Magnitude: 0.48418

Collected Steps per Second: 22,663.09848
Overall Steps per Second: 10,793.53477

Timestep Collection Time: 2.20702
Timestep Consumption Time: 2.42705
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.63407

Cumulative Model Updates: 165,918
Cumulative Timesteps: 1,383,601,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1383601854...
Checkpoint 1383601854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.66764
Value Function Loss: 0.04265

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.16151
Policy Update Magnitude: 0.35759
Value Function Update Magnitude: 0.48077

Collected Steps per Second: 22,385.28848
Overall Steps per Second: 10,756.64900

Timestep Collection Time: 2.23540
Timestep Consumption Time: 2.41661
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.65201

Cumulative Model Updates: 165,924
Cumulative Timesteps: 1,383,651,894

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.67853
Value Function Loss: 0.04368

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.16585
Policy Update Magnitude: 0.30752
Value Function Update Magnitude: 0.33630

Collected Steps per Second: 22,815.99857
Overall Steps per Second: 10,772.36194

Timestep Collection Time: 2.19215
Timestep Consumption Time: 2.45085
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.64299

Cumulative Model Updates: 165,930
Cumulative Timesteps: 1,383,701,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1383701910...
Checkpoint 1383701910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.65551
Value Function Loss: 0.04182

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.15782
Policy Update Magnitude: 0.30736
Value Function Update Magnitude: 0.25898

Collected Steps per Second: 22,338.03152
Overall Steps per Second: 10,677.19518

Timestep Collection Time: 2.23968
Timestep Consumption Time: 2.44601
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.68569

Cumulative Model Updates: 165,936
Cumulative Timesteps: 1,383,751,940

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.66489
Value Function Loss: 0.03792

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.28311
Value Function Update Magnitude: 0.22000

Collected Steps per Second: 22,724.09907
Overall Steps per Second: 10,578.51117

Timestep Collection Time: 2.20136
Timestep Consumption Time: 2.52747
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.72883

Cumulative Model Updates: 165,942
Cumulative Timesteps: 1,383,801,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1383801964...
Checkpoint 1383801964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.65634
Value Function Loss: 0.03733

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.24556
Value Function Update Magnitude: 0.18461

Collected Steps per Second: 22,467.01434
Overall Steps per Second: 10,564.94717

Timestep Collection Time: 2.22664
Timestep Consumption Time: 2.50845
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.73509

Cumulative Model Updates: 165,948
Cumulative Timesteps: 1,383,851,990

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.64401
Value Function Loss: 0.03268

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.21762
Value Function Update Magnitude: 0.13628

Collected Steps per Second: 22,472.89643
Overall Steps per Second: 10,543.69811

Timestep Collection Time: 2.22597
Timestep Consumption Time: 2.51848
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.74445

Cumulative Model Updates: 165,954
Cumulative Timesteps: 1,383,902,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1383902014...
Checkpoint 1383902014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.64958
Value Function Loss: 0.03342

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.21998
Value Function Update Magnitude: 0.15702

Collected Steps per Second: 22,519.66846
Overall Steps per Second: 10,558.60484

Timestep Collection Time: 2.22064
Timestep Consumption Time: 2.51560
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.73623

Cumulative Model Updates: 165,960
Cumulative Timesteps: 1,383,952,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.65621
Value Function Loss: 0.03591

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.26091
Value Function Update Magnitude: 0.21867

Collected Steps per Second: 22,919.89511
Overall Steps per Second: 10,824.55387

Timestep Collection Time: 2.18230
Timestep Consumption Time: 2.43849
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.62079

Cumulative Model Updates: 165,966
Cumulative Timesteps: 1,384,002,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1384002040...
Checkpoint 1384002040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.64134
Value Function Loss: 0.03641

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.27489
Value Function Update Magnitude: 0.37733

Collected Steps per Second: 21,746.71913
Overall Steps per Second: 10,720.90554

Timestep Collection Time: 2.29947
Timestep Consumption Time: 2.36487
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.66434

Cumulative Model Updates: 165,972
Cumulative Timesteps: 1,384,052,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.64865
Value Function Loss: 0.03694

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.29667
Value Function Update Magnitude: 0.43063

Collected Steps per Second: 21,771.80302
Overall Steps per Second: 10,545.93940

Timestep Collection Time: 2.29710
Timestep Consumption Time: 2.44520
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.74230

Cumulative Model Updates: 165,978
Cumulative Timesteps: 1,384,102,058

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1384102058...
Checkpoint 1384102058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.62579
Value Function Loss: 0.04860

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.32192
Value Function Update Magnitude: 0.40375

Collected Steps per Second: 21,483.35025
Overall Steps per Second: 10,505.76800

Timestep Collection Time: 2.32813
Timestep Consumption Time: 2.43268
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.76081

Cumulative Model Updates: 165,984
Cumulative Timesteps: 1,384,152,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.64161
Value Function Loss: 0.04910

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13227
Policy Update Magnitude: 0.33374
Value Function Update Magnitude: 0.33411

Collected Steps per Second: 22,841.67614
Overall Steps per Second: 10,718.14851

Timestep Collection Time: 2.19073
Timestep Consumption Time: 2.47798
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.66872

Cumulative Model Updates: 165,990
Cumulative Timesteps: 1,384,202,114

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1384202114...
Checkpoint 1384202114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.63256
Value Function Loss: 0.04559

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.33177
Value Function Update Magnitude: 0.33753

Collected Steps per Second: 22,496.15801
Overall Steps per Second: 10,786.04290

Timestep Collection Time: 2.22385
Timestep Consumption Time: 2.41437
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.63822

Cumulative Model Updates: 165,996
Cumulative Timesteps: 1,384,252,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.65480
Value Function Loss: 0.03552

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13156
Policy Update Magnitude: 0.29950
Value Function Update Magnitude: 0.40980

Collected Steps per Second: 22,551.74089
Overall Steps per Second: 10,560.17219

Timestep Collection Time: 2.21792
Timestep Consumption Time: 2.51855
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.73648

Cumulative Model Updates: 166,002
Cumulative Timesteps: 1,384,302,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1384302160...
Checkpoint 1384302160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218,606.95415
Policy Entropy: 3.64600
Value Function Loss: 0.03620

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.26297
Value Function Update Magnitude: 0.35236

Collected Steps per Second: 22,605.12241
Overall Steps per Second: 10,635.68774

Timestep Collection Time: 2.21277
Timestep Consumption Time: 2.49026
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.70303

Cumulative Model Updates: 166,008
Cumulative Timesteps: 1,384,352,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788,572.05396
Policy Entropy: 3.66534
Value Function Loss: 0.04608

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.32524
Value Function Update Magnitude: 0.44003

Collected Steps per Second: 22,514.29094
Overall Steps per Second: 10,552.68957

Timestep Collection Time: 2.22090
Timestep Consumption Time: 2.51742
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.73832

Cumulative Model Updates: 166,014
Cumulative Timesteps: 1,384,402,182

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1384402182...
Checkpoint 1384402182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517,384.00653
Policy Entropy: 3.66446
Value Function Loss: 0.05096

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.37349
Value Function Update Magnitude: 0.47457

Collected Steps per Second: 22,537.42165
Overall Steps per Second: 10,503.07658

Timestep Collection Time: 2.21898
Timestep Consumption Time: 2.54249
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.76146

Cumulative Model Updates: 166,020
Cumulative Timesteps: 1,384,452,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395,005.48354
Policy Entropy: 3.67102
Value Function Loss: 0.05462

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.39415
Value Function Update Magnitude: 0.47695

Collected Steps per Second: 22,684.13688
Overall Steps per Second: 10,592.18172

Timestep Collection Time: 2.20551
Timestep Consumption Time: 2.51779
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.72330

Cumulative Model Updates: 166,026
Cumulative Timesteps: 1,384,502,222

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1384502222...
Checkpoint 1384502222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,005.48354
Policy Entropy: 3.65462
Value Function Loss: 0.04963

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.41751
Value Function Update Magnitude: 0.52123

Collected Steps per Second: 22,775.54496
Overall Steps per Second: 10,634.07868

Timestep Collection Time: 2.19630
Timestep Consumption Time: 2.50763
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.70393

Cumulative Model Updates: 166,032
Cumulative Timesteps: 1,384,552,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395,005.48354
Policy Entropy: 3.64808
Value Function Loss: 0.04326

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.38913
Value Function Update Magnitude: 0.45017

Collected Steps per Second: 22,663.96686
Overall Steps per Second: 10,732.47995

Timestep Collection Time: 2.20667
Timestep Consumption Time: 2.45320
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.65987

Cumulative Model Updates: 166,038
Cumulative Timesteps: 1,384,602,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1384602256...
Checkpoint 1384602256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,005.48354
Policy Entropy: 3.66037
Value Function Loss: 0.03457

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.32903
Value Function Update Magnitude: 0.36984

Collected Steps per Second: 22,292.83845
Overall Steps per Second: 10,627.32365

Timestep Collection Time: 2.24314
Timestep Consumption Time: 2.46228
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.70542

Cumulative Model Updates: 166,044
Cumulative Timesteps: 1,384,652,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395,005.48354
Policy Entropy: 3.64407
Value Function Loss: 0.03743

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.27696
Value Function Update Magnitude: 0.31973

Collected Steps per Second: 22,447.26810
Overall Steps per Second: 10,560.54504

Timestep Collection Time: 2.22922
Timestep Consumption Time: 2.50917
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.73839

Cumulative Model Updates: 166,050
Cumulative Timesteps: 1,384,702,302

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1384702302...
Checkpoint 1384702302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,005.48354
Policy Entropy: 3.65032
Value Function Loss: 0.03760

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13609
Policy Update Magnitude: 0.29075
Value Function Update Magnitude: 0.31659

Collected Steps per Second: 22,453.73565
Overall Steps per Second: 10,651.28233

Timestep Collection Time: 2.22698
Timestep Consumption Time: 2.46767
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.69465

Cumulative Model Updates: 166,056
Cumulative Timesteps: 1,384,752,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395,005.48354
Policy Entropy: 3.62799
Value Function Loss: 0.04729

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.29594
Value Function Update Magnitude: 0.29109

Collected Steps per Second: 22,208.84403
Overall Steps per Second: 10,810.44095

Timestep Collection Time: 2.25226
Timestep Consumption Time: 2.37475
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.62701

Cumulative Model Updates: 166,062
Cumulative Timesteps: 1,384,802,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1384802326...
Checkpoint 1384802326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,005.48354
Policy Entropy: 3.65582
Value Function Loss: 0.04192

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.28276
Value Function Update Magnitude: 0.22224

Collected Steps per Second: 21,637.11304
Overall Steps per Second: 10,670.50182

Timestep Collection Time: 2.31131
Timestep Consumption Time: 2.37545
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.68675

Cumulative Model Updates: 166,068
Cumulative Timesteps: 1,384,852,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395,005.48354
Policy Entropy: 3.63547
Value Function Loss: 0.04182

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.14734
Policy Update Magnitude: 0.29682
Value Function Update Magnitude: 0.26136

Collected Steps per Second: 22,112.98691
Overall Steps per Second: 10,493.74074

Timestep Collection Time: 2.26130
Timestep Consumption Time: 2.50383
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.76513

Cumulative Model Updates: 166,074
Cumulative Timesteps: 1,384,902,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1384902340...
Checkpoint 1384902340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746,603.17001
Policy Entropy: 3.66002
Value Function Loss: 0.04417

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.30843
Value Function Update Magnitude: 0.30770

Collected Steps per Second: 22,017.81705
Overall Steps per Second: 10,678.16786

Timestep Collection Time: 2.27125
Timestep Consumption Time: 2.41195
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.68320

Cumulative Model Updates: 166,080
Cumulative Timesteps: 1,384,952,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.64735
Value Function Loss: 0.04710

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.32382
Value Function Update Magnitude: 0.40392

Collected Steps per Second: 22,783.68580
Overall Steps per Second: 10,797.52753

Timestep Collection Time: 2.19473
Timestep Consumption Time: 2.43633
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.63106

Cumulative Model Updates: 166,086
Cumulative Timesteps: 1,385,002,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1385002352...
Checkpoint 1385002352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.65438
Value Function Loss: 0.04896

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.34491
Value Function Update Magnitude: 0.42524

Collected Steps per Second: 22,308.94256
Overall Steps per Second: 10,651.64277

Timestep Collection Time: 2.24305
Timestep Consumption Time: 2.45482
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.69787

Cumulative Model Updates: 166,092
Cumulative Timesteps: 1,385,052,392

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.64294
Value Function Loss: 0.04890

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.34658
Value Function Update Magnitude: 0.36493

Collected Steps per Second: 22,581.85720
Overall Steps per Second: 10,527.39873

Timestep Collection Time: 2.21541
Timestep Consumption Time: 2.53676
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.75217

Cumulative Model Updates: 166,098
Cumulative Timesteps: 1,385,102,420

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1385102420...
Checkpoint 1385102420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.66892
Value Function Loss: 0.04180

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.31728
Value Function Update Magnitude: 0.34052

Collected Steps per Second: 22,592.10612
Overall Steps per Second: 10,659.99025

Timestep Collection Time: 2.21414
Timestep Consumption Time: 2.47836
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.69250

Cumulative Model Updates: 166,104
Cumulative Timesteps: 1,385,152,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.65736
Value Function Loss: 0.03831

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13711
Policy Update Magnitude: 0.29094
Value Function Update Magnitude: 0.35304

Collected Steps per Second: 22,938.10265
Overall Steps per Second: 10,787.87240

Timestep Collection Time: 2.18117
Timestep Consumption Time: 2.45663
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.63780

Cumulative Model Updates: 166,110
Cumulative Timesteps: 1,385,202,474

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1385202474...
Checkpoint 1385202474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.67195
Value Function Loss: 0.03215

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.25674
Value Function Update Magnitude: 0.27822

Collected Steps per Second: 22,422.63150
Overall Steps per Second: 10,657.59287

Timestep Collection Time: 2.23034
Timestep Consumption Time: 2.46209
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.69243

Cumulative Model Updates: 166,116
Cumulative Timesteps: 1,385,252,484

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.65673
Value Function Loss: 0.03324

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.26152
Value Function Update Magnitude: 0.26527

Collected Steps per Second: 22,701.92789
Overall Steps per Second: 10,580.37129

Timestep Collection Time: 2.20343
Timestep Consumption Time: 2.52439
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.72781

Cumulative Model Updates: 166,122
Cumulative Timesteps: 1,385,302,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1385302506...
Checkpoint 1385302506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.67204
Value Function Loss: 0.03197

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.27739
Value Function Update Magnitude: 0.33965

Collected Steps per Second: 22,487.36911
Overall Steps per Second: 10,598.78765

Timestep Collection Time: 2.22480
Timestep Consumption Time: 2.49555
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.72035

Cumulative Model Updates: 166,128
Cumulative Timesteps: 1,385,352,536

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.67306
Value Function Loss: 0.03223

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.27904
Value Function Update Magnitude: 0.30715

Collected Steps per Second: 22,723.96178
Overall Steps per Second: 10,639.32668

Timestep Collection Time: 2.20138
Timestep Consumption Time: 2.50042
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.70180

Cumulative Model Updates: 166,134
Cumulative Timesteps: 1,385,402,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1385402560...
Checkpoint 1385402560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.67909
Value Function Loss: 0.03070

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.26867
Value Function Update Magnitude: 0.26783

Collected Steps per Second: 21,685.23804
Overall Steps per Second: 10,558.09591

Timestep Collection Time: 2.30608
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.73646

Cumulative Model Updates: 166,140
Cumulative Timesteps: 1,385,452,568

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.66628
Value Function Loss: 0.03076

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.30883
Value Function Update Magnitude: 0.33372

Collected Steps per Second: 22,045.34376
Overall Steps per Second: 10,823.15241

Timestep Collection Time: 2.26914
Timestep Consumption Time: 2.35280
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.62194

Cumulative Model Updates: 166,146
Cumulative Timesteps: 1,385,502,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1385502592...
Checkpoint 1385502592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.63659
Value Function Loss: 0.03555

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.34305
Value Function Update Magnitude: 0.41623

Collected Steps per Second: 21,754.00987
Overall Steps per Second: 10,572.71418

Timestep Collection Time: 2.30008
Timestep Consumption Time: 2.43248
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.73256

Cumulative Model Updates: 166,152
Cumulative Timesteps: 1,385,552,628

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.64688
Value Function Loss: 0.03671

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.35663
Value Function Update Magnitude: 0.35954

Collected Steps per Second: 22,562.10645
Overall Steps per Second: 10,642.97548

Timestep Collection Time: 2.21743
Timestep Consumption Time: 2.48332
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.70075

Cumulative Model Updates: 166,158
Cumulative Timesteps: 1,385,602,658

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1385602658...
Checkpoint 1385602658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.63282
Value Function Loss: 0.04387

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13765
Policy Update Magnitude: 0.33837
Value Function Update Magnitude: 0.40025

Collected Steps per Second: 22,414.67982
Overall Steps per Second: 10,598.90959

Timestep Collection Time: 2.23139
Timestep Consumption Time: 2.48758
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.71898

Cumulative Model Updates: 166,164
Cumulative Timesteps: 1,385,652,674

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.64872
Value Function Loss: 0.04065

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.35160
Value Function Update Magnitude: 0.37381

Collected Steps per Second: 22,949.85748
Overall Steps per Second: 10,766.98387

Timestep Collection Time: 2.17910
Timestep Consumption Time: 2.46566
PPO Batch Consumption Time: 0.28192
Total Iteration Time: 4.64475

Cumulative Model Updates: 166,170
Cumulative Timesteps: 1,385,702,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1385702684...
Checkpoint 1385702684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.64134
Value Function Loss: 0.03692

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.34537
Value Function Update Magnitude: 0.37640

Collected Steps per Second: 22,245.71518
Overall Steps per Second: 10,616.53387

Timestep Collection Time: 2.24852
Timestep Consumption Time: 2.46300
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.71152

Cumulative Model Updates: 166,176
Cumulative Timesteps: 1,385,752,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.65533
Value Function Loss: 0.03302

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.30425
Value Function Update Magnitude: 0.35931

Collected Steps per Second: 22,705.32803
Overall Steps per Second: 10,561.66000

Timestep Collection Time: 2.20213
Timestep Consumption Time: 2.53198
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.73410

Cumulative Model Updates: 166,182
Cumulative Timesteps: 1,385,802,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1385802704...
Checkpoint 1385802704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.65959
Value Function Loss: 0.03250

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.27700
Value Function Update Magnitude: 0.25583

Collected Steps per Second: 21,833.76751
Overall Steps per Second: 10,532.03744

Timestep Collection Time: 2.29031
Timestep Consumption Time: 2.45768
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.74799

Cumulative Model Updates: 166,188
Cumulative Timesteps: 1,385,852,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.65184
Value Function Loss: 0.03271

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13778
Policy Update Magnitude: 0.30234
Value Function Update Magnitude: 0.27024

Collected Steps per Second: 22,735.08211
Overall Steps per Second: 10,597.46869

Timestep Collection Time: 2.19986
Timestep Consumption Time: 2.51957
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.71943

Cumulative Model Updates: 166,194
Cumulative Timesteps: 1,385,902,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1385902724...
Checkpoint 1385902724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.66599
Value Function Loss: 0.03096

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14730
Policy Update Magnitude: 0.31002
Value Function Update Magnitude: 0.38821

Collected Steps per Second: 22,399.01596
Overall Steps per Second: 10,556.18162

Timestep Collection Time: 2.23242
Timestep Consumption Time: 2.50452
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.73694

Cumulative Model Updates: 166,200
Cumulative Timesteps: 1,385,952,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.64740
Value Function Loss: 0.03718

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15189
Policy Update Magnitude: 0.33472
Value Function Update Magnitude: 0.39106

Collected Steps per Second: 22,932.13274
Overall Steps per Second: 10,802.53103

Timestep Collection Time: 2.18096
Timestep Consumption Time: 2.44888
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.62984

Cumulative Model Updates: 166,206
Cumulative Timesteps: 1,386,002,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1386002742...
Checkpoint 1386002742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.65501
Value Function Loss: 0.03704

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.15054
Policy Update Magnitude: 0.36877
Value Function Update Magnitude: 0.38507

Collected Steps per Second: 21,790.75482
Overall Steps per Second: 10,689.08802

Timestep Collection Time: 2.29547
Timestep Consumption Time: 2.38407
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.67954

Cumulative Model Updates: 166,212
Cumulative Timesteps: 1,386,052,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.64186
Value Function Loss: 0.03815

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.37912
Value Function Update Magnitude: 0.36141

Collected Steps per Second: 22,031.21981
Overall Steps per Second: 10,630.45261

Timestep Collection Time: 2.27069
Timestep Consumption Time: 2.43523
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.70591

Cumulative Model Updates: 166,218
Cumulative Timesteps: 1,386,102,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1386102788...
Checkpoint 1386102788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.66100
Value Function Loss: 0.03640

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.40125
Value Function Update Magnitude: 0.34472

Collected Steps per Second: 21,667.21892
Overall Steps per Second: 10,494.22217

Timestep Collection Time: 2.30782
Timestep Consumption Time: 2.45709
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.76491

Cumulative Model Updates: 166,224
Cumulative Timesteps: 1,386,152,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.66645
Value Function Loss: 0.03286

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.40184
Value Function Update Magnitude: 0.28684

Collected Steps per Second: 22,686.70816
Overall Steps per Second: 10,650.33853

Timestep Collection Time: 2.20429
Timestep Consumption Time: 2.49115
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.69544

Cumulative Model Updates: 166,230
Cumulative Timesteps: 1,386,202,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1386202800...
Checkpoint 1386202800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.67273
Value Function Loss: 0.02926

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11938
Policy Update Magnitude: 0.35319
Value Function Update Magnitude: 0.18815

Collected Steps per Second: 22,567.41593
Overall Steps per Second: 10,654.89686

Timestep Collection Time: 2.21691
Timestep Consumption Time: 2.47858
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.69549

Cumulative Model Updates: 166,236
Cumulative Timesteps: 1,386,252,830

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.66283
Value Function Loss: 0.03026

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.45903
Value Function Update Magnitude: 0.21459

Collected Steps per Second: 22,948.80960
Overall Steps per Second: 10,735.96747

Timestep Collection Time: 2.17902
Timestep Consumption Time: 2.47878
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.65780

Cumulative Model Updates: 166,242
Cumulative Timesteps: 1,386,302,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1386302836...
Checkpoint 1386302836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.66090
Value Function Loss: 0.03079

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.53079
Value Function Update Magnitude: 0.34682

Collected Steps per Second: 22,418.47491
Overall Steps per Second: 10,605.38564

Timestep Collection Time: 2.23057
Timestep Consumption Time: 2.48458
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.71515

Cumulative Model Updates: 166,248
Cumulative Timesteps: 1,386,352,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.66495
Value Function Loss: 0.03581

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.50056
Value Function Update Magnitude: 0.40835

Collected Steps per Second: 22,730.88177
Overall Steps per Second: 10,610.30675

Timestep Collection Time: 2.19965
Timestep Consumption Time: 2.51275
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.71240

Cumulative Model Updates: 166,254
Cumulative Timesteps: 1,386,402,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1386402842...
Checkpoint 1386402842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.66757
Value Function Loss: 0.04041

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.62681
Value Function Update Magnitude: 0.40499

Collected Steps per Second: 22,398.20263
Overall Steps per Second: 10,492.80437

Timestep Collection Time: 2.23330
Timestep Consumption Time: 2.53396
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.76727

Cumulative Model Updates: 166,260
Cumulative Timesteps: 1,386,452,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.67298
Value Function Loss: 0.04044

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12342
Policy Update Magnitude: 0.69003
Value Function Update Magnitude: 0.50453

Collected Steps per Second: 22,649.40308
Overall Steps per Second: 10,605.06766

Timestep Collection Time: 2.20765
Timestep Consumption Time: 2.50726
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.71492

Cumulative Model Updates: 166,266
Cumulative Timesteps: 1,386,502,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1386502866...
Checkpoint 1386502866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.67883
Value Function Loss: 0.03729

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.14597
Policy Update Magnitude: 0.62644
Value Function Update Magnitude: 0.52331

Collected Steps per Second: 22,357.35960
Overall Steps per Second: 10,514.14179

Timestep Collection Time: 2.23649
Timestep Consumption Time: 2.51920
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.75569

Cumulative Model Updates: 166,272
Cumulative Timesteps: 1,386,552,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.67054
Value Function Loss: 0.04714

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.20742
Policy Update Magnitude: 0.45196
Value Function Update Magnitude: 0.41674

Collected Steps per Second: 22,737.34169
Overall Steps per Second: 10,639.62218

Timestep Collection Time: 2.19938
Timestep Consumption Time: 2.50079
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.70017

Cumulative Model Updates: 166,278
Cumulative Timesteps: 1,386,602,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1386602876...
Checkpoint 1386602876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,756.32227
Policy Entropy: 3.64957
Value Function Loss: 0.05303

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.17601
Policy Update Magnitude: 0.40489
Value Function Update Magnitude: 0.31151

Collected Steps per Second: 21,516.97283
Overall Steps per Second: 10,476.38037

Timestep Collection Time: 2.32440
Timestep Consumption Time: 2.44958
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.77398

Cumulative Model Updates: 166,284
Cumulative Timesteps: 1,386,652,890

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238,745.89782
Policy Entropy: 3.65014
Value Function Loss: 0.06020

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.17248
Policy Update Magnitude: 0.42658
Value Function Update Magnitude: 0.30838

Collected Steps per Second: 21,876.01910
Overall Steps per Second: 10,664.03625

Timestep Collection Time: 2.28634
Timestep Consumption Time: 2.40382
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.69016

Cumulative Model Updates: 166,290
Cumulative Timesteps: 1,386,702,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1386702906...
Checkpoint 1386702906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238,745.89782
Policy Entropy: 3.65743
Value Function Loss: 0.05539

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.17096
Policy Update Magnitude: 0.40904
Value Function Update Magnitude: 0.50629

Collected Steps per Second: 21,508.09782
Overall Steps per Second: 10,397.14724

Timestep Collection Time: 2.32480
Timestep Consumption Time: 2.48441
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.80920

Cumulative Model Updates: 166,296
Cumulative Timesteps: 1,386,752,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238,745.89782
Policy Entropy: 3.67018
Value Function Loss: 0.04916

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.16783
Policy Update Magnitude: 0.37925
Value Function Update Magnitude: 0.50198

Collected Steps per Second: 22,698.31761
Overall Steps per Second: 10,802.49122

Timestep Collection Time: 2.20474
Timestep Consumption Time: 2.42789
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.63264

Cumulative Model Updates: 166,302
Cumulative Timesteps: 1,386,802,952

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1386802952...
Checkpoint 1386802952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238,745.89782
Policy Entropy: 3.67849
Value Function Loss: 0.03926

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.15533
Policy Update Magnitude: 0.33830
Value Function Update Magnitude: 0.39553

Collected Steps per Second: 21,925.45390
Overall Steps per Second: 10,442.56589

Timestep Collection Time: 2.28146
Timestep Consumption Time: 2.50874
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.79020

Cumulative Model Updates: 166,308
Cumulative Timesteps: 1,386,852,974

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238,745.89782
Policy Entropy: 3.68161
Value Function Loss: 0.03956

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.29659
Value Function Update Magnitude: 0.31556

Collected Steps per Second: 22,764.02667
Overall Steps per Second: 10,739.57088

Timestep Collection Time: 2.19741
Timestep Consumption Time: 2.46031
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.65773

Cumulative Model Updates: 166,314
Cumulative Timesteps: 1,386,902,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1386902996...
Checkpoint 1386902996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238,745.89782
Policy Entropy: 3.66159
Value Function Loss: 0.03903

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.30885
Value Function Update Magnitude: 0.24460

Collected Steps per Second: 22,496.88519
Overall Steps per Second: 10,720.29329

Timestep Collection Time: 2.22253
Timestep Consumption Time: 2.44152
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.66405

Cumulative Model Updates: 166,320
Cumulative Timesteps: 1,386,952,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238,745.89782
Policy Entropy: 3.66172
Value Function Loss: 0.03863

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.15037
Policy Update Magnitude: 0.29279
Value Function Update Magnitude: 0.20754

Collected Steps per Second: 22,931.66799
Overall Steps per Second: 10,778.42239

Timestep Collection Time: 2.18100
Timestep Consumption Time: 2.45920
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.64020

Cumulative Model Updates: 166,326
Cumulative Timesteps: 1,387,003,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1387003010...
Checkpoint 1387003010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238,745.89782
Policy Entropy: 3.65583
Value Function Loss: 0.03651

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14422
Policy Update Magnitude: 0.29925
Value Function Update Magnitude: 0.24162

Collected Steps per Second: 22,345.43018
Overall Steps per Second: 10,647.80567

Timestep Collection Time: 2.23813
Timestep Consumption Time: 2.45880
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.69693

Cumulative Model Updates: 166,332
Cumulative Timesteps: 1,387,053,022

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238,745.89782
Policy Entropy: 3.66146
Value Function Loss: 0.03092

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.15282
Policy Update Magnitude: 0.33881
Value Function Update Magnitude: 0.23955

Collected Steps per Second: 22,960.63383
Overall Steps per Second: 10,657.69986

Timestep Collection Time: 2.17869
Timestep Consumption Time: 2.51501
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.69370

Cumulative Model Updates: 166,338
Cumulative Timesteps: 1,387,103,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1387103046...
Checkpoint 1387103046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,891,907.54879
Policy Entropy: 3.66627
Value Function Loss: 0.03675

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.16702
Policy Update Magnitude: 0.35946
Value Function Update Magnitude: 0.47938

Collected Steps per Second: 22,371.99602
Overall Steps per Second: 10,496.11893

Timestep Collection Time: 2.23583
Timestep Consumption Time: 2.52974
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.76557

Cumulative Model Updates: 166,344
Cumulative Timesteps: 1,387,153,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081,038.62785
Policy Entropy: 3.67869
Value Function Loss: 0.04251

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.51933
Value Function Update Magnitude: 0.71334

Collected Steps per Second: 22,649.82483
Overall Steps per Second: 10,610.23622

Timestep Collection Time: 2.20841
Timestep Consumption Time: 2.50591
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.71432

Cumulative Model Updates: 166,350
Cumulative Timesteps: 1,387,203,086

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1387203086...
Checkpoint 1387203086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081,038.62785
Policy Entropy: 3.66475
Value Function Loss: 0.04597

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11792
Policy Update Magnitude: 0.62792
Value Function Update Magnitude: 0.72280

Collected Steps per Second: 22,630.80737
Overall Steps per Second: 10,614.97334

Timestep Collection Time: 2.20991
Timestep Consumption Time: 2.50155
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.71146

Cumulative Model Updates: 166,356
Cumulative Timesteps: 1,387,253,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081,038.62785
Policy Entropy: 3.65102
Value Function Loss: 0.05251

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.15748
Policy Update Magnitude: 0.52122
Value Function Update Magnitude: 0.69026

Collected Steps per Second: 22,199.31486
Overall Steps per Second: 10,832.58924

Timestep Collection Time: 2.25313
Timestep Consumption Time: 2.36423
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.61736

Cumulative Model Updates: 166,362
Cumulative Timesteps: 1,387,303,116

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1387303116...
Checkpoint 1387303116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081,038.62785
Policy Entropy: 3.64880
Value Function Loss: 0.04850

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.17814
Policy Update Magnitude: 0.49042
Value Function Update Magnitude: 0.57633

Collected Steps per Second: 21,813.31596
Overall Steps per Second: 10,607.27689

Timestep Collection Time: 2.29264
Timestep Consumption Time: 2.42205
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.71469

Cumulative Model Updates: 166,368
Cumulative Timesteps: 1,387,353,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081,038.62785
Policy Entropy: 3.64722
Value Function Loss: 0.05208

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.16815
Policy Update Magnitude: 0.47222
Value Function Update Magnitude: 0.45930

Collected Steps per Second: 22,480.14887
Overall Steps per Second: 10,619.46767

Timestep Collection Time: 2.22516
Timestep Consumption Time: 2.48524
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.71041

Cumulative Model Updates: 166,374
Cumulative Timesteps: 1,387,403,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1387403148...
Checkpoint 1387403148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081,038.62785
Policy Entropy: 3.65070
Value Function Loss: 0.04618

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.18585
Policy Update Magnitude: 0.42899
Value Function Update Magnitude: 0.40388

Collected Steps per Second: 22,358.44777
Overall Steps per Second: 10,608.97151

Timestep Collection Time: 2.23629
Timestep Consumption Time: 2.47670
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.71299

Cumulative Model Updates: 166,380
Cumulative Timesteps: 1,387,453,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935,119.37754
Policy Entropy: 3.63088
Value Function Loss: 0.06023

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12025
Policy Update Magnitude: 0.45371
Value Function Update Magnitude: 0.38314

Collected Steps per Second: 22,553.45998
Overall Steps per Second: 10,802.52419

Timestep Collection Time: 2.21793
Timestep Consumption Time: 2.41265
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.63058

Cumulative Model Updates: 166,386
Cumulative Timesteps: 1,387,503,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1387503170...
Checkpoint 1387503170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935,119.37754
Policy Entropy: 3.65806
Value Function Loss: 0.05772

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15180
Policy Update Magnitude: 0.52618
Value Function Update Magnitude: 0.44966

Collected Steps per Second: 22,027.97009
Overall Steps per Second: 10,575.81823

Timestep Collection Time: 2.27084
Timestep Consumption Time: 2.45901
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.72985

Cumulative Model Updates: 166,392
Cumulative Timesteps: 1,387,553,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935,119.37754
Policy Entropy: 3.68357
Value Function Loss: 0.05534

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.17203
Policy Update Magnitude: 0.49546
Value Function Update Magnitude: 0.40945

Collected Steps per Second: 22,643.52721
Overall Steps per Second: 10,559.05434

Timestep Collection Time: 2.20867
Timestep Consumption Time: 2.52774
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.73641

Cumulative Model Updates: 166,398
Cumulative Timesteps: 1,387,603,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1387603204...
Checkpoint 1387603204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935,119.37754
Policy Entropy: 3.71033
Value Function Loss: 0.04854

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.17478
Policy Update Magnitude: 0.41657
Value Function Update Magnitude: 0.39484

Collected Steps per Second: 21,977.77870
Overall Steps per Second: 10,577.96706

Timestep Collection Time: 2.27657
Timestep Consumption Time: 2.45345
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.73002

Cumulative Model Updates: 166,404
Cumulative Timesteps: 1,387,653,238

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935,119.37754
Policy Entropy: 3.69364
Value Function Loss: 0.04951

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.17522
Policy Update Magnitude: 0.46908
Value Function Update Magnitude: 0.50518

Collected Steps per Second: 22,783.47071
Overall Steps per Second: 10,645.67471

Timestep Collection Time: 2.19536
Timestep Consumption Time: 2.50307
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.69843

Cumulative Model Updates: 166,410
Cumulative Timesteps: 1,387,703,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1387703256...
Checkpoint 1387703256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935,119.37754
Policy Entropy: 3.69430
Value Function Loss: 0.05426

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.23674
Policy Update Magnitude: 0.61008
Value Function Update Magnitude: 0.59584

Collected Steps per Second: 22,331.68649
Overall Steps per Second: 10,503.19255

Timestep Collection Time: 2.23978
Timestep Consumption Time: 2.52239
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.76217

Cumulative Model Updates: 166,416
Cumulative Timesteps: 1,387,753,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319,124.64256
Policy Entropy: 3.69555
Value Function Loss: 0.07402

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.23938
Policy Update Magnitude: 0.61517
Value Function Update Magnitude: 0.68468

Collected Steps per Second: 22,435.70417
Overall Steps per Second: 10,546.73611

Timestep Collection Time: 2.22895
Timestep Consumption Time: 2.51261
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.74156

Cumulative Model Updates: 166,422
Cumulative Timesteps: 1,387,803,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1387803282...
Checkpoint 1387803282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,956.41658
Policy Entropy: 3.75535
Value Function Loss: 0.08696

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.16044
Policy Update Magnitude: 0.88492
Value Function Update Magnitude: 0.73445

Collected Steps per Second: 22,203.83445
Overall Steps per Second: 10,478.07012

Timestep Collection Time: 2.25258
Timestep Consumption Time: 2.52081
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.77340

Cumulative Model Updates: 166,428
Cumulative Timesteps: 1,387,853,298

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,389.40790
Policy Entropy: 3.76127
Value Function Loss: 0.09582

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.18626
Policy Update Magnitude: 0.77142
Value Function Update Magnitude: 0.64277

Collected Steps per Second: 22,593.60224
Overall Steps per Second: 10,541.12514

Timestep Collection Time: 2.21364
Timestep Consumption Time: 2.53102
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.74465

Cumulative Model Updates: 166,434
Cumulative Timesteps: 1,387,903,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1387903312...
Checkpoint 1387903312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,936.59604
Policy Entropy: 3.74758
Value Function Loss: 0.06958

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.17788
Policy Update Magnitude: 0.64749
Value Function Update Magnitude: 0.71049

Collected Steps per Second: 22,206.28761
Overall Steps per Second: 10,559.15201

Timestep Collection Time: 2.25324
Timestep Consumption Time: 2.48540
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.73864

Cumulative Model Updates: 166,440
Cumulative Timesteps: 1,387,953,348

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,936.59604
Policy Entropy: 3.71386
Value Function Loss: 0.05513

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.16693
Policy Update Magnitude: 0.53523
Value Function Update Magnitude: 0.72228

Collected Steps per Second: 22,728.67531
Overall Steps per Second: 10,613.87744

Timestep Collection Time: 2.20048
Timestep Consumption Time: 2.51165
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.71213

Cumulative Model Updates: 166,446
Cumulative Timesteps: 1,388,003,362

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1388003362...
Checkpoint 1388003362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,936.59604
Policy Entropy: 3.69233
Value Function Loss: 0.04530

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.16285
Policy Update Magnitude: 0.46691
Value Function Update Magnitude: 0.61934

Collected Steps per Second: 21,814.77767
Overall Steps per Second: 10,554.60093

Timestep Collection Time: 2.29239
Timestep Consumption Time: 2.44564
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.73803

Cumulative Model Updates: 166,452
Cumulative Timesteps: 1,388,053,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,936.59604
Policy Entropy: 3.67604
Value Function Loss: 0.04675

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.16119
Policy Update Magnitude: 0.41397
Value Function Update Magnitude: 0.50568

Collected Steps per Second: 22,060.84818
Overall Steps per Second: 10,770.05436

Timestep Collection Time: 2.26655
Timestep Consumption Time: 2.37614
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.64269

Cumulative Model Updates: 166,458
Cumulative Timesteps: 1,388,103,372

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1388103372...
Checkpoint 1388103372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,936.59604
Policy Entropy: 3.68916
Value Function Loss: 0.03798

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.15894
Policy Update Magnitude: 0.38393
Value Function Update Magnitude: 0.51779

Collected Steps per Second: 21,422.78951
Overall Steps per Second: 10,619.58395

Timestep Collection Time: 2.33462
Timestep Consumption Time: 2.37498
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.70960

Cumulative Model Updates: 166,464
Cumulative Timesteps: 1,388,153,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,936.59604
Policy Entropy: 3.68154
Value Function Loss: 0.03479

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14471
Policy Update Magnitude: 0.35844
Value Function Update Magnitude: 0.48354

Collected Steps per Second: 22,134.18961
Overall Steps per Second: 10,527.89260

Timestep Collection Time: 2.25949
Timestep Consumption Time: 2.49094
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.75043

Cumulative Model Updates: 166,470
Cumulative Timesteps: 1,388,203,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1388203398...
Checkpoint 1388203398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,936.59604
Policy Entropy: 3.66559
Value Function Loss: 0.03192

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.31871
Value Function Update Magnitude: 0.37630

Collected Steps per Second: 22,232.67530
Overall Steps per Second: 10,673.05861

Timestep Collection Time: 2.24984
Timestep Consumption Time: 2.43672
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.68657

Cumulative Model Updates: 166,476
Cumulative Timesteps: 1,388,253,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,936.59604
Policy Entropy: 3.62273
Value Function Loss: 0.05143

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.38228
Value Function Update Magnitude: 0.44717

Collected Steps per Second: 22,846.79194
Overall Steps per Second: 10,801.35882

Timestep Collection Time: 2.18945
Timestep Consumption Time: 2.44163
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.63108

Cumulative Model Updates: 166,482
Cumulative Timesteps: 1,388,303,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1388303440...
Checkpoint 1388303440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,936.59604
Policy Entropy: 3.62887
Value Function Loss: 0.05413

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.51855
Value Function Update Magnitude: 0.56701

Collected Steps per Second: 22,452.41037
Overall Steps per Second: 10,694.03304

Timestep Collection Time: 2.22809
Timestep Consumption Time: 2.44985
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.67794

Cumulative Model Updates: 166,488
Cumulative Timesteps: 1,388,353,466

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.64188
Value Function Loss: 0.06161

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.15310
Policy Update Magnitude: 0.53084
Value Function Update Magnitude: 0.56965

Collected Steps per Second: 22,995.10614
Overall Steps per Second: 10,681.09970

Timestep Collection Time: 2.17507
Timestep Consumption Time: 2.50759
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.68266

Cumulative Model Updates: 166,494
Cumulative Timesteps: 1,388,403,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1388403482...
Checkpoint 1388403482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.68379
Value Function Loss: 0.04498

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.46215
Value Function Update Magnitude: 0.54579

Collected Steps per Second: 22,354.12037
Overall Steps per Second: 10,496.47156

Timestep Collection Time: 2.23762
Timestep Consumption Time: 2.52779
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.76541

Cumulative Model Updates: 166,500
Cumulative Timesteps: 1,388,453,502

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.67318
Value Function Loss: 0.03889

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.15137
Policy Update Magnitude: 0.40579
Value Function Update Magnitude: 0.67639

Collected Steps per Second: 22,957.91128
Overall Steps per Second: 10,818.52940

Timestep Collection Time: 2.17912
Timestep Consumption Time: 2.44517
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.62429

Cumulative Model Updates: 166,506
Cumulative Timesteps: 1,388,503,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1388503530...
Checkpoint 1388503530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.66392
Value Function Loss: 0.03563

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14090
Policy Update Magnitude: 0.39571
Value Function Update Magnitude: 0.69421

Collected Steps per Second: 21,594.02516
Overall Steps per Second: 10,664.47877

Timestep Collection Time: 2.31647
Timestep Consumption Time: 2.37405
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.69052

Cumulative Model Updates: 166,512
Cumulative Timesteps: 1,388,553,552

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.64298
Value Function Loss: 0.04129

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.39187
Value Function Update Magnitude: 0.63642

Collected Steps per Second: 22,168.76792
Overall Steps per Second: 10,688.46202

Timestep Collection Time: 2.25597
Timestep Consumption Time: 2.42310
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.67906

Cumulative Model Updates: 166,518
Cumulative Timesteps: 1,388,603,564

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1388603564...
Checkpoint 1388603564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.65492
Value Function Loss: 0.03794

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.36193
Value Function Update Magnitude: 0.51511

Collected Steps per Second: 21,723.35362
Overall Steps per Second: 10,559.82264

Timestep Collection Time: 2.30195
Timestep Consumption Time: 2.43355
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.73550

Cumulative Model Updates: 166,524
Cumulative Timesteps: 1,388,653,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.63310
Value Function Loss: 0.04642

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.33677
Value Function Update Magnitude: 0.45740

Collected Steps per Second: 22,393.73384
Overall Steps per Second: 10,737.85008

Timestep Collection Time: 2.23402
Timestep Consumption Time: 2.42502
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.65903

Cumulative Model Updates: 166,530
Cumulative Timesteps: 1,388,703,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1388703598...
Checkpoint 1388703598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.65964
Value Function Loss: 0.03906

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13659
Policy Update Magnitude: 0.34299
Value Function Update Magnitude: 0.38442

Collected Steps per Second: 22,108.89766
Overall Steps per Second: 10,652.60823

Timestep Collection Time: 2.26253
Timestep Consumption Time: 2.43322
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.69575

Cumulative Model Updates: 166,536
Cumulative Timesteps: 1,388,753,620

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.63828
Value Function Loss: 0.05316

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.34828
Value Function Update Magnitude: 0.36832

Collected Steps per Second: 22,882.30978
Overall Steps per Second: 10,837.43398

Timestep Collection Time: 2.18518
Timestep Consumption Time: 2.42864
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.61382

Cumulative Model Updates: 166,542
Cumulative Timesteps: 1,388,803,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1388803622...
Checkpoint 1388803622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.66447
Value Function Loss: 0.04712

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.38308
Value Function Update Magnitude: 0.42457

Collected Steps per Second: 22,097.50309
Overall Steps per Second: 10,443.66595

Timestep Collection Time: 2.26288
Timestep Consumption Time: 2.52509
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.78797

Cumulative Model Updates: 166,548
Cumulative Timesteps: 1,388,853,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.63488
Value Function Loss: 0.05785

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14640
Policy Update Magnitude: 0.39812
Value Function Update Magnitude: 0.44486

Collected Steps per Second: 23,113.50704
Overall Steps per Second: 10,755.73013

Timestep Collection Time: 2.16419
Timestep Consumption Time: 2.48654
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.65073

Cumulative Model Updates: 166,554
Cumulative Timesteps: 1,388,903,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1388903648...
Checkpoint 1388903648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.65160
Value Function Loss: 0.04983

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.39892
Value Function Update Magnitude: 0.44336

Collected Steps per Second: 22,441.81586
Overall Steps per Second: 10,676.52126

Timestep Collection Time: 2.22843
Timestep Consumption Time: 2.45568
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.68411

Cumulative Model Updates: 166,560
Cumulative Timesteps: 1,388,953,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.65609
Value Function Loss: 0.04480

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14644
Policy Update Magnitude: 0.38419
Value Function Update Magnitude: 0.46191

Collected Steps per Second: 23,351.69299
Overall Steps per Second: 10,941.79502

Timestep Collection Time: 2.14194
Timestep Consumption Time: 2.42934
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.57128

Cumulative Model Updates: 166,566
Cumulative Timesteps: 1,389,003,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1389003676...
Checkpoint 1389003676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.68086
Value Function Loss: 0.03179

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.33905
Value Function Update Magnitude: 0.38538

Collected Steps per Second: 22,878.37216
Overall Steps per Second: 10,676.74386

Timestep Collection Time: 2.18652
Timestep Consumption Time: 2.49880
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.68532

Cumulative Model Updates: 166,572
Cumulative Timesteps: 1,389,053,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.69655
Value Function Loss: 0.02604

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.27656
Value Function Update Magnitude: 0.29924

Collected Steps per Second: 20,680.77221
Overall Steps per Second: 10,409.80601

Timestep Collection Time: 2.41780
Timestep Consumption Time: 2.38555
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.80336

Cumulative Model Updates: 166,578
Cumulative Timesteps: 1,389,103,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1389103702...
Checkpoint 1389103702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.68962
Value Function Loss: 0.02585

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.23123
Value Function Update Magnitude: 0.22907

Collected Steps per Second: 22,127.80119
Overall Steps per Second: 10,700.73562

Timestep Collection Time: 2.26087
Timestep Consumption Time: 2.41433
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.67519

Cumulative Model Updates: 166,584
Cumulative Timesteps: 1,389,153,730

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.67682
Value Function Loss: 0.02817

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.23556
Value Function Update Magnitude: 0.19849

Collected Steps per Second: 22,725.38755
Overall Steps per Second: 10,736.45096

Timestep Collection Time: 2.20018
Timestep Consumption Time: 2.45685
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.65703

Cumulative Model Updates: 166,590
Cumulative Timesteps: 1,389,203,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1389203730...
Checkpoint 1389203730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.67497
Value Function Loss: 0.02658

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.24146
Value Function Update Magnitude: 0.24166

Collected Steps per Second: 21,925.25867
Overall Steps per Second: 10,604.22564

Timestep Collection Time: 2.28093
Timestep Consumption Time: 2.43511
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.71604

Cumulative Model Updates: 166,596
Cumulative Timesteps: 1,389,253,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.66624
Value Function Loss: 0.03045

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.27092
Value Function Update Magnitude: 0.36208

Collected Steps per Second: 22,574.68955
Overall Steps per Second: 10,567.66384

Timestep Collection Time: 2.21629
Timestep Consumption Time: 2.51816
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.73444

Cumulative Model Updates: 166,602
Cumulative Timesteps: 1,389,303,772

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1389303772...
Checkpoint 1389303772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.66199
Value Function Loss: 0.03536

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.34607
Value Function Update Magnitude: 0.49794

Collected Steps per Second: 22,108.96210
Overall Steps per Second: 10,597.81828

Timestep Collection Time: 2.26207
Timestep Consumption Time: 2.45702
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.71908

Cumulative Model Updates: 166,608
Cumulative Timesteps: 1,389,353,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,277.98831
Policy Entropy: 3.65801
Value Function Loss: 0.04438

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.44883
Value Function Update Magnitude: 0.54702

Collected Steps per Second: 22,568.08408
Overall Steps per Second: 10,488.86623

Timestep Collection Time: 2.21614
Timestep Consumption Time: 2.55216
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.76829

Cumulative Model Updates: 166,614
Cumulative Timesteps: 1,389,403,798

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1389403798...
Checkpoint 1389403798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761,365.91469
Policy Entropy: 3.64133
Value Function Loss: 0.05789

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.49443
Value Function Update Magnitude: 0.54924

Collected Steps per Second: 22,067.42263
Overall Steps per Second: 10,575.17033

Timestep Collection Time: 2.26606
Timestep Consumption Time: 2.46257
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.72862

Cumulative Model Updates: 166,620
Cumulative Timesteps: 1,389,453,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761,365.91469
Policy Entropy: 3.66384
Value Function Loss: 0.05494

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14511
Policy Update Magnitude: 0.53455
Value Function Update Magnitude: 0.54903

Collected Steps per Second: 22,789.08388
Overall Steps per Second: 10,585.71092

Timestep Collection Time: 2.19474
Timestep Consumption Time: 2.53012
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.72486

Cumulative Model Updates: 166,626
Cumulative Timesteps: 1,389,503,820

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1389503820...
Checkpoint 1389503820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761,365.91469
Policy Entropy: 3.66910
Value Function Loss: 0.04360

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14307
Policy Update Magnitude: 0.46089
Value Function Update Magnitude: 0.46279

Collected Steps per Second: 22,620.12157
Overall Steps per Second: 10,568.52342

Timestep Collection Time: 2.21113
Timestep Consumption Time: 2.52142
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.73254

Cumulative Model Updates: 166,632
Cumulative Timesteps: 1,389,553,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761,365.91469
Policy Entropy: 3.68512
Value Function Loss: 0.03464

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.36529
Value Function Update Magnitude: 0.39530

Collected Steps per Second: 22,836.78147
Overall Steps per Second: 10,643.17942

Timestep Collection Time: 2.19059
Timestep Consumption Time: 2.50970
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.70029

Cumulative Model Updates: 166,638
Cumulative Timesteps: 1,389,603,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1389603862...
Checkpoint 1389603862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761,365.91469
Policy Entropy: 3.66462
Value Function Loss: 0.03311

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.32939
Value Function Update Magnitude: 0.37484

Collected Steps per Second: 22,289.31826
Overall Steps per Second: 10,468.74257

Timestep Collection Time: 2.24484
Timestep Consumption Time: 2.53472
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.77956

Cumulative Model Updates: 166,644
Cumulative Timesteps: 1,389,653,898

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761,365.91469
Policy Entropy: 3.66038
Value Function Loss: 0.03898

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.33078
Value Function Update Magnitude: 0.41029

Collected Steps per Second: 22,518.33630
Overall Steps per Second: 10,560.90100

Timestep Collection Time: 2.22254
Timestep Consumption Time: 2.51645
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.73899

Cumulative Model Updates: 166,650
Cumulative Timesteps: 1,389,703,946

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1389703946...
Checkpoint 1389703946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761,365.91469
Policy Entropy: 3.66216
Value Function Loss: 0.03855

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.32390
Value Function Update Magnitude: 0.35749

Collected Steps per Second: 22,310.54073
Overall Steps per Second: 10,555.14567

Timestep Collection Time: 2.24181
Timestep Consumption Time: 2.49673
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.73854

Cumulative Model Updates: 166,656
Cumulative Timesteps: 1,389,753,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 878,561.53620
Policy Entropy: 3.67510
Value Function Loss: 0.04027

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.35363
Value Function Update Magnitude: 0.42249

Collected Steps per Second: 23,023.15871
Overall Steps per Second: 10,824.20538

Timestep Collection Time: 2.17181
Timestep Consumption Time: 2.44765
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.61946

Cumulative Model Updates: 166,662
Cumulative Timesteps: 1,389,803,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1389803964...
Checkpoint 1389803964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711,639.27056
Policy Entropy: 3.68006
Value Function Loss: 0.03944

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.42157
Value Function Update Magnitude: 0.56440

Collected Steps per Second: 21,358.15163
Overall Steps per Second: 10,601.86334

Timestep Collection Time: 2.34206
Timestep Consumption Time: 2.37617
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.71823

Cumulative Model Updates: 166,668
Cumulative Timesteps: 1,389,853,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711,639.27056
Policy Entropy: 3.68262
Value Function Loss: 0.03598

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.45352
Value Function Update Magnitude: 0.65241

Collected Steps per Second: 21,783.75263
Overall Steps per Second: 10,573.26550

Timestep Collection Time: 2.29575
Timestep Consumption Time: 2.43411
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.72985

Cumulative Model Updates: 166,674
Cumulative Timesteps: 1,389,903,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1389903996...
Checkpoint 1389903996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711,639.27056
Policy Entropy: 3.65537
Value Function Loss: 0.03882

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.42551
Value Function Update Magnitude: 0.60222

Collected Steps per Second: 21,542.75041
Overall Steps per Second: 10,379.05272

Timestep Collection Time: 2.32143
Timestep Consumption Time: 2.49693
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.81836

Cumulative Model Updates: 166,680
Cumulative Timesteps: 1,389,954,006

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711,639.27056
Policy Entropy: 3.65059
Value Function Loss: 0.03910

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.40817
Value Function Update Magnitude: 0.41131

Collected Steps per Second: 22,481.34888
Overall Steps per Second: 10,745.63672

Timestep Collection Time: 2.22487
Timestep Consumption Time: 2.42986
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.65473

Cumulative Model Updates: 166,686
Cumulative Timesteps: 1,390,004,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1390004024...
Checkpoint 1390004024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619,856.51999
Policy Entropy: 3.64112
Value Function Loss: 0.05425

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.52865
Value Function Update Magnitude: 0.57639

Collected Steps per Second: 21,711.56290
Overall Steps per Second: 10,568.24461

Timestep Collection Time: 2.30375
Timestep Consumption Time: 2.42911
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.73286

Cumulative Model Updates: 166,692
Cumulative Timesteps: 1,390,054,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312,086.86713
Policy Entropy: 3.66584
Value Function Loss: 0.05206

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.61481
Value Function Update Magnitude: 0.86840

Collected Steps per Second: 22,812.18845
Overall Steps per Second: 10,585.93547

Timestep Collection Time: 2.19199
Timestep Consumption Time: 2.53164
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.72363

Cumulative Model Updates: 166,698
Cumulative Timesteps: 1,390,104,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1390104046...
Checkpoint 1390104046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312,086.86713
Policy Entropy: 3.64074
Value Function Loss: 0.06621

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.60532
Value Function Update Magnitude: 0.84633

Collected Steps per Second: 22,234.91372
Overall Steps per Second: 10,646.84273

Timestep Collection Time: 2.24997
Timestep Consumption Time: 2.44888
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.69886

Cumulative Model Updates: 166,704
Cumulative Timesteps: 1,390,154,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.65432
Value Function Loss: 0.06068

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.56688
Value Function Update Magnitude: 0.69100

Collected Steps per Second: 22,845.11702
Overall Steps per Second: 10,772.63613

Timestep Collection Time: 2.18900
Timestep Consumption Time: 2.45313
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.64213

Cumulative Model Updates: 166,710
Cumulative Timesteps: 1,390,204,082

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1390204082...
Checkpoint 1390204082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.62925
Value Function Loss: 0.06241

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13780
Policy Update Magnitude: 0.51072
Value Function Update Magnitude: 0.69268

Collected Steps per Second: 22,382.11236
Overall Steps per Second: 10,647.55999

Timestep Collection Time: 2.23428
Timestep Consumption Time: 2.46238
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.69666

Cumulative Model Updates: 166,716
Cumulative Timesteps: 1,390,254,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.66458
Value Function Loss: 0.05128

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.47188
Value Function Update Magnitude: 0.57478

Collected Steps per Second: 22,546.68569
Overall Steps per Second: 10,534.85012

Timestep Collection Time: 2.21877
Timestep Consumption Time: 2.52985
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.74862

Cumulative Model Updates: 166,722
Cumulative Timesteps: 1,390,304,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1390304116...
Checkpoint 1390304116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.66216
Value Function Loss: 0.03987

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.42442
Value Function Update Magnitude: 0.49773

Collected Steps per Second: 22,410.50929
Overall Steps per Second: 10,571.44049

Timestep Collection Time: 2.23190
Timestep Consumption Time: 2.49953
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.73143

Cumulative Model Updates: 166,728
Cumulative Timesteps: 1,390,354,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.68608
Value Function Loss: 0.03141

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.35609
Value Function Update Magnitude: 0.44855

Collected Steps per Second: 22,718.81956
Overall Steps per Second: 10,582.46802

Timestep Collection Time: 2.20143
Timestep Consumption Time: 2.52468
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.72612

Cumulative Model Updates: 166,734
Cumulative Timesteps: 1,390,404,148

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1390404148...
Checkpoint 1390404148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.66967
Value Function Loss: 0.02801

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.28808
Value Function Update Magnitude: 0.32265

Collected Steps per Second: 21,906.93822
Overall Steps per Second: 10,545.39206

Timestep Collection Time: 2.28302
Timestep Consumption Time: 2.45971
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.74274

Cumulative Model Updates: 166,740
Cumulative Timesteps: 1,390,454,162

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.68080
Value Function Loss: 0.02727

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.25126
Value Function Update Magnitude: 0.27250

Collected Steps per Second: 22,669.73697
Overall Steps per Second: 10,615.92346

Timestep Collection Time: 2.20673
Timestep Consumption Time: 2.50562
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.71235

Cumulative Model Updates: 166,746
Cumulative Timesteps: 1,390,504,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1390504188...
Checkpoint 1390504188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.67356
Value Function Loss: 0.02685

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.23335
Value Function Update Magnitude: 0.24532

Collected Steps per Second: 22,427.91407
Overall Steps per Second: 10,535.82515

Timestep Collection Time: 2.23008
Timestep Consumption Time: 2.51715
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.74723

Cumulative Model Updates: 166,752
Cumulative Timesteps: 1,390,554,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.66213
Value Function Loss: 0.03291

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12684
Policy Update Magnitude: 0.31402
Value Function Update Magnitude: 0.43345

Collected Steps per Second: 22,808.21404
Overall Steps per Second: 10,789.93341

Timestep Collection Time: 2.19281
Timestep Consumption Time: 2.44244
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.63525

Cumulative Model Updates: 166,758
Cumulative Timesteps: 1,390,604,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1390604218...
Checkpoint 1390604218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.65339
Value Function Loss: 0.03352

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.39150
Value Function Update Magnitude: 0.48995

Collected Steps per Second: 21,519.26844
Overall Steps per Second: 10,651.87168

Timestep Collection Time: 2.32452
Timestep Consumption Time: 2.37155
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.69608

Cumulative Model Updates: 166,764
Cumulative Timesteps: 1,390,654,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.64032
Value Function Loss: 0.03682

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.40419
Value Function Update Magnitude: 0.56343

Collected Steps per Second: 21,983.71222
Overall Steps per Second: 10,585.03639

Timestep Collection Time: 2.27496
Timestep Consumption Time: 2.44983
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.72478

Cumulative Model Updates: 166,770
Cumulative Timesteps: 1,390,704,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1390704252...
Checkpoint 1390704252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.66058
Value Function Loss: 0.03770

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.37282
Value Function Update Magnitude: 0.49549

Collected Steps per Second: 21,473.72338
Overall Steps per Second: 10,509.02949

Timestep Collection Time: 2.32861
Timestep Consumption Time: 2.42958
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.75819

Cumulative Model Updates: 166,776
Cumulative Timesteps: 1,390,754,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.65479
Value Function Loss: 0.04501

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.38036
Value Function Update Magnitude: 0.35610

Collected Steps per Second: 22,585.38019
Overall Steps per Second: 10,590.33471

Timestep Collection Time: 2.21418
Timestep Consumption Time: 2.50787
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.72204

Cumulative Model Updates: 166,782
Cumulative Timesteps: 1,390,804,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1390804264...
Checkpoint 1390804264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.65294
Value Function Loss: 0.04238

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14106
Policy Update Magnitude: 0.40879
Value Function Update Magnitude: 0.35432

Collected Steps per Second: 22,155.60550
Overall Steps per Second: 10,584.07004

Timestep Collection Time: 2.25776
Timestep Consumption Time: 2.46840
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.72616

Cumulative Model Updates: 166,788
Cumulative Timesteps: 1,390,854,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,190.92066
Policy Entropy: 3.63728
Value Function Loss: 0.04829

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.42716
Value Function Update Magnitude: 0.50190

Collected Steps per Second: 22,419.10893
Overall Steps per Second: 10,489.61465

Timestep Collection Time: 2.23033
Timestep Consumption Time: 2.53648
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.76681

Cumulative Model Updates: 166,794
Cumulative Timesteps: 1,390,904,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1390904288...
Checkpoint 1390904288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,883,711.09178
Policy Entropy: 3.66012
Value Function Loss: 0.04559

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.45835
Value Function Update Magnitude: 0.50157

Collected Steps per Second: 22,491.55297
Overall Steps per Second: 10,619.00639

Timestep Collection Time: 2.22421
Timestep Consumption Time: 2.48677
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.71099

Cumulative Model Updates: 166,800
Cumulative Timesteps: 1,390,954,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,883,711.09178
Policy Entropy: 3.65491
Value Function Loss: 0.04387

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.45092
Value Function Update Magnitude: 0.58810

Collected Steps per Second: 22,679.99903
Overall Steps per Second: 10,583.63916

Timestep Collection Time: 2.20529
Timestep Consumption Time: 2.52049
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.72578

Cumulative Model Updates: 166,806
Cumulative Timesteps: 1,391,004,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1391004330...
Checkpoint 1391004330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213,712.94448
Policy Entropy: 3.67079
Value Function Loss: 0.04183

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.42470
Value Function Update Magnitude: 0.68955

Collected Steps per Second: 22,325.08756
Overall Steps per Second: 10,485.39517

Timestep Collection Time: 2.24008
Timestep Consumption Time: 2.52941
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.76949

Cumulative Model Updates: 166,812
Cumulative Timesteps: 1,391,054,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213,712.94448
Policy Entropy: 3.64885
Value Function Loss: 0.04262

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.41671
Value Function Update Magnitude: 0.61695

Collected Steps per Second: 22,721.49988
Overall Steps per Second: 10,621.54648

Timestep Collection Time: 2.20153
Timestep Consumption Time: 2.50796
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.70948

Cumulative Model Updates: 166,818
Cumulative Timesteps: 1,391,104,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1391104362...
Checkpoint 1391104362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213,712.94448
Policy Entropy: 3.66396
Value Function Loss: 0.03747

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.39544
Value Function Update Magnitude: 0.57719

Collected Steps per Second: 22,212.19360
Overall Steps per Second: 10,497.34543

Timestep Collection Time: 2.25156
Timestep Consumption Time: 2.51270
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.76425

Cumulative Model Updates: 166,824
Cumulative Timesteps: 1,391,154,374

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213,712.94448
Policy Entropy: 3.66751
Value Function Loss: 0.03497

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.36018
Value Function Update Magnitude: 0.46699

Collected Steps per Second: 22,346.35374
Overall Steps per Second: 10,504.54996

Timestep Collection Time: 2.23867
Timestep Consumption Time: 2.52365
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.76232

Cumulative Model Updates: 166,830
Cumulative Timesteps: 1,391,204,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1391204400...
Checkpoint 1391204400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213,712.94448
Policy Entropy: 3.67966
Value Function Loss: 0.03072

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12584
Policy Update Magnitude: 0.33039
Value Function Update Magnitude: 0.38150

Collected Steps per Second: 22,197.82518
Overall Steps per Second: 10,562.89763

Timestep Collection Time: 2.25373
Timestep Consumption Time: 2.48247
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.73620

Cumulative Model Updates: 166,836
Cumulative Timesteps: 1,391,254,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213,712.94448
Policy Entropy: 3.67099
Value Function Loss: 0.02913

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13600
Policy Update Magnitude: 0.32035
Value Function Update Magnitude: 0.37296

Collected Steps per Second: 22,828.67572
Overall Steps per Second: 10,634.03470

Timestep Collection Time: 2.19032
Timestep Consumption Time: 2.51176
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.70207

Cumulative Model Updates: 166,842
Cumulative Timesteps: 1,391,304,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1391304430...
Checkpoint 1391304430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213,712.94448
Policy Entropy: 3.65590
Value Function Loss: 0.03063

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.30554
Value Function Update Magnitude: 0.39485

Collected Steps per Second: 21,812.78156
Overall Steps per Second: 10,569.18878

Timestep Collection Time: 2.29242
Timestep Consumption Time: 2.43869
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.73111

Cumulative Model Updates: 166,848
Cumulative Timesteps: 1,391,354,434

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213,712.94448
Policy Entropy: 3.66466
Value Function Loss: 0.03304

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.38472
Value Function Update Magnitude: 0.42504

Collected Steps per Second: 22,066.25470
Overall Steps per Second: 10,767.20987

Timestep Collection Time: 2.26708
Timestep Consumption Time: 2.37906
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.64614

Cumulative Model Updates: 166,854
Cumulative Timesteps: 1,391,404,460

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1391404460...
Checkpoint 1391404460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213,712.94448
Policy Entropy: 3.66707
Value Function Loss: 0.03139

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.41385
Value Function Update Magnitude: 0.47037

Collected Steps per Second: 21,627.50897
Overall Steps per Second: 10,429.86790

Timestep Collection Time: 2.31224
Timestep Consumption Time: 2.48245
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.79469

Cumulative Model Updates: 166,860
Cumulative Timesteps: 1,391,454,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213,712.94448
Policy Entropy: 3.67497
Value Function Loss: 0.03570

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.39695
Value Function Update Magnitude: 0.49394

Collected Steps per Second: 22,855.77115
Overall Steps per Second: 10,743.24011

Timestep Collection Time: 2.18789
Timestep Consumption Time: 2.46675
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.65465

Cumulative Model Updates: 166,866
Cumulative Timesteps: 1,391,504,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1391504474...
Checkpoint 1391504474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213,712.94448
Policy Entropy: 3.66861
Value Function Loss: 0.03530

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.36520
Value Function Update Magnitude: 0.55466

Collected Steps per Second: 22,115.12220
Overall Steps per Second: 10,632.13966

Timestep Collection Time: 2.26117
Timestep Consumption Time: 2.44212
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.70329

Cumulative Model Updates: 166,872
Cumulative Timesteps: 1,391,554,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213,712.94448
Policy Entropy: 3.66595
Value Function Loss: 0.03773

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.36029
Value Function Update Magnitude: 0.55384

Collected Steps per Second: 22,949.30138
Overall Steps per Second: 10,794.71870

Timestep Collection Time: 2.17933
Timestep Consumption Time: 2.45387
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.63319

Cumulative Model Updates: 166,878
Cumulative Timesteps: 1,391,604,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1391604494...
Checkpoint 1391604494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.67236
Value Function Loss: 0.03943

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.39795
Value Function Update Magnitude: 0.55736

Collected Steps per Second: 22,180.33107
Overall Steps per Second: 10,610.43986

Timestep Collection Time: 2.25542
Timestep Consumption Time: 2.45937
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.71479

Cumulative Model Updates: 166,884
Cumulative Timesteps: 1,391,654,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.69052
Value Function Loss: 0.03778

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13938
Policy Update Magnitude: 0.41894
Value Function Update Magnitude: 0.51006

Collected Steps per Second: 22,345.72579
Overall Steps per Second: 10,600.29461

Timestep Collection Time: 2.23837
Timestep Consumption Time: 2.48018
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.71855

Cumulative Model Updates: 166,890
Cumulative Timesteps: 1,391,704,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1391704538...
Checkpoint 1391704538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.69033
Value Function Loss: 0.03482

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.40509
Value Function Update Magnitude: 0.51252

Collected Steps per Second: 22,241.26872
Overall Steps per Second: 10,652.66450

Timestep Collection Time: 2.24888
Timestep Consumption Time: 2.44647
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.69535

Cumulative Model Updates: 166,896
Cumulative Timesteps: 1,391,754,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.67758
Value Function Loss: 0.03833

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13628
Policy Update Magnitude: 0.40396
Value Function Update Magnitude: 0.46444

Collected Steps per Second: 22,447.17561
Overall Steps per Second: 10,526.06439

Timestep Collection Time: 2.22852
Timestep Consumption Time: 2.52387
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.75239

Cumulative Model Updates: 166,902
Cumulative Timesteps: 1,391,804,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1391804580...
Checkpoint 1391804580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.66517
Value Function Loss: 0.03869

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13609
Policy Update Magnitude: 0.39128
Value Function Update Magnitude: 0.35352

Collected Steps per Second: 22,334.28960
Overall Steps per Second: 10,555.23076

Timestep Collection Time: 2.23943
Timestep Consumption Time: 2.49908
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.73850

Cumulative Model Updates: 166,908
Cumulative Timesteps: 1,391,854,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.66149
Value Function Loss: 0.03888

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.36066
Value Function Update Magnitude: 0.33650

Collected Steps per Second: 22,651.06618
Overall Steps per Second: 10,625.39409

Timestep Collection Time: 2.20767
Timestep Consumption Time: 2.49861
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.70627

Cumulative Model Updates: 166,914
Cumulative Timesteps: 1,391,904,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1391904602...
Checkpoint 1391904602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.65603
Value Function Loss: 0.03678

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.36934
Value Function Update Magnitude: 0.35680

Collected Steps per Second: 22,395.95524
Overall Steps per Second: 10,564.09442

Timestep Collection Time: 2.23317
Timestep Consumption Time: 2.50117
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.73434

Cumulative Model Updates: 166,920
Cumulative Timesteps: 1,391,954,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.65468
Value Function Loss: 0.03721

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.34971
Value Function Update Magnitude: 0.34907

Collected Steps per Second: 22,088.99570
Overall Steps per Second: 10,783.89050

Timestep Collection Time: 2.26475
Timestep Consumption Time: 2.37421
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.63896

Cumulative Model Updates: 166,926
Cumulative Timesteps: 1,392,004,642

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1392004642...
Checkpoint 1392004642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.65661
Value Function Loss: 0.03788

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.35130
Value Function Update Magnitude: 0.43260

Collected Steps per Second: 21,390.55729
Overall Steps per Second: 10,601.13577

Timestep Collection Time: 2.33832
Timestep Consumption Time: 2.37985
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.71817

Cumulative Model Updates: 166,932
Cumulative Timesteps: 1,392,054,660

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.66374
Value Function Loss: 0.03991

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.41999
Value Function Update Magnitude: 0.41603

Collected Steps per Second: 21,915.86641
Overall Steps per Second: 10,511.43979

Timestep Collection Time: 2.28173
Timestep Consumption Time: 2.47557
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.75729

Cumulative Model Updates: 166,938
Cumulative Timesteps: 1,392,104,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1392104666...
Checkpoint 1392104666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.66289
Value Function Loss: 0.03878

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.42287
Value Function Update Magnitude: 0.35778

Collected Steps per Second: 22,496.27491
Overall Steps per Second: 10,643.95933

Timestep Collection Time: 2.22277
Timestep Consumption Time: 2.47511
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.69788

Cumulative Model Updates: 166,944
Cumulative Timesteps: 1,392,154,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.66946
Value Function Loss: 0.03504

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.37356
Value Function Update Magnitude: 0.35435

Collected Steps per Second: 22,903.02114
Overall Steps per Second: 10,831.16450

Timestep Collection Time: 2.18312
Timestep Consumption Time: 2.43319
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.61631

Cumulative Model Updates: 166,950
Cumulative Timesteps: 1,392,204,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1392204670...
Checkpoint 1392204670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.66803
Value Function Loss: 0.02994

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.32208
Value Function Update Magnitude: 0.28543

Collected Steps per Second: 20,496.23530
Overall Steps per Second: 9,961.72898

Timestep Collection Time: 2.43986
Timestep Consumption Time: 2.58015
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 5.02001

Cumulative Model Updates: 166,956
Cumulative Timesteps: 1,392,254,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.66256
Value Function Loss: 0.03480

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12152
Policy Update Magnitude: 0.38049
Value Function Update Magnitude: 0.26248

Collected Steps per Second: 20,782.14150
Overall Steps per Second: 10,051.40753

Timestep Collection Time: 2.40716
Timestep Consumption Time: 2.56985
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.97701

Cumulative Model Updates: 166,962
Cumulative Timesteps: 1,392,304,704

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1392304704...
Checkpoint 1392304704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.66577
Value Function Loss: 0.03552

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.44759
Value Function Update Magnitude: 0.36539

Collected Steps per Second: 22,419.95809
Overall Steps per Second: 10,557.41332

Timestep Collection Time: 2.23132
Timestep Consumption Time: 2.50716
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.73847

Cumulative Model Updates: 166,968
Cumulative Timesteps: 1,392,354,730

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.66465
Value Function Loss: 0.03554

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.18441
Policy Update Magnitude: 0.42694
Value Function Update Magnitude: 0.43261

Collected Steps per Second: 22,937.17664
Overall Steps per Second: 10,785.01780

Timestep Collection Time: 2.18056
Timestep Consumption Time: 2.45698
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.63754

Cumulative Model Updates: 166,974
Cumulative Timesteps: 1,392,404,746

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1392404746...
Checkpoint 1392404746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.66635
Value Function Loss: 0.03109

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.19371
Policy Update Magnitude: 0.41192
Value Function Update Magnitude: 0.41279

Collected Steps per Second: 21,821.85972
Overall Steps per Second: 10,376.93218

Timestep Collection Time: 2.29321
Timestep Consumption Time: 2.52922
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.82243

Cumulative Model Updates: 166,980
Cumulative Timesteps: 1,392,454,788

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,543.79938
Policy Entropy: 3.65633
Value Function Loss: 0.03202

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.17428
Policy Update Magnitude: 0.40552
Value Function Update Magnitude: 0.35583

Collected Steps per Second: 22,773.88652
Overall Steps per Second: 10,760.70975

Timestep Collection Time: 2.19585
Timestep Consumption Time: 2.45143
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.64728

Cumulative Model Updates: 166,986
Cumulative Timesteps: 1,392,504,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1392504796...
Checkpoint 1392504796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087,298.63113
Policy Entropy: 3.67344
Value Function Loss: 0.03444

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.42795
Value Function Update Magnitude: 0.62941

Collected Steps per Second: 22,297.21419
Overall Steps per Second: 10,620.35918

Timestep Collection Time: 2.24243
Timestep Consumption Time: 2.46551
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.70794

Cumulative Model Updates: 166,992
Cumulative Timesteps: 1,392,554,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880,731.46918
Policy Entropy: 3.66804
Value Function Loss: 0.03657

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12496
Policy Update Magnitude: 0.45391
Value Function Update Magnitude: 0.80935

Collected Steps per Second: 22,307.35143
Overall Steps per Second: 10,558.81157

Timestep Collection Time: 2.24195
Timestep Consumption Time: 2.49457
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.73652

Cumulative Model Updates: 166,998
Cumulative Timesteps: 1,392,604,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1392604808...
Checkpoint 1392604808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 880,731.46918
Policy Entropy: 3.66501
Value Function Loss: 0.03425

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.40561
Value Function Update Magnitude: 0.69602

Collected Steps per Second: 22,570.92816
Overall Steps per Second: 10,624.39337

Timestep Collection Time: 2.21630
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.70841

Cumulative Model Updates: 167,004
Cumulative Timesteps: 1,392,654,832

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880,731.46918
Policy Entropy: 3.65948
Value Function Loss: 0.03249

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.36080
Value Function Update Magnitude: 0.53761

Collected Steps per Second: 22,052.60796
Overall Steps per Second: 10,655.60161

Timestep Collection Time: 2.26767
Timestep Consumption Time: 2.42545
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.69312

Cumulative Model Updates: 167,010
Cumulative Timesteps: 1,392,704,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1392704840...
Checkpoint 1392704840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 880,731.46918
Policy Entropy: 3.63472
Value Function Loss: 0.03723

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.40155
Value Function Update Magnitude: 0.48878

Collected Steps per Second: 21,737.17377
Overall Steps per Second: 10,613.17752

Timestep Collection Time: 2.30094
Timestep Consumption Time: 2.41169
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.71263

Cumulative Model Updates: 167,016
Cumulative Timesteps: 1,392,754,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292,633.24847
Policy Entropy: 3.66598
Value Function Loss: 0.04004

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.46391
Value Function Update Magnitude: 0.76852

Collected Steps per Second: 22,347.58279
Overall Steps per Second: 10,688.76890

Timestep Collection Time: 2.23818
Timestep Consumption Time: 2.44131
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.67949

Cumulative Model Updates: 167,022
Cumulative Timesteps: 1,392,804,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1392804874...
Checkpoint 1392804874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,960.82835
Policy Entropy: 3.65570
Value Function Loss: 0.04012

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14194
Policy Update Magnitude: 0.51472
Value Function Update Magnitude: 0.87284

Collected Steps per Second: 22,126.01851
Overall Steps per Second: 10,681.25081

Timestep Collection Time: 2.26060
Timestep Consumption Time: 2.42219
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.68278

Cumulative Model Updates: 167,028
Cumulative Timesteps: 1,392,854,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,960.82835
Policy Entropy: 3.68194
Value Function Loss: 0.03640

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.47794
Value Function Update Magnitude: 0.80443

Collected Steps per Second: 22,490.58699
Overall Steps per Second: 10,622.68120

Timestep Collection Time: 2.22386
Timestep Consumption Time: 2.48455
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.70842

Cumulative Model Updates: 167,034
Cumulative Timesteps: 1,392,904,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1392904908...
Checkpoint 1392904908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,960.82835
Policy Entropy: 3.65463
Value Function Loss: 0.03401

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.39912
Value Function Update Magnitude: 0.57878

Collected Steps per Second: 22,614.32315
Overall Steps per Second: 10,568.07668

Timestep Collection Time: 2.21249
Timestep Consumption Time: 2.52196
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.73445

Cumulative Model Updates: 167,040
Cumulative Timesteps: 1,392,954,942

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,960.82835
Policy Entropy: 3.65172
Value Function Loss: 0.03184

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.34528
Value Function Update Magnitude: 0.42710

Collected Steps per Second: 22,989.30902
Overall Steps per Second: 10,782.98878

Timestep Collection Time: 2.17501
Timestep Consumption Time: 2.46211
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.63712

Cumulative Model Updates: 167,046
Cumulative Timesteps: 1,393,004,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1393004944...
Checkpoint 1393004944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,960.82835
Policy Entropy: 3.64624
Value Function Loss: 0.03145

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.31639
Value Function Update Magnitude: 0.34024

Collected Steps per Second: 22,134.44360
Overall Steps per Second: 10,599.74623

Timestep Collection Time: 2.25983
Timestep Consumption Time: 2.45915
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.71898

Cumulative Model Updates: 167,052
Cumulative Timesteps: 1,393,054,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,960.82835
Policy Entropy: 3.65050
Value Function Loss: 0.02988

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.30463
Value Function Update Magnitude: 0.29237

Collected Steps per Second: 22,764.53640
Overall Steps per Second: 10,563.19542

Timestep Collection Time: 2.19816
Timestep Consumption Time: 2.53905
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.73720

Cumulative Model Updates: 167,058
Cumulative Timesteps: 1,393,105,004

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1393105004...
Checkpoint 1393105004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,960.82835
Policy Entropy: 3.65598
Value Function Loss: 0.02937

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.28711
Value Function Update Magnitude: 0.31044

Collected Steps per Second: 22,548.47941
Overall Steps per Second: 10,634.56942

Timestep Collection Time: 2.21851
Timestep Consumption Time: 2.48540
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.70390

Cumulative Model Updates: 167,064
Cumulative Timesteps: 1,393,155,028

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,960.82835
Policy Entropy: 3.65894
Value Function Loss: 0.03419

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.35480
Value Function Update Magnitude: 0.38357

Collected Steps per Second: 22,793.20216
Overall Steps per Second: 10,766.54749

Timestep Collection Time: 2.19443
Timestep Consumption Time: 2.45126
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.64569

Cumulative Model Updates: 167,070
Cumulative Timesteps: 1,393,205,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1393205046...
Checkpoint 1393205046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.66036
Value Function Loss: 0.03616

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.41127
Value Function Update Magnitude: 0.58400

Collected Steps per Second: 22,044.22591
Overall Steps per Second: 10,450.56341

Timestep Collection Time: 2.26835
Timestep Consumption Time: 2.51646
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.78481

Cumulative Model Updates: 167,076
Cumulative Timesteps: 1,393,255,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.66971
Value Function Loss: 0.03421

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.41305
Value Function Update Magnitude: 0.66095

Collected Steps per Second: 23,024.97121
Overall Steps per Second: 10,793.64434

Timestep Collection Time: 2.17173
Timestep Consumption Time: 2.46100
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.63273

Cumulative Model Updates: 167,082
Cumulative Timesteps: 1,393,305,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1393305054...
Checkpoint 1393305054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.66146
Value Function Loss: 0.03333

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.36654
Value Function Update Magnitude: 0.52263

Collected Steps per Second: 22,410.56603
Overall Steps per Second: 10,623.15822

Timestep Collection Time: 2.23118
Timestep Consumption Time: 2.47571
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.70689

Cumulative Model Updates: 167,088
Cumulative Timesteps: 1,393,355,056

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.67738
Value Function Loss: 0.02700

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.32833
Value Function Update Magnitude: 0.36882

Collected Steps per Second: 22,660.97426
Overall Steps per Second: 10,643.93917

Timestep Collection Time: 2.20741
Timestep Consumption Time: 2.49217
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.69958

Cumulative Model Updates: 167,094
Cumulative Timesteps: 1,393,405,078

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1393405078...
Checkpoint 1393405078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.66211
Value Function Loss: 0.02750

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.30657
Value Function Update Magnitude: 0.29977

Collected Steps per Second: 21,735.70742
Overall Steps per Second: 10,573.78543

Timestep Collection Time: 2.30156
Timestep Consumption Time: 2.42958
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.73113

Cumulative Model Updates: 167,100
Cumulative Timesteps: 1,393,455,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.66400
Value Function Loss: 0.02714

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.30338
Value Function Update Magnitude: 0.31811

Collected Steps per Second: 22,417.98902
Overall Steps per Second: 10,820.24429

Timestep Collection Time: 2.23160
Timestep Consumption Time: 2.39195
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.62356

Cumulative Model Updates: 167,106
Cumulative Timesteps: 1,393,505,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1393505132...
Checkpoint 1393505132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.65759
Value Function Loss: 0.03013

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.29003
Value Function Update Magnitude: 0.26513

Collected Steps per Second: 21,499.19371
Overall Steps per Second: 10,539.71767

Timestep Collection Time: 2.32632
Timestep Consumption Time: 2.41897
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.74529

Cumulative Model Updates: 167,112
Cumulative Timesteps: 1,393,555,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.65967
Value Function Loss: 0.02794

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.27559
Value Function Update Magnitude: 0.20412

Collected Steps per Second: 22,656.56773
Overall Steps per Second: 10,633.03417

Timestep Collection Time: 2.20757
Timestep Consumption Time: 2.49626
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.70383

Cumulative Model Updates: 167,118
Cumulative Timesteps: 1,393,605,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1393605162...
Checkpoint 1393605162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.66169
Value Function Loss: 0.02623

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14018
Policy Update Magnitude: 0.29027
Value Function Update Magnitude: 0.24409

Collected Steps per Second: 22,294.23289
Overall Steps per Second: 10,562.76873

Timestep Collection Time: 2.24399
Timestep Consumption Time: 2.49227
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.73626

Cumulative Model Updates: 167,124
Cumulative Timesteps: 1,393,655,190

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.64901
Value Function Loss: 0.02606

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.29447
Value Function Update Magnitude: 0.24704

Collected Steps per Second: 22,602.98238
Overall Steps per Second: 10,606.36294

Timestep Collection Time: 2.21245
Timestep Consumption Time: 2.50245
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.71491

Cumulative Model Updates: 167,130
Cumulative Timesteps: 1,393,705,198

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1393705198...
Checkpoint 1393705198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.65274
Value Function Loss: 0.02726

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.31735
Value Function Update Magnitude: 0.30432

Collected Steps per Second: 22,786.40910
Overall Steps per Second: 10,640.81974

Timestep Collection Time: 2.19508
Timestep Consumption Time: 2.50550
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.70058

Cumulative Model Updates: 167,136
Cumulative Timesteps: 1,393,755,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.63395
Value Function Loss: 0.03031

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.32348
Value Function Update Magnitude: 0.30785

Collected Steps per Second: 22,949.57151
Overall Steps per Second: 10,690.05900

Timestep Collection Time: 2.17921
Timestep Consumption Time: 2.49915
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.67837

Cumulative Model Updates: 167,142
Cumulative Timesteps: 1,393,805,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1393805228...
Checkpoint 1393805228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.65024
Value Function Loss: 0.02830

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.33777
Value Function Update Magnitude: 0.27669

Collected Steps per Second: 22,137.67616
Overall Steps per Second: 10,601.64472

Timestep Collection Time: 2.25904
Timestep Consumption Time: 2.45815
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.71719

Cumulative Model Updates: 167,148
Cumulative Timesteps: 1,393,855,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.64808
Value Function Loss: 0.03325

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.34297
Value Function Update Magnitude: 0.26219

Collected Steps per Second: 22,713.83919
Overall Steps per Second: 10,559.84915

Timestep Collection Time: 2.20192
Timestep Consumption Time: 2.53432
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.73624

Cumulative Model Updates: 167,154
Cumulative Timesteps: 1,393,905,252

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1393905252...
Checkpoint 1393905252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.66872
Value Function Loss: 0.03154

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13128
Policy Update Magnitude: 0.35696
Value Function Update Magnitude: 0.36902

Collected Steps per Second: 22,203.05029
Overall Steps per Second: 10,667.11311

Timestep Collection Time: 2.25329
Timestep Consumption Time: 2.43682
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.69012

Cumulative Model Updates: 167,160
Cumulative Timesteps: 1,393,955,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.66443
Value Function Loss: 0.03246

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.39934
Value Function Update Magnitude: 0.46065

Collected Steps per Second: 22,867.82443
Overall Steps per Second: 10,770.80082

Timestep Collection Time: 2.18823
Timestep Consumption Time: 2.45767
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.64589

Cumulative Model Updates: 167,166
Cumulative Timesteps: 1,394,005,322

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1394005322...
Checkpoint 1394005322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.66457
Value Function Loss: 0.03095

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.41787
Value Function Update Magnitude: 0.43643

Collected Steps per Second: 22,344.58186
Overall Steps per Second: 10,660.60886

Timestep Collection Time: 2.23857
Timestep Consumption Time: 2.45347
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.69204

Cumulative Model Updates: 167,172
Cumulative Timesteps: 1,394,055,342

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.65998
Value Function Loss: 0.02913

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.38408
Value Function Update Magnitude: 0.37570

Collected Steps per Second: 22,702.09784
Overall Steps per Second: 10,599.29740

Timestep Collection Time: 2.20358
Timestep Consumption Time: 2.51616
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.71975

Cumulative Model Updates: 167,178
Cumulative Timesteps: 1,394,105,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1394105368...
Checkpoint 1394105368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.66509
Value Function Loss: 0.02847

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.34862
Value Function Update Magnitude: 0.29619

Collected Steps per Second: 21,894.94132
Overall Steps per Second: 10,579.24273

Timestep Collection Time: 2.28400
Timestep Consumption Time: 2.44299
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.72699

Cumulative Model Updates: 167,184
Cumulative Timesteps: 1,394,155,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.66254
Value Function Loss: 0.02778

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14253
Policy Update Magnitude: 0.35923
Value Function Update Magnitude: 0.33531

Collected Steps per Second: 21,958.72147
Overall Steps per Second: 10,625.81957

Timestep Collection Time: 2.27837
Timestep Consumption Time: 2.42998
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.70834

Cumulative Model Updates: 167,190
Cumulative Timesteps: 1,394,205,406

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1394205406...
Checkpoint 1394205406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.63843
Value Function Loss: 0.03424

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.39887
Value Function Update Magnitude: 0.41170

Collected Steps per Second: 21,654.35946
Overall Steps per Second: 10,446.69512

Timestep Collection Time: 2.30965
Timestep Consumption Time: 2.47789
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.78754

Cumulative Model Updates: 167,196
Cumulative Timesteps: 1,394,255,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028,829.32985
Policy Entropy: 3.65481
Value Function Loss: 0.03231

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14917
Policy Update Magnitude: 0.39493
Value Function Update Magnitude: 0.41634

Collected Steps per Second: 22,684.67114
Overall Steps per Second: 10,677.99755

Timestep Collection Time: 2.20484
Timestep Consumption Time: 2.47919
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.68402

Cumulative Model Updates: 167,202
Cumulative Timesteps: 1,394,305,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1394305436...
Checkpoint 1394305436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,190.59865
Policy Entropy: 3.64184
Value Function Loss: 0.03897

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.36907
Value Function Update Magnitude: 0.38240

Collected Steps per Second: 22,409.54631
Overall Steps per Second: 10,640.50135

Timestep Collection Time: 2.23235
Timestep Consumption Time: 2.46912
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.70147

Cumulative Model Updates: 167,208
Cumulative Timesteps: 1,394,355,462

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,190.59865
Policy Entropy: 3.66204
Value Function Loss: 0.03090

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.35365
Value Function Update Magnitude: 0.36987

Collected Steps per Second: 22,932.50272
Overall Steps per Second: 10,702.77307

Timestep Collection Time: 2.18153
Timestep Consumption Time: 2.49277
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.67430

Cumulative Model Updates: 167,214
Cumulative Timesteps: 1,394,405,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1394405490...
Checkpoint 1394405490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,190.59865
Policy Entropy: 3.63836
Value Function Loss: 0.03391

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.35012
Value Function Update Magnitude: 0.31768

Collected Steps per Second: 21,984.69899
Overall Steps per Second: 10,576.31796

Timestep Collection Time: 2.27449
Timestep Consumption Time: 2.45343
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.72792

Cumulative Model Updates: 167,220
Cumulative Timesteps: 1,394,455,494

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,190.59865
Policy Entropy: 3.64644
Value Function Loss: 0.02935

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.35043
Value Function Update Magnitude: 0.28097

Collected Steps per Second: 22,669.38282
Overall Steps per Second: 10,571.22040

Timestep Collection Time: 2.20650
Timestep Consumption Time: 2.52521
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.73171

Cumulative Model Updates: 167,226
Cumulative Timesteps: 1,394,505,514

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1394505514...
Checkpoint 1394505514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,190.59865
Policy Entropy: 3.63581
Value Function Loss: 0.03708

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.42207
Value Function Update Magnitude: 0.38538

Collected Steps per Second: 22,284.54001
Overall Steps per Second: 10,581.89194

Timestep Collection Time: 2.24470
Timestep Consumption Time: 2.48244
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.72713

Cumulative Model Updates: 167,232
Cumulative Timesteps: 1,394,555,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,190.59865
Policy Entropy: 3.65361
Value Function Loss: 0.03314

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15479
Policy Update Magnitude: 0.49050
Value Function Update Magnitude: 0.47416

Collected Steps per Second: 22,736.37154
Overall Steps per Second: 10,583.18732

Timestep Collection Time: 2.20009
Timestep Consumption Time: 2.52647
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.72655

Cumulative Model Updates: 167,238
Cumulative Timesteps: 1,394,605,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1394605558...
Checkpoint 1394605558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,190.59865
Policy Entropy: 3.65707
Value Function Loss: 0.03281

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.16901
Policy Update Magnitude: 0.47986
Value Function Update Magnitude: 0.50690

Collected Steps per Second: 22,424.48865
Overall Steps per Second: 10,499.67519

Timestep Collection Time: 2.23006
Timestep Consumption Time: 2.53275
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.76281

Cumulative Model Updates: 167,244
Cumulative Timesteps: 1,394,655,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,190.59865
Policy Entropy: 3.66035
Value Function Loss: 0.02881

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14776
Policy Update Magnitude: 0.40916
Value Function Update Magnitude: 0.36000

Collected Steps per Second: 22,548.90122
Overall Steps per Second: 10,566.88249

Timestep Collection Time: 2.21847
Timestep Consumption Time: 2.51557
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.73404

Cumulative Model Updates: 167,250
Cumulative Timesteps: 1,394,705,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1394705590...
Checkpoint 1394705590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,190.59865
Policy Entropy: 3.65596
Value Function Loss: 0.03216

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.40054
Value Function Update Magnitude: 0.45718

Collected Steps per Second: 22,449.55540
Overall Steps per Second: 10,552.99131

Timestep Collection Time: 2.22722
Timestep Consumption Time: 2.51078
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.73799

Cumulative Model Updates: 167,256
Cumulative Timesteps: 1,394,755,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,190.59865
Policy Entropy: 3.65690
Value Function Loss: 0.03102

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14384
Policy Update Magnitude: 0.42458
Value Function Update Magnitude: 0.49695

Collected Steps per Second: 21,896.97642
Overall Steps per Second: 10,572.45024

Timestep Collection Time: 2.28397
Timestep Consumption Time: 2.44644
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.73041

Cumulative Model Updates: 167,262
Cumulative Timesteps: 1,394,805,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1394805602...
Checkpoint 1394805602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,190.59865
Policy Entropy: 3.66591
Value Function Loss: 0.03143

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.15451
Policy Update Magnitude: 0.40015
Value Function Update Magnitude: 0.50707

Collected Steps per Second: 21,777.43803
Overall Steps per Second: 10,547.12888

Timestep Collection Time: 2.29623
Timestep Consumption Time: 2.44497
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.74120

Cumulative Model Updates: 167,268
Cumulative Timesteps: 1,394,855,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,190.59865
Policy Entropy: 3.64739
Value Function Loss: 0.03432

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.14757
Policy Update Magnitude: 0.46041
Value Function Update Magnitude: 0.54639

Collected Steps per Second: 21,950.36619
Overall Steps per Second: 10,462.31683

Timestep Collection Time: 2.27832
Timestep Consumption Time: 2.50169
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.78001

Cumulative Model Updates: 167,274
Cumulative Timesteps: 1,394,905,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1394905618...
Checkpoint 1394905618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,190.59865
Policy Entropy: 3.64332
Value Function Loss: 0.03442

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.52555
Value Function Update Magnitude: 0.71877

Collected Steps per Second: 22,004.58934
Overall Steps per Second: 10,612.61418

Timestep Collection Time: 2.27471
Timestep Consumption Time: 2.44176
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.71646

Cumulative Model Updates: 167,280
Cumulative Timesteps: 1,394,955,672

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,190.59865
Policy Entropy: 3.62761
Value Function Loss: 0.03700

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15177
Policy Update Magnitude: 0.54058
Value Function Update Magnitude: 0.65280

Collected Steps per Second: 22,354.07035
Overall Steps per Second: 10,563.54152

Timestep Collection Time: 2.23736
Timestep Consumption Time: 2.49723
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.73459

Cumulative Model Updates: 167,286
Cumulative Timesteps: 1,395,005,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1395005686...
Checkpoint 1395005686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,393,648.10408
Policy Entropy: 3.64572
Value Function Loss: 0.03851

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11564
Policy Update Magnitude: 0.63578
Value Function Update Magnitude: 0.49839

Collected Steps per Second: 22,188.78505
Overall Steps per Second: 10,525.08597

Timestep Collection Time: 2.25411
Timestep Consumption Time: 2.49796
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.75208

Cumulative Model Updates: 167,292
Cumulative Timesteps: 1,395,055,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,393,648.10408
Policy Entropy: 3.64427
Value Function Loss: 0.04533

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.72403
Value Function Update Magnitude: 0.48107

Collected Steps per Second: 22,179.54109
Overall Steps per Second: 10,437.72203

Timestep Collection Time: 2.25460
Timestep Consumption Time: 2.53629
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.79089

Cumulative Model Updates: 167,298
Cumulative Timesteps: 1,395,105,708

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1395105708...
Checkpoint 1395105708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,393,648.10408
Policy Entropy: 3.63974
Value Function Loss: 0.04915

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.17363
Policy Update Magnitude: 0.67179
Value Function Update Magnitude: 0.44911

Collected Steps per Second: 22,156.01238
Overall Steps per Second: 10,621.99040

Timestep Collection Time: 2.25754
Timestep Consumption Time: 2.45137
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.70891

Cumulative Model Updates: 167,304
Cumulative Timesteps: 1,395,155,726

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,171,879.00026
Policy Entropy: 3.59142
Value Function Loss: 0.07089

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.17939
Policy Update Magnitude: 0.67102
Value Function Update Magnitude: 0.42911

Collected Steps per Second: 21,616.69452
Overall Steps per Second: 10,460.92111

Timestep Collection Time: 2.31395
Timestep Consumption Time: 2.46765
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.78161

Cumulative Model Updates: 167,310
Cumulative Timesteps: 1,395,205,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1395205746...
Checkpoint 1395205746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,981.88801
Policy Entropy: 3.60472
Value Function Loss: 0.07865

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.16409
Policy Update Magnitude: 0.75397
Value Function Update Magnitude: 0.48407

Collected Steps per Second: 22,080.77979
Overall Steps per Second: 10,595.82023

Timestep Collection Time: 2.26550
Timestep Consumption Time: 2.45561
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.72111

Cumulative Model Updates: 167,316
Cumulative Timesteps: 1,395,255,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,981.88801
Policy Entropy: 3.61879
Value Function Loss: 0.07447

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.16094
Policy Update Magnitude: 0.75130
Value Function Update Magnitude: 0.48369

Collected Steps per Second: 22,792.81437
Overall Steps per Second: 10,607.91017

Timestep Collection Time: 2.19402
Timestep Consumption Time: 2.52019
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.71422

Cumulative Model Updates: 167,322
Cumulative Timesteps: 1,395,305,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1395305778...
Checkpoint 1395305778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,981.88801
Policy Entropy: 3.63712
Value Function Loss: 0.07085

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.15081
Policy Update Magnitude: 0.71265
Value Function Update Magnitude: 0.48569

Collected Steps per Second: 22,368.13120
Overall Steps per Second: 10,578.73291

Timestep Collection Time: 2.23613
Timestep Consumption Time: 2.49204
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.72817

Cumulative Model Updates: 167,328
Cumulative Timesteps: 1,395,355,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,981.88801
Policy Entropy: 3.63302
Value Function Loss: 0.06590

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14406
Policy Update Magnitude: 0.62701
Value Function Update Magnitude: 0.39603

Collected Steps per Second: 22,064.42255
Overall Steps per Second: 10,651.02670

Timestep Collection Time: 2.26654
Timestep Consumption Time: 2.42878
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.69532

Cumulative Model Updates: 167,334
Cumulative Timesteps: 1,395,405,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1395405806...
Checkpoint 1395405806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,981.88801
Policy Entropy: 3.62726
Value Function Loss: 0.05985

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14950
Policy Update Magnitude: 0.61158
Value Function Update Magnitude: 0.48249

Collected Steps per Second: 21,617.58951
Overall Steps per Second: 10,506.49498

Timestep Collection Time: 2.31386
Timestep Consumption Time: 2.44701
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.76086

Cumulative Model Updates: 167,340
Cumulative Timesteps: 1,395,455,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,981.88801
Policy Entropy: 3.63268
Value Function Loss: 0.05653

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.16445
Policy Update Magnitude: 0.64675
Value Function Update Magnitude: 0.45671

Collected Steps per Second: 21,960.60826
Overall Steps per Second: 10,439.51350

Timestep Collection Time: 2.27735
Timestep Consumption Time: 2.51329
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.79064

Cumulative Model Updates: 167,346
Cumulative Timesteps: 1,395,505,838

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1395505838...
Checkpoint 1395505838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,981.88801
Policy Entropy: 3.65265
Value Function Loss: 0.04874

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11022
Policy Update Magnitude: 0.65577
Value Function Update Magnitude: 0.36937

Collected Steps per Second: 22,447.35311
Overall Steps per Second: 10,595.46029

Timestep Collection Time: 2.22779
Timestep Consumption Time: 2.49197
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.71976

Cumulative Model Updates: 167,352
Cumulative Timesteps: 1,395,555,846

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,981.88801
Policy Entropy: 3.67336
Value Function Loss: 0.03794

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.63982
Value Function Update Magnitude: 0.38873

Collected Steps per Second: 22,737.75645
Overall Steps per Second: 10,785.88798

Timestep Collection Time: 2.19951
Timestep Consumption Time: 2.43729
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.63680

Cumulative Model Updates: 167,358
Cumulative Timesteps: 1,395,605,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1395605858...
Checkpoint 1395605858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,981.88801
Policy Entropy: 3.68500
Value Function Loss: 0.03303

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.16365
Policy Update Magnitude: 0.53894
Value Function Update Magnitude: 0.35063

Collected Steps per Second: 22,354.35106
Overall Steps per Second: 10,641.28714

Timestep Collection Time: 2.23706
Timestep Consumption Time: 2.46237
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.69943

Cumulative Model Updates: 167,364
Cumulative Timesteps: 1,395,655,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,981.88801
Policy Entropy: 3.68984
Value Function Loss: 0.03019

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.18834
Policy Update Magnitude: 0.41629
Value Function Update Magnitude: 0.31958

Collected Steps per Second: 22,775.86504
Overall Steps per Second: 10,543.52260

Timestep Collection Time: 2.19531
Timestep Consumption Time: 2.54694
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.74225

Cumulative Model Updates: 167,370
Cumulative Timesteps: 1,395,705,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1395705866...
Checkpoint 1395705866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,981.88801
Policy Entropy: 3.70214
Value Function Loss: 0.02769

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.15786
Policy Update Magnitude: 0.34226
Value Function Update Magnitude: 0.34861

Collected Steps per Second: 22,448.14945
Overall Steps per Second: 10,700.69307

Timestep Collection Time: 2.22878
Timestep Consumption Time: 2.44680
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.67558

Cumulative Model Updates: 167,376
Cumulative Timesteps: 1,395,755,898

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,981.88801
Policy Entropy: 3.69420
Value Function Loss: 0.02960

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.15580
Policy Update Magnitude: 0.32684
Value Function Update Magnitude: 0.40616

Collected Steps per Second: 22,575.28887
Overall Steps per Second: 10,582.52683

Timestep Collection Time: 2.21579
Timestep Consumption Time: 2.51106
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.72685

Cumulative Model Updates: 167,382
Cumulative Timesteps: 1,395,805,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1395805920...
Checkpoint 1395805920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167,825.63387
Policy Entropy: 3.70565
Value Function Loss: 0.04053

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.43313
Value Function Update Magnitude: 0.66207

Collected Steps per Second: 22,253.71360
Overall Steps per Second: 10,462.25124

Timestep Collection Time: 2.24816
Timestep Consumption Time: 2.53379
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.78195

Cumulative Model Updates: 167,388
Cumulative Timesteps: 1,395,855,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766,214.90675
Policy Entropy: 3.68007
Value Function Loss: 0.04587

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.57922
Value Function Update Magnitude: 0.87195

Collected Steps per Second: 22,621.74494
Overall Steps per Second: 10,549.58376

Timestep Collection Time: 2.21159
Timestep Consumption Time: 2.53078
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.74237

Cumulative Model Updates: 167,394
Cumulative Timesteps: 1,395,905,980

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1395905980...
Checkpoint 1395905980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 766,214.90675
Policy Entropy: 3.70133
Value Function Loss: 0.04122

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.56658
Value Function Update Magnitude: 0.89557

Collected Steps per Second: 22,336.55639
Overall Steps per Second: 10,580.90443

Timestep Collection Time: 2.23866
Timestep Consumption Time: 2.48721
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.72587

Cumulative Model Updates: 167,400
Cumulative Timesteps: 1,395,955,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203,955.18127
Policy Entropy: 3.68499
Value Function Loss: 0.03925

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.15368
Policy Update Magnitude: 0.47815
Value Function Update Magnitude: 0.70702

Collected Steps per Second: 22,674.71583
Overall Steps per Second: 10,573.64118

Timestep Collection Time: 2.20510
Timestep Consumption Time: 2.52364
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.72874

Cumulative Model Updates: 167,406
Cumulative Timesteps: 1,396,005,984

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1396005984...
Checkpoint 1396005984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419,805.68849
Policy Entropy: 3.70846
Value Function Loss: 0.03868

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14746
Policy Update Magnitude: 0.47769
Value Function Update Magnitude: 0.69737

Collected Steps per Second: 22,365.92278
Overall Steps per Second: 10,494.76014

Timestep Collection Time: 2.23554
Timestep Consumption Time: 2.52874
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.76428

Cumulative Model Updates: 167,412
Cumulative Timesteps: 1,396,055,984

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340,041.49048
Policy Entropy: 3.67321
Value Function Loss: 0.04573

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.15797
Policy Update Magnitude: 0.50201
Value Function Update Magnitude: 0.64487

Collected Steps per Second: 22,660.62045
Overall Steps per Second: 10,618.07489

Timestep Collection Time: 2.20779
Timestep Consumption Time: 2.50398
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.71178

Cumulative Model Updates: 167,418
Cumulative Timesteps: 1,396,106,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1396106014...
Checkpoint 1396106014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340,041.49048
Policy Entropy: 3.66219
Value Function Loss: 0.04580

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.50202
Value Function Update Magnitude: 0.66055

Collected Steps per Second: 22,540.48549
Overall Steps per Second: 10,678.09557

Timestep Collection Time: 2.21903
Timestep Consumption Time: 2.46514
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.68417

Cumulative Model Updates: 167,424
Cumulative Timesteps: 1,396,156,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340,041.49048
Policy Entropy: 3.64390
Value Function Loss: 0.04612

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.45566
Value Function Update Magnitude: 0.59029

Collected Steps per Second: 22,772.17779
Overall Steps per Second: 10,644.53332

Timestep Collection Time: 2.19645
Timestep Consumption Time: 2.50249
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.69894

Cumulative Model Updates: 167,430
Cumulative Timesteps: 1,396,206,050

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1396206050...
Checkpoint 1396206050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340,041.49048
Policy Entropy: 3.64446
Value Function Loss: 0.04536

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.41433
Value Function Update Magnitude: 0.45424

Collected Steps per Second: 21,866.21839
Overall Steps per Second: 10,623.53755

Timestep Collection Time: 2.28727
Timestep Consumption Time: 2.42058
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.70785

Cumulative Model Updates: 167,436
Cumulative Timesteps: 1,396,256,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340,041.49048
Policy Entropy: 3.65553
Value Function Loss: 0.04185

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.42710
Value Function Update Magnitude: 0.43455

Collected Steps per Second: 21,315.74060
Overall Steps per Second: 10,602.57719

Timestep Collection Time: 2.34606
Timestep Consumption Time: 2.37053
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.71659

Cumulative Model Updates: 167,442
Cumulative Timesteps: 1,396,306,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1396306072...
Checkpoint 1396306072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,598,929.48247
Policy Entropy: 3.66535
Value Function Loss: 0.04052

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.44723
Value Function Update Magnitude: 0.48979

Collected Steps per Second: 21,693.63035
Overall Steps per Second: 10,429.03416

Timestep Collection Time: 2.30621
Timestep Consumption Time: 2.49098
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.79718

Cumulative Model Updates: 167,448
Cumulative Timesteps: 1,396,356,102

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049,068.91557
Policy Entropy: 3.67014
Value Function Loss: 0.03486

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.43609
Value Function Update Magnitude: 0.61466

Collected Steps per Second: 22,337.58430
Overall Steps per Second: 10,717.92071

Timestep Collection Time: 2.23936
Timestep Consumption Time: 2.42777
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.66714

Cumulative Model Updates: 167,454
Cumulative Timesteps: 1,396,406,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1396406124...
Checkpoint 1396406124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049,068.91557
Policy Entropy: 3.67155
Value Function Loss: 0.03515

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.39917
Value Function Update Magnitude: 0.60094

Collected Steps per Second: 22,355.76238
Overall Steps per Second: 10,692.21670

Timestep Collection Time: 2.23710
Timestep Consumption Time: 2.44032
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.67742

Cumulative Model Updates: 167,460
Cumulative Timesteps: 1,396,456,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351,643.11248
Policy Entropy: 3.65496
Value Function Loss: 0.03488

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.38261
Value Function Update Magnitude: 0.56987

Collected Steps per Second: 22,917.93362
Overall Steps per Second: 10,651.97588

Timestep Collection Time: 2.18405
Timestep Consumption Time: 2.51498
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.69903

Cumulative Model Updates: 167,466
Cumulative Timesteps: 1,396,506,190

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1396506190...
Checkpoint 1396506190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351,643.11248
Policy Entropy: 3.66513
Value Function Loss: 0.03112

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13434
Policy Update Magnitude: 0.38619
Value Function Update Magnitude: 0.67454

Collected Steps per Second: 22,678.48435
Overall Steps per Second: 10,638.09513

Timestep Collection Time: 2.20535
Timestep Consumption Time: 2.49606
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.70141

Cumulative Model Updates: 167,472
Cumulative Timesteps: 1,396,556,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351,643.11248
Policy Entropy: 3.65738
Value Function Loss: 0.03456

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.37686
Value Function Update Magnitude: 0.54158

Collected Steps per Second: 22,714.65776
Overall Steps per Second: 10,706.36422

Timestep Collection Time: 2.20175
Timestep Consumption Time: 2.46949
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.67124

Cumulative Model Updates: 167,478
Cumulative Timesteps: 1,396,606,216

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1396606216...
Checkpoint 1396606216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351,643.11248
Policy Entropy: 3.67322
Value Function Loss: 0.03096

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.36075
Value Function Update Magnitude: 0.35611

Collected Steps per Second: 22,455.87831
Overall Steps per Second: 10,723.39656

Timestep Collection Time: 2.22703
Timestep Consumption Time: 2.43660
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.66363

Cumulative Model Updates: 167,484
Cumulative Timesteps: 1,396,656,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351,643.11248
Policy Entropy: 3.67110
Value Function Loss: 0.02815

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.35760
Value Function Update Magnitude: 0.32213

Collected Steps per Second: 22,912.55816
Overall Steps per Second: 10,770.05576

Timestep Collection Time: 2.18378
Timestep Consumption Time: 2.46206
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.64584

Cumulative Model Updates: 167,490
Cumulative Timesteps: 1,396,706,262

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1396706262...
Checkpoint 1396706262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351,643.11248
Policy Entropy: 3.66543
Value Function Loss: 0.02957

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.39918
Value Function Update Magnitude: 0.36531

Collected Steps per Second: 22,499.99123
Overall Steps per Second: 10,724.26436

Timestep Collection Time: 2.22293
Timestep Consumption Time: 2.44088
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.66382

Cumulative Model Updates: 167,496
Cumulative Timesteps: 1,396,756,278

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351,643.11248
Policy Entropy: 3.66129
Value Function Loss: 0.02753

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.44024
Value Function Update Magnitude: 0.36022

Collected Steps per Second: 22,639.68190
Overall Steps per Second: 10,585.44561

Timestep Collection Time: 2.20939
Timestep Consumption Time: 2.51596
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.72536

Cumulative Model Updates: 167,502
Cumulative Timesteps: 1,396,806,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1396806298...
Checkpoint 1396806298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351,643.11248
Policy Entropy: 3.64689
Value Function Loss: 0.03205

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11319
Policy Update Magnitude: 0.42066
Value Function Update Magnitude: 0.32630

Collected Steps per Second: 22,616.94995
Overall Steps per Second: 10,583.02283

Timestep Collection Time: 2.21153
Timestep Consumption Time: 2.51472
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.72625

Cumulative Model Updates: 167,508
Cumulative Timesteps: 1,396,856,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351,643.11248
Policy Entropy: 3.65607
Value Function Loss: 0.02863

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10087
Policy Update Magnitude: 0.47467
Value Function Update Magnitude: 0.25881

Collected Steps per Second: 22,982.86358
Overall Steps per Second: 10,799.66961

Timestep Collection Time: 2.17614
Timestep Consumption Time: 2.45492
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.63107

Cumulative Model Updates: 167,514
Cumulative Timesteps: 1,396,906,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1396906330...
Checkpoint 1396906330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351,643.11248
Policy Entropy: 3.65154
Value Function Loss: 0.03336

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07750
Policy Update Magnitude: 0.56555
Value Function Update Magnitude: 0.25699

Collected Steps per Second: 22,558.59034
Overall Steps per Second: 10,682.33055

Timestep Collection Time: 2.21698
Timestep Consumption Time: 2.46477
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.68175

Cumulative Model Updates: 167,520
Cumulative Timesteps: 1,396,956,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892,997.97389
Policy Entropy: 3.66927
Value Function Loss: 0.03695

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.66322
Value Function Update Magnitude: 0.45045

Collected Steps per Second: 21,954.11747
Overall Steps per Second: 10,613.05082

Timestep Collection Time: 2.27848
Timestep Consumption Time: 2.43477
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.71325

Cumulative Model Updates: 167,526
Cumulative Timesteps: 1,397,006,364

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1397006364...
Checkpoint 1397006364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723,333.34587
Policy Entropy: 3.66927
Value Function Loss: 0.03678

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14230
Policy Update Magnitude: 0.68194
Value Function Update Magnitude: 0.68647

Collected Steps per Second: 21,639.25207
Overall Steps per Second: 10,534.56361

Timestep Collection Time: 2.31173
Timestep Consumption Time: 2.43683
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.74856

Cumulative Model Updates: 167,532
Cumulative Timesteps: 1,397,056,388

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,333.34587
Policy Entropy: 3.67747
Value Function Loss: 0.03479

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15878
Policy Update Magnitude: 0.58138
Value Function Update Magnitude: 0.75620

Collected Steps per Second: 22,059.04207
Overall Steps per Second: 10,515.60719

Timestep Collection Time: 2.26773
Timestep Consumption Time: 2.48939
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.75712

Cumulative Model Updates: 167,538
Cumulative Timesteps: 1,397,106,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1397106412...
Checkpoint 1397106412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723,333.34587
Policy Entropy: 3.67701
Value Function Loss: 0.03311

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.16815
Policy Update Magnitude: 0.48397
Value Function Update Magnitude: 0.59613

Collected Steps per Second: 22,289.99298
Overall Steps per Second: 10,553.90170

Timestep Collection Time: 2.24325
Timestep Consumption Time: 2.49453
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.73777

Cumulative Model Updates: 167,544
Cumulative Timesteps: 1,397,156,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,333.34587
Policy Entropy: 3.66618
Value Function Loss: 0.03173

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.20470
Policy Update Magnitude: 0.36813
Value Function Update Magnitude: 0.44416

Collected Steps per Second: 22,691.13297
Overall Steps per Second: 10,771.75186

Timestep Collection Time: 2.20350
Timestep Consumption Time: 2.43827
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.64177

Cumulative Model Updates: 167,550
Cumulative Timesteps: 1,397,206,414

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1397206414...
Checkpoint 1397206414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723,333.34587
Policy Entropy: 3.67436
Value Function Loss: 0.03701

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.17856
Policy Update Magnitude: 0.31012
Value Function Update Magnitude: 0.30415

Collected Steps per Second: 22,511.56202
Overall Steps per Second: 10,682.83551

Timestep Collection Time: 2.22215
Timestep Consumption Time: 2.46050
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.68265

Cumulative Model Updates: 167,556
Cumulative Timesteps: 1,397,256,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,333.34587
Policy Entropy: 3.66233
Value Function Loss: 0.03552

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.33165
Value Function Update Magnitude: 0.26814

Collected Steps per Second: 23,057.79592
Overall Steps per Second: 10,707.07598

Timestep Collection Time: 2.16872
Timestep Consumption Time: 2.50165
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.67037

Cumulative Model Updates: 167,562
Cumulative Timesteps: 1,397,306,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1397306444...
Checkpoint 1397306444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008,275.64846
Policy Entropy: 3.65920
Value Function Loss: 0.04622

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.20083
Policy Update Magnitude: 0.43754
Value Function Update Magnitude: 0.43060

Collected Steps per Second: 22,640.80811
Overall Steps per Second: 10,630.77384

Timestep Collection Time: 2.20929
Timestep Consumption Time: 2.49592
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.70521

Cumulative Model Updates: 167,568
Cumulative Timesteps: 1,397,356,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,573.91900
Policy Entropy: 3.67542
Value Function Loss: 0.05208

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.17856
Policy Update Magnitude: 0.62362
Value Function Update Magnitude: 0.73406

Collected Steps per Second: 22,785.62022
Overall Steps per Second: 10,661.38133

Timestep Collection Time: 2.19445
Timestep Consumption Time: 2.49556
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.69001

Cumulative Model Updates: 167,574
Cumulative Timesteps: 1,397,406,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1397406466...
Checkpoint 1397406466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374,688.25503
Policy Entropy: 3.65828
Value Function Loss: 0.05167

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.17842
Policy Update Magnitude: 0.60004
Value Function Update Magnitude: 0.74188

Collected Steps per Second: 21,976.59610
Overall Steps per Second: 10,435.87704

Timestep Collection Time: 2.27660
Timestep Consumption Time: 2.51763
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.79423

Cumulative Model Updates: 167,580
Cumulative Timesteps: 1,397,456,498

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374,688.25503
Policy Entropy: 3.70055
Value Function Loss: 0.04208

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.19951
Policy Update Magnitude: 0.52162
Value Function Update Magnitude: 0.75537

Collected Steps per Second: 22,826.77548
Overall Steps per Second: 10,790.29355

Timestep Collection Time: 2.19137
Timestep Consumption Time: 2.44446
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.63583

Cumulative Model Updates: 167,586
Cumulative Timesteps: 1,397,506,520

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1397506520...
Checkpoint 1397506520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374,688.25503
Policy Entropy: 3.64883
Value Function Loss: 0.03737

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.17403
Policy Update Magnitude: 0.47302
Value Function Update Magnitude: 0.58493

Collected Steps per Second: 22,814.62922
Overall Steps per Second: 10,611.99111

Timestep Collection Time: 2.19245
Timestep Consumption Time: 2.52108
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.71354

Cumulative Model Updates: 167,592
Cumulative Timesteps: 1,397,556,540

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374,688.25503
Policy Entropy: 3.64102
Value Function Loss: 0.06103

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.17394
Policy Update Magnitude: 0.68770
Value Function Update Magnitude: 0.50023

Collected Steps per Second: 22,463.50724
Overall Steps per Second: 10,518.72536

Timestep Collection Time: 2.22690
Timestep Consumption Time: 2.52881
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.75571

Cumulative Model Updates: 167,598
Cumulative Timesteps: 1,397,606,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1397606564...
Checkpoint 1397606564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978,301.34061
Policy Entropy: 3.63739
Value Function Loss: 0.06535

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.18113
Policy Update Magnitude: 0.85385
Value Function Update Magnitude: 0.75978

Collected Steps per Second: 22,369.13646
Overall Steps per Second: 10,587.69004

Timestep Collection Time: 2.23594
Timestep Consumption Time: 2.48804
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.72398

Cumulative Model Updates: 167,604
Cumulative Timesteps: 1,397,656,580

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 792,425.67195
Policy Entropy: 3.69765
Value Function Loss: 0.06796

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.21902
Policy Update Magnitude: 0.75828
Value Function Update Magnitude: 0.85435

Collected Steps per Second: 22,572.25110
Overall Steps per Second: 10,582.07976

Timestep Collection Time: 2.21608
Timestep Consumption Time: 2.51096
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.72705

Cumulative Model Updates: 167,610
Cumulative Timesteps: 1,397,706,602

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1397706602...
Checkpoint 1397706602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239,219.95197
Policy Entropy: 3.73114
Value Function Loss: 0.05988

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16740
Policy Update Magnitude: 0.64923
Value Function Update Magnitude: 0.72584

Collected Steps per Second: 22,386.12316
Overall Steps per Second: 10,527.66683

Timestep Collection Time: 2.23433
Timestep Consumption Time: 2.51677
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.75110

Cumulative Model Updates: 167,616
Cumulative Timesteps: 1,397,756,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239,219.95197
Policy Entropy: 3.70463
Value Function Loss: 0.05073

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.16332
Policy Update Magnitude: 0.57144
Value Function Update Magnitude: 0.59096

Collected Steps per Second: 22,777.92484
Overall Steps per Second: 10,759.23264

Timestep Collection Time: 2.19555
Timestep Consumption Time: 2.45255
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.64810

Cumulative Model Updates: 167,622
Cumulative Timesteps: 1,397,806,630

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1397806630...
Checkpoint 1397806630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186,849.12487
Policy Entropy: 3.69911
Value Function Loss: 0.04620

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.15399
Policy Update Magnitude: 0.48574
Value Function Update Magnitude: 0.55822

Collected Steps per Second: 21,684.52732
Overall Steps per Second: 10,685.27084

Timestep Collection Time: 2.30708
Timestep Consumption Time: 2.37488
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.68196

Cumulative Model Updates: 167,628
Cumulative Timesteps: 1,397,856,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298,548.49212
Policy Entropy: 3.70806
Value Function Loss: 0.03984

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15568
Policy Update Magnitude: 0.46717
Value Function Update Magnitude: 0.72536

Collected Steps per Second: 21,884.83072
Overall Steps per Second: 10,565.63647

Timestep Collection Time: 2.28569
Timestep Consumption Time: 2.44871
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.73440

Cumulative Model Updates: 167,634
Cumulative Timesteps: 1,397,906,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1397906680...
Checkpoint 1397906680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,311.70505
Policy Entropy: 3.72611
Value Function Loss: 0.05152

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15766
Policy Update Magnitude: 0.56441
Value Function Update Magnitude: 0.79192

Collected Steps per Second: 21,313.90095
Overall Steps per Second: 10,358.96118

Timestep Collection Time: 2.34654
Timestep Consumption Time: 2.48155
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.82809

Cumulative Model Updates: 167,640
Cumulative Timesteps: 1,397,956,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,332.66456
Policy Entropy: 3.73393
Value Function Loss: 0.05057

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.16880
Policy Update Magnitude: 0.61372
Value Function Update Magnitude: 0.98640

Collected Steps per Second: 19,406.99487
Overall Steps per Second: 9,855.17018

Timestep Collection Time: 2.57742
Timestep Consumption Time: 2.49809
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 5.07551

Cumulative Model Updates: 167,646
Cumulative Timesteps: 1,398,006,714

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1398006714...
Checkpoint 1398006714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354,601.20847
Policy Entropy: 3.72205
Value Function Loss: 0.06259

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.16997
Policy Update Magnitude: 0.60304
Value Function Update Magnitude: 0.80859

Collected Steps per Second: 21,651.00051
Overall Steps per Second: 10,381.11740

Timestep Collection Time: 2.30936
Timestep Consumption Time: 2.50708
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.81644

Cumulative Model Updates: 167,652
Cumulative Timesteps: 1,398,056,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,867.33761
Policy Entropy: 3.71574
Value Function Loss: 0.05803

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.16379
Policy Update Magnitude: 0.71233
Value Function Update Magnitude: 0.66763

Collected Steps per Second: 22,422.55585
Overall Steps per Second: 10,705.53275

Timestep Collection Time: 2.23088
Timestep Consumption Time: 2.44166
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.67254

Cumulative Model Updates: 167,658
Cumulative Timesteps: 1,398,106,736

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1398106736...
Checkpoint 1398106736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.71440
Value Function Loss: 0.05537

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.18102
Policy Update Magnitude: 0.63379
Value Function Update Magnitude: 0.59653

Collected Steps per Second: 22,632.55698
Overall Steps per Second: 10,704.87180

Timestep Collection Time: 2.20991
Timestep Consumption Time: 2.46235
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.67227

Cumulative Model Updates: 167,664
Cumulative Timesteps: 1,398,156,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.71944
Value Function Loss: 0.04743

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.16423
Policy Update Magnitude: 0.50311
Value Function Update Magnitude: 0.51955

Collected Steps per Second: 22,569.46999
Overall Steps per Second: 10,518.34590

Timestep Collection Time: 2.21591
Timestep Consumption Time: 2.53883
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.75474

Cumulative Model Updates: 167,670
Cumulative Timesteps: 1,398,206,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1398206764...
Checkpoint 1398206764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.70855
Value Function Loss: 0.04718

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.16033
Policy Update Magnitude: 0.57416
Value Function Update Magnitude: 0.46520

Collected Steps per Second: 22,422.10875
Overall Steps per Second: 10,544.00424

Timestep Collection Time: 2.23030
Timestep Consumption Time: 2.51249
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.74279

Cumulative Model Updates: 167,676
Cumulative Timesteps: 1,398,256,772

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.69320
Value Function Loss: 0.04144

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15067
Policy Update Magnitude: 0.57335
Value Function Update Magnitude: 0.57039

Collected Steps per Second: 22,390.35661
Overall Steps per Second: 10,473.57521

Timestep Collection Time: 2.23337
Timestep Consumption Time: 2.54112
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.77449

Cumulative Model Updates: 167,682
Cumulative Timesteps: 1,398,306,778

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1398306778...
Checkpoint 1398306778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.70371
Value Function Loss: 0.03765

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.15789
Policy Update Magnitude: 0.53691
Value Function Update Magnitude: 0.53587

Collected Steps per Second: 22,623.17265
Overall Steps per Second: 10,667.79892

Timestep Collection Time: 2.21092
Timestep Consumption Time: 2.47777
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.68869

Cumulative Model Updates: 167,688
Cumulative Timesteps: 1,398,356,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.70093
Value Function Loss: 0.03121

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14839
Policy Update Magnitude: 0.43995
Value Function Update Magnitude: 0.42114

Collected Steps per Second: 22,479.74042
Overall Steps per Second: 10,505.70597

Timestep Collection Time: 2.22529
Timestep Consumption Time: 2.53631
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.76160

Cumulative Model Updates: 167,694
Cumulative Timesteps: 1,398,406,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1398406820...
Checkpoint 1398406820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.70470
Value Function Loss: 0.03203

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.37658
Value Function Update Magnitude: 0.31733

Collected Steps per Second: 22,384.22727
Overall Steps per Second: 10,537.45642

Timestep Collection Time: 2.23407
Timestep Consumption Time: 2.51166
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.74574

Cumulative Model Updates: 167,700
Cumulative Timesteps: 1,398,456,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.69125
Value Function Loss: 0.02992

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.33876
Value Function Update Magnitude: 0.25991

Collected Steps per Second: 22,617.51161
Overall Steps per Second: 10,553.48059

Timestep Collection Time: 2.21121
Timestep Consumption Time: 2.52770
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.73891

Cumulative Model Updates: 167,706
Cumulative Timesteps: 1,398,506,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1398506840...
Checkpoint 1398506840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.69160
Value Function Loss: 0.02811

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.30933
Value Function Update Magnitude: 0.32320

Collected Steps per Second: 22,730.31154
Overall Steps per Second: 10,615.47782

Timestep Collection Time: 2.20032
Timestep Consumption Time: 2.51110
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.71142

Cumulative Model Updates: 167,712
Cumulative Timesteps: 1,398,556,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.66780
Value Function Loss: 0.03224

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.33275
Value Function Update Magnitude: 0.39286

Collected Steps per Second: 21,903.77758
Overall Steps per Second: 10,630.89778

Timestep Collection Time: 2.28408
Timestep Consumption Time: 2.42201
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.70609

Cumulative Model Updates: 167,718
Cumulative Timesteps: 1,398,606,884

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1398606884...
Checkpoint 1398606884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.66848
Value Function Loss: 0.03718

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14352
Policy Update Magnitude: 0.38223
Value Function Update Magnitude: 0.36214

Collected Steps per Second: 21,722.50516
Overall Steps per Second: 10,557.65692

Timestep Collection Time: 2.30176
Timestep Consumption Time: 2.43414
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.73590

Cumulative Model Updates: 167,724
Cumulative Timesteps: 1,398,656,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.67165
Value Function Loss: 0.03801

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14300
Policy Update Magnitude: 0.41855
Value Function Update Magnitude: 0.35867

Collected Steps per Second: 22,223.62444
Overall Steps per Second: 10,693.31954

Timestep Collection Time: 2.25040
Timestep Consumption Time: 2.42654
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.67694

Cumulative Model Updates: 167,730
Cumulative Timesteps: 1,398,706,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1398706896...
Checkpoint 1398706896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.67947
Value Function Loss: 0.03220

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13986
Policy Update Magnitude: 0.41241
Value Function Update Magnitude: 0.40824

Collected Steps per Second: 22,645.48162
Overall Steps per Second: 10,757.29540

Timestep Collection Time: 2.20856
Timestep Consumption Time: 2.44075
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.64931

Cumulative Model Updates: 167,736
Cumulative Timesteps: 1,398,756,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.68012
Value Function Loss: 0.02952

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.15625
Policy Update Magnitude: 0.41121
Value Function Update Magnitude: 0.40876

Collected Steps per Second: 22,035.75566
Overall Steps per Second: 10,472.67848

Timestep Collection Time: 2.26904
Timestep Consumption Time: 2.50529
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.77433

Cumulative Model Updates: 167,742
Cumulative Timesteps: 1,398,806,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1398806910...
Checkpoint 1398806910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,804.64140
Policy Entropy: 3.67717
Value Function Loss: 0.03159

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.43589
Value Function Update Magnitude: 0.37826

Collected Steps per Second: 22,628.19819
Overall Steps per Second: 10,574.32193

Timestep Collection Time: 2.21087
Timestep Consumption Time: 2.52021
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.73108

Cumulative Model Updates: 167,748
Cumulative Timesteps: 1,398,856,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287,789.19478
Policy Entropy: 3.68769
Value Function Loss: 0.03214

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.16395
Policy Update Magnitude: 0.38563
Value Function Update Magnitude: 0.43277

Collected Steps per Second: 22,415.11429
Overall Steps per Second: 10,469.05971

Timestep Collection Time: 2.23153
Timestep Consumption Time: 2.54636
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.77789

Cumulative Model Updates: 167,754
Cumulative Timesteps: 1,398,906,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1398906958...
Checkpoint 1398906958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,969.29849
Policy Entropy: 3.70216
Value Function Loss: 0.03473

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14098
Policy Update Magnitude: 0.40013
Value Function Update Magnitude: 0.48754

Collected Steps per Second: 22,533.38162
Overall Steps per Second: 10,730.56241

Timestep Collection Time: 2.22008
Timestep Consumption Time: 2.44193
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.66201

Cumulative Model Updates: 167,760
Cumulative Timesteps: 1,398,956,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,367.45423
Policy Entropy: 3.71755
Value Function Loss: 0.03436

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.44651
Value Function Update Magnitude: 0.64489

Collected Steps per Second: 22,689.76074
Overall Steps per Second: 10,734.78265

Timestep Collection Time: 2.20487
Timestep Consumption Time: 2.45549
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.66036

Cumulative Model Updates: 167,766
Cumulative Timesteps: 1,399,007,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1399007012...
Checkpoint 1399007012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,439.54244
Policy Entropy: 3.69422
Value Function Loss: 0.03853

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11984
Policy Update Magnitude: 0.46051
Value Function Update Magnitude: 0.72322

Collected Steps per Second: 21,994.09073
Overall Steps per Second: 10,456.17264

Timestep Collection Time: 2.27416
Timestep Consumption Time: 2.50943
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.78359

Cumulative Model Updates: 167,772
Cumulative Timesteps: 1,399,057,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185,439.54244
Policy Entropy: 3.67316
Value Function Loss: 0.04015

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12496
Policy Update Magnitude: 0.53458
Value Function Update Magnitude: 0.79244

Collected Steps per Second: 22,579.85723
Overall Steps per Second: 10,709.15864

Timestep Collection Time: 2.21569
Timestep Consumption Time: 2.45601
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.67170

Cumulative Model Updates: 167,778
Cumulative Timesteps: 1,399,107,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1399107060...
Checkpoint 1399107060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,439.54244
Policy Entropy: 3.65573
Value Function Loss: 0.04132

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.50620
Value Function Update Magnitude: 0.56068

Collected Steps per Second: 22,419.58239
Overall Steps per Second: 10,701.73182

Timestep Collection Time: 2.23144
Timestep Consumption Time: 2.44332
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.67476

Cumulative Model Updates: 167,784
Cumulative Timesteps: 1,399,157,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185,439.54244
Policy Entropy: 3.65725
Value Function Loss: 0.04771

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13709
Policy Update Magnitude: 0.51852
Value Function Update Magnitude: 0.40838

Collected Steps per Second: 22,631.51160
Overall Steps per Second: 10,583.22883

Timestep Collection Time: 2.20931
Timestep Consumption Time: 2.51515
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.72446

Cumulative Model Updates: 167,790
Cumulative Timesteps: 1,399,207,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1399207088...
Checkpoint 1399207088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,439.54244
Policy Entropy: 3.66213
Value Function Loss: 0.04787

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14526
Policy Update Magnitude: 0.52710
Value Function Update Magnitude: 0.39046

Collected Steps per Second: 21,649.18604
Overall Steps per Second: 10,515.82734

Timestep Collection Time: 2.30983
Timestep Consumption Time: 2.44548
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.75531

Cumulative Model Updates: 167,796
Cumulative Timesteps: 1,399,257,094

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,600.40907
Policy Entropy: 3.66916
Value Function Loss: 0.05238

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.51146
Value Function Update Magnitude: 0.42857

Collected Steps per Second: 22,085.68167
Overall Steps per Second: 10,791.18858

Timestep Collection Time: 2.26391
Timestep Consumption Time: 2.36950
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.63341

Cumulative Model Updates: 167,802
Cumulative Timesteps: 1,399,307,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1399307094...
Checkpoint 1399307094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,600.40907
Policy Entropy: 3.67257
Value Function Loss: 0.05052

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.15180
Policy Update Magnitude: 0.52895
Value Function Update Magnitude: 0.60328

Collected Steps per Second: 21,493.08666
Overall Steps per Second: 10,390.44873

Timestep Collection Time: 2.32698
Timestep Consumption Time: 2.48648
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.81346

Cumulative Model Updates: 167,808
Cumulative Timesteps: 1,399,357,108

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,600.40907
Policy Entropy: 3.68316
Value Function Loss: 0.04507

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13957
Policy Update Magnitude: 0.52719
Value Function Update Magnitude: 0.64158

Collected Steps per Second: 22,129.93209
Overall Steps per Second: 10,508.26562

Timestep Collection Time: 2.26065
Timestep Consumption Time: 2.50018
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.76082

Cumulative Model Updates: 167,814
Cumulative Timesteps: 1,399,407,136

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1399407136...
Checkpoint 1399407136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,600.40907
Policy Entropy: 3.69137
Value Function Loss: 0.03863

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.46113
Value Function Update Magnitude: 0.51162

Collected Steps per Second: 22,058.44774
Overall Steps per Second: 10,499.81129

Timestep Collection Time: 2.26779
Timestep Consumption Time: 2.49648
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.76428

Cumulative Model Updates: 167,820
Cumulative Timesteps: 1,399,457,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,600.40907
Policy Entropy: 3.70028
Value Function Loss: 0.03094

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.37199
Value Function Update Magnitude: 0.35283

Collected Steps per Second: 22,514.32838
Overall Steps per Second: 10,542.24166

Timestep Collection Time: 2.22143
Timestep Consumption Time: 2.52272
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.74415

Cumulative Model Updates: 167,826
Cumulative Timesteps: 1,399,507,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1399507174...
Checkpoint 1399507174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,600.40907
Policy Entropy: 3.70432
Value Function Loss: 0.02530

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13476
Policy Update Magnitude: 0.30722
Value Function Update Magnitude: 0.25604

Collected Steps per Second: 22,439.98986
Overall Steps per Second: 10,563.38460

Timestep Collection Time: 2.22816
Timestep Consumption Time: 2.50517
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.73333

Cumulative Model Updates: 167,832
Cumulative Timesteps: 1,399,557,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,600.40907
Policy Entropy: 3.69967
Value Function Loss: 0.02245

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.26565
Value Function Update Magnitude: 0.23368

Collected Steps per Second: 22,132.41231
Overall Steps per Second: 10,447.61687

Timestep Collection Time: 2.26030
Timestep Consumption Time: 2.52796
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.78827

Cumulative Model Updates: 167,838
Cumulative Timesteps: 1,399,607,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1399607200...
Checkpoint 1399607200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,600.40907
Policy Entropy: 3.68964
Value Function Loss: 0.02861

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.28699
Value Function Update Magnitude: 0.27744

Collected Steps per Second: 22,516.03276
Overall Steps per Second: 10,645.61032

Timestep Collection Time: 2.22179
Timestep Consumption Time: 2.47742
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.69921

Cumulative Model Updates: 167,844
Cumulative Timesteps: 1,399,657,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,600.40907
Policy Entropy: 3.68652
Value Function Loss: 0.03099

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.37899
Value Function Update Magnitude: 0.34707

Collected Steps per Second: 22,531.32461
Overall Steps per Second: 10,558.70750

Timestep Collection Time: 2.21922
Timestep Consumption Time: 2.51640
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.73562

Cumulative Model Updates: 167,850
Cumulative Timesteps: 1,399,707,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1399707228...
Checkpoint 1399707228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,600.40907
Policy Entropy: 3.68462
Value Function Loss: 0.03710

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.42864
Value Function Update Magnitude: 0.41083

Collected Steps per Second: 22,587.49583
Overall Steps per Second: 10,536.02390

Timestep Collection Time: 2.21415
Timestep Consumption Time: 2.53262
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.74676

Cumulative Model Updates: 167,856
Cumulative Timesteps: 1,399,757,240

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,600.40907
Policy Entropy: 3.68572
Value Function Loss: 0.03205

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13530
Policy Update Magnitude: 0.42757
Value Function Update Magnitude: 0.42367

Collected Steps per Second: 22,898.17446
Overall Steps per Second: 10,780.06429

Timestep Collection Time: 2.18402
Timestep Consumption Time: 2.45510
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.63912

Cumulative Model Updates: 167,862
Cumulative Timesteps: 1,399,807,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1399807250...
Checkpoint 1399807250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 810,863.93117
Policy Entropy: 3.69171
Value Function Loss: 0.03217

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.42478
Value Function Update Magnitude: 0.50901

Collected Steps per Second: 22,518.04427
Overall Steps per Second: 10,701.62875

Timestep Collection Time: 2.22044
Timestep Consumption Time: 2.45174
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.67219

Cumulative Model Updates: 167,868
Cumulative Timesteps: 1,399,857,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282,745.35450
Policy Entropy: 3.69013
Value Function Loss: 0.03334

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.42570
Value Function Update Magnitude: 0.61462

Collected Steps per Second: 21,581.36214
Overall Steps per Second: 10,500.65497

Timestep Collection Time: 2.31718
Timestep Consumption Time: 2.44519
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.76237

Cumulative Model Updates: 167,874
Cumulative Timesteps: 1,399,907,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1399907258...
Checkpoint 1399907258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,167,565.87066
Policy Entropy: 3.68896
Value Function Loss: 0.04235

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13440
Policy Update Magnitude: 0.46789
Value Function Update Magnitude: 0.62072

Collected Steps per Second: 21,980.53334
Overall Steps per Second: 10,677.62414

Timestep Collection Time: 2.27538
Timestep Consumption Time: 2.40862
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.68400

Cumulative Model Updates: 167,880
Cumulative Timesteps: 1,399,957,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755,812.23683
Policy Entropy: 3.68881
Value Function Loss: 0.04117

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14263
Policy Update Magnitude: 0.47814
Value Function Update Magnitude: 0.67070

Collected Steps per Second: 21,876.08730
Overall Steps per Second: 10,581.46292

Timestep Collection Time: 2.28606
Timestep Consumption Time: 2.44013
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.72619

Cumulative Model Updates: 167,886
Cumulative Timesteps: 1,400,007,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1400007282...
Checkpoint 1400007282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,480.43134
Policy Entropy: 3.69196
Value Function Loss: 0.04188

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13476
Policy Update Magnitude: 0.43155
Value Function Update Magnitude: 0.65391

Collected Steps per Second: 21,931.15983
Overall Steps per Second: 10,477.70919

Timestep Collection Time: 2.28123
Timestep Consumption Time: 2.49367
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.77490

Cumulative Model Updates: 167,892
Cumulative Timesteps: 1,400,057,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,903.66251
Policy Entropy: 3.71216
Value Function Loss: 0.03628

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13765
Policy Update Magnitude: 0.40660
Value Function Update Magnitude: 0.58513

Collected Steps per Second: 22,517.24356
Overall Steps per Second: 10,618.66373

Timestep Collection Time: 2.22070
Timestep Consumption Time: 2.48837
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.70907

Cumulative Model Updates: 167,898
Cumulative Timesteps: 1,400,107,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1400107316...
Checkpoint 1400107316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,076.65359
Policy Entropy: 3.70346
Value Function Loss: 0.03850

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.38602
Value Function Update Magnitude: 0.56049

Collected Steps per Second: 22,196.71186
Overall Steps per Second: 10,539.36825

Timestep Collection Time: 2.25277
Timestep Consumption Time: 2.49173
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.74450

Cumulative Model Updates: 167,904
Cumulative Timesteps: 1,400,157,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346,952.39554
Policy Entropy: 3.71110
Value Function Loss: 0.03642

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.38760
Value Function Update Magnitude: 0.68963

Collected Steps per Second: 22,249.57734
Overall Steps per Second: 10,458.85748

Timestep Collection Time: 2.24723
Timestep Consumption Time: 2.53340
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.78064

Cumulative Model Updates: 167,910
Cumulative Timesteps: 1,400,207,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1400207320...
Checkpoint 1400207320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346,952.39554
Policy Entropy: 3.68779
Value Function Loss: 0.03272

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13784
Policy Update Magnitude: 0.39761
Value Function Update Magnitude: 0.82410

Collected Steps per Second: 22,440.15909
Overall Steps per Second: 10,550.84424

Timestep Collection Time: 2.22850
Timestep Consumption Time: 2.51121
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.73972

Cumulative Model Updates: 167,916
Cumulative Timesteps: 1,400,257,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346,952.39554
Policy Entropy: 3.68972
Value Function Loss: 0.02922

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.35500
Value Function Update Magnitude: 0.65498

Collected Steps per Second: 22,411.56768
Overall Steps per Second: 10,499.23916

Timestep Collection Time: 2.23135
Timestep Consumption Time: 2.53166
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.76301

Cumulative Model Updates: 167,922
Cumulative Timesteps: 1,400,307,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1400307336...
Checkpoint 1400307336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,639,234.90633
Policy Entropy: 3.67821
Value Function Loss: 0.02910

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.35623
Value Function Update Magnitude: 0.52994

Collected Steps per Second: 22,546.77692
Overall Steps per Second: 10,614.13361

Timestep Collection Time: 2.21832
Timestep Consumption Time: 2.49389
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.71221

Cumulative Model Updates: 167,928
Cumulative Timesteps: 1,400,357,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,639,234.90633
Policy Entropy: 3.67454
Value Function Loss: 0.02928

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13432
Policy Update Magnitude: 0.42674
Value Function Update Magnitude: 0.57270

Collected Steps per Second: 22,573.30433
Overall Steps per Second: 10,548.47737

Timestep Collection Time: 2.21536
Timestep Consumption Time: 2.52542
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.74078

Cumulative Model Updates: 167,934
Cumulative Timesteps: 1,400,407,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1400407360...
Checkpoint 1400407360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,639,234.90633
Policy Entropy: 3.68777
Value Function Loss: 0.03112

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.45093
Value Function Update Magnitude: 0.66541

Collected Steps per Second: 22,519.15574
Overall Steps per Second: 10,616.05083

Timestep Collection Time: 2.22095
Timestep Consumption Time: 2.49021
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.71117

Cumulative Model Updates: 167,940
Cumulative Timesteps: 1,400,457,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,223,466.48884
Policy Entropy: 3.68968
Value Function Loss: 0.03721

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.45408
Value Function Update Magnitude: 0.69899

Collected Steps per Second: 22,728.61263
Overall Steps per Second: 10,569.94165

Timestep Collection Time: 2.19996
Timestep Consumption Time: 2.53063
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.73058

Cumulative Model Updates: 167,946
Cumulative Timesteps: 1,400,507,376

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1400507376...
Checkpoint 1400507376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 957,130.70332
Policy Entropy: 3.69365
Value Function Loss: 0.04163

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.47786
Value Function Update Magnitude: 0.68211

Collected Steps per Second: 22,763.37218
Overall Steps per Second: 10,681.82937

Timestep Collection Time: 2.19765
Timestep Consumption Time: 2.48563
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.68328

Cumulative Model Updates: 167,952
Cumulative Timesteps: 1,400,557,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957,130.70332
Policy Entropy: 3.68396
Value Function Loss: 0.04151

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.47567
Value Function Update Magnitude: 0.65285

Collected Steps per Second: 21,928.02993
Overall Steps per Second: 10,756.07992

Timestep Collection Time: 2.28019
Timestep Consumption Time: 2.36835
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.64853

Cumulative Model Updates: 167,958
Cumulative Timesteps: 1,400,607,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1400607402...
Checkpoint 1400607402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 957,130.70332
Policy Entropy: 3.68370
Value Function Loss: 0.03875

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.53404
Value Function Update Magnitude: 0.60283

Collected Steps per Second: 21,971.40703
Overall Steps per Second: 10,599.26204

Timestep Collection Time: 2.27623
Timestep Consumption Time: 2.44221
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.71844

Cumulative Model Updates: 167,964
Cumulative Timesteps: 1,400,657,414

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957,130.70332
Policy Entropy: 3.66510
Value Function Loss: 0.03363

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10832
Policy Update Magnitude: 0.62168
Value Function Update Magnitude: 0.52210

Collected Steps per Second: 22,299.77222
Overall Steps per Second: 10,514.85259

Timestep Collection Time: 2.24334
Timestep Consumption Time: 2.51431
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.75765

Cumulative Model Updates: 167,970
Cumulative Timesteps: 1,400,707,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1400707440...
Checkpoint 1400707440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792,015.61653
Policy Entropy: 3.66852
Value Function Loss: 0.03566

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.17375
Policy Update Magnitude: 0.51993
Value Function Update Magnitude: 0.45845

Collected Steps per Second: 22,620.46672
Overall Steps per Second: 10,622.30234

Timestep Collection Time: 2.21074
Timestep Consumption Time: 2.49709
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.70783

Cumulative Model Updates: 167,976
Cumulative Timesteps: 1,400,757,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587,128.00528
Policy Entropy: 3.67424
Value Function Loss: 0.04335

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.16218
Policy Update Magnitude: 0.47143
Value Function Update Magnitude: 0.59947

Collected Steps per Second: 22,737.52799
Overall Steps per Second: 10,759.82358

Timestep Collection Time: 2.19954
Timestep Consumption Time: 2.44850
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.64803

Cumulative Model Updates: 167,982
Cumulative Timesteps: 1,400,807,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1400807460...
Checkpoint 1400807460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385,239.15583
Policy Entropy: 3.68566
Value Function Loss: 0.04547

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.16669
Policy Update Magnitude: 0.46851
Value Function Update Magnitude: 0.69038

Collected Steps per Second: 22,274.47286
Overall Steps per Second: 10,653.89035

Timestep Collection Time: 2.24499
Timestep Consumption Time: 2.44869
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.69368

Cumulative Model Updates: 167,988
Cumulative Timesteps: 1,400,857,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385,239.15583
Policy Entropy: 3.68225
Value Function Loss: 0.04253

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.15439
Policy Update Magnitude: 0.45950
Value Function Update Magnitude: 0.63972

Collected Steps per Second: 22,570.31131
Overall Steps per Second: 10,537.00374

Timestep Collection Time: 2.21583
Timestep Consumption Time: 2.53049
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.74632

Cumulative Model Updates: 167,994
Cumulative Timesteps: 1,400,907,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1400907478...
Checkpoint 1400907478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279,816.36803
Policy Entropy: 3.67175
Value Function Loss: 0.03776

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14106
Policy Update Magnitude: 0.42398
Value Function Update Magnitude: 0.60245

Collected Steps per Second: 22,723.90021
Overall Steps per Second: 10,668.34195

Timestep Collection Time: 2.20094
Timestep Consumption Time: 2.48713
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.68808

Cumulative Model Updates: 168,000
Cumulative Timesteps: 1,400,957,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,249.52715
Policy Entropy: 3.68295
Value Function Loss: 0.03694

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.59038
Value Function Update Magnitude: 0.51005

Collected Steps per Second: 22,414.02851
Overall Steps per Second: 10,480.16592

Timestep Collection Time: 2.23164
Timestep Consumption Time: 2.54119
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.77283

Cumulative Model Updates: 168,006
Cumulative Timesteps: 1,401,007,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1401007512...
Checkpoint 1401007512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,249.52715
Policy Entropy: 3.67473
Value Function Loss: 0.03820

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.23258
Policy Update Magnitude: 0.58772
Value Function Update Magnitude: 0.47369

Collected Steps per Second: 22,275.81685
Overall Steps per Second: 10,652.91458

Timestep Collection Time: 2.24459
Timestep Consumption Time: 2.44896
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.69355

Cumulative Model Updates: 168,012
Cumulative Timesteps: 1,401,057,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100,491.52598
Policy Entropy: 3.65592
Value Function Loss: 0.07745

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.23171
Policy Update Magnitude: 0.50267
Value Function Update Magnitude: 0.52529

Collected Steps per Second: 22,615.91095
Overall Steps per Second: 10,768.27987

Timestep Collection Time: 2.21189
Timestep Consumption Time: 2.43360
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.64550

Cumulative Model Updates: 168,018
Cumulative Timesteps: 1,401,107,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1401107536...
Checkpoint 1401107536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374,162.23146
Policy Entropy: 3.64625
Value Function Loss: 0.10135

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.20364
Policy Update Magnitude: 0.74224
Value Function Update Magnitude: 0.52256

Collected Steps per Second: 22,073.74364
Overall Steps per Second: 10,470.52169

Timestep Collection Time: 2.26550
Timestep Consumption Time: 2.51058
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.77608

Cumulative Model Updates: 168,024
Cumulative Timesteps: 1,401,157,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426,545.42802
Policy Entropy: 3.64514
Value Function Loss: 0.14732

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.17713
Policy Update Magnitude: 0.79027
Value Function Update Magnitude: 0.49985

Collected Steps per Second: 22,388.66185
Overall Steps per Second: 10,650.21015

Timestep Collection Time: 2.23452
Timestep Consumption Time: 2.46285
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.69737

Cumulative Model Updates: 168,030
Cumulative Timesteps: 1,401,207,572

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1401207572...
Checkpoint 1401207572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,327.82212
Policy Entropy: 3.70591
Value Function Loss: 0.12126

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.17927
Policy Update Magnitude: 0.78644
Value Function Update Magnitude: 0.47995

Collected Steps per Second: 21,286.97790
Overall Steps per Second: 10,595.01524

Timestep Collection Time: 2.34998
Timestep Consumption Time: 2.37148
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.72147

Cumulative Model Updates: 168,036
Cumulative Timesteps: 1,401,257,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.34105
Policy Entropy: 3.74392
Value Function Loss: 0.10996

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.80799
Value Function Update Magnitude: 0.48357

Collected Steps per Second: 21,964.21948
Overall Steps per Second: 10,578.86529

Timestep Collection Time: 2.27670
Timestep Consumption Time: 2.45027
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.72697

Cumulative Model Updates: 168,042
Cumulative Timesteps: 1,401,307,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1401307602...
Checkpoint 1401307602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862,949.12006
Policy Entropy: 3.76934
Value Function Loss: 0.09322

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.87251
Value Function Update Magnitude: 0.57096

Collected Steps per Second: 21,688.23353
Overall Steps per Second: 10,636.13116

Timestep Collection Time: 2.30697
Timestep Consumption Time: 2.39719
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.70415

Cumulative Model Updates: 168,048
Cumulative Timesteps: 1,401,357,636

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,601.95960
Policy Entropy: 3.75470
Value Function Loss: 0.08257

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.88551
Value Function Update Magnitude: 0.69104

Collected Steps per Second: 21,768.39690
Overall Steps per Second: 10,553.54912

Timestep Collection Time: 2.29718
Timestep Consumption Time: 2.44113
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.73831

Cumulative Model Updates: 168,054
Cumulative Timesteps: 1,401,407,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1401407642...
Checkpoint 1401407642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,572.86143
Policy Entropy: 3.73215
Value Function Loss: 0.07482

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.11585
Policy Update Magnitude: 0.91772
Value Function Update Magnitude: 0.79496

Collected Steps per Second: 21,410.85451
Overall Steps per Second: 10,499.61086

Timestep Collection Time: 2.33610
Timestep Consumption Time: 2.42769
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.76380

Cumulative Model Updates: 168,060
Cumulative Timesteps: 1,401,457,660

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.72350
Policy Entropy: 3.72296
Value Function Loss: 0.06550

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09641
Policy Update Magnitude: 0.82068
Value Function Update Magnitude: 0.77250

Collected Steps per Second: 22,078.20905
Overall Steps per Second: 10,502.30212

Timestep Collection Time: 2.26640
Timestep Consumption Time: 2.49808
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.76448

Cumulative Model Updates: 168,066
Cumulative Timesteps: 1,401,507,698

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1401507698...
Checkpoint 1401507698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.76966
Policy Entropy: 3.72733
Value Function Loss: 0.05501

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.16539
Policy Update Magnitude: 0.64658
Value Function Update Magnitude: 0.68331

Collected Steps per Second: 22,300.75640
Overall Steps per Second: 10,640.39508

Timestep Collection Time: 2.24217
Timestep Consumption Time: 2.45710
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.69926

Cumulative Model Updates: 168,072
Cumulative Timesteps: 1,401,557,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.58231
Policy Entropy: 3.71788
Value Function Loss: 0.05120

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.16098
Policy Update Magnitude: 0.46522
Value Function Update Magnitude: 0.67429

Collected Steps per Second: 22,857.13659
Overall Steps per Second: 10,827.59551

Timestep Collection Time: 2.18864
Timestep Consumption Time: 2.43159
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.62023

Cumulative Model Updates: 168,078
Cumulative Timesteps: 1,401,607,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1401607726...
Checkpoint 1401607726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.78914
Policy Entropy: 3.69919
Value Function Loss: 0.04538

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.15342
Policy Update Magnitude: 0.40294
Value Function Update Magnitude: 0.55499

Collected Steps per Second: 22,148.79629
Overall Steps per Second: 10,637.96600

Timestep Collection Time: 2.25863
Timestep Consumption Time: 2.44396
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.70259

Cumulative Model Updates: 168,084
Cumulative Timesteps: 1,401,657,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.62401
Policy Entropy: 3.68357
Value Function Loss: 0.04724

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14453
Policy Update Magnitude: 0.43947
Value Function Update Magnitude: 0.70961

Collected Steps per Second: 22,722.89878
Overall Steps per Second: 10,558.21212

Timestep Collection Time: 2.20157
Timestep Consumption Time: 2.53655
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.73811

Cumulative Model Updates: 168,090
Cumulative Timesteps: 1,401,707,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1401707778...
Checkpoint 1401707778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,273.76250
Policy Entropy: 3.68754
Value Function Loss: 0.04474

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.45445
Value Function Update Magnitude: 0.64462

Collected Steps per Second: 22,520.99155
Overall Steps per Second: 10,617.57899

Timestep Collection Time: 2.22139
Timestep Consumption Time: 2.49041
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.71181

Cumulative Model Updates: 168,096
Cumulative Timesteps: 1,401,757,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,152.68544
Policy Entropy: 3.67382
Value Function Loss: 0.04775

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.44262
Value Function Update Magnitude: 0.55514

Collected Steps per Second: 22,662.55326
Overall Steps per Second: 10,587.16970

Timestep Collection Time: 2.20725
Timestep Consumption Time: 2.51752
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.72478

Cumulative Model Updates: 168,102
Cumulative Timesteps: 1,401,807,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1401807828...
Checkpoint 1401807828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,167.67484
Policy Entropy: 3.66077
Value Function Loss: 0.04523

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13828
Policy Update Magnitude: 0.43265
Value Function Update Magnitude: 0.58916

Collected Steps per Second: 22,489.65600
Overall Steps per Second: 10,506.23865

Timestep Collection Time: 2.22378
Timestep Consumption Time: 2.53644
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.76022

Cumulative Model Updates: 168,108
Cumulative Timesteps: 1,401,857,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,013.71782
Policy Entropy: 3.65977
Value Function Loss: 0.04706

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13756
Policy Update Magnitude: 0.41574
Value Function Update Magnitude: 0.66535

Collected Steps per Second: 22,806.47055
Overall Steps per Second: 10,632.85487

Timestep Collection Time: 2.19350
Timestep Consumption Time: 2.51135
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.70485

Cumulative Model Updates: 168,114
Cumulative Timesteps: 1,401,907,866

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1401907866...
Checkpoint 1401907866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,059.22149
Policy Entropy: 3.66717
Value Function Loss: 0.04422

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.41067
Value Function Update Magnitude: 0.55682

Collected Steps per Second: 22,518.50715
Overall Steps per Second: 10,536.69081

Timestep Collection Time: 2.22120
Timestep Consumption Time: 2.52584
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.74703

Cumulative Model Updates: 168,120
Cumulative Timesteps: 1,401,957,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,059.22149
Policy Entropy: 3.67223
Value Function Loss: 0.04169

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.40840
Value Function Update Magnitude: 0.45881

Collected Steps per Second: 22,604.24125
Overall Steps per Second: 10,589.92057

Timestep Collection Time: 2.21268
Timestep Consumption Time: 2.51030
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.72298

Cumulative Model Updates: 168,126
Cumulative Timesteps: 1,402,007,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1402007900...
Checkpoint 1402007900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,059.22149
Policy Entropy: 3.67427
Value Function Loss: 0.03311

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.41631
Value Function Update Magnitude: 0.47987

Collected Steps per Second: 22,515.95544
Overall Steps per Second: 10,536.49900

Timestep Collection Time: 2.22136
Timestep Consumption Time: 2.52557
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.74693

Cumulative Model Updates: 168,132
Cumulative Timesteps: 1,402,057,916

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,059.22149
Policy Entropy: 3.65690
Value Function Loss: 0.03747

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.36955
Value Function Update Magnitude: 0.46570

Collected Steps per Second: 22,437.77280
Overall Steps per Second: 10,579.76235

Timestep Collection Time: 2.22999
Timestep Consumption Time: 2.49942
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.72941

Cumulative Model Updates: 168,138
Cumulative Timesteps: 1,402,107,952

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1402107952...
Checkpoint 1402107952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,969.22661
Policy Entropy: 3.68199
Value Function Loss: 0.03708

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.35249
Value Function Update Magnitude: 0.38478

Collected Steps per Second: 22,252.64604
Overall Steps per Second: 10,517.10228

Timestep Collection Time: 2.24809
Timestep Consumption Time: 2.50854
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.75663

Cumulative Model Updates: 168,144
Cumulative Timesteps: 1,402,157,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,385.99421
Policy Entropy: 3.66621
Value Function Loss: 0.04861

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.41155
Value Function Update Magnitude: 0.39318

Collected Steps per Second: 22,506.38484
Overall Steps per Second: 10,702.80596

Timestep Collection Time: 2.22159
Timestep Consumption Time: 2.45008
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.67167

Cumulative Model Updates: 168,150
Cumulative Timesteps: 1,402,207,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1402207978...
Checkpoint 1402207978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,385.99421
Policy Entropy: 3.68217
Value Function Loss: 0.04692

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13316
Policy Update Magnitude: 0.48258
Value Function Update Magnitude: 0.41113

Collected Steps per Second: 21,906.22903
Overall Steps per Second: 10,409.97653

Timestep Collection Time: 2.28364
Timestep Consumption Time: 2.52194
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.80558

Cumulative Model Updates: 168,156
Cumulative Timesteps: 1,402,258,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,385.99421
Policy Entropy: 3.66726
Value Function Loss: 0.04478

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14400
Policy Update Magnitude: 0.46774
Value Function Update Magnitude: 0.38636

Collected Steps per Second: 21,803.28328
Overall Steps per Second: 10,617.71171

Timestep Collection Time: 2.29323
Timestep Consumption Time: 2.41588
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.70911

Cumulative Model Updates: 168,162
Cumulative Timesteps: 1,402,308,004

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1402308004...
Checkpoint 1402308004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,385.99421
Policy Entropy: 3.68440
Value Function Loss: 0.03236

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.39283
Value Function Update Magnitude: 0.33460

Collected Steps per Second: 21,804.67875
Overall Steps per Second: 10,616.49476

Timestep Collection Time: 2.29373
Timestep Consumption Time: 2.41724
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.71097

Cumulative Model Updates: 168,168
Cumulative Timesteps: 1,402,358,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,385.99421
Policy Entropy: 3.67577
Value Function Loss: 0.03319

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.36286
Value Function Update Magnitude: 0.30036

Collected Steps per Second: 22,021.38668
Overall Steps per Second: 10,621.95536

Timestep Collection Time: 2.27161
Timestep Consumption Time: 2.43788
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.70949

Cumulative Model Updates: 168,174
Cumulative Timesteps: 1,402,408,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1402408042...
Checkpoint 1402408042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,530.87292
Policy Entropy: 3.67566
Value Function Loss: 0.03647

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.44197
Value Function Update Magnitude: 0.44062

Collected Steps per Second: 22,265.58593
Overall Steps per Second: 10,673.54778

Timestep Collection Time: 2.24571
Timestep Consumption Time: 2.43896
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.68467

Cumulative Model Updates: 168,180
Cumulative Timesteps: 1,402,458,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,052.29085
Policy Entropy: 3.68234
Value Function Loss: 0.03853

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.47830
Value Function Update Magnitude: 0.51140

Collected Steps per Second: 22,578.63713
Overall Steps per Second: 10,632.00898

Timestep Collection Time: 2.21466
Timestep Consumption Time: 2.48850
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.70316

Cumulative Model Updates: 168,186
Cumulative Timesteps: 1,402,508,048

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1402508048...
Checkpoint 1402508048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,052.29085
Policy Entropy: 3.69434
Value Function Loss: 0.03109

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.14880
Policy Update Magnitude: 0.42556
Value Function Update Magnitude: 0.44155

Collected Steps per Second: 22,353.72477
Overall Steps per Second: 10,505.17059

Timestep Collection Time: 2.23766
Timestep Consumption Time: 2.52381
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.76146

Cumulative Model Updates: 168,192
Cumulative Timesteps: 1,402,558,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,174.74509
Policy Entropy: 3.68861
Value Function Loss: 0.03074

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14786
Policy Update Magnitude: 0.39220
Value Function Update Magnitude: 0.46812

Collected Steps per Second: 22,908.83066
Overall Steps per Second: 10,659.87363

Timestep Collection Time: 2.18335
Timestep Consumption Time: 2.50883
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.69218

Cumulative Model Updates: 168,198
Cumulative Timesteps: 1,402,608,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1402608086...
Checkpoint 1402608086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,212.01057
Policy Entropy: 3.68456
Value Function Loss: 0.02966

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.40769
Value Function Update Magnitude: 0.69976

Collected Steps per Second: 22,748.98283
Overall Steps per Second: 10,649.25893

Timestep Collection Time: 2.19808
Timestep Consumption Time: 2.49746
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.69554

Cumulative Model Updates: 168,204
Cumulative Timesteps: 1,402,658,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,726.64728
Policy Entropy: 3.67068
Value Function Loss: 0.03238

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.45180
Value Function Update Magnitude: 0.76704

Collected Steps per Second: 22,760.12747
Overall Steps per Second: 10,717.80269

Timestep Collection Time: 2.19797
Timestep Consumption Time: 2.46959
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.66756

Cumulative Model Updates: 168,210
Cumulative Timesteps: 1,402,708,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1402708116...
Checkpoint 1402708116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,726.64728
Policy Entropy: 3.68713
Value Function Loss: 0.03051

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.48797
Value Function Update Magnitude: 0.57355

Collected Steps per Second: 22,322.30012
Overall Steps per Second: 10,613.06376

Timestep Collection Time: 2.24099
Timestep Consumption Time: 2.47245
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.71344

Cumulative Model Updates: 168,216
Cumulative Timesteps: 1,402,758,140

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,726.64728
Policy Entropy: 3.68437
Value Function Loss: 0.02784

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.43697
Value Function Update Magnitude: 0.40386

Collected Steps per Second: 22,774.88101
Overall Steps per Second: 10,651.26298

Timestep Collection Time: 2.19566
Timestep Consumption Time: 2.49918
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.69484

Cumulative Model Updates: 168,222
Cumulative Timesteps: 1,402,808,146

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1402808146...
Checkpoint 1402808146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,726.64728
Policy Entropy: 3.68356
Value Function Loss: 0.02977

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.11990
Policy Update Magnitude: 0.46284
Value Function Update Magnitude: 0.36685

Collected Steps per Second: 22,662.87206
Overall Steps per Second: 10,619.36989

Timestep Collection Time: 2.20678
Timestep Consumption Time: 2.50273
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.70951

Cumulative Model Updates: 168,228
Cumulative Timesteps: 1,402,858,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,726.64728
Policy Entropy: 3.66624
Value Function Loss: 0.03845

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.62265
Value Function Update Magnitude: 0.54361

Collected Steps per Second: 22,982.06126
Overall Steps per Second: 10,735.15801

Timestep Collection Time: 2.17561
Timestep Consumption Time: 2.48198
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.65759

Cumulative Model Updates: 168,234
Cumulative Timesteps: 1,402,908,158

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1402908158...
Checkpoint 1402908158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,708.34150
Policy Entropy: 3.66806
Value Function Loss: 0.04523

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.19055
Policy Update Magnitude: 0.61387
Value Function Update Magnitude: 0.62664

Collected Steps per Second: 21,763.88259
Overall Steps per Second: 10,382.76111

Timestep Collection Time: 2.29738
Timestep Consumption Time: 2.51829
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.81567

Cumulative Model Updates: 168,240
Cumulative Timesteps: 1,402,958,158

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439,708.34150
Policy Entropy: 3.67874
Value Function Loss: 0.04157

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.17509
Policy Update Magnitude: 0.55842
Value Function Update Magnitude: 0.64807

Collected Steps per Second: 22,790.51573
Overall Steps per Second: 10,664.23569

Timestep Collection Time: 2.19442
Timestep Consumption Time: 2.49527
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.68969

Cumulative Model Updates: 168,246
Cumulative Timesteps: 1,403,008,170

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1403008170...
Checkpoint 1403008170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,708.34150
Policy Entropy: 3.70654
Value Function Loss: 0.03646

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.45418
Value Function Update Magnitude: 0.54596

Collected Steps per Second: 22,020.41150
Overall Steps per Second: 10,600.93881

Timestep Collection Time: 2.27135
Timestep Consumption Time: 2.44673
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.71807

Cumulative Model Updates: 168,252
Cumulative Timesteps: 1,403,058,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827,573.04747
Policy Entropy: 3.69342
Value Function Loss: 0.03679

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.41959
Value Function Update Magnitude: 0.53454

Collected Steps per Second: 22,032.77316
Overall Steps per Second: 10,599.65777

Timestep Collection Time: 2.26953
Timestep Consumption Time: 2.44798
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.71751

Cumulative Model Updates: 168,258
Cumulative Timesteps: 1,403,108,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1403108190...
Checkpoint 1403108190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418,104.21248
Policy Entropy: 3.70963
Value Function Loss: 0.03818

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.43458
Value Function Update Magnitude: 0.62294

Collected Steps per Second: 21,570.47905
Overall Steps per Second: 10,579.02647

Timestep Collection Time: 2.31882
Timestep Consumption Time: 2.40922
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.72803

Cumulative Model Updates: 168,264
Cumulative Timesteps: 1,403,158,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179,984.57740
Policy Entropy: 3.69168
Value Function Loss: 0.04078

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15058
Policy Update Magnitude: 0.39758
Value Function Update Magnitude: 0.73392

Collected Steps per Second: 22,110.66079
Overall Steps per Second: 10,677.28929

Timestep Collection Time: 2.26271
Timestep Consumption Time: 2.42294
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.68565

Cumulative Model Updates: 168,270
Cumulative Timesteps: 1,403,208,238

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1403208238...
Checkpoint 1403208238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,775.30580
Policy Entropy: 3.70510
Value Function Loss: 0.03439

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.36025
Value Function Update Magnitude: 0.69808

Collected Steps per Second: 21,767.77065
Overall Steps per Second: 10,426.28247

Timestep Collection Time: 2.29808
Timestep Consumption Time: 2.49980
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.79788

Cumulative Model Updates: 168,276
Cumulative Timesteps: 1,403,258,262

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,901.87264
Policy Entropy: 3.68451
Value Function Loss: 0.03073

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.15208
Policy Update Magnitude: 0.33242
Value Function Update Magnitude: 0.69040

Collected Steps per Second: 22,723.65845
Overall Steps per Second: 10,802.72477

Timestep Collection Time: 2.20149
Timestep Consumption Time: 2.42937
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.63087

Cumulative Model Updates: 168,282
Cumulative Timesteps: 1,403,308,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1403308288...
Checkpoint 1403308288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,745.58063
Policy Entropy: 3.68024
Value Function Loss: 0.03558

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.35212
Value Function Update Magnitude: 0.65887

Collected Steps per Second: 21,953.99894
Overall Steps per Second: 10,659.18764

Timestep Collection Time: 2.27867
Timestep Consumption Time: 2.41455
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.69323

Cumulative Model Updates: 168,288
Cumulative Timesteps: 1,403,358,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214,064.48639
Policy Entropy: 3.66428
Value Function Loss: 0.04190

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.44989
Value Function Update Magnitude: 0.81419

Collected Steps per Second: 22,711.60898
Overall Steps per Second: 10,557.30673

Timestep Collection Time: 2.20196
Timestep Consumption Time: 2.53505
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.73700

Cumulative Model Updates: 168,294
Cumulative Timesteps: 1,403,408,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1403408324...
Checkpoint 1403408324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691,135.26687
Policy Entropy: 3.66291
Value Function Loss: 0.04902

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13858
Policy Update Magnitude: 0.53883
Value Function Update Magnitude: 0.81104

Collected Steps per Second: 22,357.02460
Overall Steps per Second: 10,683.51929

Timestep Collection Time: 2.23760
Timestep Consumption Time: 2.44494
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.68254

Cumulative Model Updates: 168,300
Cumulative Timesteps: 1,403,458,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691,135.26687
Policy Entropy: 3.67292
Value Function Loss: 0.04406

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14426
Policy Update Magnitude: 0.51642
Value Function Update Magnitude: 0.67357

Collected Steps per Second: 22,843.79271
Overall Steps per Second: 10,771.98957

Timestep Collection Time: 2.18895
Timestep Consumption Time: 2.45309
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.64204

Cumulative Model Updates: 168,306
Cumulative Timesteps: 1,403,508,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1403508354...
Checkpoint 1403508354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691,135.26687
Policy Entropy: 3.67369
Value Function Loss: 0.04003

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13396
Policy Update Magnitude: 0.44892
Value Function Update Magnitude: 0.51965

Collected Steps per Second: 22,262.09985
Overall Steps per Second: 10,640.76429

Timestep Collection Time: 2.24615
Timestep Consumption Time: 2.45314
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.69929

Cumulative Model Updates: 168,312
Cumulative Timesteps: 1,403,558,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691,135.26687
Policy Entropy: 3.66192
Value Function Loss: 0.03404

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.38517
Value Function Update Magnitude: 0.40258

Collected Steps per Second: 22,687.96711
Overall Steps per Second: 10,557.10488

Timestep Collection Time: 2.20469
Timestep Consumption Time: 2.53335
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.73804

Cumulative Model Updates: 168,318
Cumulative Timesteps: 1,403,608,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1403608378...
Checkpoint 1403608378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691,135.26687
Policy Entropy: 3.65732
Value Function Loss: 0.03575

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.34271
Value Function Update Magnitude: 0.32534

Collected Steps per Second: 22,543.26271
Overall Steps per Second: 10,600.67354

Timestep Collection Time: 2.21911
Timestep Consumption Time: 2.50002
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.71913

Cumulative Model Updates: 168,324
Cumulative Timesteps: 1,403,658,404

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691,135.26687
Policy Entropy: 3.65552
Value Function Loss: 0.03401

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13546
Policy Update Magnitude: 0.34124
Value Function Update Magnitude: 0.30802

Collected Steps per Second: 22,576.09692
Overall Steps per Second: 10,569.07254

Timestep Collection Time: 2.21482
Timestep Consumption Time: 2.51615
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.73097

Cumulative Model Updates: 168,330
Cumulative Timesteps: 1,403,708,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1403708406...
Checkpoint 1403708406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013,883.81127
Policy Entropy: 3.66105
Value Function Loss: 0.03901

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13756
Policy Update Magnitude: 0.34434
Value Function Update Magnitude: 0.43945

Collected Steps per Second: 22,314.09159
Overall Steps per Second: 10,557.29662

Timestep Collection Time: 2.24280
Timestep Consumption Time: 2.49762
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.74042

Cumulative Model Updates: 168,336
Cumulative Timesteps: 1,403,758,452

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 883,277.46882
Policy Entropy: 3.66437
Value Function Loss: 0.04553

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.39182
Value Function Update Magnitude: 0.52680

Collected Steps per Second: 22,014.69789
Overall Steps per Second: 10,630.50216

Timestep Collection Time: 2.27176
Timestep Consumption Time: 2.43282
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.70458

Cumulative Model Updates: 168,342
Cumulative Timesteps: 1,403,808,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1403808464...
Checkpoint 1403808464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307,995.10506
Policy Entropy: 3.67179
Value Function Loss: 0.05652

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.44093
Value Function Update Magnitude: 0.46170

Collected Steps per Second: 21,793.71855
Overall Steps per Second: 10,586.62667

Timestep Collection Time: 2.29497
Timestep Consumption Time: 2.42948
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.72445

Cumulative Model Updates: 168,348
Cumulative Timesteps: 1,403,858,480

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,680.28381
Policy Entropy: 3.66442
Value Function Loss: 0.05033

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.43541
Value Function Update Magnitude: 0.42921

Collected Steps per Second: 22,304.38439
Overall Steps per Second: 10,782.66818

Timestep Collection Time: 2.24377
Timestep Consumption Time: 2.39756
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.64134

Cumulative Model Updates: 168,354
Cumulative Timesteps: 1,403,908,526

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1403908526...
Checkpoint 1403908526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,680.28381
Policy Entropy: 3.67333
Value Function Loss: 0.03697

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.42275
Value Function Update Magnitude: 0.46739

Collected Steps per Second: 21,545.80929
Overall Steps per Second: 10,562.73222

Timestep Collection Time: 2.32138
Timestep Consumption Time: 2.41376
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.73514

Cumulative Model Updates: 168,360
Cumulative Timesteps: 1,403,958,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,680.28381
Policy Entropy: 3.66991
Value Function Loss: 0.03477

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.39782
Value Function Update Magnitude: 0.46527

Collected Steps per Second: 22,830.03174
Overall Steps per Second: 10,640.70335

Timestep Collection Time: 2.19010
Timestep Consumption Time: 2.50884
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.69894

Cumulative Model Updates: 168,366
Cumulative Timesteps: 1,404,008,542

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1404008542...
Checkpoint 1404008542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,680.28381
Policy Entropy: 3.67560
Value Function Loss: 0.02751

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.39164
Value Function Update Magnitude: 0.44899

Collected Steps per Second: 22,469.98030
Overall Steps per Second: 10,522.26344

Timestep Collection Time: 2.22528
Timestep Consumption Time: 2.52674
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.75202

Cumulative Model Updates: 168,372
Cumulative Timesteps: 1,404,058,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,680.28381
Policy Entropy: 3.65791
Value Function Loss: 0.02888

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.38603
Value Function Update Magnitude: 0.52597

Collected Steps per Second: 22,626.12415
Overall Steps per Second: 10,548.76103

Timestep Collection Time: 2.21054
Timestep Consumption Time: 2.53087
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.74141

Cumulative Model Updates: 168,378
Cumulative Timesteps: 1,404,108,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1404108560...
Checkpoint 1404108560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,680.28381
Policy Entropy: 3.65644
Value Function Loss: 0.03285

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.39559
Value Function Update Magnitude: 0.52569

Collected Steps per Second: 21,651.11322
Overall Steps per Second: 10,503.09722

Timestep Collection Time: 2.30963
Timestep Consumption Time: 2.45144
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.76107

Cumulative Model Updates: 168,384
Cumulative Timesteps: 1,404,158,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,680.28381
Policy Entropy: 3.65667
Value Function Loss: 0.03371

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.38711
Value Function Update Magnitude: 0.46114

Collected Steps per Second: 22,521.65734
Overall Steps per Second: 10,496.31559

Timestep Collection Time: 2.22053
Timestep Consumption Time: 2.54400
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.76453

Cumulative Model Updates: 168,390
Cumulative Timesteps: 1,404,208,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1404208576...
Checkpoint 1404208576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,680.28381
Policy Entropy: 3.66564
Value Function Loss: 0.03100

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.33621
Value Function Update Magnitude: 0.38406

Collected Steps per Second: 22,385.35961
Overall Steps per Second: 10,675.79453

Timestep Collection Time: 2.23459
Timestep Consumption Time: 2.45097
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.68555

Cumulative Model Updates: 168,396
Cumulative Timesteps: 1,404,258,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,680.28381
Policy Entropy: 3.66095
Value Function Loss: 0.03052

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13395
Policy Update Magnitude: 0.30672
Value Function Update Magnitude: 0.31955

Collected Steps per Second: 22,811.77699
Overall Steps per Second: 10,681.43407

Timestep Collection Time: 2.19317
Timestep Consumption Time: 2.49066
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.68383

Cumulative Model Updates: 168,402
Cumulative Timesteps: 1,404,308,628

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1404308628...
Checkpoint 1404308628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,680.28381
Policy Entropy: 3.66306
Value Function Loss: 0.02929

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.32436
Value Function Update Magnitude: 0.40934

Collected Steps per Second: 21,519.99961
Overall Steps per Second: 10,513.77901

Timestep Collection Time: 2.32388
Timestep Consumption Time: 2.43273
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.75662

Cumulative Model Updates: 168,408
Cumulative Timesteps: 1,404,358,638

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,680.28381
Policy Entropy: 3.66076
Value Function Loss: 0.03148

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13646
Policy Update Magnitude: 0.33983
Value Function Update Magnitude: 0.47666

Collected Steps per Second: 22,171.89732
Overall Steps per Second: 10,768.67819

Timestep Collection Time: 2.25592
Timestep Consumption Time: 2.38885
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.64477

Cumulative Model Updates: 168,414
Cumulative Timesteps: 1,404,408,656

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1404408656...
Checkpoint 1404408656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,680.28381
Policy Entropy: 3.65257
Value Function Loss: 0.03274

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.33543
Value Function Update Magnitude: 0.34066

Collected Steps per Second: 21,604.57282
Overall Steps per Second: 10,564.32467

Timestep Collection Time: 2.31488
Timestep Consumption Time: 2.41917
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.73405

Cumulative Model Updates: 168,420
Cumulative Timesteps: 1,404,458,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,680.28381
Policy Entropy: 3.64645
Value Function Loss: 0.03128

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13302
Policy Update Magnitude: 0.36019
Value Function Update Magnitude: 0.30894

Collected Steps per Second: 22,694.36881
Overall Steps per Second: 10,599.62763

Timestep Collection Time: 2.20345
Timestep Consumption Time: 2.51426
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.71771

Cumulative Model Updates: 168,426
Cumulative Timesteps: 1,404,508,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1404508674...
Checkpoint 1404508674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,680.28381
Policy Entropy: 3.64219
Value Function Loss: 0.03168

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.41103
Value Function Update Magnitude: 0.43752

Collected Steps per Second: 22,153.92769
Overall Steps per Second: 10,637.41550

Timestep Collection Time: 2.25829
Timestep Consumption Time: 2.44492
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.70321

Cumulative Model Updates: 168,432
Cumulative Timesteps: 1,404,558,704

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301,534.69437
Policy Entropy: 3.65419
Value Function Loss: 0.03767

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.46836
Value Function Update Magnitude: 0.44132

Collected Steps per Second: 22,544.29663
Overall Steps per Second: 10,548.68742

Timestep Collection Time: 2.21821
Timestep Consumption Time: 2.52247
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.74068

Cumulative Model Updates: 168,438
Cumulative Timesteps: 1,404,608,712

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1404608712...
Checkpoint 1404608712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301,534.69437
Policy Entropy: 3.66608
Value Function Loss: 0.03594

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.47896
Value Function Update Magnitude: 0.50735

Collected Steps per Second: 22,342.35786
Overall Steps per Second: 10,501.66312

Timestep Collection Time: 2.23862
Timestep Consumption Time: 2.52406
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.76267

Cumulative Model Updates: 168,444
Cumulative Timesteps: 1,404,658,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301,534.69437
Policy Entropy: 3.65259
Value Function Loss: 0.03593

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.47820
Value Function Update Magnitude: 0.58188

Collected Steps per Second: 22,955.40042
Overall Steps per Second: 10,691.66210

Timestep Collection Time: 2.17918
Timestep Consumption Time: 2.49960
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.67879

Cumulative Model Updates: 168,450
Cumulative Timesteps: 1,404,708,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1404708752...
Checkpoint 1404708752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212,612.35482
Policy Entropy: 3.66681
Value Function Loss: 0.03369

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12799
Policy Update Magnitude: 0.45950
Value Function Update Magnitude: 0.59418

Collected Steps per Second: 22,376.03453
Overall Steps per Second: 10,530.01304

Timestep Collection Time: 2.23480
Timestep Consumption Time: 2.51410
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.74890

Cumulative Model Updates: 168,456
Cumulative Timesteps: 1,404,758,758

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212,612.35482
Policy Entropy: 3.65259
Value Function Loss: 0.03601

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.48946
Value Function Update Magnitude: 0.57922

Collected Steps per Second: 22,835.33978
Overall Steps per Second: 10,756.81902

Timestep Collection Time: 2.19020
Timestep Consumption Time: 2.45931
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.64952

Cumulative Model Updates: 168,462
Cumulative Timesteps: 1,404,808,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1404808772...
Checkpoint 1404808772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751,009.78574
Policy Entropy: 3.67118
Value Function Loss: 0.03540

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.48732
Value Function Update Magnitude: 0.59192

Collected Steps per Second: 21,841.43674
Overall Steps per Second: 10,689.37399

Timestep Collection Time: 2.28950
Timestep Consumption Time: 2.38860
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.67810

Cumulative Model Updates: 168,468
Cumulative Timesteps: 1,404,858,778

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323,289.95340
Policy Entropy: 3.65799
Value Function Loss: 0.03654

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14464
Policy Update Magnitude: 0.49019
Value Function Update Magnitude: 0.53908

Collected Steps per Second: 22,711.27554
Overall Steps per Second: 10,981.51428

Timestep Collection Time: 2.20252
Timestep Consumption Time: 2.35259
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.55511

Cumulative Model Updates: 168,474
Cumulative Timesteps: 1,404,908,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1404908800...
Checkpoint 1404908800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323,289.95340
Policy Entropy: 3.67615
Value Function Loss: 0.03217

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14442
Policy Update Magnitude: 0.45089
Value Function Update Magnitude: 0.58570

Collected Steps per Second: 20,070.11381
Overall Steps per Second: 10,099.85793

Timestep Collection Time: 2.49266
Timestep Consumption Time: 2.46068
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.95334

Cumulative Model Updates: 168,480
Cumulative Timesteps: 1,404,958,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323,289.95340
Policy Entropy: 3.66100
Value Function Loss: 0.02978

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14782
Policy Update Magnitude: 0.36667
Value Function Update Magnitude: 0.47476

Collected Steps per Second: 21,664.59981
Overall Steps per Second: 10,406.82736

Timestep Collection Time: 2.30810
Timestep Consumption Time: 2.49683
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.80492

Cumulative Model Updates: 168,486
Cumulative Timesteps: 1,405,008,832

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1405008832...
Checkpoint 1405008832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323,289.95340
Policy Entropy: 3.66260
Value Function Loss: 0.02412

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14242
Policy Update Magnitude: 0.31022
Value Function Update Magnitude: 0.32382

Collected Steps per Second: 22,026.07290
Overall Steps per Second: 10,663.70092

Timestep Collection Time: 2.27131
Timestep Consumption Time: 2.42012
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.69143

Cumulative Model Updates: 168,492
Cumulative Timesteps: 1,405,058,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323,289.95340
Policy Entropy: 3.65964
Value Function Loss: 0.02259

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.28159
Value Function Update Magnitude: 0.21860

Collected Steps per Second: 21,443.25459
Overall Steps per Second: 10,069.60606

Timestep Collection Time: 2.33416
Timestep Consumption Time: 2.63644
PPO Batch Consumption Time: 0.31507
Total Iteration Time: 4.97060

Cumulative Model Updates: 168,498
Cumulative Timesteps: 1,405,108,912

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1405108912...
Checkpoint 1405108912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323,289.95340
Policy Entropy: 3.67710
Value Function Loss: 0.02141

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.27657
Value Function Update Magnitude: 0.26407

Collected Steps per Second: 20,102.67262
Overall Steps per Second: 9,771.42536

Timestep Collection Time: 2.48882
Timestep Consumption Time: 2.63141
PPO Batch Consumption Time: 0.30547
Total Iteration Time: 5.12024

Cumulative Model Updates: 168,504
Cumulative Timesteps: 1,405,158,944

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911,756.22366
Policy Entropy: 3.64376
Value Function Loss: 0.03404

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.43127
Value Function Update Magnitude: 0.46329

Collected Steps per Second: 19,036.69266
Overall Steps per Second: 9,678.25913

Timestep Collection Time: 2.62745
Timestep Consumption Time: 2.54063
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 5.16808

Cumulative Model Updates: 168,510
Cumulative Timesteps: 1,405,208,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1405208962...
Checkpoint 1405208962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911,756.22366
Policy Entropy: 3.62601
Value Function Loss: 0.03950

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.54567
Value Function Update Magnitude: 0.63384

Collected Steps per Second: 21,267.52945
Overall Steps per Second: 10,217.91142

Timestep Collection Time: 2.35147
Timestep Consumption Time: 2.54287
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.89435

Cumulative Model Updates: 168,516
Cumulative Timesteps: 1,405,258,972

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,113,902.18065
Policy Entropy: 3.59905
Value Function Loss: 0.06474

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.15093
Policy Update Magnitude: 0.58533
Value Function Update Magnitude: 0.66189

Collected Steps per Second: 22,001.61568
Overall Steps per Second: 10,536.37988

Timestep Collection Time: 2.27347
Timestep Consumption Time: 2.47389
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.74736

Cumulative Model Updates: 168,522
Cumulative Timesteps: 1,405,308,992

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1405308992...
Checkpoint 1405308992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,881.31672
Policy Entropy: 3.65333
Value Function Loss: 0.06948

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.66455
Value Function Update Magnitude: 0.58792

Collected Steps per Second: 22,090.42030
Overall Steps per Second: 10,590.77480

Timestep Collection Time: 2.26424
Timestep Consumption Time: 2.45855
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.72279

Cumulative Model Updates: 168,528
Cumulative Timesteps: 1,405,359,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,994.73358
Policy Entropy: 3.67660
Value Function Loss: 0.06858

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.65209
Value Function Update Magnitude: 0.69318

Collected Steps per Second: 22,666.25863
Overall Steps per Second: 10,567.00916

Timestep Collection Time: 2.20601
Timestep Consumption Time: 2.52589
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.73190

Cumulative Model Updates: 168,534
Cumulative Timesteps: 1,405,409,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1405409012...
Checkpoint 1405409012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.21244
Policy Entropy: 3.73017
Value Function Loss: 0.05711

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.62736
Value Function Update Magnitude: 0.84354

Collected Steps per Second: 22,416.42761
Overall Steps per Second: 10,557.14291

Timestep Collection Time: 2.23113
Timestep Consumption Time: 2.50632
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.73746

Cumulative Model Updates: 168,540
Cumulative Timesteps: 1,405,459,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 837.63636
Policy Entropy: 3.69955
Value Function Loss: 0.05099

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13546
Policy Update Magnitude: 0.62779
Value Function Update Magnitude: 0.85542

Collected Steps per Second: 22,715.33535
Overall Steps per Second: 10,582.48897

Timestep Collection Time: 2.20221
Timestep Consumption Time: 2.52484
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.72705

Cumulative Model Updates: 168,546
Cumulative Timesteps: 1,405,509,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1405509050...
Checkpoint 1405509050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 837.63636
Policy Entropy: 3.68141
Value Function Loss: 0.04114

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.60790
Value Function Update Magnitude: 0.78073

Collected Steps per Second: 22,198.57219
Overall Steps per Second: 10,525.58466

Timestep Collection Time: 2.25276
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.75109

Cumulative Model Updates: 168,552
Cumulative Timesteps: 1,405,559,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 837.63636
Policy Entropy: 3.67059
Value Function Loss: 0.03767

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14322
Policy Update Magnitude: 0.49369
Value Function Update Magnitude: 0.62998

Collected Steps per Second: 22,477.95103
Overall Steps per Second: 10,528.74313

Timestep Collection Time: 2.22565
Timestep Consumption Time: 2.52592
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.75156

Cumulative Model Updates: 168,558
Cumulative Timesteps: 1,405,609,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1405609086...
Checkpoint 1405609086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397,701.69440
Policy Entropy: 3.68709
Value Function Loss: 0.03037

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.40141
Value Function Update Magnitude: 0.52956

Collected Steps per Second: 22,410.37440
Overall Steps per Second: 10,586.88703

Timestep Collection Time: 2.23245
Timestep Consumption Time: 2.49321
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.72566

Cumulative Model Updates: 168,564
Cumulative Timesteps: 1,405,659,116

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,302.80433
Policy Entropy: 3.69816
Value Function Loss: 0.03108

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.38872
Value Function Update Magnitude: 0.66964

Collected Steps per Second: 22,695.82133
Overall Steps per Second: 10,642.46325

Timestep Collection Time: 2.20419
Timestep Consumption Time: 2.49641
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.70060

Cumulative Model Updates: 168,570
Cumulative Timesteps: 1,405,709,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1405709142...
Checkpoint 1405709142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273,487.63422
Policy Entropy: 3.69218
Value Function Loss: 0.02823

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.38780
Value Function Update Magnitude: 0.71317

Collected Steps per Second: 21,232.83093
Overall Steps per Second: 10,460.23005

Timestep Collection Time: 2.35616
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.78269

Cumulative Model Updates: 168,576
Cumulative Timesteps: 1,405,759,170

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,282.50028
Policy Entropy: 3.68989
Value Function Loss: 0.02964

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.38766
Value Function Update Magnitude: 0.61268

Collected Steps per Second: 22,157.06527
Overall Steps per Second: 10,799.99083

Timestep Collection Time: 2.25698
Timestep Consumption Time: 2.37340
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.63037

Cumulative Model Updates: 168,582
Cumulative Timesteps: 1,405,809,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1405809178...
Checkpoint 1405809178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,480.15092
Policy Entropy: 3.67607
Value Function Loss: 0.03857

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13308
Policy Update Magnitude: 0.50026
Value Function Update Magnitude: 0.60355

Collected Steps per Second: 21,581.00309
Overall Steps per Second: 10,656.48231

Timestep Collection Time: 2.31741
Timestep Consumption Time: 2.37570
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.69311

Cumulative Model Updates: 168,588
Cumulative Timesteps: 1,405,859,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,480.15092
Policy Entropy: 3.68083
Value Function Loss: 0.04037

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.58828
Value Function Update Magnitude: 0.67675

Collected Steps per Second: 21,874.24470
Overall Steps per Second: 10,510.27432

Timestep Collection Time: 2.28634
Timestep Consumption Time: 2.47205
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.75839

Cumulative Model Updates: 168,594
Cumulative Timesteps: 1,405,909,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1405909202...
Checkpoint 1405909202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,480.15092
Policy Entropy: 3.67661
Value Function Loss: 0.03690

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11317
Policy Update Magnitude: 0.64476
Value Function Update Magnitude: 0.66438

Collected Steps per Second: 22,207.44055
Overall Steps per Second: 10,701.87769

Timestep Collection Time: 2.25159
Timestep Consumption Time: 2.42068
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.67226

Cumulative Model Updates: 168,600
Cumulative Timesteps: 1,405,959,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,480.15092
Policy Entropy: 3.68063
Value Function Loss: 0.03016

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.63316
Value Function Update Magnitude: 0.51488

Collected Steps per Second: 22,764.96284
Overall Steps per Second: 10,756.63851

Timestep Collection Time: 2.19662
Timestep Consumption Time: 2.45223
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.64885

Cumulative Model Updates: 168,606
Cumulative Timesteps: 1,406,009,210

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1406009210...
Checkpoint 1406009210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,480.15092
Policy Entropy: 3.67547
Value Function Loss: 0.02341

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.16922
Policy Update Magnitude: 0.51808
Value Function Update Magnitude: 0.41658

Collected Steps per Second: 22,389.33893
Overall Steps per Second: 10,681.17728

Timestep Collection Time: 2.23374
Timestep Consumption Time: 2.44851
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.68226

Cumulative Model Updates: 168,612
Cumulative Timesteps: 1,406,059,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,480.15092
Policy Entropy: 3.66749
Value Function Loss: 0.03040

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.19774
Policy Update Magnitude: 0.40759
Value Function Update Magnitude: 0.39773

Collected Steps per Second: 22,570.81074
Overall Steps per Second: 10,547.59621

Timestep Collection Time: 2.21693
Timestep Consumption Time: 2.52709
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.74402

Cumulative Model Updates: 168,618
Cumulative Timesteps: 1,406,109,260

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1406109260...
Checkpoint 1406109260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,480.15092
Policy Entropy: 3.67812
Value Function Loss: 0.03352

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.17286
Policy Update Magnitude: 0.44046
Value Function Update Magnitude: 0.41806

Collected Steps per Second: 22,229.22494
Overall Steps per Second: 10,645.33926

Timestep Collection Time: 2.24992
Timestep Consumption Time: 2.44829
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.69821

Cumulative Model Updates: 168,624
Cumulative Timesteps: 1,406,159,274

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,480.15092
Policy Entropy: 3.66743
Value Function Loss: 0.03699

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.55340
Value Function Update Magnitude: 0.43943

Collected Steps per Second: 22,787.77593
Overall Steps per Second: 10,680.44262

Timestep Collection Time: 2.19609
Timestep Consumption Time: 2.48948
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.68557

Cumulative Model Updates: 168,630
Cumulative Timesteps: 1,406,209,318

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1406209318...
Checkpoint 1406209318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,480.15092
Policy Entropy: 3.69930
Value Function Loss: 0.03292

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.22280
Policy Update Magnitude: 0.53691
Value Function Update Magnitude: 0.37144

Collected Steps per Second: 22,533.80081
Overall Steps per Second: 10,748.48966

Timestep Collection Time: 2.22004
Timestep Consumption Time: 2.43419
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.65424

Cumulative Model Updates: 168,636
Cumulative Timesteps: 1,406,259,344

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416,437.63498
Policy Entropy: 3.69632
Value Function Loss: 0.06445

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.21254
Policy Update Magnitude: 0.76687
Value Function Update Magnitude: 0.51596

Collected Steps per Second: 21,383.68981
Overall Steps per Second: 10,530.24767

Timestep Collection Time: 2.33823
Timestep Consumption Time: 2.41000
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.74823

Cumulative Model Updates: 168,642
Cumulative Timesteps: 1,406,309,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1406309344...
Checkpoint 1406309344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 799,551.83678
Policy Entropy: 3.72112
Value Function Loss: 0.08218

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.22053
Policy Update Magnitude: 0.97811
Value Function Update Magnitude: 0.60851

Collected Steps per Second: 21,050.13237
Overall Steps per Second: 10,414.54043

Timestep Collection Time: 2.37633
Timestep Consumption Time: 2.42677
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.80309

Cumulative Model Updates: 168,648
Cumulative Timesteps: 1,406,359,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,725.66945
Policy Entropy: 3.71426
Value Function Loss: 0.08254

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.21479
Policy Update Magnitude: 1.13118
Value Function Update Magnitude: 0.74508

Collected Steps per Second: 21,954.91643
Overall Steps per Second: 10,617.54458

Timestep Collection Time: 2.27803
Timestep Consumption Time: 2.43247
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.71051

Cumulative Model Updates: 168,654
Cumulative Timesteps: 1,406,409,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1406409380...
Checkpoint 1406409380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,725.66945
Policy Entropy: 3.66410
Value Function Loss: 0.05857

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.19192
Policy Update Magnitude: 1.06597
Value Function Update Magnitude: 0.71179

Collected Steps per Second: 22,120.36127
Overall Steps per Second: 10,662.57936

Timestep Collection Time: 2.26090
Timestep Consumption Time: 2.42952
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.69042

Cumulative Model Updates: 168,660
Cumulative Timesteps: 1,406,459,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,725.66945
Policy Entropy: 3.64312
Value Function Loss: 0.05318

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.19972
Policy Update Magnitude: 0.90902
Value Function Update Magnitude: 0.66105

Collected Steps per Second: 22,264.72346
Overall Steps per Second: 10,530.51682

Timestep Collection Time: 2.24741
Timestep Consumption Time: 2.50430
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.75171

Cumulative Model Updates: 168,666
Cumulative Timesteps: 1,406,509,430

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1406509430...
Checkpoint 1406509430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,725.66945
Policy Entropy: 3.61407
Value Function Loss: 0.05742

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.21425
Policy Update Magnitude: 0.62663
Value Function Update Magnitude: 0.50670

Collected Steps per Second: 22,119.20074
Overall Steps per Second: 10,599.08926

Timestep Collection Time: 2.26138
Timestep Consumption Time: 2.45789
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.71927

Cumulative Model Updates: 168,672
Cumulative Timesteps: 1,406,559,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,725.66945
Policy Entropy: 3.64513
Value Function Loss: 0.05444

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.19343
Policy Update Magnitude: 0.47442
Value Function Update Magnitude: 0.41206

Collected Steps per Second: 22,631.13432
Overall Steps per Second: 10,538.13944

Timestep Collection Time: 2.20979
Timestep Consumption Time: 2.53583
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.74562

Cumulative Model Updates: 168,678
Cumulative Timesteps: 1,406,609,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1406609460...
Checkpoint 1406609460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,725.66945
Policy Entropy: 3.65117
Value Function Loss: 0.05167

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.16575
Policy Update Magnitude: 0.43102
Value Function Update Magnitude: 0.30568

Collected Steps per Second: 22,308.89376
Overall Steps per Second: 10,596.50795

Timestep Collection Time: 2.24126
Timestep Consumption Time: 2.47728
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.71854

Cumulative Model Updates: 168,684
Cumulative Timesteps: 1,406,659,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,725.66945
Policy Entropy: 3.65759
Value Function Loss: 0.04603

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11021
Policy Update Magnitude: 0.58846
Value Function Update Magnitude: 0.27512

Collected Steps per Second: 22,464.36713
Overall Steps per Second: 10,504.36256

Timestep Collection Time: 2.22575
Timestep Consumption Time: 2.53418
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.75993

Cumulative Model Updates: 168,690
Cumulative Timesteps: 1,406,709,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1406709460...
Checkpoint 1406709460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,725.66945
Policy Entropy: 3.67020
Value Function Loss: 0.04228

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.17558
Policy Update Magnitude: 0.51078
Value Function Update Magnitude: 0.28169

Collected Steps per Second: 22,307.90901
Overall Steps per Second: 10,611.27195

Timestep Collection Time: 2.24163
Timestep Consumption Time: 2.47091
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.71254

Cumulative Model Updates: 168,696
Cumulative Timesteps: 1,406,759,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,725.66945
Policy Entropy: 3.68144
Value Function Loss: 0.03599

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.16823
Policy Update Magnitude: 0.38587
Value Function Update Magnitude: 0.38404

Collected Steps per Second: 22,699.32822
Overall Steps per Second: 10,607.85040

Timestep Collection Time: 2.20315
Timestep Consumption Time: 2.51128
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.71443

Cumulative Model Updates: 168,702
Cumulative Timesteps: 1,406,809,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1406809476...
Checkpoint 1406809476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,725.66945
Policy Entropy: 3.67733
Value Function Loss: 0.03501

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15810
Policy Update Magnitude: 0.35428
Value Function Update Magnitude: 0.36778

Collected Steps per Second: 22,483.17008
Overall Steps per Second: 10,520.04251

Timestep Collection Time: 2.22584
Timestep Consumption Time: 2.53117
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.75701

Cumulative Model Updates: 168,708
Cumulative Timesteps: 1,406,859,520

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465,256.50892
Policy Entropy: 3.66407
Value Function Loss: 0.03752

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.36034
Value Function Update Magnitude: 0.36071

Collected Steps per Second: 22,300.65662
Overall Steps per Second: 10,495.02448

Timestep Collection Time: 2.24289
Timestep Consumption Time: 2.52298
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.76588

Cumulative Model Updates: 168,714
Cumulative Timesteps: 1,406,909,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1406909538...
Checkpoint 1406909538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,772.89622
Policy Entropy: 3.68541
Value Function Loss: 0.03517

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13349
Policy Update Magnitude: 0.41512
Value Function Update Magnitude: 0.45594

Collected Steps per Second: 22,096.68514
Overall Steps per Second: 10,539.69793

Timestep Collection Time: 2.26405
Timestep Consumption Time: 2.48258
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.74663

Cumulative Model Updates: 168,720
Cumulative Timesteps: 1,406,959,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630,772.89622
Policy Entropy: 3.68487
Value Function Loss: 0.03176

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.42368
Value Function Update Magnitude: 0.48868

Collected Steps per Second: 22,728.34582
Overall Steps per Second: 10,581.70833

Timestep Collection Time: 2.20051
Timestep Consumption Time: 2.52595
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.72646

Cumulative Model Updates: 168,726
Cumulative Timesteps: 1,407,009,580

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1407009580...
Checkpoint 1407009580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,772.89622
Policy Entropy: 3.70396
Value Function Loss: 0.02564

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.38572
Value Function Update Magnitude: 0.44054

Collected Steps per Second: 22,500.34347
Overall Steps per Second: 10,566.77988

Timestep Collection Time: 2.22219
Timestep Consumption Time: 2.50962
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.73181

Cumulative Model Updates: 168,732
Cumulative Timesteps: 1,407,059,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630,772.89622
Policy Entropy: 3.68130
Value Function Loss: 0.02474

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06871
Policy Update Magnitude: 0.42111
Value Function Update Magnitude: 0.34019

Collected Steps per Second: 21,917.31851
Overall Steps per Second: 10,447.22117

Timestep Collection Time: 2.28258
Timestep Consumption Time: 2.50606
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.78864

Cumulative Model Updates: 168,738
Cumulative Timesteps: 1,407,109,608

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1407109608...
Checkpoint 1407109608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,772.89622
Policy Entropy: 3.66336
Value Function Loss: 0.02646

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.17245
Policy Update Magnitude: 0.40938
Value Function Update Magnitude: 0.38809

Collected Steps per Second: 20,494.83730
Overall Steps per Second: 10,195.85368

Timestep Collection Time: 2.44022
Timestep Consumption Time: 2.46491
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.90513

Cumulative Model Updates: 168,744
Cumulative Timesteps: 1,407,159,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630,772.89622
Policy Entropy: 3.66462
Value Function Loss: 0.02893

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.40182
Value Function Update Magnitude: 0.34462

Collected Steps per Second: 22,082.15065
Overall Steps per Second: 10,480.40994

Timestep Collection Time: 2.26554
Timestep Consumption Time: 2.50794
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.77348

Cumulative Model Updates: 168,750
Cumulative Timesteps: 1,407,209,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1407209648...
Checkpoint 1407209648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,776.08846
Policy Entropy: 3.68048
Value Function Loss: 0.03452

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.22051
Policy Update Magnitude: 0.35881
Value Function Update Magnitude: 0.23753

Collected Steps per Second: 22,408.47911
Overall Steps per Second: 10,655.20498

Timestep Collection Time: 2.23174
Timestep Consumption Time: 2.46174
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.69348

Cumulative Model Updates: 168,756
Cumulative Timesteps: 1,407,259,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,776.08846
Policy Entropy: 3.70101
Value Function Loss: 0.02996

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.18778
Policy Update Magnitude: 0.30481
Value Function Update Magnitude: 0.25244

Collected Steps per Second: 22,791.90806
Overall Steps per Second: 10,704.40826

Timestep Collection Time: 2.19508
Timestep Consumption Time: 2.47870
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.67378

Cumulative Model Updates: 168,762
Cumulative Timesteps: 1,407,309,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1407309688...
Checkpoint 1407309688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,776.08846
Policy Entropy: 3.69628
Value Function Loss: 0.03010

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.17586
Policy Update Magnitude: 0.28389
Value Function Update Magnitude: 0.28950

Collected Steps per Second: 22,273.70203
Overall Steps per Second: 10,512.82106

Timestep Collection Time: 2.24498
Timestep Consumption Time: 2.51150
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.75648

Cumulative Model Updates: 168,768
Cumulative Timesteps: 1,407,359,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,776.08846
Policy Entropy: 3.68953
Value Function Loss: 0.02613

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.29874
Value Function Update Magnitude: 0.25120

Collected Steps per Second: 23,039.71422
Overall Steps per Second: 10,822.70796

Timestep Collection Time: 2.17138
Timestep Consumption Time: 2.45112
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.62250

Cumulative Model Updates: 168,774
Cumulative Timesteps: 1,407,409,720

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1407409720...
Checkpoint 1407409720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036,097.69279
Policy Entropy: 3.66057
Value Function Loss: 0.03297

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.16546
Policy Update Magnitude: 0.34913
Value Function Update Magnitude: 0.28836

Collected Steps per Second: 22,093.23163
Overall Steps per Second: 10,557.40965

Timestep Collection Time: 2.26332
Timestep Consumption Time: 2.47307
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.73639

Cumulative Model Updates: 168,780
Cumulative Timesteps: 1,407,459,724

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361,277.48695
Policy Entropy: 3.68135
Value Function Loss: 0.03504

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.16528
Policy Update Magnitude: 0.43469
Value Function Update Magnitude: 0.45639

Collected Steps per Second: 22,281.86587
Overall Steps per Second: 10,545.85156

Timestep Collection Time: 2.24452
Timestep Consumption Time: 2.49782
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.74234

Cumulative Model Updates: 168,786
Cumulative Timesteps: 1,407,509,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1407509736...
Checkpoint 1407509736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,050.18210
Policy Entropy: 3.67245
Value Function Loss: 0.04416

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.20680
Policy Update Magnitude: 0.52489
Value Function Update Magnitude: 0.58063

Collected Steps per Second: 22,195.79169
Overall Steps per Second: 10,642.27194

Timestep Collection Time: 2.25295
Timestep Consumption Time: 2.44586
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.69881

Cumulative Model Updates: 168,792
Cumulative Timesteps: 1,407,559,742

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,244.62113
Policy Entropy: 3.68772
Value Function Loss: 0.05813

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.11395
Policy Update Magnitude: 0.73545
Value Function Update Magnitude: 0.61719

Collected Steps per Second: 22,494.77593
Overall Steps per Second: 10,473.51560

Timestep Collection Time: 2.22274
Timestep Consumption Time: 2.55121
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.77395

Cumulative Model Updates: 168,798
Cumulative Timesteps: 1,407,609,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1407609742...
Checkpoint 1407609742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278,654.45085
Policy Entropy: 3.67624
Value Function Loss: 0.06373

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11442
Policy Update Magnitude: 0.87079
Value Function Update Magnitude: 0.58245

Collected Steps per Second: 22,005.59788
Overall Steps per Second: 10,557.90612

Timestep Collection Time: 2.27297
Timestep Consumption Time: 2.46453
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.73749

Cumulative Model Updates: 168,804
Cumulative Timesteps: 1,407,659,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793,648.47226
Policy Entropy: 3.67219
Value Function Loss: 0.07267

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.88129
Value Function Update Magnitude: 0.49850

Collected Steps per Second: 22,510.24470
Overall Steps per Second: 10,514.27467

Timestep Collection Time: 2.22183
Timestep Consumption Time: 2.53494
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.75677

Cumulative Model Updates: 168,810
Cumulative Timesteps: 1,407,709,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1407709774...
Checkpoint 1407709774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793,648.47226
Policy Entropy: 3.69490
Value Function Loss: 0.05620

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09551
Policy Update Magnitude: 0.80393
Value Function Update Magnitude: 0.45456

Collected Steps per Second: 21,472.34298
Overall Steps per Second: 10,332.48731

Timestep Collection Time: 2.32876
Timestep Consumption Time: 2.51073
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.83949

Cumulative Model Updates: 168,816
Cumulative Timesteps: 1,407,759,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793,648.47226
Policy Entropy: 3.67872
Value Function Loss: 0.04469

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.72140
Value Function Update Magnitude: 0.42420

Collected Steps per Second: 22,885.12625
Overall Steps per Second: 10,715.75741

Timestep Collection Time: 2.18579
Timestep Consumption Time: 2.48229
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.66808

Cumulative Model Updates: 168,822
Cumulative Timesteps: 1,407,809,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1407809800...
Checkpoint 1407809800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621,521.57102
Policy Entropy: 3.69337
Value Function Loss: 0.03798

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06900
Policy Update Magnitude: 0.64333
Value Function Update Magnitude: 0.40028

Collected Steps per Second: 22,139.83782
Overall Steps per Second: 10,617.20757

Timestep Collection Time: 2.25873
Timestep Consumption Time: 2.45136
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.71009

Cumulative Model Updates: 168,828
Cumulative Timesteps: 1,407,859,808

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621,521.57102
Policy Entropy: 3.66407
Value Function Loss: 0.04114

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.67323
Value Function Update Magnitude: 0.41301

Collected Steps per Second: 22,659.24774
Overall Steps per Second: 10,563.64288

Timestep Collection Time: 2.20731
Timestep Consumption Time: 2.52742
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.73473

Cumulative Model Updates: 168,834
Cumulative Timesteps: 1,407,909,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1407909824...
Checkpoint 1407909824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621,521.57102
Policy Entropy: 3.69866
Value Function Loss: 0.03696

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.21054
Policy Update Magnitude: 0.60613
Value Function Update Magnitude: 0.48087

Collected Steps per Second: 22,265.66346
Overall Steps per Second: 10,635.13258

Timestep Collection Time: 2.24651
Timestep Consumption Time: 2.45677
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.70328

Cumulative Model Updates: 168,840
Cumulative Timesteps: 1,407,959,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039,932.93455
Policy Entropy: 3.70899
Value Function Loss: 0.03966

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.18872
Policy Update Magnitude: 0.47443
Value Function Update Magnitude: 0.52221

Collected Steps per Second: 22,086.02609
Overall Steps per Second: 10,675.75397

Timestep Collection Time: 2.26487
Timestep Consumption Time: 2.42070
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.68557

Cumulative Model Updates: 168,846
Cumulative Timesteps: 1,408,009,866

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1408009866...
Checkpoint 1408009866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171,225.22332
Policy Entropy: 3.72411
Value Function Loss: 0.04879

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.16304
Policy Update Magnitude: 0.45360
Value Function Update Magnitude: 0.62381

Collected Steps per Second: 21,472.29666
Overall Steps per Second: 10,482.71953

Timestep Collection Time: 2.32979
Timestep Consumption Time: 2.44244
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.77223

Cumulative Model Updates: 168,852
Cumulative Timesteps: 1,408,059,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,371.86261
Policy Entropy: 3.70629
Value Function Loss: 0.05261

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15906
Policy Update Magnitude: 0.45119
Value Function Update Magnitude: 0.68455

Collected Steps per Second: 21,890.38456
Overall Steps per Second: 10,630.93683

Timestep Collection Time: 2.28484
Timestep Consumption Time: 2.41992
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.70476

Cumulative Model Updates: 168,858
Cumulative Timesteps: 1,408,109,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1408109908...
Checkpoint 1408109908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 941,853.75502
Policy Entropy: 3.70419
Value Function Loss: 0.06176

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14940
Policy Update Magnitude: 0.44597
Value Function Update Magnitude: 0.67191

Collected Steps per Second: 21,528.21880
Overall Steps per Second: 10,430.97308

Timestep Collection Time: 2.32495
Timestep Consumption Time: 2.47345
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.79840

Cumulative Model Updates: 168,864
Cumulative Timesteps: 1,408,159,960

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,631.28265
Policy Entropy: 3.72002
Value Function Loss: 0.05884

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14497
Policy Update Magnitude: 0.51506
Value Function Update Magnitude: 0.64182

Collected Steps per Second: 22,573.63349
Overall Steps per Second: 10,638.90517

Timestep Collection Time: 2.21506
Timestep Consumption Time: 2.48486
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.69992

Cumulative Model Updates: 168,870
Cumulative Timesteps: 1,408,209,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1408209962...
Checkpoint 1408209962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447,499.29870
Policy Entropy: 3.71236
Value Function Loss: 0.06141

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14434
Policy Update Magnitude: 0.50151
Value Function Update Magnitude: 0.66987

Collected Steps per Second: 22,493.13801
Overall Steps per Second: 10,651.68653

Timestep Collection Time: 2.22370
Timestep Consumption Time: 2.47208
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.69578

Cumulative Model Updates: 168,876
Cumulative Timesteps: 1,408,259,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229,494.73824
Policy Entropy: 3.71776
Value Function Loss: 0.05306

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.46531
Value Function Update Magnitude: 0.74922

Collected Steps per Second: 22,928.52494
Overall Steps per Second: 10,680.37577

Timestep Collection Time: 2.18139
Timestep Consumption Time: 2.50159
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.68298

Cumulative Model Updates: 168,882
Cumulative Timesteps: 1,408,309,996

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1408309996...
Checkpoint 1408309996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226,642.21195
Policy Entropy: 3.68767
Value Function Loss: 0.04811

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14737
Policy Update Magnitude: 0.42691
Value Function Update Magnitude: 0.78829

Collected Steps per Second: 22,282.30668
Overall Steps per Second: 10,688.47816

Timestep Collection Time: 2.24636
Timestep Consumption Time: 2.43663
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.68299

Cumulative Model Updates: 168,888
Cumulative Timesteps: 1,408,360,050

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,830.73145
Policy Entropy: 3.70948
Value Function Loss: 0.04346

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.38589
Value Function Update Magnitude: 0.67691

Collected Steps per Second: 22,414.53506
Overall Steps per Second: 10,498.72095

Timestep Collection Time: 2.23105
Timestep Consumption Time: 2.53219
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.76325

Cumulative Model Updates: 168,894
Cumulative Timesteps: 1,408,410,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1408410058...
Checkpoint 1408410058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,461.65597
Policy Entropy: 3.69791
Value Function Loss: 0.05474

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.39921
Value Function Update Magnitude: 0.60573

Collected Steps per Second: 22,000.47579
Overall Steps per Second: 10,609.60452

Timestep Collection Time: 2.27368
Timestep Consumption Time: 2.44111
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.71478

Cumulative Model Updates: 168,900
Cumulative Timesteps: 1,408,460,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,537.90398
Policy Entropy: 3.69624
Value Function Loss: 0.05661

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.47744
Value Function Update Magnitude: 0.64238

Collected Steps per Second: 22,264.09158
Overall Steps per Second: 10,462.44308

Timestep Collection Time: 2.24694
Timestep Consumption Time: 2.53455
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.78148

Cumulative Model Updates: 168,906
Cumulative Timesteps: 1,408,510,106

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1408510106...
Checkpoint 1408510106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293,537.90398
Policy Entropy: 3.68022
Value Function Loss: 0.05171

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14619
Policy Update Magnitude: 0.48788
Value Function Update Magnitude: 0.61049

Collected Steps per Second: 22,256.01906
Overall Steps per Second: 10,660.92446

Timestep Collection Time: 2.24748
Timestep Consumption Time: 2.44442
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.69190

Cumulative Model Updates: 168,912
Cumulative Timesteps: 1,408,560,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,537.90398
Policy Entropy: 3.68688
Value Function Loss: 0.03809

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.47896
Value Function Update Magnitude: 0.55642

Collected Steps per Second: 22,643.40681
Overall Steps per Second: 10,581.91836

Timestep Collection Time: 2.20921
Timestep Consumption Time: 2.51810
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.72731

Cumulative Model Updates: 168,918
Cumulative Timesteps: 1,408,610,150

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1408610150...
Checkpoint 1408610150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293,537.90398
Policy Entropy: 3.68451
Value Function Loss: 0.03834

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14516
Policy Update Magnitude: 0.41677
Value Function Update Magnitude: 0.42746

Collected Steps per Second: 22,565.82873
Overall Steps per Second: 10,594.35074

Timestep Collection Time: 2.21698
Timestep Consumption Time: 2.50516
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.72214

Cumulative Model Updates: 168,924
Cumulative Timesteps: 1,408,660,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,537.90398
Policy Entropy: 3.68779
Value Function Loss: 0.03233

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.37891
Value Function Update Magnitude: 0.30083

Collected Steps per Second: 22,068.77689
Overall Steps per Second: 10,776.10301

Timestep Collection Time: 2.26682
Timestep Consumption Time: 2.37549
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.64231

Cumulative Model Updates: 168,930
Cumulative Timesteps: 1,408,710,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1408710204...
Checkpoint 1408710204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293,537.90398
Policy Entropy: 3.68341
Value Function Loss: 0.03038

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14895
Policy Update Magnitude: 0.33753
Value Function Update Magnitude: 0.32102

Collected Steps per Second: 21,395.47801
Overall Steps per Second: 10,609.81766

Timestep Collection Time: 2.33825
Timestep Consumption Time: 2.37700
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.71526

Cumulative Model Updates: 168,936
Cumulative Timesteps: 1,408,760,232

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,537.90398
Policy Entropy: 3.68542
Value Function Loss: 0.02853

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.30004
Value Function Update Magnitude: 0.27985

Collected Steps per Second: 21,907.57492
Overall Steps per Second: 10,476.81889

Timestep Collection Time: 2.28232
Timestep Consumption Time: 2.49013
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.77244

Cumulative Model Updates: 168,942
Cumulative Timesteps: 1,408,810,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1408810232...
Checkpoint 1408810232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 741,510.02718
Policy Entropy: 3.67777
Value Function Loss: 0.03977

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.34747
Value Function Update Magnitude: 0.36208

Collected Steps per Second: 22,175.00375
Overall Steps per Second: 10,676.00761

Timestep Collection Time: 2.25533
Timestep Consumption Time: 2.42919
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.68452

Cumulative Model Updates: 168,948
Cumulative Timesteps: 1,408,860,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741,510.02718
Policy Entropy: 3.67621
Value Function Loss: 0.04017

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.41117
Value Function Update Magnitude: 0.42002

Collected Steps per Second: 22,966.55411
Overall Steps per Second: 10,842.00752

Timestep Collection Time: 2.17751
Timestep Consumption Time: 2.43510
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.61261

Cumulative Model Updates: 168,954
Cumulative Timesteps: 1,408,910,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1408910254...
Checkpoint 1408910254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719,393.91923
Policy Entropy: 3.68026
Value Function Loss: 0.05040

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13526
Policy Update Magnitude: 0.40058
Value Function Update Magnitude: 0.38578

Collected Steps per Second: 22,173.84382
Overall Steps per Second: 10,622.03508

Timestep Collection Time: 2.25491
Timestep Consumption Time: 2.45229
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.70720

Cumulative Model Updates: 168,960
Cumulative Timesteps: 1,408,960,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,709.87772
Policy Entropy: 3.68757
Value Function Loss: 0.05175

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13801
Policy Update Magnitude: 0.42491
Value Function Update Magnitude: 0.55187

Collected Steps per Second: 22,509.98279
Overall Steps per Second: 10,500.82798

Timestep Collection Time: 2.22213
Timestep Consumption Time: 2.54131
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.76343

Cumulative Model Updates: 168,966
Cumulative Timesteps: 1,409,010,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1409010274...
Checkpoint 1409010274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386,394.59980
Policy Entropy: 3.71224
Value Function Loss: 0.06702

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.46650
Value Function Update Magnitude: 0.66009

Collected Steps per Second: 22,224.93599
Overall Steps per Second: 10,609.95312

Timestep Collection Time: 2.25108
Timestep Consumption Time: 2.46431
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.71538

Cumulative Model Updates: 168,972
Cumulative Timesteps: 1,409,060,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,969.69612
Policy Entropy: 3.73411
Value Function Loss: 0.06525

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.49263
Value Function Update Magnitude: 0.78098

Collected Steps per Second: 22,550.34937
Overall Steps per Second: 10,525.80999

Timestep Collection Time: 2.21770
Timestep Consumption Time: 2.53347
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.75118

Cumulative Model Updates: 168,978
Cumulative Timesteps: 1,409,110,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1409110314...
Checkpoint 1409110314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,870.12864
Policy Entropy: 3.71426
Value Function Loss: 0.06638

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.53537
Value Function Update Magnitude: 0.83823

Collected Steps per Second: 21,982.78090
Overall Steps per Second: 10,575.09194

Timestep Collection Time: 2.27496
Timestep Consumption Time: 2.45407
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.72904

Cumulative Model Updates: 168,984
Cumulative Timesteps: 1,409,160,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,722.11341
Policy Entropy: 3.70797
Value Function Loss: 0.05912

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.53665
Value Function Update Magnitude: 0.83092

Collected Steps per Second: 22,682.57555
Overall Steps per Second: 10,571.40789

Timestep Collection Time: 2.20504
Timestep Consumption Time: 2.52621
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.73125

Cumulative Model Updates: 168,990
Cumulative Timesteps: 1,409,210,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1409210340...
Checkpoint 1409210340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,623.36817
Policy Entropy: 3.70068
Value Function Loss: 0.05297

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13691
Policy Update Magnitude: 0.48695
Value Function Update Magnitude: 0.77211

Collected Steps per Second: 22,025.98155
Overall Steps per Second: 10,620.82916

Timestep Collection Time: 2.27032
Timestep Consumption Time: 2.43798
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.70830

Cumulative Model Updates: 168,996
Cumulative Timesteps: 1,409,260,346

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,623.36817
Policy Entropy: 3.71984
Value Function Loss: 0.04310

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.46057
Value Function Update Magnitude: 0.85601

Collected Steps per Second: 22,378.30683
Overall Steps per Second: 10,517.68448

Timestep Collection Time: 2.23547
Timestep Consumption Time: 2.52090
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.75637

Cumulative Model Updates: 169,002
Cumulative Timesteps: 1,409,310,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1409310372...
Checkpoint 1409310372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757,784.27159
Policy Entropy: 3.70444
Value Function Loss: 0.04031

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.43478
Value Function Update Magnitude: 0.84497

Collected Steps per Second: 21,707.41791
Overall Steps per Second: 10,549.82751

Timestep Collection Time: 2.30447
Timestep Consumption Time: 2.43722
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.74169

Cumulative Model Updates: 169,008
Cumulative Timesteps: 1,409,360,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264,248.70298
Policy Entropy: 3.69591
Value Function Loss: 0.03895

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.44797
Value Function Update Magnitude: 0.70028

Collected Steps per Second: 21,752.34145
Overall Steps per Second: 10,578.17126

Timestep Collection Time: 2.29897
Timestep Consumption Time: 2.42850
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.72747

Cumulative Model Updates: 169,014
Cumulative Timesteps: 1,409,410,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1409410404...
Checkpoint 1409410404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,399.73317
Policy Entropy: 3.68543
Value Function Loss: 0.04522

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.48952
Value Function Update Magnitude: 0.63019

Collected Steps per Second: 21,762.88504
Overall Steps per Second: 10,537.10996

Timestep Collection Time: 2.29887
Timestep Consumption Time: 2.44911
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.74798

Cumulative Model Updates: 169,020
Cumulative Timesteps: 1,409,460,434

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,399.73317
Policy Entropy: 3.69298
Value Function Loss: 0.03952

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13616
Policy Update Magnitude: 0.49585
Value Function Update Magnitude: 0.55588

Collected Steps per Second: 21,888.77220
Overall Steps per Second: 10,460.42684

Timestep Collection Time: 2.28629
Timestep Consumption Time: 2.49784
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.78413

Cumulative Model Updates: 169,026
Cumulative Timesteps: 1,409,510,478

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1409510478...
Checkpoint 1409510478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,399.73317
Policy Entropy: 3.66984
Value Function Loss: 0.04117

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13657
Policy Update Magnitude: 0.47478
Value Function Update Magnitude: 0.50384

Collected Steps per Second: 22,340.45187
Overall Steps per Second: 10,619.83450

Timestep Collection Time: 2.23809
Timestep Consumption Time: 2.47008
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.70817

Cumulative Model Updates: 169,032
Cumulative Timesteps: 1,409,560,478

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,399.73317
Policy Entropy: 3.67430
Value Function Loss: 0.03577

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13682
Policy Update Magnitude: 0.44070
Value Function Update Magnitude: 0.50659

Collected Steps per Second: 22,581.42089
Overall Steps per Second: 10,651.55776

Timestep Collection Time: 2.21518
Timestep Consumption Time: 2.48103
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.69621

Cumulative Model Updates: 169,038
Cumulative Timesteps: 1,409,610,500

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1409610500...
Checkpoint 1409610500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,399.73317
Policy Entropy: 3.67003
Value Function Loss: 0.03853

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.41491
Value Function Update Magnitude: 0.48246

Collected Steps per Second: 22,383.39668
Overall Steps per Second: 10,522.52873

Timestep Collection Time: 2.23416
Timestep Consumption Time: 2.51831
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.75247

Cumulative Model Updates: 169,044
Cumulative Timesteps: 1,409,660,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332,818.92297
Policy Entropy: 3.67469
Value Function Loss: 0.04350

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13013
Policy Update Magnitude: 0.49180
Value Function Update Magnitude: 0.54547

Collected Steps per Second: 22,685.79167
Overall Steps per Second: 10,702.66301

Timestep Collection Time: 2.20517
Timestep Consumption Time: 2.46900
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.67416

Cumulative Model Updates: 169,050
Cumulative Timesteps: 1,409,710,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1409710534...
Checkpoint 1409710534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,658.24796
Policy Entropy: 3.69625
Value Function Loss: 0.05092

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.52907
Value Function Update Magnitude: 0.70453

Collected Steps per Second: 22,058.26263
Overall Steps per Second: 10,444.26107

Timestep Collection Time: 2.26790
Timestep Consumption Time: 2.52190
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.78981

Cumulative Model Updates: 169,056
Cumulative Timesteps: 1,409,760,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,130.63878
Policy Entropy: 3.71774
Value Function Loss: 0.04769

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.52402
Value Function Update Magnitude: 0.78135

Collected Steps per Second: 22,778.76427
Overall Steps per Second: 10,755.15271

Timestep Collection Time: 2.19617
Timestep Consumption Time: 2.45518
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.65135

Cumulative Model Updates: 169,062
Cumulative Timesteps: 1,409,810,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1409810586...
Checkpoint 1409810586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,393.66758
Policy Entropy: 3.72787
Value Function Loss: 0.04839

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.52236
Value Function Update Magnitude: 0.84997

Collected Steps per Second: 22,440.16397
Overall Steps per Second: 10,669.20436

Timestep Collection Time: 2.22948
Timestep Consumption Time: 2.45971
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.68920

Cumulative Model Updates: 169,068
Cumulative Timesteps: 1,409,860,616

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.68676
Policy Entropy: 3.69889
Value Function Loss: 0.04831

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.55146
Value Function Update Magnitude: 0.83941

Collected Steps per Second: 22,518.52135
Overall Steps per Second: 10,529.82351

Timestep Collection Time: 2.22119
Timestep Consumption Time: 2.52893
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.75013

Cumulative Model Updates: 169,074
Cumulative Timesteps: 1,409,910,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1409910634...
Checkpoint 1409910634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,491.52598
Policy Entropy: 3.67651
Value Function Loss: 0.04860

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.56196
Value Function Update Magnitude: 0.89839

Collected Steps per Second: 22,200.79259
Overall Steps per Second: 10,669.93598

Timestep Collection Time: 2.25316
Timestep Consumption Time: 2.43496
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.68813

Cumulative Model Updates: 169,080
Cumulative Timesteps: 1,409,960,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134,864.76354
Policy Entropy: 3.66524
Value Function Loss: 0.04349

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.53374
Value Function Update Magnitude: 0.83221

Collected Steps per Second: 22,809.04666
Overall Steps per Second: 10,743.69102

Timestep Collection Time: 2.19246
Timestep Consumption Time: 2.46218
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.65464

Cumulative Model Updates: 169,086
Cumulative Timesteps: 1,410,010,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1410010664...
Checkpoint 1410010664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134,864.76354
Policy Entropy: 3.67638
Value Function Loss: 0.03495

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.48639
Value Function Update Magnitude: 0.64482

Collected Steps per Second: 22,004.10391
Overall Steps per Second: 10,473.24785

Timestep Collection Time: 2.27339
Timestep Consumption Time: 2.50297
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.77636

Cumulative Model Updates: 169,092
Cumulative Timesteps: 1,410,060,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200,661.68614
Policy Entropy: 3.65965
Value Function Loss: 0.03105

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.40713
Value Function Update Magnitude: 0.61853

Collected Steps per Second: 22,766.52575
Overall Steps per Second: 10,739.21535

Timestep Collection Time: 2.19665
Timestep Consumption Time: 2.46012
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.65676

Cumulative Model Updates: 169,098
Cumulative Timesteps: 1,410,110,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1410110698...
Checkpoint 1410110698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,651.75807
Policy Entropy: 3.67250
Value Function Loss: 0.02971

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13304
Policy Update Magnitude: 0.39344
Value Function Update Magnitude: 0.59913

Collected Steps per Second: 21,556.97748
Overall Steps per Second: 10,644.73876

Timestep Collection Time: 2.32036
Timestep Consumption Time: 2.37867
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.69903

Cumulative Model Updates: 169,104
Cumulative Timesteps: 1,410,160,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,651.75807
Policy Entropy: 3.67974
Value Function Loss: 0.02808

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14482
Policy Update Magnitude: 0.36323
Value Function Update Magnitude: 0.52572

Collected Steps per Second: 21,789.91487
Overall Steps per Second: 10,574.89048

Timestep Collection Time: 2.29547
Timestep Consumption Time: 2.43442
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.72988

Cumulative Model Updates: 169,110
Cumulative Timesteps: 1,410,210,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1410210736...
Checkpoint 1410210736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,651.75807
Policy Entropy: 3.67277
Value Function Loss: 0.02899

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.35302
Value Function Update Magnitude: 0.46559

Collected Steps per Second: 21,753.34293
Overall Steps per Second: 10,508.71776

Timestep Collection Time: 2.29896
Timestep Consumption Time: 2.45995
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.75891

Cumulative Model Updates: 169,116
Cumulative Timesteps: 1,410,260,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,651.75807
Policy Entropy: 3.68150
Value Function Loss: 0.02375

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.37527
Value Function Update Magnitude: 0.45447

Collected Steps per Second: 22,448.49097
Overall Steps per Second: 10,617.64399

Timestep Collection Time: 2.22741
Timestep Consumption Time: 2.48192
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.70933

Cumulative Model Updates: 169,122
Cumulative Timesteps: 1,410,310,748

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1410310748...
Checkpoint 1410310748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,651.75807
Policy Entropy: 3.68728
Value Function Loss: 0.02537

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.34472
Value Function Update Magnitude: 0.37951

Collected Steps per Second: 22,076.00038
Overall Steps per Second: 10,476.51314

Timestep Collection Time: 2.26545
Timestep Consumption Time: 2.50828
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.77373

Cumulative Model Updates: 169,128
Cumulative Timesteps: 1,410,360,760

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,651.75807
Policy Entropy: 3.68716
Value Function Loss: 0.02358

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.30617
Value Function Update Magnitude: 0.30379

Collected Steps per Second: 22,937.75391
Overall Steps per Second: 10,653.33240

Timestep Collection Time: 2.18077
Timestep Consumption Time: 2.51466
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.69543

Cumulative Model Updates: 169,134
Cumulative Timesteps: 1,410,410,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1410410782...
Checkpoint 1410410782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,651.75807
Policy Entropy: 3.67450
Value Function Loss: 0.02518

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13451
Policy Update Magnitude: 0.31159
Value Function Update Magnitude: 0.29499

Collected Steps per Second: 22,514.09661
Overall Steps per Second: 10,551.56286

Timestep Collection Time: 2.22314
Timestep Consumption Time: 2.52042
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.74356

Cumulative Model Updates: 169,140
Cumulative Timesteps: 1,410,460,834

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,651.75807
Policy Entropy: 3.66739
Value Function Loss: 0.02538

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.32274
Value Function Update Magnitude: 0.34536

Collected Steps per Second: 22,661.99234
Overall Steps per Second: 10,734.28868

Timestep Collection Time: 2.20775
Timestep Consumption Time: 2.45320
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.66095

Cumulative Model Updates: 169,146
Cumulative Timesteps: 1,410,510,866

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1410510866...
Checkpoint 1410510866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,651.75807
Policy Entropy: 3.66604
Value Function Loss: 0.02808

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.35555
Value Function Update Magnitude: 0.46818

Collected Steps per Second: 22,048.78207
Overall Steps per Second: 10,619.40416

Timestep Collection Time: 2.26824
Timestep Consumption Time: 2.44125
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.70949

Cumulative Model Updates: 169,152
Cumulative Timesteps: 1,410,560,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733,022.78658
Policy Entropy: 3.66296
Value Function Loss: 0.03695

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.41818
Value Function Update Magnitude: 0.45530

Collected Steps per Second: 22,381.59842
Overall Steps per Second: 10,539.91404

Timestep Collection Time: 2.23478
Timestep Consumption Time: 2.51080
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.74558

Cumulative Model Updates: 169,158
Cumulative Timesteps: 1,410,610,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1410610896...
Checkpoint 1410610896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733,022.78658
Policy Entropy: 3.64858
Value Function Loss: 0.04477

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.43868
Value Function Update Magnitude: 0.41042

Collected Steps per Second: 22,070.84505
Overall Steps per Second: 10,589.34278

Timestep Collection Time: 2.26616
Timestep Consumption Time: 2.45708
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.72324

Cumulative Model Updates: 169,164
Cumulative Timesteps: 1,410,660,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663,814.79075
Policy Entropy: 3.64923
Value Function Loss: 0.04736

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.47439
Value Function Update Magnitude: 0.40542

Collected Steps per Second: 22,360.37399
Overall Steps per Second: 10,500.34825

Timestep Collection Time: 2.23619
Timestep Consumption Time: 2.52575
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.76194

Cumulative Model Updates: 169,170
Cumulative Timesteps: 1,410,710,914

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1410710914...
Checkpoint 1410710914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,690.53928
Policy Entropy: 3.67067
Value Function Loss: 0.04305

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13842
Policy Update Magnitude: 0.51774
Value Function Update Magnitude: 0.47683

Collected Steps per Second: 22,370.60805
Overall Steps per Second: 10,709.44700

Timestep Collection Time: 2.23534
Timestep Consumption Time: 2.43399
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.66934

Cumulative Model Updates: 169,176
Cumulative Timesteps: 1,410,760,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,690.53928
Policy Entropy: 3.67069
Value Function Loss: 0.03851

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.51622
Value Function Update Magnitude: 0.58165

Collected Steps per Second: 21,740.99976
Overall Steps per Second: 10,556.34308

Timestep Collection Time: 2.30146
Timestep Consumption Time: 2.43844
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.73990

Cumulative Model Updates: 169,182
Cumulative Timesteps: 1,410,810,956

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1410810956...
Checkpoint 1410810956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387,338.30407
Policy Entropy: 3.68704
Value Function Loss: 0.03797

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.53510
Value Function Update Magnitude: 0.64237

Collected Steps per Second: 21,705.51772
Overall Steps per Second: 10,513.09569

Timestep Collection Time: 2.30458
Timestep Consumption Time: 2.45349
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.75807

Cumulative Model Updates: 169,188
Cumulative Timesteps: 1,410,860,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175,680.89660
Policy Entropy: 3.66981
Value Function Loss: 0.04647

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13014
Policy Update Magnitude: 0.58653
Value Function Update Magnitude: 0.82915

Collected Steps per Second: 21,947.01419
Overall Steps per Second: 10,610.19254

Timestep Collection Time: 2.27940
Timestep Consumption Time: 2.43550
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.71490

Cumulative Model Updates: 169,194
Cumulative Timesteps: 1,410,911,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1410911004...
Checkpoint 1410911004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175,680.89660
Policy Entropy: 3.67281
Value Function Loss: 0.04967

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.60210
Value Function Update Magnitude: 0.72160

Collected Steps per Second: 21,770.63099
Overall Steps per Second: 10,477.93548

Timestep Collection Time: 2.29796
Timestep Consumption Time: 2.47665
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.77460

Cumulative Model Updates: 169,200
Cumulative Timesteps: 1,410,961,032

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175,680.89660
Policy Entropy: 3.66704
Value Function Loss: 0.04374

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14420
Policy Update Magnitude: 0.57416
Value Function Update Magnitude: 0.72572

Collected Steps per Second: 22,376.60616
Overall Steps per Second: 10,593.15192

Timestep Collection Time: 2.23564
Timestep Consumption Time: 2.48685
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.72248

Cumulative Model Updates: 169,206
Cumulative Timesteps: 1,411,011,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1411011058...
Checkpoint 1411011058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175,680.89660
Policy Entropy: 3.66610
Value Function Loss: 0.03515

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.50665
Value Function Update Magnitude: 0.65361

Collected Steps per Second: 22,364.83593
Overall Steps per Second: 10,480.68393

Timestep Collection Time: 2.23655
Timestep Consumption Time: 2.53604
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.77259

Cumulative Model Updates: 169,212
Cumulative Timesteps: 1,411,061,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175,680.89660
Policy Entropy: 3.66933
Value Function Loss: 0.02707

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.43078
Value Function Update Magnitude: 0.48730

Collected Steps per Second: 22,645.07906
Overall Steps per Second: 10,572.73229

Timestep Collection Time: 2.20878
Timestep Consumption Time: 2.52207
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.73085

Cumulative Model Updates: 169,218
Cumulative Timesteps: 1,411,111,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1411111096...
Checkpoint 1411111096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312,807.07169
Policy Entropy: 3.67938
Value Function Loss: 0.02875

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.37450
Value Function Update Magnitude: 0.53496

Collected Steps per Second: 22,368.84454
Overall Steps per Second: 10,547.02920

Timestep Collection Time: 2.23615
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.74257

Cumulative Model Updates: 169,224
Cumulative Timesteps: 1,411,161,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253,379.56929
Policy Entropy: 3.68658
Value Function Loss: 0.03179

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.36186
Value Function Update Magnitude: 0.55329

Collected Steps per Second: 22,851.29827
Overall Steps per Second: 10,630.70974

Timestep Collection Time: 2.18850
Timestep Consumption Time: 2.51580
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.70430

Cumulative Model Updates: 169,230
Cumulative Timesteps: 1,411,211,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1411211126...
Checkpoint 1411211126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253,379.56929
Policy Entropy: 3.69571
Value Function Loss: 0.03009

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.37390
Value Function Update Magnitude: 0.52921

Collected Steps per Second: 22,395.58231
Overall Steps per Second: 10,532.39064

Timestep Collection Time: 2.23357
Timestep Consumption Time: 2.51578
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.74935

Cumulative Model Updates: 169,236
Cumulative Timesteps: 1,411,261,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253,379.56929
Policy Entropy: 3.68234
Value Function Loss: 0.02723

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.35734
Value Function Update Magnitude: 0.53320

Collected Steps per Second: 22,465.11128
Overall Steps per Second: 10,573.85036

Timestep Collection Time: 2.22576
Timestep Consumption Time: 2.50307
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.72884

Cumulative Model Updates: 169,242
Cumulative Timesteps: 1,411,311,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1411311150...
Checkpoint 1411311150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,383.24860
Policy Entropy: 3.68927
Value Function Loss: 0.02583

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.34043
Value Function Update Magnitude: 0.58504

Collected Steps per Second: 21,609.60952
Overall Steps per Second: 10,518.15048

Timestep Collection Time: 2.31406
Timestep Consumption Time: 2.44019
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.75426

Cumulative Model Updates: 169,248
Cumulative Timesteps: 1,411,361,156

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,383.24860
Policy Entropy: 3.67999
Value Function Loss: 0.02883

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.35987
Value Function Update Magnitude: 0.59409

Collected Steps per Second: 21,983.24789
Overall Steps per Second: 10,730.46551

Timestep Collection Time: 2.27564
Timestep Consumption Time: 2.38641
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.66205

Cumulative Model Updates: 169,254
Cumulative Timesteps: 1,411,411,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1411411182...
Checkpoint 1411411182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,155.63299
Policy Entropy: 3.67760
Value Function Loss: 0.03352

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13190
Policy Update Magnitude: 0.37820
Value Function Update Magnitude: 0.61037

Collected Steps per Second: 21,471.14734
Overall Steps per Second: 10,370.69805

Timestep Collection Time: 2.33048
Timestep Consumption Time: 2.49446
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.82494

Cumulative Model Updates: 169,260
Cumulative Timesteps: 1,411,461,220

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,924.94536
Policy Entropy: 3.66964
Value Function Loss: 0.03476

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.41830
Value Function Update Magnitude: 0.48867

Collected Steps per Second: 22,234.34703
Overall Steps per Second: 10,586.12652

Timestep Collection Time: 2.25048
Timestep Consumption Time: 2.47627
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.72675

Cumulative Model Updates: 169,266
Cumulative Timesteps: 1,411,511,258

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1411511258...
Checkpoint 1411511258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,367.49520
Policy Entropy: 3.66315
Value Function Loss: 0.03566

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.44893
Value Function Update Magnitude: 0.43746

Collected Steps per Second: 22,443.71192
Overall Steps per Second: 10,641.58911

Timestep Collection Time: 2.22869
Timestep Consumption Time: 2.47174
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.70043

Cumulative Model Updates: 169,272
Cumulative Timesteps: 1,411,561,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426,367.49520
Policy Entropy: 3.68261
Value Function Loss: 0.03273

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.43563
Value Function Update Magnitude: 0.55751

Collected Steps per Second: 22,604.15812
Overall Steps per Second: 10,710.78032

Timestep Collection Time: 2.21242
Timestep Consumption Time: 2.45670
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.66913

Cumulative Model Updates: 169,278
Cumulative Timesteps: 1,411,611,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1411611288...
Checkpoint 1411611288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,367.49520
Policy Entropy: 3.67292
Value Function Loss: 0.03200

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.39093
Value Function Update Magnitude: 0.48032

Collected Steps per Second: 22,326.24309
Overall Steps per Second: 10,611.33094

Timestep Collection Time: 2.23979
Timestep Consumption Time: 2.47272
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.71251

Cumulative Model Updates: 169,284
Cumulative Timesteps: 1,411,661,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426,367.49520
Policy Entropy: 3.68051
Value Function Loss: 0.02819

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.35609
Value Function Update Magnitude: 0.39555

Collected Steps per Second: 22,684.07297
Overall Steps per Second: 10,562.23272

Timestep Collection Time: 2.20419
Timestep Consumption Time: 2.52966
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.73385

Cumulative Model Updates: 169,290
Cumulative Timesteps: 1,411,711,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1411711294...
Checkpoint 1411711294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,245.67294
Policy Entropy: 3.66824
Value Function Loss: 0.03533

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.35304
Value Function Update Magnitude: 0.41792

Collected Steps per Second: 22,555.55422
Overall Steps per Second: 10,550.86866

Timestep Collection Time: 2.21675
Timestep Consumption Time: 2.52220
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.73895

Cumulative Model Updates: 169,296
Cumulative Timesteps: 1,411,761,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235,565.64718
Policy Entropy: 3.68046
Value Function Loss: 0.03667

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.38221
Value Function Update Magnitude: 0.60920

Collected Steps per Second: 22,519.67601
Overall Steps per Second: 10,521.40730

Timestep Collection Time: 2.22099
Timestep Consumption Time: 2.53275
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.75374

Cumulative Model Updates: 169,302
Cumulative Timesteps: 1,411,811,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1411811310...
Checkpoint 1411811310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235,565.64718
Policy Entropy: 3.68807
Value Function Loss: 0.03681

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.44877
Value Function Update Magnitude: 0.63710

Collected Steps per Second: 22,596.74630
Overall Steps per Second: 10,587.96058

Timestep Collection Time: 2.21333
Timestep Consumption Time: 2.51034
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.72367

Cumulative Model Updates: 169,308
Cumulative Timesteps: 1,411,861,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235,071.38784
Policy Entropy: 3.69868
Value Function Loss: 0.03266

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.43966
Value Function Update Magnitude: 0.69008

Collected Steps per Second: 22,408.11965
Overall Steps per Second: 10,509.99957

Timestep Collection Time: 2.23178
Timestep Consumption Time: 2.52655
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.75833

Cumulative Model Updates: 169,314
Cumulative Timesteps: 1,411,911,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1411911334...
Checkpoint 1411911334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235,071.38784
Policy Entropy: 3.68712
Value Function Loss: 0.03108

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.45298
Value Function Update Magnitude: 0.68286

Collected Steps per Second: 22,148.04708
Overall Steps per Second: 10,625.07043

Timestep Collection Time: 2.25844
Timestep Consumption Time: 2.44930
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.70773

Cumulative Model Updates: 169,320
Cumulative Timesteps: 1,411,961,354

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317,439.90616
Policy Entropy: 3.67126
Value Function Loss: 0.03400

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.50158
Value Function Update Magnitude: 0.73373

Collected Steps per Second: 22,911.88325
Overall Steps per Second: 10,765.83923

Timestep Collection Time: 2.18411
Timestep Consumption Time: 2.46411
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.64822

Cumulative Model Updates: 169,326
Cumulative Timesteps: 1,412,011,396

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1412011396...
Checkpoint 1412011396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276,145.03676
Policy Entropy: 3.65847
Value Function Loss: 0.03805

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.51871
Value Function Update Magnitude: 0.59746

Collected Steps per Second: 22,294.98687
Overall Steps per Second: 10,641.51573

Timestep Collection Time: 2.24373
Timestep Consumption Time: 2.45710
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.70083

Cumulative Model Updates: 169,332
Cumulative Timesteps: 1,412,061,420

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,145.03676
Policy Entropy: 3.67041
Value Function Loss: 0.03748

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.51259
Value Function Update Magnitude: 0.53511

Collected Steps per Second: 22,688.58508
Overall Steps per Second: 10,548.25795

Timestep Collection Time: 2.20384
Timestep Consumption Time: 2.53647
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.74031

Cumulative Model Updates: 169,338
Cumulative Timesteps: 1,412,111,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1412111422...
Checkpoint 1412111422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276,145.03676
Policy Entropy: 3.66327
Value Function Loss: 0.03428

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.47124
Value Function Update Magnitude: 0.48234

Collected Steps per Second: 21,684.27547
Overall Steps per Second: 10,707.97967

Timestep Collection Time: 2.30628
Timestep Consumption Time: 2.36407
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.67035

Cumulative Model Updates: 169,344
Cumulative Timesteps: 1,412,161,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,145.03676
Policy Entropy: 3.66984
Value Function Loss: 0.03064

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.42428
Value Function Update Magnitude: 0.39687

Collected Steps per Second: 21,883.79062
Overall Steps per Second: 10,740.93138

Timestep Collection Time: 2.28507
Timestep Consumption Time: 2.37058
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.65565

Cumulative Model Updates: 169,350
Cumulative Timesteps: 1,412,211,438

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1412211438...
Checkpoint 1412211438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276,145.03676
Policy Entropy: 3.66307
Value Function Loss: 0.03626

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.46689
Value Function Update Magnitude: 0.48126

Collected Steps per Second: 21,587.25495
Overall Steps per Second: 10,391.82939

Timestep Collection Time: 2.31702
Timestep Consumption Time: 2.49619
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.81320

Cumulative Model Updates: 169,356
Cumulative Timesteps: 1,412,261,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,145.03676
Policy Entropy: 3.68743
Value Function Loss: 0.03556

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.53803
Value Function Update Magnitude: 0.64735

Collected Steps per Second: 22,583.38831
Overall Steps per Second: 10,762.44621

Timestep Collection Time: 2.21526
Timestep Consumption Time: 2.43313
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.64839

Cumulative Model Updates: 169,362
Cumulative Timesteps: 1,412,311,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1412311484...
Checkpoint 1412311484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276,145.03676
Policy Entropy: 3.67780
Value Function Loss: 0.03363

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.50663
Value Function Update Magnitude: 0.62214

Collected Steps per Second: 22,398.47667
Overall Steps per Second: 10,745.04661

Timestep Collection Time: 2.23301
Timestep Consumption Time: 2.42179
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.65480

Cumulative Model Updates: 169,368
Cumulative Timesteps: 1,412,361,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,145.03676
Policy Entropy: 3.67648
Value Function Loss: 0.02809

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.41688
Value Function Update Magnitude: 0.46587

Collected Steps per Second: 22,681.69646
Overall Steps per Second: 10,600.09325

Timestep Collection Time: 2.20574
Timestep Consumption Time: 2.51403
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.71977

Cumulative Model Updates: 169,374
Cumulative Timesteps: 1,412,411,530

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1412411530...
Checkpoint 1412411530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276,145.03676
Policy Entropy: 3.65776
Value Function Loss: 0.02665

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.36733
Value Function Update Magnitude: 0.46691

Collected Steps per Second: 22,631.73843
Overall Steps per Second: 10,581.66694

Timestep Collection Time: 2.21008
Timestep Consumption Time: 2.51677
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.72685

Cumulative Model Updates: 169,380
Cumulative Timesteps: 1,412,461,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,145.03676
Policy Entropy: 3.66548
Value Function Loss: 0.02392

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13712
Policy Update Magnitude: 0.37755
Value Function Update Magnitude: 0.54276

Collected Steps per Second: 22,716.94684
Overall Steps per Second: 10,728.69088

Timestep Collection Time: 2.20188
Timestep Consumption Time: 2.46038
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.66226

Cumulative Model Updates: 169,386
Cumulative Timesteps: 1,412,511,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1412511568...
Checkpoint 1412511568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,780.55858
Policy Entropy: 3.67191
Value Function Loss: 0.03044

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.39931
Value Function Update Magnitude: 0.56182

Collected Steps per Second: 22,104.02378
Overall Steps per Second: 10,623.64198

Timestep Collection Time: 2.26294
Timestep Consumption Time: 2.44543
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.70837

Cumulative Model Updates: 169,392
Cumulative Timesteps: 1,412,561,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,644.63360
Policy Entropy: 3.69486
Value Function Loss: 0.03003

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.40237
Value Function Update Magnitude: 0.69895

Collected Steps per Second: 22,646.33780
Overall Steps per Second: 10,521.22042

Timestep Collection Time: 2.20786
Timestep Consumption Time: 2.54444
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.75230

Cumulative Model Updates: 169,398
Cumulative Timesteps: 1,412,611,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1412611588...
Checkpoint 1412611588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,179.54514
Policy Entropy: 3.69489
Value Function Loss: 0.03117

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.39675
Value Function Update Magnitude: 0.73083

Collected Steps per Second: 22,316.92397
Overall Steps per Second: 10,627.07294

Timestep Collection Time: 2.24126
Timestep Consumption Time: 2.46540
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.70666

Cumulative Model Updates: 169,404
Cumulative Timesteps: 1,412,661,606

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324,666.07442
Policy Entropy: 3.68185
Value Function Loss: 0.03454

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.41956
Value Function Update Magnitude: 0.68403

Collected Steps per Second: 22,582.80584
Overall Steps per Second: 10,542.95702

Timestep Collection Time: 2.21540
Timestep Consumption Time: 2.52995
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.74535

Cumulative Model Updates: 169,410
Cumulative Timesteps: 1,412,711,636

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1412711636...
Checkpoint 1412711636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324,666.07442
Policy Entropy: 3.66470
Value Function Loss: 0.03877

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.45229
Value Function Update Magnitude: 0.67374

Collected Steps per Second: 21,990.31425
Overall Steps per Second: 10,613.99824

Timestep Collection Time: 2.27446
Timestep Consumption Time: 2.43781
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.71227

Cumulative Model Updates: 169,416
Cumulative Timesteps: 1,412,761,652

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324,666.07442
Policy Entropy: 3.65382
Value Function Loss: 0.03917

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14583
Policy Update Magnitude: 0.42636
Value Function Update Magnitude: 0.54145

Collected Steps per Second: 22,380.18856
Overall Steps per Second: 10,494.97977

Timestep Collection Time: 2.23412
Timestep Consumption Time: 2.53006
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.76418

Cumulative Model Updates: 169,422
Cumulative Timesteps: 1,412,811,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1412811652...
Checkpoint 1412811652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324,666.07442
Policy Entropy: 3.66316
Value Function Loss: 0.03517

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.15739
Policy Update Magnitude: 0.43081
Value Function Update Magnitude: 0.43522

Collected Steps per Second: 22,223.09189
Overall Steps per Second: 10,561.72109

Timestep Collection Time: 2.25117
Timestep Consumption Time: 2.48556
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.73673

Cumulative Model Updates: 169,428
Cumulative Timesteps: 1,412,861,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324,666.07442
Policy Entropy: 3.66066
Value Function Loss: 0.03216

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.15848
Policy Update Magnitude: 0.42873
Value Function Update Magnitude: 0.55726

Collected Steps per Second: 22,313.31539
Overall Steps per Second: 10,473.75565

Timestep Collection Time: 2.24117
Timestep Consumption Time: 2.53343
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.77460

Cumulative Model Updates: 169,434
Cumulative Timesteps: 1,412,911,688

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1412911688...
Checkpoint 1412911688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404,906.26156
Policy Entropy: 3.67806
Value Function Loss: 0.03812

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15488
Policy Update Magnitude: 0.43819
Value Function Update Magnitude: 0.68877

Collected Steps per Second: 22,481.47341
Overall Steps per Second: 10,650.70524

Timestep Collection Time: 2.22503
Timestep Consumption Time: 2.47156
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.69659

Cumulative Model Updates: 169,440
Cumulative Timesteps: 1,412,961,710

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258,263.54332
Policy Entropy: 3.68720
Value Function Loss: 0.04644

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.14510
Policy Update Magnitude: 0.61909
Value Function Update Magnitude: 0.62935

Collected Steps per Second: 21,601.47117
Overall Steps per Second: 10,493.20078

Timestep Collection Time: 2.31577
Timestep Consumption Time: 2.45151
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.76728

Cumulative Model Updates: 169,446
Cumulative Timesteps: 1,413,011,734

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1413011734...
Checkpoint 1413011734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,199.31719
Policy Entropy: 3.72160
Value Function Loss: 0.04850

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.16889
Policy Update Magnitude: 0.66938
Value Function Update Magnitude: 0.72922

Collected Steps per Second: 21,666.71946
Overall Steps per Second: 10,605.10070

Timestep Collection Time: 2.30787
Timestep Consumption Time: 2.40722
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.71509

Cumulative Model Updates: 169,452
Cumulative Timesteps: 1,413,061,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,983.73369
Policy Entropy: 3.73003
Value Function Loss: 0.04912

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.18302
Policy Update Magnitude: 0.65401
Value Function Update Magnitude: 0.79910

Collected Steps per Second: 22,085.60051
Overall Steps per Second: 10,664.20126

Timestep Collection Time: 2.26501
Timestep Consumption Time: 2.42583
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.69083

Cumulative Model Updates: 169,458
Cumulative Timesteps: 1,413,111,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1413111762...
Checkpoint 1413111762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,540.27611
Policy Entropy: 3.74786
Value Function Loss: 0.05276

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.20761
Policy Update Magnitude: 0.57330
Value Function Update Magnitude: 0.82727

Collected Steps per Second: 21,761.12836
Overall Steps per Second: 10,609.87765

Timestep Collection Time: 2.29804
Timestep Consumption Time: 2.41530
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.71334

Cumulative Model Updates: 169,464
Cumulative Timesteps: 1,413,161,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,308.58898
Policy Entropy: 3.73945
Value Function Loss: 0.06034

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.58108
Value Function Update Magnitude: 0.81684

Collected Steps per Second: 21,856.94419
Overall Steps per Second: 10,712.29867

Timestep Collection Time: 2.28779
Timestep Consumption Time: 2.38012
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.66791

Cumulative Model Updates: 169,470
Cumulative Timesteps: 1,413,211,774

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1413211774...
Checkpoint 1413211774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,831.80624
Policy Entropy: 3.74413
Value Function Loss: 0.06574

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.16127
Policy Update Magnitude: 0.63892
Value Function Update Magnitude: 0.84537

Collected Steps per Second: 21,579.64633
Overall Steps per Second: 10,384.69350

Timestep Collection Time: 2.31802
Timestep Consumption Time: 2.49888
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.81690

Cumulative Model Updates: 169,476
Cumulative Timesteps: 1,413,261,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306,711.93471
Policy Entropy: 3.72469
Value Function Loss: 0.07172

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.15799
Policy Update Magnitude: 0.70424
Value Function Update Magnitude: 0.77147

Collected Steps per Second: 22,355.15851
Overall Steps per Second: 10,715.24932

Timestep Collection Time: 2.23698
Timestep Consumption Time: 2.43002
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.66699

Cumulative Model Updates: 169,482
Cumulative Timesteps: 1,413,311,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1413311804...
Checkpoint 1413311804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,931.97289
Policy Entropy: 3.73807
Value Function Loss: 0.08380

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.15009
Policy Update Magnitude: 0.72253
Value Function Update Magnitude: 0.75239

Collected Steps per Second: 22,353.79470
Overall Steps per Second: 10,682.91734

Timestep Collection Time: 2.23765
Timestep Consumption Time: 2.44459
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.68224

Cumulative Model Updates: 169,488
Cumulative Timesteps: 1,413,361,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,324.72748
Policy Entropy: 3.75477
Value Function Loss: 0.08841

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.89827
Value Function Update Magnitude: 0.71833

Collected Steps per Second: 22,707.26667
Overall Steps per Second: 10,798.03561

Timestep Collection Time: 2.20308
Timestep Consumption Time: 2.42980
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.63288

Cumulative Model Updates: 169,494
Cumulative Timesteps: 1,413,411,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1413411850...
Checkpoint 1413411850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,898.55128
Policy Entropy: 3.75309
Value Function Loss: 0.07906

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.15922
Policy Update Magnitude: 0.87762
Value Function Update Magnitude: 0.84121

Collected Steps per Second: 22,159.21676
Overall Steps per Second: 10,657.25453

Timestep Collection Time: 2.25730
Timestep Consumption Time: 2.43622
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.69352

Cumulative Model Updates: 169,500
Cumulative Timesteps: 1,413,461,870

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,576.32357
Policy Entropy: 3.75418
Value Function Loss: 0.06875

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.18960
Policy Update Magnitude: 0.76562
Value Function Update Magnitude: 0.84473

Collected Steps per Second: 22,241.43223
Overall Steps per Second: 10,510.33506

Timestep Collection Time: 2.24860
Timestep Consumption Time: 2.50977
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.75836

Cumulative Model Updates: 169,506
Cumulative Timesteps: 1,413,511,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1413511882...
Checkpoint 1413511882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,560.78587
Policy Entropy: 3.75457
Value Function Loss: 0.07252

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.16940
Policy Update Magnitude: 0.66843
Value Function Update Magnitude: 0.79493

Collected Steps per Second: 22,130.81914
Overall Steps per Second: 10,653.54989

Timestep Collection Time: 2.25956
Timestep Consumption Time: 2.43427
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.69383

Cumulative Model Updates: 169,512
Cumulative Timesteps: 1,413,561,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,686.54894
Policy Entropy: 3.76333
Value Function Loss: 0.09385

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.84752
Value Function Update Magnitude: 0.71665

Collected Steps per Second: 22,453.87551
Overall Steps per Second: 10,596.63571

Timestep Collection Time: 2.22768
Timestep Consumption Time: 2.49269
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.72037

Cumulative Model Updates: 169,518
Cumulative Timesteps: 1,413,611,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1413611908...
Checkpoint 1413611908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,297.90929
Policy Entropy: 3.78725
Value Function Loss: 0.09398

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.16699
Policy Update Magnitude: 0.80559
Value Function Update Magnitude: 0.62645

Collected Steps per Second: 22,511.33727
Overall Steps per Second: 10,492.28680

Timestep Collection Time: 2.22119
Timestep Consumption Time: 2.54440
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.76560

Cumulative Model Updates: 169,524
Cumulative Timesteps: 1,413,661,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.74462
Policy Entropy: 3.77709
Value Function Loss: 0.08150

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.15296
Policy Update Magnitude: 0.72639
Value Function Update Magnitude: 0.82735

Collected Steps per Second: 22,585.07678
Overall Steps per Second: 10,513.10777

Timestep Collection Time: 2.21429
Timestep Consumption Time: 2.54262
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.75692

Cumulative Model Updates: 169,530
Cumulative Timesteps: 1,413,711,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1413711920...
Checkpoint 1413711920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,623.58034
Policy Entropy: 3.76338
Value Function Loss: 0.06657

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.59654
Value Function Update Magnitude: 0.77550

Collected Steps per Second: 22,427.25389
Overall Steps per Second: 10,610.96998

Timestep Collection Time: 2.23032
Timestep Consumption Time: 2.48367
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.71399

Cumulative Model Updates: 169,536
Cumulative Timesteps: 1,413,761,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,399.90565
Policy Entropy: 3.73894
Value Function Loss: 0.05161

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.50387
Value Function Update Magnitude: 0.73544

Collected Steps per Second: 22,761.31614
Overall Steps per Second: 10,598.84850

Timestep Collection Time: 2.19706
Timestep Consumption Time: 2.52119
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.71825

Cumulative Model Updates: 169,542
Cumulative Timesteps: 1,413,811,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1413811948...
Checkpoint 1413811948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 901.12858
Policy Entropy: 3.73728
Value Function Loss: 0.04575

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.47965
Value Function Update Magnitude: 0.78317

Collected Steps per Second: 22,273.75413
Overall Steps per Second: 10,473.25168

Timestep Collection Time: 2.24551
Timestep Consumption Time: 2.53008
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.77559

Cumulative Model Updates: 169,548
Cumulative Timesteps: 1,413,861,964

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.06376
Policy Entropy: 3.72290
Value Function Loss: 0.04402

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.46139
Value Function Update Magnitude: 0.77107

Collected Steps per Second: 22,576.64017
Overall Steps per Second: 10,547.02183

Timestep Collection Time: 2.21618
Timestep Consumption Time: 2.52771
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.74390

Cumulative Model Updates: 169,554
Cumulative Timesteps: 1,413,911,998

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1413911998...
Checkpoint 1413911998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194,477.36516
Policy Entropy: 3.72827
Value Function Loss: 0.05122

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14067
Policy Update Magnitude: 0.48707
Value Function Update Magnitude: 0.74759

Collected Steps per Second: 22,189.70091
Overall Steps per Second: 10,582.36638

Timestep Collection Time: 2.25384
Timestep Consumption Time: 2.47214
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.72598

Cumulative Model Updates: 169,560
Cumulative Timesteps: 1,413,962,010

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,205.32343
Policy Entropy: 3.72632
Value Function Loss: 0.05617

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.57266
Value Function Update Magnitude: 0.75027

Collected Steps per Second: 22,417.98948
Overall Steps per Second: 10,434.11345

Timestep Collection Time: 2.23062
Timestep Consumption Time: 2.56193
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.79255

Cumulative Model Updates: 169,566
Cumulative Timesteps: 1,414,012,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1414012016...
Checkpoint 1414012016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,557.49096
Policy Entropy: 3.75194
Value Function Loss: 0.05632

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13483
Policy Update Magnitude: 0.58624
Value Function Update Magnitude: 0.72798

Collected Steps per Second: 22,342.67214
Overall Steps per Second: 10,676.15909

Timestep Collection Time: 2.23912
Timestep Consumption Time: 2.44683
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.68595

Cumulative Model Updates: 169,572
Cumulative Timesteps: 1,414,062,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319,272.08065
Policy Entropy: 3.77266
Value Function Loss: 0.05156

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.53601
Value Function Update Magnitude: 0.80829

Collected Steps per Second: 22,589.93430
Overall Steps per Second: 10,615.92102

Timestep Collection Time: 2.21417
Timestep Consumption Time: 2.49743
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.71160

Cumulative Model Updates: 169,578
Cumulative Timesteps: 1,414,112,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1414112062...
Checkpoint 1414112062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,130.30182
Policy Entropy: 3.76773
Value Function Loss: 0.05068

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.53175
Value Function Update Magnitude: 0.92954

Collected Steps per Second: 22,585.65930
Overall Steps per Second: 10,608.54564

Timestep Collection Time: 2.21477
Timestep Consumption Time: 2.50049
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.71526

Cumulative Model Updates: 169,584
Cumulative Timesteps: 1,414,162,084

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432,900.10779
Policy Entropy: 3.76821
Value Function Loss: 0.05484

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.52355
Value Function Update Magnitude: 0.88121

Collected Steps per Second: 22,703.73715
Overall Steps per Second: 10,721.36156

Timestep Collection Time: 2.20334
Timestep Consumption Time: 2.46249
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.66583

Cumulative Model Updates: 169,590
Cumulative Timesteps: 1,414,212,108

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1414212108...
Checkpoint 1414212108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220,895.17891
Policy Entropy: 3.75431
Value Function Loss: 0.06200

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.51865
Value Function Update Magnitude: 0.83881

Collected Steps per Second: 22,520.94985
Overall Steps per Second: 10,738.64622

Timestep Collection Time: 2.22122
Timestep Consumption Time: 2.43709
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.65832

Cumulative Model Updates: 169,596
Cumulative Timesteps: 1,414,262,132

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,470.41138
Policy Entropy: 3.74159
Value Function Loss: 0.06439

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.48565
Value Function Update Magnitude: 0.68400

Collected Steps per Second: 22,486.89875
Overall Steps per Second: 10,566.06604

Timestep Collection Time: 2.22521
Timestep Consumption Time: 2.51052
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.73573

Cumulative Model Updates: 169,602
Cumulative Timesteps: 1,414,312,170

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1414312170...
Checkpoint 1414312170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,277.77063
Policy Entropy: 3.73204
Value Function Loss: 0.06143

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.46141
Value Function Update Magnitude: 0.67919

Collected Steps per Second: 22,020.11825
Overall Steps per Second: 10,657.75659

Timestep Collection Time: 2.27156
Timestep Consumption Time: 2.42174
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.69330

Cumulative Model Updates: 169,608
Cumulative Timesteps: 1,414,362,190

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.77995
Policy Entropy: 3.71287
Value Function Loss: 0.05571

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12838
Policy Update Magnitude: 0.51700
Value Function Update Magnitude: 0.76398

Collected Steps per Second: 22,114.22262
Overall Steps per Second: 10,686.30766

Timestep Collection Time: 2.26153
Timestep Consumption Time: 2.41848
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.68001

Cumulative Model Updates: 169,614
Cumulative Timesteps: 1,414,412,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1414412202...
Checkpoint 1414412202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,684.99961
Policy Entropy: 3.70260
Value Function Loss: 0.05595

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.50063
Value Function Update Magnitude: 0.87584

Collected Steps per Second: 21,744.88598
Overall Steps per Second: 10,713.16256

Timestep Collection Time: 2.29948
Timestep Consumption Time: 2.36786
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.66734

Cumulative Model Updates: 169,620
Cumulative Timesteps: 1,414,462,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.56090
Policy Entropy: 3.72770
Value Function Loss: 0.05475

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.51891
Value Function Update Magnitude: 0.89624

Collected Steps per Second: 21,508.10446
Overall Steps per Second: 10,458.63704

Timestep Collection Time: 2.32545
Timestep Consumption Time: 2.45682
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.78227

Cumulative Model Updates: 169,626
Cumulative Timesteps: 1,414,512,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1414512220...
Checkpoint 1414512220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,234.19768
Policy Entropy: 3.74302
Value Function Loss: 0.05536

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.52864
Value Function Update Magnitude: 0.74061

Collected Steps per Second: 21,784.79522
Overall Steps per Second: 10,624.09425

Timestep Collection Time: 2.29527
Timestep Consumption Time: 2.41120
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.70647

Cumulative Model Updates: 169,632
Cumulative Timesteps: 1,414,562,222

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.91361
Policy Entropy: 3.76497
Value Function Loss: 0.05492

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.49988
Value Function Update Magnitude: 0.73234

Collected Steps per Second: 22,215.49223
Overall Steps per Second: 10,498.43606

Timestep Collection Time: 2.25194
Timestep Consumption Time: 2.51334
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.76528

Cumulative Model Updates: 169,638
Cumulative Timesteps: 1,414,612,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1414612250...
Checkpoint 1414612250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.50867
Policy Entropy: 3.72465
Value Function Loss: 0.04807

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.47683
Value Function Update Magnitude: 0.74500

Collected Steps per Second: 22,537.32821
Overall Steps per Second: 10,605.44649

Timestep Collection Time: 2.22005
Timestep Consumption Time: 2.49771
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.71776

Cumulative Model Updates: 169,644
Cumulative Timesteps: 1,414,662,284

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,877.93746
Policy Entropy: 3.70762
Value Function Loss: 0.04562

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.48825
Value Function Update Magnitude: 0.75106

Collected Steps per Second: 22,353.73753
Overall Steps per Second: 10,539.59222

Timestep Collection Time: 2.23712
Timestep Consumption Time: 2.50766
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.74478

Cumulative Model Updates: 169,650
Cumulative Timesteps: 1,414,712,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1414712292...
Checkpoint 1414712292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,117.60247
Policy Entropy: 3.69685
Value Function Loss: 0.04706

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.56553
Value Function Update Magnitude: 0.82805

Collected Steps per Second: 22,480.54392
Overall Steps per Second: 10,597.66298

Timestep Collection Time: 2.22486
Timestep Consumption Time: 2.49467
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.71953

Cumulative Model Updates: 169,656
Cumulative Timesteps: 1,414,762,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,884.14181
Policy Entropy: 3.69934
Value Function Loss: 0.04579

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.56564
Value Function Update Magnitude: 0.67554

Collected Steps per Second: 22,432.14941
Overall Steps per Second: 10,535.99993

Timestep Collection Time: 2.22912
Timestep Consumption Time: 2.51689
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.74601

Cumulative Model Updates: 169,662
Cumulative Timesteps: 1,414,812,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1414812312...
Checkpoint 1414812312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,513.82182
Policy Entropy: 3.67708
Value Function Loss: 0.04813

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.50302
Value Function Update Magnitude: 0.56741

Collected Steps per Second: 22,684.00678
Overall Steps per Second: 10,571.38168

Timestep Collection Time: 2.20428
Timestep Consumption Time: 2.52566
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.72994

Cumulative Model Updates: 169,668
Cumulative Timesteps: 1,414,862,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,403.92009
Policy Entropy: 3.65924
Value Function Loss: 0.04656

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13916
Policy Update Magnitude: 0.49400
Value Function Update Magnitude: 0.51314

Collected Steps per Second: 22,544.23420
Overall Steps per Second: 10,598.98326

Timestep Collection Time: 2.21857
Timestep Consumption Time: 2.50037
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.71894

Cumulative Model Updates: 169,674
Cumulative Timesteps: 1,414,912,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1414912330...
Checkpoint 1414912330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212,631.67724
Policy Entropy: 3.65778
Value Function Loss: 0.06818

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.52718
Value Function Update Magnitude: 0.43051

Collected Steps per Second: 22,407.20800
Overall Steps per Second: 10,557.24322

Timestep Collection Time: 2.23250
Timestep Consumption Time: 2.50586
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.73836

Cumulative Model Updates: 169,680
Cumulative Timesteps: 1,414,962,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,934.20282
Policy Entropy: 3.66559
Value Function Loss: 0.06375

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.50810
Value Function Update Magnitude: 0.45148

Collected Steps per Second: 22,494.84789
Overall Steps per Second: 10,688.73404

Timestep Collection Time: 2.22380
Timestep Consumption Time: 2.45627
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.68007

Cumulative Model Updates: 169,686
Cumulative Timesteps: 1,415,012,378

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1415012378...
Checkpoint 1415012378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157,811.55231
Policy Entropy: 3.67164
Value Function Loss: 0.06125

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.49899
Value Function Update Magnitude: 0.61317

Collected Steps per Second: 22,197.17017
Overall Steps per Second: 10,626.86297

Timestep Collection Time: 2.25353
Timestep Consumption Time: 2.45360
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.70713

Cumulative Model Updates: 169,692
Cumulative Timesteps: 1,415,062,400

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,200.32955
Policy Entropy: 3.69129
Value Function Loss: 0.05061

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.50560
Value Function Update Magnitude: 0.67004

Collected Steps per Second: 22,635.56959
Overall Steps per Second: 10,547.11888

Timestep Collection Time: 2.21059
Timestep Consumption Time: 2.53364
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.74423

Cumulative Model Updates: 169,698
Cumulative Timesteps: 1,415,112,438

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1415112438...
Checkpoint 1415112438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,318.33176
Policy Entropy: 3.69647
Value Function Loss: 0.05544

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.55026
Value Function Update Magnitude: 0.61275

Collected Steps per Second: 22,164.51097
Overall Steps per Second: 10,616.12721

Timestep Collection Time: 2.25775
Timestep Consumption Time: 2.45602
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.71377

Cumulative Model Updates: 169,704
Cumulative Timesteps: 1,415,162,480

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,863.36038
Policy Entropy: 3.70839
Value Function Loss: 0.05489

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.57971
Value Function Update Magnitude: 0.75012

Collected Steps per Second: 22,449.40031
Overall Steps per Second: 10,504.62658

Timestep Collection Time: 2.22794
Timestep Consumption Time: 2.53339
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.76133

Cumulative Model Updates: 169,710
Cumulative Timesteps: 1,415,212,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1415212496...
Checkpoint 1415212496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,994.12279
Policy Entropy: 3.70263
Value Function Loss: 0.06069

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.56840
Value Function Update Magnitude: 0.92106

Collected Steps per Second: 22,219.46559
Overall Steps per Second: 10,653.97764

Timestep Collection Time: 2.25154
Timestep Consumption Time: 2.44417
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.69571

Cumulative Model Updates: 169,716
Cumulative Timesteps: 1,415,262,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.06985
Policy Entropy: 3.72077
Value Function Loss: 0.05328

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.59792
Value Function Update Magnitude: 0.92956

Collected Steps per Second: 22,615.66729
Overall Steps per Second: 10,559.40176

Timestep Collection Time: 2.21209
Timestep Consumption Time: 2.52567
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.73777

Cumulative Model Updates: 169,722
Cumulative Timesteps: 1,415,312,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1415312552...
Checkpoint 1415312552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,222.57435
Policy Entropy: 3.71933
Value Function Loss: 0.06392

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.58861
Value Function Update Magnitude: 0.69318

Collected Steps per Second: 22,074.45209
Overall Steps per Second: 10,514.83968

Timestep Collection Time: 2.26570
Timestep Consumption Time: 2.49082
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.75652

Cumulative Model Updates: 169,728
Cumulative Timesteps: 1,415,362,566

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,622.84199
Policy Entropy: 3.73836
Value Function Loss: 0.06447

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.60729
Value Function Update Magnitude: 0.59269

Collected Steps per Second: 22,862.81470
Overall Steps per Second: 10,635.58704

Timestep Collection Time: 2.18704
Timestep Consumption Time: 2.51434
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.70139

Cumulative Model Updates: 169,734
Cumulative Timesteps: 1,415,412,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1415412568...
Checkpoint 1415412568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,426.71533
Policy Entropy: 3.72133
Value Function Loss: 0.06461

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.59228
Value Function Update Magnitude: 0.60329

Collected Steps per Second: 22,549.92589
Overall Steps per Second: 10,547.31169

Timestep Collection Time: 2.21828
Timestep Consumption Time: 2.52435
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.74263

Cumulative Model Updates: 169,740
Cumulative Timesteps: 1,415,462,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,279.35229
Policy Entropy: 3.71651
Value Function Loss: 0.05421

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.58447
Value Function Update Magnitude: 0.70778

Collected Steps per Second: 22,794.78000
Overall Steps per Second: 10,744.95844

Timestep Collection Time: 2.19471
Timestep Consumption Time: 2.46124
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.65595

Cumulative Model Updates: 169,746
Cumulative Timesteps: 1,415,512,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1415512618...
Checkpoint 1415512618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,475.36117
Policy Entropy: 3.68889
Value Function Loss: 0.04793

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13544
Policy Update Magnitude: 0.51838
Value Function Update Magnitude: 0.79251

Collected Steps per Second: 22,263.27307
Overall Steps per Second: 10,670.85630

Timestep Collection Time: 2.24594
Timestep Consumption Time: 2.43991
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.68585

Cumulative Model Updates: 169,752
Cumulative Timesteps: 1,415,562,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,758.88569
Policy Entropy: 3.69538
Value Function Loss: 0.04203

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.46761
Value Function Update Magnitude: 0.62882

Collected Steps per Second: 22,670.88202
Overall Steps per Second: 10,566.40376

Timestep Collection Time: 2.20688
Timestep Consumption Time: 2.52812
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.73501

Cumulative Model Updates: 169,758
Cumulative Timesteps: 1,415,612,652

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1415612652...
Checkpoint 1415612652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,014.50597
Policy Entropy: 3.67555
Value Function Loss: 0.03577

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.46936
Value Function Update Magnitude: 0.62307

Collected Steps per Second: 22,417.68975
Overall Steps per Second: 10,606.65796

Timestep Collection Time: 2.23110
Timestep Consumption Time: 2.48443
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.71553

Cumulative Model Updates: 169,764
Cumulative Timesteps: 1,415,662,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.04057
Policy Entropy: 3.67338
Value Function Loss: 0.02973

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.42572
Value Function Update Magnitude: 0.65150

Collected Steps per Second: 22,855.48897
Overall Steps per Second: 10,648.52979

Timestep Collection Time: 2.18775
Timestep Consumption Time: 2.50793
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.69567

Cumulative Model Updates: 169,770
Cumulative Timesteps: 1,415,712,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1415712670...
Checkpoint 1415712670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.04057
Policy Entropy: 3.64944
Value Function Loss: 0.03220

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.42376
Value Function Update Magnitude: 0.55637

Collected Steps per Second: 22,410.57945
Overall Steps per Second: 10,554.46872

Timestep Collection Time: 2.23207
Timestep Consumption Time: 2.50734
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.73941

Cumulative Model Updates: 169,776
Cumulative Timesteps: 1,415,762,692

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.04057
Policy Entropy: 3.66082
Value Function Loss: 0.03139

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.44541
Value Function Update Magnitude: 0.51621

Collected Steps per Second: 22,927.82222
Overall Steps per Second: 10,810.06615

Timestep Collection Time: 2.18215
Timestep Consumption Time: 2.44613
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.62828

Cumulative Model Updates: 169,782
Cumulative Timesteps: 1,415,812,724

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1415812724...
Checkpoint 1415812724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,715.59754
Policy Entropy: 3.65717
Value Function Loss: 0.03930

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14733
Policy Update Magnitude: 0.43551
Value Function Update Magnitude: 0.50329

Collected Steps per Second: 22,509.79234
Overall Steps per Second: 10,618.89610

Timestep Collection Time: 2.22214
Timestep Consumption Time: 2.48833
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.71047

Cumulative Model Updates: 169,788
Cumulative Timesteps: 1,415,862,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,868.27923
Policy Entropy: 3.67111
Value Function Loss: 0.03855

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14514
Policy Update Magnitude: 0.48722
Value Function Update Magnitude: 0.63463

Collected Steps per Second: 22,311.91685
Overall Steps per Second: 10,494.74379

Timestep Collection Time: 2.24230
Timestep Consumption Time: 2.52485
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.76715

Cumulative Model Updates: 169,794
Cumulative Timesteps: 1,415,912,774

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1415912774...
Checkpoint 1415912774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,905.90682
Policy Entropy: 3.66789
Value Function Loss: 0.03835

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14016
Policy Update Magnitude: 0.49698
Value Function Update Magnitude: 0.73667

Collected Steps per Second: 22,373.64361
Overall Steps per Second: 10,623.73609

Timestep Collection Time: 2.23522
Timestep Consumption Time: 2.47216
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.70738

Cumulative Model Updates: 169,800
Cumulative Timesteps: 1,415,962,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394,033.86888
Policy Entropy: 3.66405
Value Function Loss: 0.03488

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.42817
Value Function Update Magnitude: 0.61738

Collected Steps per Second: 21,984.84923
Overall Steps per Second: 10,645.82440

Timestep Collection Time: 2.27466
Timestep Consumption Time: 2.42277
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.69743

Cumulative Model Updates: 169,806
Cumulative Timesteps: 1,416,012,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1416012792...
Checkpoint 1416012792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394,033.86888
Policy Entropy: 3.66517
Value Function Loss: 0.03351

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.41198
Value Function Update Magnitude: 0.46401

Collected Steps per Second: 20,606.60339
Overall Steps per Second: 10,382.75603

Timestep Collection Time: 2.42835
Timestep Consumption Time: 2.39118
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.81953

Cumulative Model Updates: 169,812
Cumulative Timesteps: 1,416,062,832

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394,033.86888
Policy Entropy: 3.65750
Value Function Loss: 0.02967

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.37982
Value Function Update Magnitude: 0.43770

Collected Steps per Second: 21,832.64855
Overall Steps per Second: 10,532.61966

Timestep Collection Time: 2.29070
Timestep Consumption Time: 2.45760
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.74830

Cumulative Model Updates: 169,818
Cumulative Timesteps: 1,416,112,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1416112844...
Checkpoint 1416112844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394,033.86888
Policy Entropy: 3.65268
Value Function Loss: 0.02621

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.37089
Value Function Update Magnitude: 0.44764

Collected Steps per Second: 21,298.40743
Overall Steps per Second: 10,324.38036

Timestep Collection Time: 2.34844
Timestep Consumption Time: 2.49621
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.84465

Cumulative Model Updates: 169,824
Cumulative Timesteps: 1,416,162,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394,033.86888
Policy Entropy: 3.63689
Value Function Loss: 0.03013

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13670
Policy Update Magnitude: 0.39769
Value Function Update Magnitude: 0.44766

Collected Steps per Second: 22,397.90843
Overall Steps per Second: 10,726.07298

Timestep Collection Time: 2.23235
Timestep Consumption Time: 2.42919
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.66154

Cumulative Model Updates: 169,830
Cumulative Timesteps: 1,416,212,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1416212862...
Checkpoint 1416212862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394,033.86888
Policy Entropy: 3.63972
Value Function Loss: 0.03566

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.43612
Value Function Update Magnitude: 0.43925

Collected Steps per Second: 22,478.59524
Overall Steps per Second: 10,687.56809

Timestep Collection Time: 2.22496
Timestep Consumption Time: 2.45468
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.67964

Cumulative Model Updates: 169,836
Cumulative Timesteps: 1,416,262,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394,033.86888
Policy Entropy: 3.64157
Value Function Loss: 0.03835

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.45344
Value Function Update Magnitude: 0.38491

Collected Steps per Second: 22,349.18922
Overall Steps per Second: 10,491.44718

Timestep Collection Time: 2.23820
Timestep Consumption Time: 2.52968
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.76788

Cumulative Model Updates: 169,842
Cumulative Timesteps: 1,416,312,898

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1416312898...
Checkpoint 1416312898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394,033.86888
Policy Entropy: 3.65679
Value Function Loss: 0.03378

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.40513
Value Function Update Magnitude: 0.38476

Collected Steps per Second: 22,419.28839
Overall Steps per Second: 10,719.15399

Timestep Collection Time: 2.23085
Timestep Consumption Time: 2.43501
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.66585

Cumulative Model Updates: 169,848
Cumulative Timesteps: 1,416,362,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,030.11788
Policy Entropy: 3.66926
Value Function Loss: 0.03381

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.39673
Value Function Update Magnitude: 0.42553

Collected Steps per Second: 22,583.09204
Overall Steps per Second: 10,724.61581

Timestep Collection Time: 2.21520
Timestep Consumption Time: 2.44940
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.66460

Cumulative Model Updates: 169,854
Cumulative Timesteps: 1,416,412,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1416412938...
Checkpoint 1416412938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325,078.44791
Policy Entropy: 3.67342
Value Function Loss: 0.03871

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.41722
Value Function Update Magnitude: 0.42561

Collected Steps per Second: 22,362.37391
Overall Steps per Second: 10,687.39789

Timestep Collection Time: 2.23670
Timestep Consumption Time: 2.44339
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.68009

Cumulative Model Updates: 169,860
Cumulative Timesteps: 1,416,462,956

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,938.79177
Policy Entropy: 3.66332
Value Function Loss: 0.03924

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.44704
Value Function Update Magnitude: 0.48200

Collected Steps per Second: 22,394.10555
Overall Steps per Second: 10,505.42842

Timestep Collection Time: 2.23380
Timestep Consumption Time: 2.52793
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.76173

Cumulative Model Updates: 169,866
Cumulative Timesteps: 1,416,512,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1416512980...
Checkpoint 1416512980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 883,156.49851
Policy Entropy: 3.64465
Value Function Loss: 0.04888

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.48442
Value Function Update Magnitude: 0.54125

Collected Steps per Second: 21,620.01601
Overall Steps per Second: 10,709.89532

Timestep Collection Time: 2.31350
Timestep Consumption Time: 2.35676
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.67026

Cumulative Model Updates: 169,872
Cumulative Timesteps: 1,416,562,998

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,830.30778
Policy Entropy: 3.65613
Value Function Loss: 0.04828

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.51111
Value Function Update Magnitude: 0.67251

Collected Steps per Second: 21,782.66892
Overall Steps per Second: 10,626.50411

Timestep Collection Time: 2.29577
Timestep Consumption Time: 2.41020
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.70597

Cumulative Model Updates: 169,878
Cumulative Timesteps: 1,416,613,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1416613006...
Checkpoint 1416613006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,145.61688
Policy Entropy: 3.66587
Value Function Loss: 0.04958

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.51142
Value Function Update Magnitude: 0.64996

Collected Steps per Second: 22,060.04867
Overall Steps per Second: 10,522.16839

Timestep Collection Time: 2.26745
Timestep Consumption Time: 2.48633
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.75377

Cumulative Model Updates: 169,884
Cumulative Timesteps: 1,416,663,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,145.61688
Policy Entropy: 3.67573
Value Function Loss: 0.04051

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.46717
Value Function Update Magnitude: 0.52023

Collected Steps per Second: 22,512.70689
Overall Steps per Second: 10,734.76360

Timestep Collection Time: 2.22159
Timestep Consumption Time: 2.43748
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.65907

Cumulative Model Updates: 169,890
Cumulative Timesteps: 1,416,713,040

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1416713040...
Checkpoint 1416713040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,145.61688
Policy Entropy: 3.66116
Value Function Loss: 0.03782

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13451
Policy Update Magnitude: 0.43696
Value Function Update Magnitude: 0.41700

Collected Steps per Second: 22,222.32393
Overall Steps per Second: 10,721.69383

Timestep Collection Time: 2.25035
Timestep Consumption Time: 2.41384
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.66419

Cumulative Model Updates: 169,896
Cumulative Timesteps: 1,416,763,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,668.54393
Policy Entropy: 3.66571
Value Function Loss: 0.03634

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.45603
Value Function Update Magnitude: 0.43122

Collected Steps per Second: 22,760.78883
Overall Steps per Second: 10,620.52963

Timestep Collection Time: 2.19711
Timestep Consumption Time: 2.51150
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.70862

Cumulative Model Updates: 169,902
Cumulative Timesteps: 1,416,813,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1416813056...
Checkpoint 1416813056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,406.59622
Policy Entropy: 3.66736
Value Function Loss: 0.03661

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07838
Policy Update Magnitude: 0.54881
Value Function Update Magnitude: 0.48260

Collected Steps per Second: 22,701.08827
Overall Steps per Second: 10,627.37701

Timestep Collection Time: 2.20377
Timestep Consumption Time: 2.50369
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.70746

Cumulative Model Updates: 169,908
Cumulative Timesteps: 1,416,863,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,406.59622
Policy Entropy: 3.66945
Value Function Loss: 0.03139

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08275
Policy Update Magnitude: 0.60189
Value Function Update Magnitude: 0.41266

Collected Steps per Second: 22,828.74268
Overall Steps per Second: 10,787.00808

Timestep Collection Time: 2.19154
Timestep Consumption Time: 2.44645
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.63799

Cumulative Model Updates: 169,914
Cumulative Timesteps: 1,416,913,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1416913114...
Checkpoint 1416913114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,741.63414
Policy Entropy: 3.66938
Value Function Loss: 0.02907

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.53687
Value Function Update Magnitude: 0.36709

Collected Steps per Second: 22,515.61902
Overall Steps per Second: 10,592.17440

Timestep Collection Time: 2.22077
Timestep Consumption Time: 2.49989
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.72065

Cumulative Model Updates: 169,920
Cumulative Timesteps: 1,416,963,116

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147,039.74538
Policy Entropy: 3.66835
Value Function Loss: 0.03442

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.16331
Policy Update Magnitude: 0.55920
Value Function Update Magnitude: 0.42274

Collected Steps per Second: 22,654.56539
Overall Steps per Second: 10,595.02937

Timestep Collection Time: 2.20786
Timestep Consumption Time: 2.51304
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.72089

Cumulative Model Updates: 169,926
Cumulative Timesteps: 1,417,013,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1417013134...
Checkpoint 1417013134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236,429.59347
Policy Entropy: 3.67413
Value Function Loss: 0.04023

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.58444
Value Function Update Magnitude: 0.54673

Collected Steps per Second: 22,264.70283
Overall Steps per Second: 10,482.57550

Timestep Collection Time: 2.24652
Timestep Consumption Time: 2.52502
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.77154

Cumulative Model Updates: 169,932
Cumulative Timesteps: 1,417,063,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236,429.59347
Policy Entropy: 3.65371
Value Function Loss: 0.04667

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.19783
Policy Update Magnitude: 0.63562
Value Function Update Magnitude: 0.66123

Collected Steps per Second: 22,282.82766
Overall Steps per Second: 10,453.36047

Timestep Collection Time: 2.24406
Timestep Consumption Time: 2.53947
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.78353

Cumulative Model Updates: 169,938
Cumulative Timesteps: 1,417,113,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1417113156...
Checkpoint 1417113156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236,429.59347
Policy Entropy: 3.63910
Value Function Loss: 0.04289

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.21766
Policy Update Magnitude: 0.49685
Value Function Update Magnitude: 0.63333

Collected Steps per Second: 22,074.88272
Overall Steps per Second: 10,580.33470

Timestep Collection Time: 2.26556
Timestep Consumption Time: 2.46132
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.72688

Cumulative Model Updates: 169,944
Cumulative Timesteps: 1,417,163,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236,429.59347
Policy Entropy: 3.62477
Value Function Loss: 0.05130

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16724
Policy Update Magnitude: 0.48242
Value Function Update Magnitude: 0.51861

Collected Steps per Second: 22,642.33946
Overall Steps per Second: 10,544.78130

Timestep Collection Time: 2.20861
Timestep Consumption Time: 2.53384
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.74244

Cumulative Model Updates: 169,950
Cumulative Timesteps: 1,417,213,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1417213176...
Checkpoint 1417213176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178,211.90384
Policy Entropy: 3.63966
Value Function Loss: 0.04982

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.15453
Policy Update Magnitude: 0.51169
Value Function Update Magnitude: 0.53216

Collected Steps per Second: 22,295.31354
Overall Steps per Second: 10,658.33810

Timestep Collection Time: 2.24325
Timestep Consumption Time: 2.44922
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.69248

Cumulative Model Updates: 169,956
Cumulative Timesteps: 1,417,263,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,339.28172
Policy Entropy: 3.65189
Value Function Loss: 0.05458

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14570
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.62506

Collected Steps per Second: 22,620.21347
Overall Steps per Second: 10,609.31052

Timestep Collection Time: 2.21103
Timestep Consumption Time: 2.50313
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.71416

Cumulative Model Updates: 169,962
Cumulative Timesteps: 1,417,313,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1417313204...
Checkpoint 1417313204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,776.59774
Policy Entropy: 3.64781
Value Function Loss: 0.05351

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15317
Policy Update Magnitude: 0.54567
Value Function Update Magnitude: 0.47216

Collected Steps per Second: 21,867.83542
Overall Steps per Second: 10,481.28505

Timestep Collection Time: 2.28747
Timestep Consumption Time: 2.48504
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.77251

Cumulative Model Updates: 169,968
Cumulative Timesteps: 1,417,363,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283,202.84265
Policy Entropy: 3.67334
Value Function Loss: 0.06589

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15318
Policy Update Magnitude: 0.56195
Value Function Update Magnitude: 0.44330

Collected Steps per Second: 22,654.72285
Overall Steps per Second: 10,573.56406

Timestep Collection Time: 2.20810
Timestep Consumption Time: 2.52294
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.73104

Cumulative Model Updates: 169,974
Cumulative Timesteps: 1,417,413,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1417413250...
Checkpoint 1417413250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,748.81734
Policy Entropy: 3.71202
Value Function Loss: 0.08090

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.14802
Policy Update Magnitude: 0.68657
Value Function Update Magnitude: 0.56522

Collected Steps per Second: 21,673.92873
Overall Steps per Second: 10,377.79959

Timestep Collection Time: 2.30729
Timestep Consumption Time: 2.51146
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.81875

Cumulative Model Updates: 169,980
Cumulative Timesteps: 1,417,463,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.16352
Policy Entropy: 3.73877
Value Function Loss: 0.09145

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.93903
Value Function Update Magnitude: 0.65964

Collected Steps per Second: 21,856.60647
Overall Steps per Second: 10,381.86553

Timestep Collection Time: 2.28864
Timestep Consumption Time: 2.52956
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.81821

Cumulative Model Updates: 169,986
Cumulative Timesteps: 1,417,513,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1417513280...
Checkpoint 1417513280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214,339.14494
Policy Entropy: 3.75924
Value Function Loss: 0.08923

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.19053
Policy Update Magnitude: 0.82571
Value Function Update Magnitude: 0.66348

Collected Steps per Second: 21,245.82110
Overall Steps per Second: 10,307.00137

Timestep Collection Time: 2.35397
Timestep Consumption Time: 2.49827
PPO Batch Consumption Time: 0.30124
Total Iteration Time: 4.85224

Cumulative Model Updates: 169,992
Cumulative Timesteps: 1,417,563,292

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,175.29016
Policy Entropy: 3.71488
Value Function Loss: 0.08449

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.17698
Policy Update Magnitude: 0.71254
Value Function Update Magnitude: 0.60126

Collected Steps per Second: 21,229.27773
Overall Steps per Second: 10,367.62965

Timestep Collection Time: 2.35599
Timestep Consumption Time: 2.46825
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.82425

Cumulative Model Updates: 169,998
Cumulative Timesteps: 1,417,613,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1417613308...
Checkpoint 1417613308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,237.94732
Policy Entropy: 3.68044
Value Function Loss: 0.08932

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14877
Policy Update Magnitude: 0.84336
Value Function Update Magnitude: 0.59264

Collected Steps per Second: 18,547.33438
Overall Steps per Second: 9,232.45895

Timestep Collection Time: 2.69656
Timestep Consumption Time: 2.72063
PPO Batch Consumption Time: 0.33130
Total Iteration Time: 5.41719

Cumulative Model Updates: 170,004
Cumulative Timesteps: 1,417,663,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,726.94806
Policy Entropy: 3.68403
Value Function Loss: 0.08127

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 1.02719
Value Function Update Magnitude: 0.61902

Collected Steps per Second: 20,482.06961
Overall Steps per Second: 10,145.47066

Timestep Collection Time: 2.44272
Timestep Consumption Time: 2.48874
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.93146

Cumulative Model Updates: 170,010
Cumulative Timesteps: 1,417,713,354

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1417713354...
Checkpoint 1417713354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,085.29440
Policy Entropy: 3.68773
Value Function Loss: 0.07146

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.16165
Policy Update Magnitude: 0.98935
Value Function Update Magnitude: 0.65262

Collected Steps per Second: 20,959.77233
Overall Steps per Second: 10,202.52117

Timestep Collection Time: 2.38600
Timestep Consumption Time: 2.51573
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.90173

Cumulative Model Updates: 170,016
Cumulative Timesteps: 1,417,763,364

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,088.27585
Policy Entropy: 3.68851
Value Function Loss: 0.06355

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.18421
Policy Update Magnitude: 0.71769
Value Function Update Magnitude: 0.52271

Collected Steps per Second: 21,495.85758
Overall Steps per Second: 10,284.19348

Timestep Collection Time: 2.32659
Timestep Consumption Time: 2.53641
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.86300

Cumulative Model Updates: 170,022
Cumulative Timesteps: 1,417,813,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1417813376...
Checkpoint 1417813376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,336.59994
Policy Entropy: 3.66638
Value Function Loss: 0.05689

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16227
Policy Update Magnitude: 0.56617
Value Function Update Magnitude: 0.52159

Collected Steps per Second: 21,496.81409
Overall Steps per Second: 10,221.08177

Timestep Collection Time: 2.32704
Timestep Consumption Time: 2.56716
PPO Batch Consumption Time: 0.30230
Total Iteration Time: 4.89420

Cumulative Model Updates: 170,028
Cumulative Timesteps: 1,417,863,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281,964.41442
Policy Entropy: 3.66983
Value Function Loss: 0.05478

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.16367
Policy Update Magnitude: 0.50117
Value Function Update Magnitude: 0.60707

Collected Steps per Second: 21,892.44888
Overall Steps per Second: 10,361.58433

Timestep Collection Time: 2.28535
Timestep Consumption Time: 2.54325
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.82861

Cumulative Model Updates: 170,034
Cumulative Timesteps: 1,417,913,432

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1417913432...
Checkpoint 1417913432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,302.16727
Policy Entropy: 3.69013
Value Function Loss: 0.04614

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.15186
Policy Update Magnitude: 0.49232
Value Function Update Magnitude: 0.68302

Collected Steps per Second: 19,551.56912
Overall Steps per Second: 9,420.09500

Timestep Collection Time: 2.55734
Timestep Consumption Time: 2.75046
PPO Batch Consumption Time: 0.32659
Total Iteration Time: 5.30780

Cumulative Model Updates: 170,040
Cumulative Timesteps: 1,417,963,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,784.73373
Policy Entropy: 3.68020
Value Function Loss: 0.04271

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.15005
Policy Update Magnitude: 0.50284
Value Function Update Magnitude: 0.65562

Collected Steps per Second: 20,545.88531
Overall Steps per Second: 9,442.30956

Timestep Collection Time: 2.43562
Timestep Consumption Time: 2.86414
PPO Batch Consumption Time: 0.33931
Total Iteration Time: 5.29976

Cumulative Model Updates: 170,046
Cumulative Timesteps: 1,418,013,474

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1418013474...
Checkpoint 1418013474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,034.28460
Policy Entropy: 3.68850
Value Function Loss: 0.04236

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.14931
Policy Update Magnitude: 0.45706
Value Function Update Magnitude: 0.64864

Collected Steps per Second: 20,708.08123
Overall Steps per Second: 10,200.71496

Timestep Collection Time: 2.41510
Timestep Consumption Time: 2.48770
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.90279

Cumulative Model Updates: 170,052
Cumulative Timesteps: 1,418,063,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.19853
Policy Entropy: 3.69582
Value Function Loss: 0.03930

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14254
Policy Update Magnitude: 0.41946
Value Function Update Magnitude: 0.65104

Collected Steps per Second: 22,596.28658
Overall Steps per Second: 10,735.90037

Timestep Collection Time: 2.21311
Timestep Consumption Time: 2.44491
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.65802

Cumulative Model Updates: 170,058
Cumulative Timesteps: 1,418,113,494

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1418113494...
Checkpoint 1418113494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,634.26991
Policy Entropy: 3.69115
Value Function Loss: 0.04459

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.44498
Value Function Update Magnitude: 0.76843

Collected Steps per Second: 20,529.00577
Overall Steps per Second: 9,753.25322

Timestep Collection Time: 2.43704
Timestep Consumption Time: 2.69253
PPO Batch Consumption Time: 0.30789
Total Iteration Time: 5.12957

Cumulative Model Updates: 170,064
Cumulative Timesteps: 1,418,163,524

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,327.43135
Policy Entropy: 3.71029
Value Function Loss: 0.04723

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14354
Policy Update Magnitude: 0.48608
Value Function Update Magnitude: 0.71567

Collected Steps per Second: 18,847.93549
Overall Steps per Second: 9,021.68723

Timestep Collection Time: 2.65334
Timestep Consumption Time: 2.88997
PPO Batch Consumption Time: 0.34348
Total Iteration Time: 5.54331

Cumulative Model Updates: 170,070
Cumulative Timesteps: 1,418,213,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1418213534...
Checkpoint 1418213534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,292.19200
Policy Entropy: 3.68631
Value Function Loss: 0.05869

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.16481
Policy Update Magnitude: 0.53877
Value Function Update Magnitude: 0.59477

Collected Steps per Second: 17,434.21456
Overall Steps per Second: 8,775.68662

Timestep Collection Time: 2.86884
Timestep Consumption Time: 2.83054
PPO Batch Consumption Time: 0.33366
Total Iteration Time: 5.69938

Cumulative Model Updates: 170,076
Cumulative Timesteps: 1,418,263,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,936.59503
Policy Entropy: 3.70598
Value Function Loss: 0.05812

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15998
Policy Update Magnitude: 0.61557
Value Function Update Magnitude: 0.71835

Collected Steps per Second: 19,604.03963
Overall Steps per Second: 9,110.87490

Timestep Collection Time: 2.55131
Timestep Consumption Time: 2.93839
PPO Batch Consumption Time: 0.35132
Total Iteration Time: 5.48970

Cumulative Model Updates: 170,082
Cumulative Timesteps: 1,418,313,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1418313566...
Checkpoint 1418313566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341,673.19988
Policy Entropy: 3.67760
Value Function Loss: 0.06342

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.62618
Value Function Update Magnitude: 0.85604

Collected Steps per Second: 19,197.42597
Overall Steps per Second: 9,621.83776

Timestep Collection Time: 2.60472
Timestep Consumption Time: 2.59220
PPO Batch Consumption Time: 0.30097
Total Iteration Time: 5.19693

Cumulative Model Updates: 170,088
Cumulative Timesteps: 1,418,363,570

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147,094.61896
Policy Entropy: 3.68589
Value Function Loss: 0.05505

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.17319
Policy Update Magnitude: 0.64267
Value Function Update Magnitude: 0.79774

Collected Steps per Second: 19,113.31078
Overall Steps per Second: 9,607.37829

Timestep Collection Time: 2.61765
Timestep Consumption Time: 2.59001
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 5.20766

Cumulative Model Updates: 170,094
Cumulative Timesteps: 1,418,413,602

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1418413602...
Checkpoint 1418413602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147,094.61896
Policy Entropy: 3.67823
Value Function Loss: 0.04131

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.20903
Policy Update Magnitude: 0.56991
Value Function Update Magnitude: 0.71679

Collected Steps per Second: 20,432.20912
Overall Steps per Second: 10,072.59612

Timestep Collection Time: 2.44770
Timestep Consumption Time: 2.51745
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.96515

Cumulative Model Updates: 170,100
Cumulative Timesteps: 1,418,463,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147,094.61896
Policy Entropy: 3.69137
Value Function Loss: 0.02876

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.24520
Policy Update Magnitude: 0.47742
Value Function Update Magnitude: 0.56390

Collected Steps per Second: 20,484.79452
Overall Steps per Second: 10,072.13106

Timestep Collection Time: 2.44220
Timestep Consumption Time: 2.52477
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.96697

Cumulative Model Updates: 170,106
Cumulative Timesteps: 1,418,513,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1418513642...
Checkpoint 1418513642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251,936.43922
Policy Entropy: 3.62875
Value Function Loss: 0.08199

Mean KL Divergence: 0.03302
SB3 Clip Fraction: 0.29724
Policy Update Magnitude: 0.39943
Value Function Update Magnitude: 0.50657

Collected Steps per Second: 20,682.69687
Overall Steps per Second: 10,138.68876

Timestep Collection Time: 2.41854
Timestep Consumption Time: 2.51523
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.93377

Cumulative Model Updates: 170,112
Cumulative Timesteps: 1,418,563,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,116.96958
Policy Entropy: 3.68232
Value Function Loss: 0.15468

Mean KL Divergence: 0.02283
SB3 Clip Fraction: 0.22739
Policy Update Magnitude: 0.53453
Value Function Update Magnitude: 0.45696

Collected Steps per Second: 19,777.03309
Overall Steps per Second: 9,751.30963

Timestep Collection Time: 2.52899
Timestep Consumption Time: 2.60016
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 5.12916

Cumulative Model Updates: 170,118
Cumulative Timesteps: 1,418,613,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1418613680...
Checkpoint 1418613680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,280.47150
Policy Entropy: 3.73757
Value Function Loss: 0.22287

Mean KL Divergence: 0.02446
SB3 Clip Fraction: 0.21333
Policy Update Magnitude: 0.78463
Value Function Update Magnitude: 0.46156

Collected Steps per Second: 20,324.54240
Overall Steps per Second: 10,048.47695

Timestep Collection Time: 2.46047
Timestep Consumption Time: 2.51620
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.97667

Cumulative Model Updates: 170,124
Cumulative Timesteps: 1,418,663,688

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,624.59851
Policy Entropy: 3.85982
Value Function Loss: 0.16225

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.15221
Policy Update Magnitude: 0.96878
Value Function Update Magnitude: 0.54405

Collected Steps per Second: 20,433.08646
Overall Steps per Second: 9,746.25965

Timestep Collection Time: 2.44711
Timestep Consumption Time: 2.68327
PPO Batch Consumption Time: 0.31297
Total Iteration Time: 5.13038

Cumulative Model Updates: 170,130
Cumulative Timesteps: 1,418,713,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1418713690...
Checkpoint 1418713690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.41333
Policy Entropy: 3.91974
Value Function Loss: 0.14254

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.17248
Policy Update Magnitude: 1.02748
Value Function Update Magnitude: 0.62347

Collected Steps per Second: 18,768.82485
Overall Steps per Second: 9,859.04554

Timestep Collection Time: 2.66410
Timestep Consumption Time: 2.40759
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 5.07169

Cumulative Model Updates: 170,136
Cumulative Timesteps: 1,418,763,692

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,665.11670
Policy Entropy: 3.88556
Value Function Loss: 0.12704

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.16877
Policy Update Magnitude: 1.14587
Value Function Update Magnitude: 0.61103

Collected Steps per Second: 19,696.23243
Overall Steps per Second: 9,641.74019

Timestep Collection Time: 2.53866
Timestep Consumption Time: 2.64734
PPO Batch Consumption Time: 0.32430
Total Iteration Time: 5.18599

Cumulative Model Updates: 170,142
Cumulative Timesteps: 1,418,813,694

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1418813694...
Checkpoint 1418813694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,607.04751
Policy Entropy: 3.89549
Value Function Loss: 0.09521

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.20692
Policy Update Magnitude: 1.28796
Value Function Update Magnitude: 0.64118

Collected Steps per Second: 19,807.32836
Overall Steps per Second: 10,019.66979

Timestep Collection Time: 2.52553
Timestep Consumption Time: 2.46705
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.99258

Cumulative Model Updates: 170,148
Cumulative Timesteps: 1,418,863,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.76251
Policy Entropy: 3.88819
Value Function Loss: 0.07898

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.17902
Policy Update Magnitude: 1.50129
Value Function Update Magnitude: 0.71747

Collected Steps per Second: 18,706.44233
Overall Steps per Second: 9,559.36892

Timestep Collection Time: 2.67459
Timestep Consumption Time: 2.55923
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 5.23382

Cumulative Model Updates: 170,154
Cumulative Timesteps: 1,418,913,750

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1418913750...
Checkpoint 1418913750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 860.75366
Policy Entropy: 3.91834
Value Function Loss: 0.06576

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 1.49151
Value Function Update Magnitude: 0.72639

Collected Steps per Second: 19,714.95782
Overall Steps per Second: 9,799.72322

Timestep Collection Time: 2.53787
Timestep Consumption Time: 2.56778
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 5.10565

Cumulative Model Updates: 170,160
Cumulative Timesteps: 1,418,963,784

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.49833
Policy Entropy: 3.89122
Value Function Loss: 0.07293

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 1.43683
Value Function Update Magnitude: 0.67445

Collected Steps per Second: 19,032.09568
Overall Steps per Second: 9,381.41235

Timestep Collection Time: 2.62977
Timestep Consumption Time: 2.70525
PPO Batch Consumption Time: 0.31404
Total Iteration Time: 5.33502

Cumulative Model Updates: 170,166
Cumulative Timesteps: 1,419,013,834

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1419013834...
Checkpoint 1419013834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,057.06248
Policy Entropy: 3.87187
Value Function Loss: 0.07818

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 1.35445
Value Function Update Magnitude: 0.58429

Collected Steps per Second: 20,273.67516
Overall Steps per Second: 9,626.94918

Timestep Collection Time: 2.46763
Timestep Consumption Time: 2.72903
PPO Batch Consumption Time: 0.33036
Total Iteration Time: 5.19666

Cumulative Model Updates: 170,172
Cumulative Timesteps: 1,419,063,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,469.61807
Policy Entropy: 3.85589
Value Function Loss: 0.07926

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 1.15584
Value Function Update Magnitude: 0.60982

Collected Steps per Second: 19,253.96451
Overall Steps per Second: 9,922.23410

Timestep Collection Time: 2.59718
Timestep Consumption Time: 2.44261
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 5.03979

Cumulative Model Updates: 170,178
Cumulative Timesteps: 1,419,113,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1419113868...
Checkpoint 1419113868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.44266
Policy Entropy: 3.88234
Value Function Loss: 0.07079

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11123
Policy Update Magnitude: 1.04174
Value Function Update Magnitude: 0.73784

Collected Steps per Second: 20,314.05213
Overall Steps per Second: 10,281.17496

Timestep Collection Time: 2.46174
Timestep Consumption Time: 2.40229
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.86404

Cumulative Model Updates: 170,184
Cumulative Timesteps: 1,419,163,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.71309
Policy Entropy: 3.88843
Value Function Loss: 0.07235

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 1.17880
Value Function Update Magnitude: 0.82212

Collected Steps per Second: 22,234.96116
Overall Steps per Second: 10,538.90328

Timestep Collection Time: 2.24997
Timestep Consumption Time: 2.49701
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.74698

Cumulative Model Updates: 170,190
Cumulative Timesteps: 1,419,213,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1419213904...
Checkpoint 1419213904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,948.09260
Policy Entropy: 3.90443
Value Function Loss: 0.09467

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11148
Policy Update Magnitude: 1.19145
Value Function Update Magnitude: 0.65814

Collected Steps per Second: 22,397.53170
Overall Steps per Second: 10,701.06227

Timestep Collection Time: 2.23337
Timestep Consumption Time: 2.44112
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.67449

Cumulative Model Updates: 170,196
Cumulative Timesteps: 1,419,263,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,387.59072
Policy Entropy: 3.86327
Value Function Loss: 0.10079

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12127
Policy Update Magnitude: 1.04442
Value Function Update Magnitude: 0.49683

Collected Steps per Second: 22,781.53933
Overall Steps per Second: 10,768.23135

Timestep Collection Time: 2.19573
Timestep Consumption Time: 2.44961
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.64533

Cumulative Model Updates: 170,202
Cumulative Timesteps: 1,419,313,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1419313948...
Checkpoint 1419313948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,251.87112
Policy Entropy: 3.87094
Value Function Loss: 0.10341

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.91045
Value Function Update Magnitude: 0.51690

Collected Steps per Second: 22,274.90258
Overall Steps per Second: 10,659.75032

Timestep Collection Time: 2.24558
Timestep Consumption Time: 2.44684
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.69242

Cumulative Model Updates: 170,208
Cumulative Timesteps: 1,419,363,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.84972
Policy Entropy: 3.83409
Value Function Loss: 0.10876

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.90046
Value Function Update Magnitude: 0.48091

Collected Steps per Second: 22,625.30452
Overall Steps per Second: 10,513.85333

Timestep Collection Time: 2.21009
Timestep Consumption Time: 2.54592
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.75601

Cumulative Model Updates: 170,214
Cumulative Timesteps: 1,419,413,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1419413972...
Checkpoint 1419413972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,727.15712
Policy Entropy: 3.80710
Value Function Loss: 0.11393

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.15442
Policy Update Magnitude: 0.70691
Value Function Update Magnitude: 0.34902

Collected Steps per Second: 22,524.61207
Overall Steps per Second: 10,651.61043

Timestep Collection Time: 2.22148
Timestep Consumption Time: 2.47621
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.69769

Cumulative Model Updates: 170,220
Cumulative Timesteps: 1,419,464,010

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.59559
Policy Entropy: 3.79061
Value Function Loss: 0.10863

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.48647
Value Function Update Magnitude: 0.28635

Collected Steps per Second: 22,686.05340
Overall Steps per Second: 10,598.54838

Timestep Collection Time: 2.20417
Timestep Consumption Time: 2.51383
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.71800

Cumulative Model Updates: 170,226
Cumulative Timesteps: 1,419,514,014

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1419514014...
Checkpoint 1419514014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 969.89449
Policy Entropy: 3.78865
Value Function Loss: 0.10374

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.39463
Value Function Update Magnitude: 0.28250

Collected Steps per Second: 22,652.65899
Overall Steps per Second: 10,625.20739

Timestep Collection Time: 2.20725
Timestep Consumption Time: 2.49854
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.70579

Cumulative Model Updates: 170,232
Cumulative Timesteps: 1,419,564,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.08947
Policy Entropy: 3.77152
Value Function Loss: 0.08602

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16227
Policy Update Magnitude: 0.42220
Value Function Update Magnitude: 0.32943

Collected Steps per Second: 22,762.72440
Overall Steps per Second: 10,738.61749

Timestep Collection Time: 2.19710
Timestep Consumption Time: 2.46011
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.65721

Cumulative Model Updates: 170,238
Cumulative Timesteps: 1,419,614,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1419614026...
Checkpoint 1419614026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,058.78591
Policy Entropy: 3.73422
Value Function Loss: 0.07986

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16424
Policy Update Magnitude: 0.37165
Value Function Update Magnitude: 0.40157

Collected Steps per Second: 22,573.42967
Overall Steps per Second: 10,679.38756

Timestep Collection Time: 2.21508
Timestep Consumption Time: 2.46702
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.68210

Cumulative Model Updates: 170,244
Cumulative Timesteps: 1,419,664,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,058.78591
Policy Entropy: 3.72607
Value Function Loss: 0.05905

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.16973
Policy Update Magnitude: 0.43538
Value Function Update Magnitude: 0.44637

Collected Steps per Second: 21,980.16756
Overall Steps per Second: 10,632.58886

Timestep Collection Time: 2.27505
Timestep Consumption Time: 2.42804
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.70309

Cumulative Model Updates: 170,250
Cumulative Timesteps: 1,419,714,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1419714034...
Checkpoint 1419714034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,058.78591
Policy Entropy: 3.69880
Value Function Loss: 0.04810

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.21385
Policy Update Magnitude: 0.34740
Value Function Update Magnitude: 0.40282

Collected Steps per Second: 21,688.38591
Overall Steps per Second: 10,557.05129

Timestep Collection Time: 2.30640
Timestep Consumption Time: 2.43186
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.73825

Cumulative Model Updates: 170,256
Cumulative Timesteps: 1,419,764,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,424.07012
Policy Entropy: 3.66847
Value Function Loss: 0.04648

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.19451
Policy Update Magnitude: 0.32144
Value Function Update Magnitude: 0.40242

Collected Steps per Second: 22,301.60422
Overall Steps per Second: 10,514.27765

Timestep Collection Time: 2.24235
Timestep Consumption Time: 2.51385
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.75620

Cumulative Model Updates: 170,262
Cumulative Timesteps: 1,419,814,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1419814064...
Checkpoint 1419814064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,427.12830
Policy Entropy: 3.64690
Value Function Loss: 0.09646

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.14724
Policy Update Magnitude: 0.49495
Value Function Update Magnitude: 0.41962

Collected Steps per Second: 21,927.50415
Overall Steps per Second: 10,637.96600

Timestep Collection Time: 2.28143
Timestep Consumption Time: 2.42116
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.70259

Cumulative Model Updates: 170,268
Cumulative Timesteps: 1,419,864,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,165.98935
Policy Entropy: 3.72993
Value Function Loss: 0.11879

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.69116
Value Function Update Magnitude: 0.48402

Collected Steps per Second: 22,019.45119
Overall Steps per Second: 10,776.28535

Timestep Collection Time: 2.27126
Timestep Consumption Time: 2.36967
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.64093

Cumulative Model Updates: 170,274
Cumulative Timesteps: 1,419,914,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1419914102...
Checkpoint 1419914102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,398.06823
Policy Entropy: 3.78297
Value Function Loss: 0.15059

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.14979
Policy Update Magnitude: 0.80835
Value Function Update Magnitude: 0.49785

Collected Steps per Second: 21,198.02768
Overall Steps per Second: 10,572.35247

Timestep Collection Time: 2.35909
Timestep Consumption Time: 2.37099
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.73007

Cumulative Model Updates: 170,280
Cumulative Timesteps: 1,419,964,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,356.19257
Policy Entropy: 3.83658
Value Function Loss: 0.13661

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.95441
Value Function Update Magnitude: 0.39199

Collected Steps per Second: 22,254.37435
Overall Steps per Second: 10,504.11720

Timestep Collection Time: 2.24765
Timestep Consumption Time: 2.51429
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.76194

Cumulative Model Updates: 170,286
Cumulative Timesteps: 1,420,014,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1420014130...
Checkpoint 1420014130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.80321
Policy Entropy: 3.82106
Value Function Loss: 0.11756

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.13795
Policy Update Magnitude: 1.00006
Value Function Update Magnitude: 0.36196

Collected Steps per Second: 22,247.55628
Overall Steps per Second: 10,641.07354

Timestep Collection Time: 2.24915
Timestep Consumption Time: 2.45320
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.70235

Cumulative Model Updates: 170,292
Cumulative Timesteps: 1,420,064,168

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,632.00137
Policy Entropy: 3.81762
Value Function Loss: 0.09363

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.17297
Policy Update Magnitude: 0.84825
Value Function Update Magnitude: 0.36904

Collected Steps per Second: 21,816.21542
Overall Steps per Second: 10,548.83810

Timestep Collection Time: 2.29196
Timestep Consumption Time: 2.44808
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.74005

Cumulative Model Updates: 170,298
Cumulative Timesteps: 1,420,114,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1420114170...
Checkpoint 1420114170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,970.48761
Policy Entropy: 3.80201
Value Function Loss: 0.10027

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.16132
Policy Update Magnitude: 0.66185
Value Function Update Magnitude: 0.37111

Collected Steps per Second: 21,259.61565
Overall Steps per Second: 10,551.95377

Timestep Collection Time: 2.35244
Timestep Consumption Time: 2.38715
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.73960

Cumulative Model Updates: 170,304
Cumulative Timesteps: 1,420,164,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.28000
Policy Entropy: 3.79231
Value Function Loss: 0.11069

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.15209
Policy Update Magnitude: 0.61575
Value Function Update Magnitude: 0.34238

Collected Steps per Second: 22,037.53422
Overall Steps per Second: 10,694.64742

Timestep Collection Time: 2.26940
Timestep Consumption Time: 2.40696
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.67636

Cumulative Model Updates: 170,310
Cumulative Timesteps: 1,420,214,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1420214194...
Checkpoint 1420214194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,856.78995
Policy Entropy: 3.79100
Value Function Loss: 0.10808

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.59175
Value Function Update Magnitude: 0.31356

Collected Steps per Second: 21,534.10145
Overall Steps per Second: 10,545.52886

Timestep Collection Time: 2.32190
Timestep Consumption Time: 2.41945
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.74135

Cumulative Model Updates: 170,316
Cumulative Timesteps: 1,420,264,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.16966
Policy Entropy: 3.77505
Value Function Loss: 0.08310

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.54142
Value Function Update Magnitude: 0.32952

Collected Steps per Second: 22,324.03225
Overall Steps per Second: 10,762.37421

Timestep Collection Time: 2.24099
Timestep Consumption Time: 2.40742
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.64842

Cumulative Model Updates: 170,322
Cumulative Timesteps: 1,420,314,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1420314222...
Checkpoint 1420314222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.51152
Policy Entropy: 3.72518
Value Function Loss: 0.05887

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11509
Policy Update Magnitude: 0.51710
Value Function Update Magnitude: 0.38209

Collected Steps per Second: 21,808.88411
Overall Steps per Second: 10,618.41052

Timestep Collection Time: 2.29319
Timestep Consumption Time: 2.41674
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.70993

Cumulative Model Updates: 170,328
Cumulative Timesteps: 1,420,364,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.34224
Policy Entropy: 3.69818
Value Function Loss: 0.04584

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.15787
Policy Update Magnitude: 0.41468
Value Function Update Magnitude: 0.37399

Collected Steps per Second: 21,867.19249
Overall Steps per Second: 10,459.31508

Timestep Collection Time: 2.28790
Timestep Consumption Time: 2.49539
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.78330

Cumulative Model Updates: 170,334
Cumulative Timesteps: 1,420,414,264

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1420414264...
Checkpoint 1420414264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117.34224
Policy Entropy: 3.66515
Value Function Loss: 0.03753

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.19671
Policy Update Magnitude: 0.34191
Value Function Update Magnitude: 0.33278

Collected Steps per Second: 22,384.13758
Overall Steps per Second: 10,646.23430

Timestep Collection Time: 2.23417
Timestep Consumption Time: 2.46326
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.69744

Cumulative Model Updates: 170,340
Cumulative Timesteps: 1,420,464,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.34224
Policy Entropy: 3.64027
Value Function Loss: 0.03913

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.20034
Policy Update Magnitude: 0.30864
Value Function Update Magnitude: 0.37781

Collected Steps per Second: 22,881.20591
Overall Steps per Second: 10,653.77122

Timestep Collection Time: 2.18616
Timestep Consumption Time: 2.50908
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.69524

Cumulative Model Updates: 170,346
Cumulative Timesteps: 1,420,514,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1420514296...
Checkpoint 1420514296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117.34224
Policy Entropy: 3.63445
Value Function Loss: 0.03356

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.18266
Policy Update Magnitude: 0.34748
Value Function Update Magnitude: 0.45376

Collected Steps per Second: 22,514.87082
Overall Steps per Second: 10,578.65756

Timestep Collection Time: 2.22084
Timestep Consumption Time: 2.50584
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.72669

Cumulative Model Updates: 170,352
Cumulative Timesteps: 1,420,564,298

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,734.73513
Policy Entropy: 3.62552
Value Function Loss: 0.05248

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14454
Policy Update Magnitude: 0.30549
Value Function Update Magnitude: 0.38569

Collected Steps per Second: 22,623.35079
Overall Steps per Second: 10,701.74153

Timestep Collection Time: 2.21108
Timestep Consumption Time: 2.46311
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.67419

Cumulative Model Updates: 170,358
Cumulative Timesteps: 1,420,614,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1420614320...
Checkpoint 1420614320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,619.32857
Policy Entropy: 3.64458
Value Function Loss: 0.05318

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13879
Policy Update Magnitude: 0.32584
Value Function Update Magnitude: 0.30350

Collected Steps per Second: 22,446.50673
Overall Steps per Second: 10,676.35620

Timestep Collection Time: 2.22761
Timestep Consumption Time: 2.45583
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.68343

Cumulative Model Updates: 170,364
Cumulative Timesteps: 1,420,664,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,708.16949
Policy Entropy: 3.64156
Value Function Loss: 0.05837

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.32665
Value Function Update Magnitude: 0.33948

Collected Steps per Second: 22,358.50228
Overall Steps per Second: 10,475.74949

Timestep Collection Time: 2.23638
Timestep Consumption Time: 2.53674
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.77312

Cumulative Model Updates: 170,370
Cumulative Timesteps: 1,420,714,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1420714324...
Checkpoint 1420714324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,130.83906
Policy Entropy: 3.65188
Value Function Loss: 0.05419

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.32919
Value Function Update Magnitude: 0.44245

Collected Steps per Second: 22,140.89261
Overall Steps per Second: 10,592.73810

Timestep Collection Time: 2.25953
Timestep Consumption Time: 2.46333
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.72286

Cumulative Model Updates: 170,376
Cumulative Timesteps: 1,420,764,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,130.83906
Policy Entropy: 3.64123
Value Function Loss: 0.04694

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.33140
Value Function Update Magnitude: 0.50284

Collected Steps per Second: 21,674.49212
Overall Steps per Second: 10,500.28096

Timestep Collection Time: 2.30732
Timestep Consumption Time: 2.45541
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.76273

Cumulative Model Updates: 170,382
Cumulative Timesteps: 1,420,814,362

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1420814362...
Checkpoint 1420814362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,979.22923
Policy Entropy: 3.65166
Value Function Loss: 0.04252

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.30600
Value Function Update Magnitude: 0.52185

Collected Steps per Second: 21,719.02840
Overall Steps per Second: 10,717.07475

Timestep Collection Time: 2.30314
Timestep Consumption Time: 2.36436
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.66750

Cumulative Model Updates: 170,388
Cumulative Timesteps: 1,420,864,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,698.54643
Policy Entropy: 3.65668
Value Function Loss: 0.03885

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13930
Policy Update Magnitude: 0.29001
Value Function Update Magnitude: 0.52545

Collected Steps per Second: 21,941.11275
Overall Steps per Second: 10,772.48363

Timestep Collection Time: 2.27901
Timestep Consumption Time: 2.36282
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.64183

Cumulative Model Updates: 170,394
Cumulative Timesteps: 1,420,914,388

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1420914388...
Checkpoint 1420914388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,970.03601
Policy Entropy: 3.65566
Value Function Loss: 0.03849

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13209
Policy Update Magnitude: 0.28912
Value Function Update Magnitude: 0.55544

Collected Steps per Second: 21,563.94231
Overall Steps per Second: 10,375.06806

Timestep Collection Time: 2.31989
Timestep Consumption Time: 2.50186
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.82175

Cumulative Model Updates: 170,400
Cumulative Timesteps: 1,420,964,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,466.15553
Policy Entropy: 3.65105
Value Function Loss: 0.04794

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.31136
Value Function Update Magnitude: 0.59775

Collected Steps per Second: 22,653.85319
Overall Steps per Second: 10,762.55220

Timestep Collection Time: 2.20739
Timestep Consumption Time: 2.43890
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.64630

Cumulative Model Updates: 170,406
Cumulative Timesteps: 1,421,014,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1421014420...
Checkpoint 1421014420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,161.00686
Policy Entropy: 3.64155
Value Function Loss: 0.04618

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.38311
Value Function Update Magnitude: 0.64520

Collected Steps per Second: 22,309.81525
Overall Steps per Second: 10,669.87992

Timestep Collection Time: 2.24188
Timestep Consumption Time: 2.44570
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.68759

Cumulative Model Updates: 170,412
Cumulative Timesteps: 1,421,064,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,392.19516
Policy Entropy: 3.62821
Value Function Loss: 0.05119

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.14800
Policy Update Magnitude: 0.41120
Value Function Update Magnitude: 0.60381

Collected Steps per Second: 22,735.18307
Overall Steps per Second: 10,609.58398

Timestep Collection Time: 2.19994
Timestep Consumption Time: 2.51429
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.71423

Cumulative Model Updates: 170,418
Cumulative Timesteps: 1,421,114,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1421114452...
Checkpoint 1421114452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,825.53801
Policy Entropy: 3.62388
Value Function Loss: 0.04229

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.40104
Value Function Update Magnitude: 0.48960

Collected Steps per Second: 22,508.14871
Overall Steps per Second: 10,545.01652

Timestep Collection Time: 2.22204
Timestep Consumption Time: 2.52086
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.74290

Cumulative Model Updates: 170,424
Cumulative Timesteps: 1,421,164,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,825.53801
Policy Entropy: 3.60884
Value Function Loss: 0.03703

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14768
Policy Update Magnitude: 0.38259
Value Function Update Magnitude: 0.48653

Collected Steps per Second: 22,688.58972
Overall Steps per Second: 10,764.65848

Timestep Collection Time: 2.20499
Timestep Consumption Time: 2.44245
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.64743

Cumulative Model Updates: 170,430
Cumulative Timesteps: 1,421,214,494

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1421214494...
Checkpoint 1421214494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,825.53801
Policy Entropy: 3.61244
Value Function Loss: 0.03239

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.34057
Value Function Update Magnitude: 0.48514

Collected Steps per Second: 22,382.82279
Overall Steps per Second: 10,662.54241

Timestep Collection Time: 2.23457
Timestep Consumption Time: 2.45624
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.69081

Cumulative Model Updates: 170,436
Cumulative Timesteps: 1,421,264,510

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,825.53801
Policy Entropy: 3.61181
Value Function Loss: 0.02867

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.30134
Value Function Update Magnitude: 0.39743

Collected Steps per Second: 22,861.22221
Overall Steps per Second: 10,611.28856

Timestep Collection Time: 2.18746
Timestep Consumption Time: 2.52526
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.71272

Cumulative Model Updates: 170,442
Cumulative Timesteps: 1,421,314,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1421314518...
Checkpoint 1421314518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,825.53801
Policy Entropy: 3.61969
Value Function Loss: 0.02648

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.27070
Value Function Update Magnitude: 0.39734

Collected Steps per Second: 22,047.06218
Overall Steps per Second: 10,572.56175

Timestep Collection Time: 2.26815
Timestep Consumption Time: 2.46164
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.72979

Cumulative Model Updates: 170,448
Cumulative Timesteps: 1,421,364,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,825.53801
Policy Entropy: 3.62549
Value Function Loss: 0.02783

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.26821
Value Function Update Magnitude: 0.47603

Collected Steps per Second: 21,837.69265
Overall Steps per Second: 10,579.38793

Timestep Collection Time: 2.29072
Timestep Consumption Time: 2.43772
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.72844

Cumulative Model Updates: 170,454
Cumulative Timesteps: 1,421,414,548

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1421414548...
Checkpoint 1421414548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,825.53801
Policy Entropy: 3.62068
Value Function Loss: 0.02874

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.27364
Value Function Update Magnitude: 0.45733

Collected Steps per Second: 21,724.84722
Overall Steps per Second: 10,530.99080

Timestep Collection Time: 2.30188
Timestep Consumption Time: 2.44677
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.74865

Cumulative Model Updates: 170,460
Cumulative Timesteps: 1,421,464,556

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,825.53801
Policy Entropy: 3.63304
Value Function Loss: 0.02740

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.26712
Value Function Update Magnitude: 0.39118

Collected Steps per Second: 22,376.85673
Overall Steps per Second: 10,625.63931

Timestep Collection Time: 2.23588
Timestep Consumption Time: 2.47273
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.70861

Cumulative Model Updates: 170,466
Cumulative Timesteps: 1,421,514,588

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1421514588...
Checkpoint 1421514588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,825.53801
Policy Entropy: 3.63874
Value Function Loss: 0.02507

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.23406
Value Function Update Magnitude: 0.30759

Collected Steps per Second: 22,475.84355
Overall Steps per Second: 10,637.81478

Timestep Collection Time: 2.22523
Timestep Consumption Time: 2.47630
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.70153

Cumulative Model Updates: 170,472
Cumulative Timesteps: 1,421,564,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,825.53801
Policy Entropy: 3.64510
Value Function Loss: 0.02472

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.23015
Value Function Update Magnitude: 0.27023

Collected Steps per Second: 22,857.32149
Overall Steps per Second: 10,728.10963

Timestep Collection Time: 2.18801
Timestep Consumption Time: 2.47376
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.66177

Cumulative Model Updates: 170,478
Cumulative Timesteps: 1,421,614,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1421614614...
Checkpoint 1421614614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,825.53801
Policy Entropy: 3.63930
Value Function Loss: 0.02680

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.27633
Value Function Update Magnitude: 0.44740

Collected Steps per Second: 22,532.21804
Overall Steps per Second: 10,618.44829

Timestep Collection Time: 2.21984
Timestep Consumption Time: 2.49064
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.71048

Cumulative Model Updates: 170,484
Cumulative Timesteps: 1,421,664,632

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,171.34624
Policy Entropy: 3.63627
Value Function Loss: 0.03745

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.30545
Value Function Update Magnitude: 0.57593

Collected Steps per Second: 22,691.96338
Overall Steps per Second: 10,605.06586

Timestep Collection Time: 2.20351
Timestep Consumption Time: 2.51141
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.71492

Cumulative Model Updates: 170,490
Cumulative Timesteps: 1,421,714,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1421714634...
Checkpoint 1421714634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.64439
Value Function Loss: 0.03710

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.33438
Value Function Update Magnitude: 0.49161

Collected Steps per Second: 22,159.02815
Overall Steps per Second: 10,499.85820

Timestep Collection Time: 2.25714
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.76349

Cumulative Model Updates: 170,496
Cumulative Timesteps: 1,421,764,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.64431
Value Function Loss: 0.03805

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.33989
Value Function Update Magnitude: 0.42536

Collected Steps per Second: 22,851.97238
Overall Steps per Second: 10,800.15257

Timestep Collection Time: 2.18913
Timestep Consumption Time: 2.44284
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.63197

Cumulative Model Updates: 170,502
Cumulative Timesteps: 1,421,814,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1421814676...
Checkpoint 1421814676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.65309
Value Function Loss: 0.02882

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.33864
Value Function Update Magnitude: 0.36720

Collected Steps per Second: 22,461.29722
Overall Steps per Second: 10,685.43860

Timestep Collection Time: 2.22667
Timestep Consumption Time: 2.45390
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.68058

Cumulative Model Updates: 170,508
Cumulative Timesteps: 1,421,864,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.64228
Value Function Loss: 0.02908

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.31252
Value Function Update Magnitude: 0.34631

Collected Steps per Second: 21,862.78481
Overall Steps per Second: 10,586.93084

Timestep Collection Time: 2.28727
Timestep Consumption Time: 2.43610
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.72337

Cumulative Model Updates: 170,514
Cumulative Timesteps: 1,421,914,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1421914696...
Checkpoint 1421914696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.65022
Value Function Loss: 0.02671

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.29337
Value Function Update Magnitude: 0.37005

Collected Steps per Second: 21,569.96583
Overall Steps per Second: 10,576.25845

Timestep Collection Time: 2.31813
Timestep Consumption Time: 2.40963
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.72776

Cumulative Model Updates: 170,520
Cumulative Timesteps: 1,421,964,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.64988
Value Function Loss: 0.02686

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.26848
Value Function Update Magnitude: 0.33674

Collected Steps per Second: 22,316.41197
Overall Steps per Second: 10,526.46289

Timestep Collection Time: 2.24122
Timestep Consumption Time: 2.51023
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.75145

Cumulative Model Updates: 170,526
Cumulative Timesteps: 1,422,014,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1422014714...
Checkpoint 1422014714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.65646
Value Function Loss: 0.02709

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.26754
Value Function Update Magnitude: 0.29166

Collected Steps per Second: 22,476.46034
Overall Steps per Second: 10,537.85513

Timestep Collection Time: 2.22535
Timestep Consumption Time: 2.52116
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.74651

Cumulative Model Updates: 170,532
Cumulative Timesteps: 1,422,064,732

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.65670
Value Function Loss: 0.02951

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.26521
Value Function Update Magnitude: 0.29458

Collected Steps per Second: 22,679.22842
Overall Steps per Second: 10,714.62357

Timestep Collection Time: 2.20493
Timestep Consumption Time: 2.46215
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.66708

Cumulative Model Updates: 170,538
Cumulative Timesteps: 1,422,114,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1422114738...
Checkpoint 1422114738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.65835
Value Function Loss: 0.02755

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.24686
Value Function Update Magnitude: 0.25429

Collected Steps per Second: 22,112.09892
Overall Steps per Second: 10,474.27946

Timestep Collection Time: 2.26193
Timestep Consumption Time: 2.51320
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.77513

Cumulative Model Updates: 170,544
Cumulative Timesteps: 1,422,164,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.65559
Value Function Loss: 0.02379

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.22438
Value Function Update Magnitude: 0.21115

Collected Steps per Second: 23,004.69365
Overall Steps per Second: 10,805.30279

Timestep Collection Time: 2.17347
Timestep Consumption Time: 2.45389
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.62736

Cumulative Model Updates: 170,550
Cumulative Timesteps: 1,422,214,754

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1422214754...
Checkpoint 1422214754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.65142
Value Function Loss: 0.02145

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.21520
Value Function Update Magnitude: 0.21414

Collected Steps per Second: 22,481.09406
Overall Steps per Second: 10,631.26969

Timestep Collection Time: 2.22445
Timestep Consumption Time: 2.47941
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.70386

Cumulative Model Updates: 170,556
Cumulative Timesteps: 1,422,264,762

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.65461
Value Function Loss: 0.02246

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.22194
Value Function Update Magnitude: 0.22505

Collected Steps per Second: 22,555.48717
Overall Steps per Second: 10,548.70389

Timestep Collection Time: 2.21702
Timestep Consumption Time: 2.52347
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.74049

Cumulative Model Updates: 170,562
Cumulative Timesteps: 1,422,314,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1422314768...
Checkpoint 1422314768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.65438
Value Function Loss: 0.02429

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.27270
Value Function Update Magnitude: 0.28522

Collected Steps per Second: 22,302.75375
Overall Steps per Second: 10,581.87113

Timestep Collection Time: 2.24304
Timestep Consumption Time: 2.48448
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.72752

Cumulative Model Updates: 170,568
Cumulative Timesteps: 1,422,364,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.64530
Value Function Loss: 0.02830

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12525
Policy Update Magnitude: 0.33345
Value Function Update Magnitude: 0.43481

Collected Steps per Second: 22,562.21812
Overall Steps per Second: 10,557.03552

Timestep Collection Time: 2.21636
Timestep Consumption Time: 2.52039
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.73675

Cumulative Model Updates: 170,574
Cumulative Timesteps: 1,422,414,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1422414800...
Checkpoint 1422414800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.65308
Value Function Loss: 0.02735

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.35492
Value Function Update Magnitude: 0.38472

Collected Steps per Second: 22,523.15446
Overall Steps per Second: 10,557.60672

Timestep Collection Time: 2.22038
Timestep Consumption Time: 2.51649
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.73687

Cumulative Model Updates: 170,580
Cumulative Timesteps: 1,422,464,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,801.43654
Policy Entropy: 3.64321
Value Function Loss: 0.02928

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.33682
Value Function Update Magnitude: 0.29893

Collected Steps per Second: 22,697.26055
Overall Steps per Second: 10,653.65391

Timestep Collection Time: 2.20388
Timestep Consumption Time: 2.49141
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.69529

Cumulative Model Updates: 170,586
Cumulative Timesteps: 1,422,514,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1422514832...
Checkpoint 1422514832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170,966.90526
Policy Entropy: 3.66384
Value Function Loss: 0.02943

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11904
Policy Update Magnitude: 0.33957
Value Function Update Magnitude: 0.34235

Collected Steps per Second: 22,013.25461
Overall Steps per Second: 10,398.14907

Timestep Collection Time: 2.27199
Timestep Consumption Time: 2.53790
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.80989

Cumulative Model Updates: 170,592
Cumulative Timesteps: 1,422,564,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175,443.78724
Policy Entropy: 3.66832
Value Function Loss: 0.03726

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.36015
Value Function Update Magnitude: 0.55789

Collected Steps per Second: 22,204.91503
Overall Steps per Second: 10,670.67160

Timestep Collection Time: 2.25211
Timestep Consumption Time: 2.43438
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.68649

Cumulative Model Updates: 170,598
Cumulative Timesteps: 1,422,614,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1422614854...
Checkpoint 1422614854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,540.98669
Policy Entropy: 3.68287
Value Function Loss: 0.03741

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.38971
Value Function Update Magnitude: 0.70100

Collected Steps per Second: 21,129.27861
Overall Steps per Second: 10,492.39855

Timestep Collection Time: 2.36686
Timestep Consumption Time: 2.39945
PPO Batch Consumption Time: 0.29547
Total Iteration Time: 4.76631

Cumulative Model Updates: 170,604
Cumulative Timesteps: 1,422,664,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,540.98669
Policy Entropy: 3.67437
Value Function Loss: 0.03583

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.37590
Value Function Update Magnitude: 0.63425

Collected Steps per Second: 21,852.41004
Overall Steps per Second: 10,703.52631

Timestep Collection Time: 2.29027
Timestep Consumption Time: 2.38557
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.67584

Cumulative Model Updates: 170,610
Cumulative Timesteps: 1,422,714,912

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1422714912...
Checkpoint 1422714912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,540.98669
Policy Entropy: 3.66418
Value Function Loss: 0.02853

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.33278
Value Function Update Magnitude: 0.45530

Collected Steps per Second: 21,614.31184
Overall Steps per Second: 10,403.78989

Timestep Collection Time: 2.31337
Timestep Consumption Time: 2.49276
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.80613

Cumulative Model Updates: 170,616
Cumulative Timesteps: 1,422,764,914

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,540.98669
Policy Entropy: 3.66801
Value Function Loss: 0.02271

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.27910
Value Function Update Magnitude: 0.34759

Collected Steps per Second: 22,577.18963
Overall Steps per Second: 10,787.23827

Timestep Collection Time: 2.21533
Timestep Consumption Time: 2.42126
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.63659

Cumulative Model Updates: 170,622
Cumulative Timesteps: 1,422,814,930

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1422814930...
Checkpoint 1422814930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,540.98669
Policy Entropy: 3.65907
Value Function Loss: 0.02311

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.23957
Value Function Update Magnitude: 0.27124

Collected Steps per Second: 22,267.44482
Overall Steps per Second: 10,643.34943

Timestep Collection Time: 2.24642
Timestep Consumption Time: 2.45342
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.69984

Cumulative Model Updates: 170,628
Cumulative Timesteps: 1,422,864,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,025.57301
Policy Entropy: 3.65675
Value Function Loss: 0.02879

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13272
Policy Update Magnitude: 0.27606
Value Function Update Magnitude: 0.33643

Collected Steps per Second: 22,749.58236
Overall Steps per Second: 10,581.09415

Timestep Collection Time: 2.19819
Timestep Consumption Time: 2.52797
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.72617

Cumulative Model Updates: 170,634
Cumulative Timesteps: 1,422,914,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1422914960...
Checkpoint 1422914960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,063.59280
Policy Entropy: 3.65209
Value Function Loss: 0.03094

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.32632
Value Function Update Magnitude: 0.36876

Collected Steps per Second: 22,332.93663
Overall Steps per Second: 10,562.42351

Timestep Collection Time: 2.24028
Timestep Consumption Time: 2.49651
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.73679

Cumulative Model Updates: 170,640
Cumulative Timesteps: 1,422,964,992

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,751.70870
Policy Entropy: 3.65743
Value Function Loss: 0.03275

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.35487
Value Function Update Magnitude: 0.42383

Collected Steps per Second: 22,921.91439
Overall Steps per Second: 10,814.92641

Timestep Collection Time: 2.18202
Timestep Consumption Time: 2.44270
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.62472

Cumulative Model Updates: 170,646
Cumulative Timesteps: 1,423,015,008

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1423015008...
Checkpoint 1423015008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,751.70870
Policy Entropy: 3.65890
Value Function Loss: 0.02801

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.33098
Value Function Update Magnitude: 0.42966

Collected Steps per Second: 22,371.51771
Overall Steps per Second: 10,689.47110

Timestep Collection Time: 2.23633
Timestep Consumption Time: 2.44398
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.68031

Cumulative Model Updates: 170,652
Cumulative Timesteps: 1,423,065,038

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,745.39299
Policy Entropy: 3.66957
Value Function Loss: 0.02819

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.30012
Value Function Update Magnitude: 0.37692

Collected Steps per Second: 23,103.36660
Overall Steps per Second: 10,754.92279

Timestep Collection Time: 2.16540
Timestep Consumption Time: 2.48624
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.65164

Cumulative Model Updates: 170,658
Cumulative Timesteps: 1,423,115,066

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1423115066...
Checkpoint 1423115066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349,574.99640
Policy Entropy: 3.67395
Value Function Loss: 0.03202

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.31984
Value Function Update Magnitude: 0.44296

Collected Steps per Second: 21,568.23690
Overall Steps per Second: 10,579.80361

Timestep Collection Time: 2.31952
Timestep Consumption Time: 2.40911
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.72863

Cumulative Model Updates: 170,664
Cumulative Timesteps: 1,423,165,094

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349,574.99640
Policy Entropy: 3.66846
Value Function Loss: 0.03394

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.35155
Value Function Update Magnitude: 0.56761

Collected Steps per Second: 22,322.90670
Overall Steps per Second: 10,746.67016

Timestep Collection Time: 2.24102
Timestep Consumption Time: 2.41401
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.65502

Cumulative Model Updates: 170,670
Cumulative Timesteps: 1,423,215,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1423215120...
Checkpoint 1423215120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349,574.99640
Policy Entropy: 3.65883
Value Function Loss: 0.03106

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.33578
Value Function Update Magnitude: 0.55353

Collected Steps per Second: 21,412.64363
Overall Steps per Second: 10,525.52867

Timestep Collection Time: 2.33563
Timestep Consumption Time: 2.41587
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.75150

Cumulative Model Updates: 170,676
Cumulative Timesteps: 1,423,265,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323,071.10159
Policy Entropy: 3.67471
Value Function Loss: 0.02790

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.28962
Value Function Update Magnitude: 0.47319

Collected Steps per Second: 22,338.45593
Overall Steps per Second: 10,549.66969

Timestep Collection Time: 2.23865
Timestep Consumption Time: 2.50159
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.74024

Cumulative Model Updates: 170,682
Cumulative Timesteps: 1,423,315,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1423315140...
Checkpoint 1423315140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261,688.87569
Policy Entropy: 3.67379
Value Function Loss: 0.02826

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.26679
Value Function Update Magnitude: 0.53318

Collected Steps per Second: 22,225.07007
Overall Steps per Second: 10,643.44041

Timestep Collection Time: 2.25043
Timestep Consumption Time: 2.44880
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.69923

Cumulative Model Updates: 170,688
Cumulative Timesteps: 1,423,365,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261,688.87569
Policy Entropy: 3.67478
Value Function Loss: 0.03047

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11905
Policy Update Magnitude: 0.32040
Value Function Update Magnitude: 0.54750

Collected Steps per Second: 22,764.16384
Overall Steps per Second: 10,656.81379

Timestep Collection Time: 2.19670
Timestep Consumption Time: 2.49570
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.69240

Cumulative Model Updates: 170,694
Cumulative Timesteps: 1,423,415,162

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1423415162...
Checkpoint 1423415162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,761.91212
Policy Entropy: 3.66606
Value Function Loss: 0.03118

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.34433
Value Function Update Magnitude: 0.53393

Collected Steps per Second: 22,744.64887
Overall Steps per Second: 10,779.09365

Timestep Collection Time: 2.19946
Timestep Consumption Time: 2.44156
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.64102

Cumulative Model Updates: 170,700
Cumulative Timesteps: 1,423,465,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,761.91212
Policy Entropy: 3.68123
Value Function Loss: 0.02631

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12856
Policy Update Magnitude: 0.32876
Value Function Update Magnitude: 0.48896

Collected Steps per Second: 23,146.74039
Overall Steps per Second: 10,718.41889

Timestep Collection Time: 2.16065
Timestep Consumption Time: 2.50534
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.66599

Cumulative Model Updates: 170,706
Cumulative Timesteps: 1,423,515,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1423515200...
Checkpoint 1423515200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,749.50326
Policy Entropy: 3.67818
Value Function Loss: 0.02890

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12491
Policy Update Magnitude: 0.29801
Value Function Update Magnitude: 0.45515

Collected Steps per Second: 22,437.72940
Overall Steps per Second: 10,531.11900

Timestep Collection Time: 2.22946
Timestep Consumption Time: 2.52065
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.75011

Cumulative Model Updates: 170,712
Cumulative Timesteps: 1,423,565,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303,856.41487
Policy Entropy: 3.67623
Value Function Loss: 0.03030

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.31445
Value Function Update Magnitude: 0.62495

Collected Steps per Second: 22,917.22009
Overall Steps per Second: 10,776.93562

Timestep Collection Time: 2.18264
Timestep Consumption Time: 2.45876
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.64139

Cumulative Model Updates: 170,718
Cumulative Timesteps: 1,423,615,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1423615244...
Checkpoint 1423615244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177,729.44321
Policy Entropy: 3.67514
Value Function Loss: 0.03602

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.33101
Value Function Update Magnitude: 0.65184

Collected Steps per Second: 22,306.07691
Overall Steps per Second: 10,629.52745

Timestep Collection Time: 2.24208
Timestep Consumption Time: 2.46293
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.70501

Cumulative Model Updates: 170,724
Cumulative Timesteps: 1,423,665,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287,254.43970
Policy Entropy: 3.68562
Value Function Loss: 0.03861

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.33993
Value Function Update Magnitude: 0.52987

Collected Steps per Second: 23,047.39770
Overall Steps per Second: 10,703.54197

Timestep Collection Time: 2.17031
Timestep Consumption Time: 2.50291
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.67322

Cumulative Model Updates: 170,730
Cumulative Timesteps: 1,423,715,276

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1423715276...
Checkpoint 1423715276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287,254.43970
Policy Entropy: 3.68028
Value Function Loss: 0.03104

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.33585
Value Function Update Magnitude: 0.44729

Collected Steps per Second: 22,350.91590
Overall Steps per Second: 10,522.99973

Timestep Collection Time: 2.23848
Timestep Consumption Time: 2.51606
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.75454

Cumulative Model Updates: 170,736
Cumulative Timesteps: 1,423,765,308

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287,254.43970
Policy Entropy: 3.68207
Value Function Loss: 0.02476

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.31439
Value Function Update Magnitude: 0.44414

Collected Steps per Second: 23,100.47988
Overall Steps per Second: 10,822.71744

Timestep Collection Time: 2.16446
Timestep Consumption Time: 2.45545
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.61991

Cumulative Model Updates: 170,742
Cumulative Timesteps: 1,423,815,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1423815308...
Checkpoint 1423815308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287,254.43970
Policy Entropy: 3.67709
Value Function Loss: 0.02034

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12578
Policy Update Magnitude: 0.27324
Value Function Update Magnitude: 0.37483

Collected Steps per Second: 22,371.99622
Overall Steps per Second: 10,671.17335

Timestep Collection Time: 2.23512
Timestep Consumption Time: 2.45078
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.68590

Cumulative Model Updates: 170,748
Cumulative Timesteps: 1,423,865,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287,254.43970
Policy Entropy: 3.66603
Value Function Loss: 0.02037

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.23318
Value Function Update Magnitude: 0.28543

Collected Steps per Second: 22,145.94470
Overall Steps per Second: 10,405.37701

Timestep Collection Time: 2.25865
Timestep Consumption Time: 2.54848
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.80713

Cumulative Model Updates: 170,754
Cumulative Timesteps: 1,423,915,332

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1423915332...
Checkpoint 1423915332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287,254.43970
Policy Entropy: 3.65383
Value Function Loss: 0.03077

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13705
Policy Update Magnitude: 0.27632
Value Function Update Magnitude: 0.30035

Collected Steps per Second: 21,755.78296
Overall Steps per Second: 10,424.24701

Timestep Collection Time: 2.29852
Timestep Consumption Time: 2.49857
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.79709

Cumulative Model Updates: 170,760
Cumulative Timesteps: 1,423,965,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327,594.27833
Policy Entropy: 3.65697
Value Function Loss: 0.03551

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.36549
Value Function Update Magnitude: 0.39754

Collected Steps per Second: 21,851.38030
Overall Steps per Second: 10,234.45189

Timestep Collection Time: 2.28928
Timestep Consumption Time: 2.59852
PPO Batch Consumption Time: 0.30563
Total Iteration Time: 4.88780

Cumulative Model Updates: 170,766
Cumulative Timesteps: 1,424,015,362

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1424015362...
Checkpoint 1424015362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202,362.54618
Policy Entropy: 3.67686
Value Function Loss: 0.04100

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.38294
Value Function Update Magnitude: 0.45561

Collected Steps per Second: 17,704.09330
Overall Steps per Second: 9,457.09285

Timestep Collection Time: 2.82432
Timestep Consumption Time: 2.46293
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 5.28725

Cumulative Model Updates: 170,772
Cumulative Timesteps: 1,424,065,364

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230,557.37687
Policy Entropy: 3.68769
Value Function Loss: 0.03959

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.36429
Value Function Update Magnitude: 0.52769

Collected Steps per Second: 21,897.07028
Overall Steps per Second: 10,362.60518

Timestep Collection Time: 2.28368
Timestep Consumption Time: 2.54194
PPO Batch Consumption Time: 0.30853
Total Iteration Time: 4.82562

Cumulative Model Updates: 170,778
Cumulative Timesteps: 1,424,115,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1424115370...
Checkpoint 1424115370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,437.79816
Policy Entropy: 3.68594
Value Function Loss: 0.04564

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.36238
Value Function Update Magnitude: 0.60185

Collected Steps per Second: 20,728.65319
Overall Steps per Second: 10,046.21621

Timestep Collection Time: 2.41308
Timestep Consumption Time: 2.56590
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 4.97899

Cumulative Model Updates: 170,784
Cumulative Timesteps: 1,424,165,390

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384,368.02284
Policy Entropy: 3.69649
Value Function Loss: 0.04651

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.43161
Value Function Update Magnitude: 0.62292

Collected Steps per Second: 21,557.74602
Overall Steps per Second: 10,228.17148

Timestep Collection Time: 2.32056
Timestep Consumption Time: 2.57044
PPO Batch Consumption Time: 0.30716
Total Iteration Time: 4.89100

Cumulative Model Updates: 170,790
Cumulative Timesteps: 1,424,215,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1424215416...
Checkpoint 1424215416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384,368.02284
Policy Entropy: 3.68302
Value Function Loss: 0.04207

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.43585
Value Function Update Magnitude: 0.64683

Collected Steps per Second: 20,992.56293
Overall Steps per Second: 10,197.40729

Timestep Collection Time: 2.38208
Timestep Consumption Time: 2.52171
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.90380

Cumulative Model Updates: 170,796
Cumulative Timesteps: 1,424,265,422

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384,368.02284
Policy Entropy: 3.67260
Value Function Loss: 0.03377

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.40263
Value Function Update Magnitude: 0.74981

Collected Steps per Second: 22,337.62355
Overall Steps per Second: 10,566.90727

Timestep Collection Time: 2.23945
Timestep Consumption Time: 2.49457
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.73402

Cumulative Model Updates: 170,802
Cumulative Timesteps: 1,424,315,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1424315446...
Checkpoint 1424315446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384,368.02284
Policy Entropy: 3.65656
Value Function Loss: 0.02874

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.39000
Value Function Update Magnitude: 0.68666

Collected Steps per Second: 18,717.36498
Overall Steps per Second: 9,653.22695

Timestep Collection Time: 2.67196
Timestep Consumption Time: 2.50890
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 5.18086

Cumulative Model Updates: 170,808
Cumulative Timesteps: 1,424,365,458

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384,368.02284
Policy Entropy: 3.65663
Value Function Loss: 0.03111

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.41084
Value Function Update Magnitude: 0.54883

Collected Steps per Second: 22,414.50307
Overall Steps per Second: 10,673.30377

Timestep Collection Time: 2.23079
Timestep Consumption Time: 2.45398
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.68477

Cumulative Model Updates: 170,814
Cumulative Timesteps: 1,424,415,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1424415460...
Checkpoint 1424415460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359,755.05153
Policy Entropy: 3.68298
Value Function Loss: 0.03091

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.43635
Value Function Update Magnitude: 0.66006

Collected Steps per Second: 21,734.09494
Overall Steps per Second: 10,193.48936

Timestep Collection Time: 2.30062
Timestep Consumption Time: 2.60466
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.90529

Cumulative Model Updates: 170,820
Cumulative Timesteps: 1,424,465,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359,755.05153
Policy Entropy: 3.68297
Value Function Loss: 0.03091

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.39922
Value Function Update Magnitude: 0.64860

Collected Steps per Second: 22,737.63881
Overall Steps per Second: 10,636.72414

Timestep Collection Time: 2.19970
Timestep Consumption Time: 2.50250
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.70220

Cumulative Model Updates: 170,826
Cumulative Timesteps: 1,424,515,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1424515478...
Checkpoint 1424515478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359,755.05153
Policy Entropy: 3.69620
Value Function Loss: 0.02622

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12836
Policy Update Magnitude: 0.35890
Value Function Update Magnitude: 0.51596

Collected Steps per Second: 21,800.96510
Overall Steps per Second: 10,380.02733

Timestep Collection Time: 2.29430
Timestep Consumption Time: 2.52437
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.81868

Cumulative Model Updates: 170,832
Cumulative Timesteps: 1,424,565,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359,755.05153
Policy Entropy: 3.66494
Value Function Loss: 0.02307

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.32000
Value Function Update Magnitude: 0.43425

Collected Steps per Second: 22,531.66510
Overall Steps per Second: 10,573.57209

Timestep Collection Time: 2.21910
Timestep Consumption Time: 2.50967
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.72877

Cumulative Model Updates: 170,838
Cumulative Timesteps: 1,424,615,496

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1424615496...
Checkpoint 1424615496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359,755.05153
Policy Entropy: 3.67826
Value Function Loss: 0.02180

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.27621
Value Function Update Magnitude: 0.34743

Collected Steps per Second: 22,705.39039
Overall Steps per Second: 10,626.30376

Timestep Collection Time: 2.20300
Timestep Consumption Time: 2.50419
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.70719

Cumulative Model Updates: 170,844
Cumulative Timesteps: 1,424,665,516

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359,755.05153
Policy Entropy: 3.67249
Value Function Loss: 0.02631

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.26748
Value Function Update Magnitude: 0.29508

Collected Steps per Second: 22,323.95796
Overall Steps per Second: 10,576.06046

Timestep Collection Time: 2.23975
Timestep Consumption Time: 2.48791
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.72766

Cumulative Model Updates: 170,850
Cumulative Timesteps: 1,424,715,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1424715516...
Checkpoint 1424715516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359,755.05153
Policy Entropy: 3.68127
Value Function Loss: 0.02599

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12513
Policy Update Magnitude: 0.31051
Value Function Update Magnitude: 0.30887

Collected Steps per Second: 22,178.50773
Overall Steps per Second: 10,539.90022

Timestep Collection Time: 2.25570
Timestep Consumption Time: 2.49084
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.74653

Cumulative Model Updates: 170,856
Cumulative Timesteps: 1,424,765,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,987.01714
Policy Entropy: 3.67575
Value Function Loss: 0.03325

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.33456
Value Function Update Magnitude: 0.37625

Collected Steps per Second: 22,181.71918
Overall Steps per Second: 10,705.74896

Timestep Collection Time: 2.25492
Timestep Consumption Time: 2.41715
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.67207

Cumulative Model Updates: 170,862
Cumulative Timesteps: 1,424,815,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1424815562...
Checkpoint 1424815562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306,936.71148
Policy Entropy: 3.68744
Value Function Loss: 0.03282

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.33332
Value Function Update Magnitude: 0.45597

Collected Steps per Second: 21,040.02136
Overall Steps per Second: 10,432.88611

Timestep Collection Time: 2.37652
Timestep Consumption Time: 2.41621
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.79273

Cumulative Model Updates: 170,868
Cumulative Timesteps: 1,424,865,564

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449,863.28655
Policy Entropy: 3.68554
Value Function Loss: 0.03289

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.32605
Value Function Update Magnitude: 0.60056

Collected Steps per Second: 21,990.71113
Overall Steps per Second: 10,546.79896

Timestep Collection Time: 2.27451
Timestep Consumption Time: 2.46798
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.74248

Cumulative Model Updates: 170,874
Cumulative Timesteps: 1,424,915,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1424915582...
Checkpoint 1424915582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295,164.59402
Policy Entropy: 3.68235
Value Function Loss: 0.02989

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.30966
Value Function Update Magnitude: 0.58763

Collected Steps per Second: 22,525.21230
Overall Steps per Second: 10,671.42029

Timestep Collection Time: 2.22062
Timestep Consumption Time: 2.46666
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.68729

Cumulative Model Updates: 170,880
Cumulative Timesteps: 1,424,965,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295,164.59402
Policy Entropy: 3.67574
Value Function Loss: 0.02640

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13483
Policy Update Magnitude: 0.28313
Value Function Update Magnitude: 0.49656

Collected Steps per Second: 22,090.78229
Overall Steps per Second: 10,579.65640

Timestep Collection Time: 2.26574
Timestep Consumption Time: 2.46523
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.73097

Cumulative Model Updates: 170,886
Cumulative Timesteps: 1,425,015,654

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1425015654...
Checkpoint 1425015654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,309.82420
Policy Entropy: 3.67551
Value Function Loss: 0.02770

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.31053
Value Function Update Magnitude: 0.48990

Collected Steps per Second: 20,472.55761
Overall Steps per Second: 10,159.75750

Timestep Collection Time: 2.44317
Timestep Consumption Time: 2.47998
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.92315

Cumulative Model Updates: 170,892
Cumulative Timesteps: 1,425,065,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,067.27865
Policy Entropy: 3.68569
Value Function Loss: 0.02733

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13705
Policy Update Magnitude: 0.34689
Value Function Update Magnitude: 0.60608

Collected Steps per Second: 22,131.65374
Overall Steps per Second: 10,679.29821

Timestep Collection Time: 2.26002
Timestep Consumption Time: 2.42362
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.68364

Cumulative Model Updates: 170,898
Cumulative Timesteps: 1,425,115,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1425115690...
Checkpoint 1425115690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,067.27865
Policy Entropy: 3.67950
Value Function Loss: 0.02819

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.34869
Value Function Update Magnitude: 0.66005

Collected Steps per Second: 22,551.02417
Overall Steps per Second: 10,612.10787

Timestep Collection Time: 2.21719
Timestep Consumption Time: 2.49441
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.71160

Cumulative Model Updates: 170,904
Cumulative Timesteps: 1,425,165,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,067.27865
Policy Entropy: 3.67698
Value Function Loss: 0.02950

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13209
Policy Update Magnitude: 0.35260
Value Function Update Magnitude: 0.57446

Collected Steps per Second: 23,279.14608
Overall Steps per Second: 10,892.70304

Timestep Collection Time: 2.14905
Timestep Consumption Time: 2.44375
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.59280

Cumulative Model Updates: 170,910
Cumulative Timesteps: 1,425,215,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1425215718...
Checkpoint 1425215718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411,959.56704
Policy Entropy: 3.67084
Value Function Loss: 0.02813

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.33662
Value Function Update Magnitude: 0.47424

Collected Steps per Second: 20,030.44583
Overall Steps per Second: 9,984.10840

Timestep Collection Time: 2.49650
Timestep Consumption Time: 2.51206
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 5.00856

Cumulative Model Updates: 170,916
Cumulative Timesteps: 1,425,265,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411,959.56704
Policy Entropy: 3.67522
Value Function Loss: 0.02783

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.30159
Value Function Update Magnitude: 0.43293

Collected Steps per Second: 21,603.65213
Overall Steps per Second: 10,312.52087

Timestep Collection Time: 2.31600
Timestep Consumption Time: 2.53577
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.85177

Cumulative Model Updates: 170,922
Cumulative Timesteps: 1,425,315,758

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1425315758...
Checkpoint 1425315758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,347.32012
Policy Entropy: 3.67401
Value Function Loss: 0.03118

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14692
Policy Update Magnitude: 0.31126
Value Function Update Magnitude: 0.43558

Collected Steps per Second: 21,636.08253
Overall Steps per Second: 10,723.93210

Timestep Collection Time: 2.31169
Timestep Consumption Time: 2.35227
PPO Batch Consumption Time: 0.27647
Total Iteration Time: 4.66396

Cumulative Model Updates: 170,928
Cumulative Timesteps: 1,425,365,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,347.32012
Policy Entropy: 3.65582
Value Function Loss: 0.03191

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13801
Policy Update Magnitude: 0.35477
Value Function Update Magnitude: 0.60540

Collected Steps per Second: 21,434.41620
Overall Steps per Second: 10,240.65247

Timestep Collection Time: 2.33298
Timestep Consumption Time: 2.55011
PPO Batch Consumption Time: 0.31309
Total Iteration Time: 4.88309

Cumulative Model Updates: 170,934
Cumulative Timesteps: 1,425,415,780

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1425415780...
Checkpoint 1425415780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,347.32012
Policy Entropy: 3.66985
Value Function Loss: 0.03313

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.37863
Value Function Update Magnitude: 0.65625

Collected Steps per Second: 20,794.95360
Overall Steps per Second: 10,059.35093

Timestep Collection Time: 2.40530
Timestep Consumption Time: 2.56699
PPO Batch Consumption Time: 0.29753
Total Iteration Time: 4.97229

Cumulative Model Updates: 170,940
Cumulative Timesteps: 1,425,465,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,347.32012
Policy Entropy: 3.65898
Value Function Loss: 0.03055

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13756
Policy Update Magnitude: 0.37975
Value Function Update Magnitude: 0.62024

Collected Steps per Second: 19,846.75565
Overall Steps per Second: 9,962.45764

Timestep Collection Time: 2.52021
Timestep Consumption Time: 2.50044
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 5.02065

Cumulative Model Updates: 170,946
Cumulative Timesteps: 1,425,515,816

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1425515816...
Checkpoint 1425515816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,347.32012
Policy Entropy: 3.66281
Value Function Loss: 0.03345

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.38779
Value Function Update Magnitude: 0.54623

Collected Steps per Second: 21,895.10109
Overall Steps per Second: 10,713.50297

Timestep Collection Time: 2.28371
Timestep Consumption Time: 2.38349
PPO Batch Consumption Time: 0.27632
Total Iteration Time: 4.66719

Cumulative Model Updates: 170,952
Cumulative Timesteps: 1,425,565,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,347.32012
Policy Entropy: 3.65191
Value Function Loss: 0.03330

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.43597
Value Function Update Magnitude: 0.49993

Collected Steps per Second: 22,967.14205
Overall Steps per Second: 10,717.30060

Timestep Collection Time: 2.17772
Timestep Consumption Time: 2.48913
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.66685

Cumulative Model Updates: 170,958
Cumulative Timesteps: 1,425,615,834

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1425615834...
Checkpoint 1425615834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,347.32012
Policy Entropy: 3.65165
Value Function Loss: 0.03708

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.45035
Value Function Update Magnitude: 0.46505

Collected Steps per Second: 22,104.38618
Overall Steps per Second: 10,573.82126

Timestep Collection Time: 2.26245
Timestep Consumption Time: 2.46716
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.72961

Cumulative Model Updates: 170,964
Cumulative Timesteps: 1,425,665,844

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299,679.64313
Policy Entropy: 3.64189
Value Function Loss: 0.04483

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.44421
Value Function Update Magnitude: 0.44582

Collected Steps per Second: 21,948.74352
Overall Steps per Second: 10,599.61691

Timestep Collection Time: 2.27876
Timestep Consumption Time: 2.43990
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.71866

Cumulative Model Updates: 170,970
Cumulative Timesteps: 1,425,715,860

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1425715860...
Checkpoint 1425715860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,261.68348
Policy Entropy: 3.65800
Value Function Loss: 0.04098

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.44586
Value Function Update Magnitude: 0.50606

Collected Steps per Second: 21,601.76435
Overall Steps per Second: 10,218.34094

Timestep Collection Time: 2.31555
Timestep Consumption Time: 2.57957
PPO Batch Consumption Time: 0.30214
Total Iteration Time: 4.89512

Cumulative Model Updates: 170,976
Cumulative Timesteps: 1,425,765,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159,261.68348
Policy Entropy: 3.65638
Value Function Loss: 0.03640

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.42744
Value Function Update Magnitude: 0.59037

Collected Steps per Second: 20,416.91307
Overall Steps per Second: 9,920.55936

Timestep Collection Time: 2.44973
Timestep Consumption Time: 2.59192
PPO Batch Consumption Time: 0.30525
Total Iteration Time: 5.04165

Cumulative Model Updates: 170,982
Cumulative Timesteps: 1,425,815,896

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1425815896...
Checkpoint 1425815896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,261.68348
Policy Entropy: 3.67543
Value Function Loss: 0.02641

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.37287
Value Function Update Magnitude: 0.58244

Collected Steps per Second: 22,137.99952
Overall Steps per Second: 10,278.81005

Timestep Collection Time: 2.25964
Timestep Consumption Time: 2.60707
PPO Batch Consumption Time: 0.30610
Total Iteration Time: 4.86671

Cumulative Model Updates: 170,988
Cumulative Timesteps: 1,425,865,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,800.35374
Policy Entropy: 3.64646
Value Function Loss: 0.02634

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.33703
Value Function Update Magnitude: 0.50419

Collected Steps per Second: 21,400.39521
Overall Steps per Second: 10,468.48062

Timestep Collection Time: 2.33715
Timestep Consumption Time: 2.44062
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.77777

Cumulative Model Updates: 170,994
Cumulative Timesteps: 1,425,915,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1425915936...
Checkpoint 1425915936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,800.35374
Policy Entropy: 3.64914
Value Function Loss: 0.02677

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.35305
Value Function Update Magnitude: 0.44052

Collected Steps per Second: 21,449.91622
Overall Steps per Second: 10,656.21086

Timestep Collection Time: 2.33185
Timestep Consumption Time: 2.36194
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.69379

Cumulative Model Updates: 171,000
Cumulative Timesteps: 1,425,965,954

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,800.35374
Policy Entropy: 3.63741
Value Function Loss: 0.03013

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14258
Policy Update Magnitude: 0.38245
Value Function Update Magnitude: 0.44975

Collected Steps per Second: 21,748.62359
Overall Steps per Second: 10,463.62685

Timestep Collection Time: 2.30028
Timestep Consumption Time: 2.48085
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.78113

Cumulative Model Updates: 171,006
Cumulative Timesteps: 1,426,015,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1426015982...
Checkpoint 1426015982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,800.35374
Policy Entropy: 3.66812
Value Function Loss: 0.02959

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.42635
Value Function Update Magnitude: 0.44752

Collected Steps per Second: 20,645.45978
Overall Steps per Second: 10,156.16232

Timestep Collection Time: 2.42252
Timestep Consumption Time: 2.50198
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.92450

Cumulative Model Updates: 171,012
Cumulative Timesteps: 1,426,065,996

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,800.35374
Policy Entropy: 3.66764
Value Function Loss: 0.02972

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.12678
Policy Update Magnitude: 0.50074
Value Function Update Magnitude: 0.41663

Collected Steps per Second: 21,556.02736
Overall Steps per Second: 10,536.04276

Timestep Collection Time: 2.32084
Timestep Consumption Time: 2.42744
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.74827

Cumulative Model Updates: 171,018
Cumulative Timesteps: 1,426,116,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1426116024...
Checkpoint 1426116024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,800.35374
Policy Entropy: 3.67762
Value Function Loss: 0.03074

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.11114
Policy Update Magnitude: 0.63303
Value Function Update Magnitude: 0.49372

Collected Steps per Second: 21,363.48685
Overall Steps per Second: 10,103.35443

Timestep Collection Time: 2.34091
Timestep Consumption Time: 2.60893
PPO Batch Consumption Time: 0.30812
Total Iteration Time: 4.94984

Cumulative Model Updates: 171,024
Cumulative Timesteps: 1,426,166,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,800.35374
Policy Entropy: 3.67525
Value Function Loss: 0.03234

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.63963
Value Function Update Magnitude: 0.54215

Collected Steps per Second: 22,610.11684
Overall Steps per Second: 10,494.82724

Timestep Collection Time: 2.21211
Timestep Consumption Time: 2.55367
PPO Batch Consumption Time: 0.30236
Total Iteration Time: 4.76578

Cumulative Model Updates: 171,030
Cumulative Timesteps: 1,426,216,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1426216050...
Checkpoint 1426216050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,800.35374
Policy Entropy: 3.63867
Value Function Loss: 0.03185

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.19167
Policy Update Magnitude: 0.52305
Value Function Update Magnitude: 0.42127

Collected Steps per Second: 20,623.32209
Overall Steps per Second: 10,301.09705

Timestep Collection Time: 2.42686
Timestep Consumption Time: 2.43184
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.85871

Cumulative Model Updates: 171,036
Cumulative Timesteps: 1,426,266,100

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447,269.55684
Policy Entropy: 3.62923
Value Function Loss: 0.04392

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.16859
Policy Update Magnitude: 0.42276
Value Function Update Magnitude: 0.40480

Collected Steps per Second: 19,551.42310
Overall Steps per Second: 10,006.39509

Timestep Collection Time: 2.55736
Timestep Consumption Time: 2.43945
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.99680

Cumulative Model Updates: 171,042
Cumulative Timesteps: 1,426,316,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1426316100...
Checkpoint 1426316100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447,269.55684
Policy Entropy: 3.62754
Value Function Loss: 0.04509

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.14608
Policy Update Magnitude: 0.46217
Value Function Update Magnitude: 0.42142

Collected Steps per Second: 20,145.86681
Overall Steps per Second: 9,498.50139

Timestep Collection Time: 2.48259
Timestep Consumption Time: 2.78287
PPO Batch Consumption Time: 0.33296
Total Iteration Time: 5.26546

Cumulative Model Updates: 171,048
Cumulative Timesteps: 1,426,366,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447,269.55684
Policy Entropy: 3.62933
Value Function Loss: 0.05184

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.14561
Policy Update Magnitude: 0.46729
Value Function Update Magnitude: 0.47025

Collected Steps per Second: 17,976.06606
Overall Steps per Second: 9,268.49725

Timestep Collection Time: 2.78203
Timestep Consumption Time: 2.61366
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 5.39570

Cumulative Model Updates: 171,054
Cumulative Timesteps: 1,426,416,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1426416124...
Checkpoint 1426416124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447,269.55684
Policy Entropy: 3.65334
Value Function Loss: 0.05102

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.50788
Value Function Update Magnitude: 0.42690

Collected Steps per Second: 12,922.67685
Overall Steps per Second: 6,917.10481

Timestep Collection Time: 3.87010
Timestep Consumption Time: 3.36010
PPO Batch Consumption Time: 0.40602
Total Iteration Time: 7.23019

Cumulative Model Updates: 171,060
Cumulative Timesteps: 1,426,466,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779,756.57287
Policy Entropy: 3.65536
Value Function Loss: 0.04885

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.62917
Value Function Update Magnitude: 0.35055

Collected Steps per Second: 6,485.37972
Overall Steps per Second: 4,348.55748

Timestep Collection Time: 7.70965
Timestep Consumption Time: 3.78842
PPO Batch Consumption Time: 0.39736
Total Iteration Time: 11.49807

Cumulative Model Updates: 171,066
Cumulative Timesteps: 1,426,516,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1426516136...
Checkpoint 1426516136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779,756.57287
Policy Entropy: 3.69243
Value Function Loss: 0.03738

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.14735
Policy Update Magnitude: 0.61482
Value Function Update Magnitude: 0.42502

Collected Steps per Second: 9,462.22832
Overall Steps per Second: 4,846.18617

Timestep Collection Time: 5.28459
Timestep Consumption Time: 5.03363
PPO Batch Consumption Time: 0.69630
Total Iteration Time: 10.31822

Cumulative Model Updates: 171,072
Cumulative Timesteps: 1,426,566,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779,756.57287
Policy Entropy: 3.68343
Value Function Loss: 0.03676

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.15627
Policy Update Magnitude: 0.48954
Value Function Update Magnitude: 0.41713

Collected Steps per Second: 13,418.00151
Overall Steps per Second: 5,784.47824

Timestep Collection Time: 3.72902
Timestep Consumption Time: 4.92103
PPO Batch Consumption Time: 0.67465
Total Iteration Time: 8.65005

Cumulative Model Updates: 171,078
Cumulative Timesteps: 1,426,616,176

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1426616176...
Checkpoint 1426616176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779,756.57287
Policy Entropy: 3.68346
Value Function Loss: 0.03601

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.47028
Value Function Update Magnitude: 0.41969

Collected Steps per Second: 12,693.81520
Overall Steps per Second: 6,384.19745

Timestep Collection Time: 3.94113
Timestep Consumption Time: 3.89509
PPO Batch Consumption Time: 0.49829
Total Iteration Time: 7.83622

Cumulative Model Updates: 171,084
Cumulative Timesteps: 1,426,666,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779,756.57287
Policy Entropy: 3.67034
Value Function Loss: 0.03306

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.16805
Policy Update Magnitude: 0.47425
Value Function Update Magnitude: 0.45104

Collected Steps per Second: 13,020.47256
Overall Steps per Second: 4,264.42891

Timestep Collection Time: 3.84011
Timestep Consumption Time: 7.88479
PPO Batch Consumption Time: 1.13481
Total Iteration Time: 11.72490

Cumulative Model Updates: 171,090
Cumulative Timesteps: 1,426,716,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1426716204...
Checkpoint 1426716204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779,756.57287
Policy Entropy: 3.66903
Value Function Loss: 0.03177

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.20311
Policy Update Magnitude: 0.42320
Value Function Update Magnitude: 0.57340

Collected Steps per Second: 8,792.64101
Overall Steps per Second: 410.82732

Timestep Collection Time: 5.68703
Timestep Consumption Time: 116.02834
PPO Batch Consumption Time: 19.15075
Total Iteration Time: 121.71537

Cumulative Model Updates: 171,096
Cumulative Timesteps: 1,426,766,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779,756.57287
Policy Entropy: 3.65593
Value Function Loss: 0.03038

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.16211
Policy Update Magnitude: 0.37252
Value Function Update Magnitude: 0.54335

Collected Steps per Second: 4,863.67966
Overall Steps per Second: 432.28471

Timestep Collection Time: 10.28316
Timestep Consumption Time: 105.41374
PPO Batch Consumption Time: 16.85722
Total Iteration Time: 115.69690

Cumulative Model Updates: 171,102
Cumulative Timesteps: 1,426,816,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1426816222...
Checkpoint 1426816222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779,756.57287
Policy Entropy: 3.63860
Value Function Loss: 0.02841

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13900
Policy Update Magnitude: 0.44891
Value Function Update Magnitude: 0.53763

Collected Steps per Second: 5,247.12817
Overall Steps per Second: 108.70100

Timestep Collection Time: 9.53436
Timestep Consumption Time: 450.70060
PPO Batch Consumption Time: 74.94480
Total Iteration Time: 460.23496

Cumulative Model Updates: 171,108
Cumulative Timesteps: 1,426,866,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1426866250...
Checkpoint 1426866250 saved!
