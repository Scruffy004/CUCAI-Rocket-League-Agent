Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,161.99143
Policy Entropy: 0.68399
Value Function Loss: 0.07320

Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.01189
Value Function Update Magnitude: 0.02032

Collected Steps per Second: 20,455.46404
Overall Steps per Second: 16,168.57044

Timestep Collection Time: 2.44570
Timestep Consumption Time: 0.64845
PPO Batch Consumption Time: 0.12897
Total Iteration Time: 3.09415

Cumulative Model Updates: 19,518
Cumulative Timesteps: 325,911,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,834.71747
Policy Entropy: 0.72397
Value Function Loss: 0.04959

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00467
Policy Update Magnitude: 0.02418
Value Function Update Magnitude: 0.04319

Collected Steps per Second: 22,628.05024
Overall Steps per Second: 16,828.12816

Timestep Collection Time: 2.21186
Timestep Consumption Time: 0.76233
PPO Batch Consumption Time: 0.10240
Total Iteration Time: 2.97419

Cumulative Model Updates: 19,520
Cumulative Timesteps: 325,961,710

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 325961710...
Checkpoint 325961710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,307.25284
Policy Entropy: 0.72713
Value Function Loss: 0.05134

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.02077
Policy Update Magnitude: 0.03636
Value Function Update Magnitude: 0.06593

Collected Steps per Second: 22,006.36728
Overall Steps per Second: 16,673.89391

Timestep Collection Time: 2.27252
Timestep Consumption Time: 0.72678
PPO Batch Consumption Time: 0.06046
Total Iteration Time: 2.99930

Cumulative Model Updates: 19,523
Cumulative Timesteps: 326,011,720

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,223.31459
Policy Entropy: 0.74659
Value Function Loss: 0.04582

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02382
Policy Update Magnitude: 0.03488
Value Function Update Magnitude: 0.07349

Collected Steps per Second: 20,101.02029
Overall Steps per Second: 14,723.90023

Timestep Collection Time: 2.48843
Timestep Consumption Time: 0.90877
PPO Batch Consumption Time: 0.10546
Total Iteration Time: 3.39720

Cumulative Model Updates: 19,526
Cumulative Timesteps: 326,061,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 326061740...
Checkpoint 326061740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,843.93737
Policy Entropy: 0.74862
Value Function Loss: 0.04692

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02786
Policy Update Magnitude: 0.03376
Value Function Update Magnitude: 0.07033

Collected Steps per Second: 22,472.97231
Overall Steps per Second: 15,753.80671

Timestep Collection Time: 2.22561
Timestep Consumption Time: 0.94924
PPO Batch Consumption Time: 0.10767
Total Iteration Time: 3.17485

Cumulative Model Updates: 19,529
Cumulative Timesteps: 326,111,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,308.40804
Policy Entropy: 0.75507
Value Function Loss: 0.04002

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03158
Policy Update Magnitude: 0.03382
Value Function Update Magnitude: 0.06449

Collected Steps per Second: 22,531.34553
Overall Steps per Second: 16,682.79960

Timestep Collection Time: 2.21957
Timestep Consumption Time: 0.77812
PPO Batch Consumption Time: 0.05961
Total Iteration Time: 2.99770

Cumulative Model Updates: 19,532
Cumulative Timesteps: 326,161,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 326161766...
Checkpoint 326161766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,512.44758
Policy Entropy: 0.75887
Value Function Loss: 0.03407

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02884
Policy Update Magnitude: 0.03093
Value Function Update Magnitude: 0.05722

Collected Steps per Second: 19,926.82341
Overall Steps per Second: 14,727.63418

Timestep Collection Time: 2.50968
Timestep Consumption Time: 0.88597
PPO Batch Consumption Time: 0.08395
Total Iteration Time: 3.39566

Cumulative Model Updates: 19,535
Cumulative Timesteps: 326,211,776

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,606.67214
Policy Entropy: 0.75436
Value Function Loss: 0.03966

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02459
Policy Update Magnitude: 0.02950
Value Function Update Magnitude: 0.05462

Collected Steps per Second: 22,765.89829
Overall Steps per Second: 15,755.42908

Timestep Collection Time: 2.19767
Timestep Consumption Time: 0.97787
PPO Batch Consumption Time: 0.10294
Total Iteration Time: 3.17554

Cumulative Model Updates: 19,538
Cumulative Timesteps: 326,261,808

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 326261808...
Checkpoint 326261808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,232.43950
Policy Entropy: 0.74755
Value Function Loss: 0.04718

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04324
Policy Update Magnitude: 0.02865
Value Function Update Magnitude: 0.05663

Collected Steps per Second: 23,130.58527
Overall Steps per Second: 16,691.44127

Timestep Collection Time: 2.16207
Timestep Consumption Time: 0.83407
PPO Batch Consumption Time: 0.06036
Total Iteration Time: 2.99615

Cumulative Model Updates: 19,541
Cumulative Timesteps: 326,311,818

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,877.91434
Policy Entropy: 0.74968
Value Function Loss: 0.05415

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03683
Policy Update Magnitude: 0.03158
Value Function Update Magnitude: 0.05810

Collected Steps per Second: 17,433.85008
Overall Steps per Second: 13,221.33097

Timestep Collection Time: 2.86844
Timestep Consumption Time: 0.91393
PPO Batch Consumption Time: 0.08692
Total Iteration Time: 3.78237

Cumulative Model Updates: 19,544
Cumulative Timesteps: 326,361,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 326361826...
Checkpoint 326361826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,914.51648
Policy Entropy: 0.75377
Value Function Loss: 0.05669

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03163
Policy Update Magnitude: 0.03393
Value Function Update Magnitude: 0.05182

Collected Steps per Second: 20,554.13318
Overall Steps per Second: 15,307.23881

Timestep Collection Time: 2.43357
Timestep Consumption Time: 0.83416
PPO Batch Consumption Time: 0.06004
Total Iteration Time: 3.26774

Cumulative Model Updates: 19,547
Cumulative Timesteps: 326,411,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,656.59300
Policy Entropy: 0.75230
Value Function Loss: 0.05461

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02955
Policy Update Magnitude: 0.03438
Value Function Update Magnitude: 0.04828

Collected Steps per Second: 20,083.66399
Overall Steps per Second: 15,287.22547

Timestep Collection Time: 2.48998
Timestep Consumption Time: 0.78124
PPO Batch Consumption Time: 0.03024
Total Iteration Time: 3.27123

Cumulative Model Updates: 19,550
Cumulative Timesteps: 326,461,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 326461854...
Checkpoint 326461854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,127.62712
Policy Entropy: 0.75539
Value Function Loss: 0.05396

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.01187
Policy Update Magnitude: 0.03336
Value Function Update Magnitude: 0.04898

Collected Steps per Second: 19,780.67090
Overall Steps per Second: 14,636.63063

Timestep Collection Time: 2.52853
Timestep Consumption Time: 0.88865
PPO Batch Consumption Time: 0.08028
Total Iteration Time: 3.41718

Cumulative Model Updates: 19,553
Cumulative Timesteps: 326,511,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,507.12546
Policy Entropy: 0.76130
Value Function Loss: 0.05046

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01472
Policy Update Magnitude: 0.03315
Value Function Update Magnitude: 0.04731

Collected Steps per Second: 21,000.45862
Overall Steps per Second: 15,839.17442

Timestep Collection Time: 2.38147
Timestep Consumption Time: 0.77602
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 3.15749

Cumulative Model Updates: 19,556
Cumulative Timesteps: 326,561,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 326561882...
Checkpoint 326561882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,488.70044
Policy Entropy: 0.76771
Value Function Loss: 0.04831

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01519
Policy Update Magnitude: 0.02983
Value Function Update Magnitude: 0.04607

Collected Steps per Second: 22,860.62373
Overall Steps per Second: 17,165.41006

Timestep Collection Time: 2.18795
Timestep Consumption Time: 0.72593
PPO Batch Consumption Time: 0.03011
Total Iteration Time: 2.91388

Cumulative Model Updates: 19,559
Cumulative Timesteps: 326,611,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,982.58756
Policy Entropy: 0.77564
Value Function Loss: 0.04484

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02357
Policy Update Magnitude: 0.02920
Value Function Update Magnitude: 0.04287

Collected Steps per Second: 19,822.63727
Overall Steps per Second: 14,336.91345

Timestep Collection Time: 2.52257
Timestep Consumption Time: 0.96521
PPO Batch Consumption Time: 0.10855
Total Iteration Time: 3.48778

Cumulative Model Updates: 19,562
Cumulative Timesteps: 326,661,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 326661904...
Checkpoint 326661904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,458.78951
Policy Entropy: 0.76645
Value Function Loss: 0.04663

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01459
Policy Update Magnitude: 0.03031
Value Function Update Magnitude: 0.04176

Collected Steps per Second: 20,304.60068
Overall Steps per Second: 14,732.78621

Timestep Collection Time: 2.46328
Timestep Consumption Time: 0.93159
PPO Batch Consumption Time: 0.08453
Total Iteration Time: 3.39488

Cumulative Model Updates: 19,565
Cumulative Timesteps: 326,711,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,990.43840
Policy Entropy: 0.77067
Value Function Loss: 0.04689

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.02963
Value Function Update Magnitude: 0.04039

Collected Steps per Second: 18,368.08360
Overall Steps per Second: 13,891.84055

Timestep Collection Time: 2.72244
Timestep Consumption Time: 0.87723
PPO Batch Consumption Time: 0.06886
Total Iteration Time: 3.59967

Cumulative Model Updates: 19,568
Cumulative Timesteps: 326,761,926

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 326761926...
Checkpoint 326761926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,914.96632
Policy Entropy: 0.75759
Value Function Loss: 0.04848

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03173
Policy Update Magnitude: 0.02985
Value Function Update Magnitude: 0.04097

Collected Steps per Second: 18,062.50806
Overall Steps per Second: 13,887.07217

Timestep Collection Time: 2.76960
Timestep Consumption Time: 0.83274
PPO Batch Consumption Time: 0.02997
Total Iteration Time: 3.60234

Cumulative Model Updates: 19,571
Cumulative Timesteps: 326,811,952

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,399.83576
Policy Entropy: 0.76158
Value Function Loss: 0.04676

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01979
Policy Update Magnitude: 0.02993
Value Function Update Magnitude: 0.04890

Collected Steps per Second: 21,807.82157
Overall Steps per Second: 16,430.29755

Timestep Collection Time: 2.29303
Timestep Consumption Time: 0.75049
PPO Batch Consumption Time: 0.03051
Total Iteration Time: 3.04352

Cumulative Model Updates: 19,574
Cumulative Timesteps: 326,861,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 326861958...
Checkpoint 326861958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,854.20675
Policy Entropy: 0.75655
Value Function Loss: 0.05104

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03489
Policy Update Magnitude: 0.03086
Value Function Update Magnitude: 0.05455

Collected Steps per Second: 19,488.38682
Overall Steps per Second: 14,590.38470

Timestep Collection Time: 2.56799
Timestep Consumption Time: 0.86208
PPO Batch Consumption Time: 0.04474
Total Iteration Time: 3.43007

Cumulative Model Updates: 19,577
Cumulative Timesteps: 326,912,004

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,904.22606
Policy Entropy: 0.75925
Value Function Loss: 0.04927

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01313
Policy Update Magnitude: 0.03024
Value Function Update Magnitude: 0.05523

Collected Steps per Second: 18,250.90108
Overall Steps per Second: 13,673.30204

Timestep Collection Time: 2.74134
Timestep Consumption Time: 0.91776
PPO Batch Consumption Time: 0.09266
Total Iteration Time: 3.65910

Cumulative Model Updates: 19,580
Cumulative Timesteps: 326,962,036

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 326962036...
Checkpoint 326962036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,311.02349
Policy Entropy: 0.75640
Value Function Loss: 0.04603

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01454
Policy Update Magnitude: 0.03362
Value Function Update Magnitude: 0.05458

Collected Steps per Second: 21,305.89720
Overall Steps per Second: 16,646.28955

Timestep Collection Time: 2.34743
Timestep Consumption Time: 0.65709
PPO Batch Consumption Time: 0.03041
Total Iteration Time: 3.00451

Cumulative Model Updates: 19,583
Cumulative Timesteps: 327,012,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,115.30314
Policy Entropy: 0.76062
Value Function Loss: 0.04835

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01683
Policy Update Magnitude: 0.03574
Value Function Update Magnitude: 0.04859

Collected Steps per Second: 22,465.85437
Overall Steps per Second: 16,232.79197

Timestep Collection Time: 2.22613
Timestep Consumption Time: 0.85479
PPO Batch Consumption Time: 0.07305
Total Iteration Time: 3.08092

Cumulative Model Updates: 19,586
Cumulative Timesteps: 327,062,062

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 327062062...
Checkpoint 327062062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,396.58484
Policy Entropy: 0.75384
Value Function Loss: 0.04739

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01259
Policy Update Magnitude: 0.03407
Value Function Update Magnitude: 0.04862

Collected Steps per Second: 21,575.71558
Overall Steps per Second: 16,010.99653

Timestep Collection Time: 2.31863
Timestep Consumption Time: 0.80585
PPO Batch Consumption Time: 0.05853
Total Iteration Time: 3.12448

Cumulative Model Updates: 19,589
Cumulative Timesteps: 327,112,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,909.33379
Policy Entropy: 0.74813
Value Function Loss: 0.04859

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01605
Policy Update Magnitude: 0.03657
Value Function Update Magnitude: 0.05610

Collected Steps per Second: 17,901.11998
Overall Steps per Second: 13,666.25492

Timestep Collection Time: 2.79480
Timestep Consumption Time: 0.86604
PPO Batch Consumption Time: 0.07612
Total Iteration Time: 3.66084

Cumulative Model Updates: 19,592
Cumulative Timesteps: 327,162,118

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 327162118...
Checkpoint 327162118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,992.45447
Policy Entropy: 0.73948
Value Function Loss: 0.05029

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01946
Policy Update Magnitude: 0.03675
Value Function Update Magnitude: 0.05611

Collected Steps per Second: 20,013.01382
Overall Steps per Second: 15,186.15384

Timestep Collection Time: 2.49857
Timestep Consumption Time: 0.79416
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 3.29274

Cumulative Model Updates: 19,595
Cumulative Timesteps: 327,212,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,764.06814
Policy Entropy: 0.75201
Value Function Loss: 0.04406

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03425
Policy Update Magnitude: 0.03305
Value Function Update Magnitude: 0.06066

Collected Steps per Second: 18,151.43517
Overall Steps per Second: 13,315.81456

Timestep Collection Time: 2.75615
Timestep Consumption Time: 1.00089
PPO Batch Consumption Time: 0.09401
Total Iteration Time: 3.75704

Cumulative Model Updates: 19,598
Cumulative Timesteps: 327,262,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 327262150...
Checkpoint 327262150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,551.08036
Policy Entropy: 0.75808
Value Function Loss: 0.04819

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02029
Policy Update Magnitude: 0.03456
Value Function Update Magnitude: 0.06767

Collected Steps per Second: 19,238.25080
Overall Steps per Second: 14,841.88441

Timestep Collection Time: 2.60024
Timestep Consumption Time: 0.77023
PPO Batch Consumption Time: 0.03056
Total Iteration Time: 3.37046

Cumulative Model Updates: 19,601
Cumulative Timesteps: 327,312,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,010.90448
Policy Entropy: 0.77074
Value Function Loss: 0.03933

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01970
Policy Update Magnitude: 0.03132
Value Function Update Magnitude: 0.06948

Collected Steps per Second: 17,837.95588
Overall Steps per Second: 13,950.44708

Timestep Collection Time: 2.80436
Timestep Consumption Time: 0.78148
PPO Batch Consumption Time: 0.03335
Total Iteration Time: 3.58583

Cumulative Model Updates: 19,604
Cumulative Timesteps: 327,362,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 327362198...
Checkpoint 327362198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,115.95402
Policy Entropy: 0.77077
Value Function Loss: 0.04037

Mean KL Divergence: 0.00124
SB3 Clip Fraction: 0.01039
Policy Update Magnitude: 0.03118
Value Function Update Magnitude: 0.07307

Collected Steps per Second: 17,802.40477
Overall Steps per Second: 13,268.34512

Timestep Collection Time: 2.80906
Timestep Consumption Time: 0.95991
PPO Batch Consumption Time: 0.06840
Total Iteration Time: 3.76897

Cumulative Model Updates: 19,607
Cumulative Timesteps: 327,412,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,327.41414
Policy Entropy: 0.75924
Value Function Loss: 0.04987

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01684
Policy Update Magnitude: 0.03173
Value Function Update Magnitude: 0.07371

Collected Steps per Second: 18,279.66135
Overall Steps per Second: 14,083.78121

Timestep Collection Time: 2.73594
Timestep Consumption Time: 0.81510
PPO Batch Consumption Time: 0.05912
Total Iteration Time: 3.55103

Cumulative Model Updates: 19,610
Cumulative Timesteps: 327,462,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 327462218...
Checkpoint 327462218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,495.94119
Policy Entropy: 0.75290
Value Function Loss: 0.05601

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03396
Policy Update Magnitude: 0.03155
Value Function Update Magnitude: 0.07593

Collected Steps per Second: 20,429.08014
Overall Steps per Second: 15,149.49843

Timestep Collection Time: 2.44749
Timestep Consumption Time: 0.85295
PPO Batch Consumption Time: 0.06388
Total Iteration Time: 3.30044

Cumulative Model Updates: 19,613
Cumulative Timesteps: 327,512,218

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,798.40333
Policy Entropy: 0.74539
Value Function Loss: 0.05989

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.03120
Value Function Update Magnitude: 0.06830

Collected Steps per Second: 18,137.06288
Overall Steps per Second: 14,328.03005

Timestep Collection Time: 2.75888
Timestep Consumption Time: 0.73343
PPO Batch Consumption Time: 0.03069
Total Iteration Time: 3.49232

Cumulative Model Updates: 19,616
Cumulative Timesteps: 327,562,256

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 327562256...
Checkpoint 327562256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,920.12521
Policy Entropy: 0.74780
Value Function Loss: 0.05656

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04649
Policy Update Magnitude: 0.02959
Value Function Update Magnitude: 0.06876

Collected Steps per Second: 21,254.46293
Overall Steps per Second: 15,764.26688

Timestep Collection Time: 2.35311
Timestep Consumption Time: 0.81951
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 3.17262

Cumulative Model Updates: 19,619
Cumulative Timesteps: 327,612,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,202.98184
Policy Entropy: 0.73613
Value Function Loss: 0.05713

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03316
Policy Update Magnitude: 0.03371
Value Function Update Magnitude: 0.07076

Collected Steps per Second: 20,325.56349
Overall Steps per Second: 15,169.62953

Timestep Collection Time: 2.45996
Timestep Consumption Time: 0.83610
PPO Batch Consumption Time: 0.04915
Total Iteration Time: 3.29606

Cumulative Model Updates: 19,622
Cumulative Timesteps: 327,662,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 327662270...
Checkpoint 327662270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,065.80307
Policy Entropy: 0.74252
Value Function Loss: 0.05743

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03546
Policy Update Magnitude: 0.03591
Value Function Update Magnitude: 0.06929

Collected Steps per Second: 17,983.18999
Overall Steps per Second: 14,172.96653

Timestep Collection Time: 2.78082
Timestep Consumption Time: 0.74759
PPO Batch Consumption Time: 0.02979
Total Iteration Time: 3.52841

Cumulative Model Updates: 19,625
Cumulative Timesteps: 327,712,278

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,640.24374
Policy Entropy: 0.75165
Value Function Loss: 0.04561

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.06542
Policy Update Magnitude: 0.03611
Value Function Update Magnitude: 0.05736

Collected Steps per Second: 20,032.36058
Overall Steps per Second: 15,340.89707

Timestep Collection Time: 2.49736
Timestep Consumption Time: 0.76373
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 3.26109

Cumulative Model Updates: 19,628
Cumulative Timesteps: 327,762,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 327762306...
Checkpoint 327762306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,283.98743
Policy Entropy: 0.76203
Value Function Loss: 0.04296

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04890
Policy Update Magnitude: 0.03543
Value Function Update Magnitude: 0.04653

Collected Steps per Second: 17,392.88295
Overall Steps per Second: 12,702.12301

Timestep Collection Time: 2.87761
Timestep Consumption Time: 1.06267
PPO Batch Consumption Time: 0.10354
Total Iteration Time: 3.94029

Cumulative Model Updates: 19,631
Cumulative Timesteps: 327,812,356

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,278.54860
Policy Entropy: 0.76060
Value Function Loss: 0.04255

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04611
Policy Update Magnitude: 0.03235
Value Function Update Magnitude: 0.04690

Collected Steps per Second: 18,858.62716
Overall Steps per Second: 14,125.76755

Timestep Collection Time: 2.65322
Timestep Consumption Time: 0.88896
PPO Batch Consumption Time: 0.07039
Total Iteration Time: 3.54218

Cumulative Model Updates: 19,634
Cumulative Timesteps: 327,862,392

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 327862392...
Checkpoint 327862392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,176.21313
Policy Entropy: 0.75996
Value Function Loss: 0.05045

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01209
Policy Update Magnitude: 0.03521
Value Function Update Magnitude: 0.04528

Collected Steps per Second: 19,280.24456
Overall Steps per Second: 14,473.58766

Timestep Collection Time: 2.59333
Timestep Consumption Time: 0.86124
PPO Batch Consumption Time: 0.06036
Total Iteration Time: 3.45457

Cumulative Model Updates: 19,637
Cumulative Timesteps: 327,912,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,590.21286
Policy Entropy: 0.76491
Value Function Loss: 0.04608

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.03356
Value Function Update Magnitude: 0.04645

Collected Steps per Second: 17,057.89806
Overall Steps per Second: 13,209.16584

Timestep Collection Time: 2.93143
Timestep Consumption Time: 0.85413
PPO Batch Consumption Time: 0.05437
Total Iteration Time: 3.78555

Cumulative Model Updates: 19,640
Cumulative Timesteps: 327,962,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 327962396...
Checkpoint 327962396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,807.66592
Policy Entropy: 0.76395
Value Function Loss: 0.05403

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.01812
Policy Update Magnitude: 0.03360
Value Function Update Magnitude: 0.04584

Collected Steps per Second: 17,097.98335
Overall Steps per Second: 12,997.59345

Timestep Collection Time: 2.92467
Timestep Consumption Time: 0.92266
PPO Batch Consumption Time: 0.06761
Total Iteration Time: 3.84733

Cumulative Model Updates: 19,643
Cumulative Timesteps: 328,012,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,058.47413
Policy Entropy: 0.77134
Value Function Loss: 0.05119

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02449
Policy Update Magnitude: 0.03355
Value Function Update Magnitude: 0.04534

Collected Steps per Second: 20,556.14481
Overall Steps per Second: 15,673.50020

Timestep Collection Time: 2.43246
Timestep Consumption Time: 0.75777
PPO Batch Consumption Time: 0.03125
Total Iteration Time: 3.19023

Cumulative Model Updates: 19,646
Cumulative Timesteps: 328,062,404

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 328062404...
Checkpoint 328062404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,782.45051
Policy Entropy: 0.76474
Value Function Loss: 0.05563

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.03496
Value Function Update Magnitude: 0.04985

Collected Steps per Second: 21,377.53174
Overall Steps per Second: 16,238.27650

Timestep Collection Time: 2.34031
Timestep Consumption Time: 0.74068
PPO Batch Consumption Time: 0.03006
Total Iteration Time: 3.08099

Cumulative Model Updates: 19,649
Cumulative Timesteps: 328,112,434

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,983.79506
Policy Entropy: 0.76953
Value Function Loss: 0.04954

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02639
Policy Update Magnitude: 0.03343
Value Function Update Magnitude: 0.05072

Collected Steps per Second: 21,850.46568
Overall Steps per Second: 16,586.25184

Timestep Collection Time: 2.28901
Timestep Consumption Time: 0.72650
PPO Batch Consumption Time: 0.02845
Total Iteration Time: 3.01551

Cumulative Model Updates: 19,652
Cumulative Timesteps: 328,162,450

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 328162450...
Checkpoint 328162450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,952.98502
Policy Entropy: 0.75329
Value Function Loss: 0.05555

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03875
Policy Update Magnitude: 0.03393
Value Function Update Magnitude: 0.06073

Collected Steps per Second: 22,086.94030
Overall Steps per Second: 15,798.36066

Timestep Collection Time: 2.26451
Timestep Consumption Time: 0.90139
PPO Batch Consumption Time: 0.08261
Total Iteration Time: 3.16590

Cumulative Model Updates: 19,655
Cumulative Timesteps: 328,212,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,536.16068
Policy Entropy: 0.75926
Value Function Loss: 0.05456

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04870
Policy Update Magnitude: 0.03397
Value Function Update Magnitude: 0.05558

Collected Steps per Second: 22,747.46876
Overall Steps per Second: 16,687.48293

Timestep Collection Time: 2.19901
Timestep Consumption Time: 0.79856
PPO Batch Consumption Time: 0.05941
Total Iteration Time: 2.99758

Cumulative Model Updates: 19,658
Cumulative Timesteps: 328,262,488

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 328262488...
Checkpoint 328262488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,321.61379
Policy Entropy: 0.76885
Value Function Loss: 0.05568

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03795
Policy Update Magnitude: 0.03446
Value Function Update Magnitude: 0.05456

Collected Steps per Second: 20,277.08283
Overall Steps per Second: 14,813.63874

Timestep Collection Time: 2.46633
Timestep Consumption Time: 0.90961
PPO Batch Consumption Time: 0.07997
Total Iteration Time: 3.37594

Cumulative Model Updates: 19,661
Cumulative Timesteps: 328,312,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,334.43914
Policy Entropy: 0.78094
Value Function Loss: 0.04928

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02896
Policy Update Magnitude: 0.03910
Value Function Update Magnitude: 0.04857

Collected Steps per Second: 22,952.24805
Overall Steps per Second: 16,561.16308

Timestep Collection Time: 2.17948
Timestep Consumption Time: 0.84108
PPO Batch Consumption Time: 0.06577
Total Iteration Time: 3.02056

Cumulative Model Updates: 19,664
Cumulative Timesteps: 328,362,522

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 328362522...
Checkpoint 328362522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,381.65572
Policy Entropy: 0.77781
Value Function Loss: 0.04986

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02894
Policy Update Magnitude: 0.03634
Value Function Update Magnitude: 0.04427

Collected Steps per Second: 19,631.97273
Overall Steps per Second: 14,582.76473

Timestep Collection Time: 2.54768
Timestep Consumption Time: 0.88212
PPO Batch Consumption Time: 0.08305
Total Iteration Time: 3.42980

Cumulative Model Updates: 19,667
Cumulative Timesteps: 328,412,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,265.94748
Policy Entropy: 0.77825
Value Function Loss: 0.04474

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01639
Policy Update Magnitude: 0.03564
Value Function Update Magnitude: 0.04177

Collected Steps per Second: 22,071.88560
Overall Steps per Second: 16,797.71116

Timestep Collection Time: 2.26560
Timestep Consumption Time: 0.71136
PPO Batch Consumption Time: 0.03076
Total Iteration Time: 2.97695

Cumulative Model Updates: 19,670
Cumulative Timesteps: 328,462,544

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 328462544...
Checkpoint 328462544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,663.82373
Policy Entropy: 0.79025
Value Function Loss: 0.04078

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02300
Policy Update Magnitude: 0.03350
Value Function Update Magnitude: 0.04556

Collected Steps per Second: 21,989.19731
Overall Steps per Second: 16,256.27422

Timestep Collection Time: 2.27503
Timestep Consumption Time: 0.80231
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 3.07733

Cumulative Model Updates: 19,673
Cumulative Timesteps: 328,512,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,754.44979
Policy Entropy: 0.80210
Value Function Loss: 0.03751

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03325
Policy Update Magnitude: 0.03052
Value Function Update Magnitude: 0.04591

Collected Steps per Second: 20,243.40998
Overall Steps per Second: 14,519.62775

Timestep Collection Time: 2.47004
Timestep Consumption Time: 0.97371
PPO Batch Consumption Time: 0.09733
Total Iteration Time: 3.44375

Cumulative Model Updates: 19,676
Cumulative Timesteps: 328,562,572

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 328562572...
Checkpoint 328562572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,342.20118
Policy Entropy: 0.80405
Value Function Loss: 0.04113

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.02891
Value Function Update Magnitude: 0.03916

Collected Steps per Second: 21,920.83964
Overall Steps per Second: 16,107.09512

Timestep Collection Time: 2.28258
Timestep Consumption Time: 0.82388
PPO Batch Consumption Time: 0.06302
Total Iteration Time: 3.10646

Cumulative Model Updates: 19,679
Cumulative Timesteps: 328,612,608

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,022.06202
Policy Entropy: 0.79497
Value Function Loss: 0.04767

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03857
Policy Update Magnitude: 0.03396
Value Function Update Magnitude: 0.04371

Collected Steps per Second: 21,941.92673
Overall Steps per Second: 15,886.49503

Timestep Collection Time: 2.28047
Timestep Consumption Time: 0.86925
PPO Batch Consumption Time: 0.06528
Total Iteration Time: 3.14972

Cumulative Model Updates: 19,682
Cumulative Timesteps: 328,662,646

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 328662646...
Checkpoint 328662646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,520.01913
Policy Entropy: 0.79253
Value Function Loss: 0.04926

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.04105
Policy Update Magnitude: 0.03790
Value Function Update Magnitude: 0.04735

Collected Steps per Second: 21,012.79576
Overall Steps per Second: 15,567.61232

Timestep Collection Time: 2.38093
Timestep Consumption Time: 0.83279
PPO Batch Consumption Time: 0.06221
Total Iteration Time: 3.21372

Cumulative Model Updates: 19,685
Cumulative Timesteps: 328,712,676

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,795.12518
Policy Entropy: 0.79635
Value Function Loss: 0.04552

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.05390
Policy Update Magnitude: 0.03535
Value Function Update Magnitude: 0.05255

Collected Steps per Second: 21,892.19083
Overall Steps per Second: 15,491.53994

Timestep Collection Time: 2.28419
Timestep Consumption Time: 0.94376
PPO Batch Consumption Time: 0.10670
Total Iteration Time: 3.22796

Cumulative Model Updates: 19,688
Cumulative Timesteps: 328,762,682

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 328762682...
Checkpoint 328762682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,828.15355
Policy Entropy: 0.79187
Value Function Loss: 0.04763

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.04199
Policy Update Magnitude: 0.03379
Value Function Update Magnitude: 0.04667

Collected Steps per Second: 21,489.47166
Overall Steps per Second: 16,308.59473

Timestep Collection Time: 2.32812
Timestep Consumption Time: 0.73959
PPO Batch Consumption Time: 0.06145
Total Iteration Time: 3.06771

Cumulative Model Updates: 19,691
Cumulative Timesteps: 328,812,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,122.49523
Policy Entropy: 0.78975
Value Function Loss: 0.05139

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04317
Policy Update Magnitude: 0.03463
Value Function Update Magnitude: 0.04805

Collected Steps per Second: 19,527.06403
Overall Steps per Second: 14,715.54487

Timestep Collection Time: 2.56157
Timestep Consumption Time: 0.83755
PPO Batch Consumption Time: 0.08745
Total Iteration Time: 3.39913

Cumulative Model Updates: 19,694
Cumulative Timesteps: 328,862,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 328862732...
Checkpoint 328862732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,649.75988
Policy Entropy: 0.79157
Value Function Loss: 0.04844

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04262
Policy Update Magnitude: 0.03628
Value Function Update Magnitude: 0.05318

Collected Steps per Second: 21,424.73273
Overall Steps per Second: 16,213.28117

Timestep Collection Time: 2.33375
Timestep Consumption Time: 0.75014
PPO Batch Consumption Time: 0.06019
Total Iteration Time: 3.08389

Cumulative Model Updates: 19,697
Cumulative Timesteps: 328,912,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,170.47185
Policy Entropy: 0.80521
Value Function Loss: 0.04309

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03659
Policy Update Magnitude: 0.03239
Value Function Update Magnitude: 0.04550

Collected Steps per Second: 19,729.71591
Overall Steps per Second: 14,444.82690

Timestep Collection Time: 2.53476
Timestep Consumption Time: 0.92738
PPO Batch Consumption Time: 0.10065
Total Iteration Time: 3.46214

Cumulative Model Updates: 19,700
Cumulative Timesteps: 328,962,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 328962742...
Checkpoint 328962742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,728.75858
Policy Entropy: 0.81695
Value Function Loss: 0.03888

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.03118
Value Function Update Magnitude: 0.04138

Collected Steps per Second: 21,445.25922
Overall Steps per Second: 16,514.79626

Timestep Collection Time: 2.33254
Timestep Consumption Time: 0.69638
PPO Batch Consumption Time: 0.03172
Total Iteration Time: 3.02892

Cumulative Model Updates: 19,703
Cumulative Timesteps: 329,012,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,782.11542
Policy Entropy: 0.80759
Value Function Loss: 0.04367

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01731
Policy Update Magnitude: 0.03148
Value Function Update Magnitude: 0.04207

Collected Steps per Second: 22,035.05473
Overall Steps per Second: 16,216.53172

Timestep Collection Time: 2.26957
Timestep Consumption Time: 0.81432
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 3.08389

Cumulative Model Updates: 19,706
Cumulative Timesteps: 329,062,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 329062774...
Checkpoint 329062774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,816.78008
Policy Entropy: 0.81596
Value Function Loss: 0.04754

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02337
Policy Update Magnitude: 0.03136
Value Function Update Magnitude: 0.04687

Collected Steps per Second: 19,791.31041
Overall Steps per Second: 14,619.01045

Timestep Collection Time: 2.52717
Timestep Consumption Time: 0.89413
PPO Batch Consumption Time: 0.07876
Total Iteration Time: 3.42130

Cumulative Model Updates: 19,709
Cumulative Timesteps: 329,112,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,791.13924
Policy Entropy: 0.81667
Value Function Loss: 0.05126

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01713
Policy Update Magnitude: 0.02980
Value Function Update Magnitude: 0.05006

Collected Steps per Second: 21,896.91815
Overall Steps per Second: 16,365.61351

Timestep Collection Time: 2.28452
Timestep Consumption Time: 0.77213
PPO Batch Consumption Time: 0.05863
Total Iteration Time: 3.05665

Cumulative Model Updates: 19,712
Cumulative Timesteps: 329,162,814

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 329162814...
Checkpoint 329162814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,937.84733
Policy Entropy: 0.81900
Value Function Loss: 0.05153

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01833
Policy Update Magnitude: 0.03100
Value Function Update Magnitude: 0.04920

Collected Steps per Second: 20,860.67166
Overall Steps per Second: 15,055.29171

Timestep Collection Time: 2.39705
Timestep Consumption Time: 0.92431
PPO Batch Consumption Time: 0.07919
Total Iteration Time: 3.32136

Cumulative Model Updates: 19,715
Cumulative Timesteps: 329,212,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,500.95546
Policy Entropy: 0.81660
Value Function Loss: 0.04734

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03705
Policy Update Magnitude: 0.03330
Value Function Update Magnitude: 0.04770

Collected Steps per Second: 22,574.70343
Overall Steps per Second: 16,505.39557

Timestep Collection Time: 2.21691
Timestep Consumption Time: 0.81519
PPO Batch Consumption Time: 0.05979
Total Iteration Time: 3.03210

Cumulative Model Updates: 19,718
Cumulative Timesteps: 329,262,864

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 329262864...
Checkpoint 329262864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,309.74200
Policy Entropy: 0.81423
Value Function Loss: 0.04491

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03085
Policy Update Magnitude: 0.03194
Value Function Update Magnitude: 0.04582

Collected Steps per Second: 20,006.59071
Overall Steps per Second: 14,236.30327

Timestep Collection Time: 2.49928
Timestep Consumption Time: 1.01301
PPO Batch Consumption Time: 0.11563
Total Iteration Time: 3.51229

Cumulative Model Updates: 19,721
Cumulative Timesteps: 329,312,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,114.63067
Policy Entropy: 0.81978
Value Function Loss: 0.03869

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.02919
Value Function Update Magnitude: 0.04040

Collected Steps per Second: 22,693.97559
Overall Steps per Second: 16,670.65372

Timestep Collection Time: 2.20446
Timestep Consumption Time: 0.79650
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 3.00096

Cumulative Model Updates: 19,724
Cumulative Timesteps: 329,362,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 329362894...
Checkpoint 329362894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,605.02771
Policy Entropy: 0.82271
Value Function Loss: 0.03734

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 0.02865
Value Function Update Magnitude: 0.04493

Collected Steps per Second: 19,348.89054
Overall Steps per Second: 13,948.96420

Timestep Collection Time: 2.58588
Timestep Consumption Time: 1.00105
PPO Batch Consumption Time: 0.11497
Total Iteration Time: 3.58693

Cumulative Model Updates: 19,727
Cumulative Timesteps: 329,412,928

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,290.98100
Policy Entropy: 0.81731
Value Function Loss: 0.04287

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02293
Policy Update Magnitude: 0.03069
Value Function Update Magnitude: 0.05437

Collected Steps per Second: 22,247.22208
Overall Steps per Second: 16,056.85699

Timestep Collection Time: 2.24819
Timestep Consumption Time: 0.86674
PPO Batch Consumption Time: 0.06699
Total Iteration Time: 3.11493

Cumulative Model Updates: 19,730
Cumulative Timesteps: 329,462,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 329462944...
Checkpoint 329462944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,230.43911
Policy Entropy: 0.81314
Value Function Loss: 0.04370

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03063
Policy Update Magnitude: 0.02783
Value Function Update Magnitude: 0.05306

Collected Steps per Second: 22,450.84520
Overall Steps per Second: 15,412.58541

Timestep Collection Time: 2.22896
Timestep Consumption Time: 1.01787
PPO Batch Consumption Time: 0.11532
Total Iteration Time: 3.24683

Cumulative Model Updates: 19,733
Cumulative Timesteps: 329,512,986

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,321.78014
Policy Entropy: 0.80212
Value Function Loss: 0.04723

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.02996
Value Function Update Magnitude: 0.05478

Collected Steps per Second: 22,571.25313
Overall Steps per Second: 16,582.90754

Timestep Collection Time: 2.21530
Timestep Consumption Time: 0.79998
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 3.01527

Cumulative Model Updates: 19,736
Cumulative Timesteps: 329,562,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 329562988...
Checkpoint 329562988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,791.22761
Policy Entropy: 0.79310
Value Function Loss: 0.04419

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02336
Policy Update Magnitude: 0.02875
Value Function Update Magnitude: 0.04774

Collected Steps per Second: 19,556.47830
Overall Steps per Second: 13,984.68230

Timestep Collection Time: 2.55874
Timestep Consumption Time: 1.01946
PPO Batch Consumption Time: 0.11166
Total Iteration Time: 3.57820

Cumulative Model Updates: 19,739
Cumulative Timesteps: 329,613,028

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,604.94537
Policy Entropy: 0.79591
Value Function Loss: 0.04427

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01933
Policy Update Magnitude: 0.02624
Value Function Update Magnitude: 0.04392

Collected Steps per Second: 21,740.72072
Overall Steps per Second: 16,026.41998

Timestep Collection Time: 2.30066
Timestep Consumption Time: 0.82031
PPO Batch Consumption Time: 0.06152
Total Iteration Time: 3.12097

Cumulative Model Updates: 19,742
Cumulative Timesteps: 329,663,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 329663046...
Checkpoint 329663046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,720.14063
Policy Entropy: 0.78991
Value Function Loss: 0.03866

Mean KL Divergence: 0.00128
SB3 Clip Fraction: 0.01067
Policy Update Magnitude: 0.02762
Value Function Update Magnitude: 0.04358

Collected Steps per Second: 22,188.31035
Overall Steps per Second: 16,318.90011

Timestep Collection Time: 2.25362
Timestep Consumption Time: 0.81056
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 3.06418

Cumulative Model Updates: 19,745
Cumulative Timesteps: 329,713,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,061.53628
Policy Entropy: 0.79408
Value Function Loss: 0.03779

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01640
Policy Update Magnitude: 0.03017
Value Function Update Magnitude: 0.04154

Collected Steps per Second: 19,566.36191
Overall Steps per Second: 14,015.43070

Timestep Collection Time: 2.55622
Timestep Consumption Time: 1.01241
PPO Batch Consumption Time: 0.11745
Total Iteration Time: 3.56864

Cumulative Model Updates: 19,748
Cumulative Timesteps: 329,763,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 329763066...
Checkpoint 329763066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,600.27571
Policy Entropy: 0.79016
Value Function Loss: 0.04314

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01339
Policy Update Magnitude: 0.02755
Value Function Update Magnitude: 0.03562

Collected Steps per Second: 22,081.29855
Overall Steps per Second: 16,267.73909

Timestep Collection Time: 2.26572
Timestep Consumption Time: 0.80969
PPO Batch Consumption Time: 0.06188
Total Iteration Time: 3.07541

Cumulative Model Updates: 19,751
Cumulative Timesteps: 329,813,096

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,535.24981
Policy Entropy: 0.79251
Value Function Loss: 0.05065

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02507
Policy Update Magnitude: 0.02896
Value Function Update Magnitude: 0.03063

Collected Steps per Second: 22,142.02857
Overall Steps per Second: 15,832.30305

Timestep Collection Time: 2.25914
Timestep Consumption Time: 0.90035
PPO Batch Consumption Time: 0.07877
Total Iteration Time: 3.15949

Cumulative Model Updates: 19,754
Cumulative Timesteps: 329,863,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 329863118...
Checkpoint 329863118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,609.56890
Policy Entropy: 0.78768
Value Function Loss: 0.05694

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04507
Policy Update Magnitude: 0.03011
Value Function Update Magnitude: 0.03529

Collected Steps per Second: 21,741.66638
Overall Steps per Second: 16,024.37560

Timestep Collection Time: 2.30084
Timestep Consumption Time: 0.82091
PPO Batch Consumption Time: 0.06173
Total Iteration Time: 3.12174

Cumulative Model Updates: 19,757
Cumulative Timesteps: 329,913,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,726.07626
Policy Entropy: 0.78106
Value Function Loss: 0.05537

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04430
Policy Update Magnitude: 0.03070
Value Function Update Magnitude: 0.04228

Collected Steps per Second: 20,197.81160
Overall Steps per Second: 14,693.60594

Timestep Collection Time: 2.47641
Timestep Consumption Time: 0.92766
PPO Batch Consumption Time: 0.09070
Total Iteration Time: 3.40407

Cumulative Model Updates: 19,760
Cumulative Timesteps: 329,963,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 329963160...
Checkpoint 329963160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,067.01118
Policy Entropy: 0.77586
Value Function Loss: 0.04990

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05606
Policy Update Magnitude: 0.03235
Value Function Update Magnitude: 0.03896

Collected Steps per Second: 21,531.71309
Overall Steps per Second: 15,933.29256

Timestep Collection Time: 2.32318
Timestep Consumption Time: 0.81629
PPO Batch Consumption Time: 0.06151
Total Iteration Time: 3.13946

Cumulative Model Updates: 19,763
Cumulative Timesteps: 330,013,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,192.29504
Policy Entropy: 0.77302
Value Function Loss: 0.04412

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04564
Policy Update Magnitude: 0.03031
Value Function Update Magnitude: 0.04106

Collected Steps per Second: 20,119.98096
Overall Steps per Second: 14,572.02389

Timestep Collection Time: 2.48738
Timestep Consumption Time: 0.94701
PPO Batch Consumption Time: 0.09446
Total Iteration Time: 3.43439

Cumulative Model Updates: 19,766
Cumulative Timesteps: 330,063,228

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 330063228...
Checkpoint 330063228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,288.96801
Policy Entropy: 0.77452
Value Function Loss: 0.04032

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06800
Policy Update Magnitude: 0.02536
Value Function Update Magnitude: 0.04448

Collected Steps per Second: 21,823.57359
Overall Steps per Second: 15,954.22755

Timestep Collection Time: 2.29238
Timestep Consumption Time: 0.84334
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 3.13572

Cumulative Model Updates: 19,769
Cumulative Timesteps: 330,113,256

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,915.68536
Policy Entropy: 0.77520
Value Function Loss: 0.04625

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04323
Policy Update Magnitude: 0.02579
Value Function Update Magnitude: 0.03879

Collected Steps per Second: 20,417.27354
Overall Steps per Second: 14,509.07739

Timestep Collection Time: 2.44891
Timestep Consumption Time: 0.99721
PPO Batch Consumption Time: 0.10183
Total Iteration Time: 3.44612

Cumulative Model Updates: 19,772
Cumulative Timesteps: 330,163,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 330163256...
Checkpoint 330163256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,397.71091
Policy Entropy: 0.78355
Value Function Loss: 0.04587

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04814
Policy Update Magnitude: 0.02718
Value Function Update Magnitude: 0.03880

Collected Steps per Second: 22,201.95181
Overall Steps per Second: 16,233.29510

Timestep Collection Time: 2.25232
Timestep Consumption Time: 0.82813
PPO Batch Consumption Time: 0.05911
Total Iteration Time: 3.08046

Cumulative Model Updates: 19,775
Cumulative Timesteps: 330,213,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,680.32838
Policy Entropy: 0.77555
Value Function Loss: 0.05051

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03038
Policy Update Magnitude: 0.02953
Value Function Update Magnitude: 0.03855

Collected Steps per Second: 22,440.14372
Overall Steps per Second: 16,436.88522

Timestep Collection Time: 2.22842
Timestep Consumption Time: 0.81389
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 3.04230

Cumulative Model Updates: 19,778
Cumulative Timesteps: 330,263,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 330263268...
Checkpoint 330263268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,924.15792
Policy Entropy: 0.77783
Value Function Loss: 0.04741

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05480
Policy Update Magnitude: 0.02855
Value Function Update Magnitude: 0.04341

Collected Steps per Second: 19,372.54346
Overall Steps per Second: 13,833.70700

Timestep Collection Time: 2.58097
Timestep Consumption Time: 1.03339
PPO Batch Consumption Time: 0.12227
Total Iteration Time: 3.61436

Cumulative Model Updates: 19,781
Cumulative Timesteps: 330,313,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,582.07391
Policy Entropy: 0.76284
Value Function Loss: 0.04577

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04976
Policy Update Magnitude: 0.02625
Value Function Update Magnitude: 0.03925

Collected Steps per Second: 21,906.63262
Overall Steps per Second: 16,510.76593

Timestep Collection Time: 2.28433
Timestep Consumption Time: 0.74654
PPO Batch Consumption Time: 0.05999
Total Iteration Time: 3.03087

Cumulative Model Updates: 19,784
Cumulative Timesteps: 330,363,310

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 330363310...
Checkpoint 330363310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,603.50182
Policy Entropy: 0.77258
Value Function Loss: 0.04884

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05469
Policy Update Magnitude: 0.02551
Value Function Update Magnitude: 0.03423

Collected Steps per Second: 19,581.26943
Overall Steps per Second: 14,161.10385

Timestep Collection Time: 2.55346
Timestep Consumption Time: 0.97734
PPO Batch Consumption Time: 0.12806
Total Iteration Time: 3.53080

Cumulative Model Updates: 19,787
Cumulative Timesteps: 330,413,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,938.71558
Policy Entropy: 0.76348
Value Function Loss: 0.05473

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03518
Policy Update Magnitude: 0.02912
Value Function Update Magnitude: 0.03524

Collected Steps per Second: 21,723.73512
Overall Steps per Second: 16,454.79885

Timestep Collection Time: 2.30237
Timestep Consumption Time: 0.73723
PPO Batch Consumption Time: 0.06128
Total Iteration Time: 3.03960

Cumulative Model Updates: 19,790
Cumulative Timesteps: 330,463,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 330463326...
Checkpoint 330463326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,917.18539
Policy Entropy: 0.76970
Value Function Loss: 0.06336

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04915
Policy Update Magnitude: 0.02882
Value Function Update Magnitude: 0.04587

Collected Steps per Second: 19,651.46584
Overall Steps per Second: 14,732.05801

Timestep Collection Time: 2.54688
Timestep Consumption Time: 0.85047
PPO Batch Consumption Time: 0.08819
Total Iteration Time: 3.39735

Cumulative Model Updates: 19,793
Cumulative Timesteps: 330,513,376

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,296.19678
Policy Entropy: 0.75884
Value Function Loss: 0.06615

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.06191
Policy Update Magnitude: 0.02879
Value Function Update Magnitude: 0.05443

Collected Steps per Second: 21,134.86231
Overall Steps per Second: 16,153.84518

Timestep Collection Time: 2.36595
Timestep Consumption Time: 0.72954
PPO Batch Consumption Time: 0.06143
Total Iteration Time: 3.09549

Cumulative Model Updates: 19,796
Cumulative Timesteps: 330,563,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 330563380...
Checkpoint 330563380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,911.79761
Policy Entropy: 0.76000
Value Function Loss: 0.06669

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04276
Policy Update Magnitude: 0.03053
Value Function Update Magnitude: 0.05619

Collected Steps per Second: 20,042.11529
Overall Steps per Second: 14,661.79625

Timestep Collection Time: 2.49525
Timestep Consumption Time: 0.91566
PPO Batch Consumption Time: 0.11482
Total Iteration Time: 3.41091

Cumulative Model Updates: 19,799
Cumulative Timesteps: 330,613,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,011.00062
Policy Entropy: 0.75972
Value Function Loss: 0.06374

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02698
Policy Update Magnitude: 0.03444
Value Function Update Magnitude: 0.05321

Collected Steps per Second: 21,910.25119
Overall Steps per Second: 16,668.14886

Timestep Collection Time: 2.28313
Timestep Consumption Time: 0.71804
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 3.00117

Cumulative Model Updates: 19,802
Cumulative Timesteps: 330,663,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 330663414...
Checkpoint 330663414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,596.32696
Policy Entropy: 0.77001
Value Function Loss: 0.05252

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.06085
Policy Update Magnitude: 0.03225
Value Function Update Magnitude: 0.05447

Collected Steps per Second: 19,265.82313
Overall Steps per Second: 13,998.22220

Timestep Collection Time: 2.59589
Timestep Consumption Time: 0.97685
PPO Batch Consumption Time: 0.11810
Total Iteration Time: 3.57274

Cumulative Model Updates: 19,805
Cumulative Timesteps: 330,713,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,681.22524
Policy Entropy: 0.78177
Value Function Loss: 0.04710

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05457
Policy Update Magnitude: 0.02820
Value Function Update Magnitude: 0.05019

Collected Steps per Second: 22,442.62827
Overall Steps per Second: 16,678.71170

Timestep Collection Time: 2.22817
Timestep Consumption Time: 0.77002
PPO Batch Consumption Time: 0.05776
Total Iteration Time: 2.99819

Cumulative Model Updates: 19,808
Cumulative Timesteps: 330,763,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 330763432...
Checkpoint 330763432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,664.17657
Policy Entropy: 0.78857
Value Function Loss: 0.04728

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04527
Policy Update Magnitude: 0.02872
Value Function Update Magnitude: 0.04404

Collected Steps per Second: 20,271.93973
Overall Steps per Second: 14,746.04273

Timestep Collection Time: 2.46844
Timestep Consumption Time: 0.92502
PPO Batch Consumption Time: 0.10029
Total Iteration Time: 3.39345

Cumulative Model Updates: 19,811
Cumulative Timesteps: 330,813,472

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,120.73992
Policy Entropy: 0.78657
Value Function Loss: 0.05144

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03221
Policy Update Magnitude: 0.03264
Value Function Update Magnitude: 0.04757

Collected Steps per Second: 22,380.45257
Overall Steps per Second: 16,329.98756

Timestep Collection Time: 2.23543
Timestep Consumption Time: 0.82826
PPO Batch Consumption Time: 0.06410
Total Iteration Time: 3.06369

Cumulative Model Updates: 19,814
Cumulative Timesteps: 330,863,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 330863502...
Checkpoint 330863502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,334.71303
Policy Entropy: 0.79904
Value Function Loss: 0.04991

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.03097
Value Function Update Magnitude: 0.04353

Collected Steps per Second: 21,912.97656
Overall Steps per Second: 15,351.95728

Timestep Collection Time: 2.28175
Timestep Consumption Time: 0.97516
PPO Batch Consumption Time: 0.02877
Total Iteration Time: 3.25691

Cumulative Model Updates: 19,817
Cumulative Timesteps: 330,913,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,934.42377
Policy Entropy: 0.78257
Value Function Loss: 0.05447

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02047
Policy Update Magnitude: 0.03179
Value Function Update Magnitude: 0.04291

Collected Steps per Second: 22,584.66326
Overall Steps per Second: 16,493.70312

Timestep Collection Time: 2.21522
Timestep Consumption Time: 0.81806
PPO Batch Consumption Time: 0.06257
Total Iteration Time: 3.03328

Cumulative Model Updates: 19,820
Cumulative Timesteps: 330,963,532

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 330963532...
Checkpoint 330963532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,145.60544
Policy Entropy: 0.78743
Value Function Loss: 0.05812

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02157
Policy Update Magnitude: 0.03109
Value Function Update Magnitude: 0.04187

Collected Steps per Second: 20,238.31090
Overall Steps per Second: 14,771.41511

Timestep Collection Time: 2.47185
Timestep Consumption Time: 0.91483
PPO Batch Consumption Time: 0.08771
Total Iteration Time: 3.38668

Cumulative Model Updates: 19,823
Cumulative Timesteps: 331,013,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,362.25739
Policy Entropy: 0.77522
Value Function Loss: 0.05924

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01823
Policy Update Magnitude: 0.03128
Value Function Update Magnitude: 0.03789

Collected Steps per Second: 22,400.02050
Overall Steps per Second: 16,385.91615

Timestep Collection Time: 2.23223
Timestep Consumption Time: 0.81929
PPO Batch Consumption Time: 0.05934
Total Iteration Time: 3.05152

Cumulative Model Updates: 19,826
Cumulative Timesteps: 331,063,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 331063560...
Checkpoint 331063560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,507.91569
Policy Entropy: 0.79130
Value Function Loss: 0.05573

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02271
Policy Update Magnitude: 0.03016
Value Function Update Magnitude: 0.03404

Collected Steps per Second: 20,744.79394
Overall Steps per Second: 15,070.92551

Timestep Collection Time: 2.41053
Timestep Consumption Time: 0.90751
PPO Batch Consumption Time: 0.08905
Total Iteration Time: 3.31804

Cumulative Model Updates: 19,829
Cumulative Timesteps: 331,113,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,358.68084
Policy Entropy: 0.80306
Value Function Loss: 0.05240

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01979
Policy Update Magnitude: 0.02930
Value Function Update Magnitude: 0.03349

Collected Steps per Second: 22,165.35457
Overall Steps per Second: 16,345.91509

Timestep Collection Time: 2.25658
Timestep Consumption Time: 0.80338
PPO Batch Consumption Time: 0.05979
Total Iteration Time: 3.05997

Cumulative Model Updates: 19,832
Cumulative Timesteps: 331,163,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 331163584...
Checkpoint 331163584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,224.16729
Policy Entropy: 0.80008
Value Function Loss: 0.05182

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01691
Policy Update Magnitude: 0.03012
Value Function Update Magnitude: 0.03605

Collected Steps per Second: 20,846.64481
Overall Steps per Second: 15,085.83632

Timestep Collection Time: 2.39971
Timestep Consumption Time: 0.91638
PPO Batch Consumption Time: 0.08969
Total Iteration Time: 3.31609

Cumulative Model Updates: 19,835
Cumulative Timesteps: 331,213,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,723.54461
Policy Entropy: 0.79847
Value Function Loss: 0.05225

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03209
Policy Update Magnitude: 0.03036
Value Function Update Magnitude: 0.03752

Collected Steps per Second: 22,496.44917
Overall Steps per Second: 16,582.12928

Timestep Collection Time: 2.22328
Timestep Consumption Time: 0.79298
PPO Batch Consumption Time: 0.05909
Total Iteration Time: 3.01626

Cumulative Model Updates: 19,838
Cumulative Timesteps: 331,263,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 331263626...
Checkpoint 331263626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,301.64208
Policy Entropy: 0.78405
Value Function Loss: 0.05543

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03498
Policy Update Magnitude: 0.03325
Value Function Update Magnitude: 0.04695

Collected Steps per Second: 20,594.01341
Overall Steps per Second: 14,920.42124

Timestep Collection Time: 2.42828
Timestep Consumption Time: 0.92337
PPO Batch Consumption Time: 0.08551
Total Iteration Time: 3.35165

Cumulative Model Updates: 19,841
Cumulative Timesteps: 331,313,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,176.27490
Policy Entropy: 0.78701
Value Function Loss: 0.05152

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02425
Policy Update Magnitude: 0.03646
Value Function Update Magnitude: 0.05087

Collected Steps per Second: 21,612.21080
Overall Steps per Second: 16,403.87258

Timestep Collection Time: 2.31499
Timestep Consumption Time: 0.73502
PPO Batch Consumption Time: 0.06213
Total Iteration Time: 3.05001

Cumulative Model Updates: 19,844
Cumulative Timesteps: 331,363,666

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 331363666...
Checkpoint 331363666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,340.91646
Policy Entropy: 0.79694
Value Function Loss: 0.04753

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.01234
Policy Update Magnitude: 0.03985
Value Function Update Magnitude: 0.04898

Collected Steps per Second: 20,242.05835
Overall Steps per Second: 15,035.70733

Timestep Collection Time: 2.47178
Timestep Consumption Time: 0.85589
PPO Batch Consumption Time: 0.09251
Total Iteration Time: 3.32768

Cumulative Model Updates: 19,847
Cumulative Timesteps: 331,413,700

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,731.68631
Policy Entropy: 0.79129
Value Function Loss: 0.04668

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02239
Policy Update Magnitude: 0.03540
Value Function Update Magnitude: 0.04373

Collected Steps per Second: 21,816.12715
Overall Steps per Second: 16,508.49655

Timestep Collection Time: 2.29225
Timestep Consumption Time: 0.73698
PPO Batch Consumption Time: 0.06325
Total Iteration Time: 3.02923

Cumulative Model Updates: 19,850
Cumulative Timesteps: 331,463,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 331463708...
Checkpoint 331463708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,254.96902
Policy Entropy: 0.78877
Value Function Loss: 0.05529

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03758
Policy Update Magnitude: 0.03194
Value Function Update Magnitude: 0.03935

Collected Steps per Second: 19,251.29607
Overall Steps per Second: 14,134.73730

Timestep Collection Time: 2.59847
Timestep Consumption Time: 0.94061
PPO Batch Consumption Time: 0.11221
Total Iteration Time: 3.53908

Cumulative Model Updates: 19,853
Cumulative Timesteps: 331,513,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,727.87134
Policy Entropy: 0.78294
Value Function Loss: 0.06259

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.03210
Value Function Update Magnitude: 0.03898

Collected Steps per Second: 21,406.15007
Overall Steps per Second: 16,018.02175

Timestep Collection Time: 2.33690
Timestep Consumption Time: 0.78608
PPO Batch Consumption Time: 0.06055
Total Iteration Time: 3.12298

Cumulative Model Updates: 19,856
Cumulative Timesteps: 331,563,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 331563756...
Checkpoint 331563756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,144.91242
Policy Entropy: 0.78971
Value Function Loss: 0.06678

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01682
Policy Update Magnitude: 0.03055
Value Function Update Magnitude: 0.03673

Collected Steps per Second: 22,217.01009
Overall Steps per Second: 16,119.24178

Timestep Collection Time: 2.25116
Timestep Consumption Time: 0.85159
PPO Batch Consumption Time: 0.07473
Total Iteration Time: 3.10275

Cumulative Model Updates: 19,859
Cumulative Timesteps: 331,613,770

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,207.22373
Policy Entropy: 0.79552
Value Function Loss: 0.06239

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02259
Policy Update Magnitude: 0.03155
Value Function Update Magnitude: 0.03418

Collected Steps per Second: 22,232.56934
Overall Steps per Second: 16,465.94983

Timestep Collection Time: 2.24904
Timestep Consumption Time: 0.78765
PPO Batch Consumption Time: 0.06154
Total Iteration Time: 3.03669

Cumulative Model Updates: 19,862
Cumulative Timesteps: 331,663,772

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 331663772...
Checkpoint 331663772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,964.99704
Policy Entropy: 0.79257
Value Function Loss: 0.06618

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02942
Policy Update Magnitude: 0.03152
Value Function Update Magnitude: 0.03094

Collected Steps per Second: 22,531.86748
Overall Steps per Second: 16,675.78301

Timestep Collection Time: 2.21997
Timestep Consumption Time: 0.77959
PPO Batch Consumption Time: 0.05778
Total Iteration Time: 2.99956

Cumulative Model Updates: 19,865
Cumulative Timesteps: 331,713,792

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,766.11054
Policy Entropy: 0.78986
Value Function Loss: 0.06709

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 0.03230
Value Function Update Magnitude: 0.03101

Collected Steps per Second: 22,351.82622
Overall Steps per Second: 16,637.02603

Timestep Collection Time: 2.23812
Timestep Consumption Time: 0.76879
PPO Batch Consumption Time: 0.05971
Total Iteration Time: 3.00691

Cumulative Model Updates: 19,868
Cumulative Timesteps: 331,763,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 331763818...
Checkpoint 331763818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,550.83619
Policy Entropy: 0.78077
Value Function Loss: 0.06434

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03979
Policy Update Magnitude: 0.03305
Value Function Update Magnitude: 0.03170

Collected Steps per Second: 22,234.94130
Overall Steps per Second: 16,572.04638

Timestep Collection Time: 2.25051
Timestep Consumption Time: 0.76903
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 3.01954

Cumulative Model Updates: 19,871
Cumulative Timesteps: 331,813,858

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,635.10381
Policy Entropy: 0.79075
Value Function Loss: 0.05556

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04271
Policy Update Magnitude: 0.03130
Value Function Update Magnitude: 0.03436

Collected Steps per Second: 20,321.53363
Overall Steps per Second: 14,580.34902

Timestep Collection Time: 2.46143
Timestep Consumption Time: 0.96922
PPO Batch Consumption Time: 0.10471
Total Iteration Time: 3.43064

Cumulative Model Updates: 19,874
Cumulative Timesteps: 331,863,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 331863878...
Checkpoint 331863878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,974.30346
Policy Entropy: 0.79663
Value Function Loss: 0.05148

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.03026
Value Function Update Magnitude: 0.03371

Collected Steps per Second: 21,932.63835
Overall Steps per Second: 16,044.21706

Timestep Collection Time: 2.28044
Timestep Consumption Time: 0.83695
PPO Batch Consumption Time: 0.05965
Total Iteration Time: 3.11738

Cumulative Model Updates: 19,877
Cumulative Timesteps: 331,913,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,653.11886
Policy Entropy: 0.79770
Value Function Loss: 0.05661

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04468
Policy Update Magnitude: 0.02877
Value Function Update Magnitude: 0.03214

Collected Steps per Second: 21,495.29602
Overall Steps per Second: 15,725.42655

Timestep Collection Time: 2.32711
Timestep Consumption Time: 0.85385
PPO Batch Consumption Time: 0.07053
Total Iteration Time: 3.18096

Cumulative Model Updates: 19,880
Cumulative Timesteps: 331,963,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 331963916...
Checkpoint 331963916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,402.85173
Policy Entropy: 0.79694
Value Function Loss: 0.05779

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04949
Policy Update Magnitude: 0.02929
Value Function Update Magnitude: 0.03176

Collected Steps per Second: 22,151.51946
Overall Steps per Second: 16,266.51385

Timestep Collection Time: 2.25863
Timestep Consumption Time: 0.81714
PPO Batch Consumption Time: 0.06396
Total Iteration Time: 3.07577

Cumulative Model Updates: 19,883
Cumulative Timesteps: 332,013,948

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,705.38494
Policy Entropy: 0.79051
Value Function Loss: 0.05993

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.02940
Value Function Update Magnitude: 0.03255

Collected Steps per Second: 19,336.35833
Overall Steps per Second: 13,982.46583

Timestep Collection Time: 2.58642
Timestep Consumption Time: 0.99034
PPO Batch Consumption Time: 0.10765
Total Iteration Time: 3.57677

Cumulative Model Updates: 19,886
Cumulative Timesteps: 332,063,960

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 332063960...
Checkpoint 332063960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,502.54858
Policy Entropy: 0.79576
Value Function Loss: 0.05622

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03497
Policy Update Magnitude: 0.02959
Value Function Update Magnitude: 0.03126

Collected Steps per Second: 22,337.09015
Overall Steps per Second: 16,405.56541

Timestep Collection Time: 2.24004
Timestep Consumption Time: 0.80990
PPO Batch Consumption Time: 0.05833
Total Iteration Time: 3.04994

Cumulative Model Updates: 19,889
Cumulative Timesteps: 332,113,996

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,197.03726
Policy Entropy: 0.78501
Value Function Loss: 0.06425

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03613
Policy Update Magnitude: 0.02940
Value Function Update Magnitude: 0.03104

Collected Steps per Second: 22,398.65923
Overall Steps per Second: 15,871.44787

Timestep Collection Time: 2.23299
Timestep Consumption Time: 0.91833
PPO Batch Consumption Time: 0.08090
Total Iteration Time: 3.15132

Cumulative Model Updates: 19,892
Cumulative Timesteps: 332,164,012

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 332164012...
Checkpoint 332164012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,543.87634
Policy Entropy: 0.79401
Value Function Loss: 0.06720

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03757
Policy Update Magnitude: 0.03003
Value Function Update Magnitude: 0.03398

Collected Steps per Second: 21,673.07491
Overall Steps per Second: 16,070.53664

Timestep Collection Time: 2.30830
Timestep Consumption Time: 0.80472
PPO Batch Consumption Time: 0.05878
Total Iteration Time: 3.11303

Cumulative Model Updates: 19,895
Cumulative Timesteps: 332,214,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,226.52534
Policy Entropy: 0.79223
Value Function Loss: 0.06878

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01391
Policy Update Magnitude: 0.03163
Value Function Update Magnitude: 0.03288

Collected Steps per Second: 20,003.42770
Overall Steps per Second: 14,567.87709

Timestep Collection Time: 2.50197
Timestep Consumption Time: 0.93353
PPO Batch Consumption Time: 0.09297
Total Iteration Time: 3.43550

Cumulative Model Updates: 19,898
Cumulative Timesteps: 332,264,088

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 332264088...
Checkpoint 332264088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,657.51487
Policy Entropy: 0.80377
Value Function Loss: 0.05926

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03835
Policy Update Magnitude: 0.03220
Value Function Update Magnitude: 0.03361

Collected Steps per Second: 21,979.54454
Overall Steps per Second: 16,026.80395

Timestep Collection Time: 2.27493
Timestep Consumption Time: 0.84497
PPO Batch Consumption Time: 0.05976
Total Iteration Time: 3.11990

Cumulative Model Updates: 19,901
Cumulative Timesteps: 332,314,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,402.93307
Policy Entropy: 0.79629
Value Function Loss: 0.05758

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04682
Policy Update Magnitude: 0.03039
Value Function Update Magnitude: 0.03816

Collected Steps per Second: 20,687.81866
Overall Steps per Second: 14,524.24007

Timestep Collection Time: 2.41688
Timestep Consumption Time: 1.02564
PPO Batch Consumption Time: 0.11764
Total Iteration Time: 3.44252

Cumulative Model Updates: 19,904
Cumulative Timesteps: 332,364,090

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 332364090...
Checkpoint 332364090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,359.50324
Policy Entropy: 0.79783
Value Function Loss: 0.05562

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03911
Policy Update Magnitude: 0.03025
Value Function Update Magnitude: 0.03395

Collected Steps per Second: 22,090.25724
Overall Steps per Second: 16,277.47503

Timestep Collection Time: 2.26398
Timestep Consumption Time: 0.80848
PPO Batch Consumption Time: 0.05900
Total Iteration Time: 3.07247

Cumulative Model Updates: 19,907
Cumulative Timesteps: 332,414,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,592.47088
Policy Entropy: 0.80091
Value Function Loss: 0.05608

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03670
Policy Update Magnitude: 0.03041
Value Function Update Magnitude: 0.03701

Collected Steps per Second: 21,744.30741
Overall Steps per Second: 16,086.82021

Timestep Collection Time: 2.30074
Timestep Consumption Time: 0.80913
PPO Batch Consumption Time: 0.05793
Total Iteration Time: 3.10987

Cumulative Model Updates: 19,910
Cumulative Timesteps: 332,464,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 332464130...
Checkpoint 332464130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,470.64085
Policy Entropy: 0.80427
Value Function Loss: 0.05919

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03219
Policy Update Magnitude: 0.02793
Value Function Update Magnitude: 0.03575

Collected Steps per Second: 20,082.06497
Overall Steps per Second: 14,775.41362

Timestep Collection Time: 2.49207
Timestep Consumption Time: 0.89504
PPO Batch Consumption Time: 0.08251
Total Iteration Time: 3.38711

Cumulative Model Updates: 19,913
Cumulative Timesteps: 332,514,176

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,716.23045
Policy Entropy: 0.80071
Value Function Loss: 0.05705

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03363
Policy Update Magnitude: 0.02719
Value Function Update Magnitude: 0.03182

Collected Steps per Second: 22,350.63684
Overall Steps per Second: 16,352.02919

Timestep Collection Time: 2.23824
Timestep Consumption Time: 0.82108
PPO Batch Consumption Time: 0.06420
Total Iteration Time: 3.05931

Cumulative Model Updates: 19,916
Cumulative Timesteps: 332,564,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 332564202...
Checkpoint 332564202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,846.26355
Policy Entropy: 0.79755
Value Function Loss: 0.05685

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.02833
Value Function Update Magnitude: 0.03207

Collected Steps per Second: 22,415.63345
Overall Steps per Second: 16,364.21875

Timestep Collection Time: 2.23103
Timestep Consumption Time: 0.82503
PPO Batch Consumption Time: 0.05935
Total Iteration Time: 3.05606

Cumulative Model Updates: 19,919
Cumulative Timesteps: 332,614,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,537.23344
Policy Entropy: 0.78163
Value Function Loss: 0.06067

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02230
Policy Update Magnitude: 0.03092
Value Function Update Magnitude: 0.03389

Collected Steps per Second: 21,038.13132
Overall Steps per Second: 15,220.29851

Timestep Collection Time: 2.37702
Timestep Consumption Time: 0.90860
PPO Batch Consumption Time: 0.08594
Total Iteration Time: 3.28561

Cumulative Model Updates: 19,922
Cumulative Timesteps: 332,664,220

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 332664220...
Checkpoint 332664220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,842.57767
Policy Entropy: 0.78096
Value Function Loss: 0.06030

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02951
Policy Update Magnitude: 0.02975
Value Function Update Magnitude: 0.03570

Collected Steps per Second: 22,398.79575
Overall Steps per Second: 16,539.91379

Timestep Collection Time: 2.23289
Timestep Consumption Time: 0.79095
PPO Batch Consumption Time: 0.06005
Total Iteration Time: 3.02384

Cumulative Model Updates: 19,925
Cumulative Timesteps: 332,714,234

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,768.07518
Policy Entropy: 0.77161
Value Function Loss: 0.06375

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 0.02933
Value Function Update Magnitude: 0.03612

Collected Steps per Second: 22,435.59635
Overall Steps per Second: 15,932.35040

Timestep Collection Time: 2.22914
Timestep Consumption Time: 0.90989
PPO Batch Consumption Time: 0.08488
Total Iteration Time: 3.13902

Cumulative Model Updates: 19,928
Cumulative Timesteps: 332,764,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 332764246...
Checkpoint 332764246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,998.09363
Policy Entropy: 0.78927
Value Function Loss: 0.05332

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02102
Policy Update Magnitude: 0.02815
Value Function Update Magnitude: 0.03542

Collected Steps per Second: 22,537.51999
Overall Steps per Second: 16,470.73949

Timestep Collection Time: 2.21914
Timestep Consumption Time: 0.81739
PPO Batch Consumption Time: 0.06121
Total Iteration Time: 3.03654

Cumulative Model Updates: 19,931
Cumulative Timesteps: 332,814,260

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,227.94135
Policy Entropy: 0.78672
Value Function Loss: 0.05617

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02405
Policy Update Magnitude: 0.02954
Value Function Update Magnitude: 0.03327

Collected Steps per Second: 22,466.96273
Overall Steps per Second: 16,482.77808

Timestep Collection Time: 2.22567
Timestep Consumption Time: 0.80804
PPO Batch Consumption Time: 0.05942
Total Iteration Time: 3.03371

Cumulative Model Updates: 19,934
Cumulative Timesteps: 332,864,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 332864264...
Checkpoint 332864264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,674.05843
Policy Entropy: 0.80199
Value Function Loss: 0.05535

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04394
Policy Update Magnitude: 0.03146
Value Function Update Magnitude: 0.03167

Collected Steps per Second: 21,809.43506
Overall Steps per Second: 16,196.88628

Timestep Collection Time: 2.29396
Timestep Consumption Time: 0.79490
PPO Batch Consumption Time: 0.06038
Total Iteration Time: 3.08887

Cumulative Model Updates: 19,937
Cumulative Timesteps: 332,914,294

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,090.52254
Policy Entropy: 0.79325
Value Function Loss: 0.05895

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04804
Policy Update Magnitude: 0.03054
Value Function Update Magnitude: 0.02922

Collected Steps per Second: 20,079.65196
Overall Steps per Second: 14,643.05160

Timestep Collection Time: 2.49008
Timestep Consumption Time: 0.92451
PPO Batch Consumption Time: 0.08369
Total Iteration Time: 3.41459

Cumulative Model Updates: 19,940
Cumulative Timesteps: 332,964,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 332964294...
Checkpoint 332964294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,392.58223
Policy Entropy: 0.78988
Value Function Loss: 0.05834

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03893
Policy Update Magnitude: 0.03080
Value Function Update Magnitude: 0.03247

Collected Steps per Second: 21,774.17789
Overall Steps per Second: 16,068.68897

Timestep Collection Time: 2.29639
Timestep Consumption Time: 0.81538
PPO Batch Consumption Time: 0.06066
Total Iteration Time: 3.11177

Cumulative Model Updates: 19,943
Cumulative Timesteps: 333,014,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,861.33346
Policy Entropy: 0.78129
Value Function Loss: 0.06289

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03386
Policy Update Magnitude: 0.03187
Value Function Update Magnitude: 0.03321

Collected Steps per Second: 20,579.57391
Overall Steps per Second: 14,715.23363

Timestep Collection Time: 2.42989
Timestep Consumption Time: 0.96836
PPO Batch Consumption Time: 0.10397
Total Iteration Time: 3.39825

Cumulative Model Updates: 19,946
Cumulative Timesteps: 333,064,302

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 333064302...
Checkpoint 333064302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,478.31800
Policy Entropy: 0.78244
Value Function Loss: 0.05614

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03595
Policy Update Magnitude: 0.03166
Value Function Update Magnitude: 0.02986

Collected Steps per Second: 22,421.63018
Overall Steps per Second: 16,391.61524

Timestep Collection Time: 2.23115
Timestep Consumption Time: 0.82078
PPO Batch Consumption Time: 0.06092
Total Iteration Time: 3.05193

Cumulative Model Updates: 19,949
Cumulative Timesteps: 333,114,328

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,618.64300
Policy Entropy: 0.78390
Value Function Loss: 0.06788

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.06171
Policy Update Magnitude: 0.03192
Value Function Update Magnitude: 0.03061

Collected Steps per Second: 20,146.08650
Overall Steps per Second: 14,816.09917

Timestep Collection Time: 2.48386
Timestep Consumption Time: 0.89355
PPO Batch Consumption Time: 0.08530
Total Iteration Time: 3.37741

Cumulative Model Updates: 19,952
Cumulative Timesteps: 333,164,368

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 333164368...
Checkpoint 333164368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,106.51323
Policy Entropy: 0.78054
Value Function Loss: 0.07299

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05673
Policy Update Magnitude: 0.02961
Value Function Update Magnitude: 0.03541

Collected Steps per Second: 21,626.42603
Overall Steps per Second: 16,060.48136

Timestep Collection Time: 2.31319
Timestep Consumption Time: 0.80166
PPO Batch Consumption Time: 0.05790
Total Iteration Time: 3.11485

Cumulative Model Updates: 19,955
Cumulative Timesteps: 333,214,394

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,217.81569
Policy Entropy: 0.77738
Value Function Loss: 0.08644

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04231
Policy Update Magnitude: 0.02986
Value Function Update Magnitude: 0.03524

Collected Steps per Second: 20,028.23201
Overall Steps per Second: 14,702.38126

Timestep Collection Time: 2.49787
Timestep Consumption Time: 0.90484
PPO Batch Consumption Time: 0.09153
Total Iteration Time: 3.40271

Cumulative Model Updates: 19,958
Cumulative Timesteps: 333,264,422

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 333264422...
Checkpoint 333264422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,981.86003
Policy Entropy: 0.77443
Value Function Loss: 0.07989

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03637
Policy Update Magnitude: 0.03102
Value Function Update Magnitude: 0.03780

Collected Steps per Second: 21,774.49981
Overall Steps per Second: 16,128.06153

Timestep Collection Time: 2.29645
Timestep Consumption Time: 0.80399
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 3.10043

Cumulative Model Updates: 19,961
Cumulative Timesteps: 333,314,426

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,788.98464
Policy Entropy: 0.76354
Value Function Loss: 0.08192

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03165
Policy Update Magnitude: 0.03287
Value Function Update Magnitude: 0.03580

Collected Steps per Second: 22,345.64827
Overall Steps per Second: 15,984.14375

Timestep Collection Time: 2.23945
Timestep Consumption Time: 0.89128
PPO Batch Consumption Time: 0.07957
Total Iteration Time: 3.13073

Cumulative Model Updates: 19,964
Cumulative Timesteps: 333,364,468

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 333364468...
Checkpoint 333364468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,303.18759
Policy Entropy: 0.75692
Value Function Loss: 0.07798

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03704
Policy Update Magnitude: 0.03283
Value Function Update Magnitude: 0.03261

Collected Steps per Second: 22,609.12361
Overall Steps per Second: 16,622.04706

Timestep Collection Time: 2.21194
Timestep Consumption Time: 0.79672
PPO Batch Consumption Time: 0.05831
Total Iteration Time: 3.00865

Cumulative Model Updates: 19,967
Cumulative Timesteps: 333,414,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,480.05997
Policy Entropy: 0.75178
Value Function Loss: 0.07663

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03619
Policy Update Magnitude: 0.03178
Value Function Update Magnitude: 0.03183

Collected Steps per Second: 22,467.20866
Overall Steps per Second: 16,503.62842

Timestep Collection Time: 2.22547
Timestep Consumption Time: 0.80417
PPO Batch Consumption Time: 0.06039
Total Iteration Time: 3.02964

Cumulative Model Updates: 19,970
Cumulative Timesteps: 333,464,478

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 333464478...
Checkpoint 333464478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,442.12444
Policy Entropy: 0.75903
Value Function Loss: 0.06427

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04111
Policy Update Magnitude: 0.03201
Value Function Update Magnitude: 0.03176

Collected Steps per Second: 22,208.64040
Overall Steps per Second: 16,344.83309

Timestep Collection Time: 2.25138
Timestep Consumption Time: 0.80769
PPO Batch Consumption Time: 0.06000
Total Iteration Time: 3.05907

Cumulative Model Updates: 19,973
Cumulative Timesteps: 333,514,478

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,716.94444
Policy Entropy: 0.75908
Value Function Loss: 0.06074

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06107
Policy Update Magnitude: 0.03082
Value Function Update Magnitude: 0.03098

Collected Steps per Second: 20,714.57538
Overall Steps per Second: 14,705.75390

Timestep Collection Time: 2.41386
Timestep Consumption Time: 0.98631
PPO Batch Consumption Time: 0.11512
Total Iteration Time: 3.40017

Cumulative Model Updates: 19,976
Cumulative Timesteps: 333,564,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 333564480...
Checkpoint 333564480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,760.97796
Policy Entropy: 0.75401
Value Function Loss: 0.06245

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.05155
Policy Update Magnitude: 0.02819
Value Function Update Magnitude: 0.03093

Collected Steps per Second: 21,443.43577
Overall Steps per Second: 15,911.28221

Timestep Collection Time: 2.33200
Timestep Consumption Time: 0.81081
PPO Batch Consumption Time: 0.05936
Total Iteration Time: 3.14280

Cumulative Model Updates: 19,979
Cumulative Timesteps: 333,614,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,366.49887
Policy Entropy: 0.76444
Value Function Loss: 0.06584

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04143
Policy Update Magnitude: 0.02885
Value Function Update Magnitude: 0.03427

Collected Steps per Second: 20,261.66038
Overall Steps per Second: 14,572.83873

Timestep Collection Time: 2.46841
Timestep Consumption Time: 0.96360
PPO Batch Consumption Time: 0.10690
Total Iteration Time: 3.43200

Cumulative Model Updates: 19,982
Cumulative Timesteps: 333,664,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 333664500...
Checkpoint 333664500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,223.90528
Policy Entropy: 0.76657
Value Function Loss: 0.05605

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.02668
Value Function Update Magnitude: 0.03365

Collected Steps per Second: 22,524.34549
Overall Steps per Second: 16,378.54590

Timestep Collection Time: 2.22018
Timestep Consumption Time: 0.83309
PPO Batch Consumption Time: 0.06167
Total Iteration Time: 3.05326

Cumulative Model Updates: 19,985
Cumulative Timesteps: 333,714,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,732.62479
Policy Entropy: 0.75857
Value Function Loss: 0.05698

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03509
Policy Update Magnitude: 0.02648
Value Function Update Magnitude: 0.03412

Collected Steps per Second: 22,671.66965
Overall Steps per Second: 16,733.59480

Timestep Collection Time: 2.20663
Timestep Consumption Time: 0.78304
PPO Batch Consumption Time: 0.05946
Total Iteration Time: 2.98967

Cumulative Model Updates: 19,988
Cumulative Timesteps: 333,764,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 333764536...
Checkpoint 333764536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,687.22497
Policy Entropy: 0.76429
Value Function Loss: 0.05506

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.02694
Value Function Update Magnitude: 0.03388

Collected Steps per Second: 21,365.35487
Overall Steps per Second: 15,088.82200

Timestep Collection Time: 2.34042
Timestep Consumption Time: 0.97355
PPO Batch Consumption Time: 0.10820
Total Iteration Time: 3.31398

Cumulative Model Updates: 19,991
Cumulative Timesteps: 333,814,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,780.16689
Policy Entropy: 0.75654
Value Function Loss: 0.05891

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02313
Policy Update Magnitude: 0.02769
Value Function Update Magnitude: 0.03224

Collected Steps per Second: 22,307.11607
Overall Steps per Second: 16,443.12175

Timestep Collection Time: 2.24251
Timestep Consumption Time: 0.79973
PPO Batch Consumption Time: 0.05838
Total Iteration Time: 3.04224

Cumulative Model Updates: 19,994
Cumulative Timesteps: 333,864,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 333864564...
Checkpoint 333864564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,265.12368
Policy Entropy: 0.77107
Value Function Loss: 0.05528

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02397
Policy Update Magnitude: 0.02659
Value Function Update Magnitude: 0.03261

Collected Steps per Second: 20,811.22356
Overall Steps per Second: 15,004.73875

Timestep Collection Time: 2.40486
Timestep Consumption Time: 0.93062
PPO Batch Consumption Time: 0.08488
Total Iteration Time: 3.33548

Cumulative Model Updates: 19,997
Cumulative Timesteps: 333,914,612

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,931.41982
Policy Entropy: 0.75017
Value Function Loss: 0.06589

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.02925
Value Function Update Magnitude: 0.03424

Collected Steps per Second: 22,131.44396
Overall Steps per Second: 16,261.36832

Timestep Collection Time: 2.25923
Timestep Consumption Time: 0.81554
PPO Batch Consumption Time: 0.06047
Total Iteration Time: 3.07477

Cumulative Model Updates: 20,000
Cumulative Timesteps: 333,964,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 333964612...
Checkpoint 333964612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,477.86373
Policy Entropy: 0.75291
Value Function Loss: 0.06814

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01977
Policy Update Magnitude: 0.02964
Value Function Update Magnitude: 0.03621

Collected Steps per Second: 22,420.02612
Overall Steps per Second: 16,450.07586

Timestep Collection Time: 2.23086
Timestep Consumption Time: 0.80961
PPO Batch Consumption Time: 0.06291
Total Iteration Time: 3.04047

Cumulative Model Updates: 20,003
Cumulative Timesteps: 334,014,628

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,327.69120
Policy Entropy: 0.74828
Value Function Loss: 0.06457

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02419
Policy Update Magnitude: 0.03080
Value Function Update Magnitude: 0.03654

Collected Steps per Second: 20,931.38381
Overall Steps per Second: 15,198.45784

Timestep Collection Time: 2.38952
Timestep Consumption Time: 0.90134
PPO Batch Consumption Time: 0.07824
Total Iteration Time: 3.29086

Cumulative Model Updates: 20,006
Cumulative Timesteps: 334,064,644

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 334064644...
Checkpoint 334064644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,236.39353
Policy Entropy: 0.76534
Value Function Loss: 0.05104

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02810
Policy Update Magnitude: 0.03291
Value Function Update Magnitude: 0.03190

Collected Steps per Second: 21,965.88767
Overall Steps per Second: 16,216.73751

Timestep Collection Time: 2.27744
Timestep Consumption Time: 0.80740
PPO Batch Consumption Time: 0.06059
Total Iteration Time: 3.08484

Cumulative Model Updates: 20,009
Cumulative Timesteps: 334,114,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,943.15103
Policy Entropy: 0.76271
Value Function Loss: 0.05178

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03319
Policy Update Magnitude: 0.03271
Value Function Update Magnitude: 0.03272

Collected Steps per Second: 20,481.92159
Overall Steps per Second: 14,455.20278

Timestep Collection Time: 2.44118
Timestep Consumption Time: 1.01779
PPO Batch Consumption Time: 0.12484
Total Iteration Time: 3.45896

Cumulative Model Updates: 20,012
Cumulative Timesteps: 334,164,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 334164670...
Checkpoint 334164670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,224.73567
Policy Entropy: 0.76278
Value Function Loss: 0.06092

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02225
Policy Update Magnitude: 0.03093
Value Function Update Magnitude: 0.03468

Collected Steps per Second: 22,856.20275
Overall Steps per Second: 17,210.50874

Timestep Collection Time: 2.18820
Timestep Consumption Time: 0.71781
PPO Batch Consumption Time: 0.03163
Total Iteration Time: 2.90602

Cumulative Model Updates: 20,015
Cumulative Timesteps: 334,214,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,920.06638
Policy Entropy: 0.75872
Value Function Loss: 0.07495

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.04057
Policy Update Magnitude: 0.03018
Value Function Update Magnitude: 0.03747

Collected Steps per Second: 21,693.26940
Overall Steps per Second: 15,372.44102

Timestep Collection Time: 2.30578
Timestep Consumption Time: 0.94809
PPO Batch Consumption Time: 0.09619
Total Iteration Time: 3.25387

Cumulative Model Updates: 20,018
Cumulative Timesteps: 334,264,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 334264704...
Checkpoint 334264704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,195.39533
Policy Entropy: 0.75928
Value Function Loss: 0.07327

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03738
Policy Update Magnitude: 0.03164
Value Function Update Magnitude: 0.03975

Collected Steps per Second: 22,573.34509
Overall Steps per Second: 16,680.82645

Timestep Collection Time: 2.21509
Timestep Consumption Time: 0.78248
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 2.99757

Cumulative Model Updates: 20,021
Cumulative Timesteps: 334,314,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,619.63787
Policy Entropy: 0.76290
Value Function Loss: 0.07301

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04163
Policy Update Magnitude: 0.03032
Value Function Update Magnitude: 0.04822

Collected Steps per Second: 20,234.60586
Overall Steps per Second: 14,789.90503

Timestep Collection Time: 2.47131
Timestep Consumption Time: 0.90978
PPO Batch Consumption Time: 0.08703
Total Iteration Time: 3.38109

Cumulative Model Updates: 20,024
Cumulative Timesteps: 334,364,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 334364712...
Checkpoint 334364712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,732.93335
Policy Entropy: 0.76570
Value Function Loss: 0.06307

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04057
Policy Update Magnitude: 0.02971
Value Function Update Magnitude: 0.04271

Collected Steps per Second: 21,758.07528
Overall Steps per Second: 16,149.23571

Timestep Collection Time: 2.29809
Timestep Consumption Time: 0.79816
PPO Batch Consumption Time: 0.06157
Total Iteration Time: 3.09625

Cumulative Model Updates: 20,027
Cumulative Timesteps: 334,414,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,737.66989
Policy Entropy: 0.76626
Value Function Loss: 0.06335

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02571
Policy Update Magnitude: 0.02904
Value Function Update Magnitude: 0.04026

Collected Steps per Second: 22,708.56273
Overall Steps per Second: 16,696.06794

Timestep Collection Time: 2.20252
Timestep Consumption Time: 0.79316
PPO Batch Consumption Time: 0.05942
Total Iteration Time: 2.99568

Cumulative Model Updates: 20,030
Cumulative Timesteps: 334,464,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 334464730...
Checkpoint 334464730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,840.74434
Policy Entropy: 0.75393
Value Function Loss: 0.06383

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02153
Policy Update Magnitude: 0.02924
Value Function Update Magnitude: 0.03503

Collected Steps per Second: 22,525.38677
Overall Steps per Second: 16,555.64532

Timestep Collection Time: 2.22061
Timestep Consumption Time: 0.80072
PPO Batch Consumption Time: 0.05768
Total Iteration Time: 3.02133

Cumulative Model Updates: 20,033
Cumulative Timesteps: 334,514,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,512.51867
Policy Entropy: 0.75094
Value Function Loss: 0.06466

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01867
Policy Update Magnitude: 0.02923
Value Function Update Magnitude: 0.03361

Collected Steps per Second: 20,878.03766
Overall Steps per Second: 14,597.69977

Timestep Collection Time: 2.39639
Timestep Consumption Time: 1.03100
PPO Batch Consumption Time: 0.12455
Total Iteration Time: 3.42739

Cumulative Model Updates: 20,036
Cumulative Timesteps: 334,564,782

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 334564782...
Checkpoint 334564782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,118.36052
Policy Entropy: 0.74242
Value Function Loss: 0.07414

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02465
Policy Update Magnitude: 0.03301
Value Function Update Magnitude: 0.03412

Collected Steps per Second: 22,516.63317
Overall Steps per Second: 16,832.45590

Timestep Collection Time: 2.22076
Timestep Consumption Time: 0.74993
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 2.97069

Cumulative Model Updates: 20,039
Cumulative Timesteps: 334,614,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,755.66734
Policy Entropy: 0.74746
Value Function Loss: 0.07533

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.03666
Value Function Update Magnitude: 0.03526

Collected Steps per Second: 20,867.41381
Overall Steps per Second: 14,758.72936

Timestep Collection Time: 2.39666
Timestep Consumption Time: 0.99198
PPO Batch Consumption Time: 0.11971
Total Iteration Time: 3.38864

Cumulative Model Updates: 20,042
Cumulative Timesteps: 334,664,798

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 334664798...
Checkpoint 334664798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,410.17378
Policy Entropy: 0.75500
Value Function Loss: 0.07507

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03681
Policy Update Magnitude: 0.03638
Value Function Update Magnitude: 0.03867

Collected Steps per Second: 22,488.84325
Overall Steps per Second: 16,640.43630

Timestep Collection Time: 2.22421
Timestep Consumption Time: 0.78172
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 3.00593

Cumulative Model Updates: 20,045
Cumulative Timesteps: 334,714,818

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,927.95694
Policy Entropy: 0.76392
Value Function Loss: 0.07151

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04575
Policy Update Magnitude: 0.03336
Value Function Update Magnitude: 0.04485

Collected Steps per Second: 20,638.87727
Overall Steps per Second: 14,757.66526

Timestep Collection Time: 2.42261
Timestep Consumption Time: 0.96546
PPO Batch Consumption Time: 0.10879
Total Iteration Time: 3.38807

Cumulative Model Updates: 20,048
Cumulative Timesteps: 334,764,818

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 334764818...
Checkpoint 334764818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,420.39330
Policy Entropy: 0.76520
Value Function Loss: 0.07372

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06975
Policy Update Magnitude: 0.03107
Value Function Update Magnitude: 0.04721

Collected Steps per Second: 22,571.81575
Overall Steps per Second: 16,550.45035

Timestep Collection Time: 2.21551
Timestep Consumption Time: 0.80604
PPO Batch Consumption Time: 0.06052
Total Iteration Time: 3.02155

Cumulative Model Updates: 20,051
Cumulative Timesteps: 334,814,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,553.33103
Policy Entropy: 0.75961
Value Function Loss: 0.07830

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05640
Policy Update Magnitude: 0.03270
Value Function Update Magnitude: 0.04902

Collected Steps per Second: 20,749.33355
Overall Steps per Second: 14,905.45872

Timestep Collection Time: 2.41184
Timestep Consumption Time: 0.94559
PPO Batch Consumption Time: 0.09981
Total Iteration Time: 3.35743

Cumulative Model Updates: 20,054
Cumulative Timesteps: 334,864,870

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 334864870...
Checkpoint 334864870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,617.82044
Policy Entropy: 0.76029
Value Function Loss: 0.07603

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04437
Policy Update Magnitude: 0.03554
Value Function Update Magnitude: 0.04777

Collected Steps per Second: 22,042.99203
Overall Steps per Second: 16,248.05793

Timestep Collection Time: 2.26884
Timestep Consumption Time: 0.80919
PPO Batch Consumption Time: 0.05961
Total Iteration Time: 3.07803

Cumulative Model Updates: 20,057
Cumulative Timesteps: 334,914,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,580.99441
Policy Entropy: 0.75174
Value Function Loss: 0.06691

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07601
Policy Update Magnitude: 0.03655
Value Function Update Magnitude: 0.05035

Collected Steps per Second: 22,410.83174
Overall Steps per Second: 16,520.65954

Timestep Collection Time: 2.23231
Timestep Consumption Time: 0.79590
PPO Batch Consumption Time: 0.05920
Total Iteration Time: 3.02821

Cumulative Model Updates: 20,060
Cumulative Timesteps: 334,964,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 334964910...
Checkpoint 334964910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,331.80626
Policy Entropy: 0.75939
Value Function Loss: 0.06187

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.03339
Value Function Update Magnitude: 0.05408

Collected Steps per Second: 22,621.64085
Overall Steps per Second: 16,634.01733

Timestep Collection Time: 2.21098
Timestep Consumption Time: 0.79587
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 3.00685

Cumulative Model Updates: 20,063
Cumulative Timesteps: 335,014,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,512.66592
Policy Entropy: 0.75607
Value Function Loss: 0.06382

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06739
Policy Update Magnitude: 0.03146
Value Function Update Magnitude: 0.05032

Collected Steps per Second: 20,330.29062
Overall Steps per Second: 14,568.04690

Timestep Collection Time: 2.46066
Timestep Consumption Time: 0.97329
PPO Batch Consumption Time: 0.11088
Total Iteration Time: 3.43395

Cumulative Model Updates: 20,066
Cumulative Timesteps: 335,064,952

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 335064952...
Checkpoint 335064952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,471.27387
Policy Entropy: 0.76982
Value Function Loss: 0.06916

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06359
Policy Update Magnitude: 0.03346
Value Function Update Magnitude: 0.05165

Collected Steps per Second: 22,256.72415
Overall Steps per Second: 16,205.59818

Timestep Collection Time: 2.24741
Timestep Consumption Time: 0.83918
PPO Batch Consumption Time: 0.07026
Total Iteration Time: 3.08659

Cumulative Model Updates: 20,069
Cumulative Timesteps: 335,114,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,853.78826
Policy Entropy: 0.76354
Value Function Loss: 0.06861

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05807
Policy Update Magnitude: 0.02980
Value Function Update Magnitude: 0.05732

Collected Steps per Second: 22,522.32272
Overall Steps per Second: 16,466.53140

Timestep Collection Time: 2.22064
Timestep Consumption Time: 0.81667
PPO Batch Consumption Time: 0.06596
Total Iteration Time: 3.03731

Cumulative Model Updates: 20,072
Cumulative Timesteps: 335,164,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 335164986...
Checkpoint 335164986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,905.79987
Policy Entropy: 0.75599
Value Function Loss: 0.07146

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.06069
Policy Update Magnitude: 0.02992
Value Function Update Magnitude: 0.06133

Collected Steps per Second: 22,166.44978
Overall Steps per Second: 16,556.55230

Timestep Collection Time: 2.25611
Timestep Consumption Time: 0.76444
PPO Batch Consumption Time: 0.05804
Total Iteration Time: 3.02056

Cumulative Model Updates: 20,075
Cumulative Timesteps: 335,214,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,278.88134
Policy Entropy: 0.75141
Value Function Loss: 0.07605

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04271
Policy Update Magnitude: 0.03103
Value Function Update Magnitude: 0.05827

Collected Steps per Second: 21,014.71131
Overall Steps per Second: 14,687.05286

Timestep Collection Time: 2.38062
Timestep Consumption Time: 1.02565
PPO Batch Consumption Time: 0.12083
Total Iteration Time: 3.40627

Cumulative Model Updates: 20,078
Cumulative Timesteps: 335,265,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 335265024...
Checkpoint 335265024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,043.26312
Policy Entropy: 0.75950
Value Function Loss: 0.07108

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02905
Policy Update Magnitude: 0.03463
Value Function Update Magnitude: 0.06455

Collected Steps per Second: 22,616.68337
Overall Steps per Second: 16,586.40953

Timestep Collection Time: 2.21253
Timestep Consumption Time: 0.80440
PPO Batch Consumption Time: 0.05773
Total Iteration Time: 3.01693

Cumulative Model Updates: 20,081
Cumulative Timesteps: 335,315,064

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,803.82622
Policy Entropy: 0.75601
Value Function Loss: 0.06271

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03074
Policy Update Magnitude: 0.03574
Value Function Update Magnitude: 0.07097

Collected Steps per Second: 20,152.69942
Overall Steps per Second: 14,660.78836

Timestep Collection Time: 2.48106
Timestep Consumption Time: 0.92940
PPO Batch Consumption Time: 0.08527
Total Iteration Time: 3.41046

Cumulative Model Updates: 20,084
Cumulative Timesteps: 335,365,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 335365064...
Checkpoint 335365064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,258.16403
Policy Entropy: 0.76700
Value Function Loss: 0.06080

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03638
Policy Update Magnitude: 0.03292
Value Function Update Magnitude: 0.06874

Collected Steps per Second: 22,289.60641
Overall Steps per Second: 16,294.83115

Timestep Collection Time: 2.24392
Timestep Consumption Time: 0.82552
PPO Batch Consumption Time: 0.05995
Total Iteration Time: 3.06944

Cumulative Model Updates: 20,087
Cumulative Timesteps: 335,415,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,899.09195
Policy Entropy: 0.75677
Value Function Loss: 0.06619

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03657
Policy Update Magnitude: 0.02993
Value Function Update Magnitude: 0.06371

Collected Steps per Second: 22,636.15556
Overall Steps per Second: 16,150.31387

Timestep Collection Time: 2.20894
Timestep Consumption Time: 0.88709
PPO Batch Consumption Time: 0.07895
Total Iteration Time: 3.09604

Cumulative Model Updates: 20,090
Cumulative Timesteps: 335,465,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 335465082...
Checkpoint 335465082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,902.54556
Policy Entropy: 0.75271
Value Function Loss: 0.06635

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03602
Policy Update Magnitude: 0.03170
Value Function Update Magnitude: 0.06772

Collected Steps per Second: 22,221.17586
Overall Steps per Second: 16,384.37057

Timestep Collection Time: 2.25119
Timestep Consumption Time: 0.80197
PPO Batch Consumption Time: 0.05977
Total Iteration Time: 3.05315

Cumulative Model Updates: 20,093
Cumulative Timesteps: 335,515,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,031.84521
Policy Entropy: 0.74824
Value Function Loss: 0.06229

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03511
Policy Update Magnitude: 0.03201
Value Function Update Magnitude: 0.06427

Collected Steps per Second: 22,639.12697
Overall Steps per Second: 16,665.25519

Timestep Collection Time: 2.20954
Timestep Consumption Time: 0.79204
PPO Batch Consumption Time: 0.05973
Total Iteration Time: 3.00157

Cumulative Model Updates: 20,096
Cumulative Timesteps: 335,565,128

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 335565128...
Checkpoint 335565128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,402.47901
Policy Entropy: 0.75648
Value Function Loss: 0.05946

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02847
Policy Update Magnitude: 0.03109
Value Function Update Magnitude: 0.06020

Collected Steps per Second: 22,360.87107
Overall Steps per Second: 16,464.41692

Timestep Collection Time: 2.23659
Timestep Consumption Time: 0.80100
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 3.03758

Cumulative Model Updates: 20,099
Cumulative Timesteps: 335,615,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,413.63345
Policy Entropy: 0.75859
Value Function Loss: 0.06214

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03750
Policy Update Magnitude: 0.03157
Value Function Update Magnitude: 0.06551

Collected Steps per Second: 20,313.01428
Overall Steps per Second: 14,632.99830

Timestep Collection Time: 2.46157
Timestep Consumption Time: 0.95550
PPO Batch Consumption Time: 0.09954
Total Iteration Time: 3.41707

Cumulative Model Updates: 20,102
Cumulative Timesteps: 335,665,142

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 335665142...
Checkpoint 335665142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,653.44241
Policy Entropy: 0.76423
Value Function Loss: 0.06353

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04387
Policy Update Magnitude: 0.02903
Value Function Update Magnitude: 0.07494

Collected Steps per Second: 21,975.18750
Overall Steps per Second: 16,158.80646

Timestep Collection Time: 2.27575
Timestep Consumption Time: 0.81916
PPO Batch Consumption Time: 0.06273
Total Iteration Time: 3.09491

Cumulative Model Updates: 20,105
Cumulative Timesteps: 335,715,152

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,697.62614
Policy Entropy: 0.75936
Value Function Loss: 0.08182

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.04005
Policy Update Magnitude: 0.03242
Value Function Update Magnitude: 0.07758

Collected Steps per Second: 22,592.80028
Overall Steps per Second: 16,586.50046

Timestep Collection Time: 2.21380
Timestep Consumption Time: 0.80166
PPO Batch Consumption Time: 0.06023
Total Iteration Time: 3.01546

Cumulative Model Updates: 20,108
Cumulative Timesteps: 335,765,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 335765168...
Checkpoint 335765168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,065.91362
Policy Entropy: 0.76213
Value Function Loss: 0.07898

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03951
Policy Update Magnitude: 0.03268
Value Function Update Magnitude: 0.08270

Collected Steps per Second: 20,843.50084
Overall Steps per Second: 15,198.34007

Timestep Collection Time: 2.39960
Timestep Consumption Time: 0.89129
PPO Batch Consumption Time: 0.08215
Total Iteration Time: 3.29089

Cumulative Model Updates: 20,111
Cumulative Timesteps: 335,815,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,438.14249
Policy Entropy: 0.76268
Value Function Loss: 0.08009

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03948
Policy Update Magnitude: 0.03546
Value Function Update Magnitude: 0.08897

Collected Steps per Second: 22,347.26129
Overall Steps per Second: 15,895.76689

Timestep Collection Time: 2.23822
Timestep Consumption Time: 0.90841
PPO Batch Consumption Time: 0.08274
Total Iteration Time: 3.14662

Cumulative Model Updates: 20,114
Cumulative Timesteps: 335,865,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 335865202...
Checkpoint 335865202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,700.55936
Policy Entropy: 0.77566
Value Function Loss: 0.06788

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04861
Policy Update Magnitude: 0.03261
Value Function Update Magnitude: 0.08301

Collected Steps per Second: 22,219.24484
Overall Steps per Second: 16,450.49943

Timestep Collection Time: 2.25030
Timestep Consumption Time: 0.78912
PPO Batch Consumption Time: 0.05961
Total Iteration Time: 3.03942

Cumulative Model Updates: 20,117
Cumulative Timesteps: 335,915,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,111.61247
Policy Entropy: 0.76409
Value Function Loss: 0.07287

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02748
Policy Update Magnitude: 0.03291
Value Function Update Magnitude: 0.07532

Collected Steps per Second: 21,099.87228
Overall Steps per Second: 15,014.80232

Timestep Collection Time: 2.37110
Timestep Consumption Time: 0.96094
PPO Batch Consumption Time: 0.10428
Total Iteration Time: 3.33205

Cumulative Model Updates: 20,120
Cumulative Timesteps: 335,965,232

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 335965232...
Checkpoint 335965232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,710.41958
Policy Entropy: 0.76668
Value Function Loss: 0.07382

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03690
Policy Update Magnitude: 0.03170
Value Function Update Magnitude: 0.06785

Collected Steps per Second: 22,141.97982
Overall Steps per Second: 16,366.99552

Timestep Collection Time: 2.25924
Timestep Consumption Time: 0.79716
PPO Batch Consumption Time: 0.05900
Total Iteration Time: 3.05639

Cumulative Model Updates: 20,123
Cumulative Timesteps: 336,015,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,384.44761
Policy Entropy: 0.75995
Value Function Loss: 0.06963

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03985
Policy Update Magnitude: 0.02988
Value Function Update Magnitude: 0.06170

Collected Steps per Second: 20,694.02568
Overall Steps per Second: 15,047.54546

Timestep Collection Time: 2.41809
Timestep Consumption Time: 0.90737
PPO Batch Consumption Time: 0.08025
Total Iteration Time: 3.32546

Cumulative Model Updates: 20,126
Cumulative Timesteps: 336,065,296

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 336065296...
Checkpoint 336065296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,270.42922
Policy Entropy: 0.77223
Value Function Loss: 0.06742

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02608
Policy Update Magnitude: 0.02922
Value Function Update Magnitude: 0.06602

Collected Steps per Second: 22,105.40938
Overall Steps per Second: 16,124.02965

Timestep Collection Time: 2.26189
Timestep Consumption Time: 0.83907
PPO Batch Consumption Time: 0.06971
Total Iteration Time: 3.10096

Cumulative Model Updates: 20,129
Cumulative Timesteps: 336,115,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,864.81021
Policy Entropy: 0.75520
Value Function Loss: 0.07198

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02831
Policy Update Magnitude: 0.03105
Value Function Update Magnitude: 0.06681

Collected Steps per Second: 22,585.25371
Overall Steps per Second: 16,511.39048

Timestep Collection Time: 2.21552
Timestep Consumption Time: 0.81500
PPO Batch Consumption Time: 0.06379
Total Iteration Time: 3.03051

Cumulative Model Updates: 20,132
Cumulative Timesteps: 336,165,334

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 336165334...
Checkpoint 336165334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,480.44018
Policy Entropy: 0.75353
Value Function Loss: 0.07458

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04429
Policy Update Magnitude: 0.03179
Value Function Update Magnitude: 0.07100

Collected Steps per Second: 20,280.47727
Overall Steps per Second: 14,634.22469

Timestep Collection Time: 2.46651
Timestep Consumption Time: 0.95164
PPO Batch Consumption Time: 0.10903
Total Iteration Time: 3.41815

Cumulative Model Updates: 20,135
Cumulative Timesteps: 336,215,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,387.61983
Policy Entropy: 0.74353
Value Function Loss: 0.08195

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03894
Policy Update Magnitude: 0.03209
Value Function Update Magnitude: 0.07317

Collected Steps per Second: 21,605.62012
Overall Steps per Second: 16,363.45824

Timestep Collection Time: 2.31532
Timestep Consumption Time: 0.74173
PPO Batch Consumption Time: 0.06226
Total Iteration Time: 3.05706

Cumulative Model Updates: 20,138
Cumulative Timesteps: 336,265,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 336265380...
Checkpoint 336265380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,806.70532
Policy Entropy: 0.74012
Value Function Loss: 0.09587

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03620
Policy Update Magnitude: 0.03693
Value Function Update Magnitude: 0.06991

Collected Steps per Second: 20,067.17723
Overall Steps per Second: 15,041.42088

Timestep Collection Time: 2.49323
Timestep Consumption Time: 0.83306
PPO Batch Consumption Time: 0.08108
Total Iteration Time: 3.32628

Cumulative Model Updates: 20,141
Cumulative Timesteps: 336,315,412

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,960.94466
Policy Entropy: 0.73785
Value Function Loss: 0.09472

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03843
Policy Update Magnitude: 0.03939
Value Function Update Magnitude: 0.07301

Collected Steps per Second: 22,171.77503
Overall Steps per Second: 16,773.87184

Timestep Collection Time: 2.25512
Timestep Consumption Time: 0.72571
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 2.98083

Cumulative Model Updates: 20,144
Cumulative Timesteps: 336,365,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 336365412...
Checkpoint 336365412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,636.30632
Policy Entropy: 0.74416
Value Function Loss: 0.08690

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04814
Policy Update Magnitude: 0.03834
Value Function Update Magnitude: 0.08654

Collected Steps per Second: 19,259.58675
Overall Steps per Second: 14,558.93158

Timestep Collection Time: 2.59704
Timestep Consumption Time: 0.83851
PPO Batch Consumption Time: 0.08544
Total Iteration Time: 3.43555

Cumulative Model Updates: 20,147
Cumulative Timesteps: 336,415,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,414.06643
Policy Entropy: 0.75950
Value Function Loss: 0.07083

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.05043
Policy Update Magnitude: 0.03376
Value Function Update Magnitude: 0.08367

Collected Steps per Second: 21,540.52537
Overall Steps per Second: 16,380.29112

Timestep Collection Time: 2.32130
Timestep Consumption Time: 0.73127
PPO Batch Consumption Time: 0.05933
Total Iteration Time: 3.05257

Cumulative Model Updates: 20,150
Cumulative Timesteps: 336,465,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 336465432...
Checkpoint 336465432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,017.25987
Policy Entropy: 0.76463
Value Function Loss: 0.06794

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05609
Policy Update Magnitude: 0.03019
Value Function Update Magnitude: 0.07322

Collected Steps per Second: 21,697.11448
Overall Steps per Second: 16,141.83073

Timestep Collection Time: 2.30528
Timestep Consumption Time: 0.79337
PPO Batch Consumption Time: 0.07760
Total Iteration Time: 3.09866

Cumulative Model Updates: 20,153
Cumulative Timesteps: 336,515,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,120.93107
Policy Entropy: 0.75995
Value Function Loss: 0.06651

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03783
Policy Update Magnitude: 0.02983
Value Function Update Magnitude: 0.06663

Collected Steps per Second: 22,003.73860
Overall Steps per Second: 16,680.88486

Timestep Collection Time: 2.27261
Timestep Consumption Time: 0.72519
PPO Batch Consumption Time: 0.05948
Total Iteration Time: 2.99780

Cumulative Model Updates: 20,156
Cumulative Timesteps: 336,565,456

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 336565456...
Checkpoint 336565456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,007.39785
Policy Entropy: 0.76622
Value Function Loss: 0.06007

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03881
Policy Update Magnitude: 0.02868
Value Function Update Magnitude: 0.07113

Collected Steps per Second: 19,592.55768
Overall Steps per Second: 14,963.66640

Timestep Collection Time: 2.55311
Timestep Consumption Time: 0.78979
PPO Batch Consumption Time: 0.08020
Total Iteration Time: 3.34290

Cumulative Model Updates: 20,159
Cumulative Timesteps: 336,615,478

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,941.28951
Policy Entropy: 0.76228
Value Function Loss: 0.05888

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02872
Policy Update Magnitude: 0.02972
Value Function Update Magnitude: 0.06668

Collected Steps per Second: 21,334.48878
Overall Steps per Second: 16,035.15202

Timestep Collection Time: 2.34390
Timestep Consumption Time: 0.77462
PPO Batch Consumption Time: 0.06593
Total Iteration Time: 3.11852

Cumulative Model Updates: 20,162
Cumulative Timesteps: 336,665,484

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 336665484...
Checkpoint 336665484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,915.03753
Policy Entropy: 0.77116
Value Function Loss: 0.05927

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.06194
Policy Update Magnitude: 0.02825
Value Function Update Magnitude: 0.06270

Collected Steps per Second: 22,166.58489
Overall Steps per Second: 15,599.50439

Timestep Collection Time: 2.25628
Timestep Consumption Time: 0.94985
PPO Batch Consumption Time: 0.10605
Total Iteration Time: 3.20613

Cumulative Model Updates: 20,165
Cumulative Timesteps: 336,715,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,759.54895
Policy Entropy: 0.76502
Value Function Loss: 0.05889

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05810
Policy Update Magnitude: 0.02639
Value Function Update Magnitude: 0.05812

Collected Steps per Second: 22,256.67556
Overall Steps per Second: 16,567.06821

Timestep Collection Time: 2.24652
Timestep Consumption Time: 0.77152
PPO Batch Consumption Time: 0.06280
Total Iteration Time: 3.01804

Cumulative Model Updates: 20,168
Cumulative Timesteps: 336,765,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 336765498...
Checkpoint 336765498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,450.42955
Policy Entropy: 0.76989
Value Function Loss: 0.05788

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03615
Policy Update Magnitude: 0.02631
Value Function Update Magnitude: 0.05449

Collected Steps per Second: 20,402.60604
Overall Steps per Second: 14,926.80664

Timestep Collection Time: 2.45204
Timestep Consumption Time: 0.89951
PPO Batch Consumption Time: 0.09313
Total Iteration Time: 3.35155

Cumulative Model Updates: 20,171
Cumulative Timesteps: 336,815,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,825.20300
Policy Entropy: 0.76186
Value Function Loss: 0.05593

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.05313
Policy Update Magnitude: 0.02540
Value Function Update Magnitude: 0.04971

Collected Steps per Second: 22,552.93487
Overall Steps per Second: 16,637.24480

Timestep Collection Time: 2.21772
Timestep Consumption Time: 0.78855
PPO Batch Consumption Time: 0.05782
Total Iteration Time: 3.00627

Cumulative Model Updates: 20,174
Cumulative Timesteps: 336,865,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 336865542...
Checkpoint 336865542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,422.19462
Policy Entropy: 0.77720
Value Function Loss: 0.05789

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02895
Policy Update Magnitude: 0.02787
Value Function Update Magnitude: 0.05726

Collected Steps per Second: 19,972.22301
Overall Steps per Second: 14,612.67004

Timestep Collection Time: 2.50488
Timestep Consumption Time: 0.91873
PPO Batch Consumption Time: 0.08836
Total Iteration Time: 3.42360

Cumulative Model Updates: 20,177
Cumulative Timesteps: 336,915,570

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,478.08964
Policy Entropy: 0.77703
Value Function Loss: 0.05511

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.03224
Value Function Update Magnitude: 0.05221

Collected Steps per Second: 21,905.33578
Overall Steps per Second: 16,282.99403

Timestep Collection Time: 2.28273
Timestep Consumption Time: 0.78820
PPO Batch Consumption Time: 0.05951
Total Iteration Time: 3.07093

Cumulative Model Updates: 20,180
Cumulative Timesteps: 336,965,574

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 336965574...
Checkpoint 336965574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,354.09220
Policy Entropy: 0.79173
Value Function Loss: 0.05589

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04572
Policy Update Magnitude: 0.03012
Value Function Update Magnitude: 0.04836

Collected Steps per Second: 22,228.43038
Overall Steps per Second: 15,437.64870

Timestep Collection Time: 2.24937
Timestep Consumption Time: 0.98946
PPO Batch Consumption Time: 0.10464
Total Iteration Time: 3.23884

Cumulative Model Updates: 20,183
Cumulative Timesteps: 337,015,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,292.68013
Policy Entropy: 0.78354
Value Function Loss: 0.05758

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04115
Policy Update Magnitude: 0.02773
Value Function Update Magnitude: 0.04703

Collected Steps per Second: 22,792.73644
Overall Steps per Second: 16,776.44299

Timestep Collection Time: 2.19570
Timestep Consumption Time: 0.78741
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 2.98311

Cumulative Model Updates: 20,186
Cumulative Timesteps: 337,065,620

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 337065620...
Checkpoint 337065620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,203.67084
Policy Entropy: 0.79491
Value Function Loss: 0.05899

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04707
Policy Update Magnitude: 0.02854
Value Function Update Magnitude: 0.05424

Collected Steps per Second: 19,774.01431
Overall Steps per Second: 13,997.86569

Timestep Collection Time: 2.53059
Timestep Consumption Time: 1.04424
PPO Batch Consumption Time: 0.12566
Total Iteration Time: 3.57483

Cumulative Model Updates: 20,189
Cumulative Timesteps: 337,115,660

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,963.34859
Policy Entropy: 0.79258
Value Function Loss: 0.05769

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01739
Policy Update Magnitude: 0.02797
Value Function Update Magnitude: 0.05048

Collected Steps per Second: 22,467.51732
Overall Steps per Second: 16,752.40132

Timestep Collection Time: 2.22633
Timestep Consumption Time: 0.75952
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 2.98584

Cumulative Model Updates: 20,192
Cumulative Timesteps: 337,165,680

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 337165680...
Checkpoint 337165680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,637.80781
Policy Entropy: 0.79982
Value Function Loss: 0.05477

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03818
Policy Update Magnitude: 0.02780
Value Function Update Magnitude: 0.04941

Collected Steps per Second: 20,157.61369
Overall Steps per Second: 14,661.32624

Timestep Collection Time: 2.48135
Timestep Consumption Time: 0.93022
PPO Batch Consumption Time: 0.09586
Total Iteration Time: 3.41156

Cumulative Model Updates: 20,195
Cumulative Timesteps: 337,215,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,395.04160
Policy Entropy: 0.79139
Value Function Loss: 0.06226

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04043
Policy Update Magnitude: 0.02713
Value Function Update Magnitude: 0.04629

Collected Steps per Second: 22,118.77876
Overall Steps per Second: 16,311.74957

Timestep Collection Time: 2.26125
Timestep Consumption Time: 0.80501
PPO Batch Consumption Time: 0.05991
Total Iteration Time: 3.06626

Cumulative Model Updates: 20,198
Cumulative Timesteps: 337,265,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 337265714...
Checkpoint 337265714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,884.66244
Policy Entropy: 0.79144
Value Function Loss: 0.06549

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05653
Policy Update Magnitude: 0.02853
Value Function Update Magnitude: 0.05197

Collected Steps per Second: 22,651.67417
Overall Steps per Second: 16,558.29349

Timestep Collection Time: 2.20823
Timestep Consumption Time: 0.81262
PPO Batch Consumption Time: 0.05851
Total Iteration Time: 3.02084

Cumulative Model Updates: 20,201
Cumulative Timesteps: 337,315,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,931.90209
Policy Entropy: 0.78135
Value Function Loss: 0.07266

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02158
Policy Update Magnitude: 0.03176
Value Function Update Magnitude: 0.05424

Collected Steps per Second: 22,638.93048
Overall Steps per Second: 16,697.05642

Timestep Collection Time: 2.20858
Timestep Consumption Time: 0.78595
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 2.99454

Cumulative Model Updates: 20,204
Cumulative Timesteps: 337,365,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 337365734...
Checkpoint 337365734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,594.92712
Policy Entropy: 0.79312
Value Function Loss: 0.06975

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04991
Policy Update Magnitude: 0.03671
Value Function Update Magnitude: 0.06443

Collected Steps per Second: 22,130.44689
Overall Steps per Second: 16,356.57236

Timestep Collection Time: 2.25996
Timestep Consumption Time: 0.79777
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 3.05773

Cumulative Model Updates: 20,207
Cumulative Timesteps: 337,415,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,328.70711
Policy Entropy: 0.78895
Value Function Loss: 0.07767

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03429
Policy Update Magnitude: 0.03385
Value Function Update Magnitude: 0.06177

Collected Steps per Second: 21,056.56283
Overall Steps per Second: 14,743.51719

Timestep Collection Time: 2.37503
Timestep Consumption Time: 1.01697
PPO Batch Consumption Time: 0.11890
Total Iteration Time: 3.39200

Cumulative Model Updates: 20,210
Cumulative Timesteps: 337,465,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 337465758...
Checkpoint 337465758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,069.56978
Policy Entropy: 0.78784
Value Function Loss: 0.08292

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02067
Policy Update Magnitude: 0.03520
Value Function Update Magnitude: 0.06291

Collected Steps per Second: 22,224.93829
Overall Steps per Second: 16,455.91544

Timestep Collection Time: 2.25080
Timestep Consumption Time: 0.78907
PPO Batch Consumption Time: 0.05754
Total Iteration Time: 3.03988

Cumulative Model Updates: 20,213
Cumulative Timesteps: 337,515,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,148.31819
Policy Entropy: 0.77885
Value Function Loss: 0.08404

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02928
Policy Update Magnitude: 0.03459
Value Function Update Magnitude: 0.05940

Collected Steps per Second: 20,801.34709
Overall Steps per Second: 14,974.00039

Timestep Collection Time: 2.40494
Timestep Consumption Time: 0.93592
PPO Batch Consumption Time: 0.09879
Total Iteration Time: 3.34086

Cumulative Model Updates: 20,216
Cumulative Timesteps: 337,565,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 337565808...
Checkpoint 337565808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,920.16330
Policy Entropy: 0.78733
Value Function Loss: 0.08020

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04079
Policy Update Magnitude: 0.03744
Value Function Update Magnitude: 0.06204

Collected Steps per Second: 21,996.44024
Overall Steps per Second: 16,338.59962

Timestep Collection Time: 2.27319
Timestep Consumption Time: 0.78717
PPO Batch Consumption Time: 0.05836
Total Iteration Time: 3.06036

Cumulative Model Updates: 20,219
Cumulative Timesteps: 337,615,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,988.30062
Policy Entropy: 0.77384
Value Function Loss: 0.07853

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03816
Policy Update Magnitude: 0.03561
Value Function Update Magnitude: 0.05797

Collected Steps per Second: 22,854.66353
Overall Steps per Second: 16,092.46404

Timestep Collection Time: 2.18861
Timestep Consumption Time: 0.91967
PPO Batch Consumption Time: 0.09853
Total Iteration Time: 3.10829

Cumulative Model Updates: 20,222
Cumulative Timesteps: 337,665,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 337665830...
Checkpoint 337665830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,313.93192
Policy Entropy: 0.78482
Value Function Loss: 0.07853

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05425
Policy Update Magnitude: 0.03598
Value Function Update Magnitude: 0.06269

Collected Steps per Second: 21,649.30890
Overall Steps per Second: 16,455.88053

Timestep Collection Time: 2.31028
Timestep Consumption Time: 0.72912
PPO Batch Consumption Time: 0.05957
Total Iteration Time: 3.03940

Cumulative Model Updates: 20,225
Cumulative Timesteps: 337,715,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,205.71231
Policy Entropy: 0.77424
Value Function Loss: 0.07988

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04623
Policy Update Magnitude: 0.03343
Value Function Update Magnitude: 0.05997

Collected Steps per Second: 19,683.73984
Overall Steps per Second: 14,796.86182

Timestep Collection Time: 2.54179
Timestep Consumption Time: 0.83946
PPO Batch Consumption Time: 0.08463
Total Iteration Time: 3.38126

Cumulative Model Updates: 20,228
Cumulative Timesteps: 337,765,878

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 337765878...
Checkpoint 337765878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,062.36095
Policy Entropy: 0.79260
Value Function Loss: 0.07597

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03929
Policy Update Magnitude: 0.03223
Value Function Update Magnitude: 0.05783

Collected Steps per Second: 21,387.10859
Overall Steps per Second: 16,267.29669

Timestep Collection Time: 2.33898
Timestep Consumption Time: 0.73615
PPO Batch Consumption Time: 0.05953
Total Iteration Time: 3.07513

Cumulative Model Updates: 20,231
Cumulative Timesteps: 337,815,902

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,403.72107
Policy Entropy: 0.77376
Value Function Loss: 0.07481

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03786
Policy Update Magnitude: 0.03409
Value Function Update Magnitude: 0.05618

Collected Steps per Second: 21,443.05318
Overall Steps per Second: 15,425.44468

Timestep Collection Time: 2.33269
Timestep Consumption Time: 0.91000
PPO Batch Consumption Time: 0.11088
Total Iteration Time: 3.24269

Cumulative Model Updates: 20,234
Cumulative Timesteps: 337,865,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 337865922...
Checkpoint 337865922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,330.37970
Policy Entropy: 0.78100
Value Function Loss: 0.06815

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03883
Policy Update Magnitude: 0.03345
Value Function Update Magnitude: 0.06320

Collected Steps per Second: 21,262.68674
Overall Steps per Second: 16,385.09079

Timestep Collection Time: 2.35191
Timestep Consumption Time: 0.70013
PPO Batch Consumption Time: 0.05837
Total Iteration Time: 3.05204

Cumulative Model Updates: 20,237
Cumulative Timesteps: 337,915,930

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,560.85502
Policy Entropy: 0.77410
Value Function Loss: 0.06922

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03329
Policy Update Magnitude: 0.03401
Value Function Update Magnitude: 0.06313

Collected Steps per Second: 20,632.21481
Overall Steps per Second: 15,077.35099

Timestep Collection Time: 2.42475
Timestep Consumption Time: 0.89334
PPO Batch Consumption Time: 0.11280
Total Iteration Time: 3.31809

Cumulative Model Updates: 20,240
Cumulative Timesteps: 337,965,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 337965958...
Checkpoint 337965958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,680.28868
Policy Entropy: 0.79136
Value Function Loss: 0.06108

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03270
Policy Update Magnitude: 0.03263
Value Function Update Magnitude: 0.07072

Collected Steps per Second: 21,798.69954
Overall Steps per Second: 16,715.27250

Timestep Collection Time: 2.29445
Timestep Consumption Time: 0.69778
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 2.99223

Cumulative Model Updates: 20,243
Cumulative Timesteps: 338,015,974

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,453.80062
Policy Entropy: 0.78448
Value Function Loss: 0.06213

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03623
Policy Update Magnitude: 0.03254
Value Function Update Magnitude: 0.07110

Collected Steps per Second: 19,778.67757
Overall Steps per Second: 14,711.94345

Timestep Collection Time: 2.52969
Timestep Consumption Time: 0.87122
PPO Batch Consumption Time: 0.10828
Total Iteration Time: 3.40091

Cumulative Model Updates: 20,246
Cumulative Timesteps: 338,066,008

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 338066008...
Checkpoint 338066008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,854.96512
Policy Entropy: 0.78876
Value Function Loss: 0.05990

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05840
Policy Update Magnitude: 0.03614
Value Function Update Magnitude: 0.06496

Collected Steps per Second: 21,073.88940
Overall Steps per Second: 16,257.26143

Timestep Collection Time: 2.37327
Timestep Consumption Time: 0.70314
PPO Batch Consumption Time: 0.05762
Total Iteration Time: 3.07641

Cumulative Model Updates: 20,249
Cumulative Timesteps: 338,116,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,292.14524
Policy Entropy: 0.78360
Value Function Loss: 0.06461

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05743
Policy Update Magnitude: 0.04090
Value Function Update Magnitude: 0.06035

Collected Steps per Second: 21,767.23560
Overall Steps per Second: 15,838.54339

Timestep Collection Time: 2.29758
Timestep Consumption Time: 0.86003
PPO Batch Consumption Time: 0.07658
Total Iteration Time: 3.15761

Cumulative Model Updates: 20,252
Cumulative Timesteps: 338,166,034

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 338166034...
Checkpoint 338166034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,943.28017
Policy Entropy: 0.79079
Value Function Loss: 0.07096

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07163
Policy Update Magnitude: 0.03572
Value Function Update Magnitude: 0.06948

Collected Steps per Second: 22,258.52979
Overall Steps per Second: 16,384.27632

Timestep Collection Time: 2.24759
Timestep Consumption Time: 0.80583
PPO Batch Consumption Time: 0.06212
Total Iteration Time: 3.05342

Cumulative Model Updates: 20,255
Cumulative Timesteps: 338,216,062

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,689.96681
Policy Entropy: 0.77602
Value Function Loss: 0.06974

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04215
Policy Update Magnitude: 0.03351
Value Function Update Magnitude: 0.07360

Collected Steps per Second: 22,578.27133
Overall Steps per Second: 16,665.90729

Timestep Collection Time: 2.21461
Timestep Consumption Time: 0.78565
PPO Batch Consumption Time: 0.06363
Total Iteration Time: 3.00026

Cumulative Model Updates: 20,258
Cumulative Timesteps: 338,266,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 338266064...
Checkpoint 338266064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,464.16648
Policy Entropy: 0.76261
Value Function Loss: 0.07816

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03677
Policy Update Magnitude: 0.03433
Value Function Update Magnitude: 0.07485

Collected Steps per Second: 21,788.30052
Overall Steps per Second: 16,127.14785

Timestep Collection Time: 2.29655
Timestep Consumption Time: 0.80616
PPO Batch Consumption Time: 0.06664
Total Iteration Time: 3.10272

Cumulative Model Updates: 20,261
Cumulative Timesteps: 338,316,102

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,242.89773
Policy Entropy: 0.75377
Value Function Loss: 0.06689

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04133
Policy Update Magnitude: 0.03290
Value Function Update Magnitude: 0.07859

Collected Steps per Second: 19,907.40105
Overall Steps per Second: 14,770.37213

Timestep Collection Time: 2.51223
Timestep Consumption Time: 0.87374
PPO Batch Consumption Time: 0.08610
Total Iteration Time: 3.38597

Cumulative Model Updates: 20,264
Cumulative Timesteps: 338,366,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 338366114...
Checkpoint 338366114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,468.25965
Policy Entropy: 0.75740
Value Function Loss: 0.06772

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03789
Policy Update Magnitude: 0.03133
Value Function Update Magnitude: 0.08129

Collected Steps per Second: 21,948.29195
Overall Steps per Second: 16,467.96108

Timestep Collection Time: 2.27927
Timestep Consumption Time: 0.75851
PPO Batch Consumption Time: 0.06007
Total Iteration Time: 3.03778

Cumulative Model Updates: 20,267
Cumulative Timesteps: 338,416,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,641.38825
Policy Entropy: 0.76425
Value Function Loss: 0.06183

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02889
Policy Update Magnitude: 0.03151
Value Function Update Magnitude: 0.07611

Collected Steps per Second: 22,364.38156
Overall Steps per Second: 16,459.58343

Timestep Collection Time: 2.23614
Timestep Consumption Time: 0.80221
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 3.03835

Cumulative Model Updates: 20,270
Cumulative Timesteps: 338,466,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 338466150...
Checkpoint 338466150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,122.96365
Policy Entropy: 0.76539
Value Function Loss: 0.06279

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03167
Policy Update Magnitude: 0.03249
Value Function Update Magnitude: 0.07510

Collected Steps per Second: 20,364.20669
Overall Steps per Second: 14,603.00511

Timestep Collection Time: 2.45548
Timestep Consumption Time: 0.96874
PPO Batch Consumption Time: 0.10521
Total Iteration Time: 3.42423

Cumulative Model Updates: 20,273
Cumulative Timesteps: 338,516,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,767.82839
Policy Entropy: 0.76085
Value Function Loss: 0.06012

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03384
Policy Update Magnitude: 0.02970
Value Function Update Magnitude: 0.07173

Collected Steps per Second: 22,283.39500
Overall Steps per Second: 16,483.77012

Timestep Collection Time: 2.24508
Timestep Consumption Time: 0.78991
PPO Batch Consumption Time: 0.05935
Total Iteration Time: 3.03499

Cumulative Model Updates: 20,276
Cumulative Timesteps: 338,566,182

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 338566182...
Checkpoint 338566182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,932.65546
Policy Entropy: 0.75614
Value Function Loss: 0.05833

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03486
Policy Update Magnitude: 0.03078
Value Function Update Magnitude: 0.06435

Collected Steps per Second: 20,504.82176
Overall Steps per Second: 14,970.05002

Timestep Collection Time: 2.43884
Timestep Consumption Time: 0.90170
PPO Batch Consumption Time: 0.08978
Total Iteration Time: 3.34054

Cumulative Model Updates: 20,279
Cumulative Timesteps: 338,616,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,600.82081
Policy Entropy: 0.74715
Value Function Loss: 0.05678

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01905
Policy Update Magnitude: 0.03173
Value Function Update Magnitude: 0.06087

Collected Steps per Second: 22,349.94528
Overall Steps per Second: 16,564.95294

Timestep Collection Time: 2.23741
Timestep Consumption Time: 0.78137
PPO Batch Consumption Time: 0.06037
Total Iteration Time: 3.01878

Cumulative Model Updates: 20,282
Cumulative Timesteps: 338,666,196

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 338666196...
Checkpoint 338666196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,242.73709
Policy Entropy: 0.75417
Value Function Loss: 0.05489

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03718
Policy Update Magnitude: 0.03112
Value Function Update Magnitude: 0.05356

Collected Steps per Second: 19,955.11018
Overall Steps per Second: 14,138.82780

Timestep Collection Time: 2.50663
Timestep Consumption Time: 1.03115
PPO Batch Consumption Time: 0.12511
Total Iteration Time: 3.53778

Cumulative Model Updates: 20,285
Cumulative Timesteps: 338,716,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,662.96373
Policy Entropy: 0.74579
Value Function Loss: 0.06263

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03722
Policy Update Magnitude: 0.02631
Value Function Update Magnitude: 0.05532

Collected Steps per Second: 22,860.95154
Overall Steps per Second: 16,809.99093

Timestep Collection Time: 2.18749
Timestep Consumption Time: 0.78741
PPO Batch Consumption Time: 0.05864
Total Iteration Time: 2.97490

Cumulative Model Updates: 20,288
Cumulative Timesteps: 338,766,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 338766224...
Checkpoint 338766224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,015.38666
Policy Entropy: 0.75429
Value Function Loss: 0.06621

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03389
Policy Update Magnitude: 0.03141
Value Function Update Magnitude: 0.05325

Collected Steps per Second: 20,427.38227
Overall Steps per Second: 14,647.12588

Timestep Collection Time: 2.44858
Timestep Consumption Time: 0.96629
PPO Batch Consumption Time: 0.11305
Total Iteration Time: 3.41487

Cumulative Model Updates: 20,291
Cumulative Timesteps: 338,816,242

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,071.85958
Policy Entropy: 0.75522
Value Function Loss: 0.07009

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01317
Policy Update Magnitude: 0.03119
Value Function Update Magnitude: 0.05809

Collected Steps per Second: 22,364.71967
Overall Steps per Second: 16,471.47908

Timestep Collection Time: 2.23647
Timestep Consumption Time: 0.80017
PPO Batch Consumption Time: 0.06086
Total Iteration Time: 3.03664

Cumulative Model Updates: 20,294
Cumulative Timesteps: 338,866,260

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 338866260...
Checkpoint 338866260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,543.61973
Policy Entropy: 0.76110
Value Function Loss: 0.06995

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01723
Policy Update Magnitude: 0.03146
Value Function Update Magnitude: 0.06078

Collected Steps per Second: 21,029.65306
Overall Steps per Second: 14,991.79622

Timestep Collection Time: 2.37769
Timestep Consumption Time: 0.95760
PPO Batch Consumption Time: 0.11579
Total Iteration Time: 3.33529

Cumulative Model Updates: 20,297
Cumulative Timesteps: 338,916,262

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,257.51189
Policy Entropy: 0.77074
Value Function Loss: 0.06901

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02985
Policy Update Magnitude: 0.03093
Value Function Update Magnitude: 0.06901

Collected Steps per Second: 22,418.23431
Overall Steps per Second: 16,537.02794

Timestep Collection Time: 2.23033
Timestep Consumption Time: 0.79319
PPO Batch Consumption Time: 0.05900
Total Iteration Time: 3.02352

Cumulative Model Updates: 20,300
Cumulative Timesteps: 338,966,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 338966262...
Checkpoint 338966262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,827.83478
Policy Entropy: 0.77167
Value Function Loss: 0.06652

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04351
Policy Update Magnitude: 0.02851
Value Function Update Magnitude: 0.07372

Collected Steps per Second: 20,449.47540
Overall Steps per Second: 14,902.46296

Timestep Collection Time: 2.44515
Timestep Consumption Time: 0.91014
PPO Batch Consumption Time: 0.09006
Total Iteration Time: 3.35528

Cumulative Model Updates: 20,303
Cumulative Timesteps: 339,016,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,837.97642
Policy Entropy: 0.77921
Value Function Loss: 0.05789

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02985
Policy Update Magnitude: 0.02958
Value Function Update Magnitude: 0.07350

Collected Steps per Second: 22,300.06434
Overall Steps per Second: 16,404.26734

Timestep Collection Time: 2.24403
Timestep Consumption Time: 0.80652
PPO Batch Consumption Time: 0.06197
Total Iteration Time: 3.05055

Cumulative Model Updates: 20,306
Cumulative Timesteps: 339,066,306

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 339066306...
Checkpoint 339066306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,764.10205
Policy Entropy: 0.77087
Value Function Loss: 0.06091

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04809
Policy Update Magnitude: 0.03002
Value Function Update Magnitude: 0.07369

Collected Steps per Second: 20,461.46481
Overall Steps per Second: 14,884.35186

Timestep Collection Time: 2.44489
Timestep Consumption Time: 0.91609
PPO Batch Consumption Time: 0.08302
Total Iteration Time: 3.36098

Cumulative Model Updates: 20,309
Cumulative Timesteps: 339,116,332

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,412.54016
Policy Entropy: 0.77872
Value Function Loss: 0.06524

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03600
Policy Update Magnitude: 0.02982
Value Function Update Magnitude: 0.07194

Collected Steps per Second: 22,405.03702
Overall Steps per Second: 16,639.99438

Timestep Collection Time: 2.23173
Timestep Consumption Time: 0.77320
PPO Batch Consumption Time: 0.05913
Total Iteration Time: 3.00493

Cumulative Model Updates: 20,312
Cumulative Timesteps: 339,166,334

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 339166334...
Checkpoint 339166334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,998.97850
Policy Entropy: 0.76431
Value Function Loss: 0.07159

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.05478
Policy Update Magnitude: 0.02688
Value Function Update Magnitude: 0.06871

Collected Steps per Second: 20,682.03310
Overall Steps per Second: 15,020.31230

Timestep Collection Time: 2.41775
Timestep Consumption Time: 0.91134
PPO Batch Consumption Time: 0.08785
Total Iteration Time: 3.32909

Cumulative Model Updates: 20,315
Cumulative Timesteps: 339,216,338

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,924.51463
Policy Entropy: 0.76559
Value Function Loss: 0.07508

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03198
Policy Update Magnitude: 0.02789
Value Function Update Magnitude: 0.06680

Collected Steps per Second: 22,440.65860
Overall Steps per Second: 16,686.56373

Timestep Collection Time: 2.22810
Timestep Consumption Time: 0.76832
PPO Batch Consumption Time: 0.05884
Total Iteration Time: 2.99642

Cumulative Model Updates: 20,318
Cumulative Timesteps: 339,266,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 339266338...
Checkpoint 339266338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,839.23800
Policy Entropy: 0.75979
Value Function Loss: 0.07196

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04125
Policy Update Magnitude: 0.02817
Value Function Update Magnitude: 0.06039

Collected Steps per Second: 18,956.93382
Overall Steps per Second: 13,998.91376

Timestep Collection Time: 2.64019
Timestep Consumption Time: 0.93508
PPO Batch Consumption Time: 0.08050
Total Iteration Time: 3.57528

Cumulative Model Updates: 20,321
Cumulative Timesteps: 339,316,388

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,266.91784
Policy Entropy: 0.76671
Value Function Loss: 0.07563

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02459
Policy Update Magnitude: 0.03082
Value Function Update Magnitude: 0.06341

Collected Steps per Second: 20,865.45344
Overall Steps per Second: 15,582.73062

Timestep Collection Time: 2.39803
Timestep Consumption Time: 0.81296
PPO Batch Consumption Time: 0.06292
Total Iteration Time: 3.21099

Cumulative Model Updates: 20,324
Cumulative Timesteps: 339,366,424

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 339366424...
Checkpoint 339366424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,257.95342
Policy Entropy: 0.76491
Value Function Loss: 0.07562

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01591
Policy Update Magnitude: 0.03278
Value Function Update Magnitude: 0.07039

Collected Steps per Second: 18,747.53904
Overall Steps per Second: 13,399.75552

Timestep Collection Time: 2.66766
Timestep Consumption Time: 1.06465
PPO Batch Consumption Time: 0.12375
Total Iteration Time: 3.73231

Cumulative Model Updates: 20,327
Cumulative Timesteps: 339,416,436

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,448.19408
Policy Entropy: 0.77584
Value Function Loss: 0.07258

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.03036
Value Function Update Magnitude: 0.07069

Collected Steps per Second: 22,906.35184
Overall Steps per Second: 16,938.15727

Timestep Collection Time: 2.18306
Timestep Consumption Time: 0.76921
PPO Batch Consumption Time: 0.05822
Total Iteration Time: 2.95227

Cumulative Model Updates: 20,330
Cumulative Timesteps: 339,466,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 339466442...
Checkpoint 339466442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,730.46682
Policy Entropy: 0.76592
Value Function Loss: 0.06615

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01896
Policy Update Magnitude: 0.02982
Value Function Update Magnitude: 0.08073

Collected Steps per Second: 21,140.81372
Overall Steps per Second: 15,275.12445

Timestep Collection Time: 2.36642
Timestep Consumption Time: 0.90871
PPO Batch Consumption Time: 0.08569
Total Iteration Time: 3.27513

Cumulative Model Updates: 20,333
Cumulative Timesteps: 339,516,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,580.01267
Policy Entropy: 0.78525
Value Function Loss: 0.05999

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.03162
Value Function Update Magnitude: 0.08102

Collected Steps per Second: 22,354.63620
Overall Steps per Second: 16,569.19151

Timestep Collection Time: 2.23748
Timestep Consumption Time: 0.78126
PPO Batch Consumption Time: 0.05815
Total Iteration Time: 3.01874

Cumulative Model Updates: 20,336
Cumulative Timesteps: 339,566,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 339566488...
Checkpoint 339566488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,679.26475
Policy Entropy: 0.77683
Value Function Loss: 0.06739

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.03050
Value Function Update Magnitude: 0.07568

Collected Steps per Second: 21,389.51259
Overall Steps per Second: 15,041.79908

Timestep Collection Time: 2.33825
Timestep Consumption Time: 0.98675
PPO Batch Consumption Time: 0.11069
Total Iteration Time: 3.32500

Cumulative Model Updates: 20,339
Cumulative Timesteps: 339,616,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,503.40034
Policy Entropy: 0.78997
Value Function Loss: 0.07585

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.05003
Policy Update Magnitude: 0.02958
Value Function Update Magnitude: 0.08197

Collected Steps per Second: 22,442.32483
Overall Steps per Second: 16,729.99021

Timestep Collection Time: 2.22909
Timestep Consumption Time: 0.76111
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 2.99020

Cumulative Model Updates: 20,342
Cumulative Timesteps: 339,666,528

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 339666528...
Checkpoint 339666528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,782.88342
Policy Entropy: 0.78165
Value Function Loss: 0.07550

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03180
Policy Update Magnitude: 0.02797
Value Function Update Magnitude: 0.08914

Collected Steps per Second: 20,022.97763
Overall Steps per Second: 14,770.31476

Timestep Collection Time: 2.49843
Timestep Consumption Time: 0.88850
PPO Batch Consumption Time: 0.08341
Total Iteration Time: 3.38693

Cumulative Model Updates: 20,345
Cumulative Timesteps: 339,716,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,086.55922
Policy Entropy: 0.79294
Value Function Loss: 0.06941

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04309
Policy Update Magnitude: 0.02828
Value Function Update Magnitude: 0.08564

Collected Steps per Second: 22,613.43510
Overall Steps per Second: 16,833.55993

Timestep Collection Time: 2.21240
Timestep Consumption Time: 0.75964
PPO Batch Consumption Time: 0.05788
Total Iteration Time: 2.97204

Cumulative Model Updates: 20,348
Cumulative Timesteps: 339,766,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 339766584...
Checkpoint 339766584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,894.45146
Policy Entropy: 0.79530
Value Function Loss: 0.05874

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04364
Policy Update Magnitude: 0.02707
Value Function Update Magnitude: 0.07760

Collected Steps per Second: 20,615.64992
Overall Steps per Second: 14,737.66841

Timestep Collection Time: 2.42660
Timestep Consumption Time: 0.96783
PPO Batch Consumption Time: 0.10309
Total Iteration Time: 3.39443

Cumulative Model Updates: 20,351
Cumulative Timesteps: 339,816,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,746.76221
Policy Entropy: 0.79121
Value Function Loss: 0.06315

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04473
Policy Update Magnitude: 0.02723
Value Function Update Magnitude: 0.06340

Collected Steps per Second: 22,018.88466
Overall Steps per Second: 16,172.12971

Timestep Collection Time: 2.27150
Timestep Consumption Time: 0.82122
PPO Batch Consumption Time: 0.06406
Total Iteration Time: 3.09273

Cumulative Model Updates: 20,354
Cumulative Timesteps: 339,866,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 339866626...
Checkpoint 339866626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,249.12560
Policy Entropy: 0.78577
Value Function Loss: 0.06824

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03357
Policy Update Magnitude: 0.02805
Value Function Update Magnitude: 0.05799

Collected Steps per Second: 22,472.80397
Overall Steps per Second: 16,525.33976

Timestep Collection Time: 2.22491
Timestep Consumption Time: 0.80074
PPO Batch Consumption Time: 0.06052
Total Iteration Time: 3.02566

Cumulative Model Updates: 20,357
Cumulative Timesteps: 339,916,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,093.70630
Policy Entropy: 0.78964
Value Function Loss: 0.06799

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05101
Policy Update Magnitude: 0.02872
Value Function Update Magnitude: 0.05318

Collected Steps per Second: 20,862.73389
Overall Steps per Second: 15,172.89381

Timestep Collection Time: 2.39806
Timestep Consumption Time: 0.89927
PPO Batch Consumption Time: 0.08695
Total Iteration Time: 3.29733

Cumulative Model Updates: 20,360
Cumulative Timesteps: 339,966,656

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 339966656...
Checkpoint 339966656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,201.06062
Policy Entropy: 0.78924
Value Function Loss: 0.06561

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03947
Policy Update Magnitude: 0.03279
Value Function Update Magnitude: 0.05319

Collected Steps per Second: 22,340.67910
Overall Steps per Second: 16,382.61554

Timestep Collection Time: 2.23950
Timestep Consumption Time: 0.81447
PPO Batch Consumption Time: 0.05975
Total Iteration Time: 3.05397

Cumulative Model Updates: 20,363
Cumulative Timesteps: 340,016,688

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,354.82094
Policy Entropy: 0.78971
Value Function Loss: 0.05691

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05654
Policy Update Magnitude: 0.02984
Value Function Update Magnitude: 0.05270

Collected Steps per Second: 22,159.93017
Overall Steps per Second: 16,095.29859

Timestep Collection Time: 2.25632
Timestep Consumption Time: 0.85017
PPO Batch Consumption Time: 0.04941
Total Iteration Time: 3.10650

Cumulative Model Updates: 20,366
Cumulative Timesteps: 340,066,688

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 340066688...
Checkpoint 340066688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,958.67643
Policy Entropy: 0.78370
Value Function Loss: 0.06194

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03505
Policy Update Magnitude: 0.03155
Value Function Update Magnitude: 0.05334

Collected Steps per Second: 21,497.39140
Overall Steps per Second: 15,368.67457

Timestep Collection Time: 2.32642
Timestep Consumption Time: 0.92773
PPO Batch Consumption Time: 0.02838
Total Iteration Time: 3.25415

Cumulative Model Updates: 20,369
Cumulative Timesteps: 340,116,700

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,364.92762
Policy Entropy: 0.79498
Value Function Loss: 0.05417

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04157
Policy Update Magnitude: 0.03625
Value Function Update Magnitude: 0.05066

Collected Steps per Second: 23,169.37414
Overall Steps per Second: 16,964.94455

Timestep Collection Time: 2.15854
Timestep Consumption Time: 0.78942
PPO Batch Consumption Time: 0.04737
Total Iteration Time: 2.94796

Cumulative Model Updates: 20,372
Cumulative Timesteps: 340,166,712

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 340166712...
Checkpoint 340166712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,799.78345
Policy Entropy: 0.78680
Value Function Loss: 0.06436

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02661
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.05547

Collected Steps per Second: 22,159.50706
Overall Steps per Second: 16,370.99326

Timestep Collection Time: 2.25673
Timestep Consumption Time: 0.79794
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 3.05467

Cumulative Model Updates: 20,375
Cumulative Timesteps: 340,216,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,685.91497
Policy Entropy: 0.78951
Value Function Loss: 0.06124

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04187
Policy Update Magnitude: 0.04348
Value Function Update Magnitude: 0.05236

Collected Steps per Second: 20,864.65276
Overall Steps per Second: 15,153.17602

Timestep Collection Time: 2.39774
Timestep Consumption Time: 0.90375
PPO Batch Consumption Time: 0.08011
Total Iteration Time: 3.30149

Cumulative Model Updates: 20,378
Cumulative Timesteps: 340,266,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 340266748...
Checkpoint 340266748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,496.47066
Policy Entropy: 0.78090
Value Function Loss: 0.06031

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02921
Policy Update Magnitude: 0.03706
Value Function Update Magnitude: 0.05414

Collected Steps per Second: 22,103.56714
Overall Steps per Second: 16,235.99015

Timestep Collection Time: 2.26325
Timestep Consumption Time: 0.81792
PPO Batch Consumption Time: 0.06267
Total Iteration Time: 3.08118

Cumulative Model Updates: 20,381
Cumulative Timesteps: 340,316,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,729.26498
Policy Entropy: 0.77855
Value Function Loss: 0.05616

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02155
Policy Update Magnitude: 0.03545
Value Function Update Magnitude: 0.06038

Collected Steps per Second: 20,945.52931
Overall Steps per Second: 15,419.79499

Timestep Collection Time: 2.38819
Timestep Consumption Time: 0.85582
PPO Batch Consumption Time: 0.08727
Total Iteration Time: 3.24401

Cumulative Model Updates: 20,384
Cumulative Timesteps: 340,366,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 340366796...
Checkpoint 340366796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,015.72545
Policy Entropy: 0.78283
Value Function Loss: 0.05111

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04091
Policy Update Magnitude: 0.03470
Value Function Update Magnitude: 0.06239

Collected Steps per Second: 22,463.52371
Overall Steps per Second: 16,497.15252

Timestep Collection Time: 2.22779
Timestep Consumption Time: 0.80570
PPO Batch Consumption Time: 0.06111
Total Iteration Time: 3.03349

Cumulative Model Updates: 20,387
Cumulative Timesteps: 340,416,840

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,697.58398
Policy Entropy: 0.77588
Value Function Loss: 0.05572

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02702
Policy Update Magnitude: 0.03332
Value Function Update Magnitude: 0.05962

Collected Steps per Second: 20,832.47861
Overall Steps per Second: 14,972.07195

Timestep Collection Time: 2.40087
Timestep Consumption Time: 0.93975
PPO Batch Consumption Time: 0.09679
Total Iteration Time: 3.34062

Cumulative Model Updates: 20,390
Cumulative Timesteps: 340,466,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 340466856...
Checkpoint 340466856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,309.76834
Policy Entropy: 0.77732
Value Function Loss: 0.06346

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04642
Policy Update Magnitude: 0.03277
Value Function Update Magnitude: 0.05714

Collected Steps per Second: 22,189.36552
Overall Steps per Second: 16,428.06506

Timestep Collection Time: 2.25423
Timestep Consumption Time: 0.79056
PPO Batch Consumption Time: 0.06004
Total Iteration Time: 3.04479

Cumulative Model Updates: 20,393
Cumulative Timesteps: 340,516,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,789.90911
Policy Entropy: 0.77127
Value Function Loss: 0.07212

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03342
Policy Update Magnitude: 0.03293
Value Function Update Magnitude: 0.06318

Collected Steps per Second: 21,509.10003
Overall Steps per Second: 15,110.33818

Timestep Collection Time: 2.32571
Timestep Consumption Time: 0.98487
PPO Batch Consumption Time: 0.11911
Total Iteration Time: 3.31058

Cumulative Model Updates: 20,396
Cumulative Timesteps: 340,566,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 340566900...
Checkpoint 340566900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,685.41943
Policy Entropy: 0.77575
Value Function Loss: 0.07360

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04919
Policy Update Magnitude: 0.03404
Value Function Update Magnitude: 0.06160

Collected Steps per Second: 22,270.03193
Overall Steps per Second: 16,379.13338

Timestep Collection Time: 2.24571
Timestep Consumption Time: 0.80769
PPO Batch Consumption Time: 0.05787
Total Iteration Time: 3.05340

Cumulative Model Updates: 20,399
Cumulative Timesteps: 340,616,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,717.51380
Policy Entropy: 0.78645
Value Function Loss: 0.06176

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02893
Policy Update Magnitude: 0.03094
Value Function Update Magnitude: 0.05397

Collected Steps per Second: 21,265.17053
Overall Steps per Second: 14,999.81920

Timestep Collection Time: 2.35258
Timestep Consumption Time: 0.98266
PPO Batch Consumption Time: 0.11102
Total Iteration Time: 3.33524

Cumulative Model Updates: 20,402
Cumulative Timesteps: 340,666,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 340666940...
Checkpoint 340666940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,239.16511
Policy Entropy: 0.78669
Value Function Loss: 0.06324

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03651
Policy Update Magnitude: 0.03137
Value Function Update Magnitude: 0.05907

Collected Steps per Second: 21,986.72400
Overall Steps per Second: 16,200.53264

Timestep Collection Time: 2.27483
Timestep Consumption Time: 0.81248
PPO Batch Consumption Time: 0.06306
Total Iteration Time: 3.08731

Cumulative Model Updates: 20,405
Cumulative Timesteps: 340,716,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,150.32157
Policy Entropy: 0.78205
Value Function Loss: 0.05933

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.03372
Value Function Update Magnitude: 0.05597

Collected Steps per Second: 22,599.45634
Overall Steps per Second: 16,143.04542

Timestep Collection Time: 2.21253
Timestep Consumption Time: 0.88490
PPO Batch Consumption Time: 0.07965
Total Iteration Time: 3.09743

Cumulative Model Updates: 20,408
Cumulative Timesteps: 340,766,958

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 340766958...
Checkpoint 340766958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,576.53345
Policy Entropy: 0.77585
Value Function Loss: 0.06536

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.03512
Value Function Update Magnitude: 0.05828

Collected Steps per Second: 22,163.30600
Overall Steps per Second: 16,381.32330

Timestep Collection Time: 2.25661
Timestep Consumption Time: 0.79650
PPO Batch Consumption Time: 0.06161
Total Iteration Time: 3.05311

Cumulative Model Updates: 20,411
Cumulative Timesteps: 340,816,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,983.07368
Policy Entropy: 0.77644
Value Function Loss: 0.05946

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02245
Policy Update Magnitude: 0.03448
Value Function Update Magnitude: 0.05106

Collected Steps per Second: 22,482.77703
Overall Steps per Second: 16,452.17548

Timestep Collection Time: 2.22508
Timestep Consumption Time: 0.81561
PPO Batch Consumption Time: 0.06462
Total Iteration Time: 3.04069

Cumulative Model Updates: 20,414
Cumulative Timesteps: 340,866,998

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 340866998...
Checkpoint 340866998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,455.75992
Policy Entropy: 0.77413
Value Function Loss: 0.06655

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02536
Policy Update Magnitude: 0.03549
Value Function Update Magnitude: 0.05127

Collected Steps per Second: 22,409.55257
Overall Steps per Second: 16,332.74884

Timestep Collection Time: 2.23146
Timestep Consumption Time: 0.83024
PPO Batch Consumption Time: 0.06139
Total Iteration Time: 3.06170

Cumulative Model Updates: 20,417
Cumulative Timesteps: 340,917,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,026.48342
Policy Entropy: 0.77308
Value Function Loss: 0.05666

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01879
Policy Update Magnitude: 0.03515
Value Function Update Magnitude: 0.05692

Collected Steps per Second: 20,318.93253
Overall Steps per Second: 14,749.26471

Timestep Collection Time: 2.46273
Timestep Consumption Time: 0.92998
PPO Batch Consumption Time: 0.09228
Total Iteration Time: 3.39271

Cumulative Model Updates: 20,420
Cumulative Timesteps: 340,967,044

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 340967044...
Checkpoint 340967044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,876.84239
Policy Entropy: 0.77290
Value Function Loss: 0.05508

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02269
Policy Update Magnitude: 0.03714
Value Function Update Magnitude: 0.05511

Collected Steps per Second: 22,225.07315
Overall Steps per Second: 16,372.11492

Timestep Collection Time: 2.25034
Timestep Consumption Time: 0.80449
PPO Batch Consumption Time: 0.06357
Total Iteration Time: 3.05483

Cumulative Model Updates: 20,423
Cumulative Timesteps: 341,017,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,035.89656
Policy Entropy: 0.77830
Value Function Loss: 0.05593

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02927
Policy Update Magnitude: 0.03666
Value Function Update Magnitude: 0.05080

Collected Steps per Second: 20,958.91586
Overall Steps per Second: 15,060.58373

Timestep Collection Time: 2.38686
Timestep Consumption Time: 0.93479
PPO Batch Consumption Time: 0.09542
Total Iteration Time: 3.32165

Cumulative Model Updates: 20,426
Cumulative Timesteps: 341,067,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 341067084...
Checkpoint 341067084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,167.60264
Policy Entropy: 0.76764
Value Function Loss: 0.06099

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02616
Policy Update Magnitude: 0.04015
Value Function Update Magnitude: 0.04639

Collected Steps per Second: 22,098.54216
Overall Steps per Second: 16,344.73866

Timestep Collection Time: 2.26277
Timestep Consumption Time: 0.79656
PPO Batch Consumption Time: 0.06121
Total Iteration Time: 3.05933

Cumulative Model Updates: 20,429
Cumulative Timesteps: 341,117,088

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,515.15678
Policy Entropy: 0.78058
Value Function Loss: 0.06317

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01797
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.04847

Collected Steps per Second: 22,464.08526
Overall Steps per Second: 16,045.07143

Timestep Collection Time: 2.22684
Timestep Consumption Time: 0.89087
PPO Batch Consumption Time: 0.07992
Total Iteration Time: 3.11772

Cumulative Model Updates: 20,432
Cumulative Timesteps: 341,167,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 341167112...
Checkpoint 341167112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,407.67201
Policy Entropy: 0.77412
Value Function Loss: 0.05998

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02040
Policy Update Magnitude: 0.03963
Value Function Update Magnitude: 0.04450

Collected Steps per Second: 22,439.43454
Overall Steps per Second: 16,569.79036

Timestep Collection Time: 2.22902
Timestep Consumption Time: 0.78960
PPO Batch Consumption Time: 0.06028
Total Iteration Time: 3.01863

Cumulative Model Updates: 20,435
Cumulative Timesteps: 341,217,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,120.82066
Policy Entropy: 0.77299
Value Function Loss: 0.06064

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01800
Policy Update Magnitude: 0.03547
Value Function Update Magnitude: 0.04916

Collected Steps per Second: 20,037.60998
Overall Steps per Second: 14,672.83121

Timestep Collection Time: 2.49631
Timestep Consumption Time: 0.91272
PPO Batch Consumption Time: 0.07990
Total Iteration Time: 3.40902

Cumulative Model Updates: 20,438
Cumulative Timesteps: 341,267,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 341267150...
Checkpoint 341267150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,634.74599
Policy Entropy: 0.76638
Value Function Loss: 0.06259

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02148
Policy Update Magnitude: 0.03600
Value Function Update Magnitude: 0.04366

Collected Steps per Second: 22,680.32005
Overall Steps per Second: 16,719.49637

Timestep Collection Time: 2.20667
Timestep Consumption Time: 0.78672
PPO Batch Consumption Time: 0.05820
Total Iteration Time: 2.99339

Cumulative Model Updates: 20,441
Cumulative Timesteps: 341,317,198

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,863.59173
Policy Entropy: 0.75660
Value Function Loss: 0.06379

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03328
Policy Update Magnitude: 0.03631
Value Function Update Magnitude: 0.04970

Collected Steps per Second: 21,276.60932
Overall Steps per Second: 15,049.53129

Timestep Collection Time: 2.35009
Timestep Consumption Time: 0.97240
PPO Batch Consumption Time: 0.09486
Total Iteration Time: 3.32250

Cumulative Model Updates: 20,444
Cumulative Timesteps: 341,367,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 341367200...
Checkpoint 341367200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,556.10309
Policy Entropy: 0.75538
Value Function Loss: 0.06556

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.03859
Value Function Update Magnitude: 0.05718

Collected Steps per Second: 21,961.13632
Overall Steps per Second: 16,195.83611

Timestep Collection Time: 2.27802
Timestep Consumption Time: 0.81092
PPO Batch Consumption Time: 0.06527
Total Iteration Time: 3.08894

Cumulative Model Updates: 20,447
Cumulative Timesteps: 341,417,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,190.37544
Policy Entropy: 0.75553
Value Function Loss: 0.06138

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03906
Policy Update Magnitude: 0.04039
Value Function Update Magnitude: 0.06340

Collected Steps per Second: 22,659.57431
Overall Steps per Second: 16,585.98700

Timestep Collection Time: 2.20701
Timestep Consumption Time: 0.80818
PPO Batch Consumption Time: 0.06345
Total Iteration Time: 3.01520

Cumulative Model Updates: 20,450
Cumulative Timesteps: 341,467,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 341467238...
Checkpoint 341467238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,497.52416
Policy Entropy: 0.76075
Value Function Loss: 0.06233

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03528
Policy Update Magnitude: 0.03909
Value Function Update Magnitude: 0.06569

Collected Steps per Second: 22,383.57697
Overall Steps per Second: 16,540.99207

Timestep Collection Time: 2.23378
Timestep Consumption Time: 0.78901
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 3.02279

Cumulative Model Updates: 20,453
Cumulative Timesteps: 341,517,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,312.75620
Policy Entropy: 0.75675
Value Function Loss: 0.06496

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03218
Policy Update Magnitude: 0.03586
Value Function Update Magnitude: 0.06578

Collected Steps per Second: 20,707.05946
Overall Steps per Second: 14,673.45145

Timestep Collection Time: 2.41502
Timestep Consumption Time: 0.99304
PPO Batch Consumption Time: 0.11553
Total Iteration Time: 3.40806

Cumulative Model Updates: 20,456
Cumulative Timesteps: 341,567,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 341567246...
Checkpoint 341567246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,751.67960
Policy Entropy: 0.76369
Value Function Loss: 0.06624

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02173
Policy Update Magnitude: 0.03209
Value Function Update Magnitude: 0.06402

Collected Steps per Second: 21,871.02829
Overall Steps per Second: 16,352.13512

Timestep Collection Time: 2.28640
Timestep Consumption Time: 0.77167
PPO Batch Consumption Time: 0.05795
Total Iteration Time: 3.05807

Cumulative Model Updates: 20,459
Cumulative Timesteps: 341,617,252

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,461.13078
Policy Entropy: 0.76447
Value Function Loss: 0.06127

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.03100
Value Function Update Magnitude: 0.05575

Collected Steps per Second: 21,473.12728
Overall Steps per Second: 15,089.31692

Timestep Collection Time: 2.32952
Timestep Consumption Time: 0.98554
PPO Batch Consumption Time: 0.11927
Total Iteration Time: 3.31506

Cumulative Model Updates: 20,462
Cumulative Timesteps: 341,667,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 341667274...
Checkpoint 341667274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,978.05124
Policy Entropy: 0.77432
Value Function Loss: 0.05293

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01698
Policy Update Magnitude: 0.03156
Value Function Update Magnitude: 0.04749

Collected Steps per Second: 22,499.29951
Overall Steps per Second: 16,568.23351

Timestep Collection Time: 2.22345
Timestep Consumption Time: 0.79595
PPO Batch Consumption Time: 0.05765
Total Iteration Time: 3.01939

Cumulative Model Updates: 20,465
Cumulative Timesteps: 341,717,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,587.17274
Policy Entropy: 0.78143
Value Function Loss: 0.05173

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02953
Policy Update Magnitude: 0.03156
Value Function Update Magnitude: 0.04575

Collected Steps per Second: 20,493.80626
Overall Steps per Second: 14,840.79226

Timestep Collection Time: 2.44103
Timestep Consumption Time: 0.92981
PPO Batch Consumption Time: 0.09752
Total Iteration Time: 3.37084

Cumulative Model Updates: 20,468
Cumulative Timesteps: 341,767,326

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 341767326...
Checkpoint 341767326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,087.20845
Policy Entropy: 0.78153
Value Function Loss: 0.05338

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02116
Policy Update Magnitude: 0.03115
Value Function Update Magnitude: 0.04447

Collected Steps per Second: 21,598.08838
Overall Steps per Second: 16,439.05106

Timestep Collection Time: 2.31548
Timestep Consumption Time: 0.72666
PPO Batch Consumption Time: 0.05940
Total Iteration Time: 3.04215

Cumulative Model Updates: 20,471
Cumulative Timesteps: 341,817,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,526.28728
Policy Entropy: 0.77667
Value Function Loss: 0.05985

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.03148
Value Function Update Magnitude: 0.05443

Collected Steps per Second: 19,862.62308
Overall Steps per Second: 14,852.95268

Timestep Collection Time: 2.51951
Timestep Consumption Time: 0.84979
PPO Batch Consumption Time: 0.08502
Total Iteration Time: 3.36930

Cumulative Model Updates: 20,474
Cumulative Timesteps: 341,867,380

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 341867380...
Checkpoint 341867380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,197.10934
Policy Entropy: 0.77941
Value Function Loss: 0.06548

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02667
Policy Update Magnitude: 0.03570
Value Function Update Magnitude: 0.06275

Collected Steps per Second: 21,617.55835
Overall Steps per Second: 16,414.91669

Timestep Collection Time: 2.31367
Timestep Consumption Time: 0.73331
PPO Batch Consumption Time: 0.06506
Total Iteration Time: 3.04698

Cumulative Model Updates: 20,477
Cumulative Timesteps: 341,917,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,693.94628
Policy Entropy: 0.77413
Value Function Loss: 0.06574

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03231
Policy Update Magnitude: 0.03506
Value Function Update Magnitude: 0.06576

Collected Steps per Second: 21,658.38692
Overall Steps per Second: 16,531.79978

Timestep Collection Time: 2.31070
Timestep Consumption Time: 0.71656
PPO Batch Consumption Time: 0.06178
Total Iteration Time: 3.02726

Cumulative Model Updates: 20,480
Cumulative Timesteps: 341,967,442

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 341967442...
Checkpoint 341967442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,845.46811
Policy Entropy: 0.77496
Value Function Loss: 0.06430

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01862
Policy Update Magnitude: 0.03469
Value Function Update Magnitude: 0.06381

Collected Steps per Second: 21,784.81535
Overall Steps per Second: 16,598.31853

Timestep Collection Time: 2.29554
Timestep Consumption Time: 0.71729
PPO Batch Consumption Time: 0.05783
Total Iteration Time: 3.01284

Cumulative Model Updates: 20,483
Cumulative Timesteps: 342,017,450

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,038.09893
Policy Entropy: 0.77713
Value Function Loss: 0.05572

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03586
Policy Update Magnitude: 0.03456
Value Function Update Magnitude: 0.05895

Collected Steps per Second: 19,164.85398
Overall Steps per Second: 13,850.31697

Timestep Collection Time: 2.61040
Timestep Consumption Time: 1.00164
PPO Batch Consumption Time: 0.12178
Total Iteration Time: 3.61205

Cumulative Model Updates: 20,486
Cumulative Timesteps: 342,067,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 342067478...
Checkpoint 342067478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,127.41396
Policy Entropy: 0.77402
Value Function Loss: 0.06313

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01803
Policy Update Magnitude: 0.03308
Value Function Update Magnitude: 0.05452

Collected Steps per Second: 20,876.88073
Overall Steps per Second: 15,804.52296

Timestep Collection Time: 2.39681
Timestep Consumption Time: 0.76924
PPO Batch Consumption Time: 0.05416
Total Iteration Time: 3.16606

Cumulative Model Updates: 20,489
Cumulative Timesteps: 342,117,516

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,179.01393
Policy Entropy: 0.76789
Value Function Loss: 0.07592

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04253
Policy Update Magnitude: 0.03545
Value Function Update Magnitude: 0.05217

Collected Steps per Second: 19,770.40096
Overall Steps per Second: 14,600.38274

Timestep Collection Time: 2.53055
Timestep Consumption Time: 0.89607
PPO Batch Consumption Time: 0.09215
Total Iteration Time: 3.42662

Cumulative Model Updates: 20,492
Cumulative Timesteps: 342,167,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 342167546...
Checkpoint 342167546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,571.43861
Policy Entropy: 0.76314
Value Function Loss: 0.08467

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01859
Policy Update Magnitude: 0.03504
Value Function Update Magnitude: 0.06100

Collected Steps per Second: 22,439.86424
Overall Steps per Second: 16,642.80849

Timestep Collection Time: 2.22827
Timestep Consumption Time: 0.77615
PPO Batch Consumption Time: 0.05838
Total Iteration Time: 3.00442

Cumulative Model Updates: 20,495
Cumulative Timesteps: 342,217,548

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,380.50978
Policy Entropy: 0.76473
Value Function Loss: 0.08276

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03204
Policy Update Magnitude: 0.03533
Value Function Update Magnitude: 0.05737

Collected Steps per Second: 20,422.63233
Overall Steps per Second: 14,939.01613

Timestep Collection Time: 2.45012
Timestep Consumption Time: 0.89936
PPO Batch Consumption Time: 0.09263
Total Iteration Time: 3.34948

Cumulative Model Updates: 20,498
Cumulative Timesteps: 342,267,586

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 342267586...
Checkpoint 342267586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,763.36362
Policy Entropy: 0.77242
Value Function Loss: 0.06703

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05143
Policy Update Magnitude: 0.03506
Value Function Update Magnitude: 0.05790

Collected Steps per Second: 22,339.31266
Overall Steps per Second: 16,565.62143

Timestep Collection Time: 2.23937
Timestep Consumption Time: 0.78050
PPO Batch Consumption Time: 0.06124
Total Iteration Time: 3.01987

Cumulative Model Updates: 20,501
Cumulative Timesteps: 342,317,612

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,510.41512
Policy Entropy: 0.78250
Value Function Loss: 0.06288

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03686
Policy Update Magnitude: 0.03405
Value Function Update Magnitude: 0.05057

Collected Steps per Second: 20,536.94463
Overall Steps per Second: 14,915.58212

Timestep Collection Time: 2.43493
Timestep Consumption Time: 0.91767
PPO Batch Consumption Time: 0.09935
Total Iteration Time: 3.35260

Cumulative Model Updates: 20,504
Cumulative Timesteps: 342,367,618

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 342367618...
Checkpoint 342367618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,105.09489
Policy Entropy: 0.79285
Value Function Loss: 0.05932

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03280
Policy Update Magnitude: 0.03055
Value Function Update Magnitude: 0.05347

Collected Steps per Second: 22,009.64904
Overall Steps per Second: 16,228.27505

Timestep Collection Time: 2.27264
Timestep Consumption Time: 0.80964
PPO Batch Consumption Time: 0.06199
Total Iteration Time: 3.08227

Cumulative Model Updates: 20,507
Cumulative Timesteps: 342,417,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,303.18756
Policy Entropy: 0.78491
Value Function Loss: 0.06334

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01785
Policy Update Magnitude: 0.03214
Value Function Update Magnitude: 0.05172

Collected Steps per Second: 22,616.08953
Overall Steps per Second: 16,533.63275

Timestep Collection Time: 2.21205
Timestep Consumption Time: 0.81378
PPO Batch Consumption Time: 0.06510
Total Iteration Time: 3.02583

Cumulative Model Updates: 20,510
Cumulative Timesteps: 342,467,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 342467666...
Checkpoint 342467666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,646.18232
Policy Entropy: 0.78785
Value Function Loss: 0.06153

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.03547
Value Function Update Magnitude: 0.04820

Collected Steps per Second: 22,225.84411
Overall Steps per Second: 16,322.04785

Timestep Collection Time: 2.24990
Timestep Consumption Time: 0.81381
PPO Batch Consumption Time: 0.06037
Total Iteration Time: 3.06371

Cumulative Model Updates: 20,513
Cumulative Timesteps: 342,517,672

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,810.14241
Policy Entropy: 0.78637
Value Function Loss: 0.06333

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03595
Policy Update Magnitude: 0.03307
Value Function Update Magnitude: 0.05658

Collected Steps per Second: 21,162.79056
Overall Steps per Second: 14,801.24808

Timestep Collection Time: 2.36302
Timestep Consumption Time: 1.01562
PPO Batch Consumption Time: 0.11477
Total Iteration Time: 3.37863

Cumulative Model Updates: 20,516
Cumulative Timesteps: 342,567,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 342567680...
Checkpoint 342567680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,233.03571
Policy Entropy: 0.77724
Value Function Loss: 0.06067

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03658
Policy Update Magnitude: 0.03268
Value Function Update Magnitude: 0.06113

Collected Steps per Second: 22,007.40411
Overall Steps per Second: 16,311.78966

Timestep Collection Time: 2.27214
Timestep Consumption Time: 0.79337
PPO Batch Consumption Time: 0.05811
Total Iteration Time: 3.06551

Cumulative Model Updates: 20,519
Cumulative Timesteps: 342,617,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,268.87467
Policy Entropy: 0.78025
Value Function Loss: 0.05801

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.05123
Policy Update Magnitude: 0.03090
Value Function Update Magnitude: 0.05332

Collected Steps per Second: 22,747.57952
Overall Steps per Second: 16,694.29073

Timestep Collection Time: 2.19821
Timestep Consumption Time: 0.79706
PPO Batch Consumption Time: 0.05802
Total Iteration Time: 2.99528

Cumulative Model Updates: 20,522
Cumulative Timesteps: 342,667,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 342667688...
Checkpoint 342667688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,277.09772
Policy Entropy: 0.77049
Value Function Loss: 0.05598

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.05190
Policy Update Magnitude: 0.02833
Value Function Update Magnitude: 0.05418

Collected Steps per Second: 22,429.13649
Overall Steps per Second: 16,564.80252

Timestep Collection Time: 2.22924
Timestep Consumption Time: 0.78921
PPO Batch Consumption Time: 0.05820
Total Iteration Time: 3.01845

Cumulative Model Updates: 20,525
Cumulative Timesteps: 342,717,688

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,934.74455
Policy Entropy: 0.76587
Value Function Loss: 0.05500

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04554
Policy Update Magnitude: 0.02733
Value Function Update Magnitude: 0.05360

Collected Steps per Second: 22,873.11831
Overall Steps per Second: 16,793.01610

Timestep Collection Time: 2.18650
Timestep Consumption Time: 0.79165
PPO Batch Consumption Time: 0.05966
Total Iteration Time: 2.97814

Cumulative Model Updates: 20,528
Cumulative Timesteps: 342,767,700

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 342767700...
Checkpoint 342767700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,768.00831
Policy Entropy: 0.75435
Value Function Loss: 0.06462

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.05118
Policy Update Magnitude: 0.02981
Value Function Update Magnitude: 0.05158

Collected Steps per Second: 22,435.38833
Overall Steps per Second: 16,671.43581

Timestep Collection Time: 2.22862
Timestep Consumption Time: 0.77052
PPO Batch Consumption Time: 0.05792
Total Iteration Time: 2.99914

Cumulative Model Updates: 20,531
Cumulative Timesteps: 342,817,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,751.69382
Policy Entropy: 0.75870
Value Function Loss: 0.06311

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04809
Policy Update Magnitude: 0.02976
Value Function Update Magnitude: 0.05733

Collected Steps per Second: 22,536.55802
Overall Steps per Second: 16,646.83854

Timestep Collection Time: 2.21879
Timestep Consumption Time: 0.78502
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 3.00381

Cumulative Model Updates: 20,534
Cumulative Timesteps: 342,867,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 342867704...
Checkpoint 342867704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,225.49240
Policy Entropy: 0.75561
Value Function Loss: 0.06449

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04374
Policy Update Magnitude: 0.02980
Value Function Update Magnitude: 0.05844

Collected Steps per Second: 21,536.12379
Overall Steps per Second: 15,414.60926

Timestep Collection Time: 2.32242
Timestep Consumption Time: 0.92229
PPO Batch Consumption Time: 0.07849
Total Iteration Time: 3.24471

Cumulative Model Updates: 20,537
Cumulative Timesteps: 342,917,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,406.25114
Policy Entropy: 0.77400
Value Function Loss: 0.05342

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05917
Policy Update Magnitude: 0.03136
Value Function Update Magnitude: 0.06293

Collected Steps per Second: 22,679.57964
Overall Steps per Second: 16,928.52142

Timestep Collection Time: 2.20639
Timestep Consumption Time: 0.74957
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 2.95596

Cumulative Model Updates: 20,540
Cumulative Timesteps: 342,967,760

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 342967760...
Checkpoint 342967760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,255.29876
Policy Entropy: 0.76801
Value Function Loss: 0.05293

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05584
Policy Update Magnitude: 0.02903
Value Function Update Magnitude: 0.06785

Collected Steps per Second: 19,371.64003
Overall Steps per Second: 13,899.48250

Timestep Collection Time: 2.58140
Timestep Consumption Time: 1.01629
PPO Batch Consumption Time: 0.11617
Total Iteration Time: 3.59769

Cumulative Model Updates: 20,543
Cumulative Timesteps: 343,017,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,826.02768
Policy Entropy: 0.76270
Value Function Loss: 0.05408

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02449
Policy Update Magnitude: 0.02906
Value Function Update Magnitude: 0.06637

Collected Steps per Second: 22,490.89723
Overall Steps per Second: 16,612.09915

Timestep Collection Time: 2.22339
Timestep Consumption Time: 0.78683
PPO Batch Consumption Time: 0.05789
Total Iteration Time: 3.01022

Cumulative Model Updates: 20,546
Cumulative Timesteps: 343,067,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 343067772...
Checkpoint 343067772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,098.62524
Policy Entropy: 0.75423
Value Function Loss: 0.06710

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05555
Policy Update Magnitude: 0.03198
Value Function Update Magnitude: 0.05932

Collected Steps per Second: 19,313.14188
Overall Steps per Second: 13,961.63930

Timestep Collection Time: 2.58943
Timestep Consumption Time: 0.99253
PPO Batch Consumption Time: 0.11294
Total Iteration Time: 3.58196

Cumulative Model Updates: 20,549
Cumulative Timesteps: 343,117,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,684.38337
Policy Entropy: 0.75526
Value Function Loss: 0.06612

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05575
Policy Update Magnitude: 0.03013
Value Function Update Magnitude: 0.06408

Collected Steps per Second: 22,349.50401
Overall Steps per Second: 16,491.51072

Timestep Collection Time: 2.23799
Timestep Consumption Time: 0.79496
PPO Batch Consumption Time: 0.05987
Total Iteration Time: 3.03295

Cumulative Model Updates: 20,552
Cumulative Timesteps: 343,167,800

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 343167800...
Checkpoint 343167800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,163.63931
Policy Entropy: 0.75655
Value Function Loss: 0.06763

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.03269
Value Function Update Magnitude: 0.06773

Collected Steps per Second: 20,732.14104
Overall Steps per Second: 14,994.42521

Timestep Collection Time: 2.41249
Timestep Consumption Time: 0.92315
PPO Batch Consumption Time: 0.08470
Total Iteration Time: 3.33564

Cumulative Model Updates: 20,555
Cumulative Timesteps: 343,217,816

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,433.20312
Policy Entropy: 0.76229
Value Function Loss: 0.06366

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06127
Policy Update Magnitude: 0.03161
Value Function Update Magnitude: 0.06016

Collected Steps per Second: 22,490.34272
Overall Steps per Second: 16,574.03232

Timestep Collection Time: 2.22371
Timestep Consumption Time: 0.79378
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 3.01749

Cumulative Model Updates: 20,558
Cumulative Timesteps: 343,267,828

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 343267828...
Checkpoint 343267828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,037.22266
Policy Entropy: 0.75105
Value Function Loss: 0.07275

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06979
Policy Update Magnitude: 0.03357
Value Function Update Magnitude: 0.05350

Collected Steps per Second: 20,638.79241
Overall Steps per Second: 14,910.05762

Timestep Collection Time: 2.42340
Timestep Consumption Time: 0.93112
PPO Batch Consumption Time: 0.09415
Total Iteration Time: 3.35451

Cumulative Model Updates: 20,561
Cumulative Timesteps: 343,317,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,023.07976
Policy Entropy: 0.75096
Value Function Loss: 0.07590

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04878
Policy Update Magnitude: 0.03352
Value Function Update Magnitude: 0.05229

Collected Steps per Second: 22,309.66844
Overall Steps per Second: 16,423.23549

Timestep Collection Time: 2.24199
Timestep Consumption Time: 0.80358
PPO Batch Consumption Time: 0.06090
Total Iteration Time: 3.04556

Cumulative Model Updates: 20,564
Cumulative Timesteps: 343,367,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 343367862...
Checkpoint 343367862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,523.28300
Policy Entropy: 0.75540
Value Function Loss: 0.07015

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03862
Policy Update Magnitude: 0.03306
Value Function Update Magnitude: 0.05442

Collected Steps per Second: 20,401.26318
Overall Steps per Second: 14,994.24046

Timestep Collection Time: 2.45161
Timestep Consumption Time: 0.88407
PPO Batch Consumption Time: 0.08132
Total Iteration Time: 3.33568

Cumulative Model Updates: 20,567
Cumulative Timesteps: 343,417,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,640.98038
Policy Entropy: 0.76047
Value Function Loss: 0.06562

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02843
Policy Update Magnitude: 0.03130
Value Function Update Magnitude: 0.05125

Collected Steps per Second: 22,720.34242
Overall Steps per Second: 16,635.55386

Timestep Collection Time: 2.20146
Timestep Consumption Time: 0.80523
PPO Batch Consumption Time: 0.05963
Total Iteration Time: 3.00669

Cumulative Model Updates: 20,570
Cumulative Timesteps: 343,467,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 343467896...
Checkpoint 343467896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,613.61563
Policy Entropy: 0.74714
Value Function Loss: 0.06854

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02148
Policy Update Magnitude: 0.02972
Value Function Update Magnitude: 0.04973

Collected Steps per Second: 20,168.33288
Overall Steps per Second: 14,872.53870

Timestep Collection Time: 2.48003
Timestep Consumption Time: 0.88308
PPO Batch Consumption Time: 0.08038
Total Iteration Time: 3.36311

Cumulative Model Updates: 20,573
Cumulative Timesteps: 343,517,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,452.38855
Policy Entropy: 0.75185
Value Function Loss: 0.06587

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04467
Policy Update Magnitude: 0.02797
Value Function Update Magnitude: 0.04615

Collected Steps per Second: 22,746.71083
Overall Steps per Second: 16,717.16756

Timestep Collection Time: 2.19812
Timestep Consumption Time: 0.79282
PPO Batch Consumption Time: 0.05872
Total Iteration Time: 2.99094

Cumulative Model Updates: 20,576
Cumulative Timesteps: 343,567,914

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 343567914...
Checkpoint 343567914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,571.57410
Policy Entropy: 0.74130
Value Function Loss: 0.06591

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03815
Policy Update Magnitude: 0.02812
Value Function Update Magnitude: 0.04914

Collected Steps per Second: 20,812.95005
Overall Steps per Second: 14,904.40196

Timestep Collection Time: 2.40322
Timestep Consumption Time: 0.95271
PPO Batch Consumption Time: 0.11858
Total Iteration Time: 3.35592

Cumulative Model Updates: 20,579
Cumulative Timesteps: 343,617,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,335.05129
Policy Entropy: 0.74942
Value Function Loss: 0.06745

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04839
Policy Update Magnitude: 0.02884
Value Function Update Magnitude: 0.04449

Collected Steps per Second: 22,802.32970
Overall Steps per Second: 16,770.59291

Timestep Collection Time: 2.19276
Timestep Consumption Time: 0.78865
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 2.98141

Cumulative Model Updates: 20,582
Cumulative Timesteps: 343,667,932

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 343667932...
Checkpoint 343667932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,871.44550
Policy Entropy: 0.74249
Value Function Loss: 0.06134

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03229
Policy Update Magnitude: 0.02956
Value Function Update Magnitude: 0.05108

Collected Steps per Second: 20,211.16170
Overall Steps per Second: 14,629.77080

Timestep Collection Time: 2.47467
Timestep Consumption Time: 0.94411
PPO Batch Consumption Time: 0.09885
Total Iteration Time: 3.41878

Cumulative Model Updates: 20,585
Cumulative Timesteps: 343,717,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,814.38321
Policy Entropy: 0.75265
Value Function Loss: 0.06743

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05979
Policy Update Magnitude: 0.02996
Value Function Update Magnitude: 0.05602

Collected Steps per Second: 22,077.30810
Overall Steps per Second: 16,214.27981

Timestep Collection Time: 2.26540
Timestep Consumption Time: 0.81916
PPO Batch Consumption Time: 0.05996
Total Iteration Time: 3.08456

Cumulative Model Updates: 20,588
Cumulative Timesteps: 343,767,962

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 343767962...
Checkpoint 343767962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,610.46237
Policy Entropy: 0.75014
Value Function Loss: 0.06118

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05315
Policy Update Magnitude: 0.02847
Value Function Update Magnitude: 0.05429

Collected Steps per Second: 22,591.47043
Overall Steps per Second: 16,096.04532

Timestep Collection Time: 2.21358
Timestep Consumption Time: 0.89327
PPO Batch Consumption Time: 0.08163
Total Iteration Time: 3.10685

Cumulative Model Updates: 20,591
Cumulative Timesteps: 343,817,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,685.67961
Policy Entropy: 0.75145
Value Function Loss: 0.06637

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05185
Policy Update Magnitude: 0.02810
Value Function Update Magnitude: 0.05640

Collected Steps per Second: 22,952.86066
Overall Steps per Second: 16,893.01271

Timestep Collection Time: 2.17960
Timestep Consumption Time: 0.78186
PPO Batch Consumption Time: 0.05446
Total Iteration Time: 2.96146

Cumulative Model Updates: 20,594
Cumulative Timesteps: 343,867,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 343867998...
Checkpoint 343867998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,395.25571
Policy Entropy: 0.75254
Value Function Loss: 0.06371

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02833
Policy Update Magnitude: 0.02863
Value Function Update Magnitude: 0.05482

Collected Steps per Second: 20,176.79430
Overall Steps per Second: 14,613.93966

Timestep Collection Time: 2.47829
Timestep Consumption Time: 0.94337
PPO Batch Consumption Time: 0.08765
Total Iteration Time: 3.42166

Cumulative Model Updates: 20,597
Cumulative Timesteps: 343,918,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,668.36537
Policy Entropy: 0.75386
Value Function Loss: 0.05816

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04763
Policy Update Magnitude: 0.02676
Value Function Update Magnitude: 0.04985

Collected Steps per Second: 22,404.80410
Overall Steps per Second: 16,466.63628

Timestep Collection Time: 2.23282
Timestep Consumption Time: 0.80520
PPO Batch Consumption Time: 0.06097
Total Iteration Time: 3.03802

Cumulative Model Updates: 20,600
Cumulative Timesteps: 343,968,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 343968028...
Checkpoint 343968028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,061.84888
Policy Entropy: 0.76489
Value Function Loss: 0.05668

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.02858
Value Function Update Magnitude: 0.05321

Collected Steps per Second: 22,463.03511
Overall Steps per Second: 16,096.10577

Timestep Collection Time: 2.22668
Timestep Consumption Time: 0.88078
PPO Batch Consumption Time: 0.08016
Total Iteration Time: 3.10746

Cumulative Model Updates: 20,603
Cumulative Timesteps: 344,018,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,549.14564
Policy Entropy: 0.77300
Value Function Loss: 0.05237

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03199
Policy Update Magnitude: 0.02612
Value Function Update Magnitude: 0.05451

Collected Steps per Second: 22,640.40076
Overall Steps per Second: 16,607.06242

Timestep Collection Time: 2.20968
Timestep Consumption Time: 0.80278
PPO Batch Consumption Time: 0.06115
Total Iteration Time: 3.01245

Cumulative Model Updates: 20,606
Cumulative Timesteps: 344,068,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 344068074...
Checkpoint 344068074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,193.22596
Policy Entropy: 0.77632
Value Function Loss: 0.05779

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.02826
Value Function Update Magnitude: 0.04975

Collected Steps per Second: 19,990.06851
Overall Steps per Second: 14,148.02795

Timestep Collection Time: 2.50214
Timestep Consumption Time: 1.03319
PPO Batch Consumption Time: 0.12483
Total Iteration Time: 3.53533

Cumulative Model Updates: 20,609
Cumulative Timesteps: 344,118,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,540.50395
Policy Entropy: 0.77466
Value Function Loss: 0.06717

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02428
Policy Update Magnitude: 0.02769
Value Function Update Magnitude: 0.04480

Collected Steps per Second: 23,048.37190
Overall Steps per Second: 16,825.12949

Timestep Collection Time: 2.16944
Timestep Consumption Time: 0.80243
PPO Batch Consumption Time: 0.05840
Total Iteration Time: 2.97186

Cumulative Model Updates: 20,612
Cumulative Timesteps: 344,168,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 344168094...
Checkpoint 344168094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,571.96600
Policy Entropy: 0.78813
Value Function Loss: 0.05823

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02698
Policy Update Magnitude: 0.02704
Value Function Update Magnitude: 0.04858

Collected Steps per Second: 20,212.22758
Overall Steps per Second: 14,634.44386

Timestep Collection Time: 2.47514
Timestep Consumption Time: 0.94338
PPO Batch Consumption Time: 0.09936
Total Iteration Time: 3.41851

Cumulative Model Updates: 20,615
Cumulative Timesteps: 344,218,122

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,957.51287
Policy Entropy: 0.78793
Value Function Loss: 0.05706

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03091
Policy Update Magnitude: 0.02680
Value Function Update Magnitude: 0.04511

Collected Steps per Second: 22,023.78594
Overall Steps per Second: 16,263.67694

Timestep Collection Time: 2.27109
Timestep Consumption Time: 0.80435
PPO Batch Consumption Time: 0.05796
Total Iteration Time: 3.07544

Cumulative Model Updates: 20,618
Cumulative Timesteps: 344,268,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 344268140...
Checkpoint 344268140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,195.06837
Policy Entropy: 0.79213
Value Function Loss: 0.05327

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01871
Policy Update Magnitude: 0.02948
Value Function Update Magnitude: 0.05024

Collected Steps per Second: 22,583.56182
Overall Steps per Second: 16,120.72740

Timestep Collection Time: 2.21453
Timestep Consumption Time: 0.88781
PPO Batch Consumption Time: 0.08505
Total Iteration Time: 3.10234

Cumulative Model Updates: 20,621
Cumulative Timesteps: 344,318,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,065.81130
Policy Entropy: 0.78924
Value Function Loss: 0.06157

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02175
Policy Update Magnitude: 0.02868
Value Function Update Magnitude: 0.05663

Collected Steps per Second: 22,605.70642
Overall Steps per Second: 16,724.04030

Timestep Collection Time: 2.21316
Timestep Consumption Time: 0.77834
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 2.99150

Cumulative Model Updates: 20,624
Cumulative Timesteps: 344,368,182

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 344368182...
Checkpoint 344368182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,407.25597
Policy Entropy: 0.79829
Value Function Loss: 0.06305

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02685
Policy Update Magnitude: 0.02963
Value Function Update Magnitude: 0.05035

Collected Steps per Second: 20,018.86210
Overall Steps per Second: 14,616.10699

Timestep Collection Time: 2.49834
Timestep Consumption Time: 0.92350
PPO Batch Consumption Time: 0.08748
Total Iteration Time: 3.42184

Cumulative Model Updates: 20,627
Cumulative Timesteps: 344,418,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,770.74215
Policy Entropy: 0.80294
Value Function Loss: 0.06224

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01765
Policy Update Magnitude: 0.02953
Value Function Update Magnitude: 0.04476

Collected Steps per Second: 22,681.16170
Overall Steps per Second: 16,716.78138

Timestep Collection Time: 2.20624
Timestep Consumption Time: 0.78716
PPO Batch Consumption Time: 0.06108
Total Iteration Time: 2.99340

Cumulative Model Updates: 20,630
Cumulative Timesteps: 344,468,236

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 344468236...
Checkpoint 344468236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,899.89589
Policy Entropy: 0.79976
Value Function Loss: 0.06051

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02039
Policy Update Magnitude: 0.03083
Value Function Update Magnitude: 0.04791

Collected Steps per Second: 20,389.57021
Overall Steps per Second: 14,968.00852

Timestep Collection Time: 2.45253
Timestep Consumption Time: 0.88833
PPO Batch Consumption Time: 0.08072
Total Iteration Time: 3.34086

Cumulative Model Updates: 20,633
Cumulative Timesteps: 344,518,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,824.88236
Policy Entropy: 0.79255
Value Function Loss: 0.06735

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01781
Policy Update Magnitude: 0.03194
Value Function Update Magnitude: 0.04835

Collected Steps per Second: 21,750.82766
Overall Steps per Second: 16,051.72660

Timestep Collection Time: 2.29895
Timestep Consumption Time: 0.81623
PPO Batch Consumption Time: 0.06462
Total Iteration Time: 3.11518

Cumulative Model Updates: 20,636
Cumulative Timesteps: 344,568,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 344568246...
Checkpoint 344568246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,603.54344
Policy Entropy: 0.79446
Value Function Loss: 0.06373

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.03165
Value Function Update Magnitude: 0.04767

Collected Steps per Second: 22,305.29754
Overall Steps per Second: 16,456.93668

Timestep Collection Time: 2.24252
Timestep Consumption Time: 0.79693
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 3.03945

Cumulative Model Updates: 20,639
Cumulative Timesteps: 344,618,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,273.97945
Policy Entropy: 0.80335
Value Function Loss: 0.06569

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02344
Policy Update Magnitude: 0.03320
Value Function Update Magnitude: 0.05056

Collected Steps per Second: 20,585.45024
Overall Steps per Second: 14,693.34610

Timestep Collection Time: 2.42977
Timestep Consumption Time: 0.97435
PPO Batch Consumption Time: 0.10939
Total Iteration Time: 3.40413

Cumulative Model Updates: 20,642
Cumulative Timesteps: 344,668,284

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 344668284...
Checkpoint 344668284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,969.24419
Policy Entropy: 0.81775
Value Function Loss: 0.06159

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01965
Policy Update Magnitude: 0.03147
Value Function Update Magnitude: 0.06107

Collected Steps per Second: 22,354.66751
Overall Steps per Second: 16,473.19179

Timestep Collection Time: 2.23765
Timestep Consumption Time: 0.79892
PPO Batch Consumption Time: 0.06212
Total Iteration Time: 3.03657

Cumulative Model Updates: 20,645
Cumulative Timesteps: 344,718,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,481.32316
Policy Entropy: 0.81126
Value Function Loss: 0.06972

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02859
Policy Update Magnitude: 0.03117
Value Function Update Magnitude: 0.06428

Collected Steps per Second: 20,975.80048
Overall Steps per Second: 14,973.95623

Timestep Collection Time: 2.38399
Timestep Consumption Time: 0.95555
PPO Batch Consumption Time: 0.10238
Total Iteration Time: 3.33953

Cumulative Model Updates: 20,648
Cumulative Timesteps: 344,768,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 344768312...
Checkpoint 344768312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,376.23451
Policy Entropy: 0.80816
Value Function Loss: 0.07127

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01842
Policy Update Magnitude: 0.03231
Value Function Update Magnitude: 0.07079

Collected Steps per Second: 21,263.79699
Overall Steps per Second: 15,874.21759

Timestep Collection Time: 2.35179
Timestep Consumption Time: 0.79847
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 3.15027

Cumulative Model Updates: 20,651
Cumulative Timesteps: 344,818,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,243.87128
Policy Entropy: 0.80847
Value Function Loss: 0.06344

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03771
Policy Update Magnitude: 0.03205
Value Function Update Magnitude: 0.07270

Collected Steps per Second: 20,271.20334
Overall Steps per Second: 14,571.11220

Timestep Collection Time: 2.46715
Timestep Consumption Time: 0.96513
PPO Batch Consumption Time: 0.10265
Total Iteration Time: 3.43227

Cumulative Model Updates: 20,654
Cumulative Timesteps: 344,868,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 344868332...
Checkpoint 344868332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,357.74374
Policy Entropy: 0.80792
Value Function Loss: 0.05677

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03341
Policy Update Magnitude: 0.03256
Value Function Update Magnitude: 0.06795

Collected Steps per Second: 22,228.45456
Overall Steps per Second: 16,337.18059

Timestep Collection Time: 2.25027
Timestep Consumption Time: 0.81146
PPO Batch Consumption Time: 0.06366
Total Iteration Time: 3.06173

Cumulative Model Updates: 20,657
Cumulative Timesteps: 344,918,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,030.80375
Policy Entropy: 0.81965
Value Function Loss: 0.05623

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04897
Policy Update Magnitude: 0.02902
Value Function Update Magnitude: 0.05633

Collected Steps per Second: 22,784.48862
Overall Steps per Second: 16,796.31201

Timestep Collection Time: 2.19535
Timestep Consumption Time: 0.78268
PPO Batch Consumption Time: 0.06035
Total Iteration Time: 2.97803

Cumulative Model Updates: 20,660
Cumulative Timesteps: 344,968,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 344968372...
Checkpoint 344968372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,825.06262
Policy Entropy: 0.80412
Value Function Loss: 0.06472

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04111
Policy Update Magnitude: 0.02794
Value Function Update Magnitude: 0.05063

Collected Steps per Second: 22,528.92649
Overall Steps per Second: 16,503.27671

Timestep Collection Time: 2.22061
Timestep Consumption Time: 0.81079
PPO Batch Consumption Time: 0.06111
Total Iteration Time: 3.03140

Cumulative Model Updates: 20,663
Cumulative Timesteps: 345,018,400

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,485.92387
Policy Entropy: 0.80173
Value Function Loss: 0.06820

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04903
Policy Update Magnitude: 0.02762
Value Function Update Magnitude: 0.04787

Collected Steps per Second: 22,423.99383
Overall Steps per Second: 16,557.15362

Timestep Collection Time: 2.23020
Timestep Consumption Time: 0.79025
PPO Batch Consumption Time: 0.06172
Total Iteration Time: 3.02045

Cumulative Model Updates: 20,666
Cumulative Timesteps: 345,068,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 345068410...
Checkpoint 345068410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,000.92412
Policy Entropy: 0.79681
Value Function Loss: 0.07026

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02708
Policy Update Magnitude: 0.02936
Value Function Update Magnitude: 0.04573

Collected Steps per Second: 22,478.51512
Overall Steps per Second: 16,521.12211

Timestep Collection Time: 2.22541
Timestep Consumption Time: 0.80247
PPO Batch Consumption Time: 0.05882
Total Iteration Time: 3.02788

Cumulative Model Updates: 20,669
Cumulative Timesteps: 345,118,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,234.76896
Policy Entropy: 0.80635
Value Function Loss: 0.06631

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05477
Policy Update Magnitude: 0.03032
Value Function Update Magnitude: 0.04569

Collected Steps per Second: 20,303.05647
Overall Steps per Second: 14,690.07603

Timestep Collection Time: 2.46278
Timestep Consumption Time: 0.94101
PPO Batch Consumption Time: 0.09490
Total Iteration Time: 3.40379

Cumulative Model Updates: 20,672
Cumulative Timesteps: 345,168,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 345168436...
Checkpoint 345168436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,675.37667
Policy Entropy: 0.79935
Value Function Loss: 0.06433

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04415
Policy Update Magnitude: 0.03038
Value Function Update Magnitude: 0.04721

Collected Steps per Second: 22,377.15306
Overall Steps per Second: 16,508.80579

Timestep Collection Time: 2.23505
Timestep Consumption Time: 0.79449
PPO Batch Consumption Time: 0.05908
Total Iteration Time: 3.02953

Cumulative Model Updates: 20,675
Cumulative Timesteps: 345,218,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,335.19517
Policy Entropy: 0.80514
Value Function Loss: 0.06399

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.05213
Policy Update Magnitude: 0.02934
Value Function Update Magnitude: 0.04527

Collected Steps per Second: 21,085.51044
Overall Steps per Second: 14,936.87666

Timestep Collection Time: 2.37196
Timestep Consumption Time: 0.97640
PPO Batch Consumption Time: 0.10330
Total Iteration Time: 3.34836

Cumulative Model Updates: 20,678
Cumulative Timesteps: 345,268,464

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 345268464...
Checkpoint 345268464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,969.76479
Policy Entropy: 0.79648
Value Function Loss: 0.06396

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02531
Policy Update Magnitude: 0.03065
Value Function Update Magnitude: 0.04979

Collected Steps per Second: 22,440.04610
Overall Steps per Second: 16,502.41135

Timestep Collection Time: 2.22878
Timestep Consumption Time: 0.80193
PPO Batch Consumption Time: 0.06010
Total Iteration Time: 3.03071

Cumulative Model Updates: 20,681
Cumulative Timesteps: 345,318,478

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,341.43243
Policy Entropy: 0.80193
Value Function Loss: 0.06520

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03307
Policy Update Magnitude: 0.03167
Value Function Update Magnitude: 0.04980

Collected Steps per Second: 20,679.82261
Overall Steps per Second: 14,963.31878

Timestep Collection Time: 2.41927
Timestep Consumption Time: 0.92424
PPO Batch Consumption Time: 0.08750
Total Iteration Time: 3.34351

Cumulative Model Updates: 20,684
Cumulative Timesteps: 345,368,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 345368508...
Checkpoint 345368508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,028.94140
Policy Entropy: 0.81001
Value Function Loss: 0.06153

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02233
Policy Update Magnitude: 0.02931
Value Function Update Magnitude: 0.05603

Collected Steps per Second: 22,556.93200
Overall Steps per Second: 16,632.38510

Timestep Collection Time: 2.21661
Timestep Consumption Time: 0.78957
PPO Batch Consumption Time: 0.05816
Total Iteration Time: 3.00618

Cumulative Model Updates: 20,687
Cumulative Timesteps: 345,418,508

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,336.28099
Policy Entropy: 0.81679
Value Function Loss: 0.06108

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02187
Policy Update Magnitude: 0.02876
Value Function Update Magnitude: 0.05054

Collected Steps per Second: 20,835.56439
Overall Steps per Second: 14,859.38193

Timestep Collection Time: 2.39984
Timestep Consumption Time: 0.96517
PPO Batch Consumption Time: 0.10456
Total Iteration Time: 3.36501

Cumulative Model Updates: 20,690
Cumulative Timesteps: 345,468,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 345468510...
Checkpoint 345468510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,819.94013
Policy Entropy: 0.79390
Value Function Loss: 0.06820

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02888
Policy Update Magnitude: 0.03014
Value Function Update Magnitude: 0.04662

Collected Steps per Second: 22,175.91378
Overall Steps per Second: 16,387.05101

Timestep Collection Time: 2.25560
Timestep Consumption Time: 0.79681
PPO Batch Consumption Time: 0.06096
Total Iteration Time: 3.05241

Cumulative Model Updates: 20,693
Cumulative Timesteps: 345,518,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,966.90935
Policy Entropy: 0.79676
Value Function Loss: 0.06511

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02585
Policy Update Magnitude: 0.03231
Value Function Update Magnitude: 0.04793

Collected Steps per Second: 21,256.52625
Overall Steps per Second: 15,047.04148

Timestep Collection Time: 2.35363
Timestep Consumption Time: 0.97128
PPO Batch Consumption Time: 0.10886
Total Iteration Time: 3.32491

Cumulative Model Updates: 20,696
Cumulative Timesteps: 345,568,560

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 345568560...
Checkpoint 345568560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,654.52533
Policy Entropy: 0.80109
Value Function Loss: 0.06663

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03733
Policy Update Magnitude: 0.03061
Value Function Update Magnitude: 0.04637

Collected Steps per Second: 22,471.63252
Overall Steps per Second: 16,521.54037

Timestep Collection Time: 2.22618
Timestep Consumption Time: 0.80174
PPO Batch Consumption Time: 0.06085
Total Iteration Time: 3.02793

Cumulative Model Updates: 20,699
Cumulative Timesteps: 345,618,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,260.58212
Policy Entropy: 0.82281
Value Function Loss: 0.05999

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02375
Policy Update Magnitude: 0.03261
Value Function Update Magnitude: 0.04708

Collected Steps per Second: 20,303.73976
Overall Steps per Second: 14,952.27400

Timestep Collection Time: 2.46467
Timestep Consumption Time: 0.88211
PPO Batch Consumption Time: 0.08125
Total Iteration Time: 3.34678

Cumulative Model Updates: 20,702
Cumulative Timesteps: 345,668,628

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 345668628...
Checkpoint 345668628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,846.85277
Policy Entropy: 0.81881
Value Function Loss: 0.06255

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03769
Policy Update Magnitude: 0.03125
Value Function Update Magnitude: 0.05364

Collected Steps per Second: 21,509.59954
Overall Steps per Second: 16,413.47032

Timestep Collection Time: 2.32510
Timestep Consumption Time: 0.72191
PPO Batch Consumption Time: 0.06236
Total Iteration Time: 3.04701

Cumulative Model Updates: 20,705
Cumulative Timesteps: 345,718,640

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,038.55918
Policy Entropy: 0.81793
Value Function Loss: 0.06244

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03098
Policy Update Magnitude: 0.02998
Value Function Update Magnitude: 0.05119

Collected Steps per Second: 20,875.54527
Overall Steps per Second: 15,087.92271

Timestep Collection Time: 2.39649
Timestep Consumption Time: 0.91928
PPO Batch Consumption Time: 0.11812
Total Iteration Time: 3.31576

Cumulative Model Updates: 20,708
Cumulative Timesteps: 345,768,668

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 345768668...
Checkpoint 345768668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,638.20710
Policy Entropy: 0.81962
Value Function Loss: 0.06300

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04198
Policy Update Magnitude: 0.03326
Value Function Update Magnitude: 0.04580

Collected Steps per Second: 21,833.56547
Overall Steps per Second: 16,682.58137

Timestep Collection Time: 2.29060
Timestep Consumption Time: 0.70726
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 2.99786

Cumulative Model Updates: 20,711
Cumulative Timesteps: 345,818,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,683.80878
Policy Entropy: 0.82719
Value Function Loss: 0.06676

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02753
Policy Update Magnitude: 0.03692
Value Function Update Magnitude: 0.03995

Collected Steps per Second: 19,341.33292
Overall Steps per Second: 14,591.37925

Timestep Collection Time: 2.58627
Timestep Consumption Time: 0.84191
PPO Batch Consumption Time: 0.08679
Total Iteration Time: 3.42819

Cumulative Model Updates: 20,714
Cumulative Timesteps: 345,868,702

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 345868702...
Checkpoint 345868702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,649.42648
Policy Entropy: 0.82899
Value Function Loss: 0.06641

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.03887
Value Function Update Magnitude: 0.03823

Collected Steps per Second: 22,152.08355
Overall Steps per Second: 16,798.83620

Timestep Collection Time: 2.25848
Timestep Consumption Time: 0.71970
PPO Batch Consumption Time: 0.05780
Total Iteration Time: 2.97818

Cumulative Model Updates: 20,717
Cumulative Timesteps: 345,918,732

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,650.61025
Policy Entropy: 0.83460
Value Function Loss: 0.06175

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03743
Policy Update Magnitude: 0.03700
Value Function Update Magnitude: 0.03515

Collected Steps per Second: 20,219.64601
Overall Steps per Second: 14,899.30913

Timestep Collection Time: 2.47284
Timestep Consumption Time: 0.88302
PPO Batch Consumption Time: 0.09909
Total Iteration Time: 3.35586

Cumulative Model Updates: 20,720
Cumulative Timesteps: 345,968,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 345968732...
Checkpoint 345968732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,267.33755
Policy Entropy: 0.82868
Value Function Loss: 0.05865

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04385
Policy Update Magnitude: 0.03227
Value Function Update Magnitude: 0.03280

Collected Steps per Second: 21,766.60936
Overall Steps per Second: 16,317.44293

Timestep Collection Time: 2.29710
Timestep Consumption Time: 0.76711
PPO Batch Consumption Time: 0.06091
Total Iteration Time: 3.06421

Cumulative Model Updates: 20,723
Cumulative Timesteps: 346,018,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,860.74439
Policy Entropy: 0.83030
Value Function Loss: 0.06034

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02709
Policy Update Magnitude: 0.02922
Value Function Update Magnitude: 0.03301

Collected Steps per Second: 22,492.62078
Overall Steps per Second: 16,718.13799

Timestep Collection Time: 2.22357
Timestep Consumption Time: 0.76803
PPO Batch Consumption Time: 0.06340
Total Iteration Time: 2.99160

Cumulative Model Updates: 20,726
Cumulative Timesteps: 346,068,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 346068746...
Checkpoint 346068746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,929.27339
Policy Entropy: 0.81767
Value Function Loss: 0.06867

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02945
Policy Update Magnitude: 0.02812
Value Function Update Magnitude: 0.03498

Collected Steps per Second: 22,206.70976
Overall Steps per Second: 16,457.59768

Timestep Collection Time: 2.25238
Timestep Consumption Time: 0.78682
PPO Batch Consumption Time: 0.06315
Total Iteration Time: 3.03920

Cumulative Model Updates: 20,729
Cumulative Timesteps: 346,118,764

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,503.36461
Policy Entropy: 0.82232
Value Function Loss: 0.06685

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02011
Policy Update Magnitude: 0.02952
Value Function Update Magnitude: 0.03657

Collected Steps per Second: 22,145.92853
Overall Steps per Second: 16,485.51322

Timestep Collection Time: 2.26001
Timestep Consumption Time: 0.77599
PPO Batch Consumption Time: 0.06047
Total Iteration Time: 3.03600

Cumulative Model Updates: 20,732
Cumulative Timesteps: 346,168,814

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 346168814...
Checkpoint 346168814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,175.43107
Policy Entropy: 0.82562
Value Function Loss: 0.06489

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02348
Policy Update Magnitude: 0.02854
Value Function Update Magnitude: 0.03424

Collected Steps per Second: 19,821.65739
Overall Steps per Second: 14,714.05047

Timestep Collection Time: 2.52340
Timestep Consumption Time: 0.87593
PPO Batch Consumption Time: 0.08433
Total Iteration Time: 3.39934

Cumulative Model Updates: 20,735
Cumulative Timesteps: 346,218,832

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,740.50806
Policy Entropy: 0.83685
Value Function Loss: 0.06042

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03572
Policy Update Magnitude: 0.02812
Value Function Update Magnitude: 0.02991

Collected Steps per Second: 23,022.57445
Overall Steps per Second: 17,038.57310

Timestep Collection Time: 2.17282
Timestep Consumption Time: 0.76310
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 2.93593

Cumulative Model Updates: 20,738
Cumulative Timesteps: 346,268,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 346268856...
Checkpoint 346268856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,184.83421
Policy Entropy: 0.83034
Value Function Loss: 0.06032

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03849
Policy Update Magnitude: 0.02823
Value Function Update Magnitude: 0.03083

Collected Steps per Second: 20,978.88636
Overall Steps per Second: 15,234.08867

Timestep Collection Time: 2.38440
Timestep Consumption Time: 0.89916
PPO Batch Consumption Time: 0.08668
Total Iteration Time: 3.28356

Cumulative Model Updates: 20,741
Cumulative Timesteps: 346,318,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,781.95246
Policy Entropy: 0.82525
Value Function Loss: 0.05963

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02167
Policy Update Magnitude: 0.02844
Value Function Update Magnitude: 0.02944

Collected Steps per Second: 22,327.41000
Overall Steps per Second: 16,575.01032

Timestep Collection Time: 2.24056
Timestep Consumption Time: 0.77759
PPO Batch Consumption Time: 0.05966
Total Iteration Time: 3.01816

Cumulative Model Updates: 20,744
Cumulative Timesteps: 346,368,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 346368904...
Checkpoint 346368904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,221.00073
Policy Entropy: 0.82924
Value Function Loss: 0.05001

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04204
Policy Update Magnitude: 0.02938
Value Function Update Magnitude: 0.03620

Collected Steps per Second: 22,581.90000
Overall Steps per Second: 16,111.04801

Timestep Collection Time: 2.21593
Timestep Consumption Time: 0.89001
PPO Batch Consumption Time: 0.08289
Total Iteration Time: 3.10594

Cumulative Model Updates: 20,747
Cumulative Timesteps: 346,418,944

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,038.68813
Policy Entropy: 0.83708
Value Function Loss: 0.04776

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02585
Policy Update Magnitude: 0.02822
Value Function Update Magnitude: 0.04078

Collected Steps per Second: 22,484.72326
Overall Steps per Second: 16,449.75383

Timestep Collection Time: 2.22507
Timestep Consumption Time: 0.81632
PPO Batch Consumption Time: 0.06178
Total Iteration Time: 3.04138

Cumulative Model Updates: 20,750
Cumulative Timesteps: 346,468,974

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 346468974...
Checkpoint 346468974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,960.60656
Policy Entropy: 0.83619
Value Function Loss: 0.04871

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04500
Policy Update Magnitude: 0.02728
Value Function Update Magnitude: 0.03935

Collected Steps per Second: 20,839.17652
Overall Steps per Second: 15,024.06482

Timestep Collection Time: 2.39952
Timestep Consumption Time: 0.92874
PPO Batch Consumption Time: 0.09950
Total Iteration Time: 3.32826

Cumulative Model Updates: 20,753
Cumulative Timesteps: 346,518,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,858.22907
Policy Entropy: 0.82622
Value Function Loss: 0.05132

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.02904
Value Function Update Magnitude: 0.04151

Collected Steps per Second: 22,571.36944
Overall Steps per Second: 16,508.16384

Timestep Collection Time: 2.21546
Timestep Consumption Time: 0.81371
PPO Batch Consumption Time: 0.06134
Total Iteration Time: 3.02917

Cumulative Model Updates: 20,756
Cumulative Timesteps: 346,568,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 346568984...
Checkpoint 346568984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,039.34420
Policy Entropy: 0.81377
Value Function Loss: 0.06450

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03489
Policy Update Magnitude: 0.02795
Value Function Update Magnitude: 0.04763

Collected Steps per Second: 20,166.36018
Overall Steps per Second: 14,818.56822

Timestep Collection Time: 2.48067
Timestep Consumption Time: 0.89523
PPO Batch Consumption Time: 0.08737
Total Iteration Time: 3.37590

Cumulative Model Updates: 20,759
Cumulative Timesteps: 346,619,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,135.09428
Policy Entropy: 0.81477
Value Function Loss: 0.06354

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03285
Policy Update Magnitude: 0.02993
Value Function Update Magnitude: 0.04400

Collected Steps per Second: 22,433.08293
Overall Steps per Second: 16,468.99536

Timestep Collection Time: 2.22930
Timestep Consumption Time: 0.80732
PPO Batch Consumption Time: 0.06372
Total Iteration Time: 3.03662

Cumulative Model Updates: 20,762
Cumulative Timesteps: 346,669,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 346669020...
Checkpoint 346669020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,424.00293
Policy Entropy: 0.81142
Value Function Loss: 0.06504

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.05077
Policy Update Magnitude: 0.03054
Value Function Update Magnitude: 0.05305

Collected Steps per Second: 22,532.26075
Overall Steps per Second: 16,502.13842

Timestep Collection Time: 2.22028
Timestep Consumption Time: 0.81132
PPO Batch Consumption Time: 0.06294
Total Iteration Time: 3.03161

Cumulative Model Updates: 20,765
Cumulative Timesteps: 346,719,048

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,215.02538
Policy Entropy: 0.82294
Value Function Loss: 0.05692

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04951
Policy Update Magnitude: 0.03056
Value Function Update Magnitude: 0.05298

Collected Steps per Second: 22,728.39325
Overall Steps per Second: 16,668.84283

Timestep Collection Time: 2.20068
Timestep Consumption Time: 0.80000
PPO Batch Consumption Time: 0.06056
Total Iteration Time: 3.00069

Cumulative Model Updates: 20,768
Cumulative Timesteps: 346,769,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 346769066...
Checkpoint 346769066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,630.26310
Policy Entropy: 0.81331
Value Function Loss: 0.06145

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04938
Policy Update Magnitude: 0.03032
Value Function Update Magnitude: 0.04887

Collected Steps per Second: 20,278.43454
Overall Steps per Second: 14,556.38521

Timestep Collection Time: 2.46617
Timestep Consumption Time: 0.96944
PPO Batch Consumption Time: 0.10947
Total Iteration Time: 3.43561

Cumulative Model Updates: 20,771
Cumulative Timesteps: 346,819,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,075.07293
Policy Entropy: 0.80046
Value Function Loss: 0.07517

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05317
Policy Update Magnitude: 0.02925
Value Function Update Magnitude: 0.04377

Collected Steps per Second: 22,612.88729
Overall Steps per Second: 16,656.37079

Timestep Collection Time: 2.21148
Timestep Consumption Time: 0.79085
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 3.00233

Cumulative Model Updates: 20,774
Cumulative Timesteps: 346,869,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 346869084...
Checkpoint 346869084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,608.14429
Policy Entropy: 0.80068
Value Function Loss: 0.07718

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.06073
Policy Update Magnitude: 0.03251
Value Function Update Magnitude: 0.03909

Collected Steps per Second: 20,809.69320
Overall Steps per Second: 14,844.37742

Timestep Collection Time: 2.40340
Timestep Consumption Time: 0.96582
PPO Batch Consumption Time: 0.10966
Total Iteration Time: 3.36922

Cumulative Model Updates: 20,777
Cumulative Timesteps: 346,919,098

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,092.68603
Policy Entropy: 0.79384
Value Function Loss: 0.07847

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07505
Policy Update Magnitude: 0.03241
Value Function Update Magnitude: 0.04755

Collected Steps per Second: 22,495.44640
Overall Steps per Second: 16,625.90858

Timestep Collection Time: 2.22329
Timestep Consumption Time: 0.78490
PPO Batch Consumption Time: 0.05864
Total Iteration Time: 3.00820

Cumulative Model Updates: 20,780
Cumulative Timesteps: 346,969,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 346969112...
Checkpoint 346969112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,271.70812
Policy Entropy: 0.79361
Value Function Loss: 0.07156

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05826
Policy Update Magnitude: 0.03177
Value Function Update Magnitude: 0.04167

Collected Steps per Second: 20,424.84160
Overall Steps per Second: 14,835.17624

Timestep Collection Time: 2.44947
Timestep Consumption Time: 0.92292
PPO Batch Consumption Time: 0.09354
Total Iteration Time: 3.37239

Cumulative Model Updates: 20,783
Cumulative Timesteps: 347,019,142

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,536.67773
Policy Entropy: 0.79164
Value Function Loss: 0.06794

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05783
Policy Update Magnitude: 0.03015
Value Function Update Magnitude: 0.03468

Collected Steps per Second: 22,227.55831
Overall Steps per Second: 16,432.49793

Timestep Collection Time: 2.25009
Timestep Consumption Time: 0.79351
PPO Batch Consumption Time: 0.06048
Total Iteration Time: 3.04360

Cumulative Model Updates: 20,786
Cumulative Timesteps: 347,069,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 347069156...
Checkpoint 347069156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,955.50693
Policy Entropy: 0.79539
Value Function Loss: 0.06428

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.03082
Value Function Update Magnitude: 0.03283

Collected Steps per Second: 20,379.64286
Overall Steps per Second: 15,018.39857

Timestep Collection Time: 2.45431
Timestep Consumption Time: 0.87614
PPO Batch Consumption Time: 0.08529
Total Iteration Time: 3.33045

Cumulative Model Updates: 20,789
Cumulative Timesteps: 347,119,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,888.41916
Policy Entropy: 0.78837
Value Function Loss: 0.06657

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.06664
Policy Update Magnitude: 0.02915
Value Function Update Magnitude: 0.03213

Collected Steps per Second: 22,541.10717
Overall Steps per Second: 16,601.40238

Timestep Collection Time: 2.21897
Timestep Consumption Time: 0.79391
PPO Batch Consumption Time: 0.06160
Total Iteration Time: 3.01288

Cumulative Model Updates: 20,792
Cumulative Timesteps: 347,169,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 347169192...
Checkpoint 347169192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,488.45316
Policy Entropy: 0.78786
Value Function Loss: 0.07109

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.02935
Value Function Update Magnitude: 0.03011

Collected Steps per Second: 20,485.84498
Overall Steps per Second: 14,916.49687

Timestep Collection Time: 2.44149
Timestep Consumption Time: 0.91158
PPO Batch Consumption Time: 0.08898
Total Iteration Time: 3.35307

Cumulative Model Updates: 20,795
Cumulative Timesteps: 347,219,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,972.36575
Policy Entropy: 0.78540
Value Function Loss: 0.07294

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07848
Policy Update Magnitude: 0.02879
Value Function Update Magnitude: 0.02958

Collected Steps per Second: 22,430.44421
Overall Steps per Second: 16,507.22550

Timestep Collection Time: 2.23045
Timestep Consumption Time: 0.80034
PPO Batch Consumption Time: 0.06212
Total Iteration Time: 3.03079

Cumulative Model Updates: 20,798
Cumulative Timesteps: 347,269,238

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 347269238...
Checkpoint 347269238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,182.24974
Policy Entropy: 0.78362
Value Function Loss: 0.07387

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06611
Policy Update Magnitude: 0.02945
Value Function Update Magnitude: 0.03319

Collected Steps per Second: 20,636.52230
Overall Steps per Second: 14,915.11968

Timestep Collection Time: 2.42376
Timestep Consumption Time: 0.92975
PPO Batch Consumption Time: 0.08759
Total Iteration Time: 3.35351

Cumulative Model Updates: 20,801
Cumulative Timesteps: 347,319,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,415.06502
Policy Entropy: 0.78030
Value Function Loss: 0.07362

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.06547
Policy Update Magnitude: 0.03003
Value Function Update Magnitude: 0.03429

Collected Steps per Second: 22,498.94214
Overall Steps per Second: 16,538.48530

Timestep Collection Time: 2.22242
Timestep Consumption Time: 0.80096
PPO Batch Consumption Time: 0.06102
Total Iteration Time: 3.02337

Cumulative Model Updates: 20,804
Cumulative Timesteps: 347,369,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 347369258...
Checkpoint 347369258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,851.50565
Policy Entropy: 0.76995
Value Function Loss: 0.08183

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05875
Policy Update Magnitude: 0.02784
Value Function Update Magnitude: 0.04209

Collected Steps per Second: 20,268.99223
Overall Steps per Second: 14,748.02440

Timestep Collection Time: 2.46682
Timestep Consumption Time: 0.92346
PPO Batch Consumption Time: 0.08995
Total Iteration Time: 3.39028

Cumulative Model Updates: 20,807
Cumulative Timesteps: 347,419,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,642.35607
Policy Entropy: 0.78243
Value Function Loss: 0.07402

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02971
Policy Update Magnitude: 0.02956
Value Function Update Magnitude: 0.05115

Collected Steps per Second: 22,734.44568
Overall Steps per Second: 16,663.12772

Timestep Collection Time: 2.20019
Timestep Consumption Time: 0.80165
PPO Batch Consumption Time: 0.05979
Total Iteration Time: 3.00184

Cumulative Model Updates: 20,810
Cumulative Timesteps: 347,469,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 347469278...
Checkpoint 347469278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,624.93676
Policy Entropy: 0.78559
Value Function Loss: 0.06662

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02811
Policy Update Magnitude: 0.02908
Value Function Update Magnitude: 0.05662

Collected Steps per Second: 20,977.13708
Overall Steps per Second: 15,085.47293

Timestep Collection Time: 2.38383
Timestep Consumption Time: 0.93101
PPO Batch Consumption Time: 0.09155
Total Iteration Time: 3.31484

Cumulative Model Updates: 20,813
Cumulative Timesteps: 347,519,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,267.16248
Policy Entropy: 0.78867
Value Function Loss: 0.05587

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01631
Policy Update Magnitude: 0.02906
Value Function Update Magnitude: 0.06105

Collected Steps per Second: 22,590.59921
Overall Steps per Second: 16,639.43447

Timestep Collection Time: 2.21375
Timestep Consumption Time: 0.79176
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 3.00551

Cumulative Model Updates: 20,816
Cumulative Timesteps: 347,569,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 347569294...
Checkpoint 347569294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,286.56557
Policy Entropy: 0.78061
Value Function Loss: 0.06165

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02278
Policy Update Magnitude: 0.02894
Value Function Update Magnitude: 0.06281

Collected Steps per Second: 19,812.32452
Overall Steps per Second: 14,600.25318

Timestep Collection Time: 2.52398
Timestep Consumption Time: 0.90102
PPO Batch Consumption Time: 0.08681
Total Iteration Time: 3.42501

Cumulative Model Updates: 20,819
Cumulative Timesteps: 347,619,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,087.52304
Policy Entropy: 0.78104
Value Function Loss: 0.06853

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.00945
Policy Update Magnitude: 0.02903
Value Function Update Magnitude: 0.06288

Collected Steps per Second: 22,665.40709
Overall Steps per Second: 16,586.94762

Timestep Collection Time: 2.20636
Timestep Consumption Time: 0.80854
PPO Batch Consumption Time: 0.06151
Total Iteration Time: 3.01490

Cumulative Model Updates: 20,822
Cumulative Timesteps: 347,669,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 347669308...
Checkpoint 347669308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,920.18242
Policy Entropy: 0.78380
Value Function Loss: 0.07057

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02711
Policy Update Magnitude: 0.03180
Value Function Update Magnitude: 0.06687

Collected Steps per Second: 22,243.58603
Overall Steps per Second: 15,951.07063

Timestep Collection Time: 2.24856
Timestep Consumption Time: 0.88703
PPO Batch Consumption Time: 0.08295
Total Iteration Time: 3.13559

Cumulative Model Updates: 20,825
Cumulative Timesteps: 347,719,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,207.19944
Policy Entropy: 0.79046
Value Function Loss: 0.07358

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02911
Policy Update Magnitude: 0.03493
Value Function Update Magnitude: 0.07019

Collected Steps per Second: 22,617.79749
Overall Steps per Second: 16,519.56148

Timestep Collection Time: 2.21100
Timestep Consumption Time: 0.81620
PPO Batch Consumption Time: 0.06060
Total Iteration Time: 3.02720

Cumulative Model Updates: 20,828
Cumulative Timesteps: 347,769,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 347769332...
Checkpoint 347769332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,408.45753
Policy Entropy: 0.79037
Value Function Loss: 0.07171

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.04332
Policy Update Magnitude: 0.03052
Value Function Update Magnitude: 0.07472

Collected Steps per Second: 20,746.28758
Overall Steps per Second: 15,117.72475

Timestep Collection Time: 2.41200
Timestep Consumption Time: 0.89802
PPO Batch Consumption Time: 0.09318
Total Iteration Time: 3.31002

Cumulative Model Updates: 20,831
Cumulative Timesteps: 347,819,372

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,291.31105
Policy Entropy: 0.79414
Value Function Loss: 0.08030

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03098
Policy Update Magnitude: 0.02984
Value Function Update Magnitude: 0.07397

Collected Steps per Second: 22,604.99038
Overall Steps per Second: 16,846.28130

Timestep Collection Time: 2.21287
Timestep Consumption Time: 0.75645
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 2.96932

Cumulative Model Updates: 20,834
Cumulative Timesteps: 347,869,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 347869394...
Checkpoint 347869394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,540.39602
Policy Entropy: 0.80827
Value Function Loss: 0.07806

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03274
Policy Update Magnitude: 0.03218
Value Function Update Magnitude: 0.07091

Collected Steps per Second: 20,021.04592
Overall Steps per Second: 14,708.00507

Timestep Collection Time: 2.49787
Timestep Consumption Time: 0.90232
PPO Batch Consumption Time: 0.08595
Total Iteration Time: 3.40019

Cumulative Model Updates: 20,837
Cumulative Timesteps: 347,919,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,857.61405
Policy Entropy: 0.81352
Value Function Loss: 0.07418

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01947
Policy Update Magnitude: 0.03363
Value Function Update Magnitude: 0.07304

Collected Steps per Second: 22,347.92096
Overall Steps per Second: 16,395.19942

Timestep Collection Time: 2.23860
Timestep Consumption Time: 0.81278
PPO Batch Consumption Time: 0.05930
Total Iteration Time: 3.05138

Cumulative Model Updates: 20,840
Cumulative Timesteps: 347,969,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 347969432...
Checkpoint 347969432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,128.02532
Policy Entropy: 0.82199
Value Function Loss: 0.06453

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03307
Policy Update Magnitude: 0.03138
Value Function Update Magnitude: 0.06918

Collected Steps per Second: 20,672.25707
Overall Steps per Second: 15,050.04723

Timestep Collection Time: 2.41976
Timestep Consumption Time: 0.90395
PPO Batch Consumption Time: 0.09237
Total Iteration Time: 3.32371

Cumulative Model Updates: 20,843
Cumulative Timesteps: 348,019,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,639.57863
Policy Entropy: 0.82706
Value Function Loss: 0.05822

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01919
Policy Update Magnitude: 0.03155
Value Function Update Magnitude: 0.06819

Collected Steps per Second: 22,346.72208
Overall Steps per Second: 16,433.34250

Timestep Collection Time: 2.23863
Timestep Consumption Time: 0.80555
PPO Batch Consumption Time: 0.06074
Total Iteration Time: 3.04418

Cumulative Model Updates: 20,846
Cumulative Timesteps: 348,069,480

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 348069480...
Checkpoint 348069480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,086.28145
Policy Entropy: 0.83796
Value Function Loss: 0.05660

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.03308
Value Function Update Magnitude: 0.06565

Collected Steps per Second: 20,144.62132
Overall Steps per Second: 14,270.81737

Timestep Collection Time: 2.48215
Timestep Consumption Time: 1.02164
PPO Batch Consumption Time: 0.11972
Total Iteration Time: 3.50379

Cumulative Model Updates: 20,849
Cumulative Timesteps: 348,119,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,331.41841
Policy Entropy: 0.83607
Value Function Loss: 0.06181

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02176
Policy Update Magnitude: 0.03112
Value Function Update Magnitude: 0.05726

Collected Steps per Second: 22,914.01198
Overall Steps per Second: 16,881.66278

Timestep Collection Time: 2.18286
Timestep Consumption Time: 0.78000
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 2.96286

Cumulative Model Updates: 20,852
Cumulative Timesteps: 348,169,500

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 348169500...
Checkpoint 348169500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,250.39191
Policy Entropy: 0.83133
Value Function Loss: 0.06379

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03113
Policy Update Magnitude: 0.03039
Value Function Update Magnitude: 0.05280

Collected Steps per Second: 20,797.23914
Overall Steps per Second: 14,664.07621

Timestep Collection Time: 2.40522
Timestep Consumption Time: 1.00597
PPO Batch Consumption Time: 0.12158
Total Iteration Time: 3.41119

Cumulative Model Updates: 20,855
Cumulative Timesteps: 348,219,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,109.35064
Policy Entropy: 0.82621
Value Function Loss: 0.06233

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02947
Policy Update Magnitude: 0.02805
Value Function Update Magnitude: 0.05023

Collected Steps per Second: 22,932.60562
Overall Steps per Second: 16,714.73107

Timestep Collection Time: 2.18144
Timestep Consumption Time: 0.81149
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 2.99293

Cumulative Model Updates: 20,858
Cumulative Timesteps: 348,269,548

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 348269548...
Checkpoint 348269548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,241.34221
Policy Entropy: 0.83171
Value Function Loss: 0.05896

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03069
Policy Update Magnitude: 0.02751
Value Function Update Magnitude: 0.04630

Collected Steps per Second: 19,751.66470
Overall Steps per Second: 14,529.57178

Timestep Collection Time: 2.53214
Timestep Consumption Time: 0.91008
PPO Batch Consumption Time: 0.08683
Total Iteration Time: 3.44222

Cumulative Model Updates: 20,861
Cumulative Timesteps: 348,319,562

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,472.40364
Policy Entropy: 0.82699
Value Function Loss: 0.05748

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.02549
Value Function Update Magnitude: 0.04171

Collected Steps per Second: 22,355.62069
Overall Steps per Second: 16,465.16325

Timestep Collection Time: 2.23657
Timestep Consumption Time: 0.80014
PPO Batch Consumption Time: 0.06065
Total Iteration Time: 3.03671

Cumulative Model Updates: 20,864
Cumulative Timesteps: 348,369,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 348369562...
Checkpoint 348369562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,710.64034
Policy Entropy: 0.82548
Value Function Loss: 0.06292

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02799
Policy Update Magnitude: 0.02806
Value Function Update Magnitude: 0.04455

Collected Steps per Second: 22,654.09626
Overall Steps per Second: 16,639.45276

Timestep Collection Time: 2.20746
Timestep Consumption Time: 0.79793
PPO Batch Consumption Time: 0.05888
Total Iteration Time: 3.00539

Cumulative Model Updates: 20,867
Cumulative Timesteps: 348,419,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,901.90321
Policy Entropy: 0.82358
Value Function Loss: 0.06249

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04608
Policy Update Magnitude: 0.02752
Value Function Update Magnitude: 0.04949

Collected Steps per Second: 22,635.01088
Overall Steps per Second: 16,648.00367

Timestep Collection Time: 2.21100
Timestep Consumption Time: 0.79513
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 3.00613

Cumulative Model Updates: 20,870
Cumulative Timesteps: 348,469,616

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 348469616...
Checkpoint 348469616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,406.77258
Policy Entropy: 0.83036
Value Function Loss: 0.06571

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03431
Policy Update Magnitude: 0.02831
Value Function Update Magnitude: 0.04642

Collected Steps per Second: 22,492.14536
Overall Steps per Second: 16,515.52095

Timestep Collection Time: 2.22362
Timestep Consumption Time: 0.80468
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 3.02830

Cumulative Model Updates: 20,873
Cumulative Timesteps: 348,519,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,181.51711
Policy Entropy: 0.84048
Value Function Loss: 0.05999

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03944
Policy Update Magnitude: 0.02626
Value Function Update Magnitude: 0.04565

Collected Steps per Second: 19,943.41989
Overall Steps per Second: 14,624.10678

Timestep Collection Time: 2.50820
Timestep Consumption Time: 0.91232
PPO Batch Consumption Time: 0.08874
Total Iteration Time: 3.42052

Cumulative Model Updates: 20,876
Cumulative Timesteps: 348,569,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 348569652...
Checkpoint 348569652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,949.83438
Policy Entropy: 0.84455
Value Function Loss: 0.05672

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03737
Policy Update Magnitude: 0.02730
Value Function Update Magnitude: 0.04219

Collected Steps per Second: 21,665.85505
Overall Steps per Second: 16,603.90234

Timestep Collection Time: 2.30815
Timestep Consumption Time: 0.70367
PPO Batch Consumption Time: 0.05899
Total Iteration Time: 3.01182

Cumulative Model Updates: 20,879
Cumulative Timesteps: 348,619,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,272.46872
Policy Entropy: 0.83994
Value Function Loss: 0.05420

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02367
Policy Update Magnitude: 0.02823
Value Function Update Magnitude: 0.04240

Collected Steps per Second: 19,721.98102
Overall Steps per Second: 14,852.27456

Timestep Collection Time: 2.53656
Timestep Consumption Time: 0.83168
PPO Batch Consumption Time: 0.08334
Total Iteration Time: 3.36824

Cumulative Model Updates: 20,882
Cumulative Timesteps: 348,669,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 348669686...
Checkpoint 348669686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,356.13358
Policy Entropy: 0.83731
Value Function Loss: 0.05829

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.02784
Value Function Update Magnitude: 0.04594

Collected Steps per Second: 21,674.83510
Overall Steps per Second: 16,483.25704

Timestep Collection Time: 2.30793
Timestep Consumption Time: 0.72691
PPO Batch Consumption Time: 0.06202
Total Iteration Time: 3.03484

Cumulative Model Updates: 20,885
Cumulative Timesteps: 348,719,710

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,009.00547
Policy Entropy: 0.83021
Value Function Loss: 0.06689

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03634
Policy Update Magnitude: 0.02668
Value Function Update Magnitude: 0.04574

Collected Steps per Second: 19,691.17525
Overall Steps per Second: 14,943.04826

Timestep Collection Time: 2.53992
Timestep Consumption Time: 0.80705
PPO Batch Consumption Time: 0.07895
Total Iteration Time: 3.34697

Cumulative Model Updates: 20,888
Cumulative Timesteps: 348,769,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 348769724...
Checkpoint 348769724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,156.50207
Policy Entropy: 0.83520
Value Function Loss: 0.06885

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03021
Policy Update Magnitude: 0.03050
Value Function Update Magnitude: 0.04624

Collected Steps per Second: 22,010.28373
Overall Steps per Second: 16,877.03234

Timestep Collection Time: 2.27248
Timestep Consumption Time: 0.69119
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 2.96367

Cumulative Model Updates: 20,891
Cumulative Timesteps: 348,819,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,741.99961
Policy Entropy: 0.84628
Value Function Loss: 0.06965

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02579
Policy Update Magnitude: 0.03108
Value Function Update Magnitude: 0.05003

Collected Steps per Second: 20,346.79221
Overall Steps per Second: 14,775.56756

Timestep Collection Time: 2.45778
Timestep Consumption Time: 0.92672
PPO Batch Consumption Time: 0.11800
Total Iteration Time: 3.38451

Cumulative Model Updates: 20,894
Cumulative Timesteps: 348,869,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 348869750...
Checkpoint 348869750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,526.15903
Policy Entropy: 0.85353
Value Function Loss: 0.06721

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03168
Policy Update Magnitude: 0.03183
Value Function Update Magnitude: 0.05660

Collected Steps per Second: 21,995.43459
Overall Steps per Second: 16,827.46076

Timestep Collection Time: 2.27384
Timestep Consumption Time: 0.69833
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 2.97217

Cumulative Model Updates: 20,897
Cumulative Timesteps: 348,919,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,867.20564
Policy Entropy: 0.85490
Value Function Loss: 0.06868

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02936
Policy Update Magnitude: 0.03185
Value Function Update Magnitude: 0.06580

Collected Steps per Second: 19,876.78760
Overall Steps per Second: 14,593.79950

Timestep Collection Time: 2.51691
Timestep Consumption Time: 0.91113
PPO Batch Consumption Time: 0.10020
Total Iteration Time: 3.42803

Cumulative Model Updates: 20,900
Cumulative Timesteps: 348,969,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 348969792...
Checkpoint 348969792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,672.82953
Policy Entropy: 0.83858
Value Function Loss: 0.06348

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.04123
Policy Update Magnitude: 0.03205
Value Function Update Magnitude: 0.07102

Collected Steps per Second: 22,506.21826
Overall Steps per Second: 16,662.04313

Timestep Collection Time: 2.22196
Timestep Consumption Time: 0.77935
PPO Batch Consumption Time: 0.05865
Total Iteration Time: 3.00131

Cumulative Model Updates: 20,903
Cumulative Timesteps: 349,019,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,342.67356
Policy Entropy: 0.84534
Value Function Loss: 0.06533

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.06019
Policy Update Magnitude: 0.03188
Value Function Update Magnitude: 0.06155

Collected Steps per Second: 19,936.22862
Overall Steps per Second: 14,689.36579

Timestep Collection Time: 2.50890
Timestep Consumption Time: 0.89615
PPO Batch Consumption Time: 0.08800
Total Iteration Time: 3.40505

Cumulative Model Updates: 20,906
Cumulative Timesteps: 349,069,818

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 349069818...
Checkpoint 349069818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,139.11888
Policy Entropy: 0.84415
Value Function Loss: 0.05772

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05860
Policy Update Magnitude: 0.02918
Value Function Update Magnitude: 0.05775

Collected Steps per Second: 22,179.27388
Overall Steps per Second: 16,547.85688

Timestep Collection Time: 2.25625
Timestep Consumption Time: 0.76783
PPO Batch Consumption Time: 0.05900
Total Iteration Time: 3.02408

Cumulative Model Updates: 20,909
Cumulative Timesteps: 349,119,860

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,010.66148
Policy Entropy: 0.85156
Value Function Loss: 0.06152

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05876
Policy Update Magnitude: 0.02769
Value Function Update Magnitude: 0.05455

Collected Steps per Second: 22,758.59524
Overall Steps per Second: 16,096.51732

Timestep Collection Time: 2.19803
Timestep Consumption Time: 0.90973
PPO Batch Consumption Time: 0.10051
Total Iteration Time: 3.10775

Cumulative Model Updates: 20,912
Cumulative Timesteps: 349,169,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 349169884...
Checkpoint 349169884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,321.07819
Policy Entropy: 0.83790
Value Function Loss: 0.06088

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03994
Policy Update Magnitude: 0.03123
Value Function Update Magnitude: 0.05827

Collected Steps per Second: 22,478.58333
Overall Steps per Second: 16,518.01008

Timestep Collection Time: 2.22523
Timestep Consumption Time: 0.80298
PPO Batch Consumption Time: 0.06085
Total Iteration Time: 3.02821

Cumulative Model Updates: 20,915
Cumulative Timesteps: 349,219,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,229.67195
Policy Entropy: 0.84775
Value Function Loss: 0.05897

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.04113
Policy Update Magnitude: 0.03214
Value Function Update Magnitude: 0.05810

Collected Steps per Second: 20,004.88141
Overall Steps per Second: 14,164.46884

Timestep Collection Time: 2.49969
Timestep Consumption Time: 1.03069
PPO Batch Consumption Time: 0.12663
Total Iteration Time: 3.53038

Cumulative Model Updates: 20,918
Cumulative Timesteps: 349,269,910

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 349269910...
Checkpoint 349269910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,544.95559
Policy Entropy: 0.84754
Value Function Loss: 0.05683

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02070
Policy Update Magnitude: 0.03034
Value Function Update Magnitude: 0.05480

Collected Steps per Second: 22,837.61993
Overall Steps per Second: 16,736.37816

Timestep Collection Time: 2.19042
Timestep Consumption Time: 0.79852
PPO Batch Consumption Time: 0.05772
Total Iteration Time: 2.98894

Cumulative Model Updates: 20,921
Cumulative Timesteps: 349,319,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,920.02017
Policy Entropy: 0.84967
Value Function Loss: 0.05585

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01859
Policy Update Magnitude: 0.02998
Value Function Update Magnitude: 0.04903

Collected Steps per Second: 20,200.00403
Overall Steps per Second: 14,658.40543

Timestep Collection Time: 2.47594
Timestep Consumption Time: 0.93603
PPO Batch Consumption Time: 0.09388
Total Iteration Time: 3.41197

Cumulative Model Updates: 20,924
Cumulative Timesteps: 349,369,948

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 349369948...
Checkpoint 349369948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,080.09053
Policy Entropy: 0.83980
Value Function Loss: 0.06453

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03525
Policy Update Magnitude: 0.03001
Value Function Update Magnitude: 0.05242

Collected Steps per Second: 22,215.73008
Overall Steps per Second: 16,364.96778

Timestep Collection Time: 2.25093
Timestep Consumption Time: 0.80475
PPO Batch Consumption Time: 0.05886
Total Iteration Time: 3.05567

Cumulative Model Updates: 20,927
Cumulative Timesteps: 349,419,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,189.51658
Policy Entropy: 0.83423
Value Function Loss: 0.06327

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03359
Policy Update Magnitude: 0.02985
Value Function Update Magnitude: 0.04999

Collected Steps per Second: 22,878.16435
Overall Steps per Second: 16,055.99147

Timestep Collection Time: 2.18671
Timestep Consumption Time: 0.92913
PPO Batch Consumption Time: 0.08495
Total Iteration Time: 3.11585

Cumulative Model Updates: 20,930
Cumulative Timesteps: 349,469,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 349469982...
Checkpoint 349469982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,212.55157
Policy Entropy: 0.83136
Value Function Loss: 0.06131

Mean KL Divergence: 0.00124
SB3 Clip Fraction: 0.01105
Policy Update Magnitude: 0.03083
Value Function Update Magnitude: 0.04906

Collected Steps per Second: 22,678.37060
Overall Steps per Second: 16,630.60974

Timestep Collection Time: 2.20589
Timestep Consumption Time: 0.80218
PPO Batch Consumption Time: 0.05878
Total Iteration Time: 3.00807

Cumulative Model Updates: 20,933
Cumulative Timesteps: 349,520,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,739.37391
Policy Entropy: 0.85405
Value Function Loss: 0.05345

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02119
Policy Update Magnitude: 0.03058
Value Function Update Magnitude: 0.04947

Collected Steps per Second: 20,685.72770
Overall Steps per Second: 14,867.97088

Timestep Collection Time: 2.41780
Timestep Consumption Time: 0.94607
PPO Batch Consumption Time: 0.09416
Total Iteration Time: 3.36388

Cumulative Model Updates: 20,936
Cumulative Timesteps: 349,570,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 349570022...
Checkpoint 349570022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,014.94083
Policy Entropy: 0.85623
Value Function Loss: 0.05906

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01834
Policy Update Magnitude: 0.02766
Value Function Update Magnitude: 0.04356

Collected Steps per Second: 22,600.02372
Overall Steps per Second: 16,561.24403

Timestep Collection Time: 2.21354
Timestep Consumption Time: 0.80713
PPO Batch Consumption Time: 0.05986
Total Iteration Time: 3.02067

Cumulative Model Updates: 20,939
Cumulative Timesteps: 349,620,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,718.51099
Policy Entropy: 0.86848
Value Function Loss: 0.05721

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01721
Policy Update Magnitude: 0.02673
Value Function Update Magnitude: 0.05592

Collected Steps per Second: 20,366.68751
Overall Steps per Second: 14,895.79185

Timestep Collection Time: 2.45587
Timestep Consumption Time: 0.90199
PPO Batch Consumption Time: 0.08240
Total Iteration Time: 3.35786

Cumulative Model Updates: 20,942
Cumulative Timesteps: 349,670,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 349670066...
Checkpoint 349670066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,980.17098
Policy Entropy: 0.84884
Value Function Loss: 0.06291

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01658
Policy Update Magnitude: 0.03256
Value Function Update Magnitude: 0.05810

Collected Steps per Second: 22,523.53576
Overall Steps per Second: 16,506.41970

Timestep Collection Time: 2.22061
Timestep Consumption Time: 0.80948
PPO Batch Consumption Time: 0.06081
Total Iteration Time: 3.03009

Cumulative Model Updates: 20,945
Cumulative Timesteps: 349,720,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,104.02171
Policy Entropy: 0.84171
Value Function Loss: 0.06092

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02199
Policy Update Magnitude: 0.03290
Value Function Update Magnitude: 0.05986

Collected Steps per Second: 20,996.53265
Overall Steps per Second: 14,976.78616

Timestep Collection Time: 2.38335
Timestep Consumption Time: 0.95796
PPO Batch Consumption Time: 0.09920
Total Iteration Time: 3.34130

Cumulative Model Updates: 20,948
Cumulative Timesteps: 349,770,124

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 349770124...
Checkpoint 349770124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,966.99668
Policy Entropy: 0.85044
Value Function Loss: 0.05867

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02347
Policy Update Magnitude: 0.03214
Value Function Update Magnitude: 0.05873

Collected Steps per Second: 22,309.69671
Overall Steps per Second: 16,398.01897

Timestep Collection Time: 2.24225
Timestep Consumption Time: 0.80836
PPO Batch Consumption Time: 0.06281
Total Iteration Time: 3.05061

Cumulative Model Updates: 20,951
Cumulative Timesteps: 349,820,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,922.98804
Policy Entropy: 0.85307
Value Function Loss: 0.05839

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01974
Policy Update Magnitude: 0.03077
Value Function Update Magnitude: 0.06063

Collected Steps per Second: 22,333.51958
Overall Steps per Second: 16,473.63683

Timestep Collection Time: 2.23879
Timestep Consumption Time: 0.79637
PPO Batch Consumption Time: 0.05995
Total Iteration Time: 3.03515

Cumulative Model Updates: 20,954
Cumulative Timesteps: 349,870,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 349870148...
Checkpoint 349870148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,603.38571
Policy Entropy: 0.85301
Value Function Loss: 0.06222

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02885
Policy Update Magnitude: 0.03015
Value Function Update Magnitude: 0.06121

Collected Steps per Second: 22,227.40909
Overall Steps per Second: 16,415.89956

Timestep Collection Time: 2.25055
Timestep Consumption Time: 0.79673
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 3.04729

Cumulative Model Updates: 20,957
Cumulative Timesteps: 349,920,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,193.31951
Policy Entropy: 0.84022
Value Function Loss: 0.06479

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01289
Policy Update Magnitude: 0.03092
Value Function Update Magnitude: 0.06025

Collected Steps per Second: 20,416.37322
Overall Steps per Second: 14,655.37618

Timestep Collection Time: 2.45048
Timestep Consumption Time: 0.96328
PPO Batch Consumption Time: 0.10358
Total Iteration Time: 3.41376

Cumulative Model Updates: 20,960
Cumulative Timesteps: 349,970,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 349970202...
Checkpoint 349970202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,396.60721
Policy Entropy: 0.84059
Value Function Loss: 0.06491

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01547
Policy Update Magnitude: 0.03127
Value Function Update Magnitude: 0.06098

Collected Steps per Second: 22,268.37095
Overall Steps per Second: 16,366.24319

Timestep Collection Time: 2.24650
Timestep Consumption Time: 0.81015
PPO Batch Consumption Time: 0.06161
Total Iteration Time: 3.05666

Cumulative Model Updates: 20,963
Cumulative Timesteps: 350,020,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,604.92674
Policy Entropy: 0.82348
Value Function Loss: 0.07045

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02189
Policy Update Magnitude: 0.03263
Value Function Update Magnitude: 0.06576

Collected Steps per Second: 22,567.05024
Overall Steps per Second: 16,718.44360

Timestep Collection Time: 2.21651
Timestep Consumption Time: 0.77540
PPO Batch Consumption Time: 0.06017
Total Iteration Time: 2.99191

Cumulative Model Updates: 20,966
Cumulative Timesteps: 350,070,248

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 350070248...
Checkpoint 350070248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,153.67373
Policy Entropy: 0.83281
Value Function Loss: 0.07583

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02445
Policy Update Magnitude: 0.03552
Value Function Update Magnitude: 0.07316

Collected Steps per Second: 21,391.51529
Overall Steps per Second: 15,140.22372

Timestep Collection Time: 2.33784
Timestep Consumption Time: 0.96528
PPO Batch Consumption Time: 0.10587
Total Iteration Time: 3.30312

Cumulative Model Updates: 20,969
Cumulative Timesteps: 350,120,258

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,426.99258
Policy Entropy: 0.82629
Value Function Loss: 0.07151

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03965
Policy Update Magnitude: 0.03452
Value Function Update Magnitude: 0.07137

Collected Steps per Second: 22,426.05404
Overall Steps per Second: 16,519.94420

Timestep Collection Time: 2.23008
Timestep Consumption Time: 0.79729
PPO Batch Consumption Time: 0.05857
Total Iteration Time: 3.02737

Cumulative Model Updates: 20,972
Cumulative Timesteps: 350,170,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 350170270...
Checkpoint 350170270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,303.28394
Policy Entropy: 0.84617
Value Function Loss: 0.06181

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04263
Policy Update Magnitude: 0.03447
Value Function Update Magnitude: 0.06642

Collected Steps per Second: 19,937.71209
Overall Steps per Second: 14,167.64946

Timestep Collection Time: 2.50851
Timestep Consumption Time: 1.02164
PPO Batch Consumption Time: 0.12111
Total Iteration Time: 3.53016

Cumulative Model Updates: 20,975
Cumulative Timesteps: 350,220,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,500.98210
Policy Entropy: 0.84204
Value Function Loss: 0.05909

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04212
Policy Update Magnitude: 0.03425
Value Function Update Magnitude: 0.06598

Collected Steps per Second: 23,102.51684
Overall Steps per Second: 16,934.92719

Timestep Collection Time: 2.16444
Timestep Consumption Time: 0.78827
PPO Batch Consumption Time: 0.05788
Total Iteration Time: 2.95271

Cumulative Model Updates: 20,978
Cumulative Timesteps: 350,270,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 350270288...
Checkpoint 350270288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,041.23988
Policy Entropy: 0.84176
Value Function Loss: 0.06936

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04992
Policy Update Magnitude: 0.03097
Value Function Update Magnitude: 0.06620

Collected Steps per Second: 21,029.48176
Overall Steps per Second: 15,421.58404

Timestep Collection Time: 2.37838
Timestep Consumption Time: 0.86487
PPO Batch Consumption Time: 0.07602
Total Iteration Time: 3.24325

Cumulative Model Updates: 20,981
Cumulative Timesteps: 350,320,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,175.26195
Policy Entropy: 0.82819
Value Function Loss: 0.07389

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03392
Policy Update Magnitude: 0.03111
Value Function Update Magnitude: 0.06701

Collected Steps per Second: 22,103.48901
Overall Steps per Second: 16,375.33930

Timestep Collection Time: 2.26326
Timestep Consumption Time: 0.79170
PPO Batch Consumption Time: 0.06518
Total Iteration Time: 3.05496

Cumulative Model Updates: 20,984
Cumulative Timesteps: 350,370,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 350370330...
Checkpoint 350370330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,263.35808
Policy Entropy: 0.82774
Value Function Loss: 0.07901

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03375
Policy Update Magnitude: 0.03247
Value Function Update Magnitude: 0.06433

Collected Steps per Second: 21,481.38227
Overall Steps per Second: 15,091.00763

Timestep Collection Time: 2.32862
Timestep Consumption Time: 0.98607
PPO Batch Consumption Time: 0.11155
Total Iteration Time: 3.31469

Cumulative Model Updates: 20,987
Cumulative Timesteps: 350,420,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,362.82288
Policy Entropy: 0.82310
Value Function Loss: 0.07438

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04289
Policy Update Magnitude: 0.03122
Value Function Update Magnitude: 0.05877

Collected Steps per Second: 22,524.55772
Overall Steps per Second: 16,686.12904

Timestep Collection Time: 2.22104
Timestep Consumption Time: 0.77714
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 2.99818

Cumulative Model Updates: 20,990
Cumulative Timesteps: 350,470,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 350470380...
Checkpoint 350470380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,134.93612
Policy Entropy: 0.83413
Value Function Loss: 0.06993

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03429
Policy Update Magnitude: 0.03024
Value Function Update Magnitude: 0.06573

Collected Steps per Second: 20,226.37763
Overall Steps per Second: 14,882.76248

Timestep Collection Time: 2.47410
Timestep Consumption Time: 0.88832
PPO Batch Consumption Time: 0.08370
Total Iteration Time: 3.36241

Cumulative Model Updates: 20,993
Cumulative Timesteps: 350,520,422

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,147.58201
Policy Entropy: 0.83032
Value Function Loss: 0.05712

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03205
Policy Update Magnitude: 0.03019
Value Function Update Magnitude: 0.06219

Collected Steps per Second: 22,903.15981
Overall Steps per Second: 16,748.67943

Timestep Collection Time: 2.18389
Timestep Consumption Time: 0.80249
PPO Batch Consumption Time: 0.05894
Total Iteration Time: 2.98638

Cumulative Model Updates: 20,996
Cumulative Timesteps: 350,570,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 350570440...
Checkpoint 350570440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,762.39978
Policy Entropy: 0.83941
Value Function Loss: 0.05451

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.02912
Value Function Update Magnitude: 0.05206

Collected Steps per Second: 19,419.79990
Overall Steps per Second: 13,971.71970

Timestep Collection Time: 2.57572
Timestep Consumption Time: 1.00437
PPO Batch Consumption Time: 0.10056
Total Iteration Time: 3.58009

Cumulative Model Updates: 20,999
Cumulative Timesteps: 350,620,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,174.72113
Policy Entropy: 0.83065
Value Function Loss: 0.05038

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.02986
Value Function Update Magnitude: 0.04355

Collected Steps per Second: 22,819.55173
Overall Steps per Second: 16,914.64579

Timestep Collection Time: 2.19207
Timestep Consumption Time: 0.76525
PPO Batch Consumption Time: 0.05393
Total Iteration Time: 2.95732

Cumulative Model Updates: 21,002
Cumulative Timesteps: 350,670,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 350670482...
Checkpoint 350670482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,660.46482
Policy Entropy: 0.83122
Value Function Loss: 0.05640

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01637
Policy Update Magnitude: 0.02983
Value Function Update Magnitude: 0.03786

Collected Steps per Second: 20,619.79944
Overall Steps per Second: 14,652.87230

Timestep Collection Time: 2.42563
Timestep Consumption Time: 0.98776
PPO Batch Consumption Time: 0.11373
Total Iteration Time: 3.41339

Cumulative Model Updates: 21,005
Cumulative Timesteps: 350,720,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,929.55584
Policy Entropy: 0.82678
Value Function Loss: 0.05323

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02217
Policy Update Magnitude: 0.02776
Value Function Update Magnitude: 0.04127

Collected Steps per Second: 22,489.63730
Overall Steps per Second: 16,448.79302

Timestep Collection Time: 2.22334
Timestep Consumption Time: 0.81652
PPO Batch Consumption Time: 0.06224
Total Iteration Time: 3.03986

Cumulative Model Updates: 21,008
Cumulative Timesteps: 350,770,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 350770500...
Checkpoint 350770500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,228.34054
Policy Entropy: 0.83497
Value Function Loss: 0.05644

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02809
Policy Update Magnitude: 0.02707
Value Function Update Magnitude: 0.04094

Collected Steps per Second: 19,755.74904
Overall Steps per Second: 14,140.70799

Timestep Collection Time: 2.53162
Timestep Consumption Time: 1.00526
PPO Batch Consumption Time: 0.11214
Total Iteration Time: 3.53688

Cumulative Model Updates: 21,011
Cumulative Timesteps: 350,820,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,790.62829
Policy Entropy: 0.81652
Value Function Loss: 0.06034

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02998
Policy Update Magnitude: 0.03156
Value Function Update Magnitude: 0.04663

Collected Steps per Second: 22,427.73909
Overall Steps per Second: 16,538.95790

Timestep Collection Time: 2.23045
Timestep Consumption Time: 0.79416
PPO Batch Consumption Time: 0.06229
Total Iteration Time: 3.02462

Cumulative Model Updates: 21,014
Cumulative Timesteps: 350,870,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 350870538...
Checkpoint 350870538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,484.02431
Policy Entropy: 0.80882
Value Function Loss: 0.06661

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03293
Policy Update Magnitude: 0.03397
Value Function Update Magnitude: 0.04479

Collected Steps per Second: 19,790.41661
Overall Steps per Second: 14,148.25206

Timestep Collection Time: 2.52688
Timestep Consumption Time: 1.00769
PPO Batch Consumption Time: 0.12090
Total Iteration Time: 3.53457

Cumulative Model Updates: 21,017
Cumulative Timesteps: 350,920,546

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,841.60662
Policy Entropy: 0.79987
Value Function Loss: 0.06923

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03867
Policy Update Magnitude: 0.03253
Value Function Update Magnitude: 0.05298

Collected Steps per Second: 22,716.35728
Overall Steps per Second: 16,744.93207

Timestep Collection Time: 2.20247
Timestep Consumption Time: 0.78542
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 2.98789

Cumulative Model Updates: 21,020
Cumulative Timesteps: 350,970,578

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 350970578...
Checkpoint 350970578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,638.88139
Policy Entropy: 0.81428
Value Function Loss: 0.06465

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02323
Policy Update Magnitude: 0.03394
Value Function Update Magnitude: 0.05421

Collected Steps per Second: 20,429.82956
Overall Steps per Second: 14,720.55755

Timestep Collection Time: 2.44789
Timestep Consumption Time: 0.94940
PPO Batch Consumption Time: 0.09830
Total Iteration Time: 3.39729

Cumulative Model Updates: 21,023
Cumulative Timesteps: 351,020,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,604.74092
Policy Entropy: 0.81243
Value Function Loss: 0.05676

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03803
Policy Update Magnitude: 0.03415
Value Function Update Magnitude: 0.05304

Collected Steps per Second: 22,455.39300
Overall Steps per Second: 16,523.44978

Timestep Collection Time: 2.22690
Timestep Consumption Time: 0.79946
PPO Batch Consumption Time: 0.05851
Total Iteration Time: 3.02637

Cumulative Model Updates: 21,026
Cumulative Timesteps: 351,070,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 351070594...
Checkpoint 351070594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,293.46072
Policy Entropy: 0.81316
Value Function Loss: 0.05396

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04195
Policy Update Magnitude: 0.03410
Value Function Update Magnitude: 0.04745

Collected Steps per Second: 20,328.32938
Overall Steps per Second: 14,777.92509

Timestep Collection Time: 2.46090
Timestep Consumption Time: 0.92428
PPO Batch Consumption Time: 0.08682
Total Iteration Time: 3.38518

Cumulative Model Updates: 21,029
Cumulative Timesteps: 351,120,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,722.29015
Policy Entropy: 0.81505
Value Function Loss: 0.04670

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04617
Policy Update Magnitude: 0.03058
Value Function Update Magnitude: 0.04150

Collected Steps per Second: 22,084.20478
Overall Steps per Second: 16,241.48991

Timestep Collection Time: 2.26406
Timestep Consumption Time: 0.81447
PPO Batch Consumption Time: 0.06233
Total Iteration Time: 3.07854

Cumulative Model Updates: 21,032
Cumulative Timesteps: 351,170,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 351170620...
Checkpoint 351170620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,196.06589
Policy Entropy: 0.81917
Value Function Loss: 0.04963

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.04001
Policy Update Magnitude: 0.02933
Value Function Update Magnitude: 0.04212

Collected Steps per Second: 22,334.20478
Overall Steps per Second: 16,484.16141

Timestep Collection Time: 2.23979
Timestep Consumption Time: 0.79488
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 3.03467

Cumulative Model Updates: 21,035
Cumulative Timesteps: 351,220,644

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,275.87792
Policy Entropy: 0.81237
Value Function Loss: 0.05012

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04629
Policy Update Magnitude: 0.03139
Value Function Update Magnitude: 0.03989

Collected Steps per Second: 20,008.63216
Overall Steps per Second: 14,617.97477

Timestep Collection Time: 2.49972
Timestep Consumption Time: 0.92182
PPO Batch Consumption Time: 0.08999
Total Iteration Time: 3.42154

Cumulative Model Updates: 21,038
Cumulative Timesteps: 351,270,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 351270660...
Checkpoint 351270660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,356.17697
Policy Entropy: 0.80957
Value Function Loss: 0.06394

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04429
Policy Update Magnitude: 0.03241
Value Function Update Magnitude: 0.04434

Collected Steps per Second: 22,647.26199
Overall Steps per Second: 16,663.23583

Timestep Collection Time: 2.20857
Timestep Consumption Time: 0.79313
PPO Batch Consumption Time: 0.06162
Total Iteration Time: 3.00170

Cumulative Model Updates: 21,041
Cumulative Timesteps: 351,320,678

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,475.48512
Policy Entropy: 0.80689
Value Function Loss: 0.06377

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05606
Policy Update Magnitude: 0.02976
Value Function Update Magnitude: 0.04507

Collected Steps per Second: 20,884.59059
Overall Steps per Second: 14,864.03627

Timestep Collection Time: 2.39507
Timestep Consumption Time: 0.97010
PPO Batch Consumption Time: 0.09886
Total Iteration Time: 3.36517

Cumulative Model Updates: 21,044
Cumulative Timesteps: 351,370,698

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 351370698...
Checkpoint 351370698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,465.18560
Policy Entropy: 0.80187
Value Function Loss: 0.06498

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03197
Policy Update Magnitude: 0.03310
Value Function Update Magnitude: 0.04898

Collected Steps per Second: 22,223.23800
Overall Steps per Second: 16,366.04083

Timestep Collection Time: 2.25116
Timestep Consumption Time: 0.80566
PPO Batch Consumption Time: 0.06244
Total Iteration Time: 3.05682

Cumulative Model Updates: 21,047
Cumulative Timesteps: 351,420,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,325.87019
Policy Entropy: 0.79501
Value Function Loss: 0.06447

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03773
Policy Update Magnitude: 0.03336
Value Function Update Magnitude: 0.05634

Collected Steps per Second: 21,260.12882
Overall Steps per Second: 15,056.83513

Timestep Collection Time: 2.35314
Timestep Consumption Time: 0.96947
PPO Batch Consumption Time: 0.11413
Total Iteration Time: 3.32261

Cumulative Model Updates: 21,050
Cumulative Timesteps: 351,470,754

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 351470754...
Checkpoint 351470754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,549.17569
Policy Entropy: 0.79645
Value Function Loss: 0.06383

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03497
Policy Update Magnitude: 0.03648
Value Function Update Magnitude: 0.05501

Collected Steps per Second: 22,396.40053
Overall Steps per Second: 16,548.57740

Timestep Collection Time: 2.23322
Timestep Consumption Time: 0.78916
PPO Batch Consumption Time: 0.05781
Total Iteration Time: 3.02237

Cumulative Model Updates: 21,053
Cumulative Timesteps: 351,520,770

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,673.54997
Policy Entropy: 0.78751
Value Function Loss: 0.06820

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05503
Policy Update Magnitude: 0.03562
Value Function Update Magnitude: 0.05046

Collected Steps per Second: 20,469.19161
Overall Steps per Second: 14,909.88887

Timestep Collection Time: 2.44406
Timestep Consumption Time: 0.91129
PPO Batch Consumption Time: 0.09015
Total Iteration Time: 3.35536

Cumulative Model Updates: 21,056
Cumulative Timesteps: 351,570,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 351570798...
Checkpoint 351570798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,960.35884
Policy Entropy: 0.79409
Value Function Loss: 0.06509

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05970
Policy Update Magnitude: 0.03227
Value Function Update Magnitude: 0.04723

Collected Steps per Second: 22,206.58760
Overall Steps per Second: 16,351.58083

Timestep Collection Time: 2.25212
Timestep Consumption Time: 0.80642
PPO Batch Consumption Time: 0.06065
Total Iteration Time: 3.05854

Cumulative Model Updates: 21,059
Cumulative Timesteps: 351,620,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,504.94038
Policy Entropy: 0.79861
Value Function Loss: 0.06342

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.03145
Value Function Update Magnitude: 0.04901

Collected Steps per Second: 21,705.64362
Overall Steps per Second: 15,101.29686

Timestep Collection Time: 2.30493
Timestep Consumption Time: 1.00803
PPO Batch Consumption Time: 0.11715
Total Iteration Time: 3.31296

Cumulative Model Updates: 21,062
Cumulative Timesteps: 351,670,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 351670840...
Checkpoint 351670840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,804.56425
Policy Entropy: 0.78866
Value Function Loss: 0.06418

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.02863
Value Function Update Magnitude: 0.05111

Collected Steps per Second: 22,395.58732
Overall Steps per Second: 16,567.61109

Timestep Collection Time: 2.23356
Timestep Consumption Time: 0.78570
PPO Batch Consumption Time: 0.06129
Total Iteration Time: 3.01926

Cumulative Model Updates: 21,065
Cumulative Timesteps: 351,720,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,734.28358
Policy Entropy: 0.77676
Value Function Loss: 0.06839

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.03433
Value Function Update Magnitude: 0.06067

Collected Steps per Second: 20,486.68914
Overall Steps per Second: 14,868.73631

Timestep Collection Time: 2.44100
Timestep Consumption Time: 0.92230
PPO Batch Consumption Time: 0.08952
Total Iteration Time: 3.36330

Cumulative Model Updates: 21,068
Cumulative Timesteps: 351,770,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 351770870...
Checkpoint 351770870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,261.84110
Policy Entropy: 0.77141
Value Function Loss: 0.07448

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03213
Policy Update Magnitude: 0.04386
Value Function Update Magnitude: 0.07214

Collected Steps per Second: 22,607.51855
Overall Steps per Second: 16,606.45461

Timestep Collection Time: 2.21325
Timestep Consumption Time: 0.79980
PPO Batch Consumption Time: 0.06179
Total Iteration Time: 3.01305

Cumulative Model Updates: 21,071
Cumulative Timesteps: 351,820,906

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,760.85899
Policy Entropy: 0.77532
Value Function Loss: 0.07562

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02247
Policy Update Magnitude: 0.04003
Value Function Update Magnitude: 0.07292

Collected Steps per Second: 20,302.00552
Overall Steps per Second: 14,867.15843

Timestep Collection Time: 2.46380
Timestep Consumption Time: 0.90067
PPO Batch Consumption Time: 0.08599
Total Iteration Time: 3.36446

Cumulative Model Updates: 21,074
Cumulative Timesteps: 351,870,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 351870926...
Checkpoint 351870926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,505.05855
Policy Entropy: 0.78959
Value Function Loss: 0.06702

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03797
Policy Update Magnitude: 0.03980
Value Function Update Magnitude: 0.07887

Collected Steps per Second: 21,440.59405
Overall Steps per Second: 16,420.85908

Timestep Collection Time: 2.33417
Timestep Consumption Time: 0.71354
PPO Batch Consumption Time: 0.06210
Total Iteration Time: 3.04771

Cumulative Model Updates: 21,077
Cumulative Timesteps: 351,920,972

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,187.66924
Policy Entropy: 0.78909
Value Function Loss: 0.06672

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04409
Policy Update Magnitude: 0.04004
Value Function Update Magnitude: 0.06928

Collected Steps per Second: 20,540.70650
Overall Steps per Second: 15,074.06018

Timestep Collection Time: 2.43497
Timestep Consumption Time: 0.88305
PPO Batch Consumption Time: 0.11133
Total Iteration Time: 3.31802

Cumulative Model Updates: 21,080
Cumulative Timesteps: 351,970,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 351970988...
Checkpoint 351970988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,643.97606
Policy Entropy: 0.79951
Value Function Loss: 0.06045

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06646
Policy Update Magnitude: 0.03391
Value Function Update Magnitude: 0.07215

Collected Steps per Second: 21,438.64487
Overall Steps per Second: 16,416.68900

Timestep Collection Time: 2.33280
Timestep Consumption Time: 0.71362
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 3.04641

Cumulative Model Updates: 21,083
Cumulative Timesteps: 352,021,000

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,302.08471
Policy Entropy: 0.79589
Value Function Loss: 0.06802

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03836
Policy Update Magnitude: 0.03249
Value Function Update Magnitude: 0.07337

Collected Steps per Second: 20,531.48686
Overall Steps per Second: 15,024.61373

Timestep Collection Time: 2.43675
Timestep Consumption Time: 0.89312
PPO Batch Consumption Time: 0.10585
Total Iteration Time: 3.32987

Cumulative Model Updates: 21,086
Cumulative Timesteps: 352,071,030

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 352071030...
Checkpoint 352071030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,033.85545
Policy Entropy: 0.79470
Value Function Loss: 0.07390

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05653
Policy Update Magnitude: 0.03472
Value Function Update Magnitude: 0.06820

Collected Steps per Second: 21,604.36847
Overall Steps per Second: 16,467.45711

Timestep Collection Time: 2.31453
Timestep Consumption Time: 0.72200
PPO Batch Consumption Time: 0.06066
Total Iteration Time: 3.03653

Cumulative Model Updates: 21,089
Cumulative Timesteps: 352,121,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,420.33795
Policy Entropy: 0.78474
Value Function Loss: 0.07416

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02995
Policy Update Magnitude: 0.03598
Value Function Update Magnitude: 0.05873

Collected Steps per Second: 19,765.82684
Overall Steps per Second: 14,948.99252

Timestep Collection Time: 2.53053
Timestep Consumption Time: 0.81538
PPO Batch Consumption Time: 0.08451
Total Iteration Time: 3.34591

Cumulative Model Updates: 21,092
Cumulative Timesteps: 352,171,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 352171052...
Checkpoint 352171052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,677.08156
Policy Entropy: 0.79183
Value Function Loss: 0.07489

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02584
Policy Update Magnitude: 0.03364
Value Function Update Magnitude: 0.05372

Collected Steps per Second: 21,526.24669
Overall Steps per Second: 16,225.04190

Timestep Collection Time: 2.32423
Timestep Consumption Time: 0.75940
PPO Batch Consumption Time: 0.06342
Total Iteration Time: 3.08363

Cumulative Model Updates: 21,095
Cumulative Timesteps: 352,221,084

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,640.67076
Policy Entropy: 0.80278
Value Function Loss: 0.06944

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03037
Policy Update Magnitude: 0.03281
Value Function Update Magnitude: 0.05420

Collected Steps per Second: 21,701.44896
Overall Steps per Second: 16,556.91509

Timestep Collection Time: 2.30473
Timestep Consumption Time: 0.71612
PPO Batch Consumption Time: 0.05832
Total Iteration Time: 3.02085

Cumulative Model Updates: 21,098
Cumulative Timesteps: 352,271,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 352271100...
Checkpoint 352271100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,512.24882
Policy Entropy: 0.81785
Value Function Loss: 0.06840

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02789
Policy Update Magnitude: 0.03435
Value Function Update Magnitude: 0.05016

Collected Steps per Second: 21,752.58261
Overall Steps per Second: 16,640.54461

Timestep Collection Time: 2.29977
Timestep Consumption Time: 0.70650
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 3.00627

Cumulative Model Updates: 21,101
Cumulative Timesteps: 352,321,126

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,238.98003
Policy Entropy: 0.83020
Value Function Loss: 0.06186

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02630
Policy Update Magnitude: 0.03182
Value Function Update Magnitude: 0.05471

Collected Steps per Second: 19,805.69964
Overall Steps per Second: 14,526.35491

Timestep Collection Time: 2.52513
Timestep Consumption Time: 0.91771
PPO Batch Consumption Time: 0.09092
Total Iteration Time: 3.44285

Cumulative Model Updates: 21,104
Cumulative Timesteps: 352,371,138

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 352371138...
Checkpoint 352371138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,020.75452
Policy Entropy: 0.81710
Value Function Loss: 0.06540

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01769
Policy Update Magnitude: 0.03395
Value Function Update Magnitude: 0.05432

Collected Steps per Second: 22,141.65996
Overall Steps per Second: 16,544.34884

Timestep Collection Time: 2.25882
Timestep Consumption Time: 0.76421
PPO Batch Consumption Time: 0.06339
Total Iteration Time: 3.02303

Cumulative Model Updates: 21,107
Cumulative Timesteps: 352,421,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,492.02363
Policy Entropy: 0.82664
Value Function Loss: 0.07371

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01923
Policy Update Magnitude: 0.03356
Value Function Update Magnitude: 0.04728

Collected Steps per Second: 20,684.61440
Overall Steps per Second: 14,946.50839

Timestep Collection Time: 2.41726
Timestep Consumption Time: 0.92801
PPO Batch Consumption Time: 0.09647
Total Iteration Time: 3.34526

Cumulative Model Updates: 21,110
Cumulative Timesteps: 352,471,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 352471152...
Checkpoint 352471152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,447.45712
Policy Entropy: 0.83122
Value Function Loss: 0.07342

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02367
Policy Update Magnitude: 0.03508
Value Function Update Magnitude: 0.04056

Collected Steps per Second: 22,475.90447
Overall Steps per Second: 16,749.11725

Timestep Collection Time: 2.22505
Timestep Consumption Time: 0.76078
PPO Batch Consumption Time: 0.05792
Total Iteration Time: 2.98583

Cumulative Model Updates: 21,113
Cumulative Timesteps: 352,521,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,304.78567
Policy Entropy: 0.83714
Value Function Loss: 0.07316

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03131
Policy Update Magnitude: 0.03423
Value Function Update Magnitude: 0.04196

Collected Steps per Second: 20,213.26465
Overall Steps per Second: 14,765.60488

Timestep Collection Time: 2.47521
Timestep Consumption Time: 0.91321
PPO Batch Consumption Time: 0.10159
Total Iteration Time: 3.38842

Cumulative Model Updates: 21,116
Cumulative Timesteps: 352,571,194

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 352571194...
Checkpoint 352571194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,180.69391
Policy Entropy: 0.84892
Value Function Loss: 0.06835

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02560
Policy Update Magnitude: 0.03182
Value Function Update Magnitude: 0.03831

Collected Steps per Second: 22,225.31364
Overall Steps per Second: 16,415.95400

Timestep Collection Time: 2.24996
Timestep Consumption Time: 0.79623
PPO Batch Consumption Time: 0.06093
Total Iteration Time: 3.04618

Cumulative Model Updates: 21,119
Cumulative Timesteps: 352,621,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,994.85867
Policy Entropy: 0.85589
Value Function Loss: 0.06155

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04153
Policy Update Magnitude: 0.03194
Value Function Update Magnitude: 0.03876

Collected Steps per Second: 20,575.66448
Overall Steps per Second: 15,028.10860

Timestep Collection Time: 2.43103
Timestep Consumption Time: 0.89740
PPO Batch Consumption Time: 0.08427
Total Iteration Time: 3.32843

Cumulative Model Updates: 21,122
Cumulative Timesteps: 352,671,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 352671220...
Checkpoint 352671220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,934.55404
Policy Entropy: 0.85961
Value Function Loss: 0.06353

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03361
Policy Update Magnitude: 0.03363
Value Function Update Magnitude: 0.03300

Collected Steps per Second: 21,949.74621
Overall Steps per Second: 16,263.48009

Timestep Collection Time: 2.27811
Timestep Consumption Time: 0.79651
PPO Batch Consumption Time: 0.05843
Total Iteration Time: 3.07462

Cumulative Model Updates: 21,125
Cumulative Timesteps: 352,721,224

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,646.32988
Policy Entropy: 0.84633
Value Function Loss: 0.06831

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02801
Policy Update Magnitude: 0.03328
Value Function Update Magnitude: 0.02992

Collected Steps per Second: 22,630.99087
Overall Steps per Second: 16,578.63320

Timestep Collection Time: 2.21086
Timestep Consumption Time: 0.80712
PPO Batch Consumption Time: 0.06127
Total Iteration Time: 3.01798

Cumulative Model Updates: 21,128
Cumulative Timesteps: 352,771,258

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 352771258...
Checkpoint 352771258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,437.39047
Policy Entropy: 0.84984
Value Function Loss: 0.07260

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01577
Policy Update Magnitude: 0.03321
Value Function Update Magnitude: 0.02751

Collected Steps per Second: 22,100.55700
Overall Steps per Second: 16,486.97638

Timestep Collection Time: 2.26275
Timestep Consumption Time: 0.77043
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 3.03318

Cumulative Model Updates: 21,131
Cumulative Timesteps: 352,821,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,074.38812
Policy Entropy: 0.85401
Value Function Loss: 0.06648

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02716
Policy Update Magnitude: 0.03335
Value Function Update Magnitude: 0.02771

Collected Steps per Second: 20,859.13538
Overall Steps per Second: 14,702.67002

Timestep Collection Time: 2.39847
Timestep Consumption Time: 1.00431
PPO Batch Consumption Time: 0.11980
Total Iteration Time: 3.40278

Cumulative Model Updates: 21,134
Cumulative Timesteps: 352,871,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 352871296...
Checkpoint 352871296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,247.71088
Policy Entropy: 0.85903
Value Function Loss: 0.06757

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01599
Policy Update Magnitude: 0.03134
Value Function Update Magnitude: 0.02927

Collected Steps per Second: 22,797.60926
Overall Steps per Second: 16,726.77989

Timestep Collection Time: 2.19435
Timestep Consumption Time: 0.79642
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 2.99077

Cumulative Model Updates: 21,137
Cumulative Timesteps: 352,921,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,577.15442
Policy Entropy: 0.85404
Value Function Loss: 0.06678

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02167
Policy Update Magnitude: 0.03562
Value Function Update Magnitude: 0.03044

Collected Steps per Second: 21,001.61578
Overall Steps per Second: 14,771.24370

Timestep Collection Time: 2.38201
Timestep Consumption Time: 1.00471
PPO Batch Consumption Time: 0.11970
Total Iteration Time: 3.38672

Cumulative Model Updates: 21,140
Cumulative Timesteps: 352,971,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 352971348...
Checkpoint 352971348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,330.54224
Policy Entropy: 0.84922
Value Function Loss: 0.07754

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02271
Policy Update Magnitude: 0.04062
Value Function Update Magnitude: 0.02931

Collected Steps per Second: 22,390.55712
Overall Steps per Second: 16,558.59506

Timestep Collection Time: 2.23335
Timestep Consumption Time: 0.78659
PPO Batch Consumption Time: 0.05864
Total Iteration Time: 3.01994

Cumulative Model Updates: 21,143
Cumulative Timesteps: 353,021,354

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,995.20842
Policy Entropy: 0.84239
Value Function Loss: 0.07175

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03243
Policy Update Magnitude: 0.03707
Value Function Update Magnitude: 0.03319

Collected Steps per Second: 20,205.68894
Overall Steps per Second: 14,630.75934

Timestep Collection Time: 2.47574
Timestep Consumption Time: 0.94336
PPO Batch Consumption Time: 0.08734
Total Iteration Time: 3.41910

Cumulative Model Updates: 21,146
Cumulative Timesteps: 353,071,378

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 353071378...
Checkpoint 353071378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,242.78392
Policy Entropy: 0.84813
Value Function Loss: 0.06587

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.04130
Policy Update Magnitude: 0.03800
Value Function Update Magnitude: 0.03584

Collected Steps per Second: 22,462.88746
Overall Steps per Second: 16,489.66444

Timestep Collection Time: 2.22661
Timestep Consumption Time: 0.80657
PPO Batch Consumption Time: 0.05999
Total Iteration Time: 3.03317

Cumulative Model Updates: 21,149
Cumulative Timesteps: 353,121,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,249.63401
Policy Entropy: 0.84006
Value Function Loss: 0.05345

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03553
Policy Update Magnitude: 0.03665
Value Function Update Magnitude: 0.03529

Collected Steps per Second: 22,696.92439
Overall Steps per Second: 16,033.82766

Timestep Collection Time: 2.20470
Timestep Consumption Time: 0.91620
PPO Batch Consumption Time: 0.08132
Total Iteration Time: 3.12090

Cumulative Model Updates: 21,152
Cumulative Timesteps: 353,171,434

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 353171434...
Checkpoint 353171434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,573.39062
Policy Entropy: 0.85075
Value Function Loss: 0.05575

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04992
Policy Update Magnitude: 0.03797
Value Function Update Magnitude: 0.03793

Collected Steps per Second: 22,872.64509
Overall Steps per Second: 16,790.30636

Timestep Collection Time: 2.18689
Timestep Consumption Time: 0.79221
PPO Batch Consumption Time: 0.05893
Total Iteration Time: 2.97910

Cumulative Model Updates: 21,155
Cumulative Timesteps: 353,221,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,664.26611
Policy Entropy: 0.84667
Value Function Loss: 0.05898

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04889
Policy Update Magnitude: 0.03459
Value Function Update Magnitude: 0.03922

Collected Steps per Second: 20,682.44202
Overall Steps per Second: 14,837.24505

Timestep Collection Time: 2.41838
Timestep Consumption Time: 0.95273
PPO Batch Consumption Time: 0.09740
Total Iteration Time: 3.37111

Cumulative Model Updates: 21,158
Cumulative Timesteps: 353,271,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 353271472...
Checkpoint 353271472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,167.17634
Policy Entropy: 0.86868
Value Function Loss: 0.05710

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03064
Policy Update Magnitude: 0.03163
Value Function Update Magnitude: 0.03476

Collected Steps per Second: 22,278.12860
Overall Steps per Second: 16,422.31057

Timestep Collection Time: 2.24534
Timestep Consumption Time: 0.80064
PPO Batch Consumption Time: 0.06241
Total Iteration Time: 3.04598

Cumulative Model Updates: 21,161
Cumulative Timesteps: 353,321,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,171.75823
Policy Entropy: 0.85393
Value Function Loss: 0.05886

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04361
Policy Update Magnitude: 0.02920
Value Function Update Magnitude: 0.03443

Collected Steps per Second: 22,497.48822
Overall Steps per Second: 16,512.94378

Timestep Collection Time: 2.22452
Timestep Consumption Time: 0.80620
PPO Batch Consumption Time: 0.06094
Total Iteration Time: 3.03071

Cumulative Model Updates: 21,164
Cumulative Timesteps: 353,371,540

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 353371540...
Checkpoint 353371540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,628.29426
Policy Entropy: 0.84108
Value Function Loss: 0.05884

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03091
Policy Update Magnitude: 0.02886
Value Function Update Magnitude: 0.03325

Collected Steps per Second: 22,288.08800
Overall Steps per Second: 16,011.20496

Timestep Collection Time: 2.24362
Timestep Consumption Time: 0.87957
PPO Batch Consumption Time: 0.07955
Total Iteration Time: 3.12319

Cumulative Model Updates: 21,167
Cumulative Timesteps: 353,421,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,381.07559
Policy Entropy: 0.82418
Value Function Loss: 0.06361

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03923
Policy Update Magnitude: 0.03168
Value Function Update Magnitude: 0.03597

Collected Steps per Second: 22,712.61476
Overall Steps per Second: 16,577.23796

Timestep Collection Time: 2.20327
Timestep Consumption Time: 0.81545
PPO Batch Consumption Time: 0.06395
Total Iteration Time: 3.01872

Cumulative Model Updates: 21,170
Cumulative Timesteps: 353,471,588

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 353471588...
Checkpoint 353471588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,034.90837
Policy Entropy: 0.82022
Value Function Loss: 0.06304

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04079
Policy Update Magnitude: 0.02994
Value Function Update Magnitude: 0.03104

Collected Steps per Second: 22,198.51023
Overall Steps per Second: 16,392.26619

Timestep Collection Time: 2.25249
Timestep Consumption Time: 0.79785
PPO Batch Consumption Time: 0.05828
Total Iteration Time: 3.05034

Cumulative Model Updates: 21,173
Cumulative Timesteps: 353,521,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,405.33574
Policy Entropy: 0.81839
Value Function Loss: 0.06818

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04726
Policy Update Magnitude: 0.03114
Value Function Update Magnitude: 0.03214

Collected Steps per Second: 21,139.87269
Overall Steps per Second: 15,351.06672

Timestep Collection Time: 2.36605
Timestep Consumption Time: 0.89222
PPO Batch Consumption Time: 0.08230
Total Iteration Time: 3.25828

Cumulative Model Updates: 21,176
Cumulative Timesteps: 353,571,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 353571608...
Checkpoint 353571608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,917.57145
Policy Entropy: 0.81876
Value Function Loss: 0.06462

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02648
Policy Update Magnitude: 0.02956
Value Function Update Magnitude: 0.02840

Collected Steps per Second: 22,689.41286
Overall Steps per Second: 16,631.85408

Timestep Collection Time: 2.20508
Timestep Consumption Time: 0.80312
PPO Batch Consumption Time: 0.05772
Total Iteration Time: 3.00820

Cumulative Model Updates: 21,179
Cumulative Timesteps: 353,621,640

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,746.24932
Policy Entropy: 0.83894
Value Function Loss: 0.05897

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02891
Policy Update Magnitude: 0.03003
Value Function Update Magnitude: 0.02987

Collected Steps per Second: 20,387.21105
Overall Steps per Second: 14,904.95898

Timestep Collection Time: 2.45271
Timestep Consumption Time: 0.90214
PPO Batch Consumption Time: 0.08423
Total Iteration Time: 3.35486

Cumulative Model Updates: 21,182
Cumulative Timesteps: 353,671,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 353671644...
Checkpoint 353671644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,440.37413
Policy Entropy: 0.84010
Value Function Loss: 0.06510

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03807
Policy Update Magnitude: 0.03095
Value Function Update Magnitude: 0.02855

Collected Steps per Second: 22,474.97479
Overall Steps per Second: 16,528.75569

Timestep Collection Time: 2.22470
Timestep Consumption Time: 0.80033
PPO Batch Consumption Time: 0.06030
Total Iteration Time: 3.02503

Cumulative Model Updates: 21,185
Cumulative Timesteps: 353,721,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,355.87712
Policy Entropy: 0.84735
Value Function Loss: 0.06877

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06378
Policy Update Magnitude: 0.03193
Value Function Update Magnitude: 0.02804

Collected Steps per Second: 20,612.21060
Overall Steps per Second: 14,925.97010

Timestep Collection Time: 2.42604
Timestep Consumption Time: 0.92423
PPO Batch Consumption Time: 0.09688
Total Iteration Time: 3.35027

Cumulative Model Updates: 21,188
Cumulative Timesteps: 353,771,650

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 353771650...
Checkpoint 353771650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,798.79330
Policy Entropy: 0.83494
Value Function Loss: 0.07457

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.04417
Policy Update Magnitude: 0.02899
Value Function Update Magnitude: 0.03199

Collected Steps per Second: 22,268.35289
Overall Steps per Second: 16,336.63130

Timestep Collection Time: 2.24570
Timestep Consumption Time: 0.81540
PPO Batch Consumption Time: 0.06165
Total Iteration Time: 3.06110

Cumulative Model Updates: 21,191
Cumulative Timesteps: 353,821,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,876.57042
Policy Entropy: 0.82688
Value Function Loss: 0.06670

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03329
Policy Update Magnitude: 0.03112
Value Function Update Magnitude: 0.03095

Collected Steps per Second: 22,739.99019
Overall Steps per Second: 16,717.59021

Timestep Collection Time: 2.20009
Timestep Consumption Time: 0.79257
PPO Batch Consumption Time: 0.05999
Total Iteration Time: 2.99266

Cumulative Model Updates: 21,194
Cumulative Timesteps: 353,871,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 353871688...
Checkpoint 353871688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,472.10907
Policy Entropy: 0.82319
Value Function Loss: 0.07779

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.03115
Policy Update Magnitude: 0.03104
Value Function Update Magnitude: 0.04004

Collected Steps per Second: 22,310.99464
Overall Steps per Second: 16,412.71674

Timestep Collection Time: 2.24221
Timestep Consumption Time: 0.80579
PPO Batch Consumption Time: 0.05834
Total Iteration Time: 3.04800

Cumulative Model Updates: 21,197
Cumulative Timesteps: 353,921,714

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,891.95820
Policy Entropy: 0.82622
Value Function Loss: 0.08059

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.03118
Value Function Update Magnitude: 0.04282

Collected Steps per Second: 20,584.67389
Overall Steps per Second: 14,608.99938

Timestep Collection Time: 2.42948
Timestep Consumption Time: 0.99375
PPO Batch Consumption Time: 0.11478
Total Iteration Time: 3.42323

Cumulative Model Updates: 21,200
Cumulative Timesteps: 353,971,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 353971724...
Checkpoint 353971724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,022.36876
Policy Entropy: 0.83225
Value Function Loss: 0.08373

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01808
Policy Update Magnitude: 0.03313
Value Function Update Magnitude: 0.04516

Collected Steps per Second: 21,703.20901
Overall Steps per Second: 15,619.20418

Timestep Collection Time: 2.30473
Timestep Consumption Time: 0.89774
PPO Batch Consumption Time: 0.09522
Total Iteration Time: 3.20247

Cumulative Model Updates: 21,203
Cumulative Timesteps: 354,021,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,060.37105
Policy Entropy: 0.84008
Value Function Loss: 0.07980

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.05193
Policy Update Magnitude: 0.03544
Value Function Update Magnitude: 0.04626

Collected Steps per Second: 22,504.58398
Overall Steps per Second: 16,570.18946

Timestep Collection Time: 2.22230
Timestep Consumption Time: 0.79589
PPO Batch Consumption Time: 0.06033
Total Iteration Time: 3.01819

Cumulative Model Updates: 21,206
Cumulative Timesteps: 354,071,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 354071756...
Checkpoint 354071756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,016.69019
Policy Entropy: 0.84690
Value Function Loss: 0.07708

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04692
Policy Update Magnitude: 0.03490
Value Function Update Magnitude: 0.05388

Collected Steps per Second: 20,259.28860
Overall Steps per Second: 14,948.36560

Timestep Collection Time: 2.46929
Timestep Consumption Time: 0.87730
PPO Batch Consumption Time: 0.09116
Total Iteration Time: 3.34659

Cumulative Model Updates: 21,209
Cumulative Timesteps: 354,121,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,499.09708
Policy Entropy: 0.85014
Value Function Loss: 0.07173

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03532
Policy Update Magnitude: 0.03306
Value Function Update Magnitude: 0.04547

Collected Steps per Second: 22,869.21281
Overall Steps per Second: 16,980.12030

Timestep Collection Time: 2.18687
Timestep Consumption Time: 0.75846
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 2.94533

Cumulative Model Updates: 21,212
Cumulative Timesteps: 354,171,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 354171794...
Checkpoint 354171794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,902.89523
Policy Entropy: 0.84114
Value Function Loss: 0.07435

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06411
Policy Update Magnitude: 0.03402
Value Function Update Magnitude: 0.05208

Collected Steps per Second: 20,105.41277
Overall Steps per Second: 14,563.11089

Timestep Collection Time: 2.48848
Timestep Consumption Time: 0.94705
PPO Batch Consumption Time: 0.11130
Total Iteration Time: 3.43553

Cumulative Model Updates: 21,215
Cumulative Timesteps: 354,221,826

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,014.99480
Policy Entropy: 0.83197
Value Function Loss: 0.08013

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05285
Policy Update Magnitude: 0.03392
Value Function Update Magnitude: 0.05377

Collected Steps per Second: 22,672.78819
Overall Steps per Second: 16,953.28537

Timestep Collection Time: 2.20546
Timestep Consumption Time: 0.74405
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 2.94952

Cumulative Model Updates: 21,218
Cumulative Timesteps: 354,271,830

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 354271830...
Checkpoint 354271830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,030.99356
Policy Entropy: 0.81024
Value Function Loss: 0.08719

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07262
Policy Update Magnitude: 0.03544
Value Function Update Magnitude: 0.05799

Collected Steps per Second: 20,053.55259
Overall Steps per Second: 14,618.03785

Timestep Collection Time: 2.49392
Timestep Consumption Time: 0.92733
PPO Batch Consumption Time: 0.09282
Total Iteration Time: 3.42125

Cumulative Model Updates: 21,221
Cumulative Timesteps: 354,321,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,568.81022
Policy Entropy: 0.81182
Value Function Loss: 0.07944

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.03637
Value Function Update Magnitude: 0.05316

Collected Steps per Second: 22,563.76204
Overall Steps per Second: 16,511.58122

Timestep Collection Time: 2.21798
Timestep Consumption Time: 0.81298
PPO Batch Consumption Time: 0.06127
Total Iteration Time: 3.03096

Cumulative Model Updates: 21,224
Cumulative Timesteps: 354,371,888

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 354371888...
Checkpoint 354371888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,285.53487
Policy Entropy: 0.81510
Value Function Loss: 0.07173

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05467
Policy Update Magnitude: 0.03447
Value Function Update Magnitude: 0.05061

Collected Steps per Second: 20,118.95928
Overall Steps per Second: 14,211.96016

Timestep Collection Time: 2.48621
Timestep Consumption Time: 1.03336
PPO Batch Consumption Time: 0.12835
Total Iteration Time: 3.51957

Cumulative Model Updates: 21,227
Cumulative Timesteps: 354,421,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,045.94554
Policy Entropy: 0.81776
Value Function Loss: 0.05870

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06077
Policy Update Magnitude: 0.03354
Value Function Update Magnitude: 0.04592

Collected Steps per Second: 23,170.88547
Overall Steps per Second: 16,937.21094

Timestep Collection Time: 2.15892
Timestep Consumption Time: 0.79458
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 2.95350

Cumulative Model Updates: 21,230
Cumulative Timesteps: 354,471,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 354471932...
Checkpoint 354471932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,666.84497
Policy Entropy: 0.81410
Value Function Loss: 0.05819

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04294
Policy Update Magnitude: 0.03253
Value Function Update Magnitude: 0.04291

Collected Steps per Second: 20,941.49740
Overall Steps per Second: 15,193.88961

Timestep Collection Time: 2.38856
Timestep Consumption Time: 0.90355
PPO Batch Consumption Time: 0.08705
Total Iteration Time: 3.29211

Cumulative Model Updates: 21,233
Cumulative Timesteps: 354,521,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,481.88541
Policy Entropy: 0.80239
Value Function Loss: 0.06034

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06047
Policy Update Magnitude: 0.03193
Value Function Update Magnitude: 0.04866

Collected Steps per Second: 22,518.55265
Overall Steps per Second: 16,509.28597

Timestep Collection Time: 2.22226
Timestep Consumption Time: 0.80889
PPO Batch Consumption Time: 0.06257
Total Iteration Time: 3.03114

Cumulative Model Updates: 21,236
Cumulative Timesteps: 354,571,994

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 354571994...
Checkpoint 354571994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,876.26453
Policy Entropy: 0.80469
Value Function Loss: 0.06570

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05931
Policy Update Magnitude: 0.03173
Value Function Update Magnitude: 0.04886

Collected Steps per Second: 22,516.45865
Overall Steps per Second: 16,182.60636

Timestep Collection Time: 2.22184
Timestep Consumption Time: 0.86963
PPO Batch Consumption Time: 0.08344
Total Iteration Time: 3.09147

Cumulative Model Updates: 21,239
Cumulative Timesteps: 354,622,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,671.91500
Policy Entropy: 0.79958
Value Function Loss: 0.06678

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.05727
Policy Update Magnitude: 0.03260
Value Function Update Magnitude: 0.05062

Collected Steps per Second: 22,553.18017
Overall Steps per Second: 16,571.11510

Timestep Collection Time: 2.21760
Timestep Consumption Time: 0.80054
PPO Batch Consumption Time: 0.05778
Total Iteration Time: 3.01814

Cumulative Model Updates: 21,242
Cumulative Timesteps: 354,672,036

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 354672036...
Checkpoint 354672036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,236.97319
Policy Entropy: 0.80924
Value Function Loss: 0.06731

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06558
Policy Update Magnitude: 0.03202
Value Function Update Magnitude: 0.04943

Collected Steps per Second: 20,228.12088
Overall Steps per Second: 14,735.45886

Timestep Collection Time: 2.47240
Timestep Consumption Time: 0.92159
PPO Batch Consumption Time: 0.08781
Total Iteration Time: 3.39399

Cumulative Model Updates: 21,245
Cumulative Timesteps: 354,722,048

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,218.26238
Policy Entropy: 0.79290
Value Function Loss: 0.07039

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04951
Policy Update Magnitude: 0.03824
Value Function Update Magnitude: 0.05394

Collected Steps per Second: 22,567.03598
Overall Steps per Second: 16,449.77648

Timestep Collection Time: 2.21651
Timestep Consumption Time: 0.82426
PPO Batch Consumption Time: 0.06351
Total Iteration Time: 3.04077

Cumulative Model Updates: 21,248
Cumulative Timesteps: 354,772,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 354772068...
Checkpoint 354772068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,273.43014
Policy Entropy: 0.79081
Value Function Loss: 0.06742

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05730
Policy Update Magnitude: 0.04055
Value Function Update Magnitude: 0.04720

Collected Steps per Second: 22,428.68979
Overall Steps per Second: 15,970.70288

Timestep Collection Time: 2.23054
Timestep Consumption Time: 0.90195
PPO Batch Consumption Time: 0.08252
Total Iteration Time: 3.13249

Cumulative Model Updates: 21,251
Cumulative Timesteps: 354,822,096

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,665.21575
Policy Entropy: 0.79459
Value Function Loss: 0.06303

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04033
Policy Update Magnitude: 0.04032
Value Function Update Magnitude: 0.04701

Collected Steps per Second: 22,600.75231
Overall Steps per Second: 16,594.04904

Timestep Collection Time: 2.21276
Timestep Consumption Time: 0.80097
PPO Batch Consumption Time: 0.05875
Total Iteration Time: 3.01373

Cumulative Model Updates: 21,254
Cumulative Timesteps: 354,872,106

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 354872106...
Checkpoint 354872106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,472.70458
Policy Entropy: 0.80234
Value Function Loss: 0.06214

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05491
Policy Update Magnitude: 0.03817
Value Function Update Magnitude: 0.04655

Collected Steps per Second: 20,932.26081
Overall Steps per Second: 15,093.46764

Timestep Collection Time: 2.38904
Timestep Consumption Time: 0.92418
PPO Batch Consumption Time: 0.10062
Total Iteration Time: 3.31322

Cumulative Model Updates: 21,257
Cumulative Timesteps: 354,922,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,719.10715
Policy Entropy: 0.81130
Value Function Loss: 0.06235

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.05049
Policy Update Magnitude: 0.03813
Value Function Update Magnitude: 0.05403

Collected Steps per Second: 22,490.14465
Overall Steps per Second: 16,483.23956

Timestep Collection Time: 2.22346
Timestep Consumption Time: 0.81029
PPO Batch Consumption Time: 0.06277
Total Iteration Time: 3.03375

Cumulative Model Updates: 21,260
Cumulative Timesteps: 354,972,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 354972120...
Checkpoint 354972120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,505.25794
Policy Entropy: 0.80925
Value Function Loss: 0.06388

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04784
Policy Update Magnitude: 0.03604
Value Function Update Magnitude: 0.05017

Collected Steps per Second: 20,521.28680
Overall Steps per Second: 14,968.67231

Timestep Collection Time: 2.43718
Timestep Consumption Time: 0.90407
PPO Batch Consumption Time: 0.09261
Total Iteration Time: 3.34124

Cumulative Model Updates: 21,263
Cumulative Timesteps: 355,022,134

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,263.00667
Policy Entropy: 0.81439
Value Function Loss: 0.06101

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03813
Policy Update Magnitude: 0.03682
Value Function Update Magnitude: 0.04986

Collected Steps per Second: 22,619.00806
Overall Steps per Second: 16,741.48299

Timestep Collection Time: 2.21186
Timestep Consumption Time: 0.77653
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 2.98839

Cumulative Model Updates: 21,266
Cumulative Timesteps: 355,072,164

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 355072164...
Checkpoint 355072164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,171.85946
Policy Entropy: 0.79378
Value Function Loss: 0.06409

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.04034
Policy Update Magnitude: 0.03643
Value Function Update Magnitude: 0.05151

Collected Steps per Second: 21,085.04041
Overall Steps per Second: 14,867.74952

Timestep Collection Time: 2.37258
Timestep Consumption Time: 0.99215
PPO Batch Consumption Time: 0.12048
Total Iteration Time: 3.36473

Cumulative Model Updates: 21,269
Cumulative Timesteps: 355,122,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,173.49772
Policy Entropy: 0.79376
Value Function Loss: 0.06490

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02779
Policy Update Magnitude: 0.03834
Value Function Update Magnitude: 0.04838

Collected Steps per Second: 22,649.58097
Overall Steps per Second: 16,710.25154

Timestep Collection Time: 2.20949
Timestep Consumption Time: 0.78532
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 2.99481

Cumulative Model Updates: 21,272
Cumulative Timesteps: 355,172,234

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 355172234...
Checkpoint 355172234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,090.96342
Policy Entropy: 0.79732
Value Function Loss: 0.06472

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04115
Policy Update Magnitude: 0.04033
Value Function Update Magnitude: 0.05347

Collected Steps per Second: 20,181.09088
Overall Steps per Second: 14,734.97717

Timestep Collection Time: 2.47895
Timestep Consumption Time: 0.91623
PPO Batch Consumption Time: 0.08955
Total Iteration Time: 3.39519

Cumulative Model Updates: 21,275
Cumulative Timesteps: 355,222,262

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,453.22096
Policy Entropy: 0.80661
Value Function Loss: 0.06172

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03382
Policy Update Magnitude: 0.04034
Value Function Update Magnitude: 0.05316

Collected Steps per Second: 22,760.39220
Overall Steps per Second: 16,692.09095

Timestep Collection Time: 2.19680
Timestep Consumption Time: 0.79863
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 2.99543

Cumulative Model Updates: 21,278
Cumulative Timesteps: 355,272,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 355272262...
Checkpoint 355272262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,341.90163
Policy Entropy: 0.80427
Value Function Loss: 0.06344

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03695
Policy Update Magnitude: 0.03759
Value Function Update Magnitude: 0.05082

Collected Steps per Second: 20,057.20564
Overall Steps per Second: 14,784.62959

Timestep Collection Time: 2.49496
Timestep Consumption Time: 0.88977
PPO Batch Consumption Time: 0.07747
Total Iteration Time: 3.38473

Cumulative Model Updates: 21,281
Cumulative Timesteps: 355,322,304

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,854.92737
Policy Entropy: 0.81747
Value Function Loss: 0.06813

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02376
Policy Update Magnitude: 0.03796
Value Function Update Magnitude: 0.04621

Collected Steps per Second: 22,541.69332
Overall Steps per Second: 16,681.49730

Timestep Collection Time: 2.21891
Timestep Consumption Time: 0.77950
PPO Batch Consumption Time: 0.05793
Total Iteration Time: 2.99841

Cumulative Model Updates: 21,284
Cumulative Timesteps: 355,372,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 355372322...
Checkpoint 355372322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,725.64364
Policy Entropy: 0.82328
Value Function Loss: 0.06366

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.03049
Policy Update Magnitude: 0.03460
Value Function Update Magnitude: 0.04504

Collected Steps per Second: 19,889.15853
Overall Steps per Second: 14,638.20306

Timestep Collection Time: 2.51534
Timestep Consumption Time: 0.90229
PPO Batch Consumption Time: 0.08665
Total Iteration Time: 3.41763

Cumulative Model Updates: 21,287
Cumulative Timesteps: 355,422,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,860.88671
Policy Entropy: 0.83856
Value Function Loss: 0.06145

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03643
Policy Update Magnitude: 0.03298
Value Function Update Magnitude: 0.04596

Collected Steps per Second: 22,445.91971
Overall Steps per Second: 16,496.10905

Timestep Collection Time: 2.22891
Timestep Consumption Time: 0.80392
PPO Batch Consumption Time: 0.06156
Total Iteration Time: 3.03284

Cumulative Model Updates: 21,290
Cumulative Timesteps: 355,472,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 355472380...
Checkpoint 355472380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,768.80552
Policy Entropy: 0.83109
Value Function Loss: 0.05699

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03119
Policy Update Magnitude: 0.03469
Value Function Update Magnitude: 0.05092

Collected Steps per Second: 22,506.00621
Overall Steps per Second: 16,571.92404

Timestep Collection Time: 2.22207
Timestep Consumption Time: 0.79568
PPO Batch Consumption Time: 0.06212
Total Iteration Time: 3.01775

Cumulative Model Updates: 21,293
Cumulative Timesteps: 355,522,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,537.12678
Policy Entropy: 0.83116
Value Function Loss: 0.05779

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04183
Policy Update Magnitude: 0.03497
Value Function Update Magnitude: 0.05186

Collected Steps per Second: 22,663.55355
Overall Steps per Second: 16,678.81406

Timestep Collection Time: 2.20645
Timestep Consumption Time: 0.79172
PPO Batch Consumption Time: 0.06232
Total Iteration Time: 2.99817

Cumulative Model Updates: 21,296
Cumulative Timesteps: 355,572,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 355572396...
Checkpoint 355572396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,450.55165
Policy Entropy: 0.83297
Value Function Loss: 0.06397

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04161
Policy Update Magnitude: 0.03649
Value Function Update Magnitude: 0.04668

Collected Steps per Second: 22,284.46618
Overall Steps per Second: 16,465.50177

Timestep Collection Time: 2.24389
Timestep Consumption Time: 0.79300
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 3.03689

Cumulative Model Updates: 21,299
Cumulative Timesteps: 355,622,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,614.89094
Policy Entropy: 0.83981
Value Function Loss: 0.06156

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.05209
Policy Update Magnitude: 0.03302
Value Function Update Magnitude: 0.04750

Collected Steps per Second: 20,531.39705
Overall Steps per Second: 14,701.12369

Timestep Collection Time: 2.43627
Timestep Consumption Time: 0.96619
PPO Batch Consumption Time: 0.10277
Total Iteration Time: 3.40246

Cumulative Model Updates: 21,302
Cumulative Timesteps: 355,672,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 355672420...
Checkpoint 355672420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,549.32946
Policy Entropy: 0.84906
Value Function Loss: 0.06620

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02913
Policy Update Magnitude: 0.03260
Value Function Update Magnitude: 0.04558

Collected Steps per Second: 22,429.00914
Overall Steps per Second: 16,516.45881

Timestep Collection Time: 2.23033
Timestep Consumption Time: 0.79841
PPO Batch Consumption Time: 0.05913
Total Iteration Time: 3.02874

Cumulative Model Updates: 21,305
Cumulative Timesteps: 355,722,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,264.43670
Policy Entropy: 0.83788
Value Function Loss: 0.06219

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03381
Policy Update Magnitude: 0.03227
Value Function Update Magnitude: 0.04601

Collected Steps per Second: 20,329.75918
Overall Steps per Second: 14,802.78289

Timestep Collection Time: 2.45994
Timestep Consumption Time: 0.91848
PPO Batch Consumption Time: 0.08300
Total Iteration Time: 3.37842

Cumulative Model Updates: 21,308
Cumulative Timesteps: 355,772,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 355772454...
Checkpoint 355772454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,539.05259
Policy Entropy: 0.85578
Value Function Loss: 0.06495

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02904
Policy Update Magnitude: 0.03509
Value Function Update Magnitude: 0.05143

Collected Steps per Second: 21,415.77074
Overall Steps per Second: 15,024.10940

Timestep Collection Time: 2.33576
Timestep Consumption Time: 0.99369
PPO Batch Consumption Time: 0.11171
Total Iteration Time: 3.32945

Cumulative Model Updates: 21,311
Cumulative Timesteps: 355,822,476

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,974.62246
Policy Entropy: 0.85246
Value Function Loss: 0.06582

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04323
Policy Update Magnitude: 0.03388
Value Function Update Magnitude: 0.04654

Collected Steps per Second: 22,853.60880
Overall Steps per Second: 16,837.44305

Timestep Collection Time: 2.18801
Timestep Consumption Time: 0.78180
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 2.96981

Cumulative Model Updates: 21,314
Cumulative Timesteps: 355,872,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 355872480...
Checkpoint 355872480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,096.35851
Policy Entropy: 0.87566
Value Function Loss: 0.06233

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03345
Policy Update Magnitude: 0.03230
Value Function Update Magnitude: 0.04510

Collected Steps per Second: 20,585.86632
Overall Steps per Second: 14,630.67328

Timestep Collection Time: 2.43118
Timestep Consumption Time: 0.98958
PPO Batch Consumption Time: 0.11703
Total Iteration Time: 3.42076

Cumulative Model Updates: 21,317
Cumulative Timesteps: 355,922,528

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,307.52035
Policy Entropy: 0.87701
Value Function Loss: 0.05923

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03431
Policy Update Magnitude: 0.03241
Value Function Update Magnitude: 0.04259

Collected Steps per Second: 22,613.82473
Overall Steps per Second: 16,491.35627

Timestep Collection Time: 2.21113
Timestep Consumption Time: 0.82089
PPO Batch Consumption Time: 0.06133
Total Iteration Time: 3.03201

Cumulative Model Updates: 21,320
Cumulative Timesteps: 355,972,530

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 355972530...
Checkpoint 355972530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,578.75927
Policy Entropy: 0.87128
Value Function Loss: 0.05855

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03675
Policy Update Magnitude: 0.03532
Value Function Update Magnitude: 0.04840

Collected Steps per Second: 19,722.73752
Overall Steps per Second: 14,151.31542

Timestep Collection Time: 2.53636
Timestep Consumption Time: 0.99857
PPO Batch Consumption Time: 0.11638
Total Iteration Time: 3.53494

Cumulative Model Updates: 21,323
Cumulative Timesteps: 356,022,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,483.48557
Policy Entropy: 0.85788
Value Function Loss: 0.06432

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04681
Policy Update Magnitude: 0.03451
Value Function Update Magnitude: 0.05193

Collected Steps per Second: 22,696.21111
Overall Steps per Second: 16,735.82414

Timestep Collection Time: 2.20310
Timestep Consumption Time: 0.78462
PPO Batch Consumption Time: 0.06165
Total Iteration Time: 2.98772

Cumulative Model Updates: 21,326
Cumulative Timesteps: 356,072,556

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 356072556...
Checkpoint 356072556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,364.86804
Policy Entropy: 0.86022
Value Function Loss: 0.07347

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03970
Policy Update Magnitude: 0.03596
Value Function Update Magnitude: 0.04632

Collected Steps per Second: 19,939.54443
Overall Steps per Second: 14,759.92245

Timestep Collection Time: 2.50888
Timestep Consumption Time: 0.88043
PPO Batch Consumption Time: 0.08750
Total Iteration Time: 3.38931

Cumulative Model Updates: 21,329
Cumulative Timesteps: 356,122,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,671.70265
Policy Entropy: 0.87011
Value Function Loss: 0.06478

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04045
Policy Update Magnitude: 0.03591
Value Function Update Magnitude: 0.05013

Collected Steps per Second: 22,313.22541
Overall Steps per Second: 16,987.46306

Timestep Collection Time: 2.24217
Timestep Consumption Time: 0.70295
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 2.94511

Cumulative Model Updates: 21,332
Cumulative Timesteps: 356,172,612

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 356172612...
Checkpoint 356172612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,719.28945
Policy Entropy: 0.88253
Value Function Loss: 0.05987

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01941
Policy Update Magnitude: 0.03507
Value Function Update Magnitude: 0.04655

Collected Steps per Second: 20,017.93357
Overall Steps per Second: 14,616.82682

Timestep Collection Time: 2.49956
Timestep Consumption Time: 0.92362
PPO Batch Consumption Time: 0.11473
Total Iteration Time: 3.42318

Cumulative Model Updates: 21,335
Cumulative Timesteps: 356,222,648

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,983.20491
Policy Entropy: 0.89387
Value Function Loss: 0.05297

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.03515
Value Function Update Magnitude: 0.04995

Collected Steps per Second: 21,634.04430
Overall Steps per Second: 16,480.63506

Timestep Collection Time: 2.31173
Timestep Consumption Time: 0.72287
PPO Batch Consumption Time: 0.05984
Total Iteration Time: 3.03459

Cumulative Model Updates: 21,338
Cumulative Timesteps: 356,272,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 356272660...
Checkpoint 356272660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,832.35811
Policy Entropy: 0.87865
Value Function Loss: 0.06253

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02249
Policy Update Magnitude: 0.03436
Value Function Update Magnitude: 0.04992

Collected Steps per Second: 20,305.53734
Overall Steps per Second: 14,971.25480

Timestep Collection Time: 2.46258
Timestep Consumption Time: 0.87742
PPO Batch Consumption Time: 0.10996
Total Iteration Time: 3.34000

Cumulative Model Updates: 21,341
Cumulative Timesteps: 356,322,664

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,930.72621
Policy Entropy: 0.88161
Value Function Loss: 0.06342

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02373
Policy Update Magnitude: 0.03421
Value Function Update Magnitude: 0.04924

Collected Steps per Second: 21,536.89063
Overall Steps per Second: 16,455.51573

Timestep Collection Time: 2.32262
Timestep Consumption Time: 0.71721
PPO Batch Consumption Time: 0.05895
Total Iteration Time: 3.03983

Cumulative Model Updates: 21,344
Cumulative Timesteps: 356,372,686

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 356372686...
Checkpoint 356372686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,584.44181
Policy Entropy: 0.87466
Value Function Loss: 0.06193

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02252
Policy Update Magnitude: 0.03370
Value Function Update Magnitude: 0.05487

Collected Steps per Second: 19,840.12731
Overall Steps per Second: 14,998.27631

Timestep Collection Time: 2.52156
Timestep Consumption Time: 0.81403
PPO Batch Consumption Time: 0.07711
Total Iteration Time: 3.33558

Cumulative Model Updates: 21,347
Cumulative Timesteps: 356,422,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,375.93418
Policy Entropy: 0.87623
Value Function Loss: 0.06152

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03673
Policy Update Magnitude: 0.03283
Value Function Update Magnitude: 0.06095

Collected Steps per Second: 22,001.92925
Overall Steps per Second: 16,778.78125

Timestep Collection Time: 2.27353
Timestep Consumption Time: 0.70774
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 2.98127

Cumulative Model Updates: 21,350
Cumulative Timesteps: 356,472,736

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 356472736...
Checkpoint 356472736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,128.25169
Policy Entropy: 0.86678
Value Function Loss: 0.06568

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03720
Policy Update Magnitude: 0.03261
Value Function Update Magnitude: 0.06391

Collected Steps per Second: 19,340.56663
Overall Steps per Second: 14,733.53037

Timestep Collection Time: 2.58669
Timestep Consumption Time: 0.80883
PPO Batch Consumption Time: 0.07985
Total Iteration Time: 3.39552

Cumulative Model Updates: 21,353
Cumulative Timesteps: 356,522,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,097.27342
Policy Entropy: 0.86347
Value Function Loss: 0.06696

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03115
Policy Update Magnitude: 0.03251
Value Function Update Magnitude: 0.06368

Collected Steps per Second: 21,666.14209
Overall Steps per Second: 16,158.14151

Timestep Collection Time: 2.30886
Timestep Consumption Time: 0.78704
PPO Batch Consumption Time: 0.06442
Total Iteration Time: 3.09590

Cumulative Model Updates: 21,356
Cumulative Timesteps: 356,572,788

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 356572788...
Checkpoint 356572788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,293.98580
Policy Entropy: 0.87048
Value Function Loss: 0.06149

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03453
Policy Update Magnitude: 0.03100
Value Function Update Magnitude: 0.06992

Collected Steps per Second: 22,301.24648
Overall Steps per Second: 16,615.34088

Timestep Collection Time: 2.24319
Timestep Consumption Time: 0.76764
PPO Batch Consumption Time: 0.06319
Total Iteration Time: 3.01083

Cumulative Model Updates: 21,359
Cumulative Timesteps: 356,622,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,341.31957
Policy Entropy: 0.87541
Value Function Loss: 0.06071

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03155
Policy Update Magnitude: 0.03129
Value Function Update Magnitude: 0.07152

Collected Steps per Second: 22,624.44360
Overall Steps per Second: 16,731.11802

Timestep Collection Time: 2.21106
Timestep Consumption Time: 0.77882
PPO Batch Consumption Time: 0.05939
Total Iteration Time: 2.98988

Cumulative Model Updates: 21,362
Cumulative Timesteps: 356,672,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 356672838...
Checkpoint 356672838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,687.09958
Policy Entropy: 0.87110
Value Function Loss: 0.05765

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03707
Policy Update Magnitude: 0.03272
Value Function Update Magnitude: 0.06889

Collected Steps per Second: 20,608.40240
Overall Steps per Second: 15,201.78154

Timestep Collection Time: 2.42668
Timestep Consumption Time: 0.86307
PPO Batch Consumption Time: 0.08641
Total Iteration Time: 3.28975

Cumulative Model Updates: 21,365
Cumulative Timesteps: 356,722,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,222.15799
Policy Entropy: 0.86686
Value Function Loss: 0.05899

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03051
Policy Update Magnitude: 0.03224
Value Function Update Magnitude: 0.06741

Collected Steps per Second: 22,628.76900
Overall Steps per Second: 16,777.62338

Timestep Collection Time: 2.20993
Timestep Consumption Time: 0.77071
PPO Batch Consumption Time: 0.06093
Total Iteration Time: 2.98064

Cumulative Model Updates: 21,368
Cumulative Timesteps: 356,772,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 356772856...
Checkpoint 356772856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,232.82924
Policy Entropy: 0.86809
Value Function Loss: 0.05319

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04207
Policy Update Magnitude: 0.03127
Value Function Update Magnitude: 0.06566

Collected Steps per Second: 20,099.76343
Overall Steps per Second: 14,769.55357

Timestep Collection Time: 2.48849
Timestep Consumption Time: 0.89807
PPO Batch Consumption Time: 0.08734
Total Iteration Time: 3.38656

Cumulative Model Updates: 21,371
Cumulative Timesteps: 356,822,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,786.47371
Policy Entropy: 0.86841
Value Function Loss: 0.04977

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02513
Policy Update Magnitude: 0.03248
Value Function Update Magnitude: 0.06400

Collected Steps per Second: 22,395.69450
Overall Steps per Second: 16,475.99341

Timestep Collection Time: 2.23320
Timestep Consumption Time: 0.80237
PPO Batch Consumption Time: 0.06066
Total Iteration Time: 3.03557

Cumulative Model Updates: 21,374
Cumulative Timesteps: 356,872,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 356872888...
Checkpoint 356872888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,873.42089
Policy Entropy: 0.87298
Value Function Loss: 0.05183

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03006
Policy Update Magnitude: 0.03309
Value Function Update Magnitude: 0.06651

Collected Steps per Second: 22,479.23856
Overall Steps per Second: 16,020.19181

Timestep Collection Time: 2.22436
Timestep Consumption Time: 0.89682
PPO Batch Consumption Time: 0.08377
Total Iteration Time: 3.12119

Cumulative Model Updates: 21,377
Cumulative Timesteps: 356,922,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,502.47462
Policy Entropy: 0.85486
Value Function Loss: 0.04867

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02919
Policy Update Magnitude: 0.03183
Value Function Update Magnitude: 0.06781

Collected Steps per Second: 22,799.22871
Overall Steps per Second: 16,750.76758

Timestep Collection Time: 2.19446
Timestep Consumption Time: 0.79239
PPO Batch Consumption Time: 0.05888
Total Iteration Time: 2.98685

Cumulative Model Updates: 21,380
Cumulative Timesteps: 356,972,922

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 356972922...
Checkpoint 356972922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,493.15034
Policy Entropy: 0.85407
Value Function Loss: 0.05008

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02109
Policy Update Magnitude: 0.03100
Value Function Update Magnitude: 0.06597

Collected Steps per Second: 20,820.79902
Overall Steps per Second: 14,978.74139

Timestep Collection Time: 2.40241
Timestep Consumption Time: 0.93699
PPO Batch Consumption Time: 0.09735
Total Iteration Time: 3.33940

Cumulative Model Updates: 21,383
Cumulative Timesteps: 357,022,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,015.65757
Policy Entropy: 0.84648
Value Function Loss: 0.05110

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02261
Policy Update Magnitude: 0.02932
Value Function Update Magnitude: 0.06568

Collected Steps per Second: 22,506.17937
Overall Steps per Second: 16,495.33360

Timestep Collection Time: 2.22357
Timestep Consumption Time: 0.81026
PPO Batch Consumption Time: 0.06219
Total Iteration Time: 3.03383

Cumulative Model Updates: 21,386
Cumulative Timesteps: 357,072,986

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 357072986...
Checkpoint 357072986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,207.41052
Policy Entropy: 0.84201
Value Function Loss: 0.05967

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01708
Policy Update Magnitude: 0.02980
Value Function Update Magnitude: 0.06361

Collected Steps per Second: 20,085.81581
Overall Steps per Second: 14,238.52873

Timestep Collection Time: 2.48952
Timestep Consumption Time: 1.02236
PPO Batch Consumption Time: 0.12614
Total Iteration Time: 3.51188

Cumulative Model Updates: 21,389
Cumulative Timesteps: 357,122,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,420.70041
Policy Entropy: 0.83784
Value Function Loss: 0.06515

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02254
Policy Update Magnitude: 0.03379
Value Function Update Magnitude: 0.06204

Collected Steps per Second: 23,005.16928
Overall Steps per Second: 16,835.87843

Timestep Collection Time: 2.17351
Timestep Consumption Time: 0.79646
PPO Batch Consumption Time: 0.05844
Total Iteration Time: 2.96997

Cumulative Model Updates: 21,392
Cumulative Timesteps: 357,172,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 357172992...
Checkpoint 357172992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,433.75571
Policy Entropy: 0.83925
Value Function Loss: 0.06751

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.03336
Value Function Update Magnitude: 0.05317

Collected Steps per Second: 20,616.67550
Overall Steps per Second: 14,620.19721

Timestep Collection Time: 2.42551
Timestep Consumption Time: 0.99482
PPO Batch Consumption Time: 0.11170
Total Iteration Time: 3.42034

Cumulative Model Updates: 21,395
Cumulative Timesteps: 357,222,998

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,275.87502
Policy Entropy: 0.85508
Value Function Loss: 0.07055

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03365
Policy Update Magnitude: 0.03576
Value Function Update Magnitude: 0.04720

Collected Steps per Second: 22,708.35281
Overall Steps per Second: 16,723.34379

Timestep Collection Time: 2.20307
Timestep Consumption Time: 0.78844
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 2.99151

Cumulative Model Updates: 21,398
Cumulative Timesteps: 357,273,026

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 357273026...
Checkpoint 357273026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,370.83719
Policy Entropy: 0.84533
Value Function Loss: 0.07212

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03292
Policy Update Magnitude: 0.03722
Value Function Update Magnitude: 0.04768

Collected Steps per Second: 20,388.46826
Overall Steps per Second: 14,760.38016

Timestep Collection Time: 2.45364
Timestep Consumption Time: 0.93557
PPO Batch Consumption Time: 0.09199
Total Iteration Time: 3.38921

Cumulative Model Updates: 21,401
Cumulative Timesteps: 357,323,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,092.46707
Policy Entropy: 0.85626
Value Function Loss: 0.06525

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02617
Policy Update Magnitude: 0.03540
Value Function Update Magnitude: 0.05229

Collected Steps per Second: 22,418.59522
Overall Steps per Second: 16,474.84768

Timestep Collection Time: 2.23109
Timestep Consumption Time: 0.80493
PPO Batch Consumption Time: 0.06169
Total Iteration Time: 3.03602

Cumulative Model Updates: 21,404
Cumulative Timesteps: 357,373,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 357373070...
Checkpoint 357373070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,938.88928
Policy Entropy: 0.85482
Value Function Loss: 0.06045

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02639
Policy Update Magnitude: 0.03448
Value Function Update Magnitude: 0.04817

Collected Steps per Second: 20,546.46497
Overall Steps per Second: 14,808.94527

Timestep Collection Time: 2.43390
Timestep Consumption Time: 0.94298
PPO Batch Consumption Time: 0.07096
Total Iteration Time: 3.37688

Cumulative Model Updates: 21,407
Cumulative Timesteps: 357,423,078

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,294.74249
Policy Entropy: 0.87078
Value Function Loss: 0.05526

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03373
Policy Update Magnitude: 0.03588
Value Function Update Magnitude: 0.04518

Collected Steps per Second: 22,811.14387
Overall Steps per Second: 16,918.94741

Timestep Collection Time: 2.19200
Timestep Consumption Time: 0.76339
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 2.95538

Cumulative Model Updates: 21,410
Cumulative Timesteps: 357,473,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 357473080...
Checkpoint 357473080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,474.01354
Policy Entropy: 0.85532
Value Function Loss: 0.05869

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03142
Policy Update Magnitude: 0.03499
Value Function Update Magnitude: 0.04847

Collected Steps per Second: 20,163.30382
Overall Steps per Second: 14,671.05346

Timestep Collection Time: 2.48124
Timestep Consumption Time: 0.92888
PPO Batch Consumption Time: 0.08458
Total Iteration Time: 3.41012

Cumulative Model Updates: 21,413
Cumulative Timesteps: 357,523,110

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,515.64868
Policy Entropy: 0.85872
Value Function Loss: 0.06298

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03268
Policy Update Magnitude: 0.03398
Value Function Update Magnitude: 0.05335

Collected Steps per Second: 22,579.22894
Overall Steps per Second: 16,617.48565

Timestep Collection Time: 2.21558
Timestep Consumption Time: 0.79487
PPO Batch Consumption Time: 0.05952
Total Iteration Time: 3.01044

Cumulative Model Updates: 21,416
Cumulative Timesteps: 357,573,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 357573136...
Checkpoint 357573136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,046.00343
Policy Entropy: 0.83879
Value Function Loss: 0.06543

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.03786
Value Function Update Magnitude: 0.05169

Collected Steps per Second: 21,007.66021
Overall Steps per Second: 15,009.52188

Timestep Collection Time: 2.38027
Timestep Consumption Time: 0.95121
PPO Batch Consumption Time: 0.09873
Total Iteration Time: 3.33149

Cumulative Model Updates: 21,419
Cumulative Timesteps: 357,623,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,244.81374
Policy Entropy: 0.83577
Value Function Loss: 0.06847

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03072
Policy Update Magnitude: 0.03679
Value Function Update Magnitude: 0.04974

Collected Steps per Second: 22,648.20264
Overall Steps per Second: 16,810.95798

Timestep Collection Time: 2.20883
Timestep Consumption Time: 0.76697
PPO Batch Consumption Time: 0.05891
Total Iteration Time: 2.97580

Cumulative Model Updates: 21,422
Cumulative Timesteps: 357,673,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 357673166...
Checkpoint 357673166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,654.24841
Policy Entropy: 0.82034
Value Function Loss: 0.06435

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02846
Policy Update Magnitude: 0.03701
Value Function Update Magnitude: 0.04839

Collected Steps per Second: 20,201.19919
Overall Steps per Second: 14,757.31062

Timestep Collection Time: 2.47540
Timestep Consumption Time: 0.91316
PPO Batch Consumption Time: 0.09111
Total Iteration Time: 3.38856

Cumulative Model Updates: 21,425
Cumulative Timesteps: 357,723,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,991.52954
Policy Entropy: 0.82508
Value Function Loss: 0.06541

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02066
Policy Update Magnitude: 0.04010
Value Function Update Magnitude: 0.04489

Collected Steps per Second: 22,489.54292
Overall Steps per Second: 16,478.09356

Timestep Collection Time: 2.22326
Timestep Consumption Time: 0.81108
PPO Batch Consumption Time: 0.05844
Total Iteration Time: 3.03433

Cumulative Model Updates: 21,428
Cumulative Timesteps: 357,773,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 357773172...
Checkpoint 357773172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,562.30988
Policy Entropy: 0.83212
Value Function Loss: 0.05811

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02799
Policy Update Magnitude: 0.03736
Value Function Update Magnitude: 0.04759

Collected Steps per Second: 20,968.50038
Overall Steps per Second: 15,010.43158

Timestep Collection Time: 2.38520
Timestep Consumption Time: 0.94675
PPO Batch Consumption Time: 0.09282
Total Iteration Time: 3.33195

Cumulative Model Updates: 21,431
Cumulative Timesteps: 357,823,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,467.17624
Policy Entropy: 0.83340
Value Function Loss: 0.06559

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03559
Policy Update Magnitude: 0.03542
Value Function Update Magnitude: 0.04963

Collected Steps per Second: 22,223.70054
Overall Steps per Second: 16,513.39740

Timestep Collection Time: 2.25030
Timestep Consumption Time: 0.77815
PPO Batch Consumption Time: 0.05972
Total Iteration Time: 3.02845

Cumulative Model Updates: 21,434
Cumulative Timesteps: 357,873,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 357873196...
Checkpoint 357873196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,687.06392
Policy Entropy: 0.83223
Value Function Loss: 0.07101

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02843
Policy Update Magnitude: 0.03706
Value Function Update Magnitude: 0.05880

Collected Steps per Second: 20,925.87391
Overall Steps per Second: 14,949.74031

Timestep Collection Time: 2.39044
Timestep Consumption Time: 0.95557
PPO Batch Consumption Time: 0.10302
Total Iteration Time: 3.34601

Cumulative Model Updates: 21,437
Cumulative Timesteps: 357,923,218

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,280.90682
Policy Entropy: 0.83440
Value Function Loss: 0.07836

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03425
Policy Update Magnitude: 0.03710
Value Function Update Magnitude: 0.06023

Collected Steps per Second: 22,427.30255
Overall Steps per Second: 16,591.74890

Timestep Collection Time: 2.23094
Timestep Consumption Time: 0.78465
PPO Batch Consumption Time: 0.06021
Total Iteration Time: 3.01560

Cumulative Model Updates: 21,440
Cumulative Timesteps: 357,973,252

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 357973252...
Checkpoint 357973252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,176.50910
Policy Entropy: 0.83883
Value Function Loss: 0.07805

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.03465
Value Function Update Magnitude: 0.05137

Collected Steps per Second: 19,846.50576
Overall Steps per Second: 14,152.83254

Timestep Collection Time: 2.52075
Timestep Consumption Time: 1.01409
PPO Batch Consumption Time: 0.12660
Total Iteration Time: 3.53484

Cumulative Model Updates: 21,443
Cumulative Timesteps: 358,023,280

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,389.58236
Policy Entropy: 0.82790
Value Function Loss: 0.07233

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02135
Policy Update Magnitude: 0.03516
Value Function Update Magnitude: 0.05367

Collected Steps per Second: 23,194.91153
Overall Steps per Second: 16,946.31186

Timestep Collection Time: 2.15694
Timestep Consumption Time: 0.79533
PPO Batch Consumption Time: 0.05800
Total Iteration Time: 2.95226

Cumulative Model Updates: 21,446
Cumulative Timesteps: 358,073,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 358073310...
Checkpoint 358073310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,636.49614
Policy Entropy: 0.82172
Value Function Loss: 0.06770

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.01060
Policy Update Magnitude: 0.03477
Value Function Update Magnitude: 0.05460

Collected Steps per Second: 20,758.80578
Overall Steps per Second: 15,227.02277

Timestep Collection Time: 2.40948
Timestep Consumption Time: 0.87533
PPO Batch Consumption Time: 0.07767
Total Iteration Time: 3.28482

Cumulative Model Updates: 21,449
Cumulative Timesteps: 358,123,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,043.02195
Policy Entropy: 0.81785
Value Function Loss: 0.06009

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02585
Policy Update Magnitude: 0.03177
Value Function Update Magnitude: 0.06004

Collected Steps per Second: 22,269.80461
Overall Steps per Second: 16,317.39605

Timestep Collection Time: 2.24663
Timestep Consumption Time: 0.81955
PPO Batch Consumption Time: 0.06463
Total Iteration Time: 3.06618

Cumulative Model Updates: 21,452
Cumulative Timesteps: 358,173,360

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 358173360...
Checkpoint 358173360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,222.69854
Policy Entropy: 0.81625
Value Function Loss: 0.06026

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.03033
Policy Update Magnitude: 0.03095
Value Function Update Magnitude: 0.05945

Collected Steps per Second: 22,506.99740
Overall Steps per Second: 16,540.09550

Timestep Collection Time: 2.22322
Timestep Consumption Time: 0.80203
PPO Batch Consumption Time: 0.05822
Total Iteration Time: 3.02525

Cumulative Model Updates: 21,455
Cumulative Timesteps: 358,223,398

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,972.45218
Policy Entropy: 0.81330
Value Function Loss: 0.06615

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03423
Policy Update Magnitude: 0.03223
Value Function Update Magnitude: 0.05615

Collected Steps per Second: 20,328.73472
Overall Steps per Second: 14,583.42141

Timestep Collection Time: 2.46046
Timestep Consumption Time: 0.96933
PPO Batch Consumption Time: 0.10634
Total Iteration Time: 3.42978

Cumulative Model Updates: 21,458
Cumulative Timesteps: 358,273,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 358273416...
Checkpoint 358273416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,759.09299
Policy Entropy: 0.80051
Value Function Loss: 0.07270

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04647
Policy Update Magnitude: 0.03202
Value Function Update Magnitude: 0.05106

Collected Steps per Second: 22,305.78365
Overall Steps per Second: 16,622.76981

Timestep Collection Time: 2.24157
Timestep Consumption Time: 0.76635
PPO Batch Consumption Time: 0.05944
Total Iteration Time: 3.00792

Cumulative Model Updates: 21,461
Cumulative Timesteps: 358,323,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,578.26315
Policy Entropy: 0.79782
Value Function Loss: 0.07419

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04203
Policy Update Magnitude: 0.03420
Value Function Update Magnitude: 0.04870

Collected Steps per Second: 20,473.19624
Overall Steps per Second: 14,825.68350

Timestep Collection Time: 2.44300
Timestep Consumption Time: 0.93061
PPO Batch Consumption Time: 0.08624
Total Iteration Time: 3.37360

Cumulative Model Updates: 21,464
Cumulative Timesteps: 358,373,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 358373432...
Checkpoint 358373432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,483.07512
Policy Entropy: 0.79192
Value Function Loss: 0.07259

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03447
Policy Update Magnitude: 0.03560
Value Function Update Magnitude: 0.05238

Collected Steps per Second: 22,295.18963
Overall Steps per Second: 16,463.49426

Timestep Collection Time: 2.24380
Timestep Consumption Time: 0.79480
PPO Batch Consumption Time: 0.05791
Total Iteration Time: 3.03860

Cumulative Model Updates: 21,467
Cumulative Timesteps: 358,423,458

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,670.10964
Policy Entropy: 0.80291
Value Function Loss: 0.07508

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04604
Policy Update Magnitude: 0.03525
Value Function Update Magnitude: 0.04950

Collected Steps per Second: 20,966.53127
Overall Steps per Second: 15,039.63691

Timestep Collection Time: 2.38552
Timestep Consumption Time: 0.94010
PPO Batch Consumption Time: 0.10937
Total Iteration Time: 3.32561

Cumulative Model Updates: 21,470
Cumulative Timesteps: 358,473,474

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 358473474...
Checkpoint 358473474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,530.02210
Policy Entropy: 0.80988
Value Function Loss: 0.07517

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.03027
Policy Update Magnitude: 0.03464
Value Function Update Magnitude: 0.04793

Collected Steps per Second: 22,072.11996
Overall Steps per Second: 16,311.83247

Timestep Collection Time: 2.26675
Timestep Consumption Time: 0.80047
PPO Batch Consumption Time: 0.06070
Total Iteration Time: 3.06722

Cumulative Model Updates: 21,473
Cumulative Timesteps: 358,523,506

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,066.12860
Policy Entropy: 0.81846
Value Function Loss: 0.07219

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04306
Policy Update Magnitude: 0.03388
Value Function Update Magnitude: 0.04584

Collected Steps per Second: 22,591.98611
Overall Steps per Second: 16,051.57199

Timestep Collection Time: 2.21362
Timestep Consumption Time: 0.90197
PPO Batch Consumption Time: 0.08094
Total Iteration Time: 3.11558

Cumulative Model Updates: 21,476
Cumulative Timesteps: 358,573,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 358573516...
Checkpoint 358573516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,216.70035
Policy Entropy: 0.80990
Value Function Loss: 0.06719

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01997
Policy Update Magnitude: 0.03444
Value Function Update Magnitude: 0.04465

Collected Steps per Second: 22,300.17949
Overall Steps per Second: 16,566.01507

Timestep Collection Time: 2.24348
Timestep Consumption Time: 0.77656
PPO Batch Consumption Time: 0.06129
Total Iteration Time: 3.02004

Cumulative Model Updates: 21,479
Cumulative Timesteps: 358,623,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,245.48180
Policy Entropy: 0.80974
Value Function Loss: 0.07251

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03584
Policy Update Magnitude: 0.03614
Value Function Update Magnitude: 0.04448

Collected Steps per Second: 19,975.17524
Overall Steps per Second: 14,897.27601

Timestep Collection Time: 2.50331
Timestep Consumption Time: 0.85328
PPO Batch Consumption Time: 0.07947
Total Iteration Time: 3.35659

Cumulative Model Updates: 21,482
Cumulative Timesteps: 358,673,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 358673550...
Checkpoint 358673550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,442.92777
Policy Entropy: 0.81496
Value Function Loss: 0.07168

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03152
Policy Update Magnitude: 0.03658
Value Function Update Magnitude: 0.04758

Collected Steps per Second: 22,060.19997
Overall Steps per Second: 16,283.89483

Timestep Collection Time: 2.26662
Timestep Consumption Time: 0.80403
PPO Batch Consumption Time: 0.06330
Total Iteration Time: 3.07064

Cumulative Model Updates: 21,485
Cumulative Timesteps: 358,723,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,507.73982
Policy Entropy: 0.81614
Value Function Loss: 0.07312

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05759
Policy Update Magnitude: 0.03505
Value Function Update Magnitude: 0.05182

Collected Steps per Second: 22,535.55073
Overall Steps per Second: 16,111.40871

Timestep Collection Time: 2.22058
Timestep Consumption Time: 0.88542
PPO Batch Consumption Time: 0.08729
Total Iteration Time: 3.10600

Cumulative Model Updates: 21,488
Cumulative Timesteps: 358,773,594

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 358773594...
Checkpoint 358773594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,874.32686
Policy Entropy: 0.82009
Value Function Loss: 0.06402

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04653
Policy Update Magnitude: 0.03328
Value Function Update Magnitude: 0.05015

Collected Steps per Second: 22,164.83236
Overall Steps per Second: 16,427.31920

Timestep Collection Time: 2.25646
Timestep Consumption Time: 0.78811
PPO Batch Consumption Time: 0.05835
Total Iteration Time: 3.04456

Cumulative Model Updates: 21,491
Cumulative Timesteps: 358,823,608

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,997.44400
Policy Entropy: 0.82017
Value Function Loss: 0.06882

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.03344
Value Function Update Magnitude: 0.04793

Collected Steps per Second: 21,214.11368
Overall Steps per Second: 15,036.15912

Timestep Collection Time: 2.35843
Timestep Consumption Time: 0.96902
PPO Batch Consumption Time: 0.11521
Total Iteration Time: 3.32745

Cumulative Model Updates: 21,494
Cumulative Timesteps: 358,873,640

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 358873640...
Checkpoint 358873640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,754.13793
Policy Entropy: 0.80772
Value Function Loss: 0.07837

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.02800
Value Function Update Magnitude: 0.04425

Collected Steps per Second: 22,254.97264
Overall Steps per Second: 16,406.40261

Timestep Collection Time: 2.24669
Timestep Consumption Time: 0.80090
PPO Batch Consumption Time: 0.05957
Total Iteration Time: 3.04759

Cumulative Model Updates: 21,497
Cumulative Timesteps: 358,923,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,074.66203
Policy Entropy: 0.80703
Value Function Loss: 0.08001

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.03435
Value Function Update Magnitude: 0.05040

Collected Steps per Second: 20,640.49414
Overall Steps per Second: 15,007.80186

Timestep Collection Time: 2.42320
Timestep Consumption Time: 0.90947
PPO Batch Consumption Time: 0.08699
Total Iteration Time: 3.33267

Cumulative Model Updates: 21,500
Cumulative Timesteps: 358,973,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 358973656...
Checkpoint 358973656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,704.67776
Policy Entropy: 0.79085
Value Function Loss: 0.08211

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.03398
Value Function Update Magnitude: 0.05154

Collected Steps per Second: 22,449.96767
Overall Steps per Second: 16,693.81198

Timestep Collection Time: 2.22922
Timestep Consumption Time: 0.76865
PPO Batch Consumption Time: 0.05921
Total Iteration Time: 2.99788

Cumulative Model Updates: 21,503
Cumulative Timesteps: 359,023,702

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,500.74305
Policy Entropy: 0.80182
Value Function Loss: 0.07264

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.02980
Value Function Update Magnitude: 0.04922

Collected Steps per Second: 19,292.52711
Overall Steps per Second: 14,013.54777

Timestep Collection Time: 2.59251
Timestep Consumption Time: 0.97661
PPO Batch Consumption Time: 0.10480
Total Iteration Time: 3.56912

Cumulative Model Updates: 21,506
Cumulative Timesteps: 359,073,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 359073718...
Checkpoint 359073718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,206.19257
Policy Entropy: 0.80369
Value Function Loss: 0.07026

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.02839
Value Function Update Magnitude: 0.04867

Collected Steps per Second: 22,396.45670
Overall Steps per Second: 16,429.88874

Timestep Collection Time: 2.23267
Timestep Consumption Time: 0.81080
PPO Batch Consumption Time: 0.06140
Total Iteration Time: 3.04348

Cumulative Model Updates: 21,509
Cumulative Timesteps: 359,123,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,635.56596
Policy Entropy: 0.81579
Value Function Loss: 0.06270

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07697
Policy Update Magnitude: 0.03197
Value Function Update Magnitude: 0.05220

Collected Steps per Second: 21,135.45314
Overall Steps per Second: 15,003.73924

Timestep Collection Time: 2.36636
Timestep Consumption Time: 0.96708
PPO Batch Consumption Time: 0.09704
Total Iteration Time: 3.33344

Cumulative Model Updates: 21,512
Cumulative Timesteps: 359,173,736

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 359173736...
Checkpoint 359173736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,202.90226
Policy Entropy: 0.80329
Value Function Loss: 0.06494

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05161
Policy Update Magnitude: 0.03298
Value Function Update Magnitude: 0.05399

Collected Steps per Second: 21,832.01715
Overall Steps per Second: 16,162.75504

Timestep Collection Time: 2.29131
Timestep Consumption Time: 0.80370
PPO Batch Consumption Time: 0.06315
Total Iteration Time: 3.09502

Cumulative Model Updates: 21,515
Cumulative Timesteps: 359,223,760

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,828.32702
Policy Entropy: 0.79763
Value Function Loss: 0.06933

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06266
Policy Update Magnitude: 0.03212
Value Function Update Magnitude: 0.05155

Collected Steps per Second: 22,764.70638
Overall Steps per Second: 16,686.73761

Timestep Collection Time: 2.19752
Timestep Consumption Time: 0.80043
PPO Batch Consumption Time: 0.06232
Total Iteration Time: 2.99795

Cumulative Model Updates: 21,518
Cumulative Timesteps: 359,273,786

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 359273786...
Checkpoint 359273786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,976.74668
Policy Entropy: 0.78270
Value Function Loss: 0.06868

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05784
Policy Update Magnitude: 0.03155
Value Function Update Magnitude: 0.05271

Collected Steps per Second: 22,182.83338
Overall Steps per Second: 16,495.82996

Timestep Collection Time: 2.25490
Timestep Consumption Time: 0.77738
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 3.03228

Cumulative Model Updates: 21,521
Cumulative Timesteps: 359,323,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,445.48128
Policy Entropy: 0.79544
Value Function Loss: 0.06263

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05595
Policy Update Magnitude: 0.03538
Value Function Update Magnitude: 0.05232

Collected Steps per Second: 20,282.27586
Overall Steps per Second: 14,603.50298

Timestep Collection Time: 2.46659
Timestep Consumption Time: 0.95917
PPO Batch Consumption Time: 0.10086
Total Iteration Time: 3.42575

Cumulative Model Updates: 21,524
Cumulative Timesteps: 359,373,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 359373834...
Checkpoint 359373834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,030.11351
Policy Entropy: 0.79011
Value Function Loss: 0.06147

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04305
Policy Update Magnitude: 0.03610
Value Function Update Magnitude: 0.06054

Collected Steps per Second: 22,038.83893
Overall Steps per Second: 16,553.67533

Timestep Collection Time: 2.26936
Timestep Consumption Time: 0.75197
PPO Batch Consumption Time: 0.05963
Total Iteration Time: 3.02132

Cumulative Model Updates: 21,527
Cumulative Timesteps: 359,423,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,832.99725
Policy Entropy: 0.80443
Value Function Loss: 0.07168

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03251
Policy Update Magnitude: 0.03623
Value Function Update Magnitude: 0.05773

Collected Steps per Second: 20,742.17224
Overall Steps per Second: 14,943.98233

Timestep Collection Time: 2.41093
Timestep Consumption Time: 0.93543
PPO Batch Consumption Time: 0.09194
Total Iteration Time: 3.34636

Cumulative Model Updates: 21,530
Cumulative Timesteps: 359,473,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 359473856...
Checkpoint 359473856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,240.03595
Policy Entropy: 0.79470
Value Function Loss: 0.07703

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03927
Policy Update Magnitude: 0.03739
Value Function Update Magnitude: 0.05499

Collected Steps per Second: 22,552.08896
Overall Steps per Second: 16,523.57547

Timestep Collection Time: 2.21718
Timestep Consumption Time: 0.80892
PPO Batch Consumption Time: 0.05882
Total Iteration Time: 3.02610

Cumulative Model Updates: 21,533
Cumulative Timesteps: 359,523,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,940.76864
Policy Entropy: 0.80692
Value Function Loss: 0.07815

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02966
Policy Update Magnitude: 0.03629
Value Function Update Magnitude: 0.06029

Collected Steps per Second: 21,035.35496
Overall Steps per Second: 14,908.80917

Timestep Collection Time: 2.37790
Timestep Consumption Time: 0.97716
PPO Batch Consumption Time: 0.10619
Total Iteration Time: 3.35506

Cumulative Model Updates: 21,536
Cumulative Timesteps: 359,573,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 359573878...
Checkpoint 359573878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,945.57188
Policy Entropy: 0.80464
Value Function Loss: 0.06932

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03832
Policy Update Magnitude: 0.03471
Value Function Update Magnitude: 0.06789

Collected Steps per Second: 22,453.07372
Overall Steps per Second: 16,446.93899

Timestep Collection Time: 2.22758
Timestep Consumption Time: 0.81347
PPO Batch Consumption Time: 0.06208
Total Iteration Time: 3.04105

Cumulative Model Updates: 21,539
Cumulative Timesteps: 359,623,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,952.86220
Policy Entropy: 0.81264
Value Function Loss: 0.06654

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01983
Policy Update Magnitude: 0.03341
Value Function Update Magnitude: 0.06314

Collected Steps per Second: 21,373.94951
Overall Steps per Second: 15,013.49753

Timestep Collection Time: 2.34014
Timestep Consumption Time: 0.99140
PPO Batch Consumption Time: 0.08835
Total Iteration Time: 3.33154

Cumulative Model Updates: 21,542
Cumulative Timesteps: 359,673,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 359673912...
Checkpoint 359673912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,411.53008
Policy Entropy: 0.80357
Value Function Loss: 0.07456

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03388
Policy Update Magnitude: 0.03259
Value Function Update Magnitude: 0.05265

Collected Steps per Second: 22,323.35059
Overall Steps per Second: 16,397.77238

Timestep Collection Time: 2.24026
Timestep Consumption Time: 0.80955
PPO Batch Consumption Time: 0.06263
Total Iteration Time: 3.04980

Cumulative Model Updates: 21,545
Cumulative Timesteps: 359,723,922

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,204.59175
Policy Entropy: 0.81079
Value Function Loss: 0.08040

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03257
Policy Update Magnitude: 0.03254
Value Function Update Magnitude: 0.05163

Collected Steps per Second: 21,200.48251
Overall Steps per Second: 15,061.88835

Timestep Collection Time: 2.36023
Timestep Consumption Time: 0.96193
PPO Batch Consumption Time: 0.11198
Total Iteration Time: 3.32216

Cumulative Model Updates: 21,548
Cumulative Timesteps: 359,773,960

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 359773960...
Checkpoint 359773960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,888.84562
Policy Entropy: 0.79313
Value Function Loss: 0.08473

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03367
Policy Update Magnitude: 0.03114
Value Function Update Magnitude: 0.05402

Collected Steps per Second: 21,874.00293
Overall Steps per Second: 16,191.76519

Timestep Collection Time: 2.28701
Timestep Consumption Time: 0.80259
PPO Batch Consumption Time: 0.05951
Total Iteration Time: 3.08960

Cumulative Model Updates: 21,551
Cumulative Timesteps: 359,823,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,482.88620
Policy Entropy: 0.79013
Value Function Loss: 0.07686

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.03364
Value Function Update Magnitude: 0.05080

Collected Steps per Second: 22,360.34308
Overall Steps per Second: 15,930.85317

Timestep Collection Time: 2.23682
Timestep Consumption Time: 0.90275
PPO Batch Consumption Time: 0.07838
Total Iteration Time: 3.13957

Cumulative Model Updates: 21,554
Cumulative Timesteps: 359,874,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 359874002...
Checkpoint 359874002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,401.95590
Policy Entropy: 0.80081
Value Function Loss: 0.06811

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03090
Policy Update Magnitude: 0.03511
Value Function Update Magnitude: 0.04685

Collected Steps per Second: 22,608.00551
Overall Steps per Second: 16,556.03156

Timestep Collection Time: 2.21178
Timestep Consumption Time: 0.80851
PPO Batch Consumption Time: 0.05920
Total Iteration Time: 3.02029

Cumulative Model Updates: 21,557
Cumulative Timesteps: 359,924,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,779.75945
Policy Entropy: 0.80435
Value Function Loss: 0.06218

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02153
Policy Update Magnitude: 0.03459
Value Function Update Magnitude: 0.04830

Collected Steps per Second: 22,490.65371
Overall Steps per Second: 16,504.10033

Timestep Collection Time: 2.22350
Timestep Consumption Time: 0.80653
PPO Batch Consumption Time: 0.06206
Total Iteration Time: 3.03003

Cumulative Model Updates: 21,560
Cumulative Timesteps: 359,974,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 359974014...
Checkpoint 359974014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,055.94878
Policy Entropy: 0.80304
Value Function Loss: 0.06623

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.04094
Policy Update Magnitude: 0.03632
Value Function Update Magnitude: 0.04509

Collected Steps per Second: 22,349.63509
Overall Steps per Second: 16,515.45496

Timestep Collection Time: 2.23780
Timestep Consumption Time: 0.79052
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 3.02832

Cumulative Model Updates: 21,563
Cumulative Timesteps: 360,024,028

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,582.89324
Policy Entropy: 0.79149
Value Function Loss: 0.06711

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04331
Policy Update Magnitude: 0.03694
Value Function Update Magnitude: 0.04718

Collected Steps per Second: 20,839.16430
Overall Steps per Second: 14,710.55270

Timestep Collection Time: 2.39990
Timestep Consumption Time: 0.99983
PPO Batch Consumption Time: 0.11289
Total Iteration Time: 3.39974

Cumulative Model Updates: 21,566
Cumulative Timesteps: 360,074,040

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 360074040...
Checkpoint 360074040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,069.67531
Policy Entropy: 0.79470
Value Function Loss: 0.06595

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05867
Policy Update Magnitude: 0.03365
Value Function Update Magnitude: 0.04508

Collected Steps per Second: 22,598.03671
Overall Steps per Second: 16,655.22424

Timestep Collection Time: 2.21285
Timestep Consumption Time: 0.78957
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 3.00242

Cumulative Model Updates: 21,569
Cumulative Timesteps: 360,124,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,738.68290
Policy Entropy: 0.79202
Value Function Loss: 0.05935

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04707
Policy Update Magnitude: 0.03326
Value Function Update Magnitude: 0.04408

Collected Steps per Second: 20,153.40065
Overall Steps per Second: 14,733.21040

Timestep Collection Time: 2.48206
Timestep Consumption Time: 0.91312
PPO Batch Consumption Time: 0.08418
Total Iteration Time: 3.39519

Cumulative Model Updates: 21,572
Cumulative Timesteps: 360,174,068

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 360174068...
Checkpoint 360174068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,802.55723
Policy Entropy: 0.78371
Value Function Loss: 0.06151

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03715
Policy Update Magnitude: 0.03621
Value Function Update Magnitude: 0.04123

Collected Steps per Second: 22,360.46299
Overall Steps per Second: 16,598.37373

Timestep Collection Time: 2.23618
Timestep Consumption Time: 0.77628
PPO Batch Consumption Time: 0.06210
Total Iteration Time: 3.01246

Cumulative Model Updates: 21,575
Cumulative Timesteps: 360,224,070

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,504.74694
Policy Entropy: 0.77070
Value Function Loss: 0.07603

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.03573
Value Function Update Magnitude: 0.04043

Collected Steps per Second: 20,062.70921
Overall Steps per Second: 14,877.94628

Timestep Collection Time: 2.49258
Timestep Consumption Time: 0.86863
PPO Batch Consumption Time: 0.09182
Total Iteration Time: 3.36122

Cumulative Model Updates: 21,578
Cumulative Timesteps: 360,274,078

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 360274078...
Checkpoint 360274078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,186.83518
Policy Entropy: 0.76083
Value Function Loss: 0.08083

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03244
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.05071

Collected Steps per Second: 22,296.04818
Overall Steps per Second: 16,379.96489

Timestep Collection Time: 2.24381
Timestep Consumption Time: 0.81041
PPO Batch Consumption Time: 0.06114
Total Iteration Time: 3.05422

Cumulative Model Updates: 21,581
Cumulative Timesteps: 360,324,106

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,732.69284
Policy Entropy: 0.76094
Value Function Loss: 0.07828

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02181
Policy Update Magnitude: 0.04220
Value Function Update Magnitude: 0.06186

Collected Steps per Second: 22,849.28085
Overall Steps per Second: 16,818.87489

Timestep Collection Time: 2.19035
Timestep Consumption Time: 0.78535
PPO Batch Consumption Time: 0.05962
Total Iteration Time: 2.97570

Cumulative Model Updates: 21,584
Cumulative Timesteps: 360,374,154

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 360374154...
Checkpoint 360374154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,582.59968
Policy Entropy: 0.77048
Value Function Loss: 0.06769

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03855
Policy Update Magnitude: 0.03672
Value Function Update Magnitude: 0.07036

Collected Steps per Second: 20,996.09939
Overall Steps per Second: 15,030.64296

Timestep Collection Time: 2.38206
Timestep Consumption Time: 0.94541
PPO Batch Consumption Time: 0.09461
Total Iteration Time: 3.32747

Cumulative Model Updates: 21,587
Cumulative Timesteps: 360,424,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,797.33169
Policy Entropy: 0.77220
Value Function Loss: 0.06188

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02512
Policy Update Magnitude: 0.03465
Value Function Update Magnitude: 0.06699

Collected Steps per Second: 22,515.75380
Overall Steps per Second: 16,742.51011

Timestep Collection Time: 2.22173
Timestep Consumption Time: 0.76611
PPO Batch Consumption Time: 0.05906
Total Iteration Time: 2.98784

Cumulative Model Updates: 21,590
Cumulative Timesteps: 360,474,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 360474192...
Checkpoint 360474192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,764.57154
Policy Entropy: 0.77491
Value Function Loss: 0.05632

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.03010
Policy Update Magnitude: 0.03272
Value Function Update Magnitude: 0.06412

Collected Steps per Second: 20,234.27146
Overall Steps per Second: 14,785.11641

Timestep Collection Time: 2.47125
Timestep Consumption Time: 0.91080
PPO Batch Consumption Time: 0.08573
Total Iteration Time: 3.38205

Cumulative Model Updates: 21,593
Cumulative Timesteps: 360,524,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,374.11174
Policy Entropy: 0.77297
Value Function Loss: 0.05821

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02221
Policy Update Magnitude: 0.03089
Value Function Update Magnitude: 0.06895

Collected Steps per Second: 22,546.04145
Overall Steps per Second: 16,656.55640

Timestep Collection Time: 2.21884
Timestep Consumption Time: 0.78454
PPO Batch Consumption Time: 0.05767
Total Iteration Time: 3.00338

Cumulative Model Updates: 21,596
Cumulative Timesteps: 360,574,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 360574222...
Checkpoint 360574222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,890.13442
Policy Entropy: 0.77412
Value Function Loss: 0.06286

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01847
Policy Update Magnitude: 0.03070
Value Function Update Magnitude: 0.06769

Collected Steps per Second: 20,097.09591
Overall Steps per Second: 14,848.96466

Timestep Collection Time: 2.48822
Timestep Consumption Time: 0.87942
PPO Batch Consumption Time: 0.08946
Total Iteration Time: 3.36764

Cumulative Model Updates: 21,599
Cumulative Timesteps: 360,624,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,988.98187
Policy Entropy: 0.77931
Value Function Loss: 0.07074

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03277
Policy Update Magnitude: 0.03155
Value Function Update Magnitude: 0.06340

Collected Steps per Second: 22,362.78243
Overall Steps per Second: 16,466.62145

Timestep Collection Time: 2.23604
Timestep Consumption Time: 0.80065
PPO Batch Consumption Time: 0.05927
Total Iteration Time: 3.03669

Cumulative Model Updates: 21,602
Cumulative Timesteps: 360,674,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 360674232...
Checkpoint 360674232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,082.13319
Policy Entropy: 0.78061
Value Function Loss: 0.07618

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02397
Policy Update Magnitude: 0.03289
Value Function Update Magnitude: 0.05928

Collected Steps per Second: 20,815.16460
Overall Steps per Second: 14,974.27128

Timestep Collection Time: 2.40248
Timestep Consumption Time: 0.93712
PPO Batch Consumption Time: 0.09392
Total Iteration Time: 3.33959

Cumulative Model Updates: 21,605
Cumulative Timesteps: 360,724,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,392.94476
Policy Entropy: 0.79406
Value Function Loss: 0.07412

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.03025
Policy Update Magnitude: 0.03348
Value Function Update Magnitude: 0.05506

Collected Steps per Second: 22,173.11020
Overall Steps per Second: 16,349.64791

Timestep Collection Time: 2.25589
Timestep Consumption Time: 0.80351
PPO Batch Consumption Time: 0.06286
Total Iteration Time: 3.05939

Cumulative Model Updates: 21,608
Cumulative Timesteps: 360,774,260

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 360774260...
Checkpoint 360774260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,284.24823
Policy Entropy: 0.78363
Value Function Loss: 0.06607

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01564
Policy Update Magnitude: 0.03484
Value Function Update Magnitude: 0.05989

Collected Steps per Second: 22,407.99137
Overall Steps per Second: 16,487.35109

Timestep Collection Time: 2.23233
Timestep Consumption Time: 0.80163
PPO Batch Consumption Time: 0.06247
Total Iteration Time: 3.03396

Cumulative Model Updates: 21,611
Cumulative Timesteps: 360,824,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,116.93193
Policy Entropy: 0.78394
Value Function Loss: 0.05318

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02941
Policy Update Magnitude: 0.03072
Value Function Update Magnitude: 0.05912

Collected Steps per Second: 22,504.94216
Overall Steps per Second: 16,601.58950

Timestep Collection Time: 2.22236
Timestep Consumption Time: 0.79025
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 3.01260

Cumulative Model Updates: 21,614
Cumulative Timesteps: 360,874,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 360874296...
Checkpoint 360874296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,179.79215
Policy Entropy: 0.77039
Value Function Loss: 0.06096

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01941
Policy Update Magnitude: 0.02879
Value Function Update Magnitude: 0.06008

Collected Steps per Second: 21,240.10732
Overall Steps per Second: 15,421.71629

Timestep Collection Time: 2.35470
Timestep Consumption Time: 0.88839
PPO Batch Consumption Time: 0.08283
Total Iteration Time: 3.24309

Cumulative Model Updates: 21,617
Cumulative Timesteps: 360,924,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,001.94413
Policy Entropy: 0.77604
Value Function Loss: 0.06577

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02240
Policy Update Magnitude: 0.02797
Value Function Update Magnitude: 0.05866

Collected Steps per Second: 22,617.84632
Overall Steps per Second: 16,757.38305

Timestep Collection Time: 2.21091
Timestep Consumption Time: 0.77321
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 2.98412

Cumulative Model Updates: 21,620
Cumulative Timesteps: 360,974,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 360974316...
Checkpoint 360974316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,747.29366
Policy Entropy: 0.78760
Value Function Loss: 0.06568

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01035
Policy Update Magnitude: 0.02948
Value Function Update Magnitude: 0.05775

Collected Steps per Second: 20,286.37817
Overall Steps per Second: 14,733.25754

Timestep Collection Time: 2.46530
Timestep Consumption Time: 0.92920
PPO Batch Consumption Time: 0.09155
Total Iteration Time: 3.39450

Cumulative Model Updates: 21,623
Cumulative Timesteps: 361,024,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,314.56335
Policy Entropy: 0.80502
Value Function Loss: 0.06075

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01374
Policy Update Magnitude: 0.03360
Value Function Update Magnitude: 0.06509

Collected Steps per Second: 22,734.76633
Overall Steps per Second: 16,914.57275

Timestep Collection Time: 2.19945
Timestep Consumption Time: 0.75682
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 2.95627

Cumulative Model Updates: 21,626
Cumulative Timesteps: 361,074,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 361074332...
Checkpoint 361074332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,332.27578
Policy Entropy: 0.82084
Value Function Loss: 0.05727

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02536
Policy Update Magnitude: 0.03296
Value Function Update Magnitude: 0.06716

Collected Steps per Second: 19,779.77369
Overall Steps per Second: 14,624.41585

Timestep Collection Time: 2.52945
Timestep Consumption Time: 0.89168
PPO Batch Consumption Time: 0.08098
Total Iteration Time: 3.42113

Cumulative Model Updates: 21,629
Cumulative Timesteps: 361,124,364

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,533.63786
Policy Entropy: 0.81086
Value Function Loss: 0.06823

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02822
Policy Update Magnitude: 0.03280
Value Function Update Magnitude: 0.06942

Collected Steps per Second: 22,839.52557
Overall Steps per Second: 16,982.72057

Timestep Collection Time: 2.18954
Timestep Consumption Time: 0.75510
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 2.94464

Cumulative Model Updates: 21,632
Cumulative Timesteps: 361,174,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 361174372...
Checkpoint 361174372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,881.71637
Policy Entropy: 0.79942
Value Function Loss: 0.06325

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02586
Policy Update Magnitude: 0.03488
Value Function Update Magnitude: 0.06872

Collected Steps per Second: 19,959.05477
Overall Steps per Second: 14,638.83522

Timestep Collection Time: 2.50603
Timestep Consumption Time: 0.91077
PPO Batch Consumption Time: 0.08854
Total Iteration Time: 3.41680

Cumulative Model Updates: 21,635
Cumulative Timesteps: 361,224,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,289.20146
Policy Entropy: 0.79753
Value Function Loss: 0.06919

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03785
Policy Update Magnitude: 0.03325
Value Function Update Magnitude: 0.06661

Collected Steps per Second: 22,624.36273
Overall Steps per Second: 16,677.77796

Timestep Collection Time: 2.21001
Timestep Consumption Time: 0.78799
PPO Batch Consumption Time: 0.05809
Total Iteration Time: 2.99800

Cumulative Model Updates: 21,638
Cumulative Timesteps: 361,274,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 361274390...
Checkpoint 361274390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,612.93947
Policy Entropy: 0.80478
Value Function Loss: 0.06982

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02986
Policy Update Magnitude: 0.03119
Value Function Update Magnitude: 0.06312

Collected Steps per Second: 20,613.03587
Overall Steps per Second: 14,817.53027

Timestep Collection Time: 2.42643
Timestep Consumption Time: 0.94904
PPO Batch Consumption Time: 0.11248
Total Iteration Time: 3.37546

Cumulative Model Updates: 21,641
Cumulative Timesteps: 361,324,406

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,576.63204
Policy Entropy: 0.81512
Value Function Loss: 0.06717

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03393
Policy Update Magnitude: 0.03157
Value Function Update Magnitude: 0.06384

Collected Steps per Second: 22,126.21604
Overall Steps per Second: 16,331.41429

Timestep Collection Time: 2.26076
Timestep Consumption Time: 0.80217
PPO Batch Consumption Time: 0.06305
Total Iteration Time: 3.06293

Cumulative Model Updates: 21,644
Cumulative Timesteps: 361,374,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 361374428...
Checkpoint 361374428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,313.79894
Policy Entropy: 0.80603
Value Function Loss: 0.07189

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02268
Policy Update Magnitude: 0.03169
Value Function Update Magnitude: 0.06710

Collected Steps per Second: 20,611.56490
Overall Steps per Second: 15,058.63117

Timestep Collection Time: 2.42640
Timestep Consumption Time: 0.89475
PPO Batch Consumption Time: 0.08150
Total Iteration Time: 3.32115

Cumulative Model Updates: 21,647
Cumulative Timesteps: 361,424,440

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,934.57847
Policy Entropy: 0.80852
Value Function Loss: 0.06122

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02749
Policy Update Magnitude: 0.03233
Value Function Update Magnitude: 0.06777

Collected Steps per Second: 22,751.53853
Overall Steps per Second: 16,820.09974

Timestep Collection Time: 2.19801
Timestep Consumption Time: 0.77510
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 2.97311

Cumulative Model Updates: 21,650
Cumulative Timesteps: 361,474,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 361474448...
Checkpoint 361474448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,917.76280
Policy Entropy: 0.80580
Value Function Loss: 0.06026

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03261
Policy Update Magnitude: 0.03122
Value Function Update Magnitude: 0.06122

Collected Steps per Second: 20,140.31794
Overall Steps per Second: 14,731.11533

Timestep Collection Time: 2.48387
Timestep Consumption Time: 0.91207
PPO Batch Consumption Time: 0.09649
Total Iteration Time: 3.39594

Cumulative Model Updates: 21,653
Cumulative Timesteps: 361,524,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,345.75515
Policy Entropy: 0.81052
Value Function Loss: 0.05388

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.02901
Value Function Update Magnitude: 0.06013

Collected Steps per Second: 22,611.88629
Overall Steps per Second: 16,595.50216

Timestep Collection Time: 2.21158
Timestep Consumption Time: 0.80177
PPO Batch Consumption Time: 0.06045
Total Iteration Time: 3.01335

Cumulative Model Updates: 21,656
Cumulative Timesteps: 361,574,482

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 361574482...
Checkpoint 361574482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,421.88355
Policy Entropy: 0.82576
Value Function Loss: 0.05651

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02746
Policy Update Magnitude: 0.02769
Value Function Update Magnitude: 0.05861

Collected Steps per Second: 20,154.74378
Overall Steps per Second: 14,709.48805

Timestep Collection Time: 2.48130
Timestep Consumption Time: 0.91854
PPO Batch Consumption Time: 0.08671
Total Iteration Time: 3.39985

Cumulative Model Updates: 21,659
Cumulative Timesteps: 361,624,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,926.68770
Policy Entropy: 0.83367
Value Function Loss: 0.05716

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02155
Policy Update Magnitude: 0.02982
Value Function Update Magnitude: 0.05555

Collected Steps per Second: 22,149.90862
Overall Steps per Second: 16,296.90353

Timestep Collection Time: 2.25816
Timestep Consumption Time: 0.81101
PPO Batch Consumption Time: 0.06249
Total Iteration Time: 3.06917

Cumulative Model Updates: 21,662
Cumulative Timesteps: 361,674,510

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 361674510...
Checkpoint 361674510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,874.86371
Policy Entropy: 0.84181
Value Function Loss: 0.05635

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01619
Policy Update Magnitude: 0.02963
Value Function Update Magnitude: 0.05091

Collected Steps per Second: 22,459.24361
Overall Steps per Second: 16,579.27234

Timestep Collection Time: 2.22652
Timestep Consumption Time: 0.78965
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 3.01618

Cumulative Model Updates: 21,665
Cumulative Timesteps: 361,724,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,395.69405
Policy Entropy: 0.82833
Value Function Loss: 0.06011

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.03055
Policy Update Magnitude: 0.02931
Value Function Update Magnitude: 0.04439

Collected Steps per Second: 20,315.44874
Overall Steps per Second: 14,600.29155

Timestep Collection Time: 2.46207
Timestep Consumption Time: 0.96375
PPO Batch Consumption Time: 0.10994
Total Iteration Time: 3.42582

Cumulative Model Updates: 21,668
Cumulative Timesteps: 361,774,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 361774534...
Checkpoint 361774534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,974.14023
Policy Entropy: 0.82157
Value Function Loss: 0.06346

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03216
Policy Update Magnitude: 0.03043
Value Function Update Magnitude: 0.04756

Collected Steps per Second: 22,421.98586
Overall Steps per Second: 16,485.01814

Timestep Collection Time: 2.23147
Timestep Consumption Time: 0.80365
PPO Batch Consumption Time: 0.06119
Total Iteration Time: 3.03512

Cumulative Model Updates: 21,671
Cumulative Timesteps: 361,824,568

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,185.42672
Policy Entropy: 0.80424
Value Function Loss: 0.06831

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04158
Policy Update Magnitude: 0.02845
Value Function Update Magnitude: 0.04652

Collected Steps per Second: 20,387.73953
Overall Steps per Second: 14,909.35388

Timestep Collection Time: 2.45383
Timestep Consumption Time: 0.90165
PPO Batch Consumption Time: 0.08193
Total Iteration Time: 3.35548

Cumulative Model Updates: 21,674
Cumulative Timesteps: 361,874,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 361874596...
Checkpoint 361874596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,425.35257
Policy Entropy: 0.79997
Value Function Loss: 0.07216

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02392
Policy Update Magnitude: 0.02947
Value Function Update Magnitude: 0.05445

Collected Steps per Second: 22,138.44193
Overall Steps per Second: 16,377.78170

Timestep Collection Time: 2.25906
Timestep Consumption Time: 0.79459
PPO Batch Consumption Time: 0.06123
Total Iteration Time: 3.05365

Cumulative Model Updates: 21,677
Cumulative Timesteps: 361,924,608

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,594.29989
Policy Entropy: 0.78445
Value Function Loss: 0.07823

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01527
Policy Update Magnitude: 0.03244
Value Function Update Magnitude: 0.05206

Collected Steps per Second: 21,315.91396
Overall Steps per Second: 15,082.51005

Timestep Collection Time: 2.34632
Timestep Consumption Time: 0.96970
PPO Batch Consumption Time: 0.11217
Total Iteration Time: 3.31603

Cumulative Model Updates: 21,680
Cumulative Timesteps: 361,974,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 361974622...
Checkpoint 361974622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,604.59283
Policy Entropy: 0.78551
Value Function Loss: 0.08306

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03923
Policy Update Magnitude: 0.03098
Value Function Update Magnitude: 0.05184

Collected Steps per Second: 22,119.80882
Overall Steps per Second: 16,309.79025

Timestep Collection Time: 2.26060
Timestep Consumption Time: 0.80529
PPO Batch Consumption Time: 0.06147
Total Iteration Time: 3.06589

Cumulative Model Updates: 21,683
Cumulative Timesteps: 362,024,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,179.17992
Policy Entropy: 0.77808
Value Function Loss: 0.08605

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.03119
Value Function Update Magnitude: 0.04878

Collected Steps per Second: 22,577.50336
Overall Steps per Second: 15,982.84699

Timestep Collection Time: 2.21539
Timestep Consumption Time: 0.91409
PPO Batch Consumption Time: 0.08146
Total Iteration Time: 3.12948

Cumulative Model Updates: 21,686
Cumulative Timesteps: 362,074,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 362074644...
Checkpoint 362074644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,773.35931
Policy Entropy: 0.79391
Value Function Loss: 0.08633

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03505
Policy Update Magnitude: 0.03365
Value Function Update Magnitude: 0.05298

Collected Steps per Second: 22,485.72925
Overall Steps per Second: 16,671.94840

Timestep Collection Time: 2.22408
Timestep Consumption Time: 0.77557
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 2.99965

Cumulative Model Updates: 21,689
Cumulative Timesteps: 362,124,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,680.40185
Policy Entropy: 0.79611
Value Function Loss: 0.08042

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03369
Policy Update Magnitude: 0.03195
Value Function Update Magnitude: 0.06008

Collected Steps per Second: 20,689.23261
Overall Steps per Second: 14,887.43402

Timestep Collection Time: 2.41710
Timestep Consumption Time: 0.94197
PPO Batch Consumption Time: 0.09527
Total Iteration Time: 3.35907

Cumulative Model Updates: 21,692
Cumulative Timesteps: 362,174,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 362174662...
Checkpoint 362174662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,851.56106
Policy Entropy: 0.81190
Value Function Loss: 0.07155

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02361
Policy Update Magnitude: 0.03583
Value Function Update Magnitude: 0.05728

Collected Steps per Second: 22,248.54903
Overall Steps per Second: 16,449.24959

Timestep Collection Time: 2.24824
Timestep Consumption Time: 0.79263
PPO Batch Consumption Time: 0.06291
Total Iteration Time: 3.04087

Cumulative Model Updates: 21,695
Cumulative Timesteps: 362,224,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,599.18466
Policy Entropy: 0.80710
Value Function Loss: 0.05831

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01933
Policy Update Magnitude: 0.03367
Value Function Update Magnitude: 0.05288

Collected Steps per Second: 20,681.87663
Overall Steps per Second: 15,012.22141

Timestep Collection Time: 2.41806
Timestep Consumption Time: 0.91323
PPO Batch Consumption Time: 0.08341
Total Iteration Time: 3.33129

Cumulative Model Updates: 21,698
Cumulative Timesteps: 362,274,692

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 362274692...
Checkpoint 362274692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,499.32315
Policy Entropy: 0.81659
Value Function Loss: 0.06199

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02628
Policy Update Magnitude: 0.03059
Value Function Update Magnitude: 0.05184

Collected Steps per Second: 22,132.71465
Overall Steps per Second: 16,520.79962

Timestep Collection Time: 2.26109
Timestep Consumption Time: 0.76806
PPO Batch Consumption Time: 0.06373
Total Iteration Time: 3.02915

Cumulative Model Updates: 21,701
Cumulative Timesteps: 362,324,736

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,699.18992
Policy Entropy: 0.81650
Value Function Loss: 0.06798

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03025
Policy Update Magnitude: 0.03056
Value Function Update Magnitude: 0.05687

Collected Steps per Second: 21,255.13736
Overall Steps per Second: 15,050.83493

Timestep Collection Time: 2.35369
Timestep Consumption Time: 0.97025
PPO Batch Consumption Time: 0.11735
Total Iteration Time: 3.32394

Cumulative Model Updates: 21,704
Cumulative Timesteps: 362,374,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 362374764...
Checkpoint 362374764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,210.87784
Policy Entropy: 0.81908
Value Function Loss: 0.07307

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02881
Policy Update Magnitude: 0.03050
Value Function Update Magnitude: 0.06501

Collected Steps per Second: 22,670.58863
Overall Steps per Second: 16,934.57515

Timestep Collection Time: 2.20665
Timestep Consumption Time: 0.74743
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 2.95407

Cumulative Model Updates: 21,707
Cumulative Timesteps: 362,424,790

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,689.91875
Policy Entropy: 0.82011
Value Function Loss: 0.07328

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.04020
Policy Update Magnitude: 0.03059
Value Function Update Magnitude: 0.05903

Collected Steps per Second: 20,403.70247
Overall Steps per Second: 14,613.24336

Timestep Collection Time: 2.45083
Timestep Consumption Time: 0.97113
PPO Batch Consumption Time: 0.12075
Total Iteration Time: 3.42196

Cumulative Model Updates: 21,710
Cumulative Timesteps: 362,474,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 362474796...
Checkpoint 362474796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,599.07995
Policy Entropy: 0.82418
Value Function Loss: 0.06637

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03288
Policy Update Magnitude: 0.03017
Value Function Update Magnitude: 0.05664

Collected Steps per Second: 22,680.97793
Overall Steps per Second: 16,751.56542

Timestep Collection Time: 2.20528
Timestep Consumption Time: 0.78059
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 2.98587

Cumulative Model Updates: 21,713
Cumulative Timesteps: 362,524,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,722.68024
Policy Entropy: 0.82087
Value Function Loss: 0.06739

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02874
Policy Update Magnitude: 0.03091
Value Function Update Magnitude: 0.05537

Collected Steps per Second: 20,245.21434
Overall Steps per Second: 14,670.12725

Timestep Collection Time: 2.47120
Timestep Consumption Time: 0.93913
PPO Batch Consumption Time: 0.09761
Total Iteration Time: 3.41033

Cumulative Model Updates: 21,716
Cumulative Timesteps: 362,574,844

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 362574844...
Checkpoint 362574844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,543.79558
Policy Entropy: 0.82437
Value Function Loss: 0.06947

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01847
Policy Update Magnitude: 0.03207
Value Function Update Magnitude: 0.05116

Collected Steps per Second: 21,714.34898
Overall Steps per Second: 16,164.40139

Timestep Collection Time: 2.30318
Timestep Consumption Time: 0.79078
PPO Batch Consumption Time: 0.05906
Total Iteration Time: 3.09396

Cumulative Model Updates: 21,719
Cumulative Timesteps: 362,624,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,880.77961
Policy Entropy: 0.82507
Value Function Loss: 0.06909

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01845
Policy Update Magnitude: 0.03074
Value Function Update Magnitude: 0.04774

Collected Steps per Second: 22,437.61789
Overall Steps per Second: 16,543.29923

Timestep Collection Time: 2.22902
Timestep Consumption Time: 0.79419
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 3.02322

Cumulative Model Updates: 21,722
Cumulative Timesteps: 362,674,870

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 362674870...
Checkpoint 362674870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,846.82260
Policy Entropy: 0.81755
Value Function Loss: 0.07109

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01901
Policy Update Magnitude: 0.03153
Value Function Update Magnitude: 0.05488

Collected Steps per Second: 21,131.10286
Overall Steps per Second: 15,218.28399

Timestep Collection Time: 2.36732
Timestep Consumption Time: 0.91978
PPO Batch Consumption Time: 0.08691
Total Iteration Time: 3.28710

Cumulative Model Updates: 21,725
Cumulative Timesteps: 362,724,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,082.41669
Policy Entropy: 0.81400
Value Function Loss: 0.07489

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.01093
Policy Update Magnitude: 0.03379
Value Function Update Magnitude: 0.05465

Collected Steps per Second: 22,670.70292
Overall Steps per Second: 16,615.16789

Timestep Collection Time: 2.20584
Timestep Consumption Time: 0.80394
PPO Batch Consumption Time: 0.05995
Total Iteration Time: 3.00978

Cumulative Model Updates: 21,728
Cumulative Timesteps: 362,774,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 362774902...
Checkpoint 362774902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,224.06944
Policy Entropy: 0.81606
Value Function Loss: 0.07612

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03081
Policy Update Magnitude: 0.03278
Value Function Update Magnitude: 0.06132

Collected Steps per Second: 21,141.14965
Overall Steps per Second: 15,073.32511

Timestep Collection Time: 2.36647
Timestep Consumption Time: 0.95263
PPO Batch Consumption Time: 0.09507
Total Iteration Time: 3.31911

Cumulative Model Updates: 21,731
Cumulative Timesteps: 362,824,932

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,065.04212
Policy Entropy: 0.80546
Value Function Loss: 0.07769

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02779
Policy Update Magnitude: 0.03192
Value Function Update Magnitude: 0.06931

Collected Steps per Second: 22,084.92557
Overall Steps per Second: 16,377.74283

Timestep Collection Time: 2.26535
Timestep Consumption Time: 0.78941
PPO Batch Consumption Time: 0.06555
Total Iteration Time: 3.05476

Cumulative Model Updates: 21,734
Cumulative Timesteps: 362,874,962

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 362874962...
Checkpoint 362874962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,177.13356
Policy Entropy: 0.81718
Value Function Loss: 0.06535

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.03452
Value Function Update Magnitude: 0.06562

Collected Steps per Second: 19,957.55401
Overall Steps per Second: 14,283.31956

Timestep Collection Time: 2.50742
Timestep Consumption Time: 0.99611
PPO Batch Consumption Time: 0.11814
Total Iteration Time: 3.50353

Cumulative Model Updates: 21,737
Cumulative Timesteps: 362,925,004

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,878.99650
Policy Entropy: 0.82900
Value Function Loss: 0.06537

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02182
Policy Update Magnitude: 0.03184
Value Function Update Magnitude: 0.06441

Collected Steps per Second: 22,970.40097
Overall Steps per Second: 16,886.68508

Timestep Collection Time: 2.17724
Timestep Consumption Time: 0.78439
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 2.96162

Cumulative Model Updates: 21,740
Cumulative Timesteps: 362,975,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 362975016...
Checkpoint 362975016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,029.72172
Policy Entropy: 0.83534
Value Function Loss: 0.06099

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01819
Policy Update Magnitude: 0.02991
Value Function Update Magnitude: 0.06122

Collected Steps per Second: 19,940.47686
Overall Steps per Second: 14,617.25941

Timestep Collection Time: 2.50766
Timestep Consumption Time: 0.91322
PPO Batch Consumption Time: 0.09339
Total Iteration Time: 3.42089

Cumulative Model Updates: 21,743
Cumulative Timesteps: 363,025,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,945.09560
Policy Entropy: 0.84680
Value Function Loss: 0.05966

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02155
Policy Update Magnitude: 0.02772
Value Function Update Magnitude: 0.06175

Collected Steps per Second: 22,385.68119
Overall Steps per Second: 16,401.94500

Timestep Collection Time: 2.23393
Timestep Consumption Time: 0.81498
PPO Batch Consumption Time: 0.06269
Total Iteration Time: 3.04891

Cumulative Model Updates: 21,746
Cumulative Timesteps: 363,075,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 363075028...
Checkpoint 363075028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,736.95523
Policy Entropy: 0.83091
Value Function Loss: 0.05971

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01757
Policy Update Magnitude: 0.02715
Value Function Update Magnitude: 0.05870

Collected Steps per Second: 20,537.57400
Overall Steps per Second: 15,046.02361

Timestep Collection Time: 2.43476
Timestep Consumption Time: 0.88865
PPO Batch Consumption Time: 0.08003
Total Iteration Time: 3.32340

Cumulative Model Updates: 21,749
Cumulative Timesteps: 363,125,032

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,233.81300
Policy Entropy: 0.85107
Value Function Loss: 0.05889

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01443
Policy Update Magnitude: 0.02810
Value Function Update Magnitude: 0.05562

Collected Steps per Second: 22,499.15201
Overall Steps per Second: 16,556.05630

Timestep Collection Time: 2.22319
Timestep Consumption Time: 0.79806
PPO Batch Consumption Time: 0.05922
Total Iteration Time: 3.02125

Cumulative Model Updates: 21,752
Cumulative Timesteps: 363,175,052

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 363175052...
Checkpoint 363175052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,042.60298
Policy Entropy: 0.84568
Value Function Loss: 0.06241

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01553
Policy Update Magnitude: 0.02875
Value Function Update Magnitude: 0.05034

Collected Steps per Second: 20,038.29703
Overall Steps per Second: 14,172.96601

Timestep Collection Time: 2.49612
Timestep Consumption Time: 1.03299
PPO Batch Consumption Time: 0.11580
Total Iteration Time: 3.52911

Cumulative Model Updates: 21,755
Cumulative Timesteps: 363,225,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,754.47717
Policy Entropy: 0.85791
Value Function Loss: 0.05705

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01577
Policy Update Magnitude: 0.03010
Value Function Update Magnitude: 0.04702

Collected Steps per Second: 22,778.94681
Overall Steps per Second: 16,664.56508

Timestep Collection Time: 2.19598
Timestep Consumption Time: 0.80572
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 3.00170

Cumulative Model Updates: 21,758
Cumulative Timesteps: 363,275,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 363275092...
Checkpoint 363275092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,198.17157
Policy Entropy: 0.86625
Value Function Loss: 0.05579

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02849
Policy Update Magnitude: 0.02956
Value Function Update Magnitude: 0.04475

Collected Steps per Second: 20,290.24607
Overall Steps per Second: 14,739.23504

Timestep Collection Time: 2.46562
Timestep Consumption Time: 0.92859
PPO Batch Consumption Time: 0.08965
Total Iteration Time: 3.39421

Cumulative Model Updates: 21,761
Cumulative Timesteps: 363,325,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,095.82907
Policy Entropy: 0.85969
Value Function Loss: 0.05712

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03687
Policy Update Magnitude: 0.02861
Value Function Update Magnitude: 0.04495

Collected Steps per Second: 22,514.62618
Overall Steps per Second: 16,417.10748

Timestep Collection Time: 2.22078
Timestep Consumption Time: 0.82482
PPO Batch Consumption Time: 0.06165
Total Iteration Time: 3.04560

Cumulative Model Updates: 21,764
Cumulative Timesteps: 363,375,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 363375120...
Checkpoint 363375120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,801.55595
Policy Entropy: 0.85065
Value Function Loss: 0.06238

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.02871
Value Function Update Magnitude: 0.04676

Collected Steps per Second: 19,758.79249
Overall Steps per Second: 14,197.45070

Timestep Collection Time: 2.53194
Timestep Consumption Time: 0.99180
PPO Batch Consumption Time: 0.11531
Total Iteration Time: 3.52373

Cumulative Model Updates: 21,767
Cumulative Timesteps: 363,425,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,992.21580
Policy Entropy: 0.84625
Value Function Loss: 0.06325

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02256
Policy Update Magnitude: 0.03019
Value Function Update Magnitude: 0.04494

Collected Steps per Second: 22,345.95329
Overall Steps per Second: 16,569.05677

Timestep Collection Time: 2.23772
Timestep Consumption Time: 0.78019
PPO Batch Consumption Time: 0.06006
Total Iteration Time: 3.01791

Cumulative Model Updates: 21,770
Cumulative Timesteps: 363,475,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 363475152...
Checkpoint 363475152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,446.86724
Policy Entropy: 0.84119
Value Function Loss: 0.06480

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01640
Policy Update Magnitude: 0.02952
Value Function Update Magnitude: 0.04904

Collected Steps per Second: 19,569.10955
Overall Steps per Second: 14,099.66344

Timestep Collection Time: 2.55648
Timestep Consumption Time: 0.99169
PPO Batch Consumption Time: 0.12237
Total Iteration Time: 3.54817

Cumulative Model Updates: 21,773
Cumulative Timesteps: 363,525,180

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,125.38205
Policy Entropy: 0.84063
Value Function Loss: 0.06654

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01829
Policy Update Magnitude: 0.02928
Value Function Update Magnitude: 0.04979

Collected Steps per Second: 22,790.72044
Overall Steps per Second: 16,850.65911

Timestep Collection Time: 2.19458
Timestep Consumption Time: 0.77362
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 2.96819

Cumulative Model Updates: 21,776
Cumulative Timesteps: 363,575,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 363575196...
Checkpoint 363575196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,804.54497
Policy Entropy: 0.83356
Value Function Loss: 0.06936

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01736
Policy Update Magnitude: 0.02921
Value Function Update Magnitude: 0.04762

Collected Steps per Second: 20,826.96370
Overall Steps per Second: 15,303.89210

Timestep Collection Time: 2.40169
Timestep Consumption Time: 0.86676
PPO Batch Consumption Time: 0.08624
Total Iteration Time: 3.26845

Cumulative Model Updates: 21,779
Cumulative Timesteps: 363,625,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,006.92942
Policy Entropy: 0.84252
Value Function Loss: 0.06253

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01907
Policy Update Magnitude: 0.02952
Value Function Update Magnitude: 0.04922

Collected Steps per Second: 22,906.76354
Overall Steps per Second: 16,863.97652

Timestep Collection Time: 2.18416
Timestep Consumption Time: 0.78264
PPO Batch Consumption Time: 0.05791
Total Iteration Time: 2.96680

Cumulative Model Updates: 21,782
Cumulative Timesteps: 363,675,248

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 363675248...
Checkpoint 363675248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,332.98495
Policy Entropy: 0.84869
Value Function Loss: 0.05336

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.03036
Value Function Update Magnitude: 0.04777

Collected Steps per Second: 20,261.85814
Overall Steps per Second: 14,916.04327

Timestep Collection Time: 2.46828
Timestep Consumption Time: 0.88462
PPO Batch Consumption Time: 0.08095
Total Iteration Time: 3.35290

Cumulative Model Updates: 21,785
Cumulative Timesteps: 363,725,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,609.76858
Policy Entropy: 0.86221
Value Function Loss: 0.04967

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03413
Policy Update Magnitude: 0.02905
Value Function Update Magnitude: 0.04904

Collected Steps per Second: 22,456.92737
Overall Steps per Second: 16,499.42372

Timestep Collection Time: 2.22773
Timestep Consumption Time: 0.80437
PPO Batch Consumption Time: 0.06025
Total Iteration Time: 3.03211

Cumulative Model Updates: 21,788
Cumulative Timesteps: 363,775,288

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 363775288...
Checkpoint 363775288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,126.21376
Policy Entropy: 0.85520
Value Function Loss: 0.05559

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04906
Policy Update Magnitude: 0.03019
Value Function Update Magnitude: 0.04296

Collected Steps per Second: 20,112.98453
Overall Steps per Second: 14,219.75452

Timestep Collection Time: 2.48655
Timestep Consumption Time: 1.03053
PPO Batch Consumption Time: 0.12593
Total Iteration Time: 3.51708

Cumulative Model Updates: 21,791
Cumulative Timesteps: 363,825,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,424.88350
Policy Entropy: 0.85229
Value Function Loss: 0.05881

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03885
Policy Update Magnitude: 0.03060
Value Function Update Magnitude: 0.04279

Collected Steps per Second: 22,760.63311
Overall Steps per Second: 16,493.84410

Timestep Collection Time: 2.19783
Timestep Consumption Time: 0.83506
PPO Batch Consumption Time: 0.05841
Total Iteration Time: 3.03289

Cumulative Model Updates: 21,794
Cumulative Timesteps: 363,875,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 363875324...
Checkpoint 363875324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,216.64194
Policy Entropy: 0.84916
Value Function Loss: 0.05808

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04773
Policy Update Magnitude: 0.03051
Value Function Update Magnitude: 0.03958

Collected Steps per Second: 19,923.99921
Overall Steps per Second: 14,126.58378

Timestep Collection Time: 2.50974
Timestep Consumption Time: 1.02997
PPO Batch Consumption Time: 0.12497
Total Iteration Time: 3.53971

Cumulative Model Updates: 21,797
Cumulative Timesteps: 363,925,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,218.91112
Policy Entropy: 0.83909
Value Function Loss: 0.05921

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04838
Policy Update Magnitude: 0.02966
Value Function Update Magnitude: 0.04466

Collected Steps per Second: 22,892.12374
Overall Steps per Second: 16,831.30139

Timestep Collection Time: 2.18477
Timestep Consumption Time: 0.78672
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 2.97149

Cumulative Model Updates: 21,800
Cumulative Timesteps: 363,975,342

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 363975342...
Checkpoint 363975342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,499.60838
Policy Entropy: 0.83806
Value Function Loss: 0.06186

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03905
Policy Update Magnitude: 0.02891
Value Function Update Magnitude: 0.04459

Collected Steps per Second: 20,272.55084
Overall Steps per Second: 14,626.70689

Timestep Collection Time: 2.46678
Timestep Consumption Time: 0.95217
PPO Batch Consumption Time: 0.10286
Total Iteration Time: 3.41895

Cumulative Model Updates: 21,803
Cumulative Timesteps: 364,025,350

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,212.59999
Policy Entropy: 0.83163
Value Function Loss: 0.06314

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01804
Policy Update Magnitude: 0.02878
Value Function Update Magnitude: 0.05025

Collected Steps per Second: 22,487.95444
Overall Steps per Second: 16,491.78453

Timestep Collection Time: 2.22404
Timestep Consumption Time: 0.80863
PPO Batch Consumption Time: 0.06094
Total Iteration Time: 3.03266

Cumulative Model Updates: 21,806
Cumulative Timesteps: 364,075,364

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 364075364...
Checkpoint 364075364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,580.11801
Policy Entropy: 0.84306
Value Function Loss: 0.06482

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01517
Policy Update Magnitude: 0.03066
Value Function Update Magnitude: 0.05090

Collected Steps per Second: 20,674.20997
Overall Steps per Second: 14,948.22250

Timestep Collection Time: 2.41847
Timestep Consumption Time: 0.92641
PPO Batch Consumption Time: 0.08907
Total Iteration Time: 3.34488

Cumulative Model Updates: 21,809
Cumulative Timesteps: 364,125,364

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,306.13968
Policy Entropy: 0.84095
Value Function Loss: 0.06661

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.03058
Value Function Update Magnitude: 0.05138

Collected Steps per Second: 22,062.62526
Overall Steps per Second: 16,357.07092

Timestep Collection Time: 2.26755
Timestep Consumption Time: 0.79095
PPO Batch Consumption Time: 0.05854
Total Iteration Time: 3.05849

Cumulative Model Updates: 21,812
Cumulative Timesteps: 364,175,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 364175392...
Checkpoint 364175392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,599.79339
Policy Entropy: 0.83751
Value Function Loss: 0.06786

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02208
Policy Update Magnitude: 0.03053
Value Function Update Magnitude: 0.04684

Collected Steps per Second: 21,003.48735
Overall Steps per Second: 15,098.62324

Timestep Collection Time: 2.38160
Timestep Consumption Time: 0.93141
PPO Batch Consumption Time: 0.09741
Total Iteration Time: 3.31302

Cumulative Model Updates: 21,815
Cumulative Timesteps: 364,225,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,894.24307
Policy Entropy: 0.83101
Value Function Loss: 0.06353

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03209
Policy Update Magnitude: 0.03034
Value Function Update Magnitude: 0.04427

Collected Steps per Second: 22,676.92671
Overall Steps per Second: 16,634.75339

Timestep Collection Time: 2.20515
Timestep Consumption Time: 0.80097
PPO Batch Consumption Time: 0.05824
Total Iteration Time: 3.00612

Cumulative Model Updates: 21,818
Cumulative Timesteps: 364,275,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 364275420...
Checkpoint 364275420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,947.63499
Policy Entropy: 0.83070
Value Function Loss: 0.05745

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02713
Policy Update Magnitude: 0.03002
Value Function Update Magnitude: 0.04965

Collected Steps per Second: 19,943.10252
Overall Steps per Second: 14,639.90270

Timestep Collection Time: 2.50834
Timestep Consumption Time: 0.90863
PPO Batch Consumption Time: 0.08759
Total Iteration Time: 3.41696

Cumulative Model Updates: 21,821
Cumulative Timesteps: 364,325,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,074.75397
Policy Entropy: 0.83534
Value Function Loss: 0.05866

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04431
Policy Update Magnitude: 0.02764
Value Function Update Magnitude: 0.04450

Collected Steps per Second: 22,175.67237
Overall Steps per Second: 16,256.69428

Timestep Collection Time: 2.25526
Timestep Consumption Time: 0.82113
PPO Batch Consumption Time: 0.06722
Total Iteration Time: 3.07639

Cumulative Model Updates: 21,824
Cumulative Timesteps: 364,375,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 364375456...
Checkpoint 364375456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,898.88658
Policy Entropy: 0.84006
Value Function Loss: 0.06230

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01793
Policy Update Magnitude: 0.02814
Value Function Update Magnitude: 0.04230

Collected Steps per Second: 21,977.22983
Overall Steps per Second: 16,154.69999

Timestep Collection Time: 2.27508
Timestep Consumption Time: 0.81999
PPO Batch Consumption Time: 0.06340
Total Iteration Time: 3.09507

Cumulative Model Updates: 21,827
Cumulative Timesteps: 364,425,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,697.14344
Policy Entropy: 0.84531
Value Function Loss: 0.06722

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01925
Policy Update Magnitude: 0.02996
Value Function Update Magnitude: 0.04690

Collected Steps per Second: 19,592.89261
Overall Steps per Second: 14,092.34834

Timestep Collection Time: 2.55195
Timestep Consumption Time: 0.99608
PPO Batch Consumption Time: 0.11189
Total Iteration Time: 3.54802

Cumulative Model Updates: 21,830
Cumulative Timesteps: 364,475,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 364475456...
Checkpoint 364475456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,498.03645
Policy Entropy: 0.83455
Value Function Loss: 0.07030

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02450
Policy Update Magnitude: 0.03105
Value Function Update Magnitude: 0.04964

Collected Steps per Second: 22,368.92244
Overall Steps per Second: 16,419.78632

Timestep Collection Time: 2.23694
Timestep Consumption Time: 0.81048
PPO Batch Consumption Time: 0.06188
Total Iteration Time: 3.04742

Cumulative Model Updates: 21,833
Cumulative Timesteps: 364,525,494

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,899.56788
Policy Entropy: 0.83371
Value Function Loss: 0.07182

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03957
Policy Update Magnitude: 0.03049
Value Function Update Magnitude: 0.04752

Collected Steps per Second: 20,941.09797
Overall Steps per Second: 15,026.01424

Timestep Collection Time: 2.38765
Timestep Consumption Time: 0.93991
PPO Batch Consumption Time: 0.10152
Total Iteration Time: 3.32756

Cumulative Model Updates: 21,836
Cumulative Timesteps: 364,575,494

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 364575494...
Checkpoint 364575494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,182.38915
Policy Entropy: 0.83900
Value Function Loss: 0.07387

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03456
Policy Update Magnitude: 0.03158
Value Function Update Magnitude: 0.05114

Collected Steps per Second: 22,412.13592
Overall Steps per Second: 16,781.05500

Timestep Collection Time: 2.23218
Timestep Consumption Time: 0.74904
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 2.98122

Cumulative Model Updates: 21,839
Cumulative Timesteps: 364,625,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,591.41675
Policy Entropy: 0.84801
Value Function Loss: 0.07008

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02455
Policy Update Magnitude: 0.03286
Value Function Update Magnitude: 0.05260

Collected Steps per Second: 20,134.55082
Overall Steps per Second: 14,716.56704

Timestep Collection Time: 2.48379
Timestep Consumption Time: 0.91442
PPO Batch Consumption Time: 0.09115
Total Iteration Time: 3.39821

Cumulative Model Updates: 21,842
Cumulative Timesteps: 364,675,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 364675532...
Checkpoint 364675532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,579.83172
Policy Entropy: 0.84705
Value Function Loss: 0.06924

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03022
Policy Update Magnitude: 0.03421
Value Function Update Magnitude: 0.04925

Collected Steps per Second: 22,316.94904
Overall Steps per Second: 16,610.59787

Timestep Collection Time: 2.24135
Timestep Consumption Time: 0.76998
PPO Batch Consumption Time: 0.05977
Total Iteration Time: 3.01133

Cumulative Model Updates: 21,845
Cumulative Timesteps: 364,725,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,670.42702
Policy Entropy: 0.82978
Value Function Loss: 0.07295

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.05331
Policy Update Magnitude: 0.03322
Value Function Update Magnitude: 0.05879

Collected Steps per Second: 20,505.44932
Overall Steps per Second: 14,876.59130

Timestep Collection Time: 2.43916
Timestep Consumption Time: 0.92290
PPO Batch Consumption Time: 0.08537
Total Iteration Time: 3.36206

Cumulative Model Updates: 21,848
Cumulative Timesteps: 364,775,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 364775568...
Checkpoint 364775568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,010.79576
Policy Entropy: 0.83371
Value Function Loss: 0.07048

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04678
Policy Update Magnitude: 0.03105
Value Function Update Magnitude: 0.05412

Collected Steps per Second: 22,171.40260
Overall Steps per Second: 16,393.18896

Timestep Collection Time: 2.25543
Timestep Consumption Time: 0.79499
PPO Batch Consumption Time: 0.06038
Total Iteration Time: 3.05041

Cumulative Model Updates: 21,851
Cumulative Timesteps: 364,825,574

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,464.82875
Policy Entropy: 0.82637
Value Function Loss: 0.06666

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04665
Policy Update Magnitude: 0.03021
Value Function Update Magnitude: 0.04842

Collected Steps per Second: 20,296.41054
Overall Steps per Second: 14,874.68046

Timestep Collection Time: 2.46428
Timestep Consumption Time: 0.89821
PPO Batch Consumption Time: 0.08148
Total Iteration Time: 3.36249

Cumulative Model Updates: 21,854
Cumulative Timesteps: 364,875,590

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 364875590...
Checkpoint 364875590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,949.17153
Policy Entropy: 0.83679
Value Function Loss: 0.06046

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04212
Policy Update Magnitude: 0.02946
Value Function Update Magnitude: 0.04014

Collected Steps per Second: 22,334.50522
Overall Steps per Second: 16,458.06671

Timestep Collection Time: 2.23869
Timestep Consumption Time: 0.79934
PPO Batch Consumption Time: 0.06181
Total Iteration Time: 3.03802

Cumulative Model Updates: 21,857
Cumulative Timesteps: 364,925,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,476.77872
Policy Entropy: 0.82894
Value Function Loss: 0.06322

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02954
Policy Update Magnitude: 0.02937
Value Function Update Magnitude: 0.03516

Collected Steps per Second: 22,319.62870
Overall Steps per Second: 16,483.89367

Timestep Collection Time: 2.24099
Timestep Consumption Time: 0.79337
PPO Batch Consumption Time: 0.06120
Total Iteration Time: 3.03436

Cumulative Model Updates: 21,860
Cumulative Timesteps: 364,975,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 364975608...
Checkpoint 364975608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,647.41261
Policy Entropy: 0.82340
Value Function Loss: 0.06807

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02874
Policy Update Magnitude: 0.02985
Value Function Update Magnitude: 0.03532

Collected Steps per Second: 22,014.21821
Overall Steps per Second: 16,258.28132

Timestep Collection Time: 2.27180
Timestep Consumption Time: 0.80429
PPO Batch Consumption Time: 0.06329
Total Iteration Time: 3.07609

Cumulative Model Updates: 21,863
Cumulative Timesteps: 365,025,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,546.17653
Policy Entropy: 0.82289
Value Function Loss: 0.06520

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05503
Policy Update Magnitude: 0.02746
Value Function Update Magnitude: 0.03430

Collected Steps per Second: 20,256.52762
Overall Steps per Second: 14,869.13635

Timestep Collection Time: 2.47002
Timestep Consumption Time: 0.89494
PPO Batch Consumption Time: 0.09567
Total Iteration Time: 3.36496

Cumulative Model Updates: 21,866
Cumulative Timesteps: 365,075,654

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 365075654...
Checkpoint 365075654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,902.82872
Policy Entropy: 0.82793
Value Function Loss: 0.07170

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04233
Policy Update Magnitude: 0.02806
Value Function Update Magnitude: 0.03487

Collected Steps per Second: 22,020.17470
Overall Steps per Second: 16,199.96773

Timestep Collection Time: 2.27128
Timestep Consumption Time: 0.81601
PPO Batch Consumption Time: 0.06074
Total Iteration Time: 3.08729

Cumulative Model Updates: 21,869
Cumulative Timesteps: 365,125,668

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,029.42995
Policy Entropy: 0.82489
Value Function Loss: 0.07302

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.05021
Policy Update Magnitude: 0.02947
Value Function Update Magnitude: 0.03406

Collected Steps per Second: 22,330.81085
Overall Steps per Second: 16,713.02083

Timestep Collection Time: 2.24040
Timestep Consumption Time: 0.75307
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 2.99347

Cumulative Model Updates: 21,872
Cumulative Timesteps: 365,175,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 365175698...
Checkpoint 365175698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,776.50729
Policy Entropy: 0.82129
Value Function Loss: 0.08224

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04738
Policy Update Magnitude: 0.03147
Value Function Update Magnitude: 0.03269

Collected Steps per Second: 22,402.38008
Overall Steps per Second: 16,689.29727

Timestep Collection Time: 2.23307
Timestep Consumption Time: 0.76442
PPO Batch Consumption Time: 0.05767
Total Iteration Time: 2.99749

Cumulative Model Updates: 21,875
Cumulative Timesteps: 365,225,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,868.76667
Policy Entropy: 0.81531
Value Function Loss: 0.07666

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04973
Policy Update Magnitude: 0.03408
Value Function Update Magnitude: 0.03026

Collected Steps per Second: 22,700.61230
Overall Steps per Second: 16,622.59638

Timestep Collection Time: 2.20364
Timestep Consumption Time: 0.80576
PPO Batch Consumption Time: 0.05769
Total Iteration Time: 3.00940

Cumulative Model Updates: 21,878
Cumulative Timesteps: 365,275,748

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 365275748...
Checkpoint 365275748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,429.15091
Policy Entropy: 0.81844
Value Function Loss: 0.07394

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06233
Policy Update Magnitude: 0.03337
Value Function Update Magnitude: 0.03330

Collected Steps per Second: 20,843.01683
Overall Steps per Second: 15,193.25602

Timestep Collection Time: 2.40013
Timestep Consumption Time: 0.89251
PPO Batch Consumption Time: 0.08535
Total Iteration Time: 3.29265

Cumulative Model Updates: 21,881
Cumulative Timesteps: 365,325,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,701.68862
Policy Entropy: 0.82604
Value Function Loss: 0.06388

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.03257
Value Function Update Magnitude: 0.03264

Collected Steps per Second: 22,632.93524
Overall Steps per Second: 16,598.58039

Timestep Collection Time: 2.21032
Timestep Consumption Time: 0.80355
PPO Batch Consumption Time: 0.05905
Total Iteration Time: 3.01387

Cumulative Model Updates: 21,884
Cumulative Timesteps: 365,375,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 365375800...
Checkpoint 365375800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,956.54602
Policy Entropy: 0.84600
Value Function Loss: 0.06472

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.03055
Value Function Update Magnitude: 0.03035

Collected Steps per Second: 22,144.65707
Overall Steps per Second: 16,269.15678

Timestep Collection Time: 2.25978
Timestep Consumption Time: 0.81610
PPO Batch Consumption Time: 0.06166
Total Iteration Time: 3.07588

Cumulative Model Updates: 21,887
Cumulative Timesteps: 365,425,842

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,410.29063
Policy Entropy: 0.83816
Value Function Loss: 0.06389

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.03026
Value Function Update Magnitude: 0.03031

Collected Steps per Second: 19,837.62271
Overall Steps per Second: 14,568.50011

Timestep Collection Time: 2.52046
Timestep Consumption Time: 0.91160
PPO Batch Consumption Time: 0.08132
Total Iteration Time: 3.43206

Cumulative Model Updates: 21,890
Cumulative Timesteps: 365,475,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 365475842...
Checkpoint 365475842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,672.35968
Policy Entropy: 0.84345
Value Function Loss: 0.06897

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05353
Policy Update Magnitude: 0.02842
Value Function Update Magnitude: 0.03356

Collected Steps per Second: 22,239.62294
Overall Steps per Second: 16,448.51750

Timestep Collection Time: 2.24959
Timestep Consumption Time: 0.79202
PPO Batch Consumption Time: 0.06017
Total Iteration Time: 3.04161

Cumulative Model Updates: 21,893
Cumulative Timesteps: 365,525,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,102.07775
Policy Entropy: 0.83127
Value Function Loss: 0.06514

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04586
Policy Update Magnitude: 0.02932
Value Function Update Magnitude: 0.03085

Collected Steps per Second: 21,325.75782
Overall Steps per Second: 15,071.45288

Timestep Collection Time: 2.34496
Timestep Consumption Time: 0.97310
PPO Batch Consumption Time: 0.11874
Total Iteration Time: 3.31806

Cumulative Model Updates: 21,896
Cumulative Timesteps: 365,575,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 365575880...
Checkpoint 365575880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,900.17758
Policy Entropy: 0.84056
Value Function Loss: 0.05987

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04179
Policy Update Magnitude: 0.03263
Value Function Update Magnitude: 0.03812

Collected Steps per Second: 22,476.52811
Overall Steps per Second: 16,485.87404

Timestep Collection Time: 2.22481
Timestep Consumption Time: 0.80845
PPO Batch Consumption Time: 0.06094
Total Iteration Time: 3.03326

Cumulative Model Updates: 21,899
Cumulative Timesteps: 365,625,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,547.22109
Policy Entropy: 0.82930
Value Function Loss: 0.05861

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05250
Policy Update Magnitude: 0.03146
Value Function Update Magnitude: 0.04342

Collected Steps per Second: 20,595.65513
Overall Steps per Second: 14,918.46986

Timestep Collection Time: 2.42886
Timestep Consumption Time: 0.92430
PPO Batch Consumption Time: 0.09922
Total Iteration Time: 3.35316

Cumulative Model Updates: 21,902
Cumulative Timesteps: 365,675,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 365675910...
Checkpoint 365675910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,233.97831
Policy Entropy: 0.83549
Value Function Loss: 0.05854

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03655
Policy Update Magnitude: 0.02746
Value Function Update Magnitude: 0.04313

Collected Steps per Second: 22,484.82598
Overall Steps per Second: 16,532.52860

Timestep Collection Time: 2.22390
Timestep Consumption Time: 0.80068
PPO Batch Consumption Time: 0.05914
Total Iteration Time: 3.02458

Cumulative Model Updates: 21,905
Cumulative Timesteps: 365,725,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,290.98515
Policy Entropy: 0.82460
Value Function Loss: 0.06362

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03863
Policy Update Magnitude: 0.02849
Value Function Update Magnitude: 0.05001

Collected Steps per Second: 20,926.70558
Overall Steps per Second: 14,933.13138

Timestep Collection Time: 2.39034
Timestep Consumption Time: 0.95939
PPO Batch Consumption Time: 0.10530
Total Iteration Time: 3.34973

Cumulative Model Updates: 21,908
Cumulative Timesteps: 365,775,936

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 365775936...
Checkpoint 365775936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,157.74701
Policy Entropy: 0.83710
Value Function Loss: 0.06395

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.03024
Policy Update Magnitude: 0.03329
Value Function Update Magnitude: 0.04684

Collected Steps per Second: 22,286.77023
Overall Steps per Second: 16,419.99624

Timestep Collection Time: 2.24384
Timestep Consumption Time: 0.80171
PPO Batch Consumption Time: 0.06143
Total Iteration Time: 3.04555

Cumulative Model Updates: 21,911
Cumulative Timesteps: 365,825,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,473.90298
Policy Entropy: 0.83420
Value Function Loss: 0.07048

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03188
Policy Update Magnitude: 0.03308
Value Function Update Magnitude: 0.04616

Collected Steps per Second: 20,918.53818
Overall Steps per Second: 15,020.05016

Timestep Collection Time: 2.39042
Timestep Consumption Time: 0.93873
PPO Batch Consumption Time: 0.10718
Total Iteration Time: 3.32915

Cumulative Model Updates: 21,914
Cumulative Timesteps: 365,875,948

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 365875948...
Checkpoint 365875948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,035.43562
Policy Entropy: 0.83896
Value Function Loss: 0.07472

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.06121
Policy Update Magnitude: 0.03212
Value Function Update Magnitude: 0.04673

Collected Steps per Second: 22,241.96024
Overall Steps per Second: 16,518.17321

Timestep Collection Time: 2.24845
Timestep Consumption Time: 0.77912
PPO Batch Consumption Time: 0.05897
Total Iteration Time: 3.02757

Cumulative Model Updates: 21,917
Cumulative Timesteps: 365,925,958

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,717.36675
Policy Entropy: 0.81135
Value Function Loss: 0.07576

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05392
Policy Update Magnitude: 0.03000
Value Function Update Magnitude: 0.04728

Collected Steps per Second: 20,816.10862
Overall Steps per Second: 14,968.44038

Timestep Collection Time: 2.40352
Timestep Consumption Time: 0.93898
PPO Batch Consumption Time: 0.10785
Total Iteration Time: 3.34250

Cumulative Model Updates: 21,920
Cumulative Timesteps: 365,975,990

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 365975990...
Checkpoint 365975990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,708.92031
Policy Entropy: 0.81607
Value Function Loss: 0.06735

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04310
Policy Update Magnitude: 0.02990
Value Function Update Magnitude: 0.05656

Collected Steps per Second: 22,371.19850
Overall Steps per Second: 16,239.16576

Timestep Collection Time: 2.23502
Timestep Consumption Time: 0.84396
PPO Batch Consumption Time: 0.06606
Total Iteration Time: 3.07898

Cumulative Model Updates: 21,923
Cumulative Timesteps: 366,025,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,797.11990
Policy Entropy: 0.81850
Value Function Loss: 0.05912

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03571
Policy Update Magnitude: 0.03356
Value Function Update Magnitude: 0.05697

Collected Steps per Second: 22,374.87229
Overall Steps per Second: 16,516.81456

Timestep Collection Time: 2.23545
Timestep Consumption Time: 0.79285
PPO Batch Consumption Time: 0.05807
Total Iteration Time: 3.02831

Cumulative Model Updates: 21,926
Cumulative Timesteps: 366,076,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 366076008...
Checkpoint 366076008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,072.56597
Policy Entropy: 0.83227
Value Function Loss: 0.06066

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04703
Policy Update Magnitude: 0.03076
Value Function Update Magnitude: 0.05066

Collected Steps per Second: 22,338.79164
Overall Steps per Second: 16,579.33549

Timestep Collection Time: 2.23933
Timestep Consumption Time: 0.77792
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 3.01725

Cumulative Model Updates: 21,929
Cumulative Timesteps: 366,126,032

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,039.81109
Policy Entropy: 0.82750
Value Function Loss: 0.06850

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03523
Policy Update Magnitude: 0.02872
Value Function Update Magnitude: 0.04748

Collected Steps per Second: 20,234.42777
Overall Steps per Second: 14,636.95505

Timestep Collection Time: 2.47193
Timestep Consumption Time: 0.94532
PPO Batch Consumption Time: 0.10536
Total Iteration Time: 3.41724

Cumulative Model Updates: 21,932
Cumulative Timesteps: 366,176,050

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 366176050...
Checkpoint 366176050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,566.26580
Policy Entropy: 0.81414
Value Function Loss: 0.07257

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.03116
Value Function Update Magnitude: 0.04725

Collected Steps per Second: 22,057.75480
Overall Steps per Second: 16,361.25922

Timestep Collection Time: 2.26768
Timestep Consumption Time: 0.78954
PPO Batch Consumption Time: 0.05967
Total Iteration Time: 3.05722

Cumulative Model Updates: 21,935
Cumulative Timesteps: 366,226,070

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,090.29060
Policy Entropy: 0.80730
Value Function Loss: 0.07749

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02983
Policy Update Magnitude: 0.03557
Value Function Update Magnitude: 0.05259

Collected Steps per Second: 21,155.49875
Overall Steps per Second: 15,020.35245

Timestep Collection Time: 2.36364
Timestep Consumption Time: 0.96544
PPO Batch Consumption Time: 0.10624
Total Iteration Time: 3.32908

Cumulative Model Updates: 21,938
Cumulative Timesteps: 366,276,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 366276074...
Checkpoint 366276074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,212.35274
Policy Entropy: 0.80352
Value Function Loss: 0.07618

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01951
Policy Update Magnitude: 0.03585
Value Function Update Magnitude: 0.05089

Collected Steps per Second: 22,730.11836
Overall Steps per Second: 16,623.83460

Timestep Collection Time: 2.20034
Timestep Consumption Time: 0.80823
PPO Batch Consumption Time: 0.05841
Total Iteration Time: 3.00857

Cumulative Model Updates: 21,941
Cumulative Timesteps: 366,326,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,787.41179
Policy Entropy: 0.79996
Value Function Loss: 0.08209

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02129
Policy Update Magnitude: 0.03584
Value Function Update Magnitude: 0.04740

Collected Steps per Second: 20,904.37134
Overall Steps per Second: 14,846.08563

Timestep Collection Time: 2.39232
Timestep Consumption Time: 0.97624
PPO Batch Consumption Time: 0.10864
Total Iteration Time: 3.36856

Cumulative Model Updates: 21,944
Cumulative Timesteps: 366,376,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 366376098...
Checkpoint 366376098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,448.15434
Policy Entropy: 0.81762
Value Function Loss: 0.07356

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02853
Policy Update Magnitude: 0.03482
Value Function Update Magnitude: 0.04607

Collected Steps per Second: 22,118.96639
Overall Steps per Second: 16,277.87216

Timestep Collection Time: 2.26249
Timestep Consumption Time: 0.81186
PPO Batch Consumption Time: 0.06170
Total Iteration Time: 3.07436

Cumulative Model Updates: 21,947
Cumulative Timesteps: 366,426,142

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,213.10591
Policy Entropy: 0.81895
Value Function Loss: 0.07123

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02952
Policy Update Magnitude: 0.03265
Value Function Update Magnitude: 0.05212

Collected Steps per Second: 22,553.73663
Overall Steps per Second: 16,106.97370

Timestep Collection Time: 2.21710
Timestep Consumption Time: 0.88739
PPO Batch Consumption Time: 0.07964
Total Iteration Time: 3.10449

Cumulative Model Updates: 21,950
Cumulative Timesteps: 366,476,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 366476146...
Checkpoint 366476146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,348.49694
Policy Entropy: 0.82523
Value Function Loss: 0.06674

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03523
Policy Update Magnitude: 0.03335
Value Function Update Magnitude: 0.04991

Collected Steps per Second: 22,488.10668
Overall Steps per Second: 16,552.02017

Timestep Collection Time: 2.22366
Timestep Consumption Time: 0.79748
PPO Batch Consumption Time: 0.06151
Total Iteration Time: 3.02114

Cumulative Model Updates: 21,953
Cumulative Timesteps: 366,526,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,300.08314
Policy Entropy: 0.82043
Value Function Loss: 0.07131

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03114
Policy Update Magnitude: 0.03139
Value Function Update Magnitude: 0.04864

Collected Steps per Second: 20,138.20930
Overall Steps per Second: 14,732.85369

Timestep Collection Time: 2.48354
Timestep Consumption Time: 0.91119
PPO Batch Consumption Time: 0.08784
Total Iteration Time: 3.39473

Cumulative Model Updates: 21,956
Cumulative Timesteps: 366,576,166

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 366576166...
Checkpoint 366576166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,057.65704
Policy Entropy: 0.82925
Value Function Loss: 0.07254

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04211
Policy Update Magnitude: 0.03895
Value Function Update Magnitude: 0.04623

Collected Steps per Second: 22,376.81401
Overall Steps per Second: 16,510.38682

Timestep Collection Time: 2.23535
Timestep Consumption Time: 0.79426
PPO Batch Consumption Time: 0.05900
Total Iteration Time: 3.02961

Cumulative Model Updates: 21,959
Cumulative Timesteps: 366,626,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,220.19890
Policy Entropy: 0.83425
Value Function Loss: 0.07207

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06381
Policy Update Magnitude: 0.03411
Value Function Update Magnitude: 0.04610

Collected Steps per Second: 22,489.52573
Overall Steps per Second: 16,011.83390

Timestep Collection Time: 2.22326
Timestep Consumption Time: 0.89943
PPO Batch Consumption Time: 0.08393
Total Iteration Time: 3.12269

Cumulative Model Updates: 21,962
Cumulative Timesteps: 366,676,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 366676186...
Checkpoint 366676186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,166.86334
Policy Entropy: 0.82873
Value Function Loss: 0.08235

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05684
Policy Update Magnitude: 0.03140
Value Function Update Magnitude: 0.04785

Collected Steps per Second: 22,003.98705
Overall Steps per Second: 16,325.72104

Timestep Collection Time: 2.27432
Timestep Consumption Time: 0.79103
PPO Batch Consumption Time: 0.05752
Total Iteration Time: 3.06535

Cumulative Model Updates: 21,965
Cumulative Timesteps: 366,726,230

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,569.55425
Policy Entropy: 0.82892
Value Function Loss: 0.08077

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06642
Policy Update Magnitude: 0.03020
Value Function Update Magnitude: 0.04767

Collected Steps per Second: 22,950.80824
Overall Steps per Second: 16,727.30250

Timestep Collection Time: 2.17936
Timestep Consumption Time: 0.81084
PPO Batch Consumption Time: 0.05823
Total Iteration Time: 2.99020

Cumulative Model Updates: 21,968
Cumulative Timesteps: 366,776,248

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 366776248...
Checkpoint 366776248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,761.37748
Policy Entropy: 0.83343
Value Function Loss: 0.08167

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08002
Policy Update Magnitude: 0.02997
Value Function Update Magnitude: 0.04731

Collected Steps per Second: 22,197.73564
Overall Steps per Second: 16,459.01224

Timestep Collection Time: 2.25266
Timestep Consumption Time: 0.78543
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 3.03809

Cumulative Model Updates: 21,971
Cumulative Timesteps: 366,826,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,361.81446
Policy Entropy: 0.84990
Value Function Loss: 0.07408

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.05675
Policy Update Magnitude: 0.02856
Value Function Update Magnitude: 0.05443

Collected Steps per Second: 20,289.38559
Overall Steps per Second: 14,604.29323

Timestep Collection Time: 2.46523
Timestep Consumption Time: 0.95965
PPO Batch Consumption Time: 0.10066
Total Iteration Time: 3.42488

Cumulative Model Updates: 21,974
Cumulative Timesteps: 366,876,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 366876270...
Checkpoint 366876270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,901.89102
Policy Entropy: 0.85315
Value Function Loss: 0.07899

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.09810
Policy Update Magnitude: 0.02964
Value Function Update Magnitude: 0.06250

Collected Steps per Second: 22,525.74727
Overall Steps per Second: 16,751.90890

Timestep Collection Time: 2.22030
Timestep Consumption Time: 0.76527
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 2.98557

Cumulative Model Updates: 21,977
Cumulative Timesteps: 366,926,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,467.12885
Policy Entropy: 0.85381
Value Function Loss: 0.08016

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.10072
Policy Update Magnitude: 0.02701
Value Function Update Magnitude: 0.06744

Collected Steps per Second: 20,162.70638
Overall Steps per Second: 14,749.89211

Timestep Collection Time: 2.48161
Timestep Consumption Time: 0.91068
PPO Batch Consumption Time: 0.09210
Total Iteration Time: 3.39230

Cumulative Model Updates: 21,980
Cumulative Timesteps: 366,976,320

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 366976320...
Checkpoint 366976320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,147.61119
Policy Entropy: 0.85140
Value Function Loss: 0.07960

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.03087
Value Function Update Magnitude: 0.05856

Collected Steps per Second: 22,039.54185
Overall Steps per Second: 16,447.52370

Timestep Collection Time: 2.26865
Timestep Consumption Time: 0.77132
PPO Batch Consumption Time: 0.06137
Total Iteration Time: 3.03997

Cumulative Model Updates: 21,983
Cumulative Timesteps: 367,026,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,004.42905
Policy Entropy: 0.86254
Value Function Loss: 0.07428

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07398
Policy Update Magnitude: 0.03446
Value Function Update Magnitude: 0.05716

Collected Steps per Second: 20,883.16415
Overall Steps per Second: 15,002.01483

Timestep Collection Time: 2.39456
Timestep Consumption Time: 0.93873
PPO Batch Consumption Time: 0.09968
Total Iteration Time: 3.33329

Cumulative Model Updates: 21,986
Cumulative Timesteps: 367,076,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 367076326...
Checkpoint 367076326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,927.26801
Policy Entropy: 0.86618
Value Function Loss: 0.06766

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.03156
Value Function Update Magnitude: 0.05264

Collected Steps per Second: 22,222.50752
Overall Steps per Second: 16,383.70839

Timestep Collection Time: 2.25105
Timestep Consumption Time: 0.80223
PPO Batch Consumption Time: 0.06202
Total Iteration Time: 3.05328

Cumulative Model Updates: 21,989
Cumulative Timesteps: 367,126,350

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,964.60794
Policy Entropy: 0.86963
Value Function Loss: 0.06174

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.04357
Policy Update Magnitude: 0.02935
Value Function Update Magnitude: 0.05352

Collected Steps per Second: 21,044.88865
Overall Steps per Second: 15,029.62925

Timestep Collection Time: 2.37663
Timestep Consumption Time: 0.95119
PPO Batch Consumption Time: 0.10250
Total Iteration Time: 3.32783

Cumulative Model Updates: 21,992
Cumulative Timesteps: 367,176,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 367176366...
Checkpoint 367176366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,062.30723
Policy Entropy: 0.86191
Value Function Loss: 0.06561

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.04699
Policy Update Magnitude: 0.02838
Value Function Update Magnitude: 0.05058

Collected Steps per Second: 22,628.90091
Overall Steps per Second: 16,821.39649

Timestep Collection Time: 2.21001
Timestep Consumption Time: 0.76299
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 2.97300

Cumulative Model Updates: 21,995
Cumulative Timesteps: 367,226,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,194.18420
Policy Entropy: 0.85798
Value Function Loss: 0.06824

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04039
Policy Update Magnitude: 0.03247
Value Function Update Magnitude: 0.06306

Collected Steps per Second: 20,928.65103
Overall Steps per Second: 14,781.46002

Timestep Collection Time: 2.38936
Timestep Consumption Time: 0.99367
PPO Batch Consumption Time: 0.11686
Total Iteration Time: 3.38302

Cumulative Model Updates: 21,998
Cumulative Timesteps: 367,276,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 367276382...
Checkpoint 367276382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,613.83185
Policy Entropy: 0.85917
Value Function Loss: 0.07359

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04653
Policy Update Magnitude: 0.03092
Value Function Update Magnitude: 0.06931

Collected Steps per Second: 21,890.58663
Overall Steps per Second: 16,379.95952

Timestep Collection Time: 2.28509
Timestep Consumption Time: 0.76876
PPO Batch Consumption Time: 0.05936
Total Iteration Time: 3.05385

Cumulative Model Updates: 22,001
Cumulative Timesteps: 367,326,404

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,741.97749
Policy Entropy: 0.86597
Value Function Loss: 0.07130

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03165
Policy Update Magnitude: 0.02939
Value Function Update Magnitude: 0.05973

Collected Steps per Second: 20,737.35997
Overall Steps per Second: 14,983.37175

Timestep Collection Time: 2.41111
Timestep Consumption Time: 0.92593
PPO Batch Consumption Time: 0.09400
Total Iteration Time: 3.33703

Cumulative Model Updates: 22,004
Cumulative Timesteps: 367,376,404

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 367376404...
Checkpoint 367376404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,926.14985
Policy Entropy: 0.86167
Value Function Loss: 0.07464

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02981
Policy Update Magnitude: 0.02950
Value Function Update Magnitude: 0.06140

Collected Steps per Second: 22,526.14410
Overall Steps per Second: 16,506.92637

Timestep Collection Time: 2.22080
Timestep Consumption Time: 0.80981
PPO Batch Consumption Time: 0.06143
Total Iteration Time: 3.03061

Cumulative Model Updates: 22,007
Cumulative Timesteps: 367,426,430

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,465.94242
Policy Entropy: 0.86419
Value Function Loss: 0.07170

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02790
Policy Update Magnitude: 0.03191
Value Function Update Magnitude: 0.06190

Collected Steps per Second: 21,291.28607
Overall Steps per Second: 15,028.45539

Timestep Collection Time: 2.34979
Timestep Consumption Time: 0.97923
PPO Batch Consumption Time: 0.11602
Total Iteration Time: 3.32902

Cumulative Model Updates: 22,010
Cumulative Timesteps: 367,476,460

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 367476460...
Checkpoint 367476460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,888.16220
Policy Entropy: 0.85816
Value Function Loss: 0.07522

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.03176
Value Function Update Magnitude: 0.07165

Collected Steps per Second: 22,055.59814
Overall Steps per Second: 15,652.39008

Timestep Collection Time: 2.26899
Timestep Consumption Time: 0.92822
PPO Batch Consumption Time: 0.08997
Total Iteration Time: 3.19721

Cumulative Model Updates: 22,013
Cumulative Timesteps: 367,526,504

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,614.80135
Policy Entropy: 0.85782
Value Function Loss: 0.07544

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03084
Policy Update Magnitude: 0.03120
Value Function Update Magnitude: 0.06498

Collected Steps per Second: 22,498.14408
Overall Steps per Second: 16,479.20989

Timestep Collection Time: 2.22329
Timestep Consumption Time: 0.81205
PPO Batch Consumption Time: 0.06440
Total Iteration Time: 3.03534

Cumulative Model Updates: 22,016
Cumulative Timesteps: 367,576,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 367576524...
Checkpoint 367576524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,906.70305
Policy Entropy: 0.85370
Value Function Loss: 0.08286

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03981
Policy Update Magnitude: 0.03443
Value Function Update Magnitude: 0.06566

Collected Steps per Second: 20,555.85950
Overall Steps per Second: 14,989.50821

Timestep Collection Time: 2.43395
Timestep Consumption Time: 0.90385
PPO Batch Consumption Time: 0.09216
Total Iteration Time: 3.33780

Cumulative Model Updates: 22,019
Cumulative Timesteps: 367,626,556

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,038.74797
Policy Entropy: 0.85906
Value Function Loss: 0.07545

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02501
Policy Update Magnitude: 0.03545
Value Function Update Magnitude: 0.06767

Collected Steps per Second: 22,440.48428
Overall Steps per Second: 16,541.87097

Timestep Collection Time: 2.22990
Timestep Consumption Time: 0.79515
PPO Batch Consumption Time: 0.06116
Total Iteration Time: 3.02505

Cumulative Model Updates: 22,022
Cumulative Timesteps: 367,676,596

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 367676596...
Checkpoint 367676596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,770.27680
Policy Entropy: 0.85830
Value Function Loss: 0.07050

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01748
Policy Update Magnitude: 0.03406
Value Function Update Magnitude: 0.06094

Collected Steps per Second: 20,362.46076
Overall Steps per Second: 14,934.80504

Timestep Collection Time: 2.45648
Timestep Consumption Time: 0.89274
PPO Batch Consumption Time: 0.08461
Total Iteration Time: 3.34922

Cumulative Model Updates: 22,025
Cumulative Timesteps: 367,726,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,018.01919
Policy Entropy: 0.85667
Value Function Loss: 0.07142

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02797
Policy Update Magnitude: 0.03112
Value Function Update Magnitude: 0.05568

Collected Steps per Second: 21,842.11378
Overall Steps per Second: 16,396.37880

Timestep Collection Time: 2.28925
Timestep Consumption Time: 0.76033
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 3.04958

Cumulative Model Updates: 22,028
Cumulative Timesteps: 367,776,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 367776618...
Checkpoint 367776618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,168.27838
Policy Entropy: 0.84624
Value Function Loss: 0.07217

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02363
Policy Update Magnitude: 0.03151
Value Function Update Magnitude: 0.05381

Collected Steps per Second: 20,517.07524
Overall Steps per Second: 15,051.88119

Timestep Collection Time: 2.43855
Timestep Consumption Time: 0.88542
PPO Batch Consumption Time: 0.08141
Total Iteration Time: 3.32397

Cumulative Model Updates: 22,031
Cumulative Timesteps: 367,826,650

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,318.90727
Policy Entropy: 0.85337
Value Function Loss: 0.07576

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03183
Policy Update Magnitude: 0.03077
Value Function Update Magnitude: 0.05034

Collected Steps per Second: 22,803.44399
Overall Steps per Second: 16,691.52352

Timestep Collection Time: 2.19335
Timestep Consumption Time: 0.80314
PPO Batch Consumption Time: 0.05790
Total Iteration Time: 2.99649

Cumulative Model Updates: 22,034
Cumulative Timesteps: 367,876,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 367876666...
Checkpoint 367876666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,429.42915
Policy Entropy: 0.83915
Value Function Loss: 0.07047

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03213
Policy Update Magnitude: 0.03019
Value Function Update Magnitude: 0.05098

Collected Steps per Second: 20,597.88126
Overall Steps per Second: 14,836.15413

Timestep Collection Time: 2.42860
Timestep Consumption Time: 0.94316
PPO Batch Consumption Time: 0.09894
Total Iteration Time: 3.37176

Cumulative Model Updates: 22,037
Cumulative Timesteps: 367,926,690

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,909.64366
Policy Entropy: 0.83378
Value Function Loss: 0.07660

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03253
Policy Update Magnitude: 0.03134
Value Function Update Magnitude: 0.04680

Collected Steps per Second: 22,589.83923
Overall Steps per Second: 16,575.75638

Timestep Collection Time: 2.21338
Timestep Consumption Time: 0.80307
PPO Batch Consumption Time: 0.05981
Total Iteration Time: 3.01645

Cumulative Model Updates: 22,040
Cumulative Timesteps: 367,976,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 367976690...
Checkpoint 367976690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,424.04202
Policy Entropy: 0.83497
Value Function Loss: 0.07557

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02676
Policy Update Magnitude: 0.03321
Value Function Update Magnitude: 0.05314

Collected Steps per Second: 20,253.85277
Overall Steps per Second: 14,900.32404

Timestep Collection Time: 2.47054
Timestep Consumption Time: 0.88764
PPO Batch Consumption Time: 0.08814
Total Iteration Time: 3.35818

Cumulative Model Updates: 22,043
Cumulative Timesteps: 368,026,728

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,873.86725
Policy Entropy: 0.82904
Value Function Loss: 0.07733

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04901
Policy Update Magnitude: 0.03207
Value Function Update Magnitude: 0.06519

Collected Steps per Second: 22,430.38736
Overall Steps per Second: 16,626.83708

Timestep Collection Time: 2.22983
Timestep Consumption Time: 0.77832
PPO Batch Consumption Time: 0.06088
Total Iteration Time: 3.00815

Cumulative Model Updates: 22,046
Cumulative Timesteps: 368,076,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 368076744...
Checkpoint 368076744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,873.11118
Policy Entropy: 0.84215
Value Function Loss: 0.06951

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02891
Policy Update Magnitude: 0.03196
Value Function Update Magnitude: 0.06900

Collected Steps per Second: 20,462.46864
Overall Steps per Second: 14,850.33408

Timestep Collection Time: 2.44487
Timestep Consumption Time: 0.92395
PPO Batch Consumption Time: 0.08487
Total Iteration Time: 3.36881

Cumulative Model Updates: 22,049
Cumulative Timesteps: 368,126,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,411.76291
Policy Entropy: 0.84878
Value Function Loss: 0.06356

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04094
Policy Update Magnitude: 0.03145
Value Function Update Magnitude: 0.07085

Collected Steps per Second: 22,466.04675
Overall Steps per Second: 16,492.64159

Timestep Collection Time: 2.22674
Timestep Consumption Time: 0.80649
PPO Batch Consumption Time: 0.06045
Total Iteration Time: 3.03323

Cumulative Model Updates: 22,052
Cumulative Timesteps: 368,176,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 368176798...
Checkpoint 368176798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,745.37006
Policy Entropy: 0.87091
Value Function Loss: 0.05868

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03339
Policy Update Magnitude: 0.03022
Value Function Update Magnitude: 0.06727

Collected Steps per Second: 20,795.08857
Overall Steps per Second: 15,008.82714

Timestep Collection Time: 2.40441
Timestep Consumption Time: 0.92696
PPO Batch Consumption Time: 0.09910
Total Iteration Time: 3.33137

Cumulative Model Updates: 22,055
Cumulative Timesteps: 368,226,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,463.93281
Policy Entropy: 0.86920
Value Function Loss: 0.06449

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03295
Policy Update Magnitude: 0.02956
Value Function Update Magnitude: 0.06640

Collected Steps per Second: 22,405.06912
Overall Steps per Second: 16,508.21753

Timestep Collection Time: 2.23199
Timestep Consumption Time: 0.79728
PPO Batch Consumption Time: 0.05870
Total Iteration Time: 3.02928

Cumulative Model Updates: 22,058
Cumulative Timesteps: 368,276,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 368276806...
Checkpoint 368276806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,809.09158
Policy Entropy: 0.85376
Value Function Loss: 0.07383

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02824
Policy Update Magnitude: 0.03297
Value Function Update Magnitude: 0.06230

Collected Steps per Second: 20,463.69179
Overall Steps per Second: 14,920.84036

Timestep Collection Time: 2.44482
Timestep Consumption Time: 0.90821
PPO Batch Consumption Time: 0.08698
Total Iteration Time: 3.35303

Cumulative Model Updates: 22,061
Cumulative Timesteps: 368,326,836

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,382.82542
Policy Entropy: 0.85059
Value Function Loss: 0.07024

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02239
Policy Update Magnitude: 0.03400
Value Function Update Magnitude: 0.06353

Collected Steps per Second: 22,832.11017
Overall Steps per Second: 16,851.01394

Timestep Collection Time: 2.19060
Timestep Consumption Time: 0.77753
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 2.96813

Cumulative Model Updates: 22,064
Cumulative Timesteps: 368,376,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 368376852...
Checkpoint 368376852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,382.31974
Policy Entropy: 0.85010
Value Function Loss: 0.06324

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.03302
Value Function Update Magnitude: 0.06887

Collected Steps per Second: 20,270.69490
Overall Steps per Second: 14,706.45126

Timestep Collection Time: 2.46800
Timestep Consumption Time: 0.93378
PPO Batch Consumption Time: 0.09542
Total Iteration Time: 3.40177

Cumulative Model Updates: 22,067
Cumulative Timesteps: 368,426,880

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,071.40525
Policy Entropy: 0.85235
Value Function Loss: 0.06335

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02335
Policy Update Magnitude: 0.03145
Value Function Update Magnitude: 0.06806

Collected Steps per Second: 22,475.45931
Overall Steps per Second: 16,500.24576

Timestep Collection Time: 2.22554
Timestep Consumption Time: 0.80593
PPO Batch Consumption Time: 0.05982
Total Iteration Time: 3.03147

Cumulative Model Updates: 22,070
Cumulative Timesteps: 368,476,900

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 368476900...
Checkpoint 368476900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,615.75521
Policy Entropy: 0.84969
Value Function Loss: 0.07167

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.03187
Value Function Update Magnitude: 0.06726

Collected Steps per Second: 20,311.57221
Overall Steps per Second: 14,927.96882

Timestep Collection Time: 2.46165
Timestep Consumption Time: 0.88777
PPO Batch Consumption Time: 0.08281
Total Iteration Time: 3.34942

Cumulative Model Updates: 22,073
Cumulative Timesteps: 368,526,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,469.97043
Policy Entropy: 0.86054
Value Function Loss: 0.07526

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02634
Policy Update Magnitude: 0.03666
Value Function Update Magnitude: 0.06644

Collected Steps per Second: 22,741.21301
Overall Steps per Second: 16,711.31796

Timestep Collection Time: 2.19883
Timestep Consumption Time: 0.79340
PPO Batch Consumption Time: 0.05928
Total Iteration Time: 2.99222

Cumulative Model Updates: 22,076
Cumulative Timesteps: 368,576,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 368576904...
Checkpoint 368576904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,961.53641
Policy Entropy: 0.87197
Value Function Loss: 0.06454

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01911
Policy Update Magnitude: 0.03349
Value Function Update Magnitude: 0.05988

Collected Steps per Second: 19,975.23977
Overall Steps per Second: 14,608.00638

Timestep Collection Time: 2.50450
Timestep Consumption Time: 0.92020
PPO Batch Consumption Time: 0.08871
Total Iteration Time: 3.42470

Cumulative Model Updates: 22,079
Cumulative Timesteps: 368,626,932

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,557.33140
Policy Entropy: 0.88180
Value Function Loss: 0.05785

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01483
Policy Update Magnitude: 0.03328
Value Function Update Magnitude: 0.05164

Collected Steps per Second: 22,617.54002
Overall Steps per Second: 16,604.04480

Timestep Collection Time: 2.21244
Timestep Consumption Time: 0.80128
PPO Batch Consumption Time: 0.05946
Total Iteration Time: 3.01372

Cumulative Model Updates: 22,082
Cumulative Timesteps: 368,676,972

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 368676972...
Checkpoint 368676972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,211.27965
Policy Entropy: 0.87869
Value Function Loss: 0.05579

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02192
Policy Update Magnitude: 0.03164
Value Function Update Magnitude: 0.05323

Collected Steps per Second: 22,073.70689
Overall Steps per Second: 15,855.84841

Timestep Collection Time: 2.26595
Timestep Consumption Time: 0.88859
PPO Batch Consumption Time: 0.07763
Total Iteration Time: 3.15455

Cumulative Model Updates: 22,085
Cumulative Timesteps: 368,726,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,091.21405
Policy Entropy: 0.87630
Value Function Loss: 0.05570

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03120
Policy Update Magnitude: 0.03028
Value Function Update Magnitude: 0.05454

Collected Steps per Second: 22,426.92508
Overall Steps per Second: 16,570.64724

Timestep Collection Time: 2.23035
Timestep Consumption Time: 0.78824
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 3.01859

Cumulative Model Updates: 22,088
Cumulative Timesteps: 368,777,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 368777010...
Checkpoint 368777010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,485.84382
Policy Entropy: 0.88094
Value Function Loss: 0.05902

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03215
Policy Update Magnitude: 0.02953
Value Function Update Magnitude: 0.05643

Collected Steps per Second: 21,497.29031
Overall Steps per Second: 15,127.09922

Timestep Collection Time: 2.32606
Timestep Consumption Time: 0.97953
PPO Batch Consumption Time: 0.10508
Total Iteration Time: 3.30559

Cumulative Model Updates: 22,091
Cumulative Timesteps: 368,827,014

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,921.73546
Policy Entropy: 0.87817
Value Function Loss: 0.06100

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04795
Policy Update Magnitude: 0.02903
Value Function Update Magnitude: 0.05130

Collected Steps per Second: 22,527.44919
Overall Steps per Second: 16,541.43305

Timestep Collection Time: 2.22040
Timestep Consumption Time: 0.80352
PPO Batch Consumption Time: 0.06084
Total Iteration Time: 3.02392

Cumulative Model Updates: 22,094
Cumulative Timesteps: 368,877,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 368877034...
Checkpoint 368877034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,965.93720
Policy Entropy: 0.87171
Value Function Loss: 0.07162

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03630
Policy Update Magnitude: 0.03078
Value Function Update Magnitude: 0.05518

Collected Steps per Second: 19,877.17990
Overall Steps per Second: 14,749.38215

Timestep Collection Time: 2.51615
Timestep Consumption Time: 0.87477
PPO Batch Consumption Time: 0.08522
Total Iteration Time: 3.39092

Cumulative Model Updates: 22,097
Cumulative Timesteps: 368,927,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,523.87207
Policy Entropy: 0.87373
Value Function Loss: 0.07595

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05320
Policy Update Magnitude: 0.03018
Value Function Update Magnitude: 0.05211

Collected Steps per Second: 22,290.21635
Overall Steps per Second: 16,518.75331

Timestep Collection Time: 2.24421
Timestep Consumption Time: 0.78410
PPO Batch Consumption Time: 0.06167
Total Iteration Time: 3.02832

Cumulative Model Updates: 22,100
Cumulative Timesteps: 368,977,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 368977072...
Checkpoint 368977072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,837.53504
Policy Entropy: 0.87652
Value Function Loss: 0.07375

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04571
Policy Update Magnitude: 0.03093
Value Function Update Magnitude: 0.05223

Collected Steps per Second: 22,667.60688
Overall Steps per Second: 16,661.48451

Timestep Collection Time: 2.20703
Timestep Consumption Time: 0.79559
PPO Batch Consumption Time: 0.05962
Total Iteration Time: 3.00261

Cumulative Model Updates: 22,103
Cumulative Timesteps: 369,027,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,308.99796
Policy Entropy: 0.88472
Value Function Loss: 0.06469

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04321
Policy Update Magnitude: 0.03182
Value Function Update Magnitude: 0.05128

Collected Steps per Second: 22,750.26635
Overall Steps per Second: 16,531.27494

Timestep Collection Time: 2.19883
Timestep Consumption Time: 0.82719
PPO Batch Consumption Time: 0.06721
Total Iteration Time: 3.02602

Cumulative Model Updates: 22,106
Cumulative Timesteps: 369,077,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 369077124...
Checkpoint 369077124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,076.65242
Policy Entropy: 0.87230
Value Function Loss: 0.06118

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04188
Policy Update Magnitude: 0.03220
Value Function Update Magnitude: 0.05963

Collected Steps per Second: 22,366.26780
Overall Steps per Second: 16,492.50711

Timestep Collection Time: 2.23676
Timestep Consumption Time: 0.79662
PPO Batch Consumption Time: 0.05845
Total Iteration Time: 3.03338

Cumulative Model Updates: 22,109
Cumulative Timesteps: 369,127,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,412.15499
Policy Entropy: 0.86417
Value Function Loss: 0.07005

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06275
Policy Update Magnitude: 0.03438
Value Function Update Magnitude: 0.05902

Collected Steps per Second: 20,754.37665
Overall Steps per Second: 14,676.92657

Timestep Collection Time: 2.41000
Timestep Consumption Time: 0.99794
PPO Batch Consumption Time: 0.11592
Total Iteration Time: 3.40793

Cumulative Model Updates: 22,112
Cumulative Timesteps: 369,177,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 369177170...
Checkpoint 369177170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,957.38675
Policy Entropy: 0.85422
Value Function Loss: 0.07379

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05173
Policy Update Magnitude: 0.03169
Value Function Update Magnitude: 0.05022

Collected Steps per Second: 22,016.88407
Overall Steps per Second: 16,359.78151

Timestep Collection Time: 2.27217
Timestep Consumption Time: 0.78570
PPO Batch Consumption Time: 0.05994
Total Iteration Time: 3.05786

Cumulative Model Updates: 22,115
Cumulative Timesteps: 369,227,196

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,078.36706
Policy Entropy: 0.86382
Value Function Loss: 0.06635

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03585
Policy Update Magnitude: 0.03143
Value Function Update Magnitude: 0.05111

Collected Steps per Second: 22,538.78768
Overall Steps per Second: 16,681.99557

Timestep Collection Time: 2.21955
Timestep Consumption Time: 0.77925
PPO Batch Consumption Time: 0.06029
Total Iteration Time: 2.99880

Cumulative Model Updates: 22,118
Cumulative Timesteps: 369,277,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 369277222...
Checkpoint 369277222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,423.33087
Policy Entropy: 0.86061
Value Function Loss: 0.05800

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03696
Policy Update Magnitude: 0.03134
Value Function Update Magnitude: 0.05050

Collected Steps per Second: 22,079.44442
Overall Steps per Second: 16,275.15865

Timestep Collection Time: 2.26573
Timestep Consumption Time: 0.80804
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 3.07376

Cumulative Model Updates: 22,121
Cumulative Timesteps: 369,327,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,647.81187
Policy Entropy: 0.86648
Value Function Loss: 0.05496

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03047
Policy Update Magnitude: 0.03150
Value Function Update Magnitude: 0.04416

Collected Steps per Second: 20,199.69110
Overall Steps per Second: 14,631.95857

Timestep Collection Time: 2.47548
Timestep Consumption Time: 0.94197
PPO Batch Consumption Time: 0.09700
Total Iteration Time: 3.41745

Cumulative Model Updates: 22,124
Cumulative Timesteps: 369,377,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 369377252...
Checkpoint 369377252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,971.42395
Policy Entropy: 0.86117
Value Function Loss: 0.05615

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03013
Policy Update Magnitude: 0.03035
Value Function Update Magnitude: 0.04994

Collected Steps per Second: 22,332.78121
Overall Steps per Second: 16,447.80763

Timestep Collection Time: 2.23949
Timestep Consumption Time: 0.80128
PPO Batch Consumption Time: 0.06114
Total Iteration Time: 3.04077

Cumulative Model Updates: 22,127
Cumulative Timesteps: 369,427,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,971.43080
Policy Entropy: 0.85540
Value Function Loss: 0.05438

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02205
Policy Update Magnitude: 0.02849
Value Function Update Magnitude: 0.05070

Collected Steps per Second: 20,709.13640
Overall Steps per Second: 14,986.69655

Timestep Collection Time: 2.41555
Timestep Consumption Time: 0.92234
PPO Batch Consumption Time: 0.09351
Total Iteration Time: 3.33789

Cumulative Model Updates: 22,130
Cumulative Timesteps: 369,477,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 369477290...
Checkpoint 369477290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,596.76106
Policy Entropy: 0.85703
Value Function Loss: 0.05435

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02663
Policy Update Magnitude: 0.02777
Value Function Update Magnitude: 0.04650

Collected Steps per Second: 22,103.08351
Overall Steps per Second: 16,279.64551

Timestep Collection Time: 2.26222
Timestep Consumption Time: 0.80922
PPO Batch Consumption Time: 0.06415
Total Iteration Time: 3.07144

Cumulative Model Updates: 22,133
Cumulative Timesteps: 369,527,292

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,895.60060
Policy Entropy: 0.86888
Value Function Loss: 0.05646

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03351
Policy Update Magnitude: 0.02826
Value Function Update Magnitude: 0.03830

Collected Steps per Second: 22,781.08331
Overall Steps per Second: 16,782.10108

Timestep Collection Time: 2.19524
Timestep Consumption Time: 0.78472
PPO Batch Consumption Time: 0.06155
Total Iteration Time: 2.97996

Cumulative Model Updates: 22,136
Cumulative Timesteps: 369,577,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 369577302...
Checkpoint 369577302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,463.06494
Policy Entropy: 0.87287
Value Function Loss: 0.06558

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04547
Policy Update Magnitude: 0.03168
Value Function Update Magnitude: 0.03396

Collected Steps per Second: 22,412.94053
Overall Steps per Second: 16,485.83054

Timestep Collection Time: 2.23219
Timestep Consumption Time: 0.80253
PPO Batch Consumption Time: 0.06245
Total Iteration Time: 3.03473

Cumulative Model Updates: 22,139
Cumulative Timesteps: 369,627,332

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,315.05080
Policy Entropy: 0.87062
Value Function Loss: 0.06868

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04963
Policy Update Magnitude: 0.03166
Value Function Update Magnitude: 0.03459

Collected Steps per Second: 22,673.35204
Overall Steps per Second: 16,585.77836

Timestep Collection Time: 2.20585
Timestep Consumption Time: 0.80963
PPO Batch Consumption Time: 0.06187
Total Iteration Time: 3.01547

Cumulative Model Updates: 22,142
Cumulative Timesteps: 369,677,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 369677346...
Checkpoint 369677346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,013.27682
Policy Entropy: 0.86183
Value Function Loss: 0.07398

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02854
Policy Update Magnitude: 0.03030
Value Function Update Magnitude: 0.03256

Collected Steps per Second: 20,387.55178
Overall Steps per Second: 14,640.87104

Timestep Collection Time: 2.45356
Timestep Consumption Time: 0.96304
PPO Batch Consumption Time: 0.11387
Total Iteration Time: 3.41660

Cumulative Model Updates: 22,145
Cumulative Timesteps: 369,727,368

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,578.06147
Policy Entropy: 0.86191
Value Function Loss: 0.07457

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02968
Policy Update Magnitude: 0.03289
Value Function Update Magnitude: 0.03393

Collected Steps per Second: 22,817.46204
Overall Steps per Second: 16,751.87293

Timestep Collection Time: 2.19201
Timestep Consumption Time: 0.79369
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 2.98570

Cumulative Model Updates: 22,148
Cumulative Timesteps: 369,777,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 369777384...
Checkpoint 369777384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,340.48943
Policy Entropy: 0.86034
Value Function Loss: 0.07555

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02881
Policy Update Magnitude: 0.03466
Value Function Update Magnitude: 0.03316

Collected Steps per Second: 20,046.86659
Overall Steps per Second: 14,718.92581

Timestep Collection Time: 2.49525
Timestep Consumption Time: 0.90323
PPO Batch Consumption Time: 0.09174
Total Iteration Time: 3.39848

Cumulative Model Updates: 22,151
Cumulative Timesteps: 369,827,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,933.01027
Policy Entropy: 0.85050
Value Function Loss: 0.08178

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03722
Policy Update Magnitude: 0.03473
Value Function Update Magnitude: 0.04156

Collected Steps per Second: 22,518.12108
Overall Steps per Second: 16,568.12628

Timestep Collection Time: 2.22132
Timestep Consumption Time: 0.79773
PPO Batch Consumption Time: 0.05908
Total Iteration Time: 3.01905

Cumulative Model Updates: 22,154
Cumulative Timesteps: 369,877,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 369877426...
Checkpoint 369877426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,047.46714
Policy Entropy: 0.84664
Value Function Loss: 0.08808

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04581
Policy Update Magnitude: 0.03327
Value Function Update Magnitude: 0.03897

Collected Steps per Second: 20,144.33958
Overall Steps per Second: 14,720.74545

Timestep Collection Time: 2.48348
Timestep Consumption Time: 0.91499
PPO Batch Consumption Time: 0.08059
Total Iteration Time: 3.39847

Cumulative Model Updates: 22,157
Cumulative Timesteps: 369,927,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,808.02045
Policy Entropy: 0.85306
Value Function Loss: 0.08752

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03864
Policy Update Magnitude: 0.03275
Value Function Update Magnitude: 0.03756

Collected Steps per Second: 22,742.20225
Overall Steps per Second: 16,714.93648

Timestep Collection Time: 2.20049
Timestep Consumption Time: 0.79348
PPO Batch Consumption Time: 0.06225
Total Iteration Time: 2.99397

Cumulative Model Updates: 22,160
Cumulative Timesteps: 369,977,498

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 369977498...
Checkpoint 369977498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,587.35919
Policy Entropy: 0.87327
Value Function Loss: 0.06338

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.03354
Value Function Update Magnitude: 0.04019

Collected Steps per Second: 19,909.77520
Overall Steps per Second: 15,026.48333

Timestep Collection Time: 2.51264
Timestep Consumption Time: 0.81655
PPO Batch Consumption Time: 0.08432
Total Iteration Time: 3.32919

Cumulative Model Updates: 22,163
Cumulative Timesteps: 370,027,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,518.40795
Policy Entropy: 0.87826
Value Function Loss: 0.05793

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04979
Policy Update Magnitude: 0.03311
Value Function Update Magnitude: 0.04026

Collected Steps per Second: 21,774.81318
Overall Steps per Second: 16,662.81580

Timestep Collection Time: 2.29651
Timestep Consumption Time: 0.70455
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 3.00105

Cumulative Model Updates: 22,166
Cumulative Timesteps: 370,077,530

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 370077530...
Checkpoint 370077530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,304.12874
Policy Entropy: 0.86826
Value Function Loss: 0.06058

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.05108
Policy Update Magnitude: 0.03149
Value Function Update Magnitude: 0.03918

Collected Steps per Second: 19,706.68799
Overall Steps per Second: 14,804.45061

Timestep Collection Time: 2.53812
Timestep Consumption Time: 0.84046
PPO Batch Consumption Time: 0.08967
Total Iteration Time: 3.37858

Cumulative Model Updates: 22,169
Cumulative Timesteps: 370,127,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,012.95233
Policy Entropy: 0.85633
Value Function Loss: 0.07317

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04005
Policy Update Magnitude: 0.03050
Value Function Update Magnitude: 0.03924

Collected Steps per Second: 21,622.08881
Overall Steps per Second: 16,430.69234

Timestep Collection Time: 2.31402
Timestep Consumption Time: 0.73113
PPO Batch Consumption Time: 0.06174
Total Iteration Time: 3.04515

Cumulative Model Updates: 22,172
Cumulative Timesteps: 370,177,582

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 370177582...
Checkpoint 370177582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,851.38656
Policy Entropy: 0.85995
Value Function Loss: 0.07121

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.03198
Value Function Update Magnitude: 0.03640

Collected Steps per Second: 19,730.53612
Overall Steps per Second: 15,052.74950

Timestep Collection Time: 2.53414
Timestep Consumption Time: 0.78751
PPO Batch Consumption Time: 0.07649
Total Iteration Time: 3.32165

Cumulative Model Updates: 22,175
Cumulative Timesteps: 370,227,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,528.22721
Policy Entropy: 0.84694
Value Function Loss: 0.07305

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03723
Policy Update Magnitude: 0.03749
Value Function Update Magnitude: 0.04757

Collected Steps per Second: 22,159.88791
Overall Steps per Second: 16,810.76728

Timestep Collection Time: 2.25768
Timestep Consumption Time: 0.71839
PPO Batch Consumption Time: 0.05874
Total Iteration Time: 2.97607

Cumulative Model Updates: 22,178
Cumulative Timesteps: 370,277,612

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 370277612...
Checkpoint 370277612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,079.32914
Policy Entropy: 0.84180
Value Function Loss: 0.07284

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.05132
Policy Update Magnitude: 0.04535
Value Function Update Magnitude: 0.06657

Collected Steps per Second: 19,480.95126
Overall Steps per Second: 14,715.94475

Timestep Collection Time: 2.56712
Timestep Consumption Time: 0.83123
PPO Batch Consumption Time: 0.09659
Total Iteration Time: 3.39835

Cumulative Model Updates: 22,181
Cumulative Timesteps: 370,327,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,749.03527
Policy Entropy: 0.83075
Value Function Loss: 0.07358

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04683
Policy Update Magnitude: 0.04423
Value Function Update Magnitude: 0.06527

Collected Steps per Second: 21,380.47617
Overall Steps per Second: 16,367.53226

Timestep Collection Time: 2.33933
Timestep Consumption Time: 0.71648
PPO Batch Consumption Time: 0.05910
Total Iteration Time: 3.05581

Cumulative Model Updates: 22,184
Cumulative Timesteps: 370,377,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 370377638...
Checkpoint 370377638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,616.03866
Policy Entropy: 0.85015
Value Function Loss: 0.06238

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06523
Policy Update Magnitude: 0.04135
Value Function Update Magnitude: 0.05776

Collected Steps per Second: 20,379.63164
Overall Steps per Second: 15,120.27458

Timestep Collection Time: 2.45471
Timestep Consumption Time: 0.85383
PPO Batch Consumption Time: 0.10357
Total Iteration Time: 3.30854

Cumulative Model Updates: 22,187
Cumulative Timesteps: 370,427,664

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,629.70249
Policy Entropy: 0.84604
Value Function Loss: 0.05843

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06671
Policy Update Magnitude: 0.03925
Value Function Update Magnitude: 0.05112

Collected Steps per Second: 21,897.07926
Overall Steps per Second: 16,731.19810

Timestep Collection Time: 2.28478
Timestep Consumption Time: 0.70544
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 2.99022

Cumulative Model Updates: 22,190
Cumulative Timesteps: 370,477,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 370477694...
Checkpoint 370477694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,073.45597
Policy Entropy: 0.86522
Value Function Loss: 0.05661

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05417
Policy Update Magnitude: 0.03517
Value Function Update Magnitude: 0.04981

Collected Steps per Second: 19,597.81140
Overall Steps per Second: 14,018.04118

Timestep Collection Time: 2.55151
Timestep Consumption Time: 1.01561
PPO Batch Consumption Time: 0.12988
Total Iteration Time: 3.56712

Cumulative Model Updates: 22,193
Cumulative Timesteps: 370,527,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,788.27318
Policy Entropy: 0.85278
Value Function Loss: 0.05958

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05885
Policy Update Magnitude: 0.03204
Value Function Update Magnitude: 0.04548

Collected Steps per Second: 22,998.50135
Overall Steps per Second: 17,042.97907

Timestep Collection Time: 2.17475
Timestep Consumption Time: 0.75995
PPO Batch Consumption Time: 0.05902
Total Iteration Time: 2.93470

Cumulative Model Updates: 22,196
Cumulative Timesteps: 370,577,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 370577714...
Checkpoint 370577714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,861.17371
Policy Entropy: 0.85947
Value Function Loss: 0.05568

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04812
Policy Update Magnitude: 0.03182
Value Function Update Magnitude: 0.04599

Collected Steps per Second: 22,311.11706
Overall Steps per Second: 16,660.71292

Timestep Collection Time: 2.24112
Timestep Consumption Time: 0.76007
PPO Batch Consumption Time: 0.05930
Total Iteration Time: 3.00119

Cumulative Model Updates: 22,199
Cumulative Timesteps: 370,627,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,431.42890
Policy Entropy: 0.85386
Value Function Loss: 0.05437

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06531
Policy Update Magnitude: 0.02879
Value Function Update Magnitude: 0.04834

Collected Steps per Second: 21,017.52001
Overall Steps per Second: 15,351.78702

Timestep Collection Time: 2.37906
Timestep Consumption Time: 0.87802
PPO Batch Consumption Time: 0.07794
Total Iteration Time: 3.25708

Cumulative Model Updates: 22,202
Cumulative Timesteps: 370,677,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 370677718...
Checkpoint 370677718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,533.66989
Policy Entropy: 0.86246
Value Function Loss: 0.05707

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03968
Policy Update Magnitude: 0.02889
Value Function Update Magnitude: 0.04450

Collected Steps per Second: 22,581.99894
Overall Steps per Second: 16,814.96574

Timestep Collection Time: 2.21460
Timestep Consumption Time: 0.75954
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 2.97414

Cumulative Model Updates: 22,205
Cumulative Timesteps: 370,727,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,598.10006
Policy Entropy: 0.85897
Value Function Loss: 0.05870

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02956
Policy Update Magnitude: 0.02939
Value Function Update Magnitude: 0.04851

Collected Steps per Second: 19,922.61276
Overall Steps per Second: 14,546.60822

Timestep Collection Time: 2.51041
Timestep Consumption Time: 0.92778
PPO Batch Consumption Time: 0.08446
Total Iteration Time: 3.43819

Cumulative Model Updates: 22,208
Cumulative Timesteps: 370,777,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 370777742...
Checkpoint 370777742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,338.47701
Policy Entropy: 0.86437
Value Function Loss: 0.06193

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03831
Policy Update Magnitude: 0.02933
Value Function Update Magnitude: 0.04628

Collected Steps per Second: 22,106.16510
Overall Steps per Second: 16,268.41360

Timestep Collection Time: 2.26272
Timestep Consumption Time: 0.81195
PPO Batch Consumption Time: 0.06081
Total Iteration Time: 3.07467

Cumulative Model Updates: 22,211
Cumulative Timesteps: 370,827,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,991.30985
Policy Entropy: 0.85250
Value Function Loss: 0.06605

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03383
Policy Update Magnitude: 0.02857
Value Function Update Magnitude: 0.04640

Collected Steps per Second: 22,592.45280
Overall Steps per Second: 16,153.45981

Timestep Collection Time: 2.21437
Timestep Consumption Time: 0.88268
PPO Batch Consumption Time: 0.07966
Total Iteration Time: 3.09705

Cumulative Model Updates: 22,214
Cumulative Timesteps: 370,877,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 370877790...
Checkpoint 370877790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,915.87478
Policy Entropy: 0.86118
Value Function Loss: 0.06857

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04383
Policy Update Magnitude: 0.02916
Value Function Update Magnitude: 0.04706

Collected Steps per Second: 22,324.52511
Overall Steps per Second: 16,385.51511

Timestep Collection Time: 2.24041
Timestep Consumption Time: 0.81205
PPO Batch Consumption Time: 0.05816
Total Iteration Time: 3.05245

Cumulative Model Updates: 22,217
Cumulative Timesteps: 370,927,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,153.32630
Policy Entropy: 0.85294
Value Function Loss: 0.07392

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02377
Policy Update Magnitude: 0.02976
Value Function Update Magnitude: 0.04750

Collected Steps per Second: 22,448.41879
Overall Steps per Second: 16,664.76986

Timestep Collection Time: 2.22822
Timestep Consumption Time: 0.77332
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 3.00154

Cumulative Model Updates: 22,220
Cumulative Timesteps: 370,977,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 370977826...
Checkpoint 370977826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,657.58635
Policy Entropy: 0.86092
Value Function Loss: 0.06682

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02909
Policy Update Magnitude: 0.03101
Value Function Update Magnitude: 0.05250

Collected Steps per Second: 22,148.94459
Overall Steps per Second: 16,442.89692

Timestep Collection Time: 2.25771
Timestep Consumption Time: 0.78348
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 3.04119

Cumulative Model Updates: 22,223
Cumulative Timesteps: 371,027,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,192.65630
Policy Entropy: 0.86142
Value Function Loss: 0.06842

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01996
Policy Update Magnitude: 0.03553
Value Function Update Magnitude: 0.05188

Collected Steps per Second: 20,304.66168
Overall Steps per Second: 14,642.23148

Timestep Collection Time: 2.46308
Timestep Consumption Time: 0.95252
PPO Batch Consumption Time: 0.09203
Total Iteration Time: 3.41560

Cumulative Model Updates: 22,226
Cumulative Timesteps: 371,077,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 371077844...
Checkpoint 371077844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,177.13104
Policy Entropy: 0.87099
Value Function Loss: 0.06015

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02876
Policy Update Magnitude: 0.04204
Value Function Update Magnitude: 0.04710

Collected Steps per Second: 22,142.29982
Overall Steps per Second: 16,487.93801

Timestep Collection Time: 2.25902
Timestep Consumption Time: 0.77471
PPO Batch Consumption Time: 0.06071
Total Iteration Time: 3.03373

Cumulative Model Updates: 22,229
Cumulative Timesteps: 371,127,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,510.73196
Policy Entropy: 0.87399
Value Function Loss: 0.05961

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.03717
Value Function Update Magnitude: 0.04601

Collected Steps per Second: 21,207.30176
Overall Steps per Second: 15,017.76788

Timestep Collection Time: 2.35994
Timestep Consumption Time: 0.97264
PPO Batch Consumption Time: 0.10144
Total Iteration Time: 3.33259

Cumulative Model Updates: 22,232
Cumulative Timesteps: 371,177,912

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 371177912...
Checkpoint 371177912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,694.75793
Policy Entropy: 0.89066
Value Function Loss: 0.05847

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02437
Policy Update Magnitude: 0.03424
Value Function Update Magnitude: 0.04539

Collected Steps per Second: 22,400.17710
Overall Steps per Second: 16,496.53638

Timestep Collection Time: 2.23338
Timestep Consumption Time: 0.79926
PPO Batch Consumption Time: 0.06144
Total Iteration Time: 3.03264

Cumulative Model Updates: 22,235
Cumulative Timesteps: 371,227,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,113.70033
Policy Entropy: 0.88525
Value Function Loss: 0.06296

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03435
Policy Update Magnitude: 0.03361
Value Function Update Magnitude: 0.04721

Collected Steps per Second: 20,393.31158
Overall Steps per Second: 14,941.60316

Timestep Collection Time: 2.45227
Timestep Consumption Time: 0.89476
PPO Batch Consumption Time: 0.09333
Total Iteration Time: 3.34703

Cumulative Model Updates: 22,238
Cumulative Timesteps: 371,277,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 371277950...
Checkpoint 371277950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,333.22026
Policy Entropy: 0.89424
Value Function Loss: 0.06709

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02066
Policy Update Magnitude: 0.03316
Value Function Update Magnitude: 0.04461

Collected Steps per Second: 22,179.28999
Overall Steps per Second: 16,514.59434

Timestep Collection Time: 2.25472
Timestep Consumption Time: 0.77339
PPO Batch Consumption Time: 0.05910
Total Iteration Time: 3.02811

Cumulative Model Updates: 22,241
Cumulative Timesteps: 371,327,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,734.88080
Policy Entropy: 0.89055
Value Function Loss: 0.06208

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03093
Policy Update Magnitude: 0.03107
Value Function Update Magnitude: 0.04195

Collected Steps per Second: 20,569.03608
Overall Steps per Second: 14,910.46772

Timestep Collection Time: 2.43123
Timestep Consumption Time: 0.92266
PPO Batch Consumption Time: 0.09269
Total Iteration Time: 3.35389

Cumulative Model Updates: 22,244
Cumulative Timesteps: 371,377,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 371377966...
Checkpoint 371377966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,542.65056
Policy Entropy: 0.89988
Value Function Loss: 0.05775

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02584
Policy Update Magnitude: 0.03195
Value Function Update Magnitude: 0.04622

Collected Steps per Second: 22,569.28165
Overall Steps per Second: 16,542.83783

Timestep Collection Time: 2.21708
Timestep Consumption Time: 0.80767
PPO Batch Consumption Time: 0.05825
Total Iteration Time: 3.02475

Cumulative Model Updates: 22,247
Cumulative Timesteps: 371,428,004

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,464.38320
Policy Entropy: 0.89926
Value Function Loss: 0.06122

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03259
Policy Update Magnitude: 0.03245
Value Function Update Magnitude: 0.05206

Collected Steps per Second: 20,519.71769
Overall Steps per Second: 14,967.83496

Timestep Collection Time: 2.43727
Timestep Consumption Time: 0.90403
PPO Batch Consumption Time: 0.09692
Total Iteration Time: 3.34130

Cumulative Model Updates: 22,250
Cumulative Timesteps: 371,478,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 371478016...
Checkpoint 371478016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,233.92898
Policy Entropy: 0.89399
Value Function Loss: 0.06442

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02178
Policy Update Magnitude: 0.03175
Value Function Update Magnitude: 0.04878

Collected Steps per Second: 22,086.79649
Overall Steps per Second: 16,334.48767

Timestep Collection Time: 2.26479
Timestep Consumption Time: 0.79756
PPO Batch Consumption Time: 0.06141
Total Iteration Time: 3.06236

Cumulative Model Updates: 22,253
Cumulative Timesteps: 371,528,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,961.65810
Policy Entropy: 0.89353
Value Function Loss: 0.07782

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03705
Policy Update Magnitude: 0.03127
Value Function Update Magnitude: 0.05305

Collected Steps per Second: 22,799.91965
Overall Steps per Second: 16,072.01052

Timestep Collection Time: 2.19396
Timestep Consumption Time: 0.91841
PPO Batch Consumption Time: 0.10063
Total Iteration Time: 3.11237

Cumulative Model Updates: 22,256
Cumulative Timesteps: 371,578,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 371578060...
Checkpoint 371578060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,338.09437
Policy Entropy: 0.88734
Value Function Loss: 0.06964

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03705
Policy Update Magnitude: 0.03347
Value Function Update Magnitude: 0.06055

Collected Steps per Second: 22,392.84045
Overall Steps per Second: 16,534.74578

Timestep Collection Time: 2.23330
Timestep Consumption Time: 0.79124
PPO Batch Consumption Time: 0.06119
Total Iteration Time: 3.02454

Cumulative Model Updates: 22,259
Cumulative Timesteps: 371,628,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,813.83008
Policy Entropy: 0.89611
Value Function Loss: 0.06966

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04179
Policy Update Magnitude: 0.03312
Value Function Update Magnitude: 0.06735

Collected Steps per Second: 19,953.78527
Overall Steps per Second: 14,660.94656

Timestep Collection Time: 2.50699
Timestep Consumption Time: 0.90506
PPO Batch Consumption Time: 0.08698
Total Iteration Time: 3.41206

Cumulative Model Updates: 22,262
Cumulative Timesteps: 371,678,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 371678094...
Checkpoint 371678094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,474.93554
Policy Entropy: 0.89680
Value Function Loss: 0.05063

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.05045
Policy Update Magnitude: 0.03268
Value Function Update Magnitude: 0.06408

Collected Steps per Second: 22,367.74308
Overall Steps per Second: 16,010.28130

Timestep Collection Time: 2.23617
Timestep Consumption Time: 0.88795
PPO Batch Consumption Time: 0.08527
Total Iteration Time: 3.12412

Cumulative Model Updates: 22,265
Cumulative Timesteps: 371,728,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,719.06990
Policy Entropy: 0.89935
Value Function Loss: 0.05628

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02995
Policy Update Magnitude: 0.03279
Value Function Update Magnitude: 0.06248

Collected Steps per Second: 22,691.28531
Overall Steps per Second: 16,584.45654

Timestep Collection Time: 2.20481
Timestep Consumption Time: 0.81187
PPO Batch Consumption Time: 0.06230
Total Iteration Time: 3.01668

Cumulative Model Updates: 22,268
Cumulative Timesteps: 371,778,142

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 371778142...
Checkpoint 371778142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,417.02982
Policy Entropy: 0.89659
Value Function Loss: 0.05945

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03363
Policy Update Magnitude: 0.03199
Value Function Update Magnitude: 0.05893

Collected Steps per Second: 20,243.45230
Overall Steps per Second: 14,917.43336

Timestep Collection Time: 2.47142
Timestep Consumption Time: 0.88238
PPO Batch Consumption Time: 0.07939
Total Iteration Time: 3.35379

Cumulative Model Updates: 22,271
Cumulative Timesteps: 371,828,172

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,994.56263
Policy Entropy: 0.89472
Value Function Loss: 0.07137

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02587
Policy Update Magnitude: 0.03212
Value Function Update Magnitude: 0.05300

Collected Steps per Second: 22,568.81761
Overall Steps per Second: 16,602.82870

Timestep Collection Time: 2.21571
Timestep Consumption Time: 0.79618
PPO Batch Consumption Time: 0.05970
Total Iteration Time: 3.01190

Cumulative Model Updates: 22,274
Cumulative Timesteps: 371,878,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 371878178...
Checkpoint 371878178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,092.93047
Policy Entropy: 0.88040
Value Function Loss: 0.06929

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02606
Policy Update Magnitude: 0.03139
Value Function Update Magnitude: 0.05069

Collected Steps per Second: 20,155.85637
Overall Steps per Second: 14,860.57968

Timestep Collection Time: 2.48067
Timestep Consumption Time: 0.88394
PPO Batch Consumption Time: 0.08825
Total Iteration Time: 3.36461

Cumulative Model Updates: 22,277
Cumulative Timesteps: 371,928,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,294.78973
Policy Entropy: 0.86135
Value Function Loss: 0.07750

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02752
Policy Update Magnitude: 0.03088
Value Function Update Magnitude: 0.04104

Collected Steps per Second: 22,584.45888
Overall Steps per Second: 16,818.32988

Timestep Collection Time: 2.21391
Timestep Consumption Time: 0.75904
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 2.97295

Cumulative Model Updates: 22,280
Cumulative Timesteps: 371,978,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 371978178...
Checkpoint 371978178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,532.36824
Policy Entropy: 0.83310
Value Function Loss: 0.08105

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03928
Policy Update Magnitude: 0.02951
Value Function Update Magnitude: 0.03851

Collected Steps per Second: 21,041.30873
Overall Steps per Second: 14,806.70654

Timestep Collection Time: 2.37656
Timestep Consumption Time: 1.00069
PPO Batch Consumption Time: 0.11880
Total Iteration Time: 3.37725

Cumulative Model Updates: 22,283
Cumulative Timesteps: 372,028,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,140.04356
Policy Entropy: 0.84785
Value Function Loss: 0.09378

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04936
Policy Update Magnitude: 0.03087
Value Function Update Magnitude: 0.03627

Collected Steps per Second: 22,893.91577
Overall Steps per Second: 17,053.33805

Timestep Collection Time: 2.18565
Timestep Consumption Time: 0.74856
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 2.93421

Cumulative Model Updates: 22,286
Cumulative Timesteps: 372,078,222

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 372078222...
Checkpoint 372078222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,591.51304
Policy Entropy: 0.86339
Value Function Loss: 0.07901

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04679
Policy Update Magnitude: 0.03177
Value Function Update Magnitude: 0.03512

Collected Steps per Second: 22,531.25760
Overall Steps per Second: 16,186.75872

Timestep Collection Time: 2.21923
Timestep Consumption Time: 0.86984
PPO Batch Consumption Time: 0.08340
Total Iteration Time: 3.08907

Cumulative Model Updates: 22,289
Cumulative Timesteps: 372,128,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,783.37756
Policy Entropy: 0.89385
Value Function Loss: 0.06973

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.06126
Policy Update Magnitude: 0.02979
Value Function Update Magnitude: 0.03900

Collected Steps per Second: 22,485.37480
Overall Steps per Second: 16,585.95373

Timestep Collection Time: 2.22438
Timestep Consumption Time: 0.79118
PPO Batch Consumption Time: 0.05941
Total Iteration Time: 3.01556

Cumulative Model Updates: 22,292
Cumulative Timesteps: 372,178,240

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 372178240...
Checkpoint 372178240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,818.31403
Policy Entropy: 0.90186
Value Function Loss: 0.05817

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05561
Policy Update Magnitude: 0.02905
Value Function Update Magnitude: 0.03989

Collected Steps per Second: 21,232.95699
Overall Steps per Second: 15,082.43579

Timestep Collection Time: 2.35492
Timestep Consumption Time: 0.96032
PPO Batch Consumption Time: 0.11545
Total Iteration Time: 3.31525

Cumulative Model Updates: 22,295
Cumulative Timesteps: 372,228,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,085.93651
Policy Entropy: 0.89953
Value Function Loss: 0.06203

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06515
Policy Update Magnitude: 0.02992
Value Function Update Magnitude: 0.03838

Collected Steps per Second: 22,560.48827
Overall Steps per Second: 16,616.70519

Timestep Collection Time: 2.21786
Timestep Consumption Time: 0.79333
PPO Batch Consumption Time: 0.06080
Total Iteration Time: 3.01119

Cumulative Model Updates: 22,298
Cumulative Timesteps: 372,278,278

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 372278278...
Checkpoint 372278278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,283.13708
Policy Entropy: 0.88513
Value Function Loss: 0.06881

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06067
Policy Update Magnitude: 0.02893
Value Function Update Magnitude: 0.03729

Collected Steps per Second: 20,059.18566
Overall Steps per Second: 14,653.89344

Timestep Collection Time: 2.49422
Timestep Consumption Time: 0.92003
PPO Batch Consumption Time: 0.08919
Total Iteration Time: 3.41425

Cumulative Model Updates: 22,301
Cumulative Timesteps: 372,328,310

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,594.69976
Policy Entropy: 0.87873
Value Function Loss: 0.06819

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05167
Policy Update Magnitude: 0.02968
Value Function Update Magnitude: 0.03511

Collected Steps per Second: 22,695.44520
Overall Steps per Second: 16,700.67810

Timestep Collection Time: 2.20450
Timestep Consumption Time: 0.79131
PPO Batch Consumption Time: 0.05957
Total Iteration Time: 2.99581

Cumulative Model Updates: 22,304
Cumulative Timesteps: 372,378,342

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 372378342...
Checkpoint 372378342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,858.03112
Policy Entropy: 0.87799
Value Function Loss: 0.06976

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06003
Policy Update Magnitude: 0.02952
Value Function Update Magnitude: 0.03865

Collected Steps per Second: 20,529.88010
Overall Steps per Second: 15,006.74974

Timestep Collection Time: 2.43791
Timestep Consumption Time: 0.89726
PPO Batch Consumption Time: 0.09101
Total Iteration Time: 3.33517

Cumulative Model Updates: 22,307
Cumulative Timesteps: 372,428,392

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,186.29875
Policy Entropy: 0.87718
Value Function Loss: 0.06663

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05747
Policy Update Magnitude: 0.03019
Value Function Update Magnitude: 0.03615

Collected Steps per Second: 22,226.71121
Overall Steps per Second: 16,447.26625

Timestep Collection Time: 2.25144
Timestep Consumption Time: 0.79114
PPO Batch Consumption Time: 0.05834
Total Iteration Time: 3.04257

Cumulative Model Updates: 22,310
Cumulative Timesteps: 372,478,434

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 372478434...
Checkpoint 372478434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,605.15335
Policy Entropy: 0.86670
Value Function Loss: 0.06819

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.05393
Policy Update Magnitude: 0.03119
Value Function Update Magnitude: 0.03446

Collected Steps per Second: 20,647.90683
Overall Steps per Second: 15,019.32205

Timestep Collection Time: 2.42223
Timestep Consumption Time: 0.90775
PPO Batch Consumption Time: 0.09883
Total Iteration Time: 3.32998

Cumulative Model Updates: 22,313
Cumulative Timesteps: 372,528,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,779.63384
Policy Entropy: 0.86878
Value Function Loss: 0.07253

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05044
Policy Update Magnitude: 0.02913
Value Function Update Magnitude: 0.03704

Collected Steps per Second: 22,486.82791
Overall Steps per Second: 16,522.88506

Timestep Collection Time: 2.22432
Timestep Consumption Time: 0.80287
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 3.02720

Cumulative Model Updates: 22,316
Cumulative Timesteps: 372,578,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 372578466...
Checkpoint 372578466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,773.12286
Policy Entropy: 0.87310
Value Function Loss: 0.07012

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.04508
Policy Update Magnitude: 0.03144
Value Function Update Magnitude: 0.03735

Collected Steps per Second: 20,402.98298
Overall Steps per Second: 14,931.42938

Timestep Collection Time: 2.45121
Timestep Consumption Time: 0.89823
PPO Batch Consumption Time: 0.08588
Total Iteration Time: 3.34944

Cumulative Model Updates: 22,319
Cumulative Timesteps: 372,628,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,855.34637
Policy Entropy: 0.86902
Value Function Loss: 0.07623

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.05843
Policy Update Magnitude: 0.03291
Value Function Update Magnitude: 0.03268

Collected Steps per Second: 22,611.98939
Overall Steps per Second: 16,887.92691

Timestep Collection Time: 2.21263
Timestep Consumption Time: 0.74996
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 2.96259

Cumulative Model Updates: 22,322
Cumulative Timesteps: 372,678,510

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 372678510...
Checkpoint 372678510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,382.86658
Policy Entropy: 0.85822
Value Function Loss: 0.06889

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.06157
Policy Update Magnitude: 0.03027
Value Function Update Magnitude: 0.03531

Collected Steps per Second: 20,265.09829
Overall Steps per Second: 14,661.50199

Timestep Collection Time: 2.46730
Timestep Consumption Time: 0.94300
PPO Batch Consumption Time: 0.09995
Total Iteration Time: 3.41029

Cumulative Model Updates: 22,325
Cumulative Timesteps: 372,728,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,041.34032
Policy Entropy: 0.85964
Value Function Loss: 0.07438

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06539
Policy Update Magnitude: 0.03197
Value Function Update Magnitude: 0.04064

Collected Steps per Second: 22,437.41424
Overall Steps per Second: 16,450.28690

Timestep Collection Time: 2.22994
Timestep Consumption Time: 0.81159
PPO Batch Consumption Time: 0.06370
Total Iteration Time: 3.04153

Cumulative Model Updates: 22,328
Cumulative Timesteps: 372,778,544

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 372778544...
Checkpoint 372778544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,226.44979
Policy Entropy: 0.85836
Value Function Loss: 0.06844

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06867
Policy Update Magnitude: 0.03009
Value Function Update Magnitude: 0.03484

Collected Steps per Second: 20,034.64172
Overall Steps per Second: 14,192.53711

Timestep Collection Time: 2.49578
Timestep Consumption Time: 1.02734
PPO Batch Consumption Time: 0.10335
Total Iteration Time: 3.52312

Cumulative Model Updates: 22,331
Cumulative Timesteps: 372,828,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,078.06111
Policy Entropy: 0.86714
Value Function Loss: 0.07795

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04467
Policy Update Magnitude: 0.03129
Value Function Update Magnitude: 0.03370

Collected Steps per Second: 22,601.02911
Overall Steps per Second: 16,714.66604

Timestep Collection Time: 2.21273
Timestep Consumption Time: 0.77925
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 2.99198

Cumulative Model Updates: 22,334
Cumulative Timesteps: 372,878,556

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 372878556...
Checkpoint 372878556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,471.24157
Policy Entropy: 0.86211
Value Function Loss: 0.07627

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04193
Policy Update Magnitude: 0.03175
Value Function Update Magnitude: 0.03269

Collected Steps per Second: 19,398.52092
Overall Steps per Second: 13,964.54686

Timestep Collection Time: 2.57752
Timestep Consumption Time: 1.00298
PPO Batch Consumption Time: 0.12965
Total Iteration Time: 3.58050

Cumulative Model Updates: 22,337
Cumulative Timesteps: 372,928,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,250.03271
Policy Entropy: 0.86716
Value Function Loss: 0.07134

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02762
Policy Update Magnitude: 0.03382
Value Function Update Magnitude: 0.03346

Collected Steps per Second: 22,780.96278
Overall Steps per Second: 16,891.80460

Timestep Collection Time: 2.19543
Timestep Consumption Time: 0.76541
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 2.96084

Cumulative Model Updates: 22,340
Cumulative Timesteps: 372,978,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 372978570...
Checkpoint 372978570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,454.52123
Policy Entropy: 0.85745
Value Function Loss: 0.06790

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02070
Policy Update Magnitude: 0.03533
Value Function Update Magnitude: 0.03219

Collected Steps per Second: 20,733.75229
Overall Steps per Second: 14,729.62948

Timestep Collection Time: 2.41211
Timestep Consumption Time: 0.98323
PPO Batch Consumption Time: 0.12507
Total Iteration Time: 3.39533

Cumulative Model Updates: 22,343
Cumulative Timesteps: 373,028,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,329.61899
Policy Entropy: 0.84912
Value Function Loss: 0.07498

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03384
Policy Update Magnitude: 0.03311
Value Function Update Magnitude: 0.03525

Collected Steps per Second: 22,653.24040
Overall Steps per Second: 16,808.46202

Timestep Collection Time: 2.20754
Timestep Consumption Time: 0.76763
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 2.97517

Cumulative Model Updates: 22,346
Cumulative Timesteps: 373,078,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 373078590...
Checkpoint 373078590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,859.18748
Policy Entropy: 0.84234
Value Function Loss: 0.07472

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02847
Policy Update Magnitude: 0.03166
Value Function Update Magnitude: 0.03677

Collected Steps per Second: 20,594.47813
Overall Steps per Second: 14,645.72480

Timestep Collection Time: 2.42890
Timestep Consumption Time: 0.98656
PPO Batch Consumption Time: 0.11619
Total Iteration Time: 3.41547

Cumulative Model Updates: 22,349
Cumulative Timesteps: 373,128,612

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,120.72949
Policy Entropy: 0.83631
Value Function Loss: 0.07656

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04533
Policy Update Magnitude: 0.03106
Value Function Update Magnitude: 0.03542

Collected Steps per Second: 22,519.22023
Overall Steps per Second: 16,518.57218

Timestep Collection Time: 2.22068
Timestep Consumption Time: 0.80670
PPO Batch Consumption Time: 0.06058
Total Iteration Time: 3.02738

Cumulative Model Updates: 22,352
Cumulative Timesteps: 373,178,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 373178620...
Checkpoint 373178620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,467.81916
Policy Entropy: 0.83865
Value Function Loss: 0.07325

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03628
Policy Update Magnitude: 0.03240
Value Function Update Magnitude: 0.03462

Collected Steps per Second: 20,869.50802
Overall Steps per Second: 14,999.46512

Timestep Collection Time: 2.39584
Timestep Consumption Time: 0.93761
PPO Batch Consumption Time: 0.11053
Total Iteration Time: 3.33345

Cumulative Model Updates: 22,355
Cumulative Timesteps: 373,228,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,892.03803
Policy Entropy: 0.83084
Value Function Loss: 0.07777

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.04129
Policy Update Magnitude: 0.03337
Value Function Update Magnitude: 0.03261

Collected Steps per Second: 22,351.64893
Overall Steps per Second: 16,730.60909

Timestep Collection Time: 2.23751
Timestep Consumption Time: 0.75174
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 2.98925

Cumulative Model Updates: 22,358
Cumulative Timesteps: 373,278,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 373278632...
Checkpoint 373278632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,383.18402
Policy Entropy: 0.84038
Value Function Loss: 0.08033

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.07153
Policy Update Magnitude: 0.03332
Value Function Update Magnitude: 0.03406

Collected Steps per Second: 20,612.59137
Overall Steps per Second: 14,777.13247

Timestep Collection Time: 2.42570
Timestep Consumption Time: 0.95790
PPO Batch Consumption Time: 0.11620
Total Iteration Time: 3.38361

Cumulative Model Updates: 22,361
Cumulative Timesteps: 373,328,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,477.60344
Policy Entropy: 0.83727
Value Function Loss: 0.07730

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.03076
Value Function Update Magnitude: 0.03423

Collected Steps per Second: 23,011.75151
Overall Steps per Second: 16,812.40430

Timestep Collection Time: 2.17437
Timestep Consumption Time: 0.80177
PPO Batch Consumption Time: 0.05817
Total Iteration Time: 2.97614

Cumulative Model Updates: 22,364
Cumulative Timesteps: 373,378,668

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 373378668...
Checkpoint 373378668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,085.30836
Policy Entropy: 0.83862
Value Function Loss: 0.08106

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.06189
Policy Update Magnitude: 0.02948
Value Function Update Magnitude: 0.03708

Collected Steps per Second: 19,608.82461
Overall Steps per Second: 14,446.41478

Timestep Collection Time: 2.55120
Timestep Consumption Time: 0.91167
PPO Batch Consumption Time: 0.08434
Total Iteration Time: 3.46287

Cumulative Model Updates: 22,367
Cumulative Timesteps: 373,428,694

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,278.01369
Policy Entropy: 0.83888
Value Function Loss: 0.07425

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05326
Policy Update Magnitude: 0.02953
Value Function Update Magnitude: 0.03577

Collected Steps per Second: 22,458.50822
Overall Steps per Second: 16,569.39276

Timestep Collection Time: 2.22642
Timestep Consumption Time: 0.79132
PPO Batch Consumption Time: 0.05971
Total Iteration Time: 3.01773

Cumulative Model Updates: 22,370
Cumulative Timesteps: 373,478,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 373478696...
Checkpoint 373478696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,937.96834
Policy Entropy: 0.83740
Value Function Loss: 0.07575

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03803
Policy Update Magnitude: 0.03350
Value Function Update Magnitude: 0.03562

Collected Steps per Second: 20,964.61009
Overall Steps per Second: 15,145.78178

Timestep Collection Time: 2.38631
Timestep Consumption Time: 0.91679
PPO Batch Consumption Time: 0.09685
Total Iteration Time: 3.30310

Cumulative Model Updates: 22,373
Cumulative Timesteps: 373,528,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,212.12926
Policy Entropy: 0.84347
Value Function Loss: 0.07299

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04714
Policy Update Magnitude: 0.03306
Value Function Update Magnitude: 0.03777

Collected Steps per Second: 22,158.20019
Overall Steps per Second: 16,369.54096

Timestep Collection Time: 2.25731
Timestep Consumption Time: 0.79824
PPO Batch Consumption Time: 0.05994
Total Iteration Time: 3.05555

Cumulative Model Updates: 22,376
Cumulative Timesteps: 373,578,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 373578742...
Checkpoint 373578742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,240.49592
Policy Entropy: 0.83715
Value Function Loss: 0.07435

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03332
Policy Update Magnitude: 0.03410
Value Function Update Magnitude: 0.03948

Collected Steps per Second: 21,032.53638
Overall Steps per Second: 15,052.97330

Timestep Collection Time: 2.37784
Timestep Consumption Time: 0.94456
PPO Batch Consumption Time: 0.09766
Total Iteration Time: 3.32240

Cumulative Model Updates: 22,379
Cumulative Timesteps: 373,628,754

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,538.26479
Policy Entropy: 0.84354
Value Function Loss: 0.07725

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03945
Policy Update Magnitude: 0.03420
Value Function Update Magnitude: 0.04363

Collected Steps per Second: 22,433.15671
Overall Steps per Second: 16,483.36723

Timestep Collection Time: 2.22884
Timestep Consumption Time: 0.80452
PPO Batch Consumption Time: 0.06147
Total Iteration Time: 3.03336

Cumulative Model Updates: 22,382
Cumulative Timesteps: 373,678,754

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 373678754...
Checkpoint 373678754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,312.65080
Policy Entropy: 0.83689
Value Function Loss: 0.07721

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03595
Policy Update Magnitude: 0.03254
Value Function Update Magnitude: 0.04569

Collected Steps per Second: 20,649.12944
Overall Steps per Second: 15,002.53192

Timestep Collection Time: 2.42160
Timestep Consumption Time: 0.91143
PPO Batch Consumption Time: 0.09922
Total Iteration Time: 3.33304

Cumulative Model Updates: 22,385
Cumulative Timesteps: 373,728,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,303.26005
Policy Entropy: 0.83754
Value Function Loss: 0.07202

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04505
Policy Update Magnitude: 0.03716
Value Function Update Magnitude: 0.04539

Collected Steps per Second: 22,712.29354
Overall Steps per Second: 16,590.93594

Timestep Collection Time: 2.20154
Timestep Consumption Time: 0.81228
PPO Batch Consumption Time: 0.06000
Total Iteration Time: 3.01381

Cumulative Model Updates: 22,388
Cumulative Timesteps: 373,778,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 373778760...
Checkpoint 373778760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,254.49834
Policy Entropy: 0.83336
Value Function Loss: 0.07113

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03924
Policy Update Magnitude: 0.03744
Value Function Update Magnitude: 0.05047

Collected Steps per Second: 20,121.81645
Overall Steps per Second: 14,107.09494

Timestep Collection Time: 2.48536
Timestep Consumption Time: 1.05966
PPO Batch Consumption Time: 0.12992
Total Iteration Time: 3.54502

Cumulative Model Updates: 22,391
Cumulative Timesteps: 373,828,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,361.87036
Policy Entropy: 0.84506
Value Function Loss: 0.07121

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05254
Policy Update Magnitude: 0.03379
Value Function Update Magnitude: 0.04902

Collected Steps per Second: 23,017.47991
Overall Steps per Second: 17,067.95535

Timestep Collection Time: 2.17348
Timestep Consumption Time: 0.75763
PPO Batch Consumption Time: 0.05869
Total Iteration Time: 2.93111

Cumulative Model Updates: 22,394
Cumulative Timesteps: 373,878,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 373878798...
Checkpoint 373878798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,920.07938
Policy Entropy: 0.84614
Value Function Loss: 0.07553

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03763
Policy Update Magnitude: 0.03173
Value Function Update Magnitude: 0.04626

Collected Steps per Second: 22,295.78586
Overall Steps per Second: 16,607.35295

Timestep Collection Time: 2.24383
Timestep Consumption Time: 0.76857
PPO Batch Consumption Time: 0.05827
Total Iteration Time: 3.01240

Cumulative Model Updates: 22,397
Cumulative Timesteps: 373,928,826

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,882.51779
Policy Entropy: 0.85843
Value Function Loss: 0.07338

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02686
Policy Update Magnitude: 0.03354
Value Function Update Magnitude: 0.04974

Collected Steps per Second: 20,738.54043
Overall Steps per Second: 14,603.74427

Timestep Collection Time: 2.41232
Timestep Consumption Time: 1.01338
PPO Batch Consumption Time: 0.12614
Total Iteration Time: 3.42570

Cumulative Model Updates: 22,400
Cumulative Timesteps: 373,978,854

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 373978854...
Checkpoint 373978854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,896.80674
Policy Entropy: 0.86367
Value Function Loss: 0.06275

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03980
Policy Update Magnitude: 0.03123
Value Function Update Magnitude: 0.04977

Collected Steps per Second: 22,291.11461
Overall Steps per Second: 16,416.94861

Timestep Collection Time: 2.24385
Timestep Consumption Time: 0.80288
PPO Batch Consumption Time: 0.05832
Total Iteration Time: 3.04673

Cumulative Model Updates: 22,403
Cumulative Timesteps: 374,028,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,113.56788
Policy Entropy: 0.86176
Value Function Loss: 0.05424

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02068
Policy Update Magnitude: 0.03010
Value Function Update Magnitude: 0.04794

Collected Steps per Second: 20,964.35092
Overall Steps per Second: 15,011.71148

Timestep Collection Time: 2.38529
Timestep Consumption Time: 0.94585
PPO Batch Consumption Time: 0.10654
Total Iteration Time: 3.33113

Cumulative Model Updates: 22,406
Cumulative Timesteps: 374,078,878

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 374078878...
Checkpoint 374078878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,083.14471
Policy Entropy: 0.84896
Value Function Loss: 0.05504

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02274
Policy Update Magnitude: 0.03067
Value Function Update Magnitude: 0.04374

Collected Steps per Second: 22,436.50645
Overall Steps per Second: 16,564.82963

Timestep Collection Time: 2.22931
Timestep Consumption Time: 0.79022
PPO Batch Consumption Time: 0.05918
Total Iteration Time: 3.01953

Cumulative Model Updates: 22,409
Cumulative Timesteps: 374,128,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,692.55549
Policy Entropy: 0.84624
Value Function Loss: 0.05267

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.01322
Policy Update Magnitude: 0.03595
Value Function Update Magnitude: 0.05051

Collected Steps per Second: 20,441.04252
Overall Steps per Second: 14,825.21575

Timestep Collection Time: 2.44792
Timestep Consumption Time: 0.92728
PPO Batch Consumption Time: 0.09569
Total Iteration Time: 3.37520

Cumulative Model Updates: 22,412
Cumulative Timesteps: 374,178,934

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 374178934...
Checkpoint 374178934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,993.32545
Policy Entropy: 0.85035
Value Function Loss: 0.05300

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02537
Policy Update Magnitude: 0.04086
Value Function Update Magnitude: 0.05612

Collected Steps per Second: 22,238.29853
Overall Steps per Second: 16,420.24158

Timestep Collection Time: 2.24927
Timestep Consumption Time: 0.79697
PPO Batch Consumption Time: 0.05952
Total Iteration Time: 3.04624

Cumulative Model Updates: 22,415
Cumulative Timesteps: 374,228,954

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,204.13567
Policy Entropy: 0.84791
Value Function Loss: 0.05140

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03258
Policy Update Magnitude: 0.03872
Value Function Update Magnitude: 0.05790

Collected Steps per Second: 21,249.06164
Overall Steps per Second: 15,053.32419

Timestep Collection Time: 2.35399
Timestep Consumption Time: 0.96887
PPO Batch Consumption Time: 0.10883
Total Iteration Time: 3.32285

Cumulative Model Updates: 22,418
Cumulative Timesteps: 374,278,974

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 374278974...
Checkpoint 374278974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,149.69275
Policy Entropy: 0.84276
Value Function Loss: 0.05503

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.04058
Value Function Update Magnitude: 0.05728

Collected Steps per Second: 22,391.47469
Overall Steps per Second: 16,461.60326

Timestep Collection Time: 2.23335
Timestep Consumption Time: 0.80451
PPO Batch Consumption Time: 0.06090
Total Iteration Time: 3.03786

Cumulative Model Updates: 22,421
Cumulative Timesteps: 374,328,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,477.82274
Policy Entropy: 0.84783
Value Function Loss: 0.06219

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03993
Policy Update Magnitude: 0.04209
Value Function Update Magnitude: 0.06268

Collected Steps per Second: 20,902.61616
Overall Steps per Second: 14,987.94742

Timestep Collection Time: 2.39243
Timestep Consumption Time: 0.94412
PPO Batch Consumption Time: 0.10410
Total Iteration Time: 3.33655

Cumulative Model Updates: 22,424
Cumulative Timesteps: 374,378,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 374378990...
Checkpoint 374378990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,422.75761
Policy Entropy: 0.83873
Value Function Loss: 0.06179

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03101
Policy Update Magnitude: 0.04233
Value Function Update Magnitude: 0.06787

Collected Steps per Second: 22,489.55285
Overall Steps per Second: 16,500.68160

Timestep Collection Time: 2.22379
Timestep Consumption Time: 0.80712
PPO Batch Consumption Time: 0.06149
Total Iteration Time: 3.03091

Cumulative Model Updates: 22,427
Cumulative Timesteps: 374,429,002

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,404.52596
Policy Entropy: 0.83157
Value Function Loss: 0.06560

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03060
Policy Update Magnitude: 0.03722
Value Function Update Magnitude: 0.06881

Collected Steps per Second: 20,367.43461
Overall Steps per Second: 14,936.36504

Timestep Collection Time: 2.45618
Timestep Consumption Time: 0.89310
PPO Batch Consumption Time: 0.08146
Total Iteration Time: 3.34928

Cumulative Model Updates: 22,430
Cumulative Timesteps: 374,479,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 374479028...
Checkpoint 374479028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,218.94295
Policy Entropy: 0.83447
Value Function Loss: 0.05804

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03661
Policy Update Magnitude: 0.03418
Value Function Update Magnitude: 0.06739

Collected Steps per Second: 22,588.62704
Overall Steps per Second: 16,490.64634

Timestep Collection Time: 2.21465
Timestep Consumption Time: 0.81894
PPO Batch Consumption Time: 0.05842
Total Iteration Time: 3.03360

Cumulative Model Updates: 22,433
Cumulative Timesteps: 374,529,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,961.50926
Policy Entropy: 0.83478
Value Function Loss: 0.05895

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03227
Policy Update Magnitude: 0.03073
Value Function Update Magnitude: 0.06851

Collected Steps per Second: 21,021.82354
Overall Steps per Second: 14,988.36614

Timestep Collection Time: 2.37915
Timestep Consumption Time: 0.95771
PPO Batch Consumption Time: 0.10462
Total Iteration Time: 3.33685

Cumulative Model Updates: 22,436
Cumulative Timesteps: 374,579,068

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 374579068...
Checkpoint 374579068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,475.52801
Policy Entropy: 0.83645
Value Function Loss: 0.05653

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.02935
Value Function Update Magnitude: 0.07034

Collected Steps per Second: 22,471.78492
Overall Steps per Second: 16,630.92028

Timestep Collection Time: 2.22581
Timestep Consumption Time: 0.78172
PPO Batch Consumption Time: 0.05896
Total Iteration Time: 3.00753

Cumulative Model Updates: 22,439
Cumulative Timesteps: 374,629,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,465.03448
Policy Entropy: 0.82843
Value Function Loss: 0.06402

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.04062
Policy Update Magnitude: 0.03052
Value Function Update Magnitude: 0.07218

Collected Steps per Second: 20,515.22061
Overall Steps per Second: 14,834.92724

Timestep Collection Time: 2.43751
Timestep Consumption Time: 0.93332
PPO Batch Consumption Time: 0.09037
Total Iteration Time: 3.37083

Cumulative Model Updates: 22,442
Cumulative Timesteps: 374,679,092

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 374679092...
Checkpoint 374679092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,601.56808
Policy Entropy: 0.83053
Value Function Loss: 0.06813

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03638
Policy Update Magnitude: 0.02997
Value Function Update Magnitude: 0.07080

Collected Steps per Second: 22,831.10232
Overall Steps per Second: 16,658.34804

Timestep Collection Time: 2.19131
Timestep Consumption Time: 0.81199
PPO Batch Consumption Time: 0.05915
Total Iteration Time: 3.00330

Cumulative Model Updates: 22,445
Cumulative Timesteps: 374,729,122

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,683.50684
Policy Entropy: 0.83452
Value Function Loss: 0.07063

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05033
Policy Update Magnitude: 0.03011
Value Function Update Magnitude: 0.07141

Collected Steps per Second: 20,606.34043
Overall Steps per Second: 14,840.00044

Timestep Collection Time: 2.42789
Timestep Consumption Time: 0.94340
PPO Batch Consumption Time: 0.10067
Total Iteration Time: 3.37129

Cumulative Model Updates: 22,448
Cumulative Timesteps: 374,779,152

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 374779152...
Checkpoint 374779152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,031.64261
Policy Entropy: 0.82888
Value Function Loss: 0.07007

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06635
Policy Update Magnitude: 0.02774
Value Function Update Magnitude: 0.06692

Collected Steps per Second: 22,348.00647
Overall Steps per Second: 16,440.80559

Timestep Collection Time: 2.23769
Timestep Consumption Time: 0.80401
PPO Batch Consumption Time: 0.06212
Total Iteration Time: 3.04170

Cumulative Model Updates: 22,451
Cumulative Timesteps: 374,829,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,442.84473
Policy Entropy: 0.82737
Value Function Loss: 0.06237

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05576
Policy Update Magnitude: 0.02797
Value Function Update Magnitude: 0.06399

Collected Steps per Second: 20,997.92132
Overall Steps per Second: 15,019.41887

Timestep Collection Time: 2.38243
Timestep Consumption Time: 0.94833
PPO Batch Consumption Time: 0.10032
Total Iteration Time: 3.33075

Cumulative Model Updates: 22,454
Cumulative Timesteps: 374,879,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 374879186...
Checkpoint 374879186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,108.08199
Policy Entropy: 0.82637
Value Function Loss: 0.06105

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.05595
Policy Update Magnitude: 0.02834
Value Function Update Magnitude: 0.06780

Collected Steps per Second: 22,125.54962
Overall Steps per Second: 16,191.42525

Timestep Collection Time: 2.26073
Timestep Consumption Time: 0.82855
PPO Batch Consumption Time: 0.06718
Total Iteration Time: 3.08929

Cumulative Model Updates: 22,457
Cumulative Timesteps: 374,929,206

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,886.81757
Policy Entropy: 0.81783
Value Function Loss: 0.06427

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05194
Policy Update Magnitude: 0.02969
Value Function Update Magnitude: 0.07110

Collected Steps per Second: 22,707.51010
Overall Steps per Second: 16,743.84561

Timestep Collection Time: 2.20262
Timestep Consumption Time: 0.78451
PPO Batch Consumption Time: 0.06057
Total Iteration Time: 2.98713

Cumulative Model Updates: 22,460
Cumulative Timesteps: 374,979,222

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 374979222...
Checkpoint 374979222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,540.48991
Policy Entropy: 0.81131
Value Function Loss: 0.07170

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06335
Policy Update Magnitude: 0.03205
Value Function Update Magnitude: 0.07192

Collected Steps per Second: 22,555.62655
Overall Steps per Second: 16,615.33808

Timestep Collection Time: 2.21701
Timestep Consumption Time: 0.79262
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 3.00963

Cumulative Model Updates: 22,463
Cumulative Timesteps: 375,029,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,296.12903
Policy Entropy: 0.82029
Value Function Loss: 0.07166

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05347
Policy Update Magnitude: 0.03108
Value Function Update Magnitude: 0.07043

Collected Steps per Second: 22,219.74319
Overall Steps per Second: 16,473.01851

Timestep Collection Time: 2.25088
Timestep Consumption Time: 0.78524
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 3.03612

Cumulative Model Updates: 22,466
Cumulative Timesteps: 375,079,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 375079242...
Checkpoint 375079242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,156.10622
Policy Entropy: 0.81813
Value Function Loss: 0.06643

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04916
Policy Update Magnitude: 0.03022
Value Function Update Magnitude: 0.06819

Collected Steps per Second: 20,476.01768
Overall Steps per Second: 14,663.08669

Timestep Collection Time: 2.44296
Timestep Consumption Time: 0.96847
PPO Batch Consumption Time: 0.10384
Total Iteration Time: 3.41142

Cumulative Model Updates: 22,469
Cumulative Timesteps: 375,129,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,071.09424
Policy Entropy: 0.81785
Value Function Loss: 0.07042

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06087
Policy Update Magnitude: 0.02984
Value Function Update Magnitude: 0.07064

Collected Steps per Second: 22,357.61727
Overall Steps per Second: 16,575.10346

Timestep Collection Time: 2.23691
Timestep Consumption Time: 0.78039
PPO Batch Consumption Time: 0.05870
Total Iteration Time: 3.01730

Cumulative Model Updates: 22,472
Cumulative Timesteps: 375,179,276

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 375179276...
Checkpoint 375179276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,064.84654
Policy Entropy: 0.80602
Value Function Loss: 0.07680

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03246
Policy Update Magnitude: 0.03088
Value Function Update Magnitude: 0.07049

Collected Steps per Second: 20,759.15260
Overall Steps per Second: 14,941.96876

Timestep Collection Time: 2.40867
Timestep Consumption Time: 0.93774
PPO Batch Consumption Time: 0.09674
Total Iteration Time: 3.34641

Cumulative Model Updates: 22,475
Cumulative Timesteps: 375,229,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,366.95357
Policy Entropy: 0.80351
Value Function Loss: 0.08626

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04196
Policy Update Magnitude: 0.03094
Value Function Update Magnitude: 0.07024

Collected Steps per Second: 22,405.16870
Overall Steps per Second: 16,613.17135

Timestep Collection Time: 2.23270
Timestep Consumption Time: 0.77841
PPO Batch Consumption Time: 0.05791
Total Iteration Time: 3.01110

Cumulative Model Updates: 22,478
Cumulative Timesteps: 375,279,302

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 375279302...
Checkpoint 375279302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,530.89652
Policy Entropy: 0.81564
Value Function Loss: 0.07394

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02306
Policy Update Magnitude: 0.03203
Value Function Update Magnitude: 0.07069

Collected Steps per Second: 20,692.47363
Overall Steps per Second: 14,831.59055

Timestep Collection Time: 2.41634
Timestep Consumption Time: 0.95485
PPO Batch Consumption Time: 0.08859
Total Iteration Time: 3.37118

Cumulative Model Updates: 22,481
Cumulative Timesteps: 375,329,302

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,377.24180
Policy Entropy: 0.81756
Value Function Loss: 0.07354

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03178
Policy Update Magnitude: 0.02915
Value Function Update Magnitude: 0.06475

Collected Steps per Second: 22,044.66639
Overall Steps per Second: 16,753.65180

Timestep Collection Time: 2.26839
Timestep Consumption Time: 0.71639
PPO Batch Consumption Time: 0.05780
Total Iteration Time: 2.98478

Cumulative Model Updates: 22,484
Cumulative Timesteps: 375,379,308

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 375379308...
Checkpoint 375379308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,405.04011
Policy Entropy: 0.82779
Value Function Loss: 0.06347

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01999
Policy Update Magnitude: 0.03072
Value Function Update Magnitude: 0.05601

Collected Steps per Second: 19,241.35482
Overall Steps per Second: 14,591.12025

Timestep Collection Time: 2.60023
Timestep Consumption Time: 0.82870
PPO Batch Consumption Time: 0.08634
Total Iteration Time: 3.42893

Cumulative Model Updates: 22,487
Cumulative Timesteps: 375,429,340

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,815.93014
Policy Entropy: 0.82599
Value Function Loss: 0.06659

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01555
Policy Update Magnitude: 0.03148
Value Function Update Magnitude: 0.04850

Collected Steps per Second: 21,778.04414
Overall Steps per Second: 16,580.14350

Timestep Collection Time: 2.29644
Timestep Consumption Time: 0.71994
PPO Batch Consumption Time: 0.05945
Total Iteration Time: 3.01638

Cumulative Model Updates: 22,490
Cumulative Timesteps: 375,479,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 375479352...
Checkpoint 375479352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,126.16843
Policy Entropy: 0.81205
Value Function Loss: 0.06182

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02143
Policy Update Magnitude: 0.02996
Value Function Update Magnitude: 0.04918

Collected Steps per Second: 21,862.20483
Overall Steps per Second: 16,748.02254

Timestep Collection Time: 2.28824
Timestep Consumption Time: 0.69874
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 2.98698

Cumulative Model Updates: 22,493
Cumulative Timesteps: 375,529,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,440.62428
Policy Entropy: 0.80930
Value Function Loss: 0.06111

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02774
Policy Update Magnitude: 0.02737
Value Function Update Magnitude: 0.05185

Collected Steps per Second: 19,543.71934
Overall Steps per Second: 14,892.59777

Timestep Collection Time: 2.55878
Timestep Consumption Time: 0.79913
PPO Batch Consumption Time: 0.08250
Total Iteration Time: 3.35791

Cumulative Model Updates: 22,496
Cumulative Timesteps: 375,579,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 375579386...
Checkpoint 375579386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,266.20725
Policy Entropy: 0.81699
Value Function Loss: 0.06780

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02889
Policy Update Magnitude: 0.02888
Value Function Update Magnitude: 0.05058

Collected Steps per Second: 21,853.00361
Overall Steps per Second: 15,942.73495

Timestep Collection Time: 2.28847
Timestep Consumption Time: 0.84838
PPO Batch Consumption Time: 0.09578
Total Iteration Time: 3.13685

Cumulative Model Updates: 22,499
Cumulative Timesteps: 375,629,396

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,852.90562
Policy Entropy: 0.81672
Value Function Loss: 0.07345

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02978
Policy Update Magnitude: 0.02914
Value Function Update Magnitude: 0.04864

Collected Steps per Second: 22,119.80898
Overall Steps per Second: 16,912.93635

Timestep Collection Time: 2.26123
Timestep Consumption Time: 0.69615
PPO Batch Consumption Time: 0.05218
Total Iteration Time: 2.95738

Cumulative Model Updates: 22,502
Cumulative Timesteps: 375,679,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 375679414...
Checkpoint 375679414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,352.56601
Policy Entropy: 0.81889
Value Function Loss: 0.07456

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02449
Policy Update Magnitude: 0.03234
Value Function Update Magnitude: 0.04734

Collected Steps per Second: 19,421.01516
Overall Steps per Second: 14,614.97581

Timestep Collection Time: 2.57515
Timestep Consumption Time: 0.84682
PPO Batch Consumption Time: 0.08802
Total Iteration Time: 3.42197

Cumulative Model Updates: 22,505
Cumulative Timesteps: 375,729,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,534.13015
Policy Entropy: 0.81493
Value Function Loss: 0.06886

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.03066
Policy Update Magnitude: 0.03182
Value Function Update Magnitude: 0.04949

Collected Steps per Second: 21,676.39264
Overall Steps per Second: 16,573.09069

Timestep Collection Time: 2.30740
Timestep Consumption Time: 0.71051
PPO Batch Consumption Time: 0.05901
Total Iteration Time: 3.01790

Cumulative Model Updates: 22,508
Cumulative Timesteps: 375,779,442

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 375779442...
Checkpoint 375779442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,247.52863
Policy Entropy: 0.81696
Value Function Loss: 0.07412

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02471
Policy Update Magnitude: 0.03167
Value Function Update Magnitude: 0.04766

Collected Steps per Second: 19,741.22601
Overall Steps per Second: 14,905.93078

Timestep Collection Time: 2.53409
Timestep Consumption Time: 0.82203
PPO Batch Consumption Time: 0.08789
Total Iteration Time: 3.35611

Cumulative Model Updates: 22,511
Cumulative Timesteps: 375,829,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,591.71133
Policy Entropy: 0.82080
Value Function Loss: 0.08061

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02657
Policy Update Magnitude: 0.03270
Value Function Update Magnitude: 0.04856

Collected Steps per Second: 22,260.99071
Overall Steps per Second: 16,915.39253

Timestep Collection Time: 2.24644
Timestep Consumption Time: 0.70992
PPO Batch Consumption Time: 0.05789
Total Iteration Time: 2.95636

Cumulative Model Updates: 22,514
Cumulative Timesteps: 375,879,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 375879476...
Checkpoint 375879476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,902.67897
Policy Entropy: 0.81040
Value Function Loss: 0.08197

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02975
Policy Update Magnitude: 0.03302
Value Function Update Magnitude: 0.05996

Collected Steps per Second: 20,232.58941
Overall Steps per Second: 14,720.89673

Timestep Collection Time: 2.47156
Timestep Consumption Time: 0.92538
PPO Batch Consumption Time: 0.11965
Total Iteration Time: 3.39694

Cumulative Model Updates: 22,517
Cumulative Timesteps: 375,929,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,464.52291
Policy Entropy: 0.81326
Value Function Loss: 0.07243

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04255
Policy Update Magnitude: 0.03216
Value Function Update Magnitude: 0.06071

Collected Steps per Second: 21,895.49228
Overall Steps per Second: 16,728.49715

Timestep Collection Time: 2.28431
Timestep Consumption Time: 0.70556
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 2.98987

Cumulative Model Updates: 22,520
Cumulative Timesteps: 375,979,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 375979498...
Checkpoint 375979498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,799.61885
Policy Entropy: 0.81028
Value Function Loss: 0.06696

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03195
Policy Update Magnitude: 0.03127
Value Function Update Magnitude: 0.05745

Collected Steps per Second: 19,105.96154
Overall Steps per Second: 13,921.65223

Timestep Collection Time: 2.61814
Timestep Consumption Time: 0.97497
PPO Batch Consumption Time: 0.11749
Total Iteration Time: 3.59311

Cumulative Model Updates: 22,523
Cumulative Timesteps: 376,029,520

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,637.29763
Policy Entropy: 0.81528
Value Function Loss: 0.06188

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04338
Policy Update Magnitude: 0.03173
Value Function Update Magnitude: 0.05191

Collected Steps per Second: 22,372.00729
Overall Steps per Second: 16,636.42387

Timestep Collection Time: 2.23494
Timestep Consumption Time: 0.77052
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 3.00545

Cumulative Model Updates: 22,526
Cumulative Timesteps: 376,079,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 376079520...
Checkpoint 376079520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,787.08554
Policy Entropy: 0.80638
Value Function Loss: 0.06238

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03453
Policy Update Magnitude: 0.02919
Value Function Update Magnitude: 0.05007

Collected Steps per Second: 20,351.48526
Overall Steps per Second: 14,834.34561

Timestep Collection Time: 2.45771
Timestep Consumption Time: 0.91406
PPO Batch Consumption Time: 0.10250
Total Iteration Time: 3.37177

Cumulative Model Updates: 22,529
Cumulative Timesteps: 376,129,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,508.72878
Policy Entropy: 0.80236
Value Function Loss: 0.06877

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02800
Policy Update Magnitude: 0.02921
Value Function Update Magnitude: 0.05387

Collected Steps per Second: 22,247.15579
Overall Steps per Second: 16,594.39343

Timestep Collection Time: 2.24811
Timestep Consumption Time: 0.76580
PPO Batch Consumption Time: 0.05857
Total Iteration Time: 3.01391

Cumulative Model Updates: 22,532
Cumulative Timesteps: 376,179,552

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 376179552...
Checkpoint 376179552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,928.34341
Policy Entropy: 0.81552
Value Function Loss: 0.06983

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01857
Policy Update Magnitude: 0.02985
Value Function Update Magnitude: 0.05054

Collected Steps per Second: 20,108.13208
Overall Steps per Second: 14,884.89125

Timestep Collection Time: 2.48676
Timestep Consumption Time: 0.87262
PPO Batch Consumption Time: 0.09060
Total Iteration Time: 3.35938

Cumulative Model Updates: 22,535
Cumulative Timesteps: 376,229,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,205.64517
Policy Entropy: 0.81430
Value Function Loss: 0.06991

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.03165
Value Function Update Magnitude: 0.05175

Collected Steps per Second: 22,632.21070
Overall Steps per Second: 16,769.05859

Timestep Collection Time: 2.21057
Timestep Consumption Time: 0.77290
PPO Batch Consumption Time: 0.05860
Total Iteration Time: 2.98347

Cumulative Model Updates: 22,538
Cumulative Timesteps: 376,279,586

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 376279586...
Checkpoint 376279586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,745.47584
Policy Entropy: 0.83129
Value Function Loss: 0.06339

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02433
Policy Update Magnitude: 0.03015
Value Function Update Magnitude: 0.05029

Collected Steps per Second: 20,734.12452
Overall Steps per Second: 14,784.57270

Timestep Collection Time: 2.41158
Timestep Consumption Time: 0.97046
PPO Batch Consumption Time: 0.11389
Total Iteration Time: 3.38204

Cumulative Model Updates: 22,541
Cumulative Timesteps: 376,329,588

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,476.00931
Policy Entropy: 0.82823
Value Function Loss: 0.06313

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02782
Policy Update Magnitude: 0.02939
Value Function Update Magnitude: 0.04709

Collected Steps per Second: 22,234.53574
Overall Steps per Second: 16,477.81108

Timestep Collection Time: 2.25064
Timestep Consumption Time: 0.78629
PPO Batch Consumption Time: 0.05996
Total Iteration Time: 3.03693

Cumulative Model Updates: 22,544
Cumulative Timesteps: 376,379,630

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 376379630...
Checkpoint 376379630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,404.17899
Policy Entropy: 0.83569
Value Function Loss: 0.06655

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03105
Policy Update Magnitude: 0.02985
Value Function Update Magnitude: 0.04860

Collected Steps per Second: 20,360.90550
Overall Steps per Second: 14,946.58680

Timestep Collection Time: 2.45618
Timestep Consumption Time: 0.88974
PPO Batch Consumption Time: 0.07835
Total Iteration Time: 3.34591

Cumulative Model Updates: 22,547
Cumulative Timesteps: 376,429,640

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,904.46600
Policy Entropy: 0.83777
Value Function Loss: 0.07292

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02579
Policy Update Magnitude: 0.02970
Value Function Update Magnitude: 0.04872

Collected Steps per Second: 22,451.41978
Overall Steps per Second: 16,655.21210

Timestep Collection Time: 2.22774
Timestep Consumption Time: 0.77528
PPO Batch Consumption Time: 0.06029
Total Iteration Time: 3.00302

Cumulative Model Updates: 22,550
Cumulative Timesteps: 376,479,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 376479656...
Checkpoint 376479656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,887.28866
Policy Entropy: 0.82869
Value Function Loss: 0.07891

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02954
Policy Update Magnitude: 0.03155
Value Function Update Magnitude: 0.05216

Collected Steps per Second: 19,663.69070
Overall Steps per Second: 14,659.25893

Timestep Collection Time: 2.54520
Timestep Consumption Time: 0.86889
PPO Batch Consumption Time: 0.08694
Total Iteration Time: 3.41409

Cumulative Model Updates: 22,553
Cumulative Timesteps: 376,529,704

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,948.52698
Policy Entropy: 0.84045
Value Function Loss: 0.07499

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.03104
Value Function Update Magnitude: 0.05433

Collected Steps per Second: 22,566.21295
Overall Steps per Second: 16,587.46905

Timestep Collection Time: 2.21614
Timestep Consumption Time: 0.79878
PPO Batch Consumption Time: 0.05975
Total Iteration Time: 3.01493

Cumulative Model Updates: 22,556
Cumulative Timesteps: 376,579,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 376579714...
Checkpoint 376579714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,351.01938
Policy Entropy: 0.84632
Value Function Loss: 0.06631

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01775
Policy Update Magnitude: 0.03143
Value Function Update Magnitude: 0.04966

Collected Steps per Second: 22,447.45677
Overall Steps per Second: 16,500.50911

Timestep Collection Time: 2.22814
Timestep Consumption Time: 0.80304
PPO Batch Consumption Time: 0.06027
Total Iteration Time: 3.03118

Cumulative Model Updates: 22,559
Cumulative Timesteps: 376,629,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,914.13922
Policy Entropy: 0.86433
Value Function Loss: 0.05654

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01777
Policy Update Magnitude: 0.03242
Value Function Update Magnitude: 0.04857

Collected Steps per Second: 22,509.52542
Overall Steps per Second: 16,581.95783

Timestep Collection Time: 2.22208
Timestep Consumption Time: 0.79433
PPO Batch Consumption Time: 0.05803
Total Iteration Time: 3.01641

Cumulative Model Updates: 22,562
Cumulative Timesteps: 376,679,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 376679748...
Checkpoint 376679748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,409.52776
Policy Entropy: 0.86605
Value Function Loss: 0.05710

Mean KL Divergence: 0.00126
SB3 Clip Fraction: 0.01098
Policy Update Magnitude: 0.03256
Value Function Update Magnitude: 0.04581

Collected Steps per Second: 21,286.78478
Overall Steps per Second: 15,226.87931

Timestep Collection Time: 2.34963
Timestep Consumption Time: 0.93509
PPO Batch Consumption Time: 0.08444
Total Iteration Time: 3.28472

Cumulative Model Updates: 22,565
Cumulative Timesteps: 376,729,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,346.35193
Policy Entropy: 0.85598
Value Function Loss: 0.05948

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01299
Policy Update Magnitude: 0.03181
Value Function Update Magnitude: 0.04193

Collected Steps per Second: 22,576.20270
Overall Steps per Second: 16,565.54504

Timestep Collection Time: 2.21499
Timestep Consumption Time: 0.80369
PPO Batch Consumption Time: 0.05996
Total Iteration Time: 3.01868

Cumulative Model Updates: 22,568
Cumulative Timesteps: 376,779,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 376779770...
Checkpoint 376779770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,816.50131
Policy Entropy: 0.84352
Value Function Loss: 0.06318

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01654
Policy Update Magnitude: 0.03112
Value Function Update Magnitude: 0.04383

Collected Steps per Second: 22,345.63932
Overall Steps per Second: 16,658.70027

Timestep Collection Time: 2.23954
Timestep Consumption Time: 0.76453
PPO Batch Consumption Time: 0.05855
Total Iteration Time: 3.00408

Cumulative Model Updates: 22,571
Cumulative Timesteps: 376,829,814

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,610.50490
Policy Entropy: 0.84285
Value Function Loss: 0.06404

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02143
Policy Update Magnitude: 0.03017
Value Function Update Magnitude: 0.04285

Collected Steps per Second: 22,671.92072
Overall Steps per Second: 16,682.70405

Timestep Collection Time: 2.20564
Timestep Consumption Time: 0.79184
PPO Batch Consumption Time: 0.05956
Total Iteration Time: 2.99748

Cumulative Model Updates: 22,574
Cumulative Timesteps: 376,879,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 376879820...
Checkpoint 376879820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,009.52761
Policy Entropy: 0.84404
Value Function Loss: 0.06853

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01436
Policy Update Magnitude: 0.02920
Value Function Update Magnitude: 0.04299

Collected Steps per Second: 22,419.14295
Overall Steps per Second: 16,562.13132

Timestep Collection Time: 2.23113
Timestep Consumption Time: 0.78901
PPO Batch Consumption Time: 0.05910
Total Iteration Time: 3.02014

Cumulative Model Updates: 22,577
Cumulative Timesteps: 376,929,840

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,491.05809
Policy Entropy: 0.84713
Value Function Loss: 0.06744

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02204
Policy Update Magnitude: 0.02920
Value Function Update Magnitude: 0.05477

Collected Steps per Second: 20,939.81718
Overall Steps per Second: 15,204.71318

Timestep Collection Time: 2.38827
Timestep Consumption Time: 0.90084
PPO Batch Consumption Time: 0.08760
Total Iteration Time: 3.28911

Cumulative Model Updates: 22,580
Cumulative Timesteps: 376,979,850

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 376979850...
Checkpoint 376979850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,776.32010
Policy Entropy: 0.83853
Value Function Loss: 0.06745

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01781
Policy Update Magnitude: 0.03104
Value Function Update Magnitude: 0.05828

Collected Steps per Second: 22,061.85764
Overall Steps per Second: 16,284.72602

Timestep Collection Time: 2.26663
Timestep Consumption Time: 0.80410
PPO Batch Consumption Time: 0.06546
Total Iteration Time: 3.07073

Cumulative Model Updates: 22,583
Cumulative Timesteps: 377,029,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,398.97155
Policy Entropy: 0.82650
Value Function Loss: 0.06324

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.02173
Policy Update Magnitude: 0.03078
Value Function Update Magnitude: 0.06370

Collected Steps per Second: 22,816.24049
Overall Steps per Second: 16,338.69600

Timestep Collection Time: 2.19204
Timestep Consumption Time: 0.86904
PPO Batch Consumption Time: 0.08459
Total Iteration Time: 3.06108

Cumulative Model Updates: 22,586
Cumulative Timesteps: 377,079,870

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 377079870...
Checkpoint 377079870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,606.85167
Policy Entropy: 0.82285
Value Function Loss: 0.06409

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01797
Policy Update Magnitude: 0.03056
Value Function Update Magnitude: 0.05300

Collected Steps per Second: 22,244.38864
Overall Steps per Second: 16,294.01329

Timestep Collection Time: 2.24875
Timestep Consumption Time: 0.82121
PPO Batch Consumption Time: 0.06233
Total Iteration Time: 3.06996

Cumulative Model Updates: 22,589
Cumulative Timesteps: 377,129,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,519.20839
Policy Entropy: 0.81816
Value Function Loss: 0.06599

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02063
Policy Update Magnitude: 0.03124
Value Function Update Magnitude: 0.05174

Collected Steps per Second: 22,630.36554
Overall Steps per Second: 16,764.86618

Timestep Collection Time: 2.21013
Timestep Consumption Time: 0.77325
PPO Batch Consumption Time: 0.05956
Total Iteration Time: 2.98338

Cumulative Model Updates: 22,592
Cumulative Timesteps: 377,179,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 377179908...
Checkpoint 377179908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,151.30163
Policy Entropy: 0.83516
Value Function Loss: 0.06370

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02793
Policy Update Magnitude: 0.03057
Value Function Update Magnitude: 0.05247

Collected Steps per Second: 22,430.04873
Overall Steps per Second: 16,456.61458

Timestep Collection Time: 2.22951
Timestep Consumption Time: 0.80927
PPO Batch Consumption Time: 0.05828
Total Iteration Time: 3.03878

Cumulative Model Updates: 22,595
Cumulative Timesteps: 377,229,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,530.34830
Policy Entropy: 0.83947
Value Function Loss: 0.07134

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02805
Policy Update Magnitude: 0.03049
Value Function Update Magnitude: 0.05788

Collected Steps per Second: 22,637.84330
Overall Steps per Second: 16,649.11232

Timestep Collection Time: 2.20931
Timestep Consumption Time: 0.79469
PPO Batch Consumption Time: 0.05851
Total Iteration Time: 3.00400

Cumulative Model Updates: 22,598
Cumulative Timesteps: 377,279,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 377279930...
Checkpoint 377279930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,965.07405
Policy Entropy: 0.83648
Value Function Loss: 0.07074

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01813
Policy Update Magnitude: 0.03026
Value Function Update Magnitude: 0.06742

Collected Steps per Second: 20,593.14585
Overall Steps per Second: 14,628.35801

Timestep Collection Time: 2.42838
Timestep Consumption Time: 0.99018
PPO Batch Consumption Time: 0.11775
Total Iteration Time: 3.41857

Cumulative Model Updates: 22,601
Cumulative Timesteps: 377,329,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,162.69975
Policy Entropy: 0.82736
Value Function Loss: 0.07151

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01539
Policy Update Magnitude: 0.03124
Value Function Update Magnitude: 0.07031

Collected Steps per Second: 22,706.26629
Overall Steps per Second: 16,774.03925

Timestep Collection Time: 2.20300
Timestep Consumption Time: 0.77910
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 2.98211

Cumulative Model Updates: 22,604
Cumulative Timesteps: 377,379,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 377379960...
Checkpoint 377379960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,273.61649
Policy Entropy: 0.84187
Value Function Loss: 0.06387

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01167
Policy Update Magnitude: 0.03355
Value Function Update Magnitude: 0.06637

Collected Steps per Second: 19,760.64883
Overall Steps per Second: 14,485.49395

Timestep Collection Time: 2.53038
Timestep Consumption Time: 0.92148
PPO Batch Consumption Time: 0.08638
Total Iteration Time: 3.45187

Cumulative Model Updates: 22,607
Cumulative Timesteps: 377,429,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,296.74745
Policy Entropy: 0.83396
Value Function Loss: 0.06537

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01494
Policy Update Magnitude: 0.03150
Value Function Update Magnitude: 0.06601

Collected Steps per Second: 22,676.37517
Overall Steps per Second: 16,766.56828

Timestep Collection Time: 2.20644
Timestep Consumption Time: 0.77772
PPO Batch Consumption Time: 0.06255
Total Iteration Time: 2.98415

Cumulative Model Updates: 22,610
Cumulative Timesteps: 377,479,996

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 377479996...
Checkpoint 377479996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,485.07004
Policy Entropy: 0.82726
Value Function Loss: 0.06959

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01782
Policy Update Magnitude: 0.03289
Value Function Update Magnitude: 0.06866

Collected Steps per Second: 20,351.39909
Overall Steps per Second: 14,951.75082

Timestep Collection Time: 2.45811
Timestep Consumption Time: 0.88772
PPO Batch Consumption Time: 0.07843
Total Iteration Time: 3.34583

Cumulative Model Updates: 22,613
Cumulative Timesteps: 377,530,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,288.04135
Policy Entropy: 0.80939
Value Function Loss: 0.07214

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.03416
Value Function Update Magnitude: 0.06563

Collected Steps per Second: 22,408.87120
Overall Steps per Second: 16,522.67368

Timestep Collection Time: 2.23162
Timestep Consumption Time: 0.79501
PPO Batch Consumption Time: 0.06132
Total Iteration Time: 3.02663

Cumulative Model Updates: 22,616
Cumulative Timesteps: 377,580,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 377580030...
Checkpoint 377580030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,017.91163
Policy Entropy: 0.83224
Value Function Loss: 0.05928

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03134
Policy Update Magnitude: 0.03302
Value Function Update Magnitude: 0.06371

Collected Steps per Second: 20,038.39992
Overall Steps per Second: 14,709.66583

Timestep Collection Time: 2.49631
Timestep Consumption Time: 0.90431
PPO Batch Consumption Time: 0.08652
Total Iteration Time: 3.40062

Cumulative Model Updates: 22,619
Cumulative Timesteps: 377,630,052

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,891.69495
Policy Entropy: 0.84156
Value Function Loss: 0.05475

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03883
Policy Update Magnitude: 0.03275
Value Function Update Magnitude: 0.06169

Collected Steps per Second: 22,558.88006
Overall Steps per Second: 16,690.22916

Timestep Collection Time: 2.21660
Timestep Consumption Time: 0.77940
PPO Batch Consumption Time: 0.05894
Total Iteration Time: 2.99600

Cumulative Model Updates: 22,622
Cumulative Timesteps: 377,680,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 377680056...
Checkpoint 377680056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,217.42796
Policy Entropy: 0.85005
Value Function Loss: 0.05335

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02702
Policy Update Magnitude: 0.02818
Value Function Update Magnitude: 0.05911

Collected Steps per Second: 21,227.89917
Overall Steps per Second: 15,050.96039

Timestep Collection Time: 2.35614
Timestep Consumption Time: 0.96697
PPO Batch Consumption Time: 0.10847
Total Iteration Time: 3.32311

Cumulative Model Updates: 22,625
Cumulative Timesteps: 377,730,072

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,779.48587
Policy Entropy: 0.82820
Value Function Loss: 0.06000

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.02841
Value Function Update Magnitude: 0.06135

Collected Steps per Second: 22,225.44708
Overall Steps per Second: 16,468.46128

Timestep Collection Time: 2.25057
Timestep Consumption Time: 0.78675
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 3.03732

Cumulative Model Updates: 22,628
Cumulative Timesteps: 377,780,092

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 377780092...
Checkpoint 377780092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,941.56270
Policy Entropy: 0.82204
Value Function Loss: 0.06208

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03123
Policy Update Magnitude: 0.02914
Value Function Update Magnitude: 0.06258

Collected Steps per Second: 17,985.92256
Overall Steps per Second: 13,638.38487

Timestep Collection Time: 2.78129
Timestep Consumption Time: 0.88660
PPO Batch Consumption Time: 0.03202
Total Iteration Time: 3.66788

Cumulative Model Updates: 22,631
Cumulative Timesteps: 377,830,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,386.96187
Policy Entropy: 0.82034
Value Function Loss: 0.06713

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04166
Policy Update Magnitude: 0.03003
Value Function Update Magnitude: 0.06424

Collected Steps per Second: 18,409.65573
Overall Steps per Second: 14,399.27173

Timestep Collection Time: 2.71694
Timestep Consumption Time: 0.75670
PPO Batch Consumption Time: 0.03168
Total Iteration Time: 3.47365

Cumulative Model Updates: 22,634
Cumulative Timesteps: 377,880,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 377880134...
Checkpoint 377880134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,184.45816
Policy Entropy: 0.82372
Value Function Loss: 0.07064

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03337
Policy Update Magnitude: 0.03353
Value Function Update Magnitude: 0.06686

Collected Steps per Second: 21,931.38210
Overall Steps per Second: 16,106.31974

Timestep Collection Time: 2.28093
Timestep Consumption Time: 0.82493
PPO Batch Consumption Time: 0.06187
Total Iteration Time: 3.10586

Cumulative Model Updates: 22,637
Cumulative Timesteps: 377,930,158

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,778.05041
Policy Entropy: 0.83263
Value Function Loss: 0.07128

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03275
Policy Update Magnitude: 0.03483
Value Function Update Magnitude: 0.06510

Collected Steps per Second: 22,165.50072
Overall Steps per Second: 15,509.55013

Timestep Collection Time: 2.25621
Timestep Consumption Time: 0.96826
PPO Batch Consumption Time: 0.11172
Total Iteration Time: 3.22446

Cumulative Model Updates: 22,640
Cumulative Timesteps: 377,980,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 377980168...
Checkpoint 377980168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,242.63626
Policy Entropy: 0.82152
Value Function Loss: 0.07424

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03212
Policy Update Magnitude: 0.03341
Value Function Update Magnitude: 0.06591

Collected Steps per Second: 22,932.41664
Overall Steps per Second: 16,854.23152

Timestep Collection Time: 2.18093
Timestep Consumption Time: 0.78651
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 2.96744

Cumulative Model Updates: 22,643
Cumulative Timesteps: 378,030,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,725.30979
Policy Entropy: 0.83804
Value Function Loss: 0.07101

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02504
Policy Update Magnitude: 0.03175
Value Function Update Magnitude: 0.06624

Collected Steps per Second: 20,391.60073
Overall Steps per Second: 14,610.85864

Timestep Collection Time: 2.45366
Timestep Consumption Time: 0.97078
PPO Batch Consumption Time: 0.10267
Total Iteration Time: 3.42444

Cumulative Model Updates: 22,646
Cumulative Timesteps: 378,080,216

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 378080216...
Checkpoint 378080216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,602.63816
Policy Entropy: 0.83071
Value Function Loss: 0.06432

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01894
Policy Update Magnitude: 0.03049
Value Function Update Magnitude: 0.06730

Collected Steps per Second: 18,111.56087
Overall Steps per Second: 14,405.05457

Timestep Collection Time: 2.76133
Timestep Consumption Time: 0.71051
PPO Batch Consumption Time: 0.02960
Total Iteration Time: 3.47184

Cumulative Model Updates: 22,649
Cumulative Timesteps: 378,130,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,812.71222
Policy Entropy: 0.84211
Value Function Loss: 0.05919

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03541
Policy Update Magnitude: 0.03055
Value Function Update Magnitude: 0.06302

Collected Steps per Second: 20,567.41128
Overall Steps per Second: 15,181.48695

Timestep Collection Time: 2.43268
Timestep Consumption Time: 0.86304
PPO Batch Consumption Time: 0.08699
Total Iteration Time: 3.29572

Cumulative Model Updates: 22,652
Cumulative Timesteps: 378,180,262

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 378180262...
Checkpoint 378180262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,454.44465
Policy Entropy: 0.83295
Value Function Loss: 0.05871

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04651
Policy Update Magnitude: 0.02755
Value Function Update Magnitude: 0.06013

Collected Steps per Second: 23,610.85036
Overall Steps per Second: 17,124.84307

Timestep Collection Time: 2.11835
Timestep Consumption Time: 0.80232
PPO Batch Consumption Time: 0.06390
Total Iteration Time: 2.92067

Cumulative Model Updates: 22,655
Cumulative Timesteps: 378,230,278

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,349.77335
Policy Entropy: 0.83755
Value Function Loss: 0.05649

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03335
Policy Update Magnitude: 0.02908
Value Function Update Magnitude: 0.05809

Collected Steps per Second: 23,063.33451
Overall Steps per Second: 16,820.01921

Timestep Collection Time: 2.16924
Timestep Consumption Time: 0.80519
PPO Batch Consumption Time: 0.06704
Total Iteration Time: 2.97443

Cumulative Model Updates: 22,658
Cumulative Timesteps: 378,280,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 378280308...
Checkpoint 378280308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,188.35035
Policy Entropy: 0.83699
Value Function Loss: 0.05828

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04581
Policy Update Magnitude: 0.02804
Value Function Update Magnitude: 0.05592

Collected Steps per Second: 23,631.86648
Overall Steps per Second: 16,571.47106

Timestep Collection Time: 2.11613
Timestep Consumption Time: 0.90159
PPO Batch Consumption Time: 0.08614
Total Iteration Time: 3.01772

Cumulative Model Updates: 22,661
Cumulative Timesteps: 378,330,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,600.31836
Policy Entropy: 0.83780
Value Function Loss: 0.05959

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.05327
Policy Update Magnitude: 0.03368
Value Function Update Magnitude: 0.06030

Collected Steps per Second: 20,574.10581
Overall Steps per Second: 15,349.76121

Timestep Collection Time: 2.43150
Timestep Consumption Time: 0.82757
PPO Batch Consumption Time: 0.06146
Total Iteration Time: 3.25907

Cumulative Model Updates: 22,664
Cumulative Timesteps: 378,380,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 378380342...
Checkpoint 378380342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,534.18423
Policy Entropy: 0.82919
Value Function Loss: 0.06973

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04753
Policy Update Magnitude: 0.03181
Value Function Update Magnitude: 0.06382

Collected Steps per Second: 22,230.63656
Overall Steps per Second: 16,989.72915

Timestep Collection Time: 2.24960
Timestep Consumption Time: 0.69394
PPO Batch Consumption Time: 0.03002
Total Iteration Time: 2.94354

Cumulative Model Updates: 22,667
Cumulative Timesteps: 378,430,352

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,021.47784
Policy Entropy: 0.84831
Value Function Loss: 0.06587

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04588
Policy Update Magnitude: 0.02922
Value Function Update Magnitude: 0.05692

Collected Steps per Second: 20,471.99644
Overall Steps per Second: 14,625.02963

Timestep Collection Time: 2.44275
Timestep Consumption Time: 0.97659
PPO Batch Consumption Time: 0.11045
Total Iteration Time: 3.41934

Cumulative Model Updates: 22,670
Cumulative Timesteps: 378,480,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 378480360...
Checkpoint 378480360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,852.53398
Policy Entropy: 0.85485
Value Function Loss: 0.06192

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03490
Policy Update Magnitude: 0.02971
Value Function Update Magnitude: 0.05367

Collected Steps per Second: 20,170.99179
Overall Steps per Second: 15,047.88735

Timestep Collection Time: 2.48029
Timestep Consumption Time: 0.84442
PPO Batch Consumption Time: 0.06808
Total Iteration Time: 3.32472

Cumulative Model Updates: 22,673
Cumulative Timesteps: 378,530,390

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,585.84018
Policy Entropy: 0.85932
Value Function Loss: 0.05822

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03230
Policy Update Magnitude: 0.02910
Value Function Update Magnitude: 0.05553

Collected Steps per Second: 20,348.43201
Overall Steps per Second: 15,878.83144

Timestep Collection Time: 2.45788
Timestep Consumption Time: 0.69185
PPO Batch Consumption Time: 0.02942
Total Iteration Time: 3.14973

Cumulative Model Updates: 22,676
Cumulative Timesteps: 378,580,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 378580404...
Checkpoint 378580404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,282.40274
Policy Entropy: 0.85207
Value Function Loss: 0.05925

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.02019
Policy Update Magnitude: 0.03328
Value Function Update Magnitude: 0.05775

Collected Steps per Second: 20,052.77989
Overall Steps per Second: 14,443.51056

Timestep Collection Time: 2.49402
Timestep Consumption Time: 0.96857
PPO Batch Consumption Time: 0.11459
Total Iteration Time: 3.46259

Cumulative Model Updates: 22,679
Cumulative Timesteps: 378,630,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,315.70451
Policy Entropy: 0.86063
Value Function Loss: 0.06226

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01375
Policy Update Magnitude: 0.03281
Value Function Update Magnitude: 0.05232

Collected Steps per Second: 19,892.55698
Overall Steps per Second: 15,445.70809

Timestep Collection Time: 2.51571
Timestep Consumption Time: 0.72428
PPO Batch Consumption Time: 0.03048
Total Iteration Time: 3.23999

Cumulative Model Updates: 22,682
Cumulative Timesteps: 378,680,460

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 378680460...
Checkpoint 378680460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,051.95711
Policy Entropy: 0.85610
Value Function Loss: 0.06360

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.03326
Value Function Update Magnitude: 0.05551

Collected Steps per Second: 21,257.33710
Overall Steps per Second: 15,027.40459

Timestep Collection Time: 2.35241
Timestep Consumption Time: 0.97524
PPO Batch Consumption Time: 0.11105
Total Iteration Time: 3.32765

Cumulative Model Updates: 22,685
Cumulative Timesteps: 378,730,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,870.57309
Policy Entropy: 0.84939
Value Function Loss: 0.06860

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02247
Policy Update Magnitude: 0.03314
Value Function Update Magnitude: 0.05070

Collected Steps per Second: 22,955.96896
Overall Steps per Second: 15,603.70056

Timestep Collection Time: 2.17939
Timestep Consumption Time: 1.02690
PPO Batch Consumption Time: 0.10496
Total Iteration Time: 3.20629

Cumulative Model Updates: 22,688
Cumulative Timesteps: 378,780,496

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 378780496...
Checkpoint 378780496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,624.17962
Policy Entropy: 0.85523
Value Function Loss: 0.07160

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03411
Policy Update Magnitude: 0.03535
Value Function Update Magnitude: 0.04809

Collected Steps per Second: 22,495.50171
Overall Steps per Second: 17,136.09823

Timestep Collection Time: 2.22284
Timestep Consumption Time: 0.69521
PPO Batch Consumption Time: 0.02974
Total Iteration Time: 2.91805

Cumulative Model Updates: 22,691
Cumulative Timesteps: 378,830,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,199.16364
Policy Entropy: 0.85191
Value Function Loss: 0.07123

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03091
Policy Update Magnitude: 0.03678
Value Function Update Magnitude: 0.04001

Collected Steps per Second: 21,143.52812
Overall Steps per Second: 15,358.49411

Timestep Collection Time: 2.36611
Timestep Consumption Time: 0.89124
PPO Batch Consumption Time: 0.08354
Total Iteration Time: 3.25735

Cumulative Model Updates: 22,694
Cumulative Timesteps: 378,880,528

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 378880528...
Checkpoint 378880528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,813.47909
Policy Entropy: 0.85279
Value Function Loss: 0.07908

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.03662
Value Function Update Magnitude: 0.03927

Collected Steps per Second: 23,371.90454
Overall Steps per Second: 16,838.60961

Timestep Collection Time: 2.14069
Timestep Consumption Time: 0.83058
PPO Batch Consumption Time: 0.06767
Total Iteration Time: 2.97127

Cumulative Model Updates: 22,697
Cumulative Timesteps: 378,930,560

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,581.58995
Policy Entropy: 0.85256
Value Function Loss: 0.07739

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.05133
Policy Update Magnitude: 0.03730
Value Function Update Magnitude: 0.04865

Collected Steps per Second: 20,730.79750
Overall Steps per Second: 15,431.98210

Timestep Collection Time: 2.41245
Timestep Consumption Time: 0.82835
PPO Batch Consumption Time: 0.08227
Total Iteration Time: 3.24080

Cumulative Model Updates: 22,700
Cumulative Timesteps: 378,980,572

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 378980572...
Checkpoint 378980572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,521.90675
Policy Entropy: 0.85261
Value Function Loss: 0.07651

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04853
Policy Update Magnitude: 0.04274
Value Function Update Magnitude: 0.05753

Collected Steps per Second: 22,220.81377
Overall Steps per Second: 15,756.56122

Timestep Collection Time: 2.25149
Timestep Consumption Time: 0.92369
PPO Batch Consumption Time: 0.10253
Total Iteration Time: 3.17519

Cumulative Model Updates: 22,703
Cumulative Timesteps: 379,030,602

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,878.71016
Policy Entropy: 0.85764
Value Function Loss: 0.07024

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05081
Policy Update Magnitude: 0.04359
Value Function Update Magnitude: 0.06079

Collected Steps per Second: 23,049.29204
Overall Steps per Second: 17,007.90717

Timestep Collection Time: 2.17022
Timestep Consumption Time: 0.77088
PPO Batch Consumption Time: 0.05854
Total Iteration Time: 2.94110

Cumulative Model Updates: 22,706
Cumulative Timesteps: 379,080,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 379080624...
Checkpoint 379080624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,829.75407
Policy Entropy: 0.86375
Value Function Loss: 0.07029

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04417
Policy Update Magnitude: 0.04184
Value Function Update Magnitude: 0.06477

Collected Steps per Second: 20,360.47512
Overall Steps per Second: 14,733.72538

Timestep Collection Time: 2.45584
Timestep Consumption Time: 0.93787
PPO Batch Consumption Time: 0.10699
Total Iteration Time: 3.39371

Cumulative Model Updates: 22,709
Cumulative Timesteps: 379,130,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,558.01788
Policy Entropy: 0.86286
Value Function Loss: 0.06817

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04333
Policy Update Magnitude: 0.03693
Value Function Update Magnitude: 0.06796

Collected Steps per Second: 23,183.76352
Overall Steps per Second: 16,625.68037

Timestep Collection Time: 2.15711
Timestep Consumption Time: 0.85088
PPO Batch Consumption Time: 0.07571
Total Iteration Time: 3.00800

Cumulative Model Updates: 22,712
Cumulative Timesteps: 379,180,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 379180636...
Checkpoint 379180636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,141.44940
Policy Entropy: 0.86020
Value Function Loss: 0.07000

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04530
Policy Update Magnitude: 0.03637
Value Function Update Magnitude: 0.06497

Collected Steps per Second: 22,985.65312
Overall Steps per Second: 16,329.32494

Timestep Collection Time: 2.17666
Timestep Consumption Time: 0.88727
PPO Batch Consumption Time: 0.08661
Total Iteration Time: 3.06394

Cumulative Model Updates: 22,715
Cumulative Timesteps: 379,230,668

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,461.68649
Policy Entropy: 0.85221
Value Function Loss: 0.07035

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01809
Policy Update Magnitude: 0.03831
Value Function Update Magnitude: 0.06519

Collected Steps per Second: 24,230.76055
Overall Steps per Second: 18,389.64368

Timestep Collection Time: 2.06432
Timestep Consumption Time: 0.65569
PPO Batch Consumption Time: 0.02915
Total Iteration Time: 2.72001

Cumulative Model Updates: 22,718
Cumulative Timesteps: 379,280,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 379280688...
Checkpoint 379280688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,765.07065
Policy Entropy: 0.84592
Value Function Loss: 0.06870

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02399
Policy Update Magnitude: 0.03712
Value Function Update Magnitude: 0.06734

Collected Steps per Second: 23,013.57849
Overall Steps per Second: 15,881.10451

Timestep Collection Time: 2.17280
Timestep Consumption Time: 0.97584
PPO Batch Consumption Time: 0.11685
Total Iteration Time: 3.14865

Cumulative Model Updates: 22,721
Cumulative Timesteps: 379,330,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,257.54997
Policy Entropy: 0.85623
Value Function Loss: 0.06882

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03181
Policy Update Magnitude: 0.03526
Value Function Update Magnitude: 0.06936

Collected Steps per Second: 23,625.72200
Overall Steps per Second: 16,227.43092

Timestep Collection Time: 2.11659
Timestep Consumption Time: 0.96498
PPO Batch Consumption Time: 0.07912
Total Iteration Time: 3.08157

Cumulative Model Updates: 22,724
Cumulative Timesteps: 379,380,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 379380698...
Checkpoint 379380698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,446.37494
Policy Entropy: 0.86242
Value Function Loss: 0.07034

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03089
Policy Update Magnitude: 0.03364
Value Function Update Magnitude: 0.06602

Collected Steps per Second: 22,048.41992
Overall Steps per Second: 16,584.18797

Timestep Collection Time: 2.26774
Timestep Consumption Time: 0.74718
PPO Batch Consumption Time: 0.03258
Total Iteration Time: 3.01492

Cumulative Model Updates: 22,727
Cumulative Timesteps: 379,430,698

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,778.92360
Policy Entropy: 0.86294
Value Function Loss: 0.07765

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01370
Policy Update Magnitude: 0.03880
Value Function Update Magnitude: 0.06300

Collected Steps per Second: 22,544.07066
Overall Steps per Second: 17,424.40965

Timestep Collection Time: 2.21921
Timestep Consumption Time: 0.65205
PPO Batch Consumption Time: 0.02886
Total Iteration Time: 2.87126

Cumulative Model Updates: 22,730
Cumulative Timesteps: 379,480,728

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 379480728...
Checkpoint 379480728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,094.97246
Policy Entropy: 0.86128
Value Function Loss: 0.07442

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02995
Policy Update Magnitude: 0.03964
Value Function Update Magnitude: 0.06535

Collected Steps per Second: 20,950.40315
Overall Steps per Second: 14,858.03273

Timestep Collection Time: 2.38716
Timestep Consumption Time: 0.97883
PPO Batch Consumption Time: 0.11986
Total Iteration Time: 3.36599

Cumulative Model Updates: 22,733
Cumulative Timesteps: 379,530,740

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,205.73618
Policy Entropy: 0.85741
Value Function Loss: 0.07584

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03295
Policy Update Magnitude: 0.03826
Value Function Update Magnitude: 0.06592

Collected Steps per Second: 24,270.35511
Overall Steps per Second: 17,708.10134

Timestep Collection Time: 2.06128
Timestep Consumption Time: 0.76387
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 2.82515

Cumulative Model Updates: 22,736
Cumulative Timesteps: 379,580,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 379580768...
Checkpoint 379580768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,777.41215
Policy Entropy: 0.86655
Value Function Loss: 0.06456

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03920
Policy Update Magnitude: 0.03704
Value Function Update Magnitude: 0.06749

Collected Steps per Second: 20,140.30237
Overall Steps per Second: 14,824.28653

Timestep Collection Time: 2.48328
Timestep Consumption Time: 0.89051
PPO Batch Consumption Time: 0.10279
Total Iteration Time: 3.37379

Cumulative Model Updates: 22,739
Cumulative Timesteps: 379,630,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,809.80088
Policy Entropy: 0.86167
Value Function Loss: 0.06107

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03527
Policy Update Magnitude: 0.03594
Value Function Update Magnitude: 0.06829

Collected Steps per Second: 23,841.79119
Overall Steps per Second: 16,696.27103

Timestep Collection Time: 2.09758
Timestep Consumption Time: 0.89770
PPO Batch Consumption Time: 0.08761
Total Iteration Time: 2.99528

Cumulative Model Updates: 22,742
Cumulative Timesteps: 379,680,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 379680792...
Checkpoint 379680792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,167.06753
Policy Entropy: 0.87393
Value Function Loss: 0.05678

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02244
Policy Update Magnitude: 0.03374
Value Function Update Magnitude: 0.06332

Collected Steps per Second: 23,306.22501
Overall Steps per Second: 16,799.32706

Timestep Collection Time: 2.14732
Timestep Consumption Time: 0.83172
PPO Batch Consumption Time: 0.07634
Total Iteration Time: 2.97905

Cumulative Model Updates: 22,745
Cumulative Timesteps: 379,730,838

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,297.93158
Policy Entropy: 0.88807
Value Function Loss: 0.06147

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01868
Policy Update Magnitude: 0.03566
Value Function Update Magnitude: 0.06139

Collected Steps per Second: 22,817.95804
Overall Steps per Second: 16,456.90384

Timestep Collection Time: 2.19134
Timestep Consumption Time: 0.84702
PPO Batch Consumption Time: 0.08196
Total Iteration Time: 3.03836

Cumulative Model Updates: 22,748
Cumulative Timesteps: 379,780,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 379780840...
Checkpoint 379780840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,504.61315
Policy Entropy: 0.87798
Value Function Loss: 0.06891

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.01995
Policy Update Magnitude: 0.03641
Value Function Update Magnitude: 0.06322

Collected Steps per Second: 22,182.64491
Overall Steps per Second: 15,852.35095

Timestep Collection Time: 2.25528
Timestep Consumption Time: 0.90060
PPO Batch Consumption Time: 0.08797
Total Iteration Time: 3.15587

Cumulative Model Updates: 22,751
Cumulative Timesteps: 379,830,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,454.53841
Policy Entropy: 0.87225
Value Function Loss: 0.06887

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01647
Policy Update Magnitude: 0.04007
Value Function Update Magnitude: 0.06237

Collected Steps per Second: 23,237.24334
Overall Steps per Second: 16,882.38794

Timestep Collection Time: 2.15206
Timestep Consumption Time: 0.81008
PPO Batch Consumption Time: 0.05906
Total Iteration Time: 2.96214

Cumulative Model Updates: 22,754
Cumulative Timesteps: 379,880,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 379880876...
Checkpoint 379880876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,833.19243
Policy Entropy: 0.85782
Value Function Loss: 0.06371

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01827
Policy Update Magnitude: 0.03767
Value Function Update Magnitude: 0.06432

Collected Steps per Second: 20,647.00131
Overall Steps per Second: 14,749.46223

Timestep Collection Time: 2.42185
Timestep Consumption Time: 0.96837
PPO Batch Consumption Time: 0.10597
Total Iteration Time: 3.39023

Cumulative Model Updates: 22,757
Cumulative Timesteps: 379,930,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,685.71994
Policy Entropy: 0.86813
Value Function Loss: 0.05102

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02331
Policy Update Magnitude: 0.03454
Value Function Update Magnitude: 0.06304

Collected Steps per Second: 23,462.67592
Overall Steps per Second: 16,650.42891

Timestep Collection Time: 2.13181
Timestep Consumption Time: 0.87220
PPO Batch Consumption Time: 0.07601
Total Iteration Time: 3.00401

Cumulative Model Updates: 22,760
Cumulative Timesteps: 379,980,898

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 379980898...
Checkpoint 379980898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,313.64545
Policy Entropy: 0.87779
Value Function Loss: 0.04664

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03158
Policy Update Magnitude: 0.03346
Value Function Update Magnitude: 0.06405

Collected Steps per Second: 23,425.20303
Overall Steps per Second: 15,863.84319

Timestep Collection Time: 2.13531
Timestep Consumption Time: 1.01778
PPO Batch Consumption Time: 0.12023
Total Iteration Time: 3.15308

Cumulative Model Updates: 22,763
Cumulative Timesteps: 380,030,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,104.92005
Policy Entropy: 0.86762
Value Function Loss: 0.05032

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03203
Policy Update Magnitude: 0.03128
Value Function Update Magnitude: 0.06165

Collected Steps per Second: 20,329.29492
Overall Steps per Second: 15,710.29448

Timestep Collection Time: 2.46088
Timestep Consumption Time: 0.72353
PPO Batch Consumption Time: 0.03144
Total Iteration Time: 3.18441

Cumulative Model Updates: 22,766
Cumulative Timesteps: 380,080,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 380080946...
Checkpoint 380080946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,897.75562
Policy Entropy: 0.85814
Value Function Loss: 0.06397

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03165
Policy Update Magnitude: 0.03242
Value Function Update Magnitude: 0.06497

Collected Steps per Second: 21,234.13359
Overall Steps per Second: 15,833.84407

Timestep Collection Time: 2.35489
Timestep Consumption Time: 0.80316
PPO Batch Consumption Time: 0.05386
Total Iteration Time: 3.15805

Cumulative Model Updates: 22,769
Cumulative Timesteps: 380,130,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,563.22240
Policy Entropy: 0.84125
Value Function Loss: 0.06682

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05315
Policy Update Magnitude: 0.03338
Value Function Update Magnitude: 0.06229

Collected Steps per Second: 19,821.73440
Overall Steps per Second: 14,494.67326

Timestep Collection Time: 2.52299
Timestep Consumption Time: 0.92724
PPO Batch Consumption Time: 0.09291
Total Iteration Time: 3.45023

Cumulative Model Updates: 22,772
Cumulative Timesteps: 380,180,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 380180960...
Checkpoint 380180960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,546.94306
Policy Entropy: 0.84020
Value Function Loss: 0.06711

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.05007
Policy Update Magnitude: 0.03344
Value Function Update Magnitude: 0.06232

Collected Steps per Second: 20,537.00882
Overall Steps per Second: 15,840.25192

Timestep Collection Time: 2.43551
Timestep Consumption Time: 0.72215
PPO Batch Consumption Time: 0.02986
Total Iteration Time: 3.15765

Cumulative Model Updates: 22,775
Cumulative Timesteps: 380,230,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,589.81219
Policy Entropy: 0.83900
Value Function Loss: 0.06736

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04482
Policy Update Magnitude: 0.03065
Value Function Update Magnitude: 0.05961

Collected Steps per Second: 21,325.20542
Overall Steps per Second: 16,181.95310

Timestep Collection Time: 2.34596
Timestep Consumption Time: 0.74564
PPO Batch Consumption Time: 0.03315
Total Iteration Time: 3.09159

Cumulative Model Updates: 22,778
Cumulative Timesteps: 380,281,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 380281006...
Checkpoint 380281006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,878.35180
Policy Entropy: 0.82942
Value Function Loss: 0.07507

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.05313
Policy Update Magnitude: 0.03275
Value Function Update Magnitude: 0.06197

Collected Steps per Second: 21,403.11039
Overall Steps per Second: 16,263.31359

Timestep Collection Time: 2.33620
Timestep Consumption Time: 0.73832
PPO Batch Consumption Time: 0.04085
Total Iteration Time: 3.07453

Cumulative Model Updates: 22,781
Cumulative Timesteps: 380,331,008

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,883.01121
Policy Entropy: 0.84446
Value Function Loss: 0.07379

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02657
Policy Update Magnitude: 0.03641
Value Function Update Magnitude: 0.05904

Collected Steps per Second: 20,756.20668
Overall Steps per Second: 15,968.06744

Timestep Collection Time: 2.41027
Timestep Consumption Time: 0.72274
PPO Batch Consumption Time: 0.02859
Total Iteration Time: 3.13300

Cumulative Model Updates: 22,784
Cumulative Timesteps: 380,381,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 380381036...
Checkpoint 380381036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,937.09353
Policy Entropy: 0.84207
Value Function Loss: 0.07079

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03199
Policy Update Magnitude: 0.03368
Value Function Update Magnitude: 0.05915

Collected Steps per Second: 20,323.26949
Overall Steps per Second: 15,197.92712

Timestep Collection Time: 2.46161
Timestep Consumption Time: 0.83015
PPO Batch Consumption Time: 0.05026
Total Iteration Time: 3.29176

Cumulative Model Updates: 22,787
Cumulative Timesteps: 380,431,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,439.92138
Policy Entropy: 0.85619
Value Function Loss: 0.06966

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01753
Policy Update Magnitude: 0.03315
Value Function Update Magnitude: 0.06069

Collected Steps per Second: 17,539.51017
Overall Steps per Second: 13,171.88611

Timestep Collection Time: 2.85253
Timestep Consumption Time: 0.94586
PPO Batch Consumption Time: 0.08305
Total Iteration Time: 3.79839

Cumulative Model Updates: 22,790
Cumulative Timesteps: 380,481,096

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 380481096...
Checkpoint 380481096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,805.39594
Policy Entropy: 0.85237
Value Function Loss: 0.07669

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02045
Policy Update Magnitude: 0.03195
Value Function Update Magnitude: 0.06233

Collected Steps per Second: 20,291.44036
Overall Steps per Second: 15,073.12573

Timestep Collection Time: 2.46488
Timestep Consumption Time: 0.85334
PPO Batch Consumption Time: 0.06418
Total Iteration Time: 3.31822

Cumulative Model Updates: 22,793
Cumulative Timesteps: 380,531,112

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,593.85463
Policy Entropy: 0.84807
Value Function Loss: 0.07726

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01991
Policy Update Magnitude: 0.03420
Value Function Update Magnitude: 0.06345

Collected Steps per Second: 19,019.99054
Overall Steps per Second: 14,804.57382

Timestep Collection Time: 2.62944
Timestep Consumption Time: 0.74870
PPO Batch Consumption Time: 0.03315
Total Iteration Time: 3.37815

Cumulative Model Updates: 22,796
Cumulative Timesteps: 380,581,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 380581124...
Checkpoint 380581124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,538.63983
Policy Entropy: 0.83775
Value Function Loss: 0.07425

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02867
Policy Update Magnitude: 0.03348
Value Function Update Magnitude: 0.06717

Collected Steps per Second: 22,233.86207
Overall Steps per Second: 15,498.89445

Timestep Collection Time: 2.24936
Timestep Consumption Time: 0.97745
PPO Batch Consumption Time: 0.09806
Total Iteration Time: 3.22681

Cumulative Model Updates: 22,799
Cumulative Timesteps: 380,631,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,378.50544
Policy Entropy: 0.83961
Value Function Loss: 0.06722

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03320
Policy Update Magnitude: 0.03235
Value Function Update Magnitude: 0.06772

Collected Steps per Second: 22,847.47622
Overall Steps per Second: 16,138.15650

Timestep Collection Time: 2.18956
Timestep Consumption Time: 0.91029
PPO Batch Consumption Time: 0.09049
Total Iteration Time: 3.09986

Cumulative Model Updates: 22,802
Cumulative Timesteps: 380,681,162

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 380681162...
Checkpoint 380681162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,757.33042
Policy Entropy: 0.84381
Value Function Loss: 0.06694

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.05108
Policy Update Magnitude: 0.03296
Value Function Update Magnitude: 0.06735

Collected Steps per Second: 17,768.33215
Overall Steps per Second: 13,523.06286

Timestep Collection Time: 2.81490
Timestep Consumption Time: 0.88367
PPO Batch Consumption Time: 0.06261
Total Iteration Time: 3.69857

Cumulative Model Updates: 22,805
Cumulative Timesteps: 380,731,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,742.35722
Policy Entropy: 0.84311
Value Function Loss: 0.06336

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03643
Policy Update Magnitude: 0.03450
Value Function Update Magnitude: 0.06251

Collected Steps per Second: 15,479.65592
Overall Steps per Second: 12,273.75085

Timestep Collection Time: 3.23315
Timestep Consumption Time: 0.84450
PPO Batch Consumption Time: 0.03121
Total Iteration Time: 4.07765

Cumulative Model Updates: 22,808
Cumulative Timesteps: 380,781,226

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 380781226...
Checkpoint 380781226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,324.13610
Policy Entropy: 0.84000
Value Function Loss: 0.06433

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04215
Policy Update Magnitude: 0.03179
Value Function Update Magnitude: 0.05934

Collected Steps per Second: 18,754.30940
Overall Steps per Second: 13,839.66667

Timestep Collection Time: 2.66627
Timestep Consumption Time: 0.94683
PPO Batch Consumption Time: 0.07962
Total Iteration Time: 3.61309

Cumulative Model Updates: 22,811
Cumulative Timesteps: 380,831,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,647.79817
Policy Entropy: 0.83479
Value Function Loss: 0.06237

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02833
Policy Update Magnitude: 0.03165
Value Function Update Magnitude: 0.06197

Collected Steps per Second: 15,875.25098
Overall Steps per Second: 12,640.53215

Timestep Collection Time: 3.15031
Timestep Consumption Time: 0.80617
PPO Batch Consumption Time: 0.06111
Total Iteration Time: 3.95648

Cumulative Model Updates: 22,814
Cumulative Timesteps: 380,881,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 380881242...
Checkpoint 380881242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,435.16880
Policy Entropy: 0.83089
Value Function Loss: 0.06725

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.03085
Value Function Update Magnitude: 0.06358

Collected Steps per Second: 18,258.08564
Overall Steps per Second: 14,488.90887

Timestep Collection Time: 2.74005
Timestep Consumption Time: 0.71280
PPO Batch Consumption Time: 0.04976
Total Iteration Time: 3.45285

Cumulative Model Updates: 22,817
Cumulative Timesteps: 380,931,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,911.90358
Policy Entropy: 0.83401
Value Function Loss: 0.06870

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.02963
Value Function Update Magnitude: 0.06687

Collected Steps per Second: 19,286.35623
Overall Steps per Second: 15,036.63586

Timestep Collection Time: 2.59292
Timestep Consumption Time: 0.73282
PPO Batch Consumption Time: 0.06023
Total Iteration Time: 3.32574

Cumulative Model Updates: 22,820
Cumulative Timesteps: 380,981,278

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 380981278...
Checkpoint 380981278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,614.06947
Policy Entropy: 0.83222
Value Function Loss: 0.07075

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03778
Policy Update Magnitude: 0.02902
Value Function Update Magnitude: 0.06673

Collected Steps per Second: 19,152.95417
Overall Steps per Second: 15,005.47484

Timestep Collection Time: 2.61223
Timestep Consumption Time: 0.72202
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 3.33425

Cumulative Model Updates: 22,823
Cumulative Timesteps: 381,031,310

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,949.39560
Policy Entropy: 0.84053
Value Function Loss: 0.07257

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03016
Policy Update Magnitude: 0.03276
Value Function Update Magnitude: 0.06763

Collected Steps per Second: 18,985.31099
Overall Steps per Second: 14,891.54891

Timestep Collection Time: 2.63383
Timestep Consumption Time: 0.72405
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 3.35788

Cumulative Model Updates: 22,826
Cumulative Timesteps: 381,081,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 381081314...
Checkpoint 381081314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,895.43087
Policy Entropy: 0.82984
Value Function Loss: 0.07512

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02883
Policy Update Magnitude: 0.03328
Value Function Update Magnitude: 0.06256

Collected Steps per Second: 18,942.53368
Overall Steps per Second: 14,945.80435

Timestep Collection Time: 2.63967
Timestep Consumption Time: 0.70589
PPO Batch Consumption Time: 0.04992
Total Iteration Time: 3.34555

Cumulative Model Updates: 22,829
Cumulative Timesteps: 381,131,316

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,291.85093
Policy Entropy: 0.84056
Value Function Loss: 0.07445

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01987
Policy Update Magnitude: 0.03269
Value Function Update Magnitude: 0.05614

Collected Steps per Second: 18,743.43598
Overall Steps per Second: 14,724.94871

Timestep Collection Time: 2.66909
Timestep Consumption Time: 0.72840
PPO Batch Consumption Time: 0.05403
Total Iteration Time: 3.39750

Cumulative Model Updates: 22,832
Cumulative Timesteps: 381,181,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 381181344...
Checkpoint 381181344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,861.76927
Policy Entropy: 0.83436
Value Function Loss: 0.06983

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02303
Policy Update Magnitude: 0.03074
Value Function Update Magnitude: 0.04664

Collected Steps per Second: 18,412.23659
Overall Steps per Second: 14,453.56539

Timestep Collection Time: 2.71580
Timestep Consumption Time: 0.74383
PPO Batch Consumption Time: 0.06509
Total Iteration Time: 3.45963

Cumulative Model Updates: 22,835
Cumulative Timesteps: 381,231,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,443.67330
Policy Entropy: 0.84612
Value Function Loss: 0.07015

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02269
Policy Update Magnitude: 0.03454
Value Function Update Magnitude: 0.04373

Collected Steps per Second: 19,313.04276
Overall Steps per Second: 15,201.42696

Timestep Collection Time: 2.59110
Timestep Consumption Time: 0.70083
PPO Batch Consumption Time: 0.04857
Total Iteration Time: 3.29193

Cumulative Model Updates: 22,838
Cumulative Timesteps: 381,281,390

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 381281390...
Checkpoint 381281390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,478.70921
Policy Entropy: 0.84184
Value Function Loss: 0.06747

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02550
Policy Update Magnitude: 0.03589
Value Function Update Magnitude: 0.04907

Collected Steps per Second: 18,741.89125
Overall Steps per Second: 14,762.23051

Timestep Collection Time: 2.66857
Timestep Consumption Time: 0.71940
PPO Batch Consumption Time: 0.05192
Total Iteration Time: 3.38797

Cumulative Model Updates: 22,841
Cumulative Timesteps: 381,331,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,125.16272
Policy Entropy: 0.86248
Value Function Loss: 0.06680

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.03238
Value Function Update Magnitude: 0.05726

Collected Steps per Second: 18,426.52048
Overall Steps per Second: 14,451.57200

Timestep Collection Time: 2.71381
Timestep Consumption Time: 0.74644
PPO Batch Consumption Time: 0.05982
Total Iteration Time: 3.46025

Cumulative Model Updates: 22,844
Cumulative Timesteps: 381,381,410

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 381381410...
Checkpoint 381381410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,998.63814
Policy Entropy: 0.87474
Value Function Loss: 0.06215

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02031
Policy Update Magnitude: 0.03103
Value Function Update Magnitude: 0.05809

Collected Steps per Second: 19,137.19627
Overall Steps per Second: 15,065.13219

Timestep Collection Time: 2.61365
Timestep Consumption Time: 0.70646
PPO Batch Consumption Time: 0.04893
Total Iteration Time: 3.32012

Cumulative Model Updates: 22,847
Cumulative Timesteps: 381,431,428

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,175.57732
Policy Entropy: 0.89052
Value Function Loss: 0.06029

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02354
Policy Update Magnitude: 0.03025
Value Function Update Magnitude: 0.06048

Collected Steps per Second: 18,417.98447
Overall Steps per Second: 14,487.07376

Timestep Collection Time: 2.71550
Timestep Consumption Time: 0.73682
PPO Batch Consumption Time: 0.05976
Total Iteration Time: 3.45232

Cumulative Model Updates: 22,850
Cumulative Timesteps: 381,481,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 381481442...
Checkpoint 381481442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,010.12813
Policy Entropy: 0.88318
Value Function Loss: 0.06403

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02237
Policy Update Magnitude: 0.02883
Value Function Update Magnitude: 0.05669

Collected Steps per Second: 19,151.48841
Overall Steps per Second: 15,085.88355

Timestep Collection Time: 2.61097
Timestep Consumption Time: 0.70365
PPO Batch Consumption Time: 0.05097
Total Iteration Time: 3.31462

Cumulative Model Updates: 22,853
Cumulative Timesteps: 381,531,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,883.56338
Policy Entropy: 0.89367
Value Function Loss: 0.06844

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02007
Policy Update Magnitude: 0.03025
Value Function Update Magnitude: 0.05349

Collected Steps per Second: 18,794.49832
Overall Steps per Second: 14,792.11670

Timestep Collection Time: 2.66110
Timestep Consumption Time: 0.72003
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 3.38113

Cumulative Model Updates: 22,856
Cumulative Timesteps: 381,581,460

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 381581460...
Checkpoint 381581460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,413.15013
Policy Entropy: 0.88388
Value Function Loss: 0.07858

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03049
Policy Update Magnitude: 0.03550
Value Function Update Magnitude: 0.05264

Collected Steps per Second: 19,070.66933
Overall Steps per Second: 14,825.88740

Timestep Collection Time: 2.62309
Timestep Consumption Time: 0.75101
PPO Batch Consumption Time: 0.06178
Total Iteration Time: 3.37410

Cumulative Model Updates: 22,859
Cumulative Timesteps: 381,631,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,486.28537
Policy Entropy: 0.88352
Value Function Loss: 0.08043

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01593
Policy Update Magnitude: 0.03439
Value Function Update Magnitude: 0.04878

Collected Steps per Second: 19,188.34903
Overall Steps per Second: 15,019.24448

Timestep Collection Time: 2.60648
Timestep Consumption Time: 0.72352
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 3.32999

Cumulative Model Updates: 22,862
Cumulative Timesteps: 381,681,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 381681498...
Checkpoint 381681498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,299.39984
Policy Entropy: 0.87836
Value Function Loss: 0.07601

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02005
Policy Update Magnitude: 0.03263
Value Function Update Magnitude: 0.04897

Collected Steps per Second: 19,544.33657
Overall Steps per Second: 15,363.78444

Timestep Collection Time: 2.56003
Timestep Consumption Time: 0.69659
PPO Batch Consumption Time: 0.05051
Total Iteration Time: 3.25662

Cumulative Model Updates: 22,865
Cumulative Timesteps: 381,731,532

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,822.11579
Policy Entropy: 0.86870
Value Function Loss: 0.07325

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03111
Policy Update Magnitude: 0.03282
Value Function Update Magnitude: 0.04821

Collected Steps per Second: 18,888.84416
Overall Steps per Second: 14,789.47396

Timestep Collection Time: 2.64823
Timestep Consumption Time: 0.73404
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 3.38227

Cumulative Model Updates: 22,868
Cumulative Timesteps: 381,781,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 381781554...
Checkpoint 381781554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,676.83008
Policy Entropy: 0.87992
Value Function Loss: 0.06702

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02197
Policy Update Magnitude: 0.03240
Value Function Update Magnitude: 0.04565

Collected Steps per Second: 18,843.60524
Overall Steps per Second: 14,738.67108

Timestep Collection Time: 2.65384
Timestep Consumption Time: 0.73913
PPO Batch Consumption Time: 0.05304
Total Iteration Time: 3.39298

Cumulative Model Updates: 22,871
Cumulative Timesteps: 381,831,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,083.09707
Policy Entropy: 0.88124
Value Function Loss: 0.06929

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03901
Policy Update Magnitude: 0.03277
Value Function Update Magnitude: 0.04359

Collected Steps per Second: 19,348.57652
Overall Steps per Second: 15,051.61590

Timestep Collection Time: 2.58489
Timestep Consumption Time: 0.73794
PPO Batch Consumption Time: 0.06258
Total Iteration Time: 3.32283

Cumulative Model Updates: 22,874
Cumulative Timesteps: 381,881,576

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 381881576...
Checkpoint 381881576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,108.74971
Policy Entropy: 0.88972
Value Function Loss: 0.06652

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03496
Policy Update Magnitude: 0.03786
Value Function Update Magnitude: 0.04454

Collected Steps per Second: 19,760.00916
Overall Steps per Second: 15,381.64933

Timestep Collection Time: 2.53036
Timestep Consumption Time: 0.72026
PPO Batch Consumption Time: 0.05185
Total Iteration Time: 3.25063

Cumulative Model Updates: 22,877
Cumulative Timesteps: 381,931,576

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,683.54430
Policy Entropy: 0.89664
Value Function Loss: 0.06682

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04789
Policy Update Magnitude: 0.04073
Value Function Update Magnitude: 0.04763

Collected Steps per Second: 18,864.21424
Overall Steps per Second: 14,449.73612

Timestep Collection Time: 2.65148
Timestep Consumption Time: 0.81004
PPO Batch Consumption Time: 0.05985
Total Iteration Time: 3.46152

Cumulative Model Updates: 22,880
Cumulative Timesteps: 381,981,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 381981594...
Checkpoint 381981594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,341.92946
Policy Entropy: 0.88635
Value Function Loss: 0.06837

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04762
Policy Update Magnitude: 0.03840
Value Function Update Magnitude: 0.04775

Collected Steps per Second: 19,557.52430
Overall Steps per Second: 15,025.61888

Timestep Collection Time: 2.55902
Timestep Consumption Time: 0.77183
PPO Batch Consumption Time: 0.05017
Total Iteration Time: 3.33084

Cumulative Model Updates: 22,883
Cumulative Timesteps: 382,031,642

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,251.04435
Policy Entropy: 0.88445
Value Function Loss: 0.06553

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04176
Policy Update Magnitude: 0.03432
Value Function Update Magnitude: 0.04835

Collected Steps per Second: 19,558.87095
Overall Steps per Second: 14,934.83957

Timestep Collection Time: 2.55771
Timestep Consumption Time: 0.79190
PPO Batch Consumption Time: 0.05797
Total Iteration Time: 3.34962

Cumulative Model Updates: 22,886
Cumulative Timesteps: 382,081,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 382081668...
Checkpoint 382081668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,311.10255
Policy Entropy: 0.87812
Value Function Loss: 0.06438

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03889
Policy Update Magnitude: 0.03326
Value Function Update Magnitude: 0.04815

Collected Steps per Second: 19,631.05796
Overall Steps per Second: 14,872.55427

Timestep Collection Time: 2.54739
Timestep Consumption Time: 0.81504
PPO Batch Consumption Time: 0.05993
Total Iteration Time: 3.36244

Cumulative Model Updates: 22,889
Cumulative Timesteps: 382,131,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,249.72495
Policy Entropy: 0.88080
Value Function Loss: 0.06335

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04569
Policy Update Magnitude: 0.03244
Value Function Update Magnitude: 0.04477

Collected Steps per Second: 19,714.56421
Overall Steps per Second: 15,044.58424

Timestep Collection Time: 2.53650
Timestep Consumption Time: 0.78735
PPO Batch Consumption Time: 0.06070
Total Iteration Time: 3.32385

Cumulative Model Updates: 22,892
Cumulative Timesteps: 382,181,682

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 382181682...
Checkpoint 382181682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,058.96887
Policy Entropy: 0.88152
Value Function Loss: 0.06100

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02343
Policy Update Magnitude: 0.03282
Value Function Update Magnitude: 0.04634

Collected Steps per Second: 19,905.77535
Overall Steps per Second: 15,255.32584

Timestep Collection Time: 2.51234
Timestep Consumption Time: 0.76586
PPO Batch Consumption Time: 0.04984
Total Iteration Time: 3.27820

Cumulative Model Updates: 22,895
Cumulative Timesteps: 382,231,692

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,383.47891
Policy Entropy: 0.87664
Value Function Loss: 0.06200

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03137
Policy Update Magnitude: 0.03305
Value Function Update Magnitude: 0.04280

Collected Steps per Second: 19,473.66998
Overall Steps per Second: 14,806.59244

Timestep Collection Time: 2.56962
Timestep Consumption Time: 0.80995
PPO Batch Consumption Time: 0.06096
Total Iteration Time: 3.37958

Cumulative Model Updates: 22,898
Cumulative Timesteps: 382,281,732

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 382281732...
Checkpoint 382281732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,083.67285
Policy Entropy: 0.86905
Value Function Loss: 0.07190

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04003
Policy Update Magnitude: 0.03190
Value Function Update Magnitude: 0.04110

Collected Steps per Second: 19,655.77439
Overall Steps per Second: 15,000.34716

Timestep Collection Time: 2.54449
Timestep Consumption Time: 0.78970
PPO Batch Consumption Time: 0.06015
Total Iteration Time: 3.33419

Cumulative Model Updates: 22,901
Cumulative Timesteps: 382,331,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,335.35194
Policy Entropy: 0.87130
Value Function Loss: 0.07355

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03641
Policy Update Magnitude: 0.03292
Value Function Update Magnitude: 0.04743

Collected Steps per Second: 19,715.56798
Overall Steps per Second: 15,117.43293

Timestep Collection Time: 2.53789
Timestep Consumption Time: 0.77193
PPO Batch Consumption Time: 0.05178
Total Iteration Time: 3.30982

Cumulative Model Updates: 22,904
Cumulative Timesteps: 382,381,782

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 382381782...
Checkpoint 382381782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,861.94998
Policy Entropy: 0.86837
Value Function Loss: 0.07240

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01913
Policy Update Magnitude: 0.03489
Value Function Update Magnitude: 0.05028

Collected Steps per Second: 19,406.10325
Overall Steps per Second: 14,934.63812

Timestep Collection Time: 2.57733
Timestep Consumption Time: 0.77166
PPO Batch Consumption Time: 0.05123
Total Iteration Time: 3.34899

Cumulative Model Updates: 22,907
Cumulative Timesteps: 382,431,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,852.41455
Policy Entropy: 0.88618
Value Function Loss: 0.07035

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02295
Policy Update Magnitude: 0.03351
Value Function Update Magnitude: 0.04793

Collected Steps per Second: 19,242.25624
Overall Steps per Second: 14,585.92897

Timestep Collection Time: 2.59959
Timestep Consumption Time: 0.82988
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 3.42947

Cumulative Model Updates: 22,910
Cumulative Timesteps: 382,481,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 382481820...
Checkpoint 382481820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,294.44670
Policy Entropy: 0.89132
Value Function Loss: 0.06913

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03472
Policy Update Magnitude: 0.03437
Value Function Update Magnitude: 0.05177

Collected Steps per Second: 19,649.91068
Overall Steps per Second: 14,974.81776

Timestep Collection Time: 2.54525
Timestep Consumption Time: 0.79462
PPO Batch Consumption Time: 0.04956
Total Iteration Time: 3.33987

Cumulative Model Updates: 22,913
Cumulative Timesteps: 382,531,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,179.37603
Policy Entropy: 0.88397
Value Function Loss: 0.08170

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02905
Policy Update Magnitude: 0.03856
Value Function Update Magnitude: 0.05088

Collected Steps per Second: 19,324.90451
Overall Steps per Second: 14,764.22493

Timestep Collection Time: 2.58899
Timestep Consumption Time: 0.79974
PPO Batch Consumption Time: 0.05935
Total Iteration Time: 3.38873

Cumulative Model Updates: 22,916
Cumulative Timesteps: 382,581,866

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 382581866...
Checkpoint 382581866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,916.19568
Policy Entropy: 0.89107
Value Function Loss: 0.07156

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04152
Policy Update Magnitude: 0.03569
Value Function Update Magnitude: 0.04675

Collected Steps per Second: 19,500.16900
Overall Steps per Second: 14,826.53599

Timestep Collection Time: 2.56531
Timestep Consumption Time: 0.80864
PPO Batch Consumption Time: 0.05390
Total Iteration Time: 3.37395

Cumulative Model Updates: 22,919
Cumulative Timesteps: 382,631,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,905.10703
Policy Entropy: 0.89541
Value Function Loss: 0.07176

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02315
Policy Update Magnitude: 0.03478
Value Function Update Magnitude: 0.04924

Collected Steps per Second: 19,593.23470
Overall Steps per Second: 14,866.48846

Timestep Collection Time: 2.55251
Timestep Consumption Time: 0.81156
PPO Batch Consumption Time: 0.05874
Total Iteration Time: 3.36408

Cumulative Model Updates: 22,922
Cumulative Timesteps: 382,681,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 382681902...
Checkpoint 382681902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,507.20148
Policy Entropy: 0.88982
Value Function Loss: 0.06245

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06199
Policy Update Magnitude: 0.03399
Value Function Update Magnitude: 0.04803

Collected Steps per Second: 19,244.13572
Overall Steps per Second: 14,690.01855

Timestep Collection Time: 2.59892
Timestep Consumption Time: 0.80570
PPO Batch Consumption Time: 0.05174
Total Iteration Time: 3.40462

Cumulative Model Updates: 22,925
Cumulative Timesteps: 382,731,916

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,459.21096
Policy Entropy: 0.88598
Value Function Loss: 0.06323

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03649
Policy Update Magnitude: 0.03486
Value Function Update Magnitude: 0.04709

Collected Steps per Second: 19,867.60963
Overall Steps per Second: 14,983.50431

Timestep Collection Time: 2.51807
Timestep Consumption Time: 0.82080
PPO Batch Consumption Time: 0.06164
Total Iteration Time: 3.33887

Cumulative Model Updates: 22,928
Cumulative Timesteps: 382,781,944

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 382781944...
Checkpoint 382781944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,748.39548
Policy Entropy: 0.88566
Value Function Loss: 0.05985

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05377
Policy Update Magnitude: 0.03431
Value Function Update Magnitude: 0.04352

Collected Steps per Second: 19,621.44325
Overall Steps per Second: 14,760.85959

Timestep Collection Time: 2.54986
Timestep Consumption Time: 0.83964
PPO Batch Consumption Time: 0.06032
Total Iteration Time: 3.38950

Cumulative Model Updates: 22,931
Cumulative Timesteps: 382,831,976

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,153.32759
Policy Entropy: 0.89797
Value Function Loss: 0.06141

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03299
Policy Update Magnitude: 0.03399
Value Function Update Magnitude: 0.04492

Collected Steps per Second: 19,666.79990
Overall Steps per Second: 14,654.63490

Timestep Collection Time: 2.54337
Timestep Consumption Time: 0.86988
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 3.41325

Cumulative Model Updates: 22,934
Cumulative Timesteps: 382,881,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 382881996...
Checkpoint 382881996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,474.72664
Policy Entropy: 0.89637
Value Function Loss: 0.06631

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03412
Policy Update Magnitude: 0.03373
Value Function Update Magnitude: 0.04994

Collected Steps per Second: 18,672.36129
Overall Steps per Second: 14,372.92779

Timestep Collection Time: 2.67850
Timestep Consumption Time: 0.80123
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 3.47974

Cumulative Model Updates: 22,937
Cumulative Timesteps: 382,932,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,730.80461
Policy Entropy: 0.88668
Value Function Loss: 0.06607

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02071
Policy Update Magnitude: 0.03939
Value Function Update Magnitude: 0.04789

Collected Steps per Second: 20,111.89255
Overall Steps per Second: 15,114.44426

Timestep Collection Time: 2.48758
Timestep Consumption Time: 0.82250
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 3.31008

Cumulative Model Updates: 22,940
Cumulative Timesteps: 382,982,040

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 382982040...
Checkpoint 382982040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,676.71983
Policy Entropy: 0.88700
Value Function Loss: 0.07181

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03478
Policy Update Magnitude: 0.03537
Value Function Update Magnitude: 0.04521

Collected Steps per Second: 18,448.82863
Overall Steps per Second: 14,084.55623

Timestep Collection Time: 2.71063
Timestep Consumption Time: 0.83992
PPO Batch Consumption Time: 0.06732
Total Iteration Time: 3.55056

Cumulative Model Updates: 22,943
Cumulative Timesteps: 383,032,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,484.13625
Policy Entropy: 0.88434
Value Function Loss: 0.07388

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02675
Policy Update Magnitude: 0.03397
Value Function Update Magnitude: 0.04644

Collected Steps per Second: 18,344.58702
Overall Steps per Second: 14,057.50849

Timestep Collection Time: 2.72582
Timestep Consumption Time: 0.83128
PPO Batch Consumption Time: 0.05854
Total Iteration Time: 3.55710

Cumulative Model Updates: 22,946
Cumulative Timesteps: 383,082,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 383082052...
Checkpoint 383082052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,499.32626
Policy Entropy: 0.90087
Value Function Loss: 0.07927

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03248
Policy Update Magnitude: 0.03357
Value Function Update Magnitude: 0.04730

Collected Steps per Second: 19,769.80346
Overall Steps per Second: 15,059.29681

Timestep Collection Time: 2.52972
Timestep Consumption Time: 0.79129
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 3.32101

Cumulative Model Updates: 22,949
Cumulative Timesteps: 383,132,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,212.50192
Policy Entropy: 0.88258
Value Function Loss: 0.07513

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02371
Policy Update Magnitude: 0.03336
Value Function Update Magnitude: 0.04647

Collected Steps per Second: 19,325.69657
Overall Steps per Second: 14,645.31782

Timestep Collection Time: 2.58785
Timestep Consumption Time: 0.82703
PPO Batch Consumption Time: 0.06108
Total Iteration Time: 3.41488

Cumulative Model Updates: 22,952
Cumulative Timesteps: 383,182,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 383182076...
Checkpoint 383182076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,121.39003
Policy Entropy: 0.88841
Value Function Loss: 0.07788

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03505
Policy Update Magnitude: 0.03419
Value Function Update Magnitude: 0.04807

Collected Steps per Second: 19,578.70365
Overall Steps per Second: 14,907.87765

Timestep Collection Time: 2.55492
Timestep Consumption Time: 0.80049
PPO Batch Consumption Time: 0.05832
Total Iteration Time: 3.35541

Cumulative Model Updates: 22,955
Cumulative Timesteps: 383,232,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,704.06578
Policy Entropy: 0.88047
Value Function Loss: 0.07174

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03455
Policy Update Magnitude: 0.03266
Value Function Update Magnitude: 0.04555

Collected Steps per Second: 19,408.56373
Overall Steps per Second: 15,030.99824

Timestep Collection Time: 2.57752
Timestep Consumption Time: 0.75067
PPO Batch Consumption Time: 0.04764
Total Iteration Time: 3.32819

Cumulative Model Updates: 22,958
Cumulative Timesteps: 383,282,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 383282124...
Checkpoint 383282124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,955.01006
Policy Entropy: 0.90877
Value Function Loss: 0.06738

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03520
Policy Update Magnitude: 0.03201
Value Function Update Magnitude: 0.04290

Collected Steps per Second: 18,440.51571
Overall Steps per Second: 14,094.20112

Timestep Collection Time: 2.71196
Timestep Consumption Time: 0.83630
PPO Batch Consumption Time: 0.06224
Total Iteration Time: 3.54827

Cumulative Model Updates: 22,961
Cumulative Timesteps: 383,332,134

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,032.54962
Policy Entropy: 0.91227
Value Function Loss: 0.06415

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02655
Policy Update Magnitude: 0.03457
Value Function Update Magnitude: 0.03886

Collected Steps per Second: 20,063.38152
Overall Steps per Second: 15,085.15196

Timestep Collection Time: 2.49360
Timestep Consumption Time: 0.82291
PPO Batch Consumption Time: 0.05941
Total Iteration Time: 3.31651

Cumulative Model Updates: 22,964
Cumulative Timesteps: 383,382,164

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 383382164...
Checkpoint 383382164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,279.66891
Policy Entropy: 0.91729
Value Function Loss: 0.06809

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02761
Policy Update Magnitude: 0.03846
Value Function Update Magnitude: 0.03895

Collected Steps per Second: 19,673.73382
Overall Steps per Second: 14,679.35097

Timestep Collection Time: 2.54248
Timestep Consumption Time: 0.86503
PPO Batch Consumption Time: 0.06780
Total Iteration Time: 3.40751

Cumulative Model Updates: 22,967
Cumulative Timesteps: 383,432,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,034.02288
Policy Entropy: 0.91150
Value Function Loss: 0.07068

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05342
Policy Update Magnitude: 0.03613
Value Function Update Magnitude: 0.03662

Collected Steps per Second: 19,560.44595
Overall Steps per Second: 14,738.31666

Timestep Collection Time: 2.55761
Timestep Consumption Time: 0.83681
PPO Batch Consumption Time: 0.06217
Total Iteration Time: 3.39442

Cumulative Model Updates: 22,970
Cumulative Timesteps: 383,482,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 383482212...
Checkpoint 383482212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,601.54576
Policy Entropy: 0.90467
Value Function Loss: 0.07195

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05471
Policy Update Magnitude: 0.03381
Value Function Update Magnitude: 0.03265

Collected Steps per Second: 19,807.24419
Overall Steps per Second: 15,091.90415

Timestep Collection Time: 2.52453
Timestep Consumption Time: 0.78877
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 3.31330

Cumulative Model Updates: 22,973
Cumulative Timesteps: 383,532,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,699.37256
Policy Entropy: 0.91859
Value Function Loss: 0.07017

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04553
Policy Update Magnitude: 0.03729
Value Function Update Magnitude: 0.03195

Collected Steps per Second: 19,566.26253
Overall Steps per Second: 15,012.18468

Timestep Collection Time: 2.55573
Timestep Consumption Time: 0.77530
PPO Batch Consumption Time: 0.04637
Total Iteration Time: 3.33103

Cumulative Model Updates: 22,976
Cumulative Timesteps: 383,582,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 383582222...
Checkpoint 383582222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,884.26800
Policy Entropy: 0.90885
Value Function Loss: 0.07312

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06941
Policy Update Magnitude: 0.03746
Value Function Update Magnitude: 0.03339

Collected Steps per Second: 18,967.77677
Overall Steps per Second: 14,573.11014

Timestep Collection Time: 2.63710
Timestep Consumption Time: 0.79524
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 3.43235

Cumulative Model Updates: 22,979
Cumulative Timesteps: 383,632,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,997.07638
Policy Entropy: 0.90967
Value Function Loss: 0.07542

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05414
Policy Update Magnitude: 0.03458
Value Function Update Magnitude: 0.03541

Collected Steps per Second: 19,982.28547
Overall Steps per Second: 15,029.65874

Timestep Collection Time: 2.50292
Timestep Consumption Time: 0.82477
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 3.32769

Cumulative Model Updates: 22,982
Cumulative Timesteps: 383,682,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 383682256...
Checkpoint 383682256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,378.55672
Policy Entropy: 0.90945
Value Function Loss: 0.07413

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05502
Policy Update Magnitude: 0.03487
Value Function Update Magnitude: 0.03888

Collected Steps per Second: 19,364.02186
Overall Steps per Second: 14,723.15507

Timestep Collection Time: 2.58355
Timestep Consumption Time: 0.81436
PPO Batch Consumption Time: 0.05219
Total Iteration Time: 3.39791

Cumulative Model Updates: 22,985
Cumulative Timesteps: 383,732,284

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,860.77996
Policy Entropy: 0.90936
Value Function Loss: 0.06748

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04193
Policy Update Magnitude: 0.03313
Value Function Update Magnitude: 0.04461

Collected Steps per Second: 18,986.86250
Overall Steps per Second: 14,475.97978

Timestep Collection Time: 2.63456
Timestep Consumption Time: 0.82096
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 3.45552

Cumulative Model Updates: 22,988
Cumulative Timesteps: 383,782,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 383782306...
Checkpoint 383782306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,146.84685
Policy Entropy: 0.90260
Value Function Loss: 0.06126

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04023
Policy Update Magnitude: 0.03234
Value Function Update Magnitude: 0.04195

Collected Steps per Second: 19,951.76707
Overall Steps per Second: 15,178.25757

Timestep Collection Time: 2.50654
Timestep Consumption Time: 0.78830
PPO Batch Consumption Time: 0.05928
Total Iteration Time: 3.29484

Cumulative Model Updates: 22,991
Cumulative Timesteps: 383,832,316

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,247.49893
Policy Entropy: 0.91949
Value Function Loss: 0.05913

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.05195
Policy Update Magnitude: 0.02965
Value Function Update Magnitude: 0.04468

Collected Steps per Second: 19,815.03982
Overall Steps per Second: 14,924.86636

Timestep Collection Time: 2.52445
Timestep Consumption Time: 0.82714
PPO Batch Consumption Time: 0.05932
Total Iteration Time: 3.35159

Cumulative Model Updates: 22,994
Cumulative Timesteps: 383,882,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 383882338...
Checkpoint 383882338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,324.61254
Policy Entropy: 0.92324
Value Function Loss: 0.06630

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06113
Policy Update Magnitude: 0.02958
Value Function Update Magnitude: 0.03995

Collected Steps per Second: 19,699.89224
Overall Steps per Second: 14,941.74794

Timestep Collection Time: 2.53961
Timestep Consumption Time: 0.80873
PPO Batch Consumption Time: 0.06146
Total Iteration Time: 3.34834

Cumulative Model Updates: 22,997
Cumulative Timesteps: 383,932,368

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,799.84129
Policy Entropy: 0.94239
Value Function Loss: 0.06814

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.02971
Value Function Update Magnitude: 0.04234

Collected Steps per Second: 19,389.48586
Overall Steps per Second: 14,661.85235

Timestep Collection Time: 2.57985
Timestep Consumption Time: 0.83186
PPO Batch Consumption Time: 0.06145
Total Iteration Time: 3.41171

Cumulative Model Updates: 23,000
Cumulative Timesteps: 383,982,390

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 383982390...
Checkpoint 383982390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,681.61922
Policy Entropy: 0.92451
Value Function Loss: 0.06904

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07393
Policy Update Magnitude: 0.02874
Value Function Update Magnitude: 0.05340

Collected Steps per Second: 19,255.21532
Overall Steps per Second: 14,596.67224

Timestep Collection Time: 2.59795
Timestep Consumption Time: 0.82914
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 3.42708

Cumulative Model Updates: 23,003
Cumulative Timesteps: 384,032,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,349.49803
Policy Entropy: 0.92431
Value Function Loss: 0.06341

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.03081
Value Function Update Magnitude: 0.05835

Collected Steps per Second: 19,695.07599
Overall Steps per Second: 14,787.89413

Timestep Collection Time: 2.53952
Timestep Consumption Time: 0.84271
PPO Batch Consumption Time: 0.06956
Total Iteration Time: 3.38223

Cumulative Model Updates: 23,006
Cumulative Timesteps: 384,082,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 384082430...
Checkpoint 384082430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,887.24736
Policy Entropy: 0.91414
Value Function Loss: 0.06281

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.06876
Policy Update Magnitude: 0.03129
Value Function Update Magnitude: 0.06151

Collected Steps per Second: 19,721.58477
Overall Steps per Second: 14,928.08608

Timestep Collection Time: 2.53692
Timestep Consumption Time: 0.81462
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 3.35153

Cumulative Model Updates: 23,009
Cumulative Timesteps: 384,132,462

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,239.06208
Policy Entropy: 0.91696
Value Function Loss: 0.06505

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.06169
Policy Update Magnitude: 0.03133
Value Function Update Magnitude: 0.05652

Collected Steps per Second: 19,175.68175
Overall Steps per Second: 14,609.62949

Timestep Collection Time: 2.60945
Timestep Consumption Time: 0.81555
PPO Batch Consumption Time: 0.05872
Total Iteration Time: 3.42500

Cumulative Model Updates: 23,012
Cumulative Timesteps: 384,182,500

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 384182500...
Checkpoint 384182500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,777.75713
Policy Entropy: 0.91363
Value Function Loss: 0.07828

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.06047
Policy Update Magnitude: 0.03145
Value Function Update Magnitude: 0.04955

Collected Steps per Second: 19,732.12372
Overall Steps per Second: 14,998.25294

Timestep Collection Time: 2.53516
Timestep Consumption Time: 0.80017
PPO Batch Consumption Time: 0.06109
Total Iteration Time: 3.33532

Cumulative Model Updates: 23,015
Cumulative Timesteps: 384,232,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,719.91571
Policy Entropy: 0.92630
Value Function Loss: 0.07646

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04300
Policy Update Magnitude: 0.03473
Value Function Update Magnitude: 0.05403

Collected Steps per Second: 19,357.84194
Overall Steps per Second: 14,681.79846

Timestep Collection Time: 2.58324
Timestep Consumption Time: 0.82274
PPO Batch Consumption Time: 0.06098
Total Iteration Time: 3.40599

Cumulative Model Updates: 23,018
Cumulative Timesteps: 384,282,530

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 384282530...
Checkpoint 384282530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,192.02541
Policy Entropy: 0.91942
Value Function Loss: 0.07987

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06096
Policy Update Magnitude: 0.03335
Value Function Update Magnitude: 0.05917

Collected Steps per Second: 19,463.55740
Overall Steps per Second: 14,824.59319

Timestep Collection Time: 2.56952
Timestep Consumption Time: 0.80406
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 3.37358

Cumulative Model Updates: 23,021
Cumulative Timesteps: 384,332,542

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,263.86735
Policy Entropy: 0.92374
Value Function Loss: 0.06480

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03303
Policy Update Magnitude: 0.03089
Value Function Update Magnitude: 0.06116

Collected Steps per Second: 19,639.53973
Overall Steps per Second: 14,936.97740

Timestep Collection Time: 2.54700
Timestep Consumption Time: 0.80187
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 3.34887

Cumulative Model Updates: 23,024
Cumulative Timesteps: 384,382,564

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 384382564...
Checkpoint 384382564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,389.78604
Policy Entropy: 0.91456
Value Function Loss: 0.05694

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03385
Policy Update Magnitude: 0.03024
Value Function Update Magnitude: 0.06164

Collected Steps per Second: 19,882.23532
Overall Steps per Second: 14,916.10348

Timestep Collection Time: 2.51581
Timestep Consumption Time: 0.83761
PPO Batch Consumption Time: 0.06017
Total Iteration Time: 3.35342

Cumulative Model Updates: 23,027
Cumulative Timesteps: 384,432,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,036.67265
Policy Entropy: 0.91350
Value Function Loss: 0.05913

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02414
Policy Update Magnitude: 0.03124
Value Function Update Magnitude: 0.05962

Collected Steps per Second: 19,964.75278
Overall Steps per Second: 15,047.72337

Timestep Collection Time: 2.50562
Timestep Consumption Time: 0.81874
PPO Batch Consumption Time: 0.05826
Total Iteration Time: 3.32436

Cumulative Model Updates: 23,030
Cumulative Timesteps: 384,482,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 384482608...
Checkpoint 384482608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,227.29822
Policy Entropy: 0.91655
Value Function Loss: 0.06663

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02525
Policy Update Magnitude: 0.03155
Value Function Update Magnitude: 0.05611

Collected Steps per Second: 19,325.77065
Overall Steps per Second: 14,602.56819

Timestep Collection Time: 2.58950
Timestep Consumption Time: 0.83757
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 3.42707

Cumulative Model Updates: 23,033
Cumulative Timesteps: 384,532,652

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,648.99511
Policy Entropy: 0.92118
Value Function Loss: 0.07089

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02179
Policy Update Magnitude: 0.03162
Value Function Update Magnitude: 0.05051

Collected Steps per Second: 20,151.43144
Overall Steps per Second: 15,142.06982

Timestep Collection Time: 2.48221
Timestep Consumption Time: 0.82117
PPO Batch Consumption Time: 0.05843
Total Iteration Time: 3.30338

Cumulative Model Updates: 23,036
Cumulative Timesteps: 384,582,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 384582672...
Checkpoint 384582672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,031.21546
Policy Entropy: 0.93586
Value Function Loss: 0.06390

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02083
Policy Update Magnitude: 0.02984
Value Function Update Magnitude: 0.04498

Collected Steps per Second: 19,590.60532
Overall Steps per Second: 14,739.87220

Timestep Collection Time: 2.55275
Timestep Consumption Time: 0.84008
PPO Batch Consumption Time: 0.05996
Total Iteration Time: 3.39284

Cumulative Model Updates: 23,039
Cumulative Timesteps: 384,632,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,096.57596
Policy Entropy: 0.93455
Value Function Loss: 0.05569

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02043
Policy Update Magnitude: 0.03007
Value Function Update Magnitude: 0.04001

Collected Steps per Second: 19,833.70924
Overall Steps per Second: 14,969.73631

Timestep Collection Time: 2.52116
Timestep Consumption Time: 0.81918
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 3.34034

Cumulative Model Updates: 23,042
Cumulative Timesteps: 384,682,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 384682686...
Checkpoint 384682686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,905.18776
Policy Entropy: 0.92994
Value Function Loss: 0.05937

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01822
Policy Update Magnitude: 0.03115
Value Function Update Magnitude: 0.04194

Collected Steps per Second: 19,694.22301
Overall Steps per Second: 14,845.14461

Timestep Collection Time: 2.54003
Timestep Consumption Time: 0.82969
PPO Batch Consumption Time: 0.06005
Total Iteration Time: 3.36972

Cumulative Model Updates: 23,045
Cumulative Timesteps: 384,732,710

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,688.33421
Policy Entropy: 0.92937
Value Function Loss: 0.06508

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01437
Policy Update Magnitude: 0.03274
Value Function Update Magnitude: 0.04757

Collected Steps per Second: 20,193.83629
Overall Steps per Second: 15,238.49626

Timestep Collection Time: 2.47739
Timestep Consumption Time: 0.80561
PPO Batch Consumption Time: 0.05205
Total Iteration Time: 3.28300

Cumulative Model Updates: 23,048
Cumulative Timesteps: 384,782,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 384782738...
Checkpoint 384782738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,361.57293
Policy Entropy: 0.92365
Value Function Loss: 0.06586

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01337
Policy Update Magnitude: 0.03392
Value Function Update Magnitude: 0.04780

Collected Steps per Second: 18,987.70700
Overall Steps per Second: 14,482.94449

Timestep Collection Time: 2.63402
Timestep Consumption Time: 0.81928
PPO Batch Consumption Time: 0.06107
Total Iteration Time: 3.45330

Cumulative Model Updates: 23,051
Cumulative Timesteps: 384,832,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,874.98100
Policy Entropy: 0.92791
Value Function Loss: 0.06365

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01701
Policy Update Magnitude: 0.03432
Value Function Update Magnitude: 0.05596

Collected Steps per Second: 19,901.65930
Overall Steps per Second: 15,097.16616

Timestep Collection Time: 2.51286
Timestep Consumption Time: 0.79969
PPO Batch Consumption Time: 0.05317
Total Iteration Time: 3.31254

Cumulative Model Updates: 23,054
Cumulative Timesteps: 384,882,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 384882762...
Checkpoint 384882762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,123.37904
Policy Entropy: 0.91617
Value Function Loss: 0.05961

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01457
Policy Update Magnitude: 0.03128
Value Function Update Magnitude: 0.05116

Collected Steps per Second: 18,965.32711
Overall Steps per Second: 14,579.19554

Timestep Collection Time: 2.63702
Timestep Consumption Time: 0.79334
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 3.43037

Cumulative Model Updates: 23,057
Cumulative Timesteps: 384,932,774

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,140.30052
Policy Entropy: 0.92595
Value Function Loss: 0.06226

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01837
Policy Update Magnitude: 0.03030
Value Function Update Magnitude: 0.04669

Collected Steps per Second: 19,467.62515
Overall Steps per Second: 14,825.40134

Timestep Collection Time: 2.56898
Timestep Consumption Time: 0.80442
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 3.37340

Cumulative Model Updates: 23,060
Cumulative Timesteps: 384,982,786

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 384982786...
Checkpoint 384982786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,172.11626
Policy Entropy: 0.92669
Value Function Loss: 0.06158

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02104
Policy Update Magnitude: 0.03259
Value Function Update Magnitude: 0.04934

Collected Steps per Second: 19,465.21618
Overall Steps per Second: 14,777.07005

Timestep Collection Time: 2.57053
Timestep Consumption Time: 0.81552
PPO Batch Consumption Time: 0.05366
Total Iteration Time: 3.38606

Cumulative Model Updates: 23,063
Cumulative Timesteps: 385,032,822

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,272.02459
Policy Entropy: 0.93011
Value Function Loss: 0.06859

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01792
Policy Update Magnitude: 0.03290
Value Function Update Magnitude: 0.04961

Collected Steps per Second: 19,909.58084
Overall Steps per Second: 15,183.11561

Timestep Collection Time: 2.51316
Timestep Consumption Time: 0.78234
PPO Batch Consumption Time: 0.05957
Total Iteration Time: 3.29550

Cumulative Model Updates: 23,066
Cumulative Timesteps: 385,082,858

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 385082858...
Checkpoint 385082858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,351.91629
Policy Entropy: 0.92242
Value Function Loss: 0.07067

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.03324
Value Function Update Magnitude: 0.04441

Collected Steps per Second: 19,578.70822
Overall Steps per Second: 14,716.23150

Timestep Collection Time: 2.55471
Timestep Consumption Time: 0.84412
PPO Batch Consumption Time: 0.06494
Total Iteration Time: 3.39883

Cumulative Model Updates: 23,069
Cumulative Timesteps: 385,132,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,622.20198
Policy Entropy: 0.92239
Value Function Loss: 0.07249

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02879
Policy Update Magnitude: 0.03223
Value Function Update Magnitude: 0.04572

Collected Steps per Second: 19,607.56717
Overall Steps per Second: 14,820.40241

Timestep Collection Time: 2.55075
Timestep Consumption Time: 0.82392
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 3.37467

Cumulative Model Updates: 23,072
Cumulative Timesteps: 385,182,890

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 385182890...
Checkpoint 385182890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,732.71789
Policy Entropy: 0.92548
Value Function Loss: 0.06429

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.03147
Value Function Update Magnitude: 0.04828

Collected Steps per Second: 19,348.15725
Overall Steps per Second: 14,642.04773

Timestep Collection Time: 2.58433
Timestep Consumption Time: 0.83063
PPO Batch Consumption Time: 0.05851
Total Iteration Time: 3.41496

Cumulative Model Updates: 23,075
Cumulative Timesteps: 385,232,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,411.83723
Policy Entropy: 0.91902
Value Function Loss: 0.06169

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02196
Policy Update Magnitude: 0.03162
Value Function Update Magnitude: 0.04502

Collected Steps per Second: 19,597.06301
Overall Steps per Second: 14,878.03707

Timestep Collection Time: 2.55263
Timestep Consumption Time: 0.80964
PPO Batch Consumption Time: 0.05917
Total Iteration Time: 3.36227

Cumulative Model Updates: 23,078
Cumulative Timesteps: 385,282,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 385282916...
Checkpoint 385282916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,280.14119
Policy Entropy: 0.92014
Value Function Loss: 0.06075

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02480
Policy Update Magnitude: 0.03124
Value Function Update Magnitude: 0.04250

Collected Steps per Second: 19,574.15929
Overall Steps per Second: 14,705.97619

Timestep Collection Time: 2.55490
Timestep Consumption Time: 0.84576
PPO Batch Consumption Time: 0.06282
Total Iteration Time: 3.40066

Cumulative Model Updates: 23,081
Cumulative Timesteps: 385,332,926

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,537.38160
Policy Entropy: 0.91127
Value Function Loss: 0.05806

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02627
Policy Update Magnitude: 0.03027
Value Function Update Magnitude: 0.05104

Collected Steps per Second: 19,552.73165
Overall Steps per Second: 14,954.78423

Timestep Collection Time: 2.55841
Timestep Consumption Time: 0.78660
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 3.34502

Cumulative Model Updates: 23,084
Cumulative Timesteps: 385,382,950

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 385382950...
Checkpoint 385382950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,220.82492
Policy Entropy: 0.90559
Value Function Loss: 0.06361

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02479
Policy Update Magnitude: 0.02979
Value Function Update Magnitude: 0.05231

Collected Steps per Second: 19,426.88362
Overall Steps per Second: 14,694.78217

Timestep Collection Time: 2.57375
Timestep Consumption Time: 0.82882
PPO Batch Consumption Time: 0.05862
Total Iteration Time: 3.40257

Cumulative Model Updates: 23,087
Cumulative Timesteps: 385,432,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,082.36524
Policy Entropy: 0.89720
Value Function Loss: 0.07398

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.03174
Value Function Update Magnitude: 0.04685

Collected Steps per Second: 20,094.39707
Overall Steps per Second: 15,117.70167

Timestep Collection Time: 2.48925
Timestep Consumption Time: 0.81945
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 3.30870

Cumulative Model Updates: 23,090
Cumulative Timesteps: 385,482,970

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 385482970...
Checkpoint 385482970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,303.98945
Policy Entropy: 0.92805
Value Function Loss: 0.07743

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03789
Policy Update Magnitude: 0.03392
Value Function Update Magnitude: 0.04965

Collected Steps per Second: 19,862.73960
Overall Steps per Second: 15,049.75329

Timestep Collection Time: 2.51859
Timestep Consumption Time: 0.80546
PPO Batch Consumption Time: 0.04962
Total Iteration Time: 3.32404

Cumulative Model Updates: 23,093
Cumulative Timesteps: 385,532,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,136.55365
Policy Entropy: 0.93076
Value Function Loss: 0.06860

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.03449
Value Function Update Magnitude: 0.05317

Collected Steps per Second: 18,607.13129
Overall Steps per Second: 14,428.10030

Timestep Collection Time: 2.68779
Timestep Consumption Time: 0.77850
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 3.46629

Cumulative Model Updates: 23,096
Cumulative Timesteps: 385,583,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 385583008...
Checkpoint 385583008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,121.13195
Policy Entropy: 0.93405
Value Function Loss: 0.06550

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04925
Policy Update Magnitude: 0.03311
Value Function Update Magnitude: 0.05049

Collected Steps per Second: 20,200.18226
Overall Steps per Second: 15,239.59560

Timestep Collection Time: 2.47641
Timestep Consumption Time: 0.80609
PPO Batch Consumption Time: 0.05180
Total Iteration Time: 3.28250

Cumulative Model Updates: 23,099
Cumulative Timesteps: 385,633,032

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,812.06419
Policy Entropy: 0.92607
Value Function Loss: 0.05654

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03587
Policy Update Magnitude: 0.03346
Value Function Update Magnitude: 0.04037

Collected Steps per Second: 19,433.72198
Overall Steps per Second: 14,729.17368

Timestep Collection Time: 2.57326
Timestep Consumption Time: 0.82191
PPO Batch Consumption Time: 0.05872
Total Iteration Time: 3.39517

Cumulative Model Updates: 23,102
Cumulative Timesteps: 385,683,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 385683040...
Checkpoint 385683040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,350.98813
Policy Entropy: 0.92040
Value Function Loss: 0.06273

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04411
Policy Update Magnitude: 0.03410
Value Function Update Magnitude: 0.03602

Collected Steps per Second: 19,309.69538
Overall Steps per Second: 14,760.38159

Timestep Collection Time: 2.58937
Timestep Consumption Time: 0.79807
PPO Batch Consumption Time: 0.05031
Total Iteration Time: 3.38745

Cumulative Model Updates: 23,105
Cumulative Timesteps: 385,733,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,057.01339
Policy Entropy: 0.92810
Value Function Loss: 0.05774

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02942
Policy Update Magnitude: 0.03271
Value Function Update Magnitude: 0.03470

Collected Steps per Second: 19,246.65881
Overall Steps per Second: 14,689.35528

Timestep Collection Time: 2.59931
Timestep Consumption Time: 0.80642
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 3.40573

Cumulative Model Updates: 23,108
Cumulative Timesteps: 385,783,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 385783068...
Checkpoint 385783068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,961.92195
Policy Entropy: 0.90739
Value Function Loss: 0.07115

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04253
Policy Update Magnitude: 0.03208
Value Function Update Magnitude: 0.03226

Collected Steps per Second: 18,631.44496
Overall Steps per Second: 14,345.51815

Timestep Collection Time: 2.68406
Timestep Consumption Time: 0.80190
PPO Batch Consumption Time: 0.06126
Total Iteration Time: 3.48597

Cumulative Model Updates: 23,111
Cumulative Timesteps: 385,833,076

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,061.79957
Policy Entropy: 0.91166
Value Function Loss: 0.07688

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03311
Policy Update Magnitude: 0.03278
Value Function Update Magnitude: 0.03517

Collected Steps per Second: 19,885.71716
Overall Steps per Second: 15,259.70340

Timestep Collection Time: 2.51537
Timestep Consumption Time: 0.76254
PPO Batch Consumption Time: 0.05304
Total Iteration Time: 3.27791

Cumulative Model Updates: 23,114
Cumulative Timesteps: 385,883,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 385883096...
Checkpoint 385883096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,423.11624
Policy Entropy: 0.91303
Value Function Loss: 0.07349

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.04121
Policy Update Magnitude: 0.03302
Value Function Update Magnitude: 0.03397

Collected Steps per Second: 19,311.42985
Overall Steps per Second: 14,716.83080

Timestep Collection Time: 2.58924
Timestep Consumption Time: 0.80836
PPO Batch Consumption Time: 0.04968
Total Iteration Time: 3.39761

Cumulative Model Updates: 23,117
Cumulative Timesteps: 385,933,098

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,913.40056
Policy Entropy: 0.91952
Value Function Loss: 0.06116

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03379
Policy Update Magnitude: 0.03208
Value Function Update Magnitude: 0.03645

Collected Steps per Second: 17,870.38185
Overall Steps per Second: 13,408.22847

Timestep Collection Time: 2.79882
Timestep Consumption Time: 0.93143
PPO Batch Consumption Time: 0.06043
Total Iteration Time: 3.73025

Cumulative Model Updates: 23,120
Cumulative Timesteps: 385,983,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 385983114...
Checkpoint 385983114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,929.19442
Policy Entropy: 0.93167
Value Function Loss: 0.05374

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.04907
Policy Update Magnitude: 0.03125
Value Function Update Magnitude: 0.04118

Collected Steps per Second: 18,648.18790
Overall Steps per Second: 13,536.28361

Timestep Collection Time: 2.68283
Timestep Consumption Time: 1.01316
PPO Batch Consumption Time: 0.09860
Total Iteration Time: 3.69599

Cumulative Model Updates: 23,123
Cumulative Timesteps: 386,033,144

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 386033144...
Checkpoint 386033144 saved!
