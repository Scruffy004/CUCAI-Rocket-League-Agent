{"x_vel":-0.017035799835087857,"_timestamp":1.7371006895922325e+09,"Policy Reward":1724.061986595165,"SB3 Clip Fraction":0.056279998389072716,"Collected Steps per Second":17154.319554871596,"Policy Update Magnitude":0.07332199811935425,"Cumulative Timesteps":27560132,"Value Function Loss":3.0820650259653726,"Cumulative Model Updates":3300,"Timesteps Collected":50012,"Overall Steps per Second":11858.398224702009,"Policy Entropy":2.188996116320292,"_step":1101,"Mean KL Divergence":0.005690382250274221,"Timestep Collection Time":2.9154172999999446,"Total Iteration Time":4.217433000000028,"y_vel":0.425432062265535,"Value Function Update Magnitude":0.04272722825407982,"Timestep Consumption Time":1.3020157000000836,"z_vel":0.004094049792179897,"PPO Batch Consumption Time":0.09590685367584229,"_wandb":{"runtime":1964},"_runtime":1964.9205491}