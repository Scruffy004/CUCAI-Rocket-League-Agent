Created new wandb run! uo0s76iu
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 667.22627
Policy Entropy: 4.49938
Value Function Loss: nan

Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.31401
Value Function Update Magnitude: 0.30744

Collected Steps per Second: 21,152.23444
Overall Steps per Second: 14,321.17329

Timestep Collection Time: 2.36514
Timestep Consumption Time: 1.12815
PPO Batch Consumption Time: 0.19074
Total Iteration Time: 3.49329

Cumulative Model Updates: 2
Cumulative Timesteps: 50,028

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 832.89521
Policy Entropy: 4.49913
Value Function Loss: 6,970.81531

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.43847
Value Function Update Magnitude: 0.53285

Collected Steps per Second: 20,884.05201
Overall Steps per Second: 13,721.63096

Timestep Collection Time: 2.39503
Timestep Consumption Time: 1.25016
PPO Batch Consumption Time: 0.11810
Total Iteration Time: 3.64519

Cumulative Model Updates: 6
Cumulative Timesteps: 100,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 100046...
Checkpoint 100046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 913.40023
Policy Entropy: 4.49737
Value Function Loss: 4,624.50260

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.00068
Policy Update Magnitude: 0.51776
Value Function Update Magnitude: 0.74022

Collected Steps per Second: 22,944.60153
Overall Steps per Second: 14,480.15975

Timestep Collection Time: 2.18056
Timestep Consumption Time: 1.27465
PPO Batch Consumption Time: 0.09120
Total Iteration Time: 3.45521

Cumulative Model Updates: 12
Cumulative Timesteps: 150,078

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.09661
Policy Entropy: 4.49114
Value Function Loss: 1.44216

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02805
Policy Update Magnitude: 0.33930
Value Function Update Magnitude: 0.31435

Collected Steps per Second: 24,213.27317
Overall Steps per Second: 14,804.95901

Timestep Collection Time: 2.06556
Timestep Consumption Time: 1.31263
PPO Batch Consumption Time: 0.09614
Total Iteration Time: 3.37819

Cumulative Model Updates: 18
Cumulative Timesteps: 200,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 200092...
Checkpoint 200092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.39893
Policy Entropy: 4.48325
Value Function Loss: 0.75669

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05838
Policy Update Magnitude: 0.18825
Value Function Update Magnitude: 0.38777

Collected Steps per Second: 22,655.05750
Overall Steps per Second: 14,561.25528

Timestep Collection Time: 2.20754
Timestep Consumption Time: 1.22705
PPO Batch Consumption Time: 0.07934
Total Iteration Time: 3.43459

Cumulative Model Updates: 24
Cumulative Timesteps: 250,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.94038
Policy Entropy: 4.47826
Value Function Loss: 0.76550

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.00813
Policy Update Magnitude: 0.11684
Value Function Update Magnitude: 0.36681

Collected Steps per Second: 21,839.41912
Overall Steps per Second: 14,293.55857

Timestep Collection Time: 2.29100
Timestep Consumption Time: 1.20946
PPO Batch Consumption Time: 0.09236
Total Iteration Time: 3.50046

Cumulative Model Updates: 30
Cumulative Timesteps: 300,138

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 300138...
Checkpoint 300138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.72408
Policy Entropy: 4.47533
Value Function Loss: 0.79064

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09066
Value Function Update Magnitude: 0.38472

Collected Steps per Second: 23,422.69602
Overall Steps per Second: 14,748.48484

Timestep Collection Time: 2.13519
Timestep Consumption Time: 1.25580
PPO Batch Consumption Time: 0.08884
Total Iteration Time: 3.39099

Cumulative Model Updates: 36
Cumulative Timesteps: 350,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 768.12903
Policy Entropy: 4.47309
Value Function Loss: 0.80749

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08825
Value Function Update Magnitude: 0.44485

Collected Steps per Second: 23,317.21031
Overall Steps per Second: 14,729.88625

Timestep Collection Time: 2.14451
Timestep Consumption Time: 1.25022
PPO Batch Consumption Time: 0.08989
Total Iteration Time: 3.39473

Cumulative Model Updates: 42
Cumulative Timesteps: 400,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 400154...
Checkpoint 400154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.19854
Policy Entropy: 4.47130
Value Function Loss: 0.78142

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09349
Value Function Update Magnitude: 0.54083

Collected Steps per Second: 23,989.28432
Overall Steps per Second: 14,771.82200

Timestep Collection Time: 2.08435
Timestep Consumption Time: 1.30061
PPO Batch Consumption Time: 0.09559
Total Iteration Time: 3.38496

Cumulative Model Updates: 48
Cumulative Timesteps: 450,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.34205
Policy Entropy: 4.46969
Value Function Loss: 0.73760

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09802
Value Function Update Magnitude: 0.53631

Collected Steps per Second: 23,578.77109
Overall Steps per Second: 14,470.74073

Timestep Collection Time: 2.12106
Timestep Consumption Time: 1.33502
PPO Batch Consumption Time: 0.09806
Total Iteration Time: 3.45608

Cumulative Model Updates: 54
Cumulative Timesteps: 500,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 500168...
Checkpoint 500168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.02767
Policy Entropy: 4.46853
Value Function Loss: 0.66244

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10239
Value Function Update Magnitude: 0.58952

Collected Steps per Second: 22,253.93190
Overall Steps per Second: 14,278.59424

Timestep Collection Time: 2.24733
Timestep Consumption Time: 1.25525
PPO Batch Consumption Time: 0.09786
Total Iteration Time: 3.50259

Cumulative Model Updates: 60
Cumulative Timesteps: 550,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 835.65626
Policy Entropy: 4.46746
Value Function Loss: 0.63544

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10643
Value Function Update Magnitude: 0.57879

Collected Steps per Second: 23,520.07055
Overall Steps per Second: 14,462.35347

Timestep Collection Time: 2.12644
Timestep Consumption Time: 1.33178
PPO Batch Consumption Time: 0.09989
Total Iteration Time: 3.45822

Cumulative Model Updates: 66
Cumulative Timesteps: 600,194

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 600194...
Checkpoint 600194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 981.25992
Policy Entropy: 4.46618
Value Function Loss: 0.67216

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11101
Value Function Update Magnitude: 0.44417

Collected Steps per Second: 23,281.93535
Overall Steps per Second: 14,721.26101

Timestep Collection Time: 2.14793
Timestep Consumption Time: 1.24906
PPO Batch Consumption Time: 0.09057
Total Iteration Time: 3.39699

Cumulative Model Updates: 72
Cumulative Timesteps: 650,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.18845
Policy Entropy: 4.46422
Value Function Loss: 0.73451

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10938
Value Function Update Magnitude: 0.37952

Collected Steps per Second: 23,228.54484
Overall Steps per Second: 14,812.36121

Timestep Collection Time: 2.15347
Timestep Consumption Time: 1.22357
PPO Batch Consumption Time: 0.09530
Total Iteration Time: 3.37704

Cumulative Model Updates: 78
Cumulative Timesteps: 700,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 700224...
Checkpoint 700224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.77793
Policy Entropy: 4.46147
Value Function Loss: 0.76706

Mean KL Divergence: 0.00074
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11172
Value Function Update Magnitude: 0.35450

Collected Steps per Second: 23,803.34732
Overall Steps per Second: 14,843.50259

Timestep Collection Time: 2.10206
Timestep Consumption Time: 1.26885
PPO Batch Consumption Time: 0.08860
Total Iteration Time: 3.37090

Cumulative Model Updates: 84
Cumulative Timesteps: 750,260

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.86861
Policy Entropy: 4.45801
Value Function Loss: 0.78078

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00032
Policy Update Magnitude: 0.12091
Value Function Update Magnitude: 0.32597

Collected Steps per Second: 23,426.71885
Overall Steps per Second: 14,733.37694

Timestep Collection Time: 2.13466
Timestep Consumption Time: 1.25954
PPO Batch Consumption Time: 0.09090
Total Iteration Time: 3.39420

Cumulative Model Updates: 90
Cumulative Timesteps: 800,268

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 800268...
Checkpoint 800268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.15210
Policy Entropy: 4.45318
Value Function Loss: 0.78214

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.00034
Policy Update Magnitude: 0.13155
Value Function Update Magnitude: 0.29274

Collected Steps per Second: 24,268.66388
Overall Steps per Second: 14,958.38330

Timestep Collection Time: 2.06184
Timestep Consumption Time: 1.28331
PPO Batch Consumption Time: 0.09340
Total Iteration Time: 3.34515

Cumulative Model Updates: 96
Cumulative Timesteps: 850,306

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.68607
Policy Entropy: 4.44549
Value Function Loss: 0.81294

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.00218
Policy Update Magnitude: 0.14459
Value Function Update Magnitude: 0.28069

Collected Steps per Second: 23,578.55493
Overall Steps per Second: 14,628.90447

Timestep Collection Time: 2.12091
Timestep Consumption Time: 1.29753
PPO Batch Consumption Time: 0.08778
Total Iteration Time: 3.41844

Cumulative Model Updates: 102
Cumulative Timesteps: 900,314

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 900314...
Checkpoint 900314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707.66413
Policy Entropy: 4.43517
Value Function Loss: 0.86072

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.00956
Policy Update Magnitude: 0.15558
Value Function Update Magnitude: 0.28365

Collected Steps per Second: 23,286.78770
Overall Steps per Second: 14,799.38900

Timestep Collection Time: 2.14766
Timestep Consumption Time: 1.23167
PPO Batch Consumption Time: 0.09546
Total Iteration Time: 3.37933

Cumulative Model Updates: 108
Cumulative Timesteps: 950,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.58242
Policy Entropy: 4.42447
Value Function Loss: 0.90252

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.14757
Value Function Update Magnitude: 0.23843

Collected Steps per Second: 22,446.71833
Overall Steps per Second: 14,053.57142

Timestep Collection Time: 2.22830
Timestep Consumption Time: 1.33080
PPO Batch Consumption Time: 0.09641
Total Iteration Time: 3.55910

Cumulative Model Updates: 114
Cumulative Timesteps: 1,000,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1000344...
Checkpoint 1000344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.88213
Policy Entropy: 4.41918
Value Function Loss: 0.92999

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.01426
Policy Update Magnitude: 0.14449
Value Function Update Magnitude: 0.18294

Collected Steps per Second: 21,541.97170
Overall Steps per Second: 13,614.55712

Timestep Collection Time: 2.32170
Timestep Consumption Time: 1.35187
PPO Batch Consumption Time: 0.10064
Total Iteration Time: 3.67357

Cumulative Model Updates: 120
Cumulative Timesteps: 1,050,358

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 851.16527
Policy Entropy: 4.41184
Value Function Loss: 0.98052

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.01251
Policy Update Magnitude: 0.15471
Value Function Update Magnitude: 0.14781

Collected Steps per Second: 22,716.80436
Overall Steps per Second: 14,061.86654

Timestep Collection Time: 2.20339
Timestep Consumption Time: 1.35617
PPO Batch Consumption Time: 0.09643
Total Iteration Time: 3.55956

Cumulative Model Updates: 126
Cumulative Timesteps: 1,100,412

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1100412...
Checkpoint 1100412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.24930
Policy Entropy: 4.39677
Value Function Loss: 1.01209

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02793
Policy Update Magnitude: 0.14717
Value Function Update Magnitude: 0.13518

Collected Steps per Second: 22,720.97665
Overall Steps per Second: 14,205.67877

Timestep Collection Time: 2.20123
Timestep Consumption Time: 1.31948
PPO Batch Consumption Time: 0.08990
Total Iteration Time: 3.52070

Cumulative Model Updates: 132
Cumulative Timesteps: 1,150,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.22996
Policy Entropy: 4.39089
Value Function Loss: 1.05321

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.01875
Policy Update Magnitude: 0.15347
Value Function Update Magnitude: 0.14183

Collected Steps per Second: 22,674.96368
Overall Steps per Second: 14,235.73219

Timestep Collection Time: 2.20516
Timestep Consumption Time: 1.30727
PPO Batch Consumption Time: 0.10378
Total Iteration Time: 3.51243

Cumulative Model Updates: 138
Cumulative Timesteps: 1,200,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1200428...
Checkpoint 1200428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.58260
Policy Entropy: 4.37487
Value Function Loss: 1.07060

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.15510
Value Function Update Magnitude: 0.13586

Collected Steps per Second: 22,512.33824
Overall Steps per Second: 14,133.40818

Timestep Collection Time: 2.22189
Timestep Consumption Time: 1.31724
PPO Batch Consumption Time: 0.09579
Total Iteration Time: 3.53913

Cumulative Model Updates: 144
Cumulative Timesteps: 1,250,448

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.04120
Policy Entropy: 4.36087
Value Function Loss: 1.10256

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.15339
Value Function Update Magnitude: 0.12167

Collected Steps per Second: 21,944.34915
Overall Steps per Second: 13,488.51523

Timestep Collection Time: 2.28031
Timestep Consumption Time: 1.42951
PPO Batch Consumption Time: 0.11217
Total Iteration Time: 3.70982

Cumulative Model Updates: 150
Cumulative Timesteps: 1,300,488

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1300488...
Checkpoint 1300488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.48979
Policy Entropy: 4.34032
Value Function Loss: 1.13665

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.03493
Policy Update Magnitude: 0.14528
Value Function Update Magnitude: 0.11950

Collected Steps per Second: 22,697.25578
Overall Steps per Second: 14,194.37551

Timestep Collection Time: 2.20300
Timestep Consumption Time: 1.31967
PPO Batch Consumption Time: 0.09180
Total Iteration Time: 3.52266

Cumulative Model Updates: 156
Cumulative Timesteps: 1,350,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.50360
Policy Entropy: 4.33850
Value Function Loss: 1.13212

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02001
Policy Update Magnitude: 0.14225
Value Function Update Magnitude: 0.12230

Collected Steps per Second: 20,688.64116
Overall Steps per Second: 13,820.00947

Timestep Collection Time: 2.41717
Timestep Consumption Time: 1.20135
PPO Batch Consumption Time: 0.07717
Total Iteration Time: 3.61852

Cumulative Model Updates: 162
Cumulative Timesteps: 1,400,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1400498...
Checkpoint 1400498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.78306
Policy Entropy: 4.30980
Value Function Loss: 1.12875

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04012
Policy Update Magnitude: 0.13489
Value Function Update Magnitude: 0.11797

Collected Steps per Second: 22,754.42217
Overall Steps per Second: 14,186.98479

Timestep Collection Time: 2.19861
Timestep Consumption Time: 1.32773
PPO Batch Consumption Time: 0.09945
Total Iteration Time: 3.52633

Cumulative Model Updates: 168
Cumulative Timesteps: 1,450,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.99631
Policy Entropy: 4.30787
Value Function Loss: 1.12845

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01499
Policy Update Magnitude: 0.15031
Value Function Update Magnitude: 0.11437

Collected Steps per Second: 21,901.23512
Overall Steps per Second: 13,972.11884

Timestep Collection Time: 2.28362
Timestep Consumption Time: 1.29594
PPO Batch Consumption Time: 0.09314
Total Iteration Time: 3.57956

Cumulative Model Updates: 174
Cumulative Timesteps: 1,500,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1500540...
Checkpoint 1500540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.97961
Policy Entropy: 4.27108
Value Function Loss: 1.13214

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.05830
Policy Update Magnitude: 0.14665
Value Function Update Magnitude: 0.11533

Collected Steps per Second: 18,801.13219
Overall Steps per Second: 12,471.25942

Timestep Collection Time: 2.66037
Timestep Consumption Time: 1.35029
PPO Batch Consumption Time: 0.10002
Total Iteration Time: 4.01066

Cumulative Model Updates: 180
Cumulative Timesteps: 1,550,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.86380
Policy Entropy: 4.27233
Value Function Loss: 1.17645

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02370
Policy Update Magnitude: 0.14177
Value Function Update Magnitude: 0.12055

Collected Steps per Second: 23,106.83834
Overall Steps per Second: 14,170.32782

Timestep Collection Time: 2.16499
Timestep Consumption Time: 1.36535
PPO Batch Consumption Time: 0.10093
Total Iteration Time: 3.53033

Cumulative Model Updates: 186
Cumulative Timesteps: 1,600,584

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1600584...
Checkpoint 1600584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.32386
Policy Entropy: 4.23730
Value Function Loss: 1.19712

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.04978
Policy Update Magnitude: 0.13892
Value Function Update Magnitude: 0.12864

Collected Steps per Second: 22,682.18980
Overall Steps per Second: 13,976.08696

Timestep Collection Time: 2.20578
Timestep Consumption Time: 1.37405
PPO Batch Consumption Time: 0.10118
Total Iteration Time: 3.57983

Cumulative Model Updates: 192
Cumulative Timesteps: 1,650,616

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,484.15344
Policy Entropy: 4.23909
Value Function Loss: 1.26627

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02428
Policy Update Magnitude: 0.13774
Value Function Update Magnitude: 0.13196

Collected Steps per Second: 21,368.20412
Overall Steps per Second: 13,879.39801

Timestep Collection Time: 2.34095
Timestep Consumption Time: 1.26309
PPO Batch Consumption Time: 0.09622
Total Iteration Time: 3.60405

Cumulative Model Updates: 198
Cumulative Timesteps: 1,700,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1700638...
Checkpoint 1700638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.34301
Policy Entropy: 4.20825
Value Function Loss: 1.26845

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.03725
Policy Update Magnitude: 0.16287
Value Function Update Magnitude: 0.13901

Collected Steps per Second: 21,794.10878
Overall Steps per Second: 13,799.65595

Timestep Collection Time: 2.29438
Timestep Consumption Time: 1.32919
PPO Batch Consumption Time: 0.09748
Total Iteration Time: 3.62357

Cumulative Model Updates: 204
Cumulative Timesteps: 1,750,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.40792
Policy Entropy: 4.18560
Value Function Loss: 1.29242

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.05287
Policy Update Magnitude: 0.14674
Value Function Update Magnitude: 0.16110

Collected Steps per Second: 22,504.42716
Overall Steps per Second: 14,155.06015

Timestep Collection Time: 2.22321
Timestep Consumption Time: 1.31136
PPO Batch Consumption Time: 0.09258
Total Iteration Time: 3.53457

Cumulative Model Updates: 210
Cumulative Timesteps: 1,800,674

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1800674...
Checkpoint 1800674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.30498
Policy Entropy: 4.18249
Value Function Loss: 1.26111

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.03360
Policy Update Magnitude: 0.13856
Value Function Update Magnitude: 0.16304

Collected Steps per Second: 19,736.23080
Overall Steps per Second: 12,578.34991

Timestep Collection Time: 2.53341
Timestep Consumption Time: 1.44167
PPO Batch Consumption Time: 0.09480
Total Iteration Time: 3.97508

Cumulative Model Updates: 216
Cumulative Timesteps: 1,850,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.74035
Policy Entropy: 4.14545
Value Function Loss: 1.29291

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.03861
Policy Update Magnitude: 0.15181
Value Function Update Magnitude: 0.15545

Collected Steps per Second: 20,798.93546
Overall Steps per Second: 12,830.59024

Timestep Collection Time: 2.40464
Timestep Consumption Time: 1.49339
PPO Batch Consumption Time: 0.10678
Total Iteration Time: 3.89803

Cumulative Model Updates: 222
Cumulative Timesteps: 1,900,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1900688...
Checkpoint 1900688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.97259
Policy Entropy: 4.15300
Value Function Loss: 1.28987

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.03482
Policy Update Magnitude: 0.14928
Value Function Update Magnitude: 0.15156

Collected Steps per Second: 20,471.21600
Overall Steps per Second: 13,218.19551

Timestep Collection Time: 2.44421
Timestep Consumption Time: 1.34118
PPO Batch Consumption Time: 0.10320
Total Iteration Time: 3.78539

Cumulative Model Updates: 228
Cumulative Timesteps: 1,950,724

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.11599
Policy Entropy: 4.13577
Value Function Loss: 1.31041

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04386
Policy Update Magnitude: 0.15492
Value Function Update Magnitude: 0.15286

Collected Steps per Second: 20,670.06906
Overall Steps per Second: 13,065.47815

Timestep Collection Time: 2.42012
Timestep Consumption Time: 1.40860
PPO Batch Consumption Time: 0.10366
Total Iteration Time: 3.82872

Cumulative Model Updates: 234
Cumulative Timesteps: 2,000,748

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2000748...
Checkpoint 2000748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.31620
Policy Entropy: 4.11329
Value Function Loss: 1.28727

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02641
Policy Update Magnitude: 0.15053
Value Function Update Magnitude: 0.16881

Collected Steps per Second: 21,354.84079
Overall Steps per Second: 13,269.95285

Timestep Collection Time: 2.34139
Timestep Consumption Time: 1.42652
PPO Batch Consumption Time: 0.10030
Total Iteration Time: 3.76791

Cumulative Model Updates: 240
Cumulative Timesteps: 2,050,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.95058
Policy Entropy: 4.11178
Value Function Loss: 1.26536

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.15186
Value Function Update Magnitude: 0.17099

Collected Steps per Second: 22,171.74091
Overall Steps per Second: 13,956.52848

Timestep Collection Time: 2.25566
Timestep Consumption Time: 1.32775
PPO Batch Consumption Time: 0.09162
Total Iteration Time: 3.58341

Cumulative Model Updates: 246
Cumulative Timesteps: 2,100,760

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2100760...
Checkpoint 2100760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,555.22017
Policy Entropy: 4.07744
Value Function Loss: 1.24162

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05491
Policy Update Magnitude: 0.14142
Value Function Update Magnitude: 0.16402

Collected Steps per Second: 20,557.26480
Overall Steps per Second: 12,966.13711

Timestep Collection Time: 2.43301
Timestep Consumption Time: 1.42442
PPO Batch Consumption Time: 0.10233
Total Iteration Time: 3.85743

Cumulative Model Updates: 252
Cumulative Timesteps: 2,150,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.25554
Policy Entropy: 4.08771
Value Function Loss: 1.22830

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.01996
Policy Update Magnitude: 0.14644
Value Function Update Magnitude: 0.17219

Collected Steps per Second: 23,096.36911
Overall Steps per Second: 14,584.25058

Timestep Collection Time: 2.16536
Timestep Consumption Time: 1.26382
PPO Batch Consumption Time: 0.10061
Total Iteration Time: 3.42918

Cumulative Model Updates: 258
Cumulative Timesteps: 2,200,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2200788...
Checkpoint 2200788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465.81247
Policy Entropy: 4.05021
Value Function Loss: 1.21996

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.03315
Policy Update Magnitude: 0.15024
Value Function Update Magnitude: 0.17724

Collected Steps per Second: 23,442.85034
Overall Steps per Second: 14,513.49619

Timestep Collection Time: 2.13319
Timestep Consumption Time: 1.31243
PPO Batch Consumption Time: 0.09349
Total Iteration Time: 3.44562

Cumulative Model Updates: 264
Cumulative Timesteps: 2,250,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.16295
Policy Entropy: 4.06104
Value Function Loss: 1.17263

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03387
Policy Update Magnitude: 0.15036
Value Function Update Magnitude: 0.16890

Collected Steps per Second: 22,414.34647
Overall Steps per Second: 14,761.61671

Timestep Collection Time: 2.23116
Timestep Consumption Time: 1.15668
PPO Batch Consumption Time: 0.07437
Total Iteration Time: 3.38784

Cumulative Model Updates: 270
Cumulative Timesteps: 2,300,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2300806...
Checkpoint 2300806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.13230
Policy Entropy: 4.01852
Value Function Loss: 1.12718

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.03975
Policy Update Magnitude: 0.13669
Value Function Update Magnitude: 0.16760

Collected Steps per Second: 22,389.58769
Overall Steps per Second: 14,151.26790

Timestep Collection Time: 2.23345
Timestep Consumption Time: 1.30023
PPO Batch Consumption Time: 0.09696
Total Iteration Time: 3.53368

Cumulative Model Updates: 276
Cumulative Timesteps: 2,350,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.92262
Policy Entropy: 4.01915
Value Function Loss: 1.09913

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.03237
Policy Update Magnitude: 0.13929
Value Function Update Magnitude: 0.17670

Collected Steps per Second: 22,040.71232
Overall Steps per Second: 13,927.59483

Timestep Collection Time: 2.26980
Timestep Consumption Time: 1.32221
PPO Batch Consumption Time: 0.09548
Total Iteration Time: 3.59201

Cumulative Model Updates: 282
Cumulative Timesteps: 2,400,840

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2400840...
Checkpoint 2400840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.08773
Policy Entropy: 3.98767
Value Function Loss: 1.08959

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.03947
Policy Update Magnitude: 0.13585
Value Function Update Magnitude: 0.21353

Collected Steps per Second: 24,379.29738
Overall Steps per Second: 14,839.84975

Timestep Collection Time: 2.05166
Timestep Consumption Time: 1.31886
PPO Batch Consumption Time: 0.09960
Total Iteration Time: 3.37052

Cumulative Model Updates: 288
Cumulative Timesteps: 2,450,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477.54562
Policy Entropy: 3.97460
Value Function Loss: 1.06280

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.03545
Policy Update Magnitude: 0.13983
Value Function Update Magnitude: 0.20049

Collected Steps per Second: 22,888.06383
Overall Steps per Second: 14,633.06731

Timestep Collection Time: 2.18533
Timestep Consumption Time: 1.23282
PPO Batch Consumption Time: 0.07474
Total Iteration Time: 3.41815

Cumulative Model Updates: 294
Cumulative Timesteps: 2,500,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2500876...
Checkpoint 2500876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.37440
Policy Entropy: 3.97104
Value Function Loss: 0.99987

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02635
Policy Update Magnitude: 0.13062
Value Function Update Magnitude: 0.16516

Collected Steps per Second: 22,817.86545
Overall Steps per Second: 13,911.38285

Timestep Collection Time: 2.19258
Timestep Consumption Time: 1.40376
PPO Batch Consumption Time: 0.09760
Total Iteration Time: 3.59634

Cumulative Model Updates: 300
Cumulative Timesteps: 2,550,906

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.67266
Policy Entropy: 3.94417
Value Function Loss: 0.97566

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.03378
Policy Update Magnitude: 0.13474
Value Function Update Magnitude: 0.14657

Collected Steps per Second: 20,291.62227
Overall Steps per Second: 13,472.41391

Timestep Collection Time: 2.46407
Timestep Consumption Time: 1.24722
PPO Batch Consumption Time: 0.08739
Total Iteration Time: 3.71129

Cumulative Model Updates: 306
Cumulative Timesteps: 2,600,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2600906...
Checkpoint 2600906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.42204
Policy Entropy: 3.93320
Value Function Loss: 0.96271

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.04429
Policy Update Magnitude: 0.13741
Value Function Update Magnitude: 0.14341

Collected Steps per Second: 21,371.78563
Overall Steps per Second: 13,299.85230

Timestep Collection Time: 2.34056
Timestep Consumption Time: 1.42053
PPO Batch Consumption Time: 0.10411
Total Iteration Time: 3.76109

Cumulative Model Updates: 312
Cumulative Timesteps: 2,650,928

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432.45291
Policy Entropy: 3.90003
Value Function Loss: 0.97640

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02793
Policy Update Magnitude: 0.12985
Value Function Update Magnitude: 0.14927

Collected Steps per Second: 20,917.85210
Overall Steps per Second: 13,873.10145

Timestep Collection Time: 2.39126
Timestep Consumption Time: 1.21428
PPO Batch Consumption Time: 0.07364
Total Iteration Time: 3.60554

Cumulative Model Updates: 318
Cumulative Timesteps: 2,700,948

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2700948...
Checkpoint 2700948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.97585
Policy Entropy: 3.89406
Value Function Loss: 0.96244

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.03845
Policy Update Magnitude: 0.12835
Value Function Update Magnitude: 0.15495

Collected Steps per Second: 23,654.29818
Overall Steps per Second: 14,433.38779

Timestep Collection Time: 2.11420
Timestep Consumption Time: 1.35068
PPO Batch Consumption Time: 0.09882
Total Iteration Time: 3.46488

Cumulative Model Updates: 324
Cumulative Timesteps: 2,750,958

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.03102
Policy Entropy: 3.86613
Value Function Loss: 0.92004

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05148
Policy Update Magnitude: 0.12422
Value Function Update Magnitude: 0.17244

Collected Steps per Second: 23,823.13390
Overall Steps per Second: 14,395.69975

Timestep Collection Time: 2.09981
Timestep Consumption Time: 1.37512
PPO Batch Consumption Time: 0.10043
Total Iteration Time: 3.47493

Cumulative Model Updates: 330
Cumulative Timesteps: 2,800,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2800982...
Checkpoint 2800982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.34754
Policy Entropy: 3.85825
Value Function Loss: 0.88316

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03027
Policy Update Magnitude: 0.13672
Value Function Update Magnitude: 0.16951

Collected Steps per Second: 21,979.01116
Overall Steps per Second: 14,001.05774

Timestep Collection Time: 2.27517
Timestep Consumption Time: 1.29642
PPO Batch Consumption Time: 0.10251
Total Iteration Time: 3.57159

Cumulative Model Updates: 336
Cumulative Timesteps: 2,850,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.38267
Policy Entropy: 3.83119
Value Function Loss: 0.84417

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.03907
Policy Update Magnitude: 0.13500
Value Function Update Magnitude: 0.14941

Collected Steps per Second: 23,025.78582
Overall Steps per Second: 14,028.96571

Timestep Collection Time: 2.17243
Timestep Consumption Time: 1.39319
PPO Batch Consumption Time: 0.10370
Total Iteration Time: 3.56562

Cumulative Model Updates: 342
Cumulative Timesteps: 2,901,010

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2901010...
Checkpoint 2901010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.15957
Policy Entropy: 3.81736
Value Function Loss: 0.84476

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.04094
Policy Update Magnitude: 0.12800
Value Function Update Magnitude: 0.13345

Collected Steps per Second: 21,220.63081
Overall Steps per Second: 13,699.04613

Timestep Collection Time: 2.35752
Timestep Consumption Time: 1.29442
PPO Batch Consumption Time: 0.09372
Total Iteration Time: 3.65193

Cumulative Model Updates: 348
Cumulative Timesteps: 2,951,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.98982
Policy Entropy: 3.78473
Value Function Loss: 0.85646

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03348
Policy Update Magnitude: 0.13575
Value Function Update Magnitude: 0.12428

Collected Steps per Second: 20,898.20418
Overall Steps per Second: 13,279.01213

Timestep Collection Time: 2.39370
Timestep Consumption Time: 1.37345
PPO Batch Consumption Time: 0.10040
Total Iteration Time: 3.76715

Cumulative Model Updates: 354
Cumulative Timesteps: 3,001,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3001062...
Checkpoint 3001062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.37853
Policy Entropy: 3.75626
Value Function Loss: 0.85784

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.03873
Policy Update Magnitude: 0.14398
Value Function Update Magnitude: 0.11908

Collected Steps per Second: 21,077.92232
Overall Steps per Second: 13,185.25371

Timestep Collection Time: 2.37291
Timestep Consumption Time: 1.42042
PPO Batch Consumption Time: 0.10877
Total Iteration Time: 3.79333

Cumulative Model Updates: 360
Cumulative Timesteps: 3,051,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552.98209
Policy Entropy: 3.73373
Value Function Loss: 0.87383

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.03144
Policy Update Magnitude: 0.13476
Value Function Update Magnitude: 0.11688

Collected Steps per Second: 23,659.66449
Overall Steps per Second: 14,873.86240

Timestep Collection Time: 2.11406
Timestep Consumption Time: 1.24875
PPO Batch Consumption Time: 0.09214
Total Iteration Time: 3.36281

Cumulative Model Updates: 366
Cumulative Timesteps: 3,101,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3101096...
Checkpoint 3101096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.75889
Policy Entropy: 3.71945
Value Function Loss: 0.88349

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.03984
Policy Update Magnitude: 0.13267
Value Function Update Magnitude: 0.11651

Collected Steps per Second: 20,791.29812
Overall Steps per Second: 13,507.16718

Timestep Collection Time: 2.40562
Timestep Consumption Time: 1.29730
PPO Batch Consumption Time: 0.07330
Total Iteration Time: 3.70292

Cumulative Model Updates: 372
Cumulative Timesteps: 3,151,112

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.30519
Policy Entropy: 3.69638
Value Function Loss: 0.89975

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.03097
Policy Update Magnitude: 0.14384
Value Function Update Magnitude: 0.11526

Collected Steps per Second: 19,402.01864
Overall Steps per Second: 12,434.44556

Timestep Collection Time: 2.57726
Timestep Consumption Time: 1.44415
PPO Batch Consumption Time: 0.09875
Total Iteration Time: 4.02141

Cumulative Model Updates: 378
Cumulative Timesteps: 3,201,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3201116...
Checkpoint 3201116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.82344
Policy Entropy: 3.67705
Value Function Loss: 0.97280

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03090
Policy Update Magnitude: 0.15041
Value Function Update Magnitude: 0.11689

Collected Steps per Second: 22,532.38090
Overall Steps per Second: 14,078.75163

Timestep Collection Time: 2.22018
Timestep Consumption Time: 1.33312
PPO Batch Consumption Time: 0.09452
Total Iteration Time: 3.55330

Cumulative Model Updates: 384
Cumulative Timesteps: 3,251,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.47936
Policy Entropy: 3.65957
Value Function Loss: 1.05842

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.04635
Policy Update Magnitude: 0.14928
Value Function Update Magnitude: 0.12363

Collected Steps per Second: 21,896.46453
Overall Steps per Second: 13,512.35489

Timestep Collection Time: 2.28521
Timestep Consumption Time: 1.41792
PPO Batch Consumption Time: 0.10698
Total Iteration Time: 3.70313

Cumulative Model Updates: 390
Cumulative Timesteps: 3,301,180

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 3301180...
Checkpoint 3301180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.26080
Policy Entropy: 3.61950
Value Function Loss: 1.12008

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05234
Policy Update Magnitude: 0.13680
Value Function Update Magnitude: 0.12446

Collected Steps per Second: 21,797.52723
Overall Steps per Second: 14,098.42230

Timestep Collection Time: 2.29457
Timestep Consumption Time: 1.25306
PPO Batch Consumption Time: 0.08629
Total Iteration Time: 3.54763

Cumulative Model Updates: 396
Cumulative Timesteps: 3,351,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530.98220
Policy Entropy: 3.60128
Value Function Loss: 1.14313

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.04808
Policy Update Magnitude: 0.12957
Value Function Update Magnitude: 0.12256

Collected Steps per Second: 22,297.29209
Overall Steps per Second: 13,843.69784

Timestep Collection Time: 2.24440
Timestep Consumption Time: 1.37053
PPO Batch Consumption Time: 0.09947
Total Iteration Time: 3.61493

Cumulative Model Updates: 402
Cumulative Timesteps: 3,401,240

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 3401240...
Checkpoint 3401240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,519.91472
Policy Entropy: 3.55496
Value Function Loss: 1.10862

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.04951
Policy Update Magnitude: 0.13684
Value Function Update Magnitude: 0.11347

Collected Steps per Second: 22,425.75772
Overall Steps per Second: 13,926.03604

Timestep Collection Time: 2.23047
Timestep Consumption Time: 1.36136
PPO Batch Consumption Time: 0.10399
Total Iteration Time: 3.59183

Cumulative Model Updates: 408
Cumulative Timesteps: 3,451,260

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.47005
Policy Entropy: 3.55214
Value Function Loss: 1.10751

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04175
Policy Update Magnitude: 0.13913
Value Function Update Magnitude: 0.11087

Collected Steps per Second: 23,168.50262
Overall Steps per Second: 13,945.29814

Timestep Collection Time: 2.15828
Timestep Consumption Time: 1.42745
PPO Batch Consumption Time: 0.10361
Total Iteration Time: 3.58572

Cumulative Model Updates: 414
Cumulative Timesteps: 3,501,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3501264...
Checkpoint 3501264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,521.51901
Policy Entropy: 3.52617
Value Function Loss: 1.11022

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.03168
Policy Update Magnitude: 0.13537
Value Function Update Magnitude: 0.11165

Collected Steps per Second: 22,358.51307
Overall Steps per Second: 13,764.23951

Timestep Collection Time: 2.23825
Timestep Consumption Time: 1.39755
PPO Batch Consumption Time: 0.09904
Total Iteration Time: 3.63580

Cumulative Model Updates: 420
Cumulative Timesteps: 3,551,308

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.02856
Policy Entropy: 3.51043
Value Function Loss: 1.13372

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.03363
Policy Update Magnitude: 0.13970
Value Function Update Magnitude: 0.10520

Collected Steps per Second: 22,527.94272
Overall Steps per Second: 14,083.13130

Timestep Collection Time: 2.22018
Timestep Consumption Time: 1.33131
PPO Batch Consumption Time: 0.10325
Total Iteration Time: 3.55148

Cumulative Model Updates: 426
Cumulative Timesteps: 3,601,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3601324...
Checkpoint 3601324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.84263
Policy Entropy: 3.49510
Value Function Loss: 1.16031

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.04685
Policy Update Magnitude: 0.13913
Value Function Update Magnitude: 0.10393

Collected Steps per Second: 22,963.70146
Overall Steps per Second: 13,911.59270

Timestep Collection Time: 2.17778
Timestep Consumption Time: 1.41706
PPO Batch Consumption Time: 0.09898
Total Iteration Time: 3.59484

Cumulative Model Updates: 432
Cumulative Timesteps: 3,651,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,555.13972
Policy Entropy: 3.47441
Value Function Loss: 1.16158

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.03740
Policy Update Magnitude: 0.13918
Value Function Update Magnitude: 0.10359

Collected Steps per Second: 22,139.07441
Overall Steps per Second: 13,904.85453

Timestep Collection Time: 2.25908
Timestep Consumption Time: 1.33779
PPO Batch Consumption Time: 0.09383
Total Iteration Time: 3.59687

Cumulative Model Updates: 438
Cumulative Timesteps: 3,701,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3701348...
Checkpoint 3701348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493.13418
Policy Entropy: 3.44940
Value Function Loss: 1.19316

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.03802
Policy Update Magnitude: 0.13807
Value Function Update Magnitude: 0.09074

Collected Steps per Second: 21,465.06327
Overall Steps per Second: 13,380.23608

Timestep Collection Time: 2.33132
Timestep Consumption Time: 1.40867
PPO Batch Consumption Time: 0.10367
Total Iteration Time: 3.73999

Cumulative Model Updates: 444
Cumulative Timesteps: 3,751,390

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.40297
Policy Entropy: 3.43096
Value Function Loss: 1.22404

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.13075
Value Function Update Magnitude: 0.09701

Collected Steps per Second: 22,776.30750
Overall Steps per Second: 13,846.66252

Timestep Collection Time: 2.19649
Timestep Consumption Time: 1.41651
PPO Batch Consumption Time: 0.09738
Total Iteration Time: 3.61300

Cumulative Model Updates: 450
Cumulative Timesteps: 3,801,418

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3801418...
Checkpoint 3801418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.12853
Policy Entropy: 3.41825
Value Function Loss: 1.29301

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.04530
Policy Update Magnitude: 0.14051
Value Function Update Magnitude: 0.12500

Collected Steps per Second: 22,329.49580
Overall Steps per Second: 14,068.71219

Timestep Collection Time: 2.23955
Timestep Consumption Time: 1.31501
PPO Batch Consumption Time: 0.09955
Total Iteration Time: 3.55455

Cumulative Model Updates: 456
Cumulative Timesteps: 3,851,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.85831
Policy Entropy: 3.41828
Value Function Loss: 1.24716

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06340
Policy Update Magnitude: 0.13144
Value Function Update Magnitude: 0.18588

Collected Steps per Second: 22,584.40386
Overall Steps per Second: 13,998.57099

Timestep Collection Time: 2.21533
Timestep Consumption Time: 1.35874
PPO Batch Consumption Time: 0.09927
Total Iteration Time: 3.57408

Cumulative Model Updates: 462
Cumulative Timesteps: 3,901,458

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3901458...
Checkpoint 3901458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.38824
Policy Entropy: 3.39325
Value Function Loss: 1.32490

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.04977
Policy Update Magnitude: 0.13193
Value Function Update Magnitude: 0.24037

Collected Steps per Second: 23,491.12884
Overall Steps per Second: 14,395.67184

Timestep Collection Time: 2.12966
Timestep Consumption Time: 1.34556
PPO Batch Consumption Time: 0.10021
Total Iteration Time: 3.47521

Cumulative Model Updates: 468
Cumulative Timesteps: 3,951,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596.78257
Policy Entropy: 3.38924
Value Function Loss: 1.39414

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.07179
Policy Update Magnitude: 0.13226
Value Function Update Magnitude: 0.17714

Collected Steps per Second: 23,216.06870
Overall Steps per Second: 14,448.49440

Timestep Collection Time: 2.15489
Timestep Consumption Time: 1.30762
PPO Batch Consumption Time: 0.10511
Total Iteration Time: 3.46251

Cumulative Model Updates: 474
Cumulative Timesteps: 4,001,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 4001514...
Checkpoint 4001514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571.92700
Policy Entropy: 3.37080
Value Function Loss: 1.51645

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.06715
Policy Update Magnitude: 0.12797
Value Function Update Magnitude: 0.14904

Collected Steps per Second: 22,283.76126
Overall Steps per Second: 13,927.53473

Timestep Collection Time: 2.24504
Timestep Consumption Time: 1.34698
PPO Batch Consumption Time: 0.09680
Total Iteration Time: 3.59202

Cumulative Model Updates: 480
Cumulative Timesteps: 4,051,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615.67385
Policy Entropy: 3.37004
Value Function Loss: 1.45042

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.06990
Policy Update Magnitude: 0.12977
Value Function Update Magnitude: 0.23138

Collected Steps per Second: 23,102.29087
Overall Steps per Second: 14,129.51870

Timestep Collection Time: 2.16437
Timestep Consumption Time: 1.37446
PPO Batch Consumption Time: 0.10244
Total Iteration Time: 3.53883

Cumulative Model Updates: 486
Cumulative Timesteps: 4,101,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 4101544...
Checkpoint 4101544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.91890
Policy Entropy: 3.34916
Value Function Loss: 1.46295

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06493
Policy Update Magnitude: 0.11236
Value Function Update Magnitude: 0.16801

Collected Steps per Second: 24,009.86089
Overall Steps per Second: 14,521.93266

Timestep Collection Time: 2.08289
Timestep Consumption Time: 1.36086
PPO Batch Consumption Time: 0.09640
Total Iteration Time: 3.44376

Cumulative Model Updates: 492
Cumulative Timesteps: 4,151,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468.16138
Policy Entropy: 3.33071
Value Function Loss: 1.62450

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.04697
Policy Update Magnitude: 0.11372
Value Function Update Magnitude: 0.13890

Collected Steps per Second: 21,197.98894
Overall Steps per Second: 13,331.40210

Timestep Collection Time: 2.35985
Timestep Consumption Time: 1.39250
PPO Batch Consumption Time: 0.10352
Total Iteration Time: 3.75234

Cumulative Model Updates: 498
Cumulative Timesteps: 4,201,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 4201578...
Checkpoint 4201578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.10690
Policy Entropy: 3.30266
Value Function Loss: 1.67464

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.05234
Policy Update Magnitude: 0.11741
Value Function Update Magnitude: 0.11101

Collected Steps per Second: 19,465.31124
Overall Steps per Second: 13,155.18488

Timestep Collection Time: 2.57042
Timestep Consumption Time: 1.23295
PPO Batch Consumption Time: 0.09270
Total Iteration Time: 3.80337

Cumulative Model Updates: 504
Cumulative Timesteps: 4,251,612

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.24850
Policy Entropy: 3.28607
Value Function Loss: 1.76589

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.04408
Policy Update Magnitude: 0.11600
Value Function Update Magnitude: 0.14615

Collected Steps per Second: 23,443.28870
Overall Steps per Second: 14,200.22983

Timestep Collection Time: 2.13306
Timestep Consumption Time: 1.38843
PPO Batch Consumption Time: 0.10548
Total Iteration Time: 3.52149

Cumulative Model Updates: 510
Cumulative Timesteps: 4,301,618

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 4301618...
Checkpoint 4301618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.38330
Policy Entropy: 3.29003
Value Function Loss: 1.72885

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06212
Policy Update Magnitude: 0.11172
Value Function Update Magnitude: 0.16216

Collected Steps per Second: 21,873.54554
Overall Steps per Second: 13,851.81908

Timestep Collection Time: 2.28779
Timestep Consumption Time: 1.32488
PPO Batch Consumption Time: 0.09836
Total Iteration Time: 3.61267

Cumulative Model Updates: 516
Cumulative Timesteps: 4,351,660

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.94876
Policy Entropy: 3.27625
Value Function Loss: 2.06463

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.04297
Policy Update Magnitude: 0.10599
Value Function Update Magnitude: 0.11866

Collected Steps per Second: 24,166.38835
Overall Steps per Second: 14,653.07436

Timestep Collection Time: 2.06990
Timestep Consumption Time: 1.34385
PPO Batch Consumption Time: 0.09767
Total Iteration Time: 3.41375

Cumulative Model Updates: 522
Cumulative Timesteps: 4,401,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 4401682...
Checkpoint 4401682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.23672
Policy Entropy: 3.25686
Value Function Loss: 2.11494

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06853
Policy Update Magnitude: 0.10489
Value Function Update Magnitude: 0.08181

Collected Steps per Second: 21,783.31142
Overall Steps per Second: 13,586.13721

Timestep Collection Time: 2.29717
Timestep Consumption Time: 1.38599
PPO Batch Consumption Time: 0.10241
Total Iteration Time: 3.68317

Cumulative Model Updates: 528
Cumulative Timesteps: 4,451,722

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645.40873
Policy Entropy: 3.25058
Value Function Loss: 2.31939

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.04172
Policy Update Magnitude: 0.09826
Value Function Update Magnitude: 0.06525

Collected Steps per Second: 22,910.57595
Overall Steps per Second: 14,389.26303

Timestep Collection Time: 2.18266
Timestep Consumption Time: 1.29257
PPO Batch Consumption Time: 0.09666
Total Iteration Time: 3.47523

Cumulative Model Updates: 534
Cumulative Timesteps: 4,501,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 4501728...
Checkpoint 4501728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,588.06140
Policy Entropy: 3.23687
Value Function Loss: 1.82692

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06161
Policy Update Magnitude: 0.10313
Value Function Update Magnitude: 0.08444

Collected Steps per Second: 22,677.00123
Overall Steps per Second: 14,012.98652

Timestep Collection Time: 2.20611
Timestep Consumption Time: 1.36401
PPO Batch Consumption Time: 0.09794
Total Iteration Time: 3.57012

Cumulative Model Updates: 540
Cumulative Timesteps: 4,551,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764.59993
Policy Entropy: 3.23767
Value Function Loss: 2.16652

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.03667
Policy Update Magnitude: 0.09943
Value Function Update Magnitude: 0.07934

Collected Steps per Second: 22,331.90113
Overall Steps per Second: 13,979.85845

Timestep Collection Time: 2.24119
Timestep Consumption Time: 1.33896
PPO Batch Consumption Time: 0.09804
Total Iteration Time: 3.58015

Cumulative Model Updates: 546
Cumulative Timesteps: 4,601,806

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 4601806...
Checkpoint 4601806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.27209
Policy Entropy: 3.24064
Value Function Loss: 2.57778

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.03900
Policy Update Magnitude: 0.10612
Value Function Update Magnitude: 0.05049

Collected Steps per Second: 23,103.96502
Overall Steps per Second: 14,133.88806

Timestep Collection Time: 2.16413
Timestep Consumption Time: 1.37347
PPO Batch Consumption Time: 0.10095
Total Iteration Time: 3.53760

Cumulative Model Updates: 552
Cumulative Timesteps: 4,651,806

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.68375
Policy Entropy: 3.23044
Value Function Loss: 2.09654

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02856
Policy Update Magnitude: 0.09926
Value Function Update Magnitude: 0.05892

Collected Steps per Second: 23,038.98682
Overall Steps per Second: 13,988.50216

Timestep Collection Time: 2.17093
Timestep Consumption Time: 1.40458
PPO Batch Consumption Time: 0.10455
Total Iteration Time: 3.57551

Cumulative Model Updates: 558
Cumulative Timesteps: 4,701,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 4701822...
Checkpoint 4701822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.22679
Policy Entropy: 3.22094
Value Function Loss: 2.08487

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.05742
Policy Update Magnitude: 0.09693
Value Function Update Magnitude: 0.09724

Collected Steps per Second: 22,395.19614
Overall Steps per Second: 14,090.71450

Timestep Collection Time: 2.23334
Timestep Consumption Time: 1.31624
PPO Batch Consumption Time: 0.10604
Total Iteration Time: 3.54957

Cumulative Model Updates: 564
Cumulative Timesteps: 4,751,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755.09646
Policy Entropy: 3.20432
Value Function Loss: 2.12286

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.04148
Policy Update Magnitude: 0.10089
Value Function Update Magnitude: 0.13035

Collected Steps per Second: 22,246.19298
Overall Steps per Second: 13,795.31760

Timestep Collection Time: 2.24829
Timestep Consumption Time: 1.37728
PPO Batch Consumption Time: 0.09779
Total Iteration Time: 3.62558

Cumulative Model Updates: 570
Cumulative Timesteps: 4,801,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 4801854...
Checkpoint 4801854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,752.48180
Policy Entropy: 3.21358
Value Function Loss: 2.19293

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05832
Policy Update Magnitude: 0.09619
Value Function Update Magnitude: 0.08569

Collected Steps per Second: 22,162.87761
Overall Steps per Second: 14,026.46155

Timestep Collection Time: 2.25684
Timestep Consumption Time: 1.30914
PPO Batch Consumption Time: 0.09702
Total Iteration Time: 3.56597

Cumulative Model Updates: 576
Cumulative Timesteps: 4,851,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514.79602
Policy Entropy: 3.16887
Value Function Loss: 2.21293

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06482
Policy Update Magnitude: 0.10059
Value Function Update Magnitude: 0.08088

Collected Steps per Second: 24,232.52252
Overall Steps per Second: 14,525.74140

Timestep Collection Time: 2.06392
Timestep Consumption Time: 1.37921
PPO Batch Consumption Time: 0.10429
Total Iteration Time: 3.44313

Cumulative Model Updates: 582
Cumulative Timesteps: 4,901,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 4901886...
Checkpoint 4901886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530.23637
Policy Entropy: 3.21259
Value Function Loss: 2.42672

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05422
Policy Update Magnitude: 0.10193
Value Function Update Magnitude: 0.06418

Collected Steps per Second: 22,257.78744
Overall Steps per Second: 14,104.30354

Timestep Collection Time: 2.24676
Timestep Consumption Time: 1.29882
PPO Batch Consumption Time: 0.08916
Total Iteration Time: 3.54558

Cumulative Model Updates: 588
Cumulative Timesteps: 4,951,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625.28389
Policy Entropy: 3.18437
Value Function Loss: 2.43298

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06858
Policy Update Magnitude: 0.08946
Value Function Update Magnitude: 0.07583

Collected Steps per Second: 24,399.03608
Overall Steps per Second: 15,097.79175

Timestep Collection Time: 2.05033
Timestep Consumption Time: 1.26314
PPO Batch Consumption Time: 0.10055
Total Iteration Time: 3.31346

Cumulative Model Updates: 594
Cumulative Timesteps: 5,001,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 5001920...
Checkpoint 5001920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.38589
Policy Entropy: 3.20205
Value Function Loss: 2.45249

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.04529
Policy Update Magnitude: 0.09196
Value Function Update Magnitude: 0.04561

Collected Steps per Second: 23,289.12766
Overall Steps per Second: 14,864.25779

Timestep Collection Time: 2.14787
Timestep Consumption Time: 1.21738
PPO Batch Consumption Time: 0.07563
Total Iteration Time: 3.36525

Cumulative Model Updates: 600
Cumulative Timesteps: 5,051,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,681.99508
Policy Entropy: 3.16490
Value Function Loss: 2.59647

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.04512
Policy Update Magnitude: 0.09530
Value Function Update Magnitude: 0.03403

Collected Steps per Second: 22,860.28981
Overall Steps per Second: 14,761.17933

Timestep Collection Time: 2.18842
Timestep Consumption Time: 1.20074
PPO Batch Consumption Time: 0.08011
Total Iteration Time: 3.38916

Cumulative Model Updates: 606
Cumulative Timesteps: 5,101,970

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 5101970...
Checkpoint 5101970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.71081
Policy Entropy: 3.17526
Value Function Loss: 2.71198

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.03348
Policy Update Magnitude: 0.08432
Value Function Update Magnitude: 0.02939

Collected Steps per Second: 23,196.00953
Overall Steps per Second: 14,456.85553

Timestep Collection Time: 2.15684
Timestep Consumption Time: 1.30381
PPO Batch Consumption Time: 0.09206
Total Iteration Time: 3.46064

Cumulative Model Updates: 612
Cumulative Timesteps: 5,152,000

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,767.17696
Policy Entropy: 3.16668
Value Function Loss: 2.79675

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.05068
Policy Update Magnitude: 0.09270
Value Function Update Magnitude: 0.02659

Collected Steps per Second: 21,501.81341
Overall Steps per Second: 13,875.27020

Timestep Collection Time: 2.32622
Timestep Consumption Time: 1.27861
PPO Batch Consumption Time: 0.07636
Total Iteration Time: 3.60483

Cumulative Model Updates: 618
Cumulative Timesteps: 5,202,018

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 5202018...
Checkpoint 5202018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.39698
Policy Entropy: 3.17705
Value Function Loss: 2.80844

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.04120
Policy Update Magnitude: 0.09127
Value Function Update Magnitude: 0.02420

Collected Steps per Second: 22,162.39656
Overall Steps per Second: 14,125.34012

Timestep Collection Time: 2.25671
Timestep Consumption Time: 1.28402
PPO Batch Consumption Time: 0.09150
Total Iteration Time: 3.54073

Cumulative Model Updates: 624
Cumulative Timesteps: 5,252,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.12699
Policy Entropy: 3.17089
Value Function Loss: 2.80663

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05063
Policy Update Magnitude: 0.10051
Value Function Update Magnitude: 0.02306

Collected Steps per Second: 18,197.74779
Overall Steps per Second: 11,763.47090

Timestep Collection Time: 2.74891
Timestep Consumption Time: 1.50357
PPO Batch Consumption Time: 0.07668
Total Iteration Time: 4.25249

Cumulative Model Updates: 630
Cumulative Timesteps: 5,302,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 5302056...
Checkpoint 5302056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.34178
Policy Entropy: 3.15204
Value Function Loss: 2.76342

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06756
Policy Update Magnitude: 0.08631
Value Function Update Magnitude: 0.02330

Collected Steps per Second: 23,765.20792
Overall Steps per Second: 14,707.67475

Timestep Collection Time: 2.10518
Timestep Consumption Time: 1.29645
PPO Batch Consumption Time: 0.09761
Total Iteration Time: 3.40163

Cumulative Model Updates: 636
Cumulative Timesteps: 5,352,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,823.61622
Policy Entropy: 3.15686
Value Function Loss: 2.80423

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.05020
Policy Update Magnitude: 0.08736
Value Function Update Magnitude: 0.02375

Collected Steps per Second: 24,377.72120
Overall Steps per Second: 14,729.30303

Timestep Collection Time: 2.05130
Timestep Consumption Time: 1.34370
PPO Batch Consumption Time: 0.09937
Total Iteration Time: 3.39500

Cumulative Model Updates: 642
Cumulative Timesteps: 5,402,092

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 5402092...
Checkpoint 5402092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.78205
Policy Entropy: 3.13920
Value Function Loss: 2.80059

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.03420
Policy Update Magnitude: 0.09610
Value Function Update Magnitude: 0.02385

Collected Steps per Second: 24,218.45875
Overall Steps per Second: 14,646.85198

Timestep Collection Time: 2.06570
Timestep Consumption Time: 1.34992
PPO Batch Consumption Time: 0.10177
Total Iteration Time: 3.41561

Cumulative Model Updates: 648
Cumulative Timesteps: 5,452,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,756.54148
Policy Entropy: 3.13126
Value Function Loss: 2.90140

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.03879
Policy Update Magnitude: 0.09785
Value Function Update Magnitude: 0.02454

Collected Steps per Second: 24,516.43433
Overall Steps per Second: 15,090.72702

Timestep Collection Time: 2.04051
Timestep Consumption Time: 1.27451
PPO Batch Consumption Time: 0.09981
Total Iteration Time: 3.31502

Cumulative Model Updates: 654
Cumulative Timesteps: 5,502,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 5502146...
Checkpoint 5502146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.50791
Policy Entropy: 3.13807
Value Function Loss: 2.90906

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06071
Policy Update Magnitude: 0.09320
Value Function Update Magnitude: 0.02424

Collected Steps per Second: 24,250.40713
Overall Steps per Second: 14,733.28494

Timestep Collection Time: 2.06199
Timestep Consumption Time: 1.33196
PPO Batch Consumption Time: 0.09974
Total Iteration Time: 3.39395

Cumulative Model Updates: 660
Cumulative Timesteps: 5,552,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.12127
Policy Entropy: 3.13010
Value Function Loss: 2.93889

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.03134
Policy Update Magnitude: 0.08962
Value Function Update Magnitude: 0.02344

Collected Steps per Second: 24,331.18784
Overall Steps per Second: 14,750.99454

Timestep Collection Time: 2.05580
Timestep Consumption Time: 1.33516
PPO Batch Consumption Time: 0.10160
Total Iteration Time: 3.39096

Cumulative Model Updates: 666
Cumulative Timesteps: 5,602,170

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 5602170...
Checkpoint 5602170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.87303
Policy Entropy: 3.11126
Value Function Loss: 2.94272

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.04426
Policy Update Magnitude: 0.09593
Value Function Update Magnitude: 0.02246

Collected Steps per Second: 22,956.61400
Overall Steps per Second: 14,580.57443

Timestep Collection Time: 2.17907
Timestep Consumption Time: 1.25180
PPO Batch Consumption Time: 0.09791
Total Iteration Time: 3.43087

Cumulative Model Updates: 672
Cumulative Timesteps: 5,652,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,669.95574
Policy Entropy: 3.09913
Value Function Loss: 2.93430

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.03638
Policy Update Magnitude: 0.09622
Value Function Update Magnitude: 0.02377

Collected Steps per Second: 24,223.12899
Overall Steps per Second: 14,699.47862

Timestep Collection Time: 2.06513
Timestep Consumption Time: 1.33798
PPO Batch Consumption Time: 0.09730
Total Iteration Time: 3.40311

Cumulative Model Updates: 678
Cumulative Timesteps: 5,702,218

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 5702218...
Checkpoint 5702218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.53834
Policy Entropy: 3.08490
Value Function Loss: 2.89545

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.04634
Policy Update Magnitude: 0.09235
Value Function Update Magnitude: 0.02650

Collected Steps per Second: 22,670.60281
Overall Steps per Second: 13,941.00128

Timestep Collection Time: 2.20656
Timestep Consumption Time: 1.38171
PPO Batch Consumption Time: 0.10449
Total Iteration Time: 3.58826

Cumulative Model Updates: 684
Cumulative Timesteps: 5,752,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.92674
Policy Entropy: 3.07971
Value Function Loss: 2.92106

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.03935
Policy Update Magnitude: 0.08614
Value Function Update Magnitude: 0.02598

Collected Steps per Second: 20,944.77354
Overall Steps per Second: 13,014.62603

Timestep Collection Time: 2.38895
Timestep Consumption Time: 1.45565
PPO Batch Consumption Time: 0.10676
Total Iteration Time: 3.84460

Cumulative Model Updates: 690
Cumulative Timesteps: 5,802,278

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 5802278...
Checkpoint 5802278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683.62254
Policy Entropy: 3.07640
Value Function Loss: 2.94403

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02908
Policy Update Magnitude: 0.08932
Value Function Update Magnitude: 0.02325

Collected Steps per Second: 23,161.39258
Overall Steps per Second: 14,872.02805

Timestep Collection Time: 2.15989
Timestep Consumption Time: 1.20388
PPO Batch Consumption Time: 0.07442
Total Iteration Time: 3.36376

Cumulative Model Updates: 696
Cumulative Timesteps: 5,852,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.06281
Policy Entropy: 3.07821
Value Function Loss: 2.97184

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.03966
Policy Update Magnitude: 0.09182
Value Function Update Magnitude: 0.02239

Collected Steps per Second: 23,119.94843
Overall Steps per Second: 14,305.62327

Timestep Collection Time: 2.16454
Timestep Consumption Time: 1.33367
PPO Batch Consumption Time: 0.10158
Total Iteration Time: 3.49820

Cumulative Model Updates: 702
Cumulative Timesteps: 5,902,348

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 5902348...
Checkpoint 5902348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.34422
Policy Entropy: 3.07380
Value Function Loss: 2.99436

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05819
Policy Update Magnitude: 0.09284
Value Function Update Magnitude: 0.02169

Collected Steps per Second: 23,082.18866
Overall Steps per Second: 14,261.54708

Timestep Collection Time: 2.16617
Timestep Consumption Time: 1.33976
PPO Batch Consumption Time: 0.09681
Total Iteration Time: 3.50593

Cumulative Model Updates: 708
Cumulative Timesteps: 5,952,348

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,838.30755
Policy Entropy: 3.07957
Value Function Loss: 3.01835

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.05678
Policy Update Magnitude: 0.08974
Value Function Update Magnitude: 0.02191

Collected Steps per Second: 22,666.85473
Overall Steps per Second: 14,021.32701

Timestep Collection Time: 2.20701
Timestep Consumption Time: 1.36084
PPO Batch Consumption Time: 0.09809
Total Iteration Time: 3.56785

Cumulative Model Updates: 714
Cumulative Timesteps: 6,002,374

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 6002374...
Checkpoint 6002374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.29330
Policy Entropy: 3.08283
Value Function Loss: 3.02842

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.04758
Policy Update Magnitude: 0.09533
Value Function Update Magnitude: 0.02211

Collected Steps per Second: 24,883.20552
Overall Steps per Second: 15,153.75694

Timestep Collection Time: 2.01108
Timestep Consumption Time: 1.29121
PPO Batch Consumption Time: 0.09067
Total Iteration Time: 3.30228

Cumulative Model Updates: 720
Cumulative Timesteps: 6,052,416

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,774.23177
Policy Entropy: 3.06651
Value Function Loss: 3.02260

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.02574
Policy Update Magnitude: 0.08771
Value Function Update Magnitude: 0.02312

Collected Steps per Second: 23,685.81260
Overall Steps per Second: 14,696.59449

Timestep Collection Time: 2.11223
Timestep Consumption Time: 1.29196
PPO Batch Consumption Time: 0.09141
Total Iteration Time: 3.40419

Cumulative Model Updates: 726
Cumulative Timesteps: 6,102,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 6102446...
Checkpoint 6102446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.81256
Policy Entropy: 3.06796
Value Function Loss: 3.01484

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.03268
Policy Update Magnitude: 0.08791
Value Function Update Magnitude: 0.02438

Collected Steps per Second: 22,021.19647
Overall Steps per Second: 14,097.13848

Timestep Collection Time: 2.27154
Timestep Consumption Time: 1.27684
PPO Batch Consumption Time: 0.09871
Total Iteration Time: 3.54838

Cumulative Model Updates: 732
Cumulative Timesteps: 6,152,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.90022
Policy Entropy: 3.05975
Value Function Loss: 3.07419

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.04198
Policy Update Magnitude: 0.09280
Value Function Update Magnitude: 0.02495

Collected Steps per Second: 23,172.97745
Overall Steps per Second: 14,014.43848

Timestep Collection Time: 2.15872
Timestep Consumption Time: 1.41074
PPO Batch Consumption Time: 0.10632
Total Iteration Time: 3.56946

Cumulative Model Updates: 738
Cumulative Timesteps: 6,202,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 6202492...
Checkpoint 6202492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.62939
Policy Entropy: 3.05330
Value Function Loss: 3.04063

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.04600
Policy Update Magnitude: 0.09956
Value Function Update Magnitude: 0.02505

Collected Steps per Second: 21,692.23358
Overall Steps per Second: 14,355.06322

Timestep Collection Time: 2.30617
Timestep Consumption Time: 1.17873
PPO Batch Consumption Time: 0.07444
Total Iteration Time: 3.48490

Cumulative Model Updates: 744
Cumulative Timesteps: 6,252,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.82538
Policy Entropy: 3.04779
Value Function Loss: 3.06935

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.04381
Policy Update Magnitude: 0.09345
Value Function Update Magnitude: 0.02376

Collected Steps per Second: 23,681.33043
Overall Steps per Second: 14,540.73365

Timestep Collection Time: 2.11204
Timestep Consumption Time: 1.32767
PPO Batch Consumption Time: 0.09597
Total Iteration Time: 3.43972

Cumulative Model Updates: 750
Cumulative Timesteps: 6,302,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 6302534...
Checkpoint 6302534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.71133
Policy Entropy: 3.06744
Value Function Loss: 2.94145

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.04724
Policy Update Magnitude: 0.09459
Value Function Update Magnitude: 0.02473

Collected Steps per Second: 24,035.52275
Overall Steps per Second: 14,671.72026

Timestep Collection Time: 2.08092
Timestep Consumption Time: 1.32809
PPO Batch Consumption Time: 0.09612
Total Iteration Time: 3.40901

Cumulative Model Updates: 756
Cumulative Timesteps: 6,352,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,639.10527
Policy Entropy: 3.05638
Value Function Loss: 2.99849

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.04464
Policy Update Magnitude: 0.08727
Value Function Update Magnitude: 0.02535

Collected Steps per Second: 22,978.92787
Overall Steps per Second: 14,650.08885

Timestep Collection Time: 2.17695
Timestep Consumption Time: 1.23764
PPO Batch Consumption Time: 0.09338
Total Iteration Time: 3.41459

Cumulative Model Updates: 762
Cumulative Timesteps: 6,402,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 6402574...
Checkpoint 6402574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.23273
Policy Entropy: 3.03020
Value Function Loss: 2.96599

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.03920
Policy Update Magnitude: 0.08004
Value Function Update Magnitude: 0.02543

Collected Steps per Second: 23,163.33794
Overall Steps per Second: 13,939.22762

Timestep Collection Time: 2.15910
Timestep Consumption Time: 1.42876
PPO Batch Consumption Time: 0.10674
Total Iteration Time: 3.58786

Cumulative Model Updates: 768
Cumulative Timesteps: 6,452,586

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616.35294
Policy Entropy: 3.01421
Value Function Loss: 3.03601

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.04803
Policy Update Magnitude: 0.08236
Value Function Update Magnitude: 0.02531

Collected Steps per Second: 22,861.78080
Overall Steps per Second: 14,297.30697

Timestep Collection Time: 2.18767
Timestep Consumption Time: 1.31047
PPO Batch Consumption Time: 0.10094
Total Iteration Time: 3.49814

Cumulative Model Updates: 774
Cumulative Timesteps: 6,502,600

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 6502600...
Checkpoint 6502600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,775.86069
Policy Entropy: 3.02137
Value Function Loss: 3.03107

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.03845
Policy Update Magnitude: 0.07730
Value Function Update Magnitude: 0.02456

Collected Steps per Second: 24,142.06168
Overall Steps per Second: 14,704.19238

Timestep Collection Time: 2.07232
Timestep Consumption Time: 1.33011
PPO Batch Consumption Time: 0.09380
Total Iteration Time: 3.40243

Cumulative Model Updates: 780
Cumulative Timesteps: 6,552,630

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,749.96940
Policy Entropy: 3.02837
Value Function Loss: 3.05232

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.03112
Policy Update Magnitude: 0.08372
Value Function Update Magnitude: 0.02367

Collected Steps per Second: 23,358.66089
Overall Steps per Second: 14,441.09857

Timestep Collection Time: 2.14148
Timestep Consumption Time: 1.32239
PPO Batch Consumption Time: 0.09379
Total Iteration Time: 3.46386

Cumulative Model Updates: 786
Cumulative Timesteps: 6,602,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 6602652...
Checkpoint 6602652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724.11812
Policy Entropy: 3.05526
Value Function Loss: 3.05059

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.02758
Policy Update Magnitude: 0.08310
Value Function Update Magnitude: 0.02377

Collected Steps per Second: 23,115.87878
Overall Steps per Second: 14,765.75993

Timestep Collection Time: 2.16544
Timestep Consumption Time: 1.22457
PPO Batch Consumption Time: 0.09297
Total Iteration Time: 3.39001

Cumulative Model Updates: 792
Cumulative Timesteps: 6,652,708

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,595.22016
Policy Entropy: 3.03979
Value Function Loss: 3.00481

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.03433
Policy Update Magnitude: 0.09221
Value Function Update Magnitude: 0.02543

Collected Steps per Second: 24,283.45364
Overall Steps per Second: 15,034.13548

Timestep Collection Time: 2.05984
Timestep Consumption Time: 1.26726
PPO Batch Consumption Time: 0.09176
Total Iteration Time: 3.32710

Cumulative Model Updates: 798
Cumulative Timesteps: 6,702,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 6702728...
Checkpoint 6702728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.92188
Policy Entropy: 3.04713
Value Function Loss: 2.96194

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.03564
Policy Update Magnitude: 0.07915
Value Function Update Magnitude: 0.02725

Collected Steps per Second: 22,807.55971
Overall Steps per Second: 14,892.53826

Timestep Collection Time: 2.19296
Timestep Consumption Time: 1.16550
PPO Batch Consumption Time: 0.07365
Total Iteration Time: 3.35846

Cumulative Model Updates: 804
Cumulative Timesteps: 6,752,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.32569
Policy Entropy: 3.03265
Value Function Loss: 2.92787

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.04412
Policy Update Magnitude: 0.08365
Value Function Update Magnitude: 0.02812

Collected Steps per Second: 23,525.54423
Overall Steps per Second: 14,843.12481

Timestep Collection Time: 2.12569
Timestep Consumption Time: 1.24341
PPO Batch Consumption Time: 0.09693
Total Iteration Time: 3.36910

Cumulative Model Updates: 810
Cumulative Timesteps: 6,802,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 6802752...
Checkpoint 6802752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.39149
Policy Entropy: 3.06501
Value Function Loss: 2.98362

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.02868
Policy Update Magnitude: 0.08771
Value Function Update Magnitude: 0.02768

Collected Steps per Second: 23,004.70639
Overall Steps per Second: 13,985.42944

Timestep Collection Time: 2.17460
Timestep Consumption Time: 1.40241
PPO Batch Consumption Time: 0.10656
Total Iteration Time: 3.57701

Cumulative Model Updates: 816
Cumulative Timesteps: 6,852,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,780.29715
Policy Entropy: 3.04887
Value Function Loss: 3.03650

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02259
Policy Update Magnitude: 0.09076
Value Function Update Magnitude: 0.02519

Collected Steps per Second: 22,211.39293
Overall Steps per Second: 13,841.21360

Timestep Collection Time: 2.25110
Timestep Consumption Time: 1.36130
PPO Batch Consumption Time: 0.09657
Total Iteration Time: 3.61240

Cumulative Model Updates: 822
Cumulative Timesteps: 6,902,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 6902778...
Checkpoint 6902778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,770.93975
Policy Entropy: 3.02895
Value Function Loss: 3.09592

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.03472
Policy Update Magnitude: 0.09024
Value Function Update Magnitude: 0.02334

Collected Steps per Second: 23,072.02335
Overall Steps per Second: 14,870.26551

Timestep Collection Time: 2.16825
Timestep Consumption Time: 1.19591
PPO Batch Consumption Time: 0.07451
Total Iteration Time: 3.36416

Cumulative Model Updates: 828
Cumulative Timesteps: 6,952,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.74987
Policy Entropy: 3.03782
Value Function Loss: 3.10977

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.05538
Policy Update Magnitude: 0.07638
Value Function Update Magnitude: 0.02233

Collected Steps per Second: 21,910.28735
Overall Steps per Second: 13,906.45643

Timestep Collection Time: 2.28231
Timestep Consumption Time: 1.31358
PPO Batch Consumption Time: 0.09274
Total Iteration Time: 3.59588

Cumulative Model Updates: 834
Cumulative Timesteps: 7,002,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 7002810...
Checkpoint 7002810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622.22222
Policy Entropy: 3.01324
Value Function Loss: 3.08623

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.03584
Policy Update Magnitude: 0.08217
Value Function Update Magnitude: 0.02210

Collected Steps per Second: 23,629.00496
Overall Steps per Second: 14,849.34625

Timestep Collection Time: 2.11604
Timestep Consumption Time: 1.25111
PPO Batch Consumption Time: 0.09470
Total Iteration Time: 3.36715

Cumulative Model Updates: 840
Cumulative Timesteps: 7,052,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.47601
Policy Entropy: 3.02449
Value Function Loss: 3.09217

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.03093
Policy Update Magnitude: 0.08734
Value Function Update Magnitude: 0.02253

Collected Steps per Second: 23,791.64674
Overall Steps per Second: 14,765.96968

Timestep Collection Time: 2.10259
Timestep Consumption Time: 1.28520
PPO Batch Consumption Time: 0.09015
Total Iteration Time: 3.38779

Cumulative Model Updates: 846
Cumulative Timesteps: 7,102,834

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 7102834...
Checkpoint 7102834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.22588
Policy Entropy: 3.04966
Value Function Loss: 3.03773

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.05115
Policy Update Magnitude: 0.08247
Value Function Update Magnitude: 0.02261

Collected Steps per Second: 23,475.31112
Overall Steps per Second: 14,455.18586

Timestep Collection Time: 2.13041
Timestep Consumption Time: 1.32939
PPO Batch Consumption Time: 0.10062
Total Iteration Time: 3.45980

Cumulative Model Updates: 852
Cumulative Timesteps: 7,152,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729.45296
Policy Entropy: 3.04121
Value Function Loss: 3.03925

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.03483
Policy Update Magnitude: 0.08588
Value Function Update Magnitude: 0.02349

Collected Steps per Second: 24,296.67246
Overall Steps per Second: 14,666.57390

Timestep Collection Time: 2.05806
Timestep Consumption Time: 1.35133
PPO Batch Consumption Time: 0.10078
Total Iteration Time: 3.40939

Cumulative Model Updates: 858
Cumulative Timesteps: 7,202,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 7202850...
Checkpoint 7202850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.54570
Policy Entropy: 3.04645
Value Function Loss: 2.98783

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.04189
Policy Update Magnitude: 0.08452
Value Function Update Magnitude: 0.02372

Collected Steps per Second: 23,899.75142
Overall Steps per Second: 14,595.33906

Timestep Collection Time: 2.09241
Timestep Consumption Time: 1.33389
PPO Batch Consumption Time: 0.09708
Total Iteration Time: 3.42630

Cumulative Model Updates: 864
Cumulative Timesteps: 7,252,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.32916
Policy Entropy: 3.01780
Value Function Loss: 3.01411

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.03128
Policy Update Magnitude: 0.08014
Value Function Update Magnitude: 0.02439

Collected Steps per Second: 23,581.89500
Overall Steps per Second: 14,769.37835

Timestep Collection Time: 2.12061
Timestep Consumption Time: 1.26531
PPO Batch Consumption Time: 0.09900
Total Iteration Time: 3.38592

Cumulative Model Updates: 870
Cumulative Timesteps: 7,302,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 7302866...
Checkpoint 7302866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.77092
Policy Entropy: 3.02057
Value Function Loss: 3.02089

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.03886
Policy Update Magnitude: 0.09481
Value Function Update Magnitude: 0.02511

Collected Steps per Second: 23,485.56296
Overall Steps per Second: 14,197.34353

Timestep Collection Time: 2.12956
Timestep Consumption Time: 1.39321
PPO Batch Consumption Time: 0.10305
Total Iteration Time: 3.52277

Cumulative Model Updates: 876
Cumulative Timesteps: 7,352,880

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614.67966
Policy Entropy: 3.01459
Value Function Loss: 3.13035

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.04745
Policy Update Magnitude: 0.08527
Value Function Update Magnitude: 0.02535

Collected Steps per Second: 22,361.63226
Overall Steps per Second: 14,554.57414

Timestep Collection Time: 2.23705
Timestep Consumption Time: 1.19995
PPO Batch Consumption Time: 0.07595
Total Iteration Time: 3.43700

Cumulative Model Updates: 882
Cumulative Timesteps: 7,402,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 7402904...
Checkpoint 7402904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.63857
Policy Entropy: 3.00156
Value Function Loss: 3.16347

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.03213
Policy Update Magnitude: 0.07236
Value Function Update Magnitude: 0.02380

Collected Steps per Second: 24,158.68236
Overall Steps per Second: 14,740.19095

Timestep Collection Time: 2.07023
Timestep Consumption Time: 1.32281
PPO Batch Consumption Time: 0.09271
Total Iteration Time: 3.39304

Cumulative Model Updates: 888
Cumulative Timesteps: 7,452,918

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,818.57336
Policy Entropy: 2.98153
Value Function Loss: 3.20749

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.01820
Policy Update Magnitude: 0.07878
Value Function Update Magnitude: 0.02388

Collected Steps per Second: 21,390.23528
Overall Steps per Second: 13,385.85726

Timestep Collection Time: 2.33826
Timestep Consumption Time: 1.39822
PPO Batch Consumption Time: 0.09935
Total Iteration Time: 3.73648

Cumulative Model Updates: 894
Cumulative Timesteps: 7,502,934

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 7502934...
Checkpoint 7502934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.84574
Policy Entropy: 2.96433
Value Function Loss: 3.13766

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.02808
Policy Update Magnitude: 0.06586
Value Function Update Magnitude: 0.02442

Collected Steps per Second: 22,285.33310
Overall Steps per Second: 13,907.49375

Timestep Collection Time: 2.24399
Timestep Consumption Time: 1.35177
PPO Batch Consumption Time: 0.10697
Total Iteration Time: 3.59576

Cumulative Model Updates: 900
Cumulative Timesteps: 7,552,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.96901
Policy Entropy: 2.96439
Value Function Loss: 3.07606

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02087
Policy Update Magnitude: 0.07884
Value Function Update Magnitude: 0.02509

Collected Steps per Second: 21,546.41868
Overall Steps per Second: 13,424.28556

Timestep Collection Time: 2.32113
Timestep Consumption Time: 1.40436
PPO Batch Consumption Time: 0.10145
Total Iteration Time: 3.72549

Cumulative Model Updates: 906
Cumulative Timesteps: 7,602,954

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 7602954...
Checkpoint 7602954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.95846
Policy Entropy: 2.95559
Value Function Loss: 3.05385

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05302
Policy Update Magnitude: 0.09110
Value Function Update Magnitude: 0.02654

Collected Steps per Second: 23,863.02959
Overall Steps per Second: 14,637.52077

Timestep Collection Time: 2.09621
Timestep Consumption Time: 1.32117
PPO Batch Consumption Time: 0.09921
Total Iteration Time: 3.41738

Cumulative Model Updates: 912
Cumulative Timesteps: 7,652,976

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.35744
Policy Entropy: 2.96754
Value Function Loss: 3.07833

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.04578
Policy Update Magnitude: 0.08111
Value Function Update Magnitude: 0.02704

Collected Steps per Second: 24,629.65667
Overall Steps per Second: 14,778.14308

Timestep Collection Time: 2.03121
Timestep Consumption Time: 1.35406
PPO Batch Consumption Time: 0.10282
Total Iteration Time: 3.38527

Cumulative Model Updates: 918
Cumulative Timesteps: 7,703,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 7703004...
Checkpoint 7703004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.02876
Policy Entropy: 2.96676
Value Function Loss: 3.15503

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.04389
Policy Update Magnitude: 0.07554
Value Function Update Magnitude: 0.02727

Collected Steps per Second: 23,609.88363
Overall Steps per Second: 14,206.69019

Timestep Collection Time: 2.11894
Timestep Consumption Time: 1.40250
PPO Batch Consumption Time: 0.10218
Total Iteration Time: 3.52144

Cumulative Model Updates: 924
Cumulative Timesteps: 7,753,032

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.19552
Policy Entropy: 2.93646
Value Function Loss: 3.15078

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.03029
Policy Update Magnitude: 0.08444
Value Function Update Magnitude: 0.02808

Collected Steps per Second: 22,902.00971
Overall Steps per Second: 14,452.74588

Timestep Collection Time: 2.18470
Timestep Consumption Time: 1.27720
PPO Batch Consumption Time: 0.09750
Total Iteration Time: 3.46190

Cumulative Model Updates: 930
Cumulative Timesteps: 7,803,066

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 7803066...
Checkpoint 7803066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685.54379
Policy Entropy: 2.95927
Value Function Loss: 3.18239

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.03023
Policy Update Magnitude: 0.08613
Value Function Update Magnitude: 0.02554

Collected Steps per Second: 23,368.91448
Overall Steps per Second: 14,186.97555

Timestep Collection Time: 2.14045
Timestep Consumption Time: 1.38532
PPO Batch Consumption Time: 0.10207
Total Iteration Time: 3.52577

Cumulative Model Updates: 936
Cumulative Timesteps: 7,853,086

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.06708
Policy Entropy: 3.00199
Value Function Loss: 3.21517

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.03409
Policy Update Magnitude: 0.09575
Value Function Update Magnitude: 0.02559

Collected Steps per Second: 22,713.09165
Overall Steps per Second: 14,209.56342

Timestep Collection Time: 2.20252
Timestep Consumption Time: 1.31807
PPO Batch Consumption Time: 0.10083
Total Iteration Time: 3.52059

Cumulative Model Updates: 942
Cumulative Timesteps: 7,903,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 7903112...
Checkpoint 7903112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.95444
Policy Entropy: 2.98898
Value Function Loss: 3.21794

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.04551
Policy Update Magnitude: 0.08092
Value Function Update Magnitude: 0.02570

Collected Steps per Second: 23,396.02966
Overall Steps per Second: 14,368.84739

Timestep Collection Time: 2.13737
Timestep Consumption Time: 1.34280
PPO Batch Consumption Time: 0.09769
Total Iteration Time: 3.48017

Cumulative Model Updates: 948
Cumulative Timesteps: 7,953,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,841.31348
Policy Entropy: 2.93894
Value Function Loss: 3.24010

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.04353
Policy Update Magnitude: 0.09708
Value Function Update Magnitude: 0.02376

Collected Steps per Second: 22,713.94953
Overall Steps per Second: 13,941.95647

Timestep Collection Time: 2.20173
Timestep Consumption Time: 1.38528
PPO Batch Consumption Time: 0.09844
Total Iteration Time: 3.58701

Cumulative Model Updates: 954
Cumulative Timesteps: 8,003,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 8003128...
Checkpoint 8003128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696.39436
Policy Entropy: 2.96737
Value Function Loss: 3.24363

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.04160
Policy Update Magnitude: 0.08849
Value Function Update Magnitude: 0.02441

Collected Steps per Second: 21,869.42725
Overall Steps per Second: 14,044.61652

Timestep Collection Time: 2.28730
Timestep Consumption Time: 1.27435
PPO Batch Consumption Time: 0.09874
Total Iteration Time: 3.56165

Cumulative Model Updates: 960
Cumulative Timesteps: 8,053,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664.60202
Policy Entropy: 2.98360
Value Function Loss: 3.24705

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.04139
Policy Update Magnitude: 0.07155
Value Function Update Magnitude: 0.02423

Collected Steps per Second: 22,982.95979
Overall Steps per Second: 13,932.78834

Timestep Collection Time: 2.17700
Timestep Consumption Time: 1.41409
PPO Batch Consumption Time: 0.09988
Total Iteration Time: 3.59110

Cumulative Model Updates: 966
Cumulative Timesteps: 8,103,184

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 8103184...
Checkpoint 8103184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,796.58524
Policy Entropy: 3.00142
Value Function Loss: 3.26105

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.04484
Policy Update Magnitude: 0.08103
Value Function Update Magnitude: 0.02416

Collected Steps per Second: 22,804.39567
Overall Steps per Second: 14,061.50879

Timestep Collection Time: 2.19449
Timestep Consumption Time: 1.36445
PPO Batch Consumption Time: 0.10462
Total Iteration Time: 3.55894

Cumulative Model Updates: 972
Cumulative Timesteps: 8,153,228

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,736.09529
Policy Entropy: 2.99816
Value Function Loss: 3.14433

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02502
Policy Update Magnitude: 0.09105
Value Function Update Magnitude: 0.02809

Collected Steps per Second: 22,369.28694
Overall Steps per Second: 14,142.76374

Timestep Collection Time: 2.23530
Timestep Consumption Time: 1.30022
PPO Batch Consumption Time: 0.10073
Total Iteration Time: 3.53552

Cumulative Model Updates: 978
Cumulative Timesteps: 8,203,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 8203230...
Checkpoint 8203230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.55518
Policy Entropy: 3.03281
Value Function Loss: 3.13333

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.04847
Policy Update Magnitude: 0.08847
Value Function Update Magnitude: 0.02936

Collected Steps per Second: 22,859.71801
Overall Steps per Second: 14,017.83411

Timestep Collection Time: 2.18883
Timestep Consumption Time: 1.38062
PPO Batch Consumption Time: 0.10232
Total Iteration Time: 3.56945

Cumulative Model Updates: 984
Cumulative Timesteps: 8,253,266

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689.40818
Policy Entropy: 3.01615
Value Function Loss: 3.08039

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.02188
Policy Update Magnitude: 0.08941
Value Function Update Magnitude: 0.02946

Collected Steps per Second: 23,468.94199
Overall Steps per Second: 14,420.37230

Timestep Collection Time: 2.13116
Timestep Consumption Time: 1.33727
PPO Batch Consumption Time: 0.09622
Total Iteration Time: 3.46843

Cumulative Model Updates: 990
Cumulative Timesteps: 8,303,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 8303282...
Checkpoint 8303282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625.28329
Policy Entropy: 3.00806
Value Function Loss: 3.09156

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.02882
Policy Update Magnitude: 0.08620
Value Function Update Magnitude: 0.02858

Collected Steps per Second: 23,581.74071
Overall Steps per Second: 14,312.56040

Timestep Collection Time: 2.12156
Timestep Consumption Time: 1.37397
PPO Batch Consumption Time: 0.10206
Total Iteration Time: 3.49553

Cumulative Model Updates: 996
Cumulative Timesteps: 8,353,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.97208
Policy Entropy: 2.98849
Value Function Loss: 3.07257

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.03233
Policy Update Magnitude: 0.08744
Value Function Update Magnitude: 0.02719

Collected Steps per Second: 23,540.76601
Overall Steps per Second: 14,437.31567

Timestep Collection Time: 2.12431
Timestep Consumption Time: 1.33949
PPO Batch Consumption Time: 0.09642
Total Iteration Time: 3.46380

Cumulative Model Updates: 1,002
Cumulative Timesteps: 8,403,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 8403320...
Checkpoint 8403320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645.32352
Policy Entropy: 2.96079
Value Function Loss: 3.02520

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.04063
Policy Update Magnitude: 0.09095
Value Function Update Magnitude: 0.02680

Collected Steps per Second: 23,342.66800
Overall Steps per Second: 14,784.04858

Timestep Collection Time: 2.14209
Timestep Consumption Time: 1.24007
PPO Batch Consumption Time: 0.09410
Total Iteration Time: 3.38216

Cumulative Model Updates: 1,008
Cumulative Timesteps: 8,453,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,688.50279
Policy Entropy: 2.97939
Value Function Loss: 3.01888

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.04307
Policy Update Magnitude: 0.08606
Value Function Update Magnitude: 0.02603

Collected Steps per Second: 23,634.49287
Overall Steps per Second: 14,366.31077

Timestep Collection Time: 2.11648
Timestep Consumption Time: 1.36541
PPO Batch Consumption Time: 0.10155
Total Iteration Time: 3.48190

Cumulative Model Updates: 1,014
Cumulative Timesteps: 8,503,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 8503344...
Checkpoint 8503344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684.87147
Policy Entropy: 2.96306
Value Function Loss: 3.12191

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.04332
Policy Update Magnitude: 0.08260
Value Function Update Magnitude: 0.02597

Collected Steps per Second: 22,292.10003
Overall Steps per Second: 13,752.51774

Timestep Collection Time: 2.24420
Timestep Consumption Time: 1.39353
PPO Batch Consumption Time: 0.10758
Total Iteration Time: 3.63773

Cumulative Model Updates: 1,020
Cumulative Timesteps: 8,553,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,788.05642
Policy Entropy: 2.97934
Value Function Loss: 3.17235

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02455
Policy Update Magnitude: 0.08517
Value Function Update Magnitude: 0.02546

Collected Steps per Second: 22,716.01150
Overall Steps per Second: 13,930.59235

Timestep Collection Time: 2.20285
Timestep Consumption Time: 1.38924
PPO Batch Consumption Time: 0.10344
Total Iteration Time: 3.59209

Cumulative Model Updates: 1,026
Cumulative Timesteps: 8,603,412

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 8603412...
Checkpoint 8603412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,612.75355
Policy Entropy: 2.96098
Value Function Loss: 3.19428

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.08877
Value Function Update Magnitude: 0.02593

Collected Steps per Second: 23,216.65680
Overall Steps per Second: 14,216.10936

Timestep Collection Time: 2.15423
Timestep Consumption Time: 1.36389
PPO Batch Consumption Time: 0.10176
Total Iteration Time: 3.51812

Cumulative Model Updates: 1,032
Cumulative Timesteps: 8,653,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.03431
Policy Entropy: 2.98091
Value Function Loss: 3.08453

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.01931
Policy Update Magnitude: 0.09244
Value Function Update Magnitude: 0.02742

Collected Steps per Second: 22,806.14146
Overall Steps per Second: 14,440.77059

Timestep Collection Time: 2.19257
Timestep Consumption Time: 1.27013
PPO Batch Consumption Time: 0.09496
Total Iteration Time: 3.46270

Cumulative Model Updates: 1,038
Cumulative Timesteps: 8,703,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 8703430...
Checkpoint 8703430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,775.29340
Policy Entropy: 2.99609
Value Function Loss: 3.08567

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02302
Policy Update Magnitude: 0.09409
Value Function Update Magnitude: 0.02738

Collected Steps per Second: 22,951.28778
Overall Steps per Second: 14,112.75234

Timestep Collection Time: 2.17896
Timestep Consumption Time: 1.36464
PPO Batch Consumption Time: 0.09881
Total Iteration Time: 3.54360

Cumulative Model Updates: 1,044
Cumulative Timesteps: 8,753,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.75555
Policy Entropy: 3.00353
Value Function Loss: 3.12052

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.03274
Policy Update Magnitude: 0.09060
Value Function Update Magnitude: 0.03324

Collected Steps per Second: 23,135.30291
Overall Steps per Second: 14,255.08992

Timestep Collection Time: 2.16250
Timestep Consumption Time: 1.34713
PPO Batch Consumption Time: 0.10058
Total Iteration Time: 3.50962

Cumulative Model Updates: 1,050
Cumulative Timesteps: 8,803,470

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 8803470...
Checkpoint 8803470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.16573
Policy Entropy: 2.99502
Value Function Loss: 3.16869

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.02773
Policy Update Magnitude: 0.09346
Value Function Update Magnitude: 0.03663

Collected Steps per Second: 23,954.39740
Overall Steps per Second: 14,484.21969

Timestep Collection Time: 2.08864
Timestep Consumption Time: 1.36561
PPO Batch Consumption Time: 0.09819
Total Iteration Time: 3.45424

Cumulative Model Updates: 1,056
Cumulative Timesteps: 8,853,502

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,677.65951
Policy Entropy: 3.00613
Value Function Loss: 3.20144

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.02785
Policy Update Magnitude: 0.08769
Value Function Update Magnitude: 0.03318

Collected Steps per Second: 23,070.61023
Overall Steps per Second: 13,918.18418

Timestep Collection Time: 2.16847
Timestep Consumption Time: 1.42596
PPO Batch Consumption Time: 0.10770
Total Iteration Time: 3.59443

Cumulative Model Updates: 1,062
Cumulative Timesteps: 8,903,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 8903530...
Checkpoint 8903530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.40104
Policy Entropy: 2.99727
Value Function Loss: 3.16580

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.02991
Policy Update Magnitude: 0.08193
Value Function Update Magnitude: 0.03081

Collected Steps per Second: 21,524.71074
Overall Steps per Second: 13,922.47957

Timestep Collection Time: 2.32468
Timestep Consumption Time: 1.26937
PPO Batch Consumption Time: 0.09670
Total Iteration Time: 3.59404

Cumulative Model Updates: 1,068
Cumulative Timesteps: 8,953,568

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.03046
Policy Entropy: 2.98171
Value Function Loss: 3.16737

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.02814
Policy Update Magnitude: 0.08665
Value Function Update Magnitude: 0.02974

Collected Steps per Second: 22,635.94554
Overall Steps per Second: 13,974.55293

Timestep Collection Time: 2.20994
Timestep Consumption Time: 1.36971
PPO Batch Consumption Time: 0.10016
Total Iteration Time: 3.57965

Cumulative Model Updates: 1,074
Cumulative Timesteps: 9,003,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 9003592...
Checkpoint 9003592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.01605
Policy Entropy: 2.97335
Value Function Loss: 3.09288

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02025
Policy Update Magnitude: 0.08844
Value Function Update Magnitude: 0.04976

Collected Steps per Second: 22,050.70012
Overall Steps per Second: 13,994.42322

Timestep Collection Time: 2.26823
Timestep Consumption Time: 1.30577
PPO Batch Consumption Time: 0.09567
Total Iteration Time: 3.57400

Cumulative Model Updates: 1,080
Cumulative Timesteps: 9,053,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.77181
Policy Entropy: 2.95448
Value Function Loss: 3.11623

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.03087
Policy Update Magnitude: 0.08459
Value Function Update Magnitude: 0.03618

Collected Steps per Second: 22,894.98648
Overall Steps per Second: 14,040.87088

Timestep Collection Time: 2.18415
Timestep Consumption Time: 1.37731
PPO Batch Consumption Time: 0.09964
Total Iteration Time: 3.56146

Cumulative Model Updates: 1,086
Cumulative Timesteps: 9,103,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 9103614...
Checkpoint 9103614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,813.08642
Policy Entropy: 2.96826
Value Function Loss: 3.11253

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.02838
Policy Update Magnitude: 0.08331
Value Function Update Magnitude: 0.03340

Collected Steps per Second: 22,087.72857
Overall Steps per Second: 13,362.23960

Timestep Collection Time: 2.26370
Timestep Consumption Time: 1.47819
PPO Batch Consumption Time: 0.10344
Total Iteration Time: 3.74189

Cumulative Model Updates: 1,092
Cumulative Timesteps: 9,153,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.75385
Policy Entropy: 2.96591
Value Function Loss: 3.17083

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.03253
Policy Update Magnitude: 0.08055
Value Function Update Magnitude: 0.03351

Collected Steps per Second: 21,933.56909
Overall Steps per Second: 13,896.67023

Timestep Collection Time: 2.28052
Timestep Consumption Time: 1.31890
PPO Batch Consumption Time: 0.10628
Total Iteration Time: 3.59942

Cumulative Model Updates: 1,098
Cumulative Timesteps: 9,203,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 9203634...
Checkpoint 9203634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,836.88826
Policy Entropy: 2.99746
Value Function Loss: 3.18724

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.03411
Policy Update Magnitude: 0.08101
Value Function Update Magnitude: 0.03254

Collected Steps per Second: 23,082.04515
Overall Steps per Second: 14,142.79369

Timestep Collection Time: 2.16679
Timestep Consumption Time: 1.36957
PPO Batch Consumption Time: 0.10112
Total Iteration Time: 3.53636

Cumulative Model Updates: 1,104
Cumulative Timesteps: 9,253,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,732.32963
Policy Entropy: 2.98947
Value Function Loss: 3.13824

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.02524
Policy Update Magnitude: 0.08027
Value Function Update Magnitude: 0.03188

Collected Steps per Second: 22,473.03290
Overall Steps per Second: 13,793.66909

Timestep Collection Time: 2.22560
Timestep Consumption Time: 1.40041
PPO Batch Consumption Time: 0.10573
Total Iteration Time: 3.62601

Cumulative Model Updates: 1,110
Cumulative Timesteps: 9,303,664

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 9303664...
Checkpoint 9303664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.19268
Policy Entropy: 2.98029
Value Function Loss: 3.10986

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02445
Policy Update Magnitude: 0.08070
Value Function Update Magnitude: 0.03263

Collected Steps per Second: 23,226.45581
Overall Steps per Second: 14,127.78009

Timestep Collection Time: 2.15280
Timestep Consumption Time: 1.38646
PPO Batch Consumption Time: 0.10350
Total Iteration Time: 3.53927

Cumulative Model Updates: 1,116
Cumulative Timesteps: 9,353,666

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491.35242
Policy Entropy: 2.95714
Value Function Loss: 3.10046

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.02834
Policy Update Magnitude: 0.08558
Value Function Update Magnitude: 0.02884

Collected Steps per Second: 23,348.98445
Overall Steps per Second: 14,120.92592

Timestep Collection Time: 2.14193
Timestep Consumption Time: 1.39976
PPO Batch Consumption Time: 0.10449
Total Iteration Time: 3.54169

Cumulative Model Updates: 1,122
Cumulative Timesteps: 9,403,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 9403678...
Checkpoint 9403678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690.20614
Policy Entropy: 2.94374
Value Function Loss: 3.14598

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.03561
Policy Update Magnitude: 0.08395
Value Function Update Magnitude: 0.02684

Collected Steps per Second: 23,274.24706
Overall Steps per Second: 14,571.99358

Timestep Collection Time: 2.14881
Timestep Consumption Time: 1.28325
PPO Batch Consumption Time: 0.10147
Total Iteration Time: 3.43206

Cumulative Model Updates: 1,128
Cumulative Timesteps: 9,453,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.95954
Policy Entropy: 2.94744
Value Function Loss: 3.14057

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.03922
Policy Update Magnitude: 0.08005
Value Function Update Magnitude: 0.02607

Collected Steps per Second: 22,820.81473
Overall Steps per Second: 13,961.11622

Timestep Collection Time: 2.19221
Timestep Consumption Time: 1.39117
PPO Batch Consumption Time: 0.10514
Total Iteration Time: 3.58338

Cumulative Model Updates: 1,134
Cumulative Timesteps: 9,503,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 9503718...
Checkpoint 9503718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.11646
Policy Entropy: 2.95536
Value Function Loss: 3.15718

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.03370
Policy Update Magnitude: 0.08010
Value Function Update Magnitude: 0.02486

Collected Steps per Second: 22,803.28104
Overall Steps per Second: 13,970.86824

Timestep Collection Time: 2.19372
Timestep Consumption Time: 1.38687
PPO Batch Consumption Time: 0.10292
Total Iteration Time: 3.58059

Cumulative Model Updates: 1,140
Cumulative Timesteps: 9,553,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,692.99111
Policy Entropy: 2.94570
Value Function Loss: 3.16387

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.03139
Policy Update Magnitude: 0.08149
Value Function Update Magnitude: 0.02358

Collected Steps per Second: 22,948.19244
Overall Steps per Second: 14,121.91770

Timestep Collection Time: 2.18056
Timestep Consumption Time: 1.36286
PPO Batch Consumption Time: 0.10200
Total Iteration Time: 3.54343

Cumulative Model Updates: 1,146
Cumulative Timesteps: 9,603,782

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 9603782...
Checkpoint 9603782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.98393
Policy Entropy: 2.94223
Value Function Loss: 3.15935

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.08714
Value Function Update Magnitude: 0.02363

Collected Steps per Second: 23,333.46882
Overall Steps per Second: 14,520.68426

Timestep Collection Time: 2.14284
Timestep Consumption Time: 1.30052
PPO Batch Consumption Time: 0.09178
Total Iteration Time: 3.44336

Cumulative Model Updates: 1,152
Cumulative Timesteps: 9,653,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,726.72642
Policy Entropy: 2.93388
Value Function Loss: 3.20228

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.02644
Policy Update Magnitude: 0.08263
Value Function Update Magnitude: 0.02475

Collected Steps per Second: 23,073.92492
Overall Steps per Second: 14,463.06660

Timestep Collection Time: 2.16851
Timestep Consumption Time: 1.29106
PPO Batch Consumption Time: 0.09987
Total Iteration Time: 3.45957

Cumulative Model Updates: 1,158
Cumulative Timesteps: 9,703,818

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 9703818...
Checkpoint 9703818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.82001
Policy Entropy: 2.92072
Value Function Loss: 3.22290

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.01549
Policy Update Magnitude: 0.09627
Value Function Update Magnitude: 0.02591

Collected Steps per Second: 23,723.75840
Overall Steps per Second: 14,448.87189

Timestep Collection Time: 2.10860
Timestep Consumption Time: 1.35354
PPO Batch Consumption Time: 0.09976
Total Iteration Time: 3.46214

Cumulative Model Updates: 1,164
Cumulative Timesteps: 9,753,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720.10793
Policy Entropy: 2.90955
Value Function Loss: 3.23629

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04044
Policy Update Magnitude: 0.07197
Value Function Update Magnitude: 0.02441

Collected Steps per Second: 23,302.33841
Overall Steps per Second: 14,603.55426

Timestep Collection Time: 2.14631
Timestep Consumption Time: 1.27847
PPO Batch Consumption Time: 0.09092
Total Iteration Time: 3.42478

Cumulative Model Updates: 1,170
Cumulative Timesteps: 9,803,856

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 9803856...
Checkpoint 9803856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,524.51473
Policy Entropy: 2.91050
Value Function Loss: 3.20238

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.02054
Policy Update Magnitude: 0.07921
Value Function Update Magnitude: 0.02307

Collected Steps per Second: 23,715.19830
Overall Steps per Second: 14,839.66807

Timestep Collection Time: 2.10835
Timestep Consumption Time: 1.26100
PPO Batch Consumption Time: 0.09930
Total Iteration Time: 3.36935

Cumulative Model Updates: 1,176
Cumulative Timesteps: 9,853,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722.76848
Policy Entropy: 2.91620
Value Function Loss: 3.11141

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.02410
Policy Update Magnitude: 0.08100
Value Function Update Magnitude: 0.02399

Collected Steps per Second: 22,747.13202
Overall Steps per Second: 14,029.22429

Timestep Collection Time: 2.19922
Timestep Consumption Time: 1.36662
PPO Batch Consumption Time: 0.09796
Total Iteration Time: 3.56584

Cumulative Model Updates: 1,182
Cumulative Timesteps: 9,903,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 9903882...
Checkpoint 9903882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.24783
Policy Entropy: 2.92794
Value Function Loss: 3.09254

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.02657
Policy Update Magnitude: 0.08109
Value Function Update Magnitude: 0.03857

Collected Steps per Second: 23,964.60965
Overall Steps per Second: 14,824.55286

Timestep Collection Time: 2.08708
Timestep Consumption Time: 1.28678
PPO Batch Consumption Time: 0.09631
Total Iteration Time: 3.37386

Cumulative Model Updates: 1,188
Cumulative Timesteps: 9,953,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.68744
Policy Entropy: 2.91658
Value Function Loss: 3.11870

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.08716
Value Function Update Magnitude: 0.05568

Collected Steps per Second: 24,700.03484
Overall Steps per Second: 14,818.01267

Timestep Collection Time: 2.02469
Timestep Consumption Time: 1.35025
PPO Batch Consumption Time: 0.09959
Total Iteration Time: 3.37495

Cumulative Model Updates: 1,194
Cumulative Timesteps: 10,003,908

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 10003908...
Checkpoint 10003908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.53820
Policy Entropy: 2.87483
Value Function Loss: 3.14436

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.04523
Policy Update Magnitude: 0.08400
Value Function Update Magnitude: 0.05846

Collected Steps per Second: 23,306.23733
Overall Steps per Second: 14,189.13095

Timestep Collection Time: 2.14569
Timestep Consumption Time: 1.37870
PPO Batch Consumption Time: 0.10409
Total Iteration Time: 3.52439

Cumulative Model Updates: 1,200
Cumulative Timesteps: 10,053,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822.08350
Policy Entropy: 2.88092
Value Function Loss: 3.17997

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 0.07941
Value Function Update Magnitude: 0.04319

Collected Steps per Second: 23,122.23692
Overall Steps per Second: 14,481.61191

Timestep Collection Time: 2.16346
Timestep Consumption Time: 1.29085
PPO Batch Consumption Time: 0.10073
Total Iteration Time: 3.45431

Cumulative Model Updates: 1,206
Cumulative Timesteps: 10,103,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 10103940...
Checkpoint 10103940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626.15585
Policy Entropy: 2.85303
Value Function Loss: 3.18573

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.03229
Policy Update Magnitude: 0.07577
Value Function Update Magnitude: 0.03629

Collected Steps per Second: 23,143.73976
Overall Steps per Second: 14,064.60109

Timestep Collection Time: 2.16076
Timestep Consumption Time: 1.39484
PPO Batch Consumption Time: 0.10625
Total Iteration Time: 3.55559

Cumulative Model Updates: 1,212
Cumulative Timesteps: 10,153,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.89533
Policy Entropy: 2.84241
Value Function Loss: 3.25172

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.03380
Policy Update Magnitude: 0.07297
Value Function Update Magnitude: 0.03040

Collected Steps per Second: 22,512.88022
Overall Steps per Second: 13,931.23805

Timestep Collection Time: 2.22228
Timestep Consumption Time: 1.36893
PPO Batch Consumption Time: 0.10280
Total Iteration Time: 3.59121

Cumulative Model Updates: 1,218
Cumulative Timesteps: 10,203,978

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 10203978...
Checkpoint 10203978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,674.92839
Policy Entropy: 2.83678
Value Function Loss: 3.21796

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.03499
Policy Update Magnitude: 0.07404
Value Function Update Magnitude: 0.05331

Collected Steps per Second: 23,016.39727
Overall Steps per Second: 14,007.08169

Timestep Collection Time: 2.17254
Timestep Consumption Time: 1.39737
PPO Batch Consumption Time: 0.10024
Total Iteration Time: 3.56991

Cumulative Model Updates: 1,224
Cumulative Timesteps: 10,253,982

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.38742
Policy Entropy: 2.85281
Value Function Loss: 3.20133

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05161
Policy Update Magnitude: 0.07862
Value Function Update Magnitude: 0.03397

Collected Steps per Second: 23,384.11515
Overall Steps per Second: 14,133.43344

Timestep Collection Time: 2.13932
Timestep Consumption Time: 1.40023
PPO Batch Consumption Time: 0.10222
Total Iteration Time: 3.53955

Cumulative Model Updates: 1,230
Cumulative Timesteps: 10,304,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 10304008...
Checkpoint 10304008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.57253
Policy Entropy: 2.86347
Value Function Loss: 3.18146

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.03750
Policy Update Magnitude: 0.07577
Value Function Update Magnitude: 0.02591

Collected Steps per Second: 23,531.73264
Overall Steps per Second: 14,695.38593

Timestep Collection Time: 2.12496
Timestep Consumption Time: 1.27774
PPO Batch Consumption Time: 0.10075
Total Iteration Time: 3.40270

Cumulative Model Updates: 1,236
Cumulative Timesteps: 10,354,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,791.42409
Policy Entropy: 2.87533
Value Function Loss: 3.25312

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.06823
Value Function Update Magnitude: 0.02303

Collected Steps per Second: 23,889.03245
Overall Steps per Second: 14,635.37399

Timestep Collection Time: 2.09351
Timestep Consumption Time: 1.32369
PPO Batch Consumption Time: 0.09570
Total Iteration Time: 3.41720

Cumulative Model Updates: 1,242
Cumulative Timesteps: 10,404,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 10404024...
Checkpoint 10404024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.31382
Policy Entropy: 2.85366
Value Function Loss: 3.23482

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.01597
Policy Update Magnitude: 0.07528
Value Function Update Magnitude: 0.02521

Collected Steps per Second: 23,271.87720
Overall Steps per Second: 14,275.05577

Timestep Collection Time: 2.14877
Timestep Consumption Time: 1.35426
PPO Batch Consumption Time: 0.10218
Total Iteration Time: 3.50303

Cumulative Model Updates: 1,248
Cumulative Timesteps: 10,454,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,818.39180
Policy Entropy: 2.86334
Value Function Loss: 3.24398

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.05346
Policy Update Magnitude: 0.07747
Value Function Update Magnitude: 0.03825

Collected Steps per Second: 24,512.98813
Overall Steps per Second: 14,705.34712

Timestep Collection Time: 2.04055
Timestep Consumption Time: 1.36093
PPO Batch Consumption Time: 0.10237
Total Iteration Time: 3.40148

Cumulative Model Updates: 1,254
Cumulative Timesteps: 10,504,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 10504050...
Checkpoint 10504050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,588.34212
Policy Entropy: 2.84750
Value Function Loss: 3.25479

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.04930
Policy Update Magnitude: 0.06360
Value Function Update Magnitude: 0.05683

Collected Steps per Second: 23,518.32197
Overall Steps per Second: 14,221.60377

Timestep Collection Time: 2.12660
Timestep Consumption Time: 1.39017
PPO Batch Consumption Time: 0.10043
Total Iteration Time: 3.51676

Cumulative Model Updates: 1,260
Cumulative Timesteps: 10,554,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.96709
Policy Entropy: 2.83106
Value Function Loss: 3.29315

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.04647
Policy Update Magnitude: 0.06956
Value Function Update Magnitude: 0.04884

Collected Steps per Second: 22,748.84052
Overall Steps per Second: 14,342.17140

Timestep Collection Time: 2.19835
Timestep Consumption Time: 1.28857
PPO Batch Consumption Time: 0.09880
Total Iteration Time: 3.48692

Cumulative Model Updates: 1,266
Cumulative Timesteps: 10,604,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 10604074...
Checkpoint 10604074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,750.86047
Policy Entropy: 2.84369
Value Function Loss: 3.22317

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.01560
Policy Update Magnitude: 0.06194
Value Function Update Magnitude: 0.03817

Collected Steps per Second: 22,242.72032
Overall Steps per Second: 13,618.54158

Timestep Collection Time: 2.24856
Timestep Consumption Time: 1.42394
PPO Batch Consumption Time: 0.10167
Total Iteration Time: 3.67249

Cumulative Model Updates: 1,272
Cumulative Timesteps: 10,654,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.80517
Policy Entropy: 2.82171
Value Function Loss: 3.21096

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.03504
Policy Update Magnitude: 0.08526
Value Function Update Magnitude: 0.02765

Collected Steps per Second: 22,800.82685
Overall Steps per Second: 14,276.50544

Timestep Collection Time: 2.19492
Timestep Consumption Time: 1.31056
PPO Batch Consumption Time: 0.09422
Total Iteration Time: 3.50548

Cumulative Model Updates: 1,278
Cumulative Timesteps: 10,704,134

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 10704134...
Checkpoint 10704134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.16587
Policy Entropy: 2.86592
Value Function Loss: 3.16237

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.07756
Value Function Update Magnitude: 0.02233

Collected Steps per Second: 22,465.89373
Overall Steps per Second: 13,984.76368

Timestep Collection Time: 2.22613
Timestep Consumption Time: 1.35005
PPO Batch Consumption Time: 0.09608
Total Iteration Time: 3.57618

Cumulative Model Updates: 1,284
Cumulative Timesteps: 10,754,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.60367
Policy Entropy: 2.85677
Value Function Loss: 3.20771

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.01629
Policy Update Magnitude: 0.08077
Value Function Update Magnitude: 0.02083

Collected Steps per Second: 22,919.69522
Overall Steps per Second: 14,065.12267

Timestep Collection Time: 2.18284
Timestep Consumption Time: 1.37419
PPO Batch Consumption Time: 0.09859
Total Iteration Time: 3.55703

Cumulative Model Updates: 1,290
Cumulative Timesteps: 10,804,176

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 10804176...
Checkpoint 10804176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,870.46731
Policy Entropy: 2.87246
Value Function Loss: 3.21596

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.03254
Policy Update Magnitude: 0.07524
Value Function Update Magnitude: 0.02112

Collected Steps per Second: 22,150.53291
Overall Steps per Second: 14,009.96936

Timestep Collection Time: 2.25764
Timestep Consumption Time: 1.31182
PPO Batch Consumption Time: 0.10548
Total Iteration Time: 3.56946

Cumulative Model Updates: 1,296
Cumulative Timesteps: 10,854,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,762.12640
Policy Entropy: 2.83983
Value Function Loss: 3.23484

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.07765
Value Function Update Magnitude: 0.02163

Collected Steps per Second: 21,032.89323
Overall Steps per Second: 13,231.07798

Timestep Collection Time: 2.37742
Timestep Consumption Time: 1.40186
PPO Batch Consumption Time: 0.10392
Total Iteration Time: 3.77928

Cumulative Model Updates: 1,302
Cumulative Timesteps: 10,904,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 10904188...
Checkpoint 10904188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,801.57138
Policy Entropy: 2.84547
Value Function Loss: 3.25640

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02023
Policy Update Magnitude: 0.07558
Value Function Update Magnitude: 0.02212

Collected Steps per Second: 22,196.20060
Overall Steps per Second: 13,971.77248

Timestep Collection Time: 2.25300
Timestep Consumption Time: 1.32622
PPO Batch Consumption Time: 0.09962
Total Iteration Time: 3.57922

Cumulative Model Updates: 1,308
Cumulative Timesteps: 10,954,196

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.33567
Policy Entropy: 2.79886
Value Function Loss: 3.21965

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.04016
Policy Update Magnitude: 0.08681
Value Function Update Magnitude: 0.02189

Collected Steps per Second: 22,571.49093
Overall Steps per Second: 13,965.88406

Timestep Collection Time: 2.21696
Timestep Consumption Time: 1.36606
PPO Batch Consumption Time: 0.10092
Total Iteration Time: 3.58302

Cumulative Model Updates: 1,314
Cumulative Timesteps: 11,004,236

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 11004236...
Checkpoint 11004236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633.98414
Policy Entropy: 2.79671
Value Function Loss: 3.21093

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.04931
Policy Update Magnitude: 0.08025
Value Function Update Magnitude: 0.02129

Collected Steps per Second: 21,879.63601
Overall Steps per Second: 13,568.07336

Timestep Collection Time: 2.28550
Timestep Consumption Time: 1.40006
PPO Batch Consumption Time: 0.10380
Total Iteration Time: 3.68556

Cumulative Model Updates: 1,320
Cumulative Timesteps: 11,054,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585.65226
Policy Entropy: 2.77048
Value Function Loss: 3.21044

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02418
Policy Update Magnitude: 0.08971
Value Function Update Magnitude: 0.02216

Collected Steps per Second: 20,822.31058
Overall Steps per Second: 13,593.69174

Timestep Collection Time: 2.40204
Timestep Consumption Time: 1.27731
PPO Batch Consumption Time: 0.10277
Total Iteration Time: 3.67935

Cumulative Model Updates: 1,326
Cumulative Timesteps: 11,104,258

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 11104258...
Checkpoint 11104258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.14270
Policy Entropy: 2.75541
Value Function Loss: 3.24159

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.03093
Policy Update Magnitude: 0.08683
Value Function Update Magnitude: 0.02251

Collected Steps per Second: 22,948.90966
Overall Steps per Second: 14,145.65231

Timestep Collection Time: 2.17971
Timestep Consumption Time: 1.35650
PPO Batch Consumption Time: 0.10030
Total Iteration Time: 3.53621

Cumulative Model Updates: 1,332
Cumulative Timesteps: 11,154,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.25372
Policy Entropy: 2.74427
Value Function Loss: 3.27332

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.08372
Value Function Update Magnitude: 0.02180

Collected Steps per Second: 23,509.89312
Overall Steps per Second: 14,520.96967

Timestep Collection Time: 2.12804
Timestep Consumption Time: 1.31732
PPO Batch Consumption Time: 0.09438
Total Iteration Time: 3.44536

Cumulative Model Updates: 1,338
Cumulative Timesteps: 11,204,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 11204310...
Checkpoint 11204310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,778.50851
Policy Entropy: 2.75265
Value Function Loss: 3.27530

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.08589
Value Function Update Magnitude: 0.02134

Collected Steps per Second: 23,920.26782
Overall Steps per Second: 14,341.26086

Timestep Collection Time: 2.09028
Timestep Consumption Time: 1.39617
PPO Batch Consumption Time: 0.10284
Total Iteration Time: 3.48644

Cumulative Model Updates: 1,344
Cumulative Timesteps: 11,254,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.36338
Policy Entropy: 2.76030
Value Function Loss: 3.28473

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.03517
Policy Update Magnitude: 0.07916
Value Function Update Magnitude: 0.02142

Collected Steps per Second: 22,952.62443
Overall Steps per Second: 14,010.22407

Timestep Collection Time: 2.17857
Timestep Consumption Time: 1.39053
PPO Batch Consumption Time: 0.10371
Total Iteration Time: 3.56911

Cumulative Model Updates: 1,350
Cumulative Timesteps: 11,304,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 11304314...
Checkpoint 11304314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622.57492
Policy Entropy: 2.75704
Value Function Loss: 3.29100

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02078
Policy Update Magnitude: 0.08230
Value Function Update Magnitude: 0.02046

Collected Steps per Second: 22,753.28582
Overall Steps per Second: 14,535.13789

Timestep Collection Time: 2.19915
Timestep Consumption Time: 1.24340
PPO Batch Consumption Time: 0.09279
Total Iteration Time: 3.44255

Cumulative Model Updates: 1,356
Cumulative Timesteps: 11,354,352

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.66476
Policy Entropy: 2.77360
Value Function Loss: 3.28744

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.03661
Policy Update Magnitude: 0.07679
Value Function Update Magnitude: 0.02100

Collected Steps per Second: 22,190.97004
Overall Steps per Second: 13,890.76678

Timestep Collection Time: 2.25371
Timestep Consumption Time: 1.34667
PPO Batch Consumption Time: 0.09797
Total Iteration Time: 3.60038

Cumulative Model Updates: 1,362
Cumulative Timesteps: 11,404,364

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 11404364...
Checkpoint 11404364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,555.44637
Policy Entropy: 2.78161
Value Function Loss: 3.29179

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.01457
Policy Update Magnitude: 0.07269
Value Function Update Magnitude: 0.02149

Collected Steps per Second: 22,642.26431
Overall Steps per Second: 14,128.93622

Timestep Collection Time: 2.20852
Timestep Consumption Time: 1.33074
PPO Batch Consumption Time: 0.09836
Total Iteration Time: 3.53926

Cumulative Model Updates: 1,368
Cumulative Timesteps: 11,454,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636.58194
Policy Entropy: 2.79595
Value Function Loss: 3.26989

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.01739
Policy Update Magnitude: 0.07966
Value Function Update Magnitude: 0.02817

Collected Steps per Second: 20,902.73280
Overall Steps per Second: 13,499.90084

Timestep Collection Time: 2.39318
Timestep Consumption Time: 1.31233
PPO Batch Consumption Time: 0.10172
Total Iteration Time: 3.70551

Cumulative Model Updates: 1,374
Cumulative Timesteps: 11,504,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 11504394...
Checkpoint 11504394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.60911
Policy Entropy: 2.82235
Value Function Loss: 3.26471

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02212
Policy Update Magnitude: 0.07933
Value Function Update Magnitude: 0.04347

Collected Steps per Second: 22,559.21275
Overall Steps per Second: 13,710.90693

Timestep Collection Time: 2.21719
Timestep Consumption Time: 1.43086
PPO Batch Consumption Time: 0.10546
Total Iteration Time: 3.64804

Cumulative Model Updates: 1,380
Cumulative Timesteps: 11,554,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.00213
Policy Entropy: 2.82232
Value Function Loss: 3.19154

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.07411
Value Function Update Magnitude: 0.05372

Collected Steps per Second: 21,018.74552
Overall Steps per Second: 13,181.31325

Timestep Collection Time: 2.37930
Timestep Consumption Time: 1.41470
PPO Batch Consumption Time: 0.10573
Total Iteration Time: 3.79401

Cumulative Model Updates: 1,386
Cumulative Timesteps: 11,604,422

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 11604422...
Checkpoint 11604422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.34646
Policy Entropy: 2.83957
Value Function Loss: 3.18103

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.02252
Policy Update Magnitude: 0.06945
Value Function Update Magnitude: 0.05761

Collected Steps per Second: 20,310.91714
Overall Steps per Second: 12,534.61600

Timestep Collection Time: 2.46331
Timestep Consumption Time: 1.52820
PPO Batch Consumption Time: 0.09715
Total Iteration Time: 3.99151

Cumulative Model Updates: 1,392
Cumulative Timesteps: 11,654,454

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.98928
Policy Entropy: 2.82402
Value Function Loss: 3.18237

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.01772
Policy Update Magnitude: 0.08239
Value Function Update Magnitude: 0.04264

Collected Steps per Second: 20,069.69281
Overall Steps per Second: 12,685.35658

Timestep Collection Time: 2.49311
Timestep Consumption Time: 1.45128
PPO Batch Consumption Time: 0.10574
Total Iteration Time: 3.94439

Cumulative Model Updates: 1,398
Cumulative Timesteps: 11,704,490

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 11704490...
Checkpoint 11704490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.44061
Policy Entropy: 2.81917
Value Function Loss: 3.17346

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.07662
Value Function Update Magnitude: 0.05359

Collected Steps per Second: 20,425.51162
Overall Steps per Second: 13,279.63135

Timestep Collection Time: 2.44851
Timestep Consumption Time: 1.31756
PPO Batch Consumption Time: 0.10673
Total Iteration Time: 3.76607

Cumulative Model Updates: 1,404
Cumulative Timesteps: 11,754,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.53234
Policy Entropy: 2.82328
Value Function Loss: 3.21114

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.01468
Policy Update Magnitude: 0.07142
Value Function Update Magnitude: 0.04218

Collected Steps per Second: 23,416.32486
Overall Steps per Second: 14,572.89208

Timestep Collection Time: 2.13620
Timestep Consumption Time: 1.29634
PPO Batch Consumption Time: 0.08999
Total Iteration Time: 3.43254

Cumulative Model Updates: 1,410
Cumulative Timesteps: 11,804,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 11804524...
Checkpoint 11804524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676.67112
Policy Entropy: 2.82941
Value Function Loss: 3.24038

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.07411
Value Function Update Magnitude: 0.05356

Collected Steps per Second: 22,320.10589
Overall Steps per Second: 14,076.32179

Timestep Collection Time: 2.24112
Timestep Consumption Time: 1.31251
PPO Batch Consumption Time: 0.09576
Total Iteration Time: 3.55363

Cumulative Model Updates: 1,416
Cumulative Timesteps: 11,854,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,725.67202
Policy Entropy: 2.85376
Value Function Loss: 3.31078

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.03879
Policy Update Magnitude: 0.06934
Value Function Update Magnitude: 0.05814

Collected Steps per Second: 23,745.20374
Overall Steps per Second: 14,432.34216

Timestep Collection Time: 2.10661
Timestep Consumption Time: 1.35935
PPO Batch Consumption Time: 0.09760
Total Iteration Time: 3.46597

Cumulative Model Updates: 1,422
Cumulative Timesteps: 11,904,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 11904568...
Checkpoint 11904568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.70427
Policy Entropy: 2.86231
Value Function Loss: 3.25654

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.02778
Policy Update Magnitude: 0.08600
Value Function Update Magnitude: 0.04354

Collected Steps per Second: 22,940.44478
Overall Steps per Second: 14,323.55684

Timestep Collection Time: 2.18052
Timestep Consumption Time: 1.31177
PPO Batch Consumption Time: 0.09496
Total Iteration Time: 3.49229

Cumulative Model Updates: 1,428
Cumulative Timesteps: 11,954,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.79331
Policy Entropy: 2.85809
Value Function Loss: 3.24746

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.03779
Policy Update Magnitude: 0.07885
Value Function Update Magnitude: 0.04756

Collected Steps per Second: 23,039.78018
Overall Steps per Second: 14,690.95219

Timestep Collection Time: 2.17025
Timestep Consumption Time: 1.23335
PPO Batch Consumption Time: 0.09501
Total Iteration Time: 3.40359

Cumulative Model Updates: 1,434
Cumulative Timesteps: 12,004,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 12004592...
Checkpoint 12004592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.39372
Policy Entropy: 2.86311
Value Function Loss: 3.29832

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.04065
Policy Update Magnitude: 0.07315
Value Function Update Magnitude: 0.06492

Collected Steps per Second: 23,667.62645
Overall Steps per Second: 14,447.84488

Timestep Collection Time: 2.11301
Timestep Consumption Time: 1.34840
PPO Batch Consumption Time: 0.10207
Total Iteration Time: 3.46142

Cumulative Model Updates: 1,440
Cumulative Timesteps: 12,054,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821.96662
Policy Entropy: 2.85913
Value Function Loss: 3.30323

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02846
Policy Update Magnitude: 0.07680
Value Function Update Magnitude: 0.07580

Collected Steps per Second: 20,985.60734
Overall Steps per Second: 13,523.37577

Timestep Collection Time: 2.38478
Timestep Consumption Time: 1.31593
PPO Batch Consumption Time: 0.09042
Total Iteration Time: 3.70070

Cumulative Model Updates: 1,446
Cumulative Timesteps: 12,104,648

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 12104648...
Checkpoint 12104648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.96293
Policy Entropy: 2.89720
Value Function Loss: 3.32070

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.08099
Value Function Update Magnitude: 0.04663

Collected Steps per Second: 22,924.40342
Overall Steps per Second: 13,983.63675

Timestep Collection Time: 2.18161
Timestep Consumption Time: 1.39486
PPO Batch Consumption Time: 0.09836
Total Iteration Time: 3.57647

Cumulative Model Updates: 1,452
Cumulative Timesteps: 12,154,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.02285
Policy Entropy: 2.89300
Value Function Loss: 3.24908

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.01511
Policy Update Magnitude: 0.08040
Value Function Update Magnitude: 0.03393

Collected Steps per Second: 21,814.41466
Overall Steps per Second: 13,324.13223

Timestep Collection Time: 2.29215
Timestep Consumption Time: 1.46059
PPO Batch Consumption Time: 0.10712
Total Iteration Time: 3.75274

Cumulative Model Updates: 1,458
Cumulative Timesteps: 12,204,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 12204662...
Checkpoint 12204662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793.48547
Policy Entropy: 2.89144
Value Function Loss: 3.27555

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02637
Policy Update Magnitude: 0.07899
Value Function Update Magnitude: 0.02944

Collected Steps per Second: 21,249.95631
Overall Steps per Second: 13,467.53747

Timestep Collection Time: 2.35445
Timestep Consumption Time: 1.36056
PPO Batch Consumption Time: 0.10573
Total Iteration Time: 3.71501

Cumulative Model Updates: 1,464
Cumulative Timesteps: 12,254,694

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729.72196
Policy Entropy: 2.86822
Value Function Loss: 3.27820

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.01796
Policy Update Magnitude: 0.07545
Value Function Update Magnitude: 0.03052

Collected Steps per Second: 19,669.31887
Overall Steps per Second: 12,557.09729

Timestep Collection Time: 2.54295
Timestep Consumption Time: 1.44030
PPO Batch Consumption Time: 0.10586
Total Iteration Time: 3.98325

Cumulative Model Updates: 1,470
Cumulative Timesteps: 12,304,712

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 12304712...
Checkpoint 12304712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680.15525
Policy Entropy: 2.87903
Value Function Loss: 3.27302

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.03451
Policy Update Magnitude: 0.07811
Value Function Update Magnitude: 0.03524

Collected Steps per Second: 22,385.76105
Overall Steps per Second: 13,853.55784

Timestep Collection Time: 2.23428
Timestep Consumption Time: 1.37606
PPO Batch Consumption Time: 0.10021
Total Iteration Time: 3.61034

Cumulative Model Updates: 1,476
Cumulative Timesteps: 12,354,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.55036
Policy Entropy: 2.87802
Value Function Loss: 3.26398

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 0.07011
Value Function Update Magnitude: 0.04328

Collected Steps per Second: 22,519.99389
Overall Steps per Second: 13,707.83394

Timestep Collection Time: 2.22052
Timestep Consumption Time: 1.42747
PPO Batch Consumption Time: 0.09776
Total Iteration Time: 3.64799

Cumulative Model Updates: 1,482
Cumulative Timesteps: 12,404,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 12404734...
Checkpoint 12404734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.44447
Policy Entropy: 2.87687
Value Function Loss: 3.21124

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.03135
Policy Update Magnitude: 0.07288
Value Function Update Magnitude: 0.04218

Collected Steps per Second: 20,730.96265
Overall Steps per Second: 12,967.26149

Timestep Collection Time: 2.41311
Timestep Consumption Time: 1.44476
PPO Batch Consumption Time: 0.10353
Total Iteration Time: 3.85787

Cumulative Model Updates: 1,488
Cumulative Timesteps: 12,454,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,609.70223
Policy Entropy: 2.86350
Value Function Loss: 3.17653

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.01423
Policy Update Magnitude: 0.07603
Value Function Update Magnitude: 0.05238

Collected Steps per Second: 20,928.49822
Overall Steps per Second: 13,604.15098

Timestep Collection Time: 2.38976
Timestep Consumption Time: 1.28662
PPO Batch Consumption Time: 0.09376
Total Iteration Time: 3.67638

Cumulative Model Updates: 1,494
Cumulative Timesteps: 12,504,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 12504774...
Checkpoint 12504774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,640.72616
Policy Entropy: 2.84636
Value Function Loss: 3.18569

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.01774
Policy Update Magnitude: 0.07359
Value Function Update Magnitude: 0.03998

Collected Steps per Second: 20,659.90206
Overall Steps per Second: 13,253.71034

Timestep Collection Time: 2.42015
Timestep Consumption Time: 1.35238
PPO Batch Consumption Time: 0.09401
Total Iteration Time: 3.77253

Cumulative Model Updates: 1,500
Cumulative Timesteps: 12,554,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665.66197
Policy Entropy: 2.85241
Value Function Loss: 3.17328

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.02919
Policy Update Magnitude: 0.07455
Value Function Update Magnitude: 0.03092

Collected Steps per Second: 19,658.98179
Overall Steps per Second: 12,641.93492

Timestep Collection Time: 2.54449
Timestep Consumption Time: 1.41235
PPO Batch Consumption Time: 0.10441
Total Iteration Time: 3.95683

Cumulative Model Updates: 1,506
Cumulative Timesteps: 12,604,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 12604796...
Checkpoint 12604796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,600.44360
Policy Entropy: 2.85565
Value Function Loss: 3.23043

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.03542
Policy Update Magnitude: 0.07930
Value Function Update Magnitude: 0.02728

Collected Steps per Second: 22,740.67824
Overall Steps per Second: 13,903.07550

Timestep Collection Time: 2.19923
Timestep Consumption Time: 1.39796
PPO Batch Consumption Time: 0.10057
Total Iteration Time: 3.59719

Cumulative Model Updates: 1,512
Cumulative Timesteps: 12,654,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.23822
Policy Entropy: 2.86043
Value Function Loss: 3.16513

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.02364
Policy Update Magnitude: 0.07756
Value Function Update Magnitude: 0.04186

Collected Steps per Second: 21,885.09703
Overall Steps per Second: 13,530.26679

Timestep Collection Time: 2.28557
Timestep Consumption Time: 1.41132
PPO Batch Consumption Time: 0.10182
Total Iteration Time: 3.69690

Cumulative Model Updates: 1,518
Cumulative Timesteps: 12,704,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 12704828...
Checkpoint 12704828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,519.94889
Policy Entropy: 2.88209
Value Function Loss: 3.16030

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.04307
Policy Update Magnitude: 0.07848
Value Function Update Magnitude: 0.06572

Collected Steps per Second: 21,453.26311
Overall Steps per Second: 13,723.55714

Timestep Collection Time: 2.33289
Timestep Consumption Time: 1.31398
PPO Batch Consumption Time: 0.09939
Total Iteration Time: 3.64687

Cumulative Model Updates: 1,524
Cumulative Timesteps: 12,754,876

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676.31332
Policy Entropy: 2.87698
Value Function Loss: 3.14466

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.02245
Policy Update Magnitude: 0.08546
Value Function Update Magnitude: 0.07227

Collected Steps per Second: 20,996.98471
Overall Steps per Second: 13,193.46571

Timestep Collection Time: 2.38129
Timestep Consumption Time: 1.40846
PPO Batch Consumption Time: 0.10065
Total Iteration Time: 3.78975

Cumulative Model Updates: 1,530
Cumulative Timesteps: 12,804,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 12804876...
Checkpoint 12804876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.84446
Policy Entropy: 2.88525
Value Function Loss: 3.17742

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.05706
Policy Update Magnitude: 0.08270
Value Function Update Magnitude: 0.06350

Collected Steps per Second: 22,495.26674
Overall Steps per Second: 14,027.34244

Timestep Collection Time: 2.22500
Timestep Consumption Time: 1.34317
PPO Batch Consumption Time: 0.09359
Total Iteration Time: 3.56817

Cumulative Model Updates: 1,536
Cumulative Timesteps: 12,854,928

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551.83836
Policy Entropy: 2.88982
Value Function Loss: 3.15116

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05853
Policy Update Magnitude: 0.09936
Value Function Update Magnitude: 0.06049

Collected Steps per Second: 22,774.24188
Overall Steps per Second: 13,960.97800

Timestep Collection Time: 2.19564
Timestep Consumption Time: 1.38606
PPO Batch Consumption Time: 0.09854
Total Iteration Time: 3.58170

Cumulative Model Updates: 1,542
Cumulative Timesteps: 12,904,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 12904932...
Checkpoint 12904932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779.09081
Policy Entropy: 2.89437
Value Function Loss: 3.18793

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.05095
Policy Update Magnitude: 0.07465
Value Function Update Magnitude: 0.05793

Collected Steps per Second: 22,610.83349
Overall Steps per Second: 13,958.81380

Timestep Collection Time: 2.21239
Timestep Consumption Time: 1.37129
PPO Batch Consumption Time: 0.09217
Total Iteration Time: 3.58369

Cumulative Model Updates: 1,548
Cumulative Timesteps: 12,954,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642.85318
Policy Entropy: 2.87240
Value Function Loss: 3.17286

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.04327
Policy Update Magnitude: 0.07796
Value Function Update Magnitude: 0.05037

Collected Steps per Second: 23,067.25048
Overall Steps per Second: 14,765.29596

Timestep Collection Time: 2.16766
Timestep Consumption Time: 1.21879
PPO Batch Consumption Time: 0.09033
Total Iteration Time: 3.38645

Cumulative Model Updates: 1,554
Cumulative Timesteps: 13,004,958

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 13004958...
Checkpoint 13004958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697.69343
Policy Entropy: 2.86903
Value Function Loss: 3.25346

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.01830
Policy Update Magnitude: 0.07100
Value Function Update Magnitude: 0.03931

Collected Steps per Second: 23,632.80044
Overall Steps per Second: 14,369.45793

Timestep Collection Time: 2.11613
Timestep Consumption Time: 1.36417
PPO Batch Consumption Time: 0.10095
Total Iteration Time: 3.48030

Cumulative Model Updates: 1,560
Cumulative Timesteps: 13,054,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551.58338
Policy Entropy: 2.86303
Value Function Loss: 3.14708

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.02802
Policy Update Magnitude: 0.08565
Value Function Update Magnitude: 0.04716

Collected Steps per Second: 23,352.35840
Overall Steps per Second: 14,440.95513

Timestep Collection Time: 2.14214
Timestep Consumption Time: 1.32190
PPO Batch Consumption Time: 0.09891
Total Iteration Time: 3.46404

Cumulative Model Updates: 1,566
Cumulative Timesteps: 13,104,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 13104992...
Checkpoint 13104992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.74763
Policy Entropy: 2.84544
Value Function Loss: 3.17867

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.03853
Policy Update Magnitude: 0.06710
Value Function Update Magnitude: 0.03112

Collected Steps per Second: 23,147.79454
Overall Steps per Second: 14,752.63522

Timestep Collection Time: 2.16029
Timestep Consumption Time: 1.22934
PPO Batch Consumption Time: 0.09127
Total Iteration Time: 3.38963

Cumulative Model Updates: 1,572
Cumulative Timesteps: 13,154,998

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528.62600
Policy Entropy: 2.84921
Value Function Loss: 3.15254

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.02207
Policy Update Magnitude: 0.07134
Value Function Update Magnitude: 0.02534

Collected Steps per Second: 22,485.05840
Overall Steps per Second: 14,059.33700

Timestep Collection Time: 2.22441
Timestep Consumption Time: 1.33308
PPO Batch Consumption Time: 0.09630
Total Iteration Time: 3.55749

Cumulative Model Updates: 1,578
Cumulative Timesteps: 13,205,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 13205014...
Checkpoint 13205014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,711.52323
Policy Entropy: 2.86548
Value Function Loss: 3.19583

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.07593
Value Function Update Magnitude: 0.02383

Collected Steps per Second: 22,398.50275
Overall Steps per Second: 14,001.50037

Timestep Collection Time: 2.23301
Timestep Consumption Time: 1.33918
PPO Batch Consumption Time: 0.09590
Total Iteration Time: 3.57219

Cumulative Model Updates: 1,584
Cumulative Timesteps: 13,255,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.92136
Policy Entropy: 2.85558
Value Function Loss: 3.17571

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.04678
Policy Update Magnitude: 0.07408
Value Function Update Magnitude: 0.02688

Collected Steps per Second: 23,465.81855
Overall Steps per Second: 13,975.51561

Timestep Collection Time: 2.13153
Timestep Consumption Time: 1.44745
PPO Batch Consumption Time: 0.10278
Total Iteration Time: 3.57897

Cumulative Model Updates: 1,590
Cumulative Timesteps: 13,305,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 13305048...
Checkpoint 13305048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567.39207
Policy Entropy: 2.86993
Value Function Loss: 3.12224

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.02056
Policy Update Magnitude: 0.08256
Value Function Update Magnitude: 0.03371

Collected Steps per Second: 22,703.23780
Overall Steps per Second: 13,981.39013

Timestep Collection Time: 2.20418
Timestep Consumption Time: 1.37501
PPO Batch Consumption Time: 0.10244
Total Iteration Time: 3.57919

Cumulative Model Updates: 1,596
Cumulative Timesteps: 13,355,090

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.15211
Policy Entropy: 2.86808
Value Function Loss: 3.10186

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.03182
Policy Update Magnitude: 0.08212
Value Function Update Magnitude: 0.04263

Collected Steps per Second: 22,229.39392
Overall Steps per Second: 14,007.80150

Timestep Collection Time: 2.24927
Timestep Consumption Time: 1.32017
PPO Batch Consumption Time: 0.10479
Total Iteration Time: 3.56944

Cumulative Model Updates: 1,602
Cumulative Timesteps: 13,405,090

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 13405090...
Checkpoint 13405090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.68617
Policy Entropy: 2.86557
Value Function Loss: 3.06386

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.02473
Policy Update Magnitude: 0.07187
Value Function Update Magnitude: 0.03351

Collected Steps per Second: 22,096.07938
Overall Steps per Second: 13,559.10480

Timestep Collection Time: 2.26366
Timestep Consumption Time: 1.42523
PPO Batch Consumption Time: 0.10225
Total Iteration Time: 3.68889

Cumulative Model Updates: 1,608
Cumulative Timesteps: 13,455,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.25779
Policy Entropy: 2.86453
Value Function Loss: 3.10136

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.03305
Policy Update Magnitude: 0.08884
Value Function Update Magnitude: 0.03372

Collected Steps per Second: 22,218.94632
Overall Steps per Second: 13,819.79567

Timestep Collection Time: 2.25078
Timestep Consumption Time: 1.36794
PPO Batch Consumption Time: 0.10157
Total Iteration Time: 3.61872

Cumulative Model Updates: 1,614
Cumulative Timesteps: 13,505,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 13505118...
Checkpoint 13505118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.22226
Policy Entropy: 2.86343
Value Function Loss: 3.10391

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.05755
Policy Update Magnitude: 0.07056
Value Function Update Magnitude: 0.02541

Collected Steps per Second: 22,873.37050
Overall Steps per Second: 13,949.01785

Timestep Collection Time: 2.18787
Timestep Consumption Time: 1.39976
PPO Batch Consumption Time: 0.10286
Total Iteration Time: 3.58764

Cumulative Model Updates: 1,620
Cumulative Timesteps: 13,555,162

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.90942
Policy Entropy: 2.87810
Value Function Loss: 3.12720

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.02269
Policy Update Magnitude: 0.06803
Value Function Update Magnitude: 0.03983

Collected Steps per Second: 23,062.31176
Overall Steps per Second: 14,096.00089

Timestep Collection Time: 2.16934
Timestep Consumption Time: 1.37989
PPO Batch Consumption Time: 0.10386
Total Iteration Time: 3.54923

Cumulative Model Updates: 1,626
Cumulative Timesteps: 13,605,192

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 13605192...
Checkpoint 13605192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698.23950
Policy Entropy: 2.86943
Value Function Loss: 3.16071

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.01087
Policy Update Magnitude: 0.07487
Value Function Update Magnitude: 0.05834

Collected Steps per Second: 20,719.87546
Overall Steps per Second: 13,567.22158

Timestep Collection Time: 2.41420
Timestep Consumption Time: 1.27277
PPO Batch Consumption Time: 0.09383
Total Iteration Time: 3.68697

Cumulative Model Updates: 1,632
Cumulative Timesteps: 13,655,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,572.87266
Policy Entropy: 2.88291
Value Function Loss: 3.17824

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.02692
Policy Update Magnitude: 0.07316
Value Function Update Magnitude: 0.07192

Collected Steps per Second: 22,079.99192
Overall Steps per Second: 13,984.82991

Timestep Collection Time: 2.26531
Timestep Consumption Time: 1.31128
PPO Batch Consumption Time: 0.09403
Total Iteration Time: 3.57659

Cumulative Model Updates: 1,638
Cumulative Timesteps: 13,705,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 13705232...
Checkpoint 13705232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.60796
Policy Entropy: 2.86794
Value Function Loss: 3.19675

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.03076
Policy Update Magnitude: 0.07044
Value Function Update Magnitude: 0.05384

Collected Steps per Second: 22,545.68582
Overall Steps per Second: 14,024.75552

Timestep Collection Time: 2.21887
Timestep Consumption Time: 1.34811
PPO Batch Consumption Time: 0.10131
Total Iteration Time: 3.56698

Cumulative Model Updates: 1,644
Cumulative Timesteps: 13,755,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672.31797
Policy Entropy: 2.88764
Value Function Loss: 3.15480

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.02946
Policy Update Magnitude: 0.06392
Value Function Update Magnitude: 0.03419

Collected Steps per Second: 23,293.75960
Overall Steps per Second: 14,226.37601

Timestep Collection Time: 2.14658
Timestep Consumption Time: 1.36816
PPO Batch Consumption Time: 0.10109
Total Iteration Time: 3.51474

Cumulative Model Updates: 1,650
Cumulative Timesteps: 13,805,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 13805260...
Checkpoint 13805260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,677.26895
Policy Entropy: 2.87827
Value Function Loss: 3.14358

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.02082
Policy Update Magnitude: 0.07297
Value Function Update Magnitude: 0.02505

Collected Steps per Second: 23,449.02167
Overall Steps per Second: 14,113.55078

Timestep Collection Time: 2.13348
Timestep Consumption Time: 1.41120
PPO Batch Consumption Time: 0.10515
Total Iteration Time: 3.54468

Cumulative Model Updates: 1,656
Cumulative Timesteps: 13,855,288

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648.08694
Policy Entropy: 2.89363
Value Function Loss: 3.11778

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.04618
Policy Update Magnitude: 0.07929
Value Function Update Magnitude: 0.02118

Collected Steps per Second: 23,132.00954
Overall Steps per Second: 14,424.11565

Timestep Collection Time: 2.16254
Timestep Consumption Time: 1.30554
PPO Batch Consumption Time: 0.10314
Total Iteration Time: 3.46808

Cumulative Model Updates: 1,662
Cumulative Timesteps: 13,905,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 13905312...
Checkpoint 13905312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.76960
Policy Entropy: 2.86225
Value Function Loss: 3.14630

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.02843
Policy Update Magnitude: 0.07040
Value Function Update Magnitude: 0.02111

Collected Steps per Second: 22,785.29448
Overall Steps per Second: 13,955.30240

Timestep Collection Time: 2.19475
Timestep Consumption Time: 1.38869
PPO Batch Consumption Time: 0.10148
Total Iteration Time: 3.58344

Cumulative Model Updates: 1,668
Cumulative Timesteps: 13,955,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.79507
Policy Entropy: 2.86980
Value Function Loss: 3.15231

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.03498
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.02380

Collected Steps per Second: 23,102.49180
Overall Steps per Second: 14,177.22650

Timestep Collection Time: 2.16487
Timestep Consumption Time: 1.36290
PPO Batch Consumption Time: 0.10130
Total Iteration Time: 3.52777

Cumulative Model Updates: 1,674
Cumulative Timesteps: 14,005,334

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 14005334...
Checkpoint 14005334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.65061
Policy Entropy: 2.84908
Value Function Loss: 3.20066

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01490
Policy Update Magnitude: 0.06845
Value Function Update Magnitude: 0.02377

Collected Steps per Second: 22,775.55126
Overall Steps per Second: 13,955.23515

Timestep Collection Time: 2.19701
Timestep Consumption Time: 1.38860
PPO Batch Consumption Time: 0.10263
Total Iteration Time: 3.58561

Cumulative Model Updates: 1,680
Cumulative Timesteps: 14,055,372

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716.29147
Policy Entropy: 2.84335
Value Function Loss: 3.20157

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.03637
Policy Update Magnitude: 0.06625
Value Function Update Magnitude: 0.02790

Collected Steps per Second: 22,089.42493
Overall Steps per Second: 13,710.03530

Timestep Collection Time: 2.26362
Timestep Consumption Time: 1.38349
PPO Batch Consumption Time: 0.09709
Total Iteration Time: 3.64711

Cumulative Model Updates: 1,686
Cumulative Timesteps: 14,105,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 14105374...
Checkpoint 14105374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,768.67371
Policy Entropy: 2.82768
Value Function Loss: 3.26959

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.01976
Policy Update Magnitude: 0.06928
Value Function Update Magnitude: 0.03596

Collected Steps per Second: 22,576.35649
Overall Steps per Second: 14,214.89200

Timestep Collection Time: 2.21506
Timestep Consumption Time: 1.30294
PPO Batch Consumption Time: 0.10616
Total Iteration Time: 3.51800

Cumulative Model Updates: 1,692
Cumulative Timesteps: 14,155,382

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,845.67989
Policy Entropy: 2.83385
Value Function Loss: 3.16256

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02661
Policy Update Magnitude: 0.07322
Value Function Update Magnitude: 0.06590

Collected Steps per Second: 21,918.36828
Overall Steps per Second: 13,702.04084

Timestep Collection Time: 2.28156
Timestep Consumption Time: 1.36812
PPO Batch Consumption Time: 0.09700
Total Iteration Time: 3.64968

Cumulative Model Updates: 1,698
Cumulative Timesteps: 14,205,390

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 14205390...
Checkpoint 14205390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.12545
Policy Entropy: 2.81414
Value Function Loss: 3.14877

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.02433
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.09474

Collected Steps per Second: 20,288.78954
Overall Steps per Second: 12,925.94670

Timestep Collection Time: 2.46540
Timestep Consumption Time: 1.40433
PPO Batch Consumption Time: 0.10534
Total Iteration Time: 3.86974

Cumulative Model Updates: 1,704
Cumulative Timesteps: 14,255,410

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707.29797
Policy Entropy: 2.79411
Value Function Loss: 3.05815

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.02956
Policy Update Magnitude: 0.06711
Value Function Update Magnitude: 0.10704

Collected Steps per Second: 23,977.21086
Overall Steps per Second: 14,512.96256

Timestep Collection Time: 2.08573
Timestep Consumption Time: 1.36015
PPO Batch Consumption Time: 0.10192
Total Iteration Time: 3.44588

Cumulative Model Updates: 1,710
Cumulative Timesteps: 14,305,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 14305420...
Checkpoint 14305420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.87148
Policy Entropy: 2.79363
Value Function Loss: 3.15633

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.01724
Policy Update Magnitude: 0.06586
Value Function Update Magnitude: 0.08918

Collected Steps per Second: 23,123.19557
Overall Steps per Second: 14,178.02740

Timestep Collection Time: 2.16346
Timestep Consumption Time: 1.36496
PPO Batch Consumption Time: 0.10171
Total Iteration Time: 3.52842

Cumulative Model Updates: 1,716
Cumulative Timesteps: 14,355,446

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596.60891
Policy Entropy: 2.76883
Value Function Loss: 3.15715

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.01941
Policy Update Magnitude: 0.07697
Value Function Update Magnitude: 0.06856

Collected Steps per Second: 23,493.04895
Overall Steps per Second: 14,579.75461

Timestep Collection Time: 2.12829
Timestep Consumption Time: 1.30112
PPO Batch Consumption Time: 0.09784
Total Iteration Time: 3.42941

Cumulative Model Updates: 1,722
Cumulative Timesteps: 14,405,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 14405446...
Checkpoint 14405446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.31978
Policy Entropy: 2.79557
Value Function Loss: 3.20753

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.03124
Policy Update Magnitude: 0.07283
Value Function Update Magnitude: 0.04759

Collected Steps per Second: 23,599.95009
Overall Steps per Second: 14,641.79583

Timestep Collection Time: 2.11967
Timestep Consumption Time: 1.29686
PPO Batch Consumption Time: 0.09284
Total Iteration Time: 3.41652

Cumulative Model Updates: 1,728
Cumulative Timesteps: 14,455,470

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.87276
Policy Entropy: 2.78191
Value Function Loss: 3.22378

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02069
Policy Update Magnitude: 0.06340
Value Function Update Magnitude: 0.03388

Collected Steps per Second: 22,856.74811
Overall Steps per Second: 14,101.75118

Timestep Collection Time: 2.18876
Timestep Consumption Time: 1.35888
PPO Batch Consumption Time: 0.10238
Total Iteration Time: 3.54764

Cumulative Model Updates: 1,734
Cumulative Timesteps: 14,505,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 14505498...
Checkpoint 14505498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.64889
Policy Entropy: 2.79571
Value Function Loss: 3.21108

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.01738
Policy Update Magnitude: 0.07674
Value Function Update Magnitude: 0.03334

Collected Steps per Second: 22,826.49038
Overall Steps per Second: 14,043.60138

Timestep Collection Time: 2.19105
Timestep Consumption Time: 1.37029
PPO Batch Consumption Time: 0.10151
Total Iteration Time: 3.56134

Cumulative Model Updates: 1,740
Cumulative Timesteps: 14,555,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.01631
Policy Entropy: 2.77496
Value Function Loss: 3.20456

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.04239
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.05601

Collected Steps per Second: 21,922.73254
Overall Steps per Second: 13,740.57510

Timestep Collection Time: 2.28110
Timestep Consumption Time: 1.35834
PPO Batch Consumption Time: 0.09867
Total Iteration Time: 3.63944

Cumulative Model Updates: 1,746
Cumulative Timesteps: 14,605,520

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 14605520...
Checkpoint 14605520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690.68619
Policy Entropy: 2.76546
Value Function Loss: 3.15506

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.02299
Policy Update Magnitude: 0.06619
Value Function Update Magnitude: 0.07495

Collected Steps per Second: 21,997.93620
Overall Steps per Second: 14,168.25538

Timestep Collection Time: 2.27503
Timestep Consumption Time: 1.25723
PPO Batch Consumption Time: 0.09751
Total Iteration Time: 3.53226

Cumulative Model Updates: 1,752
Cumulative Timesteps: 14,655,566

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.69001
Policy Entropy: 2.75678
Value Function Loss: 3.20732

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.03769
Policy Update Magnitude: 0.06379
Value Function Update Magnitude: 0.06964

Collected Steps per Second: 23,455.39692
Overall Steps per Second: 14,360.21990

Timestep Collection Time: 2.13213
Timestep Consumption Time: 1.35041
PPO Batch Consumption Time: 0.10028
Total Iteration Time: 3.48254

Cumulative Model Updates: 1,758
Cumulative Timesteps: 14,705,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 14705576...
Checkpoint 14705576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676.93994
Policy Entropy: 2.75564
Value Function Loss: 3.18629

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.01898
Policy Update Magnitude: 0.07255
Value Function Update Magnitude: 0.04906

Collected Steps per Second: 22,923.86274
Overall Steps per Second: 14,377.99766

Timestep Collection Time: 2.18174
Timestep Consumption Time: 1.29677
PPO Batch Consumption Time: 0.09424
Total Iteration Time: 3.47851

Cumulative Model Updates: 1,764
Cumulative Timesteps: 14,755,590

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.89320
Policy Entropy: 2.76066
Value Function Loss: 3.18950

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 0.06427
Value Function Update Magnitude: 0.02907

Collected Steps per Second: 23,591.46067
Overall Steps per Second: 14,292.53945

Timestep Collection Time: 2.11958
Timestep Consumption Time: 1.37903
PPO Batch Consumption Time: 0.10330
Total Iteration Time: 3.49861

Cumulative Model Updates: 1,770
Cumulative Timesteps: 14,805,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 14805594...
Checkpoint 14805594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,490.07193
Policy Entropy: 2.76642
Value Function Loss: 3.08969

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.01682
Policy Update Magnitude: 0.07320
Value Function Update Magnitude: 0.02410

Collected Steps per Second: 22,739.07954
Overall Steps per Second: 14,023.06621

Timestep Collection Time: 2.20000
Timestep Consumption Time: 1.36741
PPO Batch Consumption Time: 0.10048
Total Iteration Time: 3.56741

Cumulative Model Updates: 1,776
Cumulative Timesteps: 14,855,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776.13488
Policy Entropy: 2.75597
Value Function Loss: 3.09439

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02638
Policy Update Magnitude: 0.07477
Value Function Update Magnitude: 0.03568

Collected Steps per Second: 23,238.78279
Overall Steps per Second: 14,399.19261

Timestep Collection Time: 2.15201
Timestep Consumption Time: 1.32111
PPO Batch Consumption Time: 0.09704
Total Iteration Time: 3.47311

Cumulative Model Updates: 1,782
Cumulative Timesteps: 14,905,630

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 14905630...
Checkpoint 14905630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,627.34176
Policy Entropy: 2.76497
Value Function Loss: 3.08864

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.01793
Policy Update Magnitude: 0.06876
Value Function Update Magnitude: 0.04927

Collected Steps per Second: 22,887.82016
Overall Steps per Second: 14,021.56075

Timestep Collection Time: 2.18518
Timestep Consumption Time: 1.38176
PPO Batch Consumption Time: 0.09959
Total Iteration Time: 3.56694

Cumulative Model Updates: 1,788
Cumulative Timesteps: 14,955,644

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,849.05470
Policy Entropy: 2.76592
Value Function Loss: 3.17552

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.02029
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.05572

Collected Steps per Second: 21,835.09912
Overall Steps per Second: 13,888.77936

Timestep Collection Time: 2.29072
Timestep Consumption Time: 1.31061
PPO Batch Consumption Time: 0.09325
Total Iteration Time: 3.60132

Cumulative Model Updates: 1,794
Cumulative Timesteps: 15,005,662

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 15005662...
Checkpoint 15005662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,611.27790
Policy Entropy: 2.77237
Value Function Loss: 3.18818

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01004
Policy Update Magnitude: 0.06474
Value Function Update Magnitude: 0.04107

Collected Steps per Second: 22,053.28579
Overall Steps per Second: 14,052.48220

Timestep Collection Time: 2.26932
Timestep Consumption Time: 1.29204
PPO Batch Consumption Time: 0.09845
Total Iteration Time: 3.56136

Cumulative Model Updates: 1,800
Cumulative Timesteps: 15,055,708

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622.07001
Policy Entropy: 2.72644
Value Function Loss: 3.15593

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.03901
Policy Update Magnitude: 0.08139
Value Function Update Magnitude: 0.02806

Collected Steps per Second: 22,019.73826
Overall Steps per Second: 13,818.32009

Timestep Collection Time: 2.27160
Timestep Consumption Time: 1.34823
PPO Batch Consumption Time: 0.09650
Total Iteration Time: 3.61983

Cumulative Model Updates: 1,806
Cumulative Timesteps: 15,105,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 15105728...
Checkpoint 15105728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,767.98261
Policy Entropy: 2.74627
Value Function Loss: 3.17905

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.04388
Policy Update Magnitude: 0.07087
Value Function Update Magnitude: 0.02479

Collected Steps per Second: 23,033.44514
Overall Steps per Second: 14,183.13833

Timestep Collection Time: 2.17171
Timestep Consumption Time: 1.35515
PPO Batch Consumption Time: 0.10407
Total Iteration Time: 3.52686

Cumulative Model Updates: 1,812
Cumulative Timesteps: 15,155,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630.17890
Policy Entropy: 2.72960
Value Function Loss: 3.19194

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02987
Policy Update Magnitude: 0.06428
Value Function Update Magnitude: 0.03069

Collected Steps per Second: 24,731.08040
Overall Steps per Second: 14,789.28929

Timestep Collection Time: 2.02256
Timestep Consumption Time: 1.35962
PPO Batch Consumption Time: 0.09866
Total Iteration Time: 3.38218

Cumulative Model Updates: 1,818
Cumulative Timesteps: 15,205,770

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 15205770...
Checkpoint 15205770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489.46645
Policy Entropy: 2.77310
Value Function Loss: 3.24480

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.02571
Policy Update Magnitude: 0.07479
Value Function Update Magnitude: 0.03432

Collected Steps per Second: 23,385.73470
Overall Steps per Second: 14,365.64445

Timestep Collection Time: 2.13900
Timestep Consumption Time: 1.34306
PPO Batch Consumption Time: 0.09980
Total Iteration Time: 3.48206

Cumulative Model Updates: 1,824
Cumulative Timesteps: 15,255,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633.62310
Policy Entropy: 2.75636
Value Function Loss: 3.20849

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.02811
Policy Update Magnitude: 0.06181
Value Function Update Magnitude: 0.02725

Collected Steps per Second: 23,498.98695
Overall Steps per Second: 14,767.52350

Timestep Collection Time: 2.12945
Timestep Consumption Time: 1.25906
PPO Batch Consumption Time: 0.09892
Total Iteration Time: 3.38852

Cumulative Model Updates: 1,830
Cumulative Timesteps: 15,305,832

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 15305832...
Checkpoint 15305832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,748.63183
Policy Entropy: 2.75610
Value Function Loss: 3.17171

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.01953
Policy Update Magnitude: 0.06401
Value Function Update Magnitude: 0.03065

Collected Steps per Second: 23,586.24348
Overall Steps per Second: 14,317.37243

Timestep Collection Time: 2.12081
Timestep Consumption Time: 1.37298
PPO Batch Consumption Time: 0.10088
Total Iteration Time: 3.49380

Cumulative Model Updates: 1,836
Cumulative Timesteps: 15,355,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,797.48017
Policy Entropy: 2.72279
Value Function Loss: 3.13825

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.01562
Policy Update Magnitude: 0.06917
Value Function Update Magnitude: 0.03069

Collected Steps per Second: 23,038.90832
Overall Steps per Second: 14,234.41076

Timestep Collection Time: 2.17276
Timestep Consumption Time: 1.34393
PPO Batch Consumption Time: 0.10281
Total Iteration Time: 3.51669

Cumulative Model Updates: 1,842
Cumulative Timesteps: 15,405,912

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


Saving checkpoint 15405912...
Checkpoint 15405912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.01017
Policy Entropy: 2.75092
Value Function Loss: 3.01201

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.01690
Policy Update Magnitude: 0.07871
Value Function Update Magnitude: 0.02938

Collected Steps per Second: 23,276.34496
Overall Steps per Second: 14,116.02533

Timestep Collection Time: 2.14888
Timestep Consumption Time: 1.39447
PPO Batch Consumption Time: 0.10325
Total Iteration Time: 3.54335

Cumulative Model Updates: 1,848
Cumulative Timesteps: 15,455,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620.46263
Policy Entropy: 2.74329
Value Function Loss: 3.08865

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.02368
Policy Update Magnitude: 0.07547
Value Function Update Magnitude: 0.02360

Collected Steps per Second: 21,606.44451
Overall Steps per Second: 13,537.06889

Timestep Collection Time: 2.31486
Timestep Consumption Time: 1.37988
PPO Batch Consumption Time: 0.09269
Total Iteration Time: 3.69474

Cumulative Model Updates: 1,854
Cumulative Timesteps: 15,505,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 15505946...
Checkpoint 15505946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.24152
Policy Entropy: 2.72131
Value Function Loss: 3.07820

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.01131
Policy Update Magnitude: 0.06588
Value Function Update Magnitude: 0.02109

Collected Steps per Second: 22,188.95417
Overall Steps per Second: 14,085.47415

Timestep Collection Time: 2.25482
Timestep Consumption Time: 1.29721
PPO Batch Consumption Time: 0.09413
Total Iteration Time: 3.55203

Cumulative Model Updates: 1,860
Cumulative Timesteps: 15,555,978

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717.56113
Policy Entropy: 2.70050
Value Function Loss: 3.18648

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.01911
Policy Update Magnitude: 0.08665
Value Function Update Magnitude: 0.01999

Collected Steps per Second: 23,645.84518
Overall Steps per Second: 14,399.35379

Timestep Collection Time: 2.11538
Timestep Consumption Time: 1.35838
PPO Batch Consumption Time: 0.10021
Total Iteration Time: 3.47377

Cumulative Model Updates: 1,866
Cumulative Timesteps: 15,605,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 15605998...
Checkpoint 15605998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,882.42904
Policy Entropy: 2.69544
Value Function Loss: 3.12727

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.03593
Policy Update Magnitude: 0.07655
Value Function Update Magnitude: 0.02051

Collected Steps per Second: 21,720.67680
Overall Steps per Second: 13,616.81895

Timestep Collection Time: 2.30260
Timestep Consumption Time: 1.37036
PPO Batch Consumption Time: 0.09757
Total Iteration Time: 3.67296

Cumulative Model Updates: 1,872
Cumulative Timesteps: 15,656,012

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,640.68351
Policy Entropy: 2.69390
Value Function Loss: 3.11247

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 0.07777
Value Function Update Magnitude: 0.02088

Collected Steps per Second: 19,191.23433
Overall Steps per Second: 12,590.57860

Timestep Collection Time: 2.60734
Timestep Consumption Time: 1.36691
PPO Batch Consumption Time: 0.10419
Total Iteration Time: 3.97424

Cumulative Model Updates: 1,878
Cumulative Timesteps: 15,706,050

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 15706050...
Checkpoint 15706050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.70181
Policy Entropy: 2.68023
Value Function Loss: 3.14610

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.01997
Policy Update Magnitude: 0.07880
Value Function Update Magnitude: 0.02483

Collected Steps per Second: 21,714.37264
Overall Steps per Second: 13,318.28635

Timestep Collection Time: 2.30336
Timestep Consumption Time: 1.45208
PPO Batch Consumption Time: 0.10048
Total Iteration Time: 3.75544

Cumulative Model Updates: 1,884
Cumulative Timesteps: 15,756,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675.89380
Policy Entropy: 2.69542
Value Function Loss: 3.13362

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02158
Policy Update Magnitude: 0.07570
Value Function Update Magnitude: 0.03259

Collected Steps per Second: 23,037.59224
Overall Steps per Second: 14,188.31193

Timestep Collection Time: 2.17037
Timestep Consumption Time: 1.35366
PPO Batch Consumption Time: 0.10303
Total Iteration Time: 3.52403

Cumulative Model Updates: 1,890
Cumulative Timesteps: 15,806,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 15806066...
Checkpoint 15806066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.87673
Policy Entropy: 2.71090
Value Function Loss: 3.14886

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02566
Policy Update Magnitude: 0.07869
Value Function Update Magnitude: 0.03469

Collected Steps per Second: 21,253.03562
Overall Steps per Second: 13,302.73067

Timestep Collection Time: 2.35261
Timestep Consumption Time: 1.40602
PPO Batch Consumption Time: 0.10378
Total Iteration Time: 3.75863

Cumulative Model Updates: 1,896
Cumulative Timesteps: 15,856,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652.29507
Policy Entropy: 2.70762
Value Function Loss: 3.11774

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.01419
Policy Update Magnitude: 0.08166
Value Function Update Magnitude: 0.02939

Collected Steps per Second: 22,114.62159
Overall Steps per Second: 13,661.20256

Timestep Collection Time: 2.26149
Timestep Consumption Time: 1.39939
PPO Batch Consumption Time: 0.10548
Total Iteration Time: 3.66088

Cumulative Model Updates: 1,902
Cumulative Timesteps: 15,906,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 15906078...
Checkpoint 15906078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697.35351
Policy Entropy: 2.70886
Value Function Loss: 3.18139

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.04857
Policy Update Magnitude: 0.08045
Value Function Update Magnitude: 0.02345

Collected Steps per Second: 22,910.03963
Overall Steps per Second: 14,309.60096

Timestep Collection Time: 2.18254
Timestep Consumption Time: 1.31176
PPO Batch Consumption Time: 0.10016
Total Iteration Time: 3.49430

Cumulative Model Updates: 1,908
Cumulative Timesteps: 15,956,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,757.46098
Policy Entropy: 2.69177
Value Function Loss: 3.19957

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02797
Policy Update Magnitude: 0.08799
Value Function Update Magnitude: 0.02066

Collected Steps per Second: 23,330.35174
Overall Steps per Second: 14,440.30272

Timestep Collection Time: 2.14382
Timestep Consumption Time: 1.31982
PPO Batch Consumption Time: 0.09737
Total Iteration Time: 3.46364

Cumulative Model Updates: 1,914
Cumulative Timesteps: 16,006,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 16006096...
Checkpoint 16006096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522.70302
Policy Entropy: 2.69834
Value Function Loss: 3.20863

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.01484
Policy Update Magnitude: 0.09277
Value Function Update Magnitude: 0.01960

Collected Steps per Second: 22,684.84950
Overall Steps per Second: 13,993.66197

Timestep Collection Time: 2.20473
Timestep Consumption Time: 1.36932
PPO Batch Consumption Time: 0.10276
Total Iteration Time: 3.57405

Cumulative Model Updates: 1,920
Cumulative Timesteps: 16,056,110

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.22565
Policy Entropy: 2.67115
Value Function Loss: 3.14920

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.01542
Policy Update Magnitude: 0.07287
Value Function Update Magnitude: 0.01828

Collected Steps per Second: 23,997.12522
Overall Steps per Second: 14,685.12333

Timestep Collection Time: 2.08433
Timestep Consumption Time: 1.32170
PPO Batch Consumption Time: 0.09321
Total Iteration Time: 3.40603

Cumulative Model Updates: 1,926
Cumulative Timesteps: 16,106,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 16106128...
Checkpoint 16106128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664.46448
Policy Entropy: 2.70740
Value Function Loss: 3.14030

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02026
Policy Update Magnitude: 0.06607
Value Function Update Magnitude: 0.01848

Collected Steps per Second: 22,913.20282
Overall Steps per Second: 14,094.12449

Timestep Collection Time: 2.18285
Timestep Consumption Time: 1.36587
PPO Batch Consumption Time: 0.10107
Total Iteration Time: 3.54871

Cumulative Model Updates: 1,932
Cumulative Timesteps: 16,156,144

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.19912
Policy Entropy: 2.67538
Value Function Loss: 3.19816

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.03780
Policy Update Magnitude: 0.08343
Value Function Update Magnitude: 0.01758

Collected Steps per Second: 23,620.80465
Overall Steps per Second: 14,650.90887

Timestep Collection Time: 2.11712
Timestep Consumption Time: 1.29619
PPO Batch Consumption Time: 0.09292
Total Iteration Time: 3.41330

Cumulative Model Updates: 1,938
Cumulative Timesteps: 16,206,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 16206152...
Checkpoint 16206152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.31734
Policy Entropy: 2.68674
Value Function Loss: 3.26440

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06887
Policy Update Magnitude: 0.07135
Value Function Update Magnitude: 0.02637

Collected Steps per Second: 23,512.32252
Overall Steps per Second: 14,312.69960

Timestep Collection Time: 2.12876
Timestep Consumption Time: 1.36828
PPO Batch Consumption Time: 0.10265
Total Iteration Time: 3.49703

Cumulative Model Updates: 1,944
Cumulative Timesteps: 16,256,204

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691.84434
Policy Entropy: 2.67704
Value Function Loss: 3.24382

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.01400
Policy Update Magnitude: 0.07575
Value Function Update Magnitude: 0.03483

Collected Steps per Second: 22,666.98066
Overall Steps per Second: 14,017.55670

Timestep Collection Time: 2.20638
Timestep Consumption Time: 1.36143
PPO Batch Consumption Time: 0.10081
Total Iteration Time: 3.56781

Cumulative Model Updates: 1,950
Cumulative Timesteps: 16,306,216

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 16306216...
Checkpoint 16306216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,884.99891
Policy Entropy: 2.68515
Value Function Loss: 3.23183

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.01933
Policy Update Magnitude: 0.07403
Value Function Update Magnitude: 0.04034

Collected Steps per Second: 23,233.95525
Overall Steps per Second: 14,486.27479

Timestep Collection Time: 2.15219
Timestep Consumption Time: 1.29962
PPO Batch Consumption Time: 0.10157
Total Iteration Time: 3.45182

Cumulative Model Updates: 1,956
Cumulative Timesteps: 16,356,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,774.08705
Policy Entropy: 2.68043
Value Function Loss: 3.19586

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.02841
Policy Update Magnitude: 0.07735
Value Function Update Magnitude: 0.03482

Collected Steps per Second: 22,672.22499
Overall Steps per Second: 13,974.76204

Timestep Collection Time: 2.20561
Timestep Consumption Time: 1.37270
PPO Batch Consumption Time: 0.10084
Total Iteration Time: 3.57831

Cumulative Model Updates: 1,962
Cumulative Timesteps: 16,406,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 16406226...
Checkpoint 16406226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.48294
Policy Entropy: 2.67247
Value Function Loss: 3.22024

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.04960
Policy Update Magnitude: 0.06710
Value Function Update Magnitude: 0.02466

Collected Steps per Second: 22,166.57882
Overall Steps per Second: 13,930.64622

Timestep Collection Time: 2.25691
Timestep Consumption Time: 1.33431
PPO Batch Consumption Time: 0.10035
Total Iteration Time: 3.59122

Cumulative Model Updates: 1,968
Cumulative Timesteps: 16,456,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,778.24019
Policy Entropy: 2.66652
Value Function Loss: 3.14132

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.01710
Policy Update Magnitude: 0.07397
Value Function Update Magnitude: 0.02152

Collected Steps per Second: 22,978.03046
Overall Steps per Second: 14,056.78121

Timestep Collection Time: 2.17721
Timestep Consumption Time: 1.38178
PPO Batch Consumption Time: 0.10185
Total Iteration Time: 3.55899

Cumulative Model Updates: 1,974
Cumulative Timesteps: 16,506,282

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 16506282...
Checkpoint 16506282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.43616
Policy Entropy: 2.68894
Value Function Loss: 3.04666

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.02773
Policy Update Magnitude: 0.07688
Value Function Update Magnitude: 0.04118

Collected Steps per Second: 23,424.43841
Overall Steps per Second: 14,202.01189

Timestep Collection Time: 2.13538
Timestep Consumption Time: 1.38666
PPO Batch Consumption Time: 0.10664
Total Iteration Time: 3.52204

Cumulative Model Updates: 1,980
Cumulative Timesteps: 16,556,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528.45401
Policy Entropy: 2.69453
Value Function Loss: 3.02430

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.02284
Policy Update Magnitude: 0.07918
Value Function Update Magnitude: 0.05244

Collected Steps per Second: 23,268.24379
Overall Steps per Second: 14,560.23785

Timestep Collection Time: 2.14937
Timestep Consumption Time: 1.28547
PPO Batch Consumption Time: 0.09892
Total Iteration Time: 3.43483

Cumulative Model Updates: 1,986
Cumulative Timesteps: 16,606,314

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 16606314...
Checkpoint 16606314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.18740
Policy Entropy: 2.69808
Value Function Loss: 3.15820

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.01831
Policy Update Magnitude: 0.08458
Value Function Update Magnitude: 0.07686

Collected Steps per Second: 22,591.35162
Overall Steps per Second: 13,980.65100

Timestep Collection Time: 2.21377
Timestep Consumption Time: 1.36346
PPO Batch Consumption Time: 0.09819
Total Iteration Time: 3.57723

Cumulative Model Updates: 1,992
Cumulative Timesteps: 16,656,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,663.38947
Policy Entropy: 2.71008
Value Function Loss: 3.24543

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.03185
Policy Update Magnitude: 0.07002
Value Function Update Magnitude: 0.07688

Collected Steps per Second: 23,185.35054
Overall Steps per Second: 14,290.04134

Timestep Collection Time: 2.15774
Timestep Consumption Time: 1.34316
PPO Batch Consumption Time: 0.10369
Total Iteration Time: 3.50090

Cumulative Model Updates: 1,998
Cumulative Timesteps: 16,706,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 16706354...
Checkpoint 16706354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,773.37983
Policy Entropy: 2.69913
Value Function Loss: 3.27096

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02213
Policy Update Magnitude: 0.07138
Value Function Update Magnitude: 0.09223

Collected Steps per Second: 23,745.72257
Overall Steps per Second: 14,389.14924

Timestep Collection Time: 2.10699
Timestep Consumption Time: 1.37007
PPO Batch Consumption Time: 0.10157
Total Iteration Time: 3.47706

Cumulative Model Updates: 2,004
Cumulative Timesteps: 16,756,386

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.05356
Policy Entropy: 2.72810
Value Function Loss: 3.30705

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.02961
Policy Update Magnitude: 0.07689
Value Function Update Magnitude: 0.05611

Collected Steps per Second: 22,620.53959
Overall Steps per Second: 13,899.12454

Timestep Collection Time: 2.21144
Timestep Consumption Time: 1.38763
PPO Batch Consumption Time: 0.10180
Total Iteration Time: 3.59908

Cumulative Model Updates: 2,010
Cumulative Timesteps: 16,806,410

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 16806410...
Checkpoint 16806410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,728.96324
Policy Entropy: 2.66232
Value Function Loss: 3.15001

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07370
Policy Update Magnitude: 0.06267
Value Function Update Magnitude: 0.03933

Collected Steps per Second: 22,703.89043
Overall Steps per Second: 13,702.22593

Timestep Collection Time: 2.20262
Timestep Consumption Time: 1.44701
PPO Batch Consumption Time: 0.10272
Total Iteration Time: 3.64963

Cumulative Model Updates: 2,016
Cumulative Timesteps: 16,856,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697.34605
Policy Entropy: 2.68633
Value Function Loss: 3.04238

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.01552
Policy Update Magnitude: 0.05877
Value Function Update Magnitude: 0.05980

Collected Steps per Second: 23,809.50794
Overall Steps per Second: 14,434.64981

Timestep Collection Time: 2.10093
Timestep Consumption Time: 1.36449
PPO Batch Consumption Time: 0.09969
Total Iteration Time: 3.46541

Cumulative Model Updates: 2,022
Cumulative Timesteps: 16,906,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 16906440...
Checkpoint 16906440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.26059
Policy Entropy: 2.66074
Value Function Loss: 2.94558

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.02892
Policy Update Magnitude: 0.06549
Value Function Update Magnitude: 0.08136

Collected Steps per Second: 22,020.80259
Overall Steps per Second: 13,882.83242

Timestep Collection Time: 2.27185
Timestep Consumption Time: 1.33174
PPO Batch Consumption Time: 0.09148
Total Iteration Time: 3.60359

Cumulative Model Updates: 2,028
Cumulative Timesteps: 16,956,468

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,866.85941
Policy Entropy: 2.68242
Value Function Loss: 3.03673

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.01951
Policy Update Magnitude: 0.06375
Value Function Update Magnitude: 0.06427

Collected Steps per Second: 22,127.85221
Overall Steps per Second: 14,032.69978

Timestep Collection Time: 2.26023
Timestep Consumption Time: 1.30388
PPO Batch Consumption Time: 0.10273
Total Iteration Time: 3.56410

Cumulative Model Updates: 2,034
Cumulative Timesteps: 17,006,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 17006482...
Checkpoint 17006482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,812.84564
Policy Entropy: 2.66238
Value Function Loss: 3.10404

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.06800
Value Function Update Magnitude: 0.04260

Collected Steps per Second: 22,365.64540
Overall Steps per Second: 13,903.56517

Timestep Collection Time: 2.23664
Timestep Consumption Time: 1.36128
PPO Batch Consumption Time: 0.09683
Total Iteration Time: 3.59793

Cumulative Model Updates: 2,040
Cumulative Timesteps: 17,056,506

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719.05013
Policy Entropy: 2.67831
Value Function Loss: 3.14938

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.01494
Policy Update Magnitude: 0.08744
Value Function Update Magnitude: 0.03859

Collected Steps per Second: 21,786.26458
Overall Steps per Second: 13,601.94546

Timestep Collection Time: 2.29539
Timestep Consumption Time: 1.38114
PPO Batch Consumption Time: 0.10102
Total Iteration Time: 3.67653

Cumulative Model Updates: 2,046
Cumulative Timesteps: 17,106,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 17106514...
Checkpoint 17106514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,784.92583
Policy Entropy: 2.68523
Value Function Loss: 3.06044

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.02148
Policy Update Magnitude: 0.07336
Value Function Update Magnitude: 0.03247

Collected Steps per Second: 23,033.50241
Overall Steps per Second: 13,955.96197

Timestep Collection Time: 2.17171
Timestep Consumption Time: 1.41257
PPO Batch Consumption Time: 0.10221
Total Iteration Time: 3.58427

Cumulative Model Updates: 2,052
Cumulative Timesteps: 17,156,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755.23478
Policy Entropy: 2.66801
Value Function Loss: 3.08187

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.07862
Value Function Update Magnitude: 0.03564

Collected Steps per Second: 20,780.29233
Overall Steps per Second: 13,014.62256

Timestep Collection Time: 2.40651
Timestep Consumption Time: 1.43594
PPO Batch Consumption Time: 0.10504
Total Iteration Time: 3.84245

Cumulative Model Updates: 2,058
Cumulative Timesteps: 17,206,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 17206544...
Checkpoint 17206544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,595.58538
Policy Entropy: 2.65356
Value Function Loss: 2.94611

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.04008
Policy Update Magnitude: 0.07509
Value Function Update Magnitude: 0.03476

Collected Steps per Second: 23,017.63145
Overall Steps per Second: 14,699.34368

Timestep Collection Time: 2.17338
Timestep Consumption Time: 1.22990
PPO Batch Consumption Time: 0.09087
Total Iteration Time: 3.40328

Cumulative Model Updates: 2,064
Cumulative Timesteps: 17,256,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.02540
Policy Entropy: 2.66559
Value Function Loss: 2.89563

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.01403
Policy Update Magnitude: 0.06825
Value Function Update Magnitude: 0.04446

Collected Steps per Second: 23,487.10703
Overall Steps per Second: 14,303.70863

Timestep Collection Time: 2.12942
Timestep Consumption Time: 1.36715
PPO Batch Consumption Time: 0.10162
Total Iteration Time: 3.49658

Cumulative Model Updates: 2,070
Cumulative Timesteps: 17,306,584

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 17306584...
Checkpoint 17306584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.86261
Policy Entropy: 2.64409
Value Function Loss: 2.90860

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03271
Policy Update Magnitude: 0.06805
Value Function Update Magnitude: 0.06659

Collected Steps per Second: 23,845.80728
Overall Steps per Second: 14,584.57765

Timestep Collection Time: 2.09731
Timestep Consumption Time: 1.33179
PPO Batch Consumption Time: 0.10058
Total Iteration Time: 3.42910

Cumulative Model Updates: 2,076
Cumulative Timesteps: 17,356,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.68898
Policy Entropy: 2.63761
Value Function Loss: 2.89275

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01092
Policy Update Magnitude: 0.07033
Value Function Update Magnitude: 0.06700

Collected Steps per Second: 23,514.49817
Overall Steps per Second: 14,591.99136

Timestep Collection Time: 2.12660
Timestep Consumption Time: 1.30035
PPO Batch Consumption Time: 0.09180
Total Iteration Time: 3.42695

Cumulative Model Updates: 2,082
Cumulative Timesteps: 17,406,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 17406602...
Checkpoint 17406602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,607.05012
Policy Entropy: 2.66149
Value Function Loss: 2.92809

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.01804
Policy Update Magnitude: 0.06590
Value Function Update Magnitude: 0.04777

Collected Steps per Second: 22,451.83742
Overall Steps per Second: 14,041.48625

Timestep Collection Time: 2.22797
Timestep Consumption Time: 1.33447
PPO Batch Consumption Time: 0.09040
Total Iteration Time: 3.56244

Cumulative Model Updates: 2,088
Cumulative Timesteps: 17,456,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,825.15703
Policy Entropy: 2.64533
Value Function Loss: 2.84114

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.01932
Policy Update Magnitude: 0.07699
Value Function Update Magnitude: 0.04239

Collected Steps per Second: 23,517.96385
Overall Steps per Second: 14,290.26870

Timestep Collection Time: 2.12646
Timestep Consumption Time: 1.37312
PPO Batch Consumption Time: 0.10424
Total Iteration Time: 3.49958

Cumulative Model Updates: 2,094
Cumulative Timesteps: 17,506,634

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 17506634...
Checkpoint 17506634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.73650
Policy Entropy: 2.64743
Value Function Loss: 3.14558

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.07628
Value Function Update Magnitude: 0.03616

Collected Steps per Second: 23,431.44819
Overall Steps per Second: 14,436.35079

Timestep Collection Time: 2.13508
Timestep Consumption Time: 1.33034
PPO Batch Consumption Time: 0.09563
Total Iteration Time: 3.46542

Cumulative Model Updates: 2,100
Cumulative Timesteps: 17,556,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,838.90057
Policy Entropy: 2.66988
Value Function Loss: 2.96121

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.02373
Policy Update Magnitude: 0.06469
Value Function Update Magnitude: 0.03085

Collected Steps per Second: 22,032.73877
Overall Steps per Second: 13,632.88296

Timestep Collection Time: 2.27107
Timestep Consumption Time: 1.39932
PPO Batch Consumption Time: 0.10455
Total Iteration Time: 3.67039

Cumulative Model Updates: 2,106
Cumulative Timesteps: 17,606,700

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 17606700...
Checkpoint 17606700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,588.31902
Policy Entropy: 2.68967
Value Function Loss: 2.76393

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.02092
Policy Update Magnitude: 0.06956
Value Function Update Magnitude: 0.02889

Collected Steps per Second: 20,971.34285
Overall Steps per Second: 13,643.99787

Timestep Collection Time: 2.38640
Timestep Consumption Time: 1.28159
PPO Batch Consumption Time: 0.09784
Total Iteration Time: 3.66799

Cumulative Model Updates: 2,112
Cumulative Timesteps: 17,656,746

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.62678
Policy Entropy: 2.69017
Value Function Loss: 2.66006

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.01421
Policy Update Magnitude: 0.07285
Value Function Update Magnitude: 0.02954

Collected Steps per Second: 22,486.24335
Overall Steps per Second: 13,522.98920

Timestep Collection Time: 2.22536
Timestep Consumption Time: 1.47500
PPO Batch Consumption Time: 0.10355
Total Iteration Time: 3.70037

Cumulative Model Updates: 2,118
Cumulative Timesteps: 17,706,786

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 17706786...
Checkpoint 17706786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.02308
Policy Entropy: 2.66670
Value Function Loss: 2.87490

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.02426
Policy Update Magnitude: 0.07503
Value Function Update Magnitude: 0.02468

Collected Steps per Second: 22,011.24264
Overall Steps per Second: 13,792.45686

Timestep Collection Time: 2.27238
Timestep Consumption Time: 1.35409
PPO Batch Consumption Time: 0.10317
Total Iteration Time: 3.62648

Cumulative Model Updates: 2,124
Cumulative Timesteps: 17,756,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771.40406
Policy Entropy: 2.62696
Value Function Loss: 2.91823

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.02185
Policy Update Magnitude: 0.08257
Value Function Update Magnitude: 0.03830

Collected Steps per Second: 22,003.38788
Overall Steps per Second: 13,731.62891

Timestep Collection Time: 2.27310
Timestep Consumption Time: 1.36929
PPO Batch Consumption Time: 0.09203
Total Iteration Time: 3.64239

Cumulative Model Updates: 2,130
Cumulative Timesteps: 17,806,820

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 17806820...
Checkpoint 17806820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.84051
Policy Entropy: 2.62967
Value Function Loss: 2.87102

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.04036
Policy Update Magnitude: 0.06732
Value Function Update Magnitude: 0.04885

Collected Steps per Second: 22,265.82204
Overall Steps per Second: 14,048.21701

Timestep Collection Time: 2.24649
Timestep Consumption Time: 1.31410
PPO Batch Consumption Time: 0.09252
Total Iteration Time: 3.56059

Cumulative Model Updates: 2,136
Cumulative Timesteps: 17,856,840

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.10284
Policy Entropy: 2.64729
Value Function Loss: 2.82281

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.00809
Policy Update Magnitude: 0.07758
Value Function Update Magnitude: 0.06228

Collected Steps per Second: 22,666.34784
Overall Steps per Second: 14,181.85952

Timestep Collection Time: 2.20644
Timestep Consumption Time: 1.32003
PPO Batch Consumption Time: 0.10439
Total Iteration Time: 3.52648

Cumulative Model Updates: 2,142
Cumulative Timesteps: 17,906,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 17906852...
Checkpoint 17906852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.04808
Policy Entropy: 2.62757
Value Function Loss: 2.79051

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02269
Policy Update Magnitude: 0.07364
Value Function Update Magnitude: 0.08988

Collected Steps per Second: 21,775.69975
Overall Steps per Second: 13,783.69136

Timestep Collection Time: 2.29641
Timestep Consumption Time: 1.33150
PPO Batch Consumption Time: 0.09394
Total Iteration Time: 3.62791

Cumulative Model Updates: 2,148
Cumulative Timesteps: 17,956,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,607.49964
Policy Entropy: 2.59583
Value Function Loss: 2.94965

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.03336
Policy Update Magnitude: 0.07429
Value Function Update Magnitude: 0.08754

Collected Steps per Second: 22,142.34514
Overall Steps per Second: 13,696.49327

Timestep Collection Time: 2.25947
Timestep Consumption Time: 1.39329
PPO Batch Consumption Time: 0.10044
Total Iteration Time: 3.65276

Cumulative Model Updates: 2,154
Cumulative Timesteps: 18,006,888

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 18006888...
Checkpoint 18006888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566.15653
Policy Entropy: 2.58082
Value Function Loss: 2.97503

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.02502
Policy Update Magnitude: 0.08807
Value Function Update Magnitude: 0.06699

Collected Steps per Second: 22,287.99928
Overall Steps per Second: 13,584.43246

Timestep Collection Time: 2.24381
Timestep Consumption Time: 1.43761
PPO Batch Consumption Time: 0.10279
Total Iteration Time: 3.68142

Cumulative Model Updates: 2,160
Cumulative Timesteps: 18,056,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.27945
Policy Entropy: 2.58622
Value Function Loss: 2.97620

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.01358
Policy Update Magnitude: 0.08492
Value Function Update Magnitude: 0.04961

Collected Steps per Second: 20,770.91909
Overall Steps per Second: 13,144.91604

Timestep Collection Time: 2.40827
Timestep Consumption Time: 1.39715
PPO Batch Consumption Time: 0.10251
Total Iteration Time: 3.80543

Cumulative Model Updates: 2,166
Cumulative Timesteps: 18,106,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 18106920...
Checkpoint 18106920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707.48453
Policy Entropy: 2.60607
Value Function Loss: 3.19878

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.10063
Value Function Update Magnitude: 0.03267

Collected Steps per Second: 21,831.28575
Overall Steps per Second: 13,592.43675

Timestep Collection Time: 2.29167
Timestep Consumption Time: 1.38906
PPO Batch Consumption Time: 0.09983
Total Iteration Time: 3.68072

Cumulative Model Updates: 2,172
Cumulative Timesteps: 18,156,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703.37535
Policy Entropy: 2.62154
Value Function Loss: 3.20979

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.01732
Policy Update Magnitude: 0.08047
Value Function Update Magnitude: 0.03443

Collected Steps per Second: 23,668.81046
Overall Steps per Second: 14,368.93409

Timestep Collection Time: 2.11274
Timestep Consumption Time: 1.36741
PPO Batch Consumption Time: 0.09221
Total Iteration Time: 3.48015

Cumulative Model Updates: 2,178
Cumulative Timesteps: 18,206,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 18206956...
Checkpoint 18206956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,786.06837
Policy Entropy: 2.63457
Value Function Loss: 3.18770

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.04028
Policy Update Magnitude: 0.07289
Value Function Update Magnitude: 0.03641

Collected Steps per Second: 22,763.09260
Overall Steps per Second: 14,066.50379

Timestep Collection Time: 2.19812
Timestep Consumption Time: 1.35898
PPO Batch Consumption Time: 0.10037
Total Iteration Time: 3.55710

Cumulative Model Updates: 2,184
Cumulative Timesteps: 18,256,992

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.61132
Policy Entropy: 2.58578
Value Function Loss: 2.90221

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.03918
Policy Update Magnitude: 0.07552
Value Function Update Magnitude: 0.03133

Collected Steps per Second: 21,676.98382
Overall Steps per Second: 13,941.67341

Timestep Collection Time: 2.30752
Timestep Consumption Time: 1.28029
PPO Batch Consumption Time: 0.09670
Total Iteration Time: 3.58780

Cumulative Model Updates: 2,190
Cumulative Timesteps: 18,307,012

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 18307012...
Checkpoint 18307012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.06122
Policy Entropy: 2.59073
Value Function Loss: 2.91552

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03475
Policy Update Magnitude: 0.07413
Value Function Update Magnitude: 0.03361

Collected Steps per Second: 21,376.42770
Overall Steps per Second: 13,305.98026

Timestep Collection Time: 2.33940
Timestep Consumption Time: 1.41891
PPO Batch Consumption Time: 0.09898
Total Iteration Time: 3.75831

Cumulative Model Updates: 2,196
Cumulative Timesteps: 18,357,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.28125
Policy Entropy: 2.58084
Value Function Loss: 3.12969

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.01252
Policy Update Magnitude: 0.08615
Value Function Update Magnitude: 0.02398

Collected Steps per Second: 21,473.55569
Overall Steps per Second: 13,419.83808

Timestep Collection Time: 2.32966
Timestep Consumption Time: 1.39811
PPO Batch Consumption Time: 0.10297
Total Iteration Time: 3.72776

Cumulative Model Updates: 2,202
Cumulative Timesteps: 18,407,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 18407046...
Checkpoint 18407046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.49414
Policy Entropy: 2.60924
Value Function Loss: 3.11446

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.01737
Policy Update Magnitude: 0.06514
Value Function Update Magnitude: 0.02819

Collected Steps per Second: 22,810.31429
Overall Steps per Second: 13,904.05816

Timestep Collection Time: 2.19217
Timestep Consumption Time: 1.40419
PPO Batch Consumption Time: 0.10535
Total Iteration Time: 3.59636

Cumulative Model Updates: 2,208
Cumulative Timesteps: 18,457,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.30749
Policy Entropy: 2.59418
Value Function Loss: 3.16611

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.00777
Policy Update Magnitude: 0.06644
Value Function Update Magnitude: 0.05062

Collected Steps per Second: 22,580.46702
Overall Steps per Second: 13,975.09518

Timestep Collection Time: 2.21457
Timestep Consumption Time: 1.36365
PPO Batch Consumption Time: 0.10188
Total Iteration Time: 3.57822

Cumulative Model Updates: 2,214
Cumulative Timesteps: 18,507,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 18507056...
Checkpoint 18507056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.38651
Policy Entropy: 2.58641
Value Function Loss: 3.10883

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.01370
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.06586

Collected Steps per Second: 23,234.58041
Overall Steps per Second: 14,647.58124

Timestep Collection Time: 2.15412
Timestep Consumption Time: 1.26283
PPO Batch Consumption Time: 0.09707
Total Iteration Time: 3.41695

Cumulative Model Updates: 2,220
Cumulative Timesteps: 18,557,106

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,780.26830
Policy Entropy: 2.56750
Value Function Loss: 3.05428

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.03609
Policy Update Magnitude: 0.08012
Value Function Update Magnitude: 0.06816

Collected Steps per Second: 23,297.81113
Overall Steps per Second: 14,127.63692

Timestep Collection Time: 2.14715
Timestep Consumption Time: 1.39371
PPO Batch Consumption Time: 0.10311
Total Iteration Time: 3.54086

Cumulative Model Updates: 2,226
Cumulative Timesteps: 18,607,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 18607130...
Checkpoint 18607130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.71170
Policy Entropy: 2.59731
Value Function Loss: 3.06231

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.02706
Policy Update Magnitude: 0.07846
Value Function Update Magnitude: 0.06212

Collected Steps per Second: 22,795.41123
Overall Steps per Second: 14,142.31850

Timestep Collection Time: 2.19483
Timestep Consumption Time: 1.34292
PPO Batch Consumption Time: 0.10120
Total Iteration Time: 3.53775

Cumulative Model Updates: 2,232
Cumulative Timesteps: 18,657,162

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.60916
Policy Entropy: 2.62198
Value Function Loss: 3.08194

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.08109
Value Function Update Magnitude: 0.05220

Collected Steps per Second: 24,009.26383
Overall Steps per Second: 14,522.60374

Timestep Collection Time: 2.08311
Timestep Consumption Time: 1.36076
PPO Batch Consumption Time: 0.10077
Total Iteration Time: 3.44387

Cumulative Model Updates: 2,238
Cumulative Timesteps: 18,707,176

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 18707176...
Checkpoint 18707176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680.86168
Policy Entropy: 2.62203
Value Function Loss: 3.04786

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.07548
Value Function Update Magnitude: 0.04660

Collected Steps per Second: 22,688.65094
Overall Steps per Second: 13,966.61573

Timestep Collection Time: 2.20524
Timestep Consumption Time: 1.37716
PPO Batch Consumption Time: 0.10263
Total Iteration Time: 3.58240

Cumulative Model Updates: 2,244
Cumulative Timesteps: 18,757,210

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.33743
Policy Entropy: 2.62324
Value Function Loss: 3.04877

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02534
Policy Update Magnitude: 0.09383
Value Function Update Magnitude: 0.04564

Collected Steps per Second: 21,915.43746
Overall Steps per Second: 13,893.12055

Timestep Collection Time: 2.28168
Timestep Consumption Time: 1.31751
PPO Batch Consumption Time: 0.09331
Total Iteration Time: 3.59919

Cumulative Model Updates: 2,250
Cumulative Timesteps: 18,807,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 18807214...
Checkpoint 18807214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.38647
Policy Entropy: 2.60614
Value Function Loss: 2.98098

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.01212
Policy Update Magnitude: 0.08015
Value Function Update Magnitude: 0.04475

Collected Steps per Second: 20,756.06752
Overall Steps per Second: 13,262.75915

Timestep Collection Time: 2.40951
Timestep Consumption Time: 1.36135
PPO Batch Consumption Time: 0.09797
Total Iteration Time: 3.77086

Cumulative Model Updates: 2,256
Cumulative Timesteps: 18,857,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.22645
Policy Entropy: 2.61377
Value Function Loss: 3.06320

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02529
Policy Update Magnitude: 0.08094
Value Function Update Magnitude: 0.07058

Collected Steps per Second: 21,656.76598
Overall Steps per Second: 13,416.10334

Timestep Collection Time: 2.30967
Timestep Consumption Time: 1.41868
PPO Batch Consumption Time: 0.10436
Total Iteration Time: 3.72836

Cumulative Model Updates: 2,262
Cumulative Timesteps: 18,907,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 18907246...
Checkpoint 18907246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.81722
Policy Entropy: 2.63820
Value Function Loss: 3.37906

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.04753
Policy Update Magnitude: 0.08215
Value Function Update Magnitude: 0.05243

Collected Steps per Second: 21,415.78215
Overall Steps per Second: 13,760.39249

Timestep Collection Time: 2.33622
Timestep Consumption Time: 1.29972
PPO Batch Consumption Time: 0.09637
Total Iteration Time: 3.63594

Cumulative Model Updates: 2,268
Cumulative Timesteps: 18,957,278

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,753.00948
Policy Entropy: 2.62422
Value Function Loss: 3.39517

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02148
Policy Update Magnitude: 0.09383
Value Function Update Magnitude: 0.05319

Collected Steps per Second: 22,594.59691
Overall Steps per Second: 14,082.93001

Timestep Collection Time: 2.21327
Timestep Consumption Time: 1.33769
PPO Batch Consumption Time: 0.09804
Total Iteration Time: 3.55097

Cumulative Model Updates: 2,274
Cumulative Timesteps: 19,007,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 19007286...
Checkpoint 19007286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,778.09745
Policy Entropy: 2.61501
Value Function Loss: 3.37621

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.01507
Policy Update Magnitude: 0.08241
Value Function Update Magnitude: 0.06656

Collected Steps per Second: 21,929.02383
Overall Steps per Second: 13,933.39898

Timestep Collection Time: 2.28136
Timestep Consumption Time: 1.30915
PPO Batch Consumption Time: 0.09411
Total Iteration Time: 3.59051

Cumulative Model Updates: 2,280
Cumulative Timesteps: 19,057,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.42655
Policy Entropy: 2.59269
Value Function Loss: 3.19867

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.01242
Policy Update Magnitude: 0.07361
Value Function Update Magnitude: 0.05380

Collected Steps per Second: 24,466.14267
Overall Steps per Second: 14,796.32907

Timestep Collection Time: 2.04454
Timestep Consumption Time: 1.33616
PPO Batch Consumption Time: 0.09651
Total Iteration Time: 3.38070

Cumulative Model Updates: 2,286
Cumulative Timesteps: 19,107,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 19107336...
Checkpoint 19107336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678.15629
Policy Entropy: 2.56175
Value Function Loss: 3.16079

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.01573
Policy Update Magnitude: 0.07398
Value Function Update Magnitude: 0.04494

Collected Steps per Second: 22,799.39537
Overall Steps per Second: 14,050.39774

Timestep Collection Time: 2.19339
Timestep Consumption Time: 1.36580
PPO Batch Consumption Time: 0.10039
Total Iteration Time: 3.55919

Cumulative Model Updates: 2,292
Cumulative Timesteps: 19,157,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707.67858
Policy Entropy: 2.57289
Value Function Loss: 3.20483

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.00976
Policy Update Magnitude: 0.07374
Value Function Update Magnitude: 0.05170

Collected Steps per Second: 23,105.54205
Overall Steps per Second: 14,709.34232

Timestep Collection Time: 2.16545
Timestep Consumption Time: 1.23606
PPO Batch Consumption Time: 0.09333
Total Iteration Time: 3.40151

Cumulative Model Updates: 2,298
Cumulative Timesteps: 19,207,378

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 19207378...
Checkpoint 19207378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834.35014
Policy Entropy: 2.55391
Value Function Loss: 3.23939

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02922
Policy Update Magnitude: 0.07474
Value Function Update Magnitude: 0.05790

Collected Steps per Second: 23,214.07280
Overall Steps per Second: 14,066.03765

Timestep Collection Time: 2.15464
Timestep Consumption Time: 1.40130
PPO Batch Consumption Time: 0.09967
Total Iteration Time: 3.55594

Cumulative Model Updates: 2,304
Cumulative Timesteps: 19,257,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664.94156
Policy Entropy: 2.56819
Value Function Loss: 3.11359

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.01354
Policy Update Magnitude: 0.08520
Value Function Update Magnitude: 0.04709

Collected Steps per Second: 22,151.95198
Overall Steps per Second: 13,864.95058

Timestep Collection Time: 2.25858
Timestep Consumption Time: 1.34994
PPO Batch Consumption Time: 0.09542
Total Iteration Time: 3.60852

Cumulative Model Updates: 2,310
Cumulative Timesteps: 19,307,428

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 19307428...
Checkpoint 19307428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,854.44934
Policy Entropy: 2.56297
Value Function Loss: 3.12837

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.01781
Policy Update Magnitude: 0.09134
Value Function Update Magnitude: 0.03691

Collected Steps per Second: 22,819.67113
Overall Steps per Second: 14,047.65699

Timestep Collection Time: 2.19179
Timestep Consumption Time: 1.36866
PPO Batch Consumption Time: 0.10077
Total Iteration Time: 3.56045

Cumulative Model Updates: 2,316
Cumulative Timesteps: 19,357,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.61116
Policy Entropy: 2.58706
Value Function Loss: 3.10824

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.08108
Value Function Update Magnitude: 0.02783

Collected Steps per Second: 22,716.54474
Overall Steps per Second: 13,951.32153

Timestep Collection Time: 2.20218
Timestep Consumption Time: 1.38357
PPO Batch Consumption Time: 0.10084
Total Iteration Time: 3.58575

Cumulative Model Updates: 2,322
Cumulative Timesteps: 19,407,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 19407470...
Checkpoint 19407470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689.71222
Policy Entropy: 2.57800
Value Function Loss: 3.11965

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02869
Policy Update Magnitude: 0.08536
Value Function Update Magnitude: 0.03033

Collected Steps per Second: 22,024.58780
Overall Steps per Second: 13,918.66843

Timestep Collection Time: 2.27083
Timestep Consumption Time: 1.32248
PPO Batch Consumption Time: 0.09572
Total Iteration Time: 3.59330

Cumulative Model Updates: 2,328
Cumulative Timesteps: 19,457,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.75935
Policy Entropy: 2.58195
Value Function Loss: 3.11480

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02009
Policy Update Magnitude: 0.08846
Value Function Update Magnitude: 0.01986

Collected Steps per Second: 23,447.40528
Overall Steps per Second: 14,096.88759

Timestep Collection Time: 2.13286
Timestep Consumption Time: 1.41473
PPO Batch Consumption Time: 0.10348
Total Iteration Time: 3.54759

Cumulative Model Updates: 2,334
Cumulative Timesteps: 19,507,494

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 19507494...
Checkpoint 19507494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,728.79007
Policy Entropy: 2.56886
Value Function Loss: 3.21468

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.07898
Value Function Update Magnitude: 0.03456

Collected Steps per Second: 20,579.56544
Overall Steps per Second: 13,153.27503

Timestep Collection Time: 2.42989
Timestep Consumption Time: 1.37190
PPO Batch Consumption Time: 0.09691
Total Iteration Time: 3.80179

Cumulative Model Updates: 2,340
Cumulative Timesteps: 19,557,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.34303
Policy Entropy: 2.58208
Value Function Loss: 3.17177

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.01813
Policy Update Magnitude: 0.06488
Value Function Update Magnitude: 0.02622

Collected Steps per Second: 22,221.59328
Overall Steps per Second: 14,067.57719

Timestep Collection Time: 2.25069
Timestep Consumption Time: 1.30457
PPO Batch Consumption Time: 0.10145
Total Iteration Time: 3.55527

Cumulative Model Updates: 2,346
Cumulative Timesteps: 19,607,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 19607514...
Checkpoint 19607514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.88060
Policy Entropy: 2.59188
Value Function Loss: 3.25226

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.01137
Policy Update Magnitude: 0.07350
Value Function Update Magnitude: 0.02419

Collected Steps per Second: 22,710.08222
Overall Steps per Second: 13,995.13060

Timestep Collection Time: 2.20299
Timestep Consumption Time: 1.37183
PPO Batch Consumption Time: 0.10250
Total Iteration Time: 3.57481

Cumulative Model Updates: 2,352
Cumulative Timesteps: 19,657,544

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,838.48056
Policy Entropy: 2.57985
Value Function Loss: 3.34666

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.03501
Policy Update Magnitude: 0.07258
Value Function Update Magnitude: 0.05064

Collected Steps per Second: 22,793.22189
Overall Steps per Second: 14,032.82201

Timestep Collection Time: 2.19442
Timestep Consumption Time: 1.36993
PPO Batch Consumption Time: 0.10318
Total Iteration Time: 3.56436

Cumulative Model Updates: 2,358
Cumulative Timesteps: 19,707,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 19707562...
Checkpoint 19707562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.40090
Policy Entropy: 2.57331
Value Function Loss: 3.18704

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03144
Policy Update Magnitude: 0.07862
Value Function Update Magnitude: 0.02979

Collected Steps per Second: 23,755.98590
Overall Steps per Second: 14,647.68161

Timestep Collection Time: 2.10541
Timestep Consumption Time: 1.30920
PPO Batch Consumption Time: 0.09280
Total Iteration Time: 3.41460

Cumulative Model Updates: 2,364
Cumulative Timesteps: 19,757,578

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.17716
Policy Entropy: 2.58767
Value Function Loss: 3.22915

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.03227
Policy Update Magnitude: 0.07536
Value Function Update Magnitude: 0.05026

Collected Steps per Second: 23,797.83163
Overall Steps per Second: 14,333.90376

Timestep Collection Time: 2.10254
Timestep Consumption Time: 1.38820
PPO Batch Consumption Time: 0.10404
Total Iteration Time: 3.49074

Cumulative Model Updates: 2,370
Cumulative Timesteps: 19,807,614

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 19807614...
Checkpoint 19807614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.97980
Policy Entropy: 2.55374
Value Function Loss: 3.36582

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.02531
Policy Update Magnitude: 0.08044
Value Function Update Magnitude: 0.06354

Collected Steps per Second: 21,844.37445
Overall Steps per Second: 13,714.30201

Timestep Collection Time: 2.28919
Timestep Consumption Time: 1.35707
PPO Batch Consumption Time: 0.10418
Total Iteration Time: 3.64627

Cumulative Model Updates: 2,376
Cumulative Timesteps: 19,857,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.96808
Policy Entropy: 2.57598
Value Function Loss: 3.14528

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.01807
Policy Update Magnitude: 0.09831
Value Function Update Magnitude: 0.03248

Collected Steps per Second: 23,550.67175
Overall Steps per Second: 14,247.55272

Timestep Collection Time: 2.12385
Timestep Consumption Time: 1.38679
PPO Batch Consumption Time: 0.10250
Total Iteration Time: 3.51064

Cumulative Model Updates: 2,382
Cumulative Timesteps: 19,907,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 19907638...
Checkpoint 19907638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690.73479
Policy Entropy: 2.54464
Value Function Loss: 3.24365

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.01857
Policy Update Magnitude: 0.09772
Value Function Update Magnitude: 0.03268

Collected Steps per Second: 22,211.93473
Overall Steps per Second: 13,877.57941

Timestep Collection Time: 2.25257
Timestep Consumption Time: 1.35281
PPO Batch Consumption Time: 0.10279
Total Iteration Time: 3.60538

Cumulative Model Updates: 2,388
Cumulative Timesteps: 19,957,672

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552.58932
Policy Entropy: 2.59614
Value Function Loss: 2.87852

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.07477
Value Function Update Magnitude: 0.03920

Collected Steps per Second: 22,805.10442
Overall Steps per Second: 14,414.45117

Timestep Collection Time: 2.19381
Timestep Consumption Time: 1.27702
PPO Batch Consumption Time: 0.09570
Total Iteration Time: 3.47082

Cumulative Model Updates: 2,394
Cumulative Timesteps: 20,007,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 20007702...
Checkpoint 20007702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,860.80669
Policy Entropy: 2.56261
Value Function Loss: 2.90574

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.00801
Policy Update Magnitude: 0.07658
Value Function Update Magnitude: 0.04247

Collected Steps per Second: 22,943.52360
Overall Steps per Second: 14,179.46149

Timestep Collection Time: 2.17961
Timestep Consumption Time: 1.34718
PPO Batch Consumption Time: 0.09899
Total Iteration Time: 3.52679

Cumulative Model Updates: 2,400
Cumulative Timesteps: 20,057,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,862.23433
Policy Entropy: 2.59748
Value Function Loss: 2.87695

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.02813
Policy Update Magnitude: 0.07968
Value Function Update Magnitude: 0.06188

Collected Steps per Second: 23,592.89096
Overall Steps per Second: 14,578.31978

Timestep Collection Time: 2.12123
Timestep Consumption Time: 1.31167
PPO Batch Consumption Time: 0.09386
Total Iteration Time: 3.43291

Cumulative Model Updates: 2,406
Cumulative Timesteps: 20,107,756

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 20107756...
Checkpoint 20107756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.00103
Policy Entropy: 2.58384
Value Function Loss: 2.91393

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.00820
Policy Update Magnitude: 0.09742
Value Function Update Magnitude: 0.04931

Collected Steps per Second: 22,410.37843
Overall Steps per Second: 14,032.12563

Timestep Collection Time: 2.23164
Timestep Consumption Time: 1.33246
PPO Batch Consumption Time: 0.09038
Total Iteration Time: 3.56411

Cumulative Model Updates: 2,412
Cumulative Timesteps: 20,157,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.26133
Policy Entropy: 2.57849
Value Function Loss: 2.77638

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.01540
Policy Update Magnitude: 0.09482
Value Function Update Magnitude: 0.04755

Collected Steps per Second: 22,669.21947
Overall Steps per Second: 14,005.89009

Timestep Collection Time: 2.20652
Timestep Consumption Time: 1.36484
PPO Batch Consumption Time: 0.09754
Total Iteration Time: 3.57135

Cumulative Model Updates: 2,418
Cumulative Timesteps: 20,207,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 20207788...
Checkpoint 20207788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676.68538
Policy Entropy: 2.57909
Value Function Loss: 2.68634

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.01665
Policy Update Magnitude: 0.09953
Value Function Update Magnitude: 0.06137

Collected Steps per Second: 22,465.44765
Overall Steps per Second: 14,172.31969

Timestep Collection Time: 2.22582
Timestep Consumption Time: 1.30247
PPO Batch Consumption Time: 0.10471
Total Iteration Time: 3.52829

Cumulative Model Updates: 2,424
Cumulative Timesteps: 20,257,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680.34740
Policy Entropy: 2.57546
Value Function Loss: 2.69868

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.01939
Policy Update Magnitude: 0.08330
Value Function Update Magnitude: 0.07065

Collected Steps per Second: 22,132.24134
Overall Steps per Second: 13,858.36892

Timestep Collection Time: 2.25969
Timestep Consumption Time: 1.34910
PPO Batch Consumption Time: 0.09966
Total Iteration Time: 3.60879

Cumulative Model Updates: 2,430
Cumulative Timesteps: 20,307,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 20307804...
Checkpoint 20307804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.80373
Policy Entropy: 2.54184
Value Function Loss: 2.86164

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02166
Policy Update Magnitude: 0.08420
Value Function Update Magnitude: 0.06789

Collected Steps per Second: 21,679.93488
Overall Steps per Second: 13,844.56355

Timestep Collection Time: 2.30702
Timestep Consumption Time: 1.30566
PPO Batch Consumption Time: 0.09239
Total Iteration Time: 3.61268

Cumulative Model Updates: 2,436
Cumulative Timesteps: 20,357,820

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,556.30273
Policy Entropy: 2.57121
Value Function Loss: 2.87877

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.02857
Policy Update Magnitude: 0.08155
Value Function Update Magnitude: 0.05284

Collected Steps per Second: 21,303.75323
Overall Steps per Second: 13,357.43198

Timestep Collection Time: 2.34738
Timestep Consumption Time: 1.39645
PPO Batch Consumption Time: 0.10302
Total Iteration Time: 3.74383

Cumulative Model Updates: 2,442
Cumulative Timesteps: 20,407,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 20407828...
Checkpoint 20407828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.87366
Policy Entropy: 2.55783
Value Function Loss: 2.94123

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.07500
Value Function Update Magnitude: 0.04015

Collected Steps per Second: 21,057.58136
Overall Steps per Second: 13,246.75250

Timestep Collection Time: 2.37501
Timestep Consumption Time: 1.40040
PPO Batch Consumption Time: 0.10711
Total Iteration Time: 3.77542

Cumulative Model Updates: 2,448
Cumulative Timesteps: 20,457,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.97046
Policy Entropy: 2.54884
Value Function Loss: 2.86724

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.03933
Policy Update Magnitude: 0.07324
Value Function Update Magnitude: 0.04643

Collected Steps per Second: 22,142.87593
Overall Steps per Second: 13,874.27966

Timestep Collection Time: 2.25806
Timestep Consumption Time: 1.34573
PPO Batch Consumption Time: 0.10295
Total Iteration Time: 3.60379

Cumulative Model Updates: 2,454
Cumulative Timesteps: 20,507,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 20507840...
Checkpoint 20507840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,797.55197
Policy Entropy: 2.53254
Value Function Loss: 2.99916

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02055
Policy Update Magnitude: 0.09078
Value Function Update Magnitude: 0.04667

Collected Steps per Second: 21,666.29693
Overall Steps per Second: 13,556.13149

Timestep Collection Time: 2.30884
Timestep Consumption Time: 1.38130
PPO Batch Consumption Time: 0.10080
Total Iteration Time: 3.69014

Cumulative Model Updates: 2,460
Cumulative Timesteps: 20,557,864

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,799.43270
Policy Entropy: 2.53503
Value Function Loss: 3.21005

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.03137
Policy Update Magnitude: 0.07218
Value Function Update Magnitude: 0.04335

Collected Steps per Second: 21,071.88071
Overall Steps per Second: 13,571.72515

Timestep Collection Time: 2.37397
Timestep Consumption Time: 1.31193
PPO Batch Consumption Time: 0.09163
Total Iteration Time: 3.68590

Cumulative Model Updates: 2,466
Cumulative Timesteps: 20,607,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 20607888...
Checkpoint 20607888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.76928
Policy Entropy: 2.51159
Value Function Loss: 3.27614

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.07350
Value Function Update Magnitude: 0.06257

Collected Steps per Second: 22,759.86251
Overall Steps per Second: 14,030.91819

Timestep Collection Time: 2.19694
Timestep Consumption Time: 1.36676
PPO Batch Consumption Time: 0.09517
Total Iteration Time: 3.56370

Cumulative Model Updates: 2,472
Cumulative Timesteps: 20,657,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,813.99742
Policy Entropy: 2.49516
Value Function Loss: 3.26157

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.02877
Policy Update Magnitude: 0.07198
Value Function Update Magnitude: 0.06038

Collected Steps per Second: 22,061.67369
Overall Steps per Second: 13,952.71763

Timestep Collection Time: 2.26665
Timestep Consumption Time: 1.31732
PPO Batch Consumption Time: 0.09046
Total Iteration Time: 3.58396

Cumulative Model Updates: 2,478
Cumulative Timesteps: 20,707,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 20707896...
Checkpoint 20707896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.50761
Policy Entropy: 2.51930
Value Function Loss: 3.23830

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.07711
Value Function Update Magnitude: 0.06059

Collected Steps per Second: 23,331.84405
Overall Steps per Second: 14,376.25952

Timestep Collection Time: 2.14377
Timestep Consumption Time: 1.33544
PPO Batch Consumption Time: 0.10248
Total Iteration Time: 3.47921

Cumulative Model Updates: 2,484
Cumulative Timesteps: 20,757,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,520.71751
Policy Entropy: 2.51762
Value Function Loss: 3.17492

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.01617
Policy Update Magnitude: 0.07957
Value Function Update Magnitude: 0.06418

Collected Steps per Second: 22,771.54033
Overall Steps per Second: 13,972.34508

Timestep Collection Time: 2.19625
Timestep Consumption Time: 1.38311
PPO Batch Consumption Time: 0.10144
Total Iteration Time: 3.57936

Cumulative Model Updates: 2,490
Cumulative Timesteps: 20,807,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 20807926...
Checkpoint 20807926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630.93882
Policy Entropy: 2.51950
Value Function Loss: 3.17044

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.02330
Policy Update Magnitude: 0.08457
Value Function Update Magnitude: 0.09302

Collected Steps per Second: 22,807.93563
Overall Steps per Second: 14,418.17688

Timestep Collection Time: 2.19336
Timestep Consumption Time: 1.27629
PPO Batch Consumption Time: 0.09073
Total Iteration Time: 3.46965

Cumulative Model Updates: 2,496
Cumulative Timesteps: 20,857,952

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.41297
Policy Entropy: 2.52667
Value Function Loss: 3.21825

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02069
Policy Update Magnitude: 0.06515
Value Function Update Magnitude: 0.08354

Collected Steps per Second: 22,745.60636
Overall Steps per Second: 14,245.01749

Timestep Collection Time: 2.19963
Timestep Consumption Time: 1.31261
PPO Batch Consumption Time: 0.10414
Total Iteration Time: 3.51225

Cumulative Model Updates: 2,502
Cumulative Timesteps: 20,907,984

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 20907984...
Checkpoint 20907984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.69577
Policy Entropy: 2.51143
Value Function Loss: 3.42215

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.00637
Policy Update Magnitude: 0.08384
Value Function Update Magnitude: 0.05962

Collected Steps per Second: 22,704.19120
Overall Steps per Second: 13,812.02920

Timestep Collection Time: 2.20277
Timestep Consumption Time: 1.41814
PPO Batch Consumption Time: 0.10353
Total Iteration Time: 3.62090

Cumulative Model Updates: 2,508
Cumulative Timesteps: 20,957,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.42971
Policy Entropy: 2.51491
Value Function Loss: 3.35874

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.03170
Policy Update Magnitude: 0.07431
Value Function Update Magnitude: 0.03471

Collected Steps per Second: 22,216.30502
Overall Steps per Second: 13,874.46003

Timestep Collection Time: 2.25069
Timestep Consumption Time: 1.35320
PPO Batch Consumption Time: 0.09934
Total Iteration Time: 3.60389

Cumulative Model Updates: 2,514
Cumulative Timesteps: 21,007,998

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 21007998...
Checkpoint 21007998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,802.20784
Policy Entropy: 2.48698
Value Function Loss: 3.47234

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.01493
Policy Update Magnitude: 0.08075
Value Function Update Magnitude: 0.03474

Collected Steps per Second: 23,131.55055
Overall Steps per Second: 14,025.25449

Timestep Collection Time: 2.16216
Timestep Consumption Time: 1.40384
PPO Batch Consumption Time: 0.10427
Total Iteration Time: 3.56600

Cumulative Model Updates: 2,520
Cumulative Timesteps: 21,058,012

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.96280
Policy Entropy: 2.51512
Value Function Loss: 3.60666

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.02816
Policy Update Magnitude: 0.08580
Value Function Update Magnitude: 0.02429

Collected Steps per Second: 23,547.87958
Overall Steps per Second: 14,315.43191

Timestep Collection Time: 2.12427
Timestep Consumption Time: 1.37000
PPO Batch Consumption Time: 0.10089
Total Iteration Time: 3.49427

Cumulative Model Updates: 2,526
Cumulative Timesteps: 21,108,034

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 21108034...
Checkpoint 21108034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,787.07745
Policy Entropy: 2.54381
Value Function Loss: 3.69388

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.01726
Policy Update Magnitude: 0.08959
Value Function Update Magnitude: 0.02740

Collected Steps per Second: 23,084.25295
Overall Steps per Second: 14,530.13897

Timestep Collection Time: 2.16710
Timestep Consumption Time: 1.27581
PPO Batch Consumption Time: 0.10122
Total Iteration Time: 3.44291

Cumulative Model Updates: 2,532
Cumulative Timesteps: 21,158,060

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596.25987
Policy Entropy: 2.56452
Value Function Loss: 3.48260

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.03641
Policy Update Magnitude: 0.08498
Value Function Update Magnitude: 0.03193

Collected Steps per Second: 23,600.13321
Overall Steps per Second: 14,602.33304

Timestep Collection Time: 2.11880
Timestep Consumption Time: 1.30558
PPO Batch Consumption Time: 0.09470
Total Iteration Time: 3.42438

Cumulative Model Updates: 2,538
Cumulative Timesteps: 21,208,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 21208064...
Checkpoint 21208064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,595.24294
Policy Entropy: 2.57051
Value Function Loss: 3.43935

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06575
Policy Update Magnitude: 0.07788
Value Function Update Magnitude: 0.04494

Collected Steps per Second: 23,150.53425
Overall Steps per Second: 14,236.53385

Timestep Collection Time: 2.16047
Timestep Consumption Time: 1.35275
PPO Batch Consumption Time: 0.10358
Total Iteration Time: 3.51321

Cumulative Model Updates: 2,544
Cumulative Timesteps: 21,258,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,735.40479
Policy Entropy: 2.55286
Value Function Loss: 3.38196

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.00977
Policy Update Magnitude: 0.07969
Value Function Update Magnitude: 0.05110

Collected Steps per Second: 24,164.00712
Overall Steps per Second: 14,603.37079

Timestep Collection Time: 2.06928
Timestep Consumption Time: 1.35473
PPO Batch Consumption Time: 0.09890
Total Iteration Time: 3.42400

Cumulative Model Updates: 2,550
Cumulative Timesteps: 21,308,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 21308082...
Checkpoint 21308082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.98110
Policy Entropy: 2.57350
Value Function Loss: 3.42814

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02432
Policy Update Magnitude: 0.06891
Value Function Update Magnitude: 0.04511

Collected Steps per Second: 23,009.93937
Overall Steps per Second: 14,129.26218

Timestep Collection Time: 2.17297
Timestep Consumption Time: 1.36578
PPO Batch Consumption Time: 0.10334
Total Iteration Time: 3.53876

Cumulative Model Updates: 2,556
Cumulative Timesteps: 21,358,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,797.30692
Policy Entropy: 2.56013
Value Function Loss: 3.32087

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01039
Policy Update Magnitude: 0.08431
Value Function Update Magnitude: 0.08105

Collected Steps per Second: 23,486.36965
Overall Steps per Second: 14,524.60918

Timestep Collection Time: 2.12941
Timestep Consumption Time: 1.31385
PPO Batch Consumption Time: 0.10448
Total Iteration Time: 3.44326

Cumulative Model Updates: 2,562
Cumulative Timesteps: 21,408,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 21408094...
Checkpoint 21408094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.26786
Policy Entropy: 2.57488
Value Function Loss: 3.23626

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02385
Policy Update Magnitude: 0.08441
Value Function Update Magnitude: 0.06766

Collected Steps per Second: 22,219.85311
Overall Steps per Second: 14,070.06347

Timestep Collection Time: 2.25213
Timestep Consumption Time: 1.30450
PPO Batch Consumption Time: 0.08969
Total Iteration Time: 3.55663

Cumulative Model Updates: 2,568
Cumulative Timesteps: 21,458,136

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.86168
Policy Entropy: 2.56965
Value Function Loss: 3.11561

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02013
Policy Update Magnitude: 0.09140
Value Function Update Magnitude: 0.06322

Collected Steps per Second: 21,479.10178
Overall Steps per Second: 13,512.59514

Timestep Collection Time: 2.32999
Timestep Consumption Time: 1.37367
PPO Batch Consumption Time: 0.10137
Total Iteration Time: 3.70366

Cumulative Model Updates: 2,574
Cumulative Timesteps: 21,508,182

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 21508182...
Checkpoint 21508182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.70744
Policy Entropy: 2.59127
Value Function Loss: 3.07834

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.01396
Policy Update Magnitude: 0.10068
Value Function Update Magnitude: 0.09372

Collected Steps per Second: 22,993.21732
Overall Steps per Second: 14,110.24668

Timestep Collection Time: 2.17464
Timestep Consumption Time: 1.36902
PPO Batch Consumption Time: 0.10219
Total Iteration Time: 3.54367

Cumulative Model Updates: 2,580
Cumulative Timesteps: 21,558,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.00354
Policy Entropy: 2.59235
Value Function Loss: 3.08121

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.01151
Policy Update Magnitude: 0.09692
Value Function Update Magnitude: 0.08437

Collected Steps per Second: 22,787.02685
Overall Steps per Second: 14,270.50027

Timestep Collection Time: 2.19528
Timestep Consumption Time: 1.31013
PPO Batch Consumption Time: 0.09101
Total Iteration Time: 3.50541

Cumulative Model Updates: 2,586
Cumulative Timesteps: 21,608,208

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 21608208...
Checkpoint 21608208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659.77757
Policy Entropy: 2.57818
Value Function Loss: 3.12766

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02557
Policy Update Magnitude: 0.07788
Value Function Update Magnitude: 0.05974

Collected Steps per Second: 23,576.26026
Overall Steps per Second: 14,897.54898

Timestep Collection Time: 2.12213
Timestep Consumption Time: 1.23627
PPO Batch Consumption Time: 0.09520
Total Iteration Time: 3.35840

Cumulative Model Updates: 2,592
Cumulative Timesteps: 21,658,240

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,748.61720
Policy Entropy: 2.57975
Value Function Loss: 3.08626

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01251
Policy Update Magnitude: 0.08475
Value Function Update Magnitude: 0.04242

Collected Steps per Second: 23,624.82378
Overall Steps per Second: 14,318.19645

Timestep Collection Time: 2.11701
Timestep Consumption Time: 1.37603
PPO Batch Consumption Time: 0.10097
Total Iteration Time: 3.49304

Cumulative Model Updates: 2,598
Cumulative Timesteps: 21,708,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 21708254...
Checkpoint 21708254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537.42568
Policy Entropy: 2.57430
Value Function Loss: 3.19824

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.00619
Policy Update Magnitude: 0.10579
Value Function Update Magnitude: 0.03718

Collected Steps per Second: 22,688.61442
Overall Steps per Second: 14,393.05237

Timestep Collection Time: 2.20392
Timestep Consumption Time: 1.27025
PPO Batch Consumption Time: 0.08917
Total Iteration Time: 3.47418

Cumulative Model Updates: 2,604
Cumulative Timesteps: 21,758,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.50292
Policy Entropy: 2.57685
Value Function Loss: 3.31300

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.01956
Policy Update Magnitude: 0.11255
Value Function Update Magnitude: 0.03780

Collected Steps per Second: 24,262.23826
Overall Steps per Second: 14,760.79368

Timestep Collection Time: 2.06123
Timestep Consumption Time: 1.32680
PPO Batch Consumption Time: 0.09442
Total Iteration Time: 3.38803

Cumulative Model Updates: 2,610
Cumulative Timesteps: 21,808,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 21808268...
Checkpoint 21808268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.82182
Policy Entropy: 2.55621
Value Function Loss: 3.18756

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.02646
Policy Update Magnitude: 0.09174
Value Function Update Magnitude: 0.02131

Collected Steps per Second: 22,746.05966
Overall Steps per Second: 14,120.51028

Timestep Collection Time: 2.19906
Timestep Consumption Time: 1.34330
PPO Batch Consumption Time: 0.09520
Total Iteration Time: 3.54236

Cumulative Model Updates: 2,616
Cumulative Timesteps: 21,858,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821.96566
Policy Entropy: 2.53584
Value Function Loss: 2.98801

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.08638
Value Function Update Magnitude: 0.02509

Collected Steps per Second: 23,191.37686
Overall Steps per Second: 14,768.08826

Timestep Collection Time: 2.15606
Timestep Consumption Time: 1.22975
PPO Batch Consumption Time: 0.10584
Total Iteration Time: 3.38581

Cumulative Model Updates: 2,622
Cumulative Timesteps: 21,908,290

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 21908290...
Checkpoint 21908290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.55936
Policy Entropy: 2.54765
Value Function Loss: 2.93786

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.01236
Policy Update Magnitude: 0.07786
Value Function Update Magnitude: 0.02328

Collected Steps per Second: 23,315.93767
Overall Steps per Second: 14,759.65804

Timestep Collection Time: 2.14523
Timestep Consumption Time: 1.24360
PPO Batch Consumption Time: 0.09016
Total Iteration Time: 3.38883

Cumulative Model Updates: 2,628
Cumulative Timesteps: 21,958,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622.28060
Policy Entropy: 2.52285
Value Function Loss: 3.02088

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.04231
Policy Update Magnitude: 0.07125
Value Function Update Magnitude: 0.03722

Collected Steps per Second: 24,116.86250
Overall Steps per Second: 15,177.86291

Timestep Collection Time: 2.07415
Timestep Consumption Time: 1.22157
PPO Batch Consumption Time: 0.09893
Total Iteration Time: 3.29572

Cumulative Model Updates: 2,634
Cumulative Timesteps: 22,008,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 22008330...
Checkpoint 22008330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703.52742
Policy Entropy: 2.50056
Value Function Loss: 3.02895

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.01944
Policy Update Magnitude: 0.08500
Value Function Update Magnitude: 0.04611

Collected Steps per Second: 25,235.06812
Overall Steps per Second: 15,561.81998

Timestep Collection Time: 1.98177
Timestep Consumption Time: 1.23187
PPO Batch Consumption Time: 0.10026
Total Iteration Time: 3.21363

Cumulative Model Updates: 2,640
Cumulative Timesteps: 22,058,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.10552
Policy Entropy: 2.49572
Value Function Loss: 3.01351

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.01566
Policy Update Magnitude: 0.09621
Value Function Update Magnitude: 0.10041

Collected Steps per Second: 24,468.12908
Overall Steps per Second: 15,444.29490

Timestep Collection Time: 2.04413
Timestep Consumption Time: 1.19435
PPO Batch Consumption Time: 0.09225
Total Iteration Time: 3.23848

Cumulative Model Updates: 2,646
Cumulative Timesteps: 22,108,356

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 22108356...
Checkpoint 22108356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,612.07973
Policy Entropy: 2.49419
Value Function Loss: 2.98618

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01561
Policy Update Magnitude: 0.08870
Value Function Update Magnitude: 0.12124

Collected Steps per Second: 23,904.56180
Overall Steps per Second: 15,322.74520

Timestep Collection Time: 2.09282
Timestep Consumption Time: 1.17213
PPO Batch Consumption Time: 0.09890
Total Iteration Time: 3.26495

Cumulative Model Updates: 2,652
Cumulative Timesteps: 22,158,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.04163
Policy Entropy: 2.50330
Value Function Loss: 2.95161

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.00755
Policy Update Magnitude: 0.08700
Value Function Update Magnitude: 0.12083

Collected Steps per Second: 24,176.34955
Overall Steps per Second: 15,244.10739

Timestep Collection Time: 2.06822
Timestep Consumption Time: 1.21187
PPO Batch Consumption Time: 0.09401
Total Iteration Time: 3.28009

Cumulative Model Updates: 2,658
Cumulative Timesteps: 22,208,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 22208386...
Checkpoint 22208386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,810.06179
Policy Entropy: 2.49231
Value Function Loss: 3.12691

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.01830
Policy Update Magnitude: 0.10874
Value Function Update Magnitude: 0.10061

Collected Steps per Second: 24,339.52538
Overall Steps per Second: 15,288.94040

Timestep Collection Time: 2.05476
Timestep Consumption Time: 1.21636
PPO Batch Consumption Time: 0.09944
Total Iteration Time: 3.27112

Cumulative Model Updates: 2,664
Cumulative Timesteps: 22,258,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.59130
Policy Entropy: 2.47494
Value Function Loss: 3.17351

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.03375
Policy Update Magnitude: 0.10678
Value Function Update Magnitude: 0.10191

Collected Steps per Second: 24,570.38788
Overall Steps per Second: 15,310.86746

Timestep Collection Time: 2.03562
Timestep Consumption Time: 1.23108
PPO Batch Consumption Time: 0.09976
Total Iteration Time: 3.26670

Cumulative Model Updates: 2,670
Cumulative Timesteps: 22,308,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 22308414...
Checkpoint 22308414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.37203
Policy Entropy: 2.48461
Value Function Loss: 3.15389

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01155
Policy Update Magnitude: 0.09459
Value Function Update Magnitude: 0.12423

Collected Steps per Second: 24,357.80656
Overall Steps per Second: 14,915.81246

Timestep Collection Time: 2.05372
Timestep Consumption Time: 1.30004
PPO Batch Consumption Time: 0.10594
Total Iteration Time: 3.35376

Cumulative Model Updates: 2,676
Cumulative Timesteps: 22,358,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.11727
Policy Entropy: 2.48696
Value Function Loss: 3.03990

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.03179
Policy Update Magnitude: 0.08927
Value Function Update Magnitude: 0.12880

Collected Steps per Second: 24,189.01632
Overall Steps per Second: 15,393.93943

Timestep Collection Time: 2.06788
Timestep Consumption Time: 1.18145
PPO Batch Consumption Time: 0.10418
Total Iteration Time: 3.24933

Cumulative Model Updates: 2,682
Cumulative Timesteps: 22,408,458

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 22408458...
Checkpoint 22408458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.05198
Policy Entropy: 2.48738
Value Function Loss: 3.22878

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02396
Policy Update Magnitude: 0.07742
Value Function Update Magnitude: 0.09970

Collected Steps per Second: 24,343.24323
Overall Steps per Second: 15,269.11122

Timestep Collection Time: 2.05462
Timestep Consumption Time: 1.22102
PPO Batch Consumption Time: 0.09914
Total Iteration Time: 3.27563

Cumulative Model Updates: 2,688
Cumulative Timesteps: 22,458,474

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,734.85879
Policy Entropy: 2.47661
Value Function Loss: 3.23943

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.01344
Policy Update Magnitude: 0.07960
Value Function Update Magnitude: 0.07734

Collected Steps per Second: 24,173.54254
Overall Steps per Second: 15,380.66831

Timestep Collection Time: 2.06879
Timestep Consumption Time: 1.18269
PPO Batch Consumption Time: 0.09577
Total Iteration Time: 3.25148

Cumulative Model Updates: 2,694
Cumulative Timesteps: 22,508,484

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 22508484...
Checkpoint 22508484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.55747
Policy Entropy: 2.44332
Value Function Loss: 3.31764

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.01310
Policy Update Magnitude: 0.07150
Value Function Update Magnitude: 0.05822

Collected Steps per Second: 23,632.40858
Overall Steps per Second: 15,622.03498

Timestep Collection Time: 2.11591
Timestep Consumption Time: 1.08496
PPO Batch Consumption Time: 0.09046
Total Iteration Time: 3.20086

Cumulative Model Updates: 2,700
Cumulative Timesteps: 22,558,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,839.98859
Policy Entropy: 2.41159
Value Function Loss: 3.29038

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.01917
Policy Update Magnitude: 0.07920
Value Function Update Magnitude: 0.05558

Collected Steps per Second: 24,418.33213
Overall Steps per Second: 15,242.02600

Timestep Collection Time: 2.04764
Timestep Consumption Time: 1.23276
PPO Batch Consumption Time: 0.09980
Total Iteration Time: 3.28040

Cumulative Model Updates: 2,706
Cumulative Timesteps: 22,608,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 22608488...
Checkpoint 22608488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719.90012
Policy Entropy: 2.43955
Value Function Loss: 3.28633

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02015
Policy Update Magnitude: 0.08221
Value Function Update Magnitude: 0.04981

Collected Steps per Second: 24,242.65338
Overall Steps per Second: 15,373.66720

Timestep Collection Time: 2.06306
Timestep Consumption Time: 1.19017
PPO Batch Consumption Time: 0.09520
Total Iteration Time: 3.25323

Cumulative Model Updates: 2,712
Cumulative Timesteps: 22,658,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,808.40023
Policy Entropy: 2.44943
Value Function Loss: 3.19315

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01616
Policy Update Magnitude: 0.07776
Value Function Update Magnitude: 0.04105

Collected Steps per Second: 25,093.85865
Overall Steps per Second: 15,628.67679

Timestep Collection Time: 1.99324
Timestep Consumption Time: 1.20716
PPO Batch Consumption Time: 0.09472
Total Iteration Time: 3.20040

Cumulative Model Updates: 2,718
Cumulative Timesteps: 22,708,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 22708520...
Checkpoint 22708520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.03872
Policy Entropy: 2.41330
Value Function Loss: 3.16484

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.01832
Policy Update Magnitude: 0.08732
Value Function Update Magnitude: 0.02941

Collected Steps per Second: 24,096.97657
Overall Steps per Second: 15,036.55082

Timestep Collection Time: 2.07520
Timestep Consumption Time: 1.25043
PPO Batch Consumption Time: 0.10124
Total Iteration Time: 3.32563

Cumulative Model Updates: 2,724
Cumulative Timesteps: 22,758,526

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493.13414
Policy Entropy: 2.39628
Value Function Loss: 3.00703

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03163
Policy Update Magnitude: 0.08685
Value Function Update Magnitude: 0.03479

Collected Steps per Second: 24,227.69968
Overall Steps per Second: 15,526.02111

Timestep Collection Time: 2.06425
Timestep Consumption Time: 1.15692
PPO Batch Consumption Time: 0.09666
Total Iteration Time: 3.22117

Cumulative Model Updates: 2,730
Cumulative Timesteps: 22,808,538

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 22808538...
Checkpoint 22808538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.85113
Policy Entropy: 2.36593
Value Function Loss: 2.90118

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.01524
Policy Update Magnitude: 0.08980
Value Function Update Magnitude: 0.05588

Collected Steps per Second: 24,551.21858
Overall Steps per Second: 15,638.11111

Timestep Collection Time: 2.03762
Timestep Consumption Time: 1.16136
PPO Batch Consumption Time: 0.08944
Total Iteration Time: 3.19898

Cumulative Model Updates: 2,736
Cumulative Timesteps: 22,858,564

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852.85570
Policy Entropy: 2.35357
Value Function Loss: 2.89045

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.01668
Policy Update Magnitude: 0.09357
Value Function Update Magnitude: 0.07885

Collected Steps per Second: 24,202.86008
Overall Steps per Second: 15,270.97152

Timestep Collection Time: 2.06695
Timestep Consumption Time: 1.20894
PPO Batch Consumption Time: 0.09909
Total Iteration Time: 3.27589

Cumulative Model Updates: 2,742
Cumulative Timesteps: 22,908,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 22908590...
Checkpoint 22908590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,726.42876
Policy Entropy: 2.38747
Value Function Loss: 2.93336

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.01982
Policy Update Magnitude: 0.08673
Value Function Update Magnitude: 0.08415

Collected Steps per Second: 25,184.89239
Overall Steps per Second: 15,554.78919

Timestep Collection Time: 1.98595
Timestep Consumption Time: 1.22952
PPO Batch Consumption Time: 0.10018
Total Iteration Time: 3.21547

Cumulative Model Updates: 2,748
Cumulative Timesteps: 22,958,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675.61134
Policy Entropy: 2.36023
Value Function Loss: 2.94212

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02156
Policy Update Magnitude: 0.07303
Value Function Update Magnitude: 0.05942

Collected Steps per Second: 24,328.48404
Overall Steps per Second: 15,395.77318

Timestep Collection Time: 2.05627
Timestep Consumption Time: 1.19306
PPO Batch Consumption Time: 0.09285
Total Iteration Time: 3.24933

Cumulative Model Updates: 2,754
Cumulative Timesteps: 23,008,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 23008632...
Checkpoint 23008632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642.61110
Policy Entropy: 2.38365
Value Function Loss: 2.92206

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.01800
Policy Update Magnitude: 0.08749
Value Function Update Magnitude: 0.04964

Collected Steps per Second: 24,009.78945
Overall Steps per Second: 15,732.63110

Timestep Collection Time: 2.08265
Timestep Consumption Time: 1.09571
PPO Batch Consumption Time: 0.09024
Total Iteration Time: 3.17836

Cumulative Model Updates: 2,760
Cumulative Timesteps: 23,058,636

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,849.09816
Policy Entropy: 2.41589
Value Function Loss: 2.91170

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.07350
Value Function Update Magnitude: 0.04669

Collected Steps per Second: 24,322.37400
Overall Steps per Second: 15,158.93563

Timestep Collection Time: 2.05662
Timestep Consumption Time: 1.24321
PPO Batch Consumption Time: 0.09895
Total Iteration Time: 3.29984

Cumulative Model Updates: 2,766
Cumulative Timesteps: 23,108,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 23108658...
Checkpoint 23108658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.05484
Policy Entropy: 2.41228
Value Function Loss: 3.01643

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.01485
Policy Update Magnitude: 0.06915
Value Function Update Magnitude: 0.04509

Collected Steps per Second: 24,505.09173
Overall Steps per Second: 15,517.71724

Timestep Collection Time: 2.04153
Timestep Consumption Time: 1.18239
PPO Batch Consumption Time: 0.09689
Total Iteration Time: 3.22393

Cumulative Model Updates: 2,772
Cumulative Timesteps: 23,158,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.14327
Policy Entropy: 2.42007
Value Function Loss: 3.12434

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01633
Policy Update Magnitude: 0.08425
Value Function Update Magnitude: 0.03651

Collected Steps per Second: 24,863.72831
Overall Steps per Second: 15,544.70424

Timestep Collection Time: 2.01120
Timestep Consumption Time: 1.20571
PPO Batch Consumption Time: 0.09213
Total Iteration Time: 3.21692

Cumulative Model Updates: 2,778
Cumulative Timesteps: 23,208,692

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 23208692...
Checkpoint 23208692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.93022
Policy Entropy: 2.39671
Value Function Loss: 3.19699

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02097
Policy Update Magnitude: 0.09229
Value Function Update Magnitude: 0.03774

Collected Steps per Second: 24,527.35060
Overall Steps per Second: 15,401.79431

Timestep Collection Time: 2.03854
Timestep Consumption Time: 1.20783
PPO Batch Consumption Time: 0.09846
Total Iteration Time: 3.24637

Cumulative Model Updates: 2,784
Cumulative Timesteps: 23,258,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.96381
Policy Entropy: 2.41398
Value Function Loss: 3.22569

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.01241
Policy Update Magnitude: 0.09244
Value Function Update Magnitude: 0.04579

Collected Steps per Second: 22,917.57458
Overall Steps per Second: 15,119.31307

Timestep Collection Time: 2.18243
Timestep Consumption Time: 1.12566
PPO Batch Consumption Time: 0.09540
Total Iteration Time: 3.30809

Cumulative Model Updates: 2,790
Cumulative Timesteps: 23,308,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 23308708...
Checkpoint 23308708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,640.63996
Policy Entropy: 2.42187
Value Function Loss: 3.23885

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01049
Policy Update Magnitude: 0.08091
Value Function Update Magnitude: 0.07044

Collected Steps per Second: 23,762.46580
Overall Steps per Second: 14,820.47663

Timestep Collection Time: 2.10475
Timestep Consumption Time: 1.26991
PPO Batch Consumption Time: 0.10477
Total Iteration Time: 3.37466

Cumulative Model Updates: 2,796
Cumulative Timesteps: 23,358,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.36663
Policy Entropy: 2.34520
Value Function Loss: 3.30410

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.01501
Policy Update Magnitude: 0.07846
Value Function Update Magnitude: 0.09498

Collected Steps per Second: 20,962.97064
Overall Steps per Second: 13,559.95023

Timestep Collection Time: 2.38611
Timestep Consumption Time: 1.30269
PPO Batch Consumption Time: 0.10380
Total Iteration Time: 3.68880

Cumulative Model Updates: 2,802
Cumulative Timesteps: 23,408,742

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 23408742...
Checkpoint 23408742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,756.47804
Policy Entropy: 2.38104
Value Function Loss: 3.32562

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.01904
Policy Update Magnitude: 0.09709
Value Function Update Magnitude: 0.09364

Collected Steps per Second: 23,576.75852
Overall Steps per Second: 14,636.58833

Timestep Collection Time: 2.12107
Timestep Consumption Time: 1.29557
PPO Batch Consumption Time: 0.10019
Total Iteration Time: 3.41664

Cumulative Model Updates: 2,808
Cumulative Timesteps: 23,458,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.02675
Policy Entropy: 2.38156
Value Function Loss: 3.21413

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02282
Policy Update Magnitude: 0.09264
Value Function Update Magnitude: 0.06349

Collected Steps per Second: 23,094.49099
Overall Steps per Second: 14,694.86867

Timestep Collection Time: 2.16623
Timestep Consumption Time: 1.23822
PPO Batch Consumption Time: 0.10093
Total Iteration Time: 3.40445

Cumulative Model Updates: 2,814
Cumulative Timesteps: 23,508,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 23508778...
Checkpoint 23508778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.49283
Policy Entropy: 2.35538
Value Function Loss: 3.12542

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.01533
Policy Update Magnitude: 0.09326
Value Function Update Magnitude: 0.05090

Collected Steps per Second: 23,949.24988
Overall Steps per Second: 15,229.62940

Timestep Collection Time: 2.08892
Timestep Consumption Time: 1.19600
PPO Batch Consumption Time: 0.10633
Total Iteration Time: 3.28491

Cumulative Model Updates: 2,820
Cumulative Timesteps: 23,558,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614.41933
Policy Entropy: 2.37599
Value Function Loss: 3.14454

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.02568
Policy Update Magnitude: 0.07729
Value Function Update Magnitude: 0.03934

Collected Steps per Second: 24,014.41153
Overall Steps per Second: 15,228.53581

Timestep Collection Time: 2.08300
Timestep Consumption Time: 1.20176
PPO Batch Consumption Time: 0.09617
Total Iteration Time: 3.28475

Cumulative Model Updates: 2,826
Cumulative Timesteps: 23,608,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 23608828...
Checkpoint 23608828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.03374
Policy Entropy: 2.39383
Value Function Loss: 3.11008

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.01571
Policy Update Magnitude: 0.07828
Value Function Update Magnitude: 0.03141

Collected Steps per Second: 23,800.11181
Overall Steps per Second: 14,759.77421

Timestep Collection Time: 2.10091
Timestep Consumption Time: 1.28681
PPO Batch Consumption Time: 0.10381
Total Iteration Time: 3.38772

Cumulative Model Updates: 2,832
Cumulative Timesteps: 23,658,830

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,789.99707
Policy Entropy: 2.33845
Value Function Loss: 3.20271

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02671
Policy Update Magnitude: 0.08583
Value Function Update Magnitude: 0.02292

Collected Steps per Second: 23,512.30555
Overall Steps per Second: 14,881.32300

Timestep Collection Time: 2.12706
Timestep Consumption Time: 1.23367
PPO Batch Consumption Time: 0.10002
Total Iteration Time: 3.36072

Cumulative Model Updates: 2,838
Cumulative Timesteps: 23,708,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 23708842...
Checkpoint 23708842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642.94787
Policy Entropy: 2.35520
Value Function Loss: 3.13281

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.07042
Value Function Update Magnitude: 0.02275

Collected Steps per Second: 24,051.47258
Overall Steps per Second: 15,161.39224

Timestep Collection Time: 2.07904
Timestep Consumption Time: 1.21907
PPO Batch Consumption Time: 0.09827
Total Iteration Time: 3.29811

Cumulative Model Updates: 2,844
Cumulative Timesteps: 23,758,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.16808
Policy Entropy: 2.34692
Value Function Loss: 3.32438

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02800
Policy Update Magnitude: 0.06997
Value Function Update Magnitude: 0.02344

Collected Steps per Second: 22,950.70219
Overall Steps per Second: 15,092.71517

Timestep Collection Time: 2.17963
Timestep Consumption Time: 1.13482
PPO Batch Consumption Time: 0.09099
Total Iteration Time: 3.31445

Cumulative Model Updates: 2,850
Cumulative Timesteps: 23,808,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 23808870...
Checkpoint 23808870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,876.82608
Policy Entropy: 2.35618
Value Function Loss: 3.69711

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.03410
Policy Update Magnitude: 0.07361
Value Function Update Magnitude: 0.02149

Collected Steps per Second: 21,714.71655
Overall Steps per Second: 13,845.28511

Timestep Collection Time: 2.30277
Timestep Consumption Time: 1.30886
PPO Batch Consumption Time: 0.10476
Total Iteration Time: 3.61163

Cumulative Model Updates: 2,856
Cumulative Timesteps: 23,858,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.75991
Policy Entropy: 2.35941
Value Function Loss: 3.59228

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.01266
Policy Update Magnitude: 0.08537
Value Function Update Magnitude: 0.02364

Collected Steps per Second: 21,211.49137
Overall Steps per Second: 14,761.31134

Timestep Collection Time: 2.35844
Timestep Consumption Time: 1.03056
PPO Batch Consumption Time: 0.07330
Total Iteration Time: 3.38899

Cumulative Model Updates: 2,862
Cumulative Timesteps: 23,908,900

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 23908900...
Checkpoint 23908900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.22873
Policy Entropy: 2.37892
Value Function Loss: 3.50172

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.01074
Policy Update Magnitude: 0.08452
Value Function Update Magnitude: 0.02231

Collected Steps per Second: 22,743.63971
Overall Steps per Second: 14,436.42475

Timestep Collection Time: 2.19886
Timestep Consumption Time: 1.26530
PPO Batch Consumption Time: 0.10197
Total Iteration Time: 3.46415

Cumulative Model Updates: 2,868
Cumulative Timesteps: 23,958,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,752.81466
Policy Entropy: 2.37262
Value Function Loss: 3.39722

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.01577
Policy Update Magnitude: 0.07512
Value Function Update Magnitude: 0.01546

Collected Steps per Second: 23,949.26102
Overall Steps per Second: 15,030.71087

Timestep Collection Time: 2.08783
Timestep Consumption Time: 1.23883
PPO Batch Consumption Time: 0.10064
Total Iteration Time: 3.32666

Cumulative Model Updates: 2,874
Cumulative Timesteps: 24,008,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 24008912...
Checkpoint 24008912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636.18830
Policy Entropy: 2.39646
Value Function Loss: 3.30147

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.01809
Policy Update Magnitude: 0.08819
Value Function Update Magnitude: 0.01710

Collected Steps per Second: 22,480.30714
Overall Steps per Second: 15,449.38921

Timestep Collection Time: 2.22417
Timestep Consumption Time: 1.01220
PPO Batch Consumption Time: 0.07757
Total Iteration Time: 3.23637

Cumulative Model Updates: 2,880
Cumulative Timesteps: 24,058,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685.24485
Policy Entropy: 2.42978
Value Function Loss: 3.21297

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.02881
Policy Update Magnitude: 0.08809
Value Function Update Magnitude: 0.01983

Collected Steps per Second: 21,894.18601
Overall Steps per Second: 13,890.81663

Timestep Collection Time: 2.28371
Timestep Consumption Time: 1.31579
PPO Batch Consumption Time: 0.10573
Total Iteration Time: 3.59950

Cumulative Model Updates: 2,886
Cumulative Timesteps: 24,108,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 24108912...
Checkpoint 24108912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,770.62099
Policy Entropy: 2.40724
Value Function Loss: 3.18635

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.00890
Policy Update Magnitude: 0.09811
Value Function Update Magnitude: 0.01509

Collected Steps per Second: 22,110.15902
Overall Steps per Second: 14,162.44008

Timestep Collection Time: 2.26204
Timestep Consumption Time: 1.26942
PPO Batch Consumption Time: 0.10447
Total Iteration Time: 3.53145

Cumulative Model Updates: 2,892
Cumulative Timesteps: 24,158,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.73169
Policy Entropy: 2.44308
Value Function Loss: 3.17021

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.08537
Value Function Update Magnitude: 0.01987

Collected Steps per Second: 23,216.04592
Overall Steps per Second: 14,854.15541

Timestep Collection Time: 2.15377
Timestep Consumption Time: 1.21243
PPO Batch Consumption Time: 0.10223
Total Iteration Time: 3.36620

Cumulative Model Updates: 2,898
Cumulative Timesteps: 24,208,928

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 24208928...
Checkpoint 24208928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,741.97308
Policy Entropy: 2.45146
Value Function Loss: 3.11659

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.01046
Policy Update Magnitude: 0.08361
Value Function Update Magnitude: 0.02789

Collected Steps per Second: 22,129.22827
Overall Steps per Second: 13,981.23957

Timestep Collection Time: 2.26072
Timestep Consumption Time: 1.31750
PPO Batch Consumption Time: 0.10474
Total Iteration Time: 3.57822

Cumulative Model Updates: 2,904
Cumulative Timesteps: 24,258,956

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.35013
Policy Entropy: 2.46287
Value Function Loss: 3.14552

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.00930
Policy Update Magnitude: 0.08910
Value Function Update Magnitude: 0.02977

Collected Steps per Second: 22,312.11213
Overall Steps per Second: 14,537.23001

Timestep Collection Time: 2.24210
Timestep Consumption Time: 1.19913
PPO Batch Consumption Time: 0.09635
Total Iteration Time: 3.44123

Cumulative Model Updates: 2,910
Cumulative Timesteps: 24,308,982

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 24308982...
Checkpoint 24308982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,674.24704
Policy Entropy: 2.45664
Value Function Loss: 3.05999

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.00397
Policy Update Magnitude: 0.10415
Value Function Update Magnitude: 0.02631

Collected Steps per Second: 25,181.24855
Overall Steps per Second: 15,645.06980

Timestep Collection Time: 1.98632
Timestep Consumption Time: 1.21073
PPO Batch Consumption Time: 0.09239
Total Iteration Time: 3.19705

Cumulative Model Updates: 2,916
Cumulative Timesteps: 24,359,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822.75936
Policy Entropy: 2.44558
Value Function Loss: 3.02029

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02654
Policy Update Magnitude: 0.08328
Value Function Update Magnitude: 0.02275

Collected Steps per Second: 23,725.37846
Overall Steps per Second: 14,949.65113

Timestep Collection Time: 2.10913
Timestep Consumption Time: 1.23810
PPO Batch Consumption Time: 0.10073
Total Iteration Time: 3.34724

Cumulative Model Updates: 2,922
Cumulative Timesteps: 24,409,040

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 24409040...
Checkpoint 24409040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,851.55356
Policy Entropy: 2.47686
Value Function Loss: 2.98318

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.01000
Policy Update Magnitude: 0.07877
Value Function Update Magnitude: 0.02530

Collected Steps per Second: 21,505.62696
Overall Steps per Second: 14,332.03435

Timestep Collection Time: 2.32544
Timestep Consumption Time: 1.16395
PPO Batch Consumption Time: 0.09526
Total Iteration Time: 3.48939

Cumulative Model Updates: 2,928
Cumulative Timesteps: 24,459,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822.01527
Policy Entropy: 2.47704
Value Function Loss: 2.94173

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.03320
Policy Update Magnitude: 0.10796
Value Function Update Magnitude: 0.01648

Collected Steps per Second: 20,418.62259
Overall Steps per Second: 13,205.86360

Timestep Collection Time: 2.44933
Timestep Consumption Time: 1.33777
PPO Batch Consumption Time: 0.10170
Total Iteration Time: 3.78711

Cumulative Model Updates: 2,934
Cumulative Timesteps: 24,509,062

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 24509062...
Checkpoint 24509062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.00941
Policy Entropy: 2.46543
Value Function Loss: 3.08675

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02350
Policy Update Magnitude: 0.10867
Value Function Update Magnitude: 0.02023

Collected Steps per Second: 19,702.14720
Overall Steps per Second: 13,997.11199

Timestep Collection Time: 2.53901
Timestep Consumption Time: 1.03487
PPO Batch Consumption Time: 0.07329
Total Iteration Time: 3.57388

Cumulative Model Updates: 2,940
Cumulative Timesteps: 24,559,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,791.86472
Policy Entropy: 2.46641
Value Function Loss: 2.98263

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.01999
Policy Update Magnitude: 0.10127
Value Function Update Magnitude: 0.01806

Collected Steps per Second: 22,350.72793
Overall Steps per Second: 14,477.95399

Timestep Collection Time: 2.23760
Timestep Consumption Time: 1.21675
PPO Batch Consumption Time: 0.09688
Total Iteration Time: 3.45436

Cumulative Model Updates: 2,946
Cumulative Timesteps: 24,609,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 24609098...
Checkpoint 24609098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.69787
Policy Entropy: 2.45453
Value Function Loss: 2.86703

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.08068
Value Function Update Magnitude: 0.02800

Collected Steps per Second: 23,053.38743
Overall Steps per Second: 14,672.85612

Timestep Collection Time: 2.16957
Timestep Consumption Time: 1.23917
PPO Batch Consumption Time: 0.09507
Total Iteration Time: 3.40874

Cumulative Model Updates: 2,952
Cumulative Timesteps: 24,659,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,607.34337
Policy Entropy: 2.43813
Value Function Loss: 2.82793

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.01399
Policy Update Magnitude: 0.09666
Value Function Update Magnitude: 0.03041

Collected Steps per Second: 23,585.62849
Overall Steps per Second: 15,207.93989

Timestep Collection Time: 2.12087
Timestep Consumption Time: 1.16834
PPO Batch Consumption Time: 0.09974
Total Iteration Time: 3.28920

Cumulative Model Updates: 2,958
Cumulative Timesteps: 24,709,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 24709136...
Checkpoint 24709136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,692.69723
Policy Entropy: 2.39506
Value Function Loss: 2.63014

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.02651
Policy Update Magnitude: 0.09463
Value Function Update Magnitude: 0.02348

Collected Steps per Second: 21,151.56421
Overall Steps per Second: 14,437.92700

Timestep Collection Time: 2.36531
Timestep Consumption Time: 1.09987
PPO Batch Consumption Time: 0.07442
Total Iteration Time: 3.46518

Cumulative Model Updates: 2,964
Cumulative Timesteps: 24,759,166

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.89564
Policy Entropy: 2.39152
Value Function Loss: 2.79602

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.04159
Policy Update Magnitude: 0.09180
Value Function Update Magnitude: 0.04192

Collected Steps per Second: 22,875.98082
Overall Steps per Second: 14,649.65968

Timestep Collection Time: 2.18622
Timestep Consumption Time: 1.22764
PPO Batch Consumption Time: 0.09707
Total Iteration Time: 3.41387

Cumulative Model Updates: 2,970
Cumulative Timesteps: 24,809,178

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 24809178...
Checkpoint 24809178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,688.21045
Policy Entropy: 2.38347
Value Function Loss: 3.07963

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.02084
Policy Update Magnitude: 0.08066
Value Function Update Magnitude: 0.02707

Collected Steps per Second: 24,048.89792
Overall Steps per Second: 14,980.45807

Timestep Collection Time: 2.07968
Timestep Consumption Time: 1.25894
PPO Batch Consumption Time: 0.10163
Total Iteration Time: 3.33862

Cumulative Model Updates: 2,976
Cumulative Timesteps: 24,859,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755.80942
Policy Entropy: 2.38072
Value Function Loss: 3.04854

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.02618
Policy Update Magnitude: 0.07092
Value Function Update Magnitude: 0.02787

Collected Steps per Second: 23,687.25101
Overall Steps per Second: 14,997.40284

Timestep Collection Time: 2.11177
Timestep Consumption Time: 1.22361
PPO Batch Consumption Time: 0.09757
Total Iteration Time: 3.33538

Cumulative Model Updates: 2,982
Cumulative Timesteps: 24,909,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 24909214...
Checkpoint 24909214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,758.97089
Policy Entropy: 2.36357
Value Function Loss: 3.00932

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.01213
Policy Update Magnitude: 0.06765
Value Function Update Magnitude: 0.01940

Collected Steps per Second: 21,972.46129
Overall Steps per Second: 14,449.67986

Timestep Collection Time: 2.27658
Timestep Consumption Time: 1.18523
PPO Batch Consumption Time: 0.10285
Total Iteration Time: 3.46181

Cumulative Model Updates: 2,988
Cumulative Timesteps: 24,959,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.05780
Policy Entropy: 2.37289
Value Function Loss: 2.94568

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.01600
Policy Update Magnitude: 0.06560
Value Function Update Magnitude: 0.01716

Collected Steps per Second: 22,860.96869
Overall Steps per Second: 14,816.09583

Timestep Collection Time: 2.18783
Timestep Consumption Time: 1.18795
PPO Batch Consumption Time: 0.09309
Total Iteration Time: 3.37579

Cumulative Model Updates: 2,994
Cumulative Timesteps: 25,009,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 25009252...
Checkpoint 25009252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.46381
Policy Entropy: 2.34857
Value Function Loss: 2.87805

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.03361
Policy Update Magnitude: 0.07843
Value Function Update Magnitude: 0.01769

Collected Steps per Second: 23,210.09259
Overall Steps per Second: 14,946.12088

Timestep Collection Time: 2.15527
Timestep Consumption Time: 1.19169
PPO Batch Consumption Time: 0.09642
Total Iteration Time: 3.34696

Cumulative Model Updates: 3,000
Cumulative Timesteps: 25,059,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.51445
Policy Entropy: 2.35589
Value Function Loss: 2.91845

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.01371
Policy Update Magnitude: 0.07119
Value Function Update Magnitude: 0.02047

Collected Steps per Second: 22,484.57878
Overall Steps per Second: 14,264.64752

Timestep Collection Time: 2.22401
Timestep Consumption Time: 1.28158
PPO Batch Consumption Time: 0.10056
Total Iteration Time: 3.50559

Cumulative Model Updates: 3,006
Cumulative Timesteps: 25,109,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 25109282...
Checkpoint 25109282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.65869
Policy Entropy: 2.35590
Value Function Loss: 2.96179

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.01977
Policy Update Magnitude: 0.06974
Value Function Update Magnitude: 0.02468

Collected Steps per Second: 22,571.69939
Overall Steps per Second: 14,518.29284

Timestep Collection Time: 2.21658
Timestep Consumption Time: 1.22955
PPO Batch Consumption Time: 0.09642
Total Iteration Time: 3.44614

Cumulative Model Updates: 3,012
Cumulative Timesteps: 25,159,314

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722.18702
Policy Entropy: 2.35848
Value Function Loss: 3.23971

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02119
Policy Update Magnitude: 0.07441
Value Function Update Magnitude: 0.02445

Collected Steps per Second: 21,640.75269
Overall Steps per Second: 14,925.21059

Timestep Collection Time: 2.31156
Timestep Consumption Time: 1.04008
PPO Batch Consumption Time: 0.07890
Total Iteration Time: 3.35164

Cumulative Model Updates: 3,018
Cumulative Timesteps: 25,209,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 25209338...
Checkpoint 25209338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.67894
Policy Entropy: 2.34824
Value Function Loss: 3.33532

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05568
Policy Update Magnitude: 0.06993
Value Function Update Magnitude: 0.02885

Collected Steps per Second: 22,273.90779
Overall Steps per Second: 14,612.10682

Timestep Collection Time: 2.24559
Timestep Consumption Time: 1.17746
PPO Batch Consumption Time: 0.09081
Total Iteration Time: 3.42305

Cumulative Model Updates: 3,024
Cumulative Timesteps: 25,259,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645.08856
Policy Entropy: 2.36785
Value Function Loss: 3.21654

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.02466
Policy Update Magnitude: 0.08158
Value Function Update Magnitude: 0.02086

Collected Steps per Second: 21,173.24013
Overall Steps per Second: 13,730.94760

Timestep Collection Time: 2.36251
Timestep Consumption Time: 1.28050
PPO Batch Consumption Time: 0.10038
Total Iteration Time: 3.64301

Cumulative Model Updates: 3,030
Cumulative Timesteps: 25,309,378

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 25309378...
Checkpoint 25309378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.80295
Policy Entropy: 2.36487
Value Function Loss: 2.96585

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.01422
Policy Update Magnitude: 0.08715
Value Function Update Magnitude: 0.01690

Collected Steps per Second: 24,730.40105
Overall Steps per Second: 15,166.78965

Timestep Collection Time: 2.02221
Timestep Consumption Time: 1.27513
PPO Batch Consumption Time: 0.10499
Total Iteration Time: 3.29734

Cumulative Model Updates: 3,036
Cumulative Timesteps: 25,359,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,789.47780
Policy Entropy: 2.31999
Value Function Loss: 2.81072

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.01671
Policy Update Magnitude: 0.07961
Value Function Update Magnitude: 0.01400

Collected Steps per Second: 21,934.16802
Overall Steps per Second: 14,116.70050

Timestep Collection Time: 2.28010
Timestep Consumption Time: 1.26266
PPO Batch Consumption Time: 0.10013
Total Iteration Time: 3.54275

Cumulative Model Updates: 3,042
Cumulative Timesteps: 25,409,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 25409400...
Checkpoint 25409400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.96621
Policy Entropy: 2.35939
Value Function Loss: 2.83426

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01151
Policy Update Magnitude: 0.06557
Value Function Update Magnitude: 0.05503

Collected Steps per Second: 22,212.48279
Overall Steps per Second: 14,611.37006

Timestep Collection Time: 2.25270
Timestep Consumption Time: 1.17190
PPO Batch Consumption Time: 0.09695
Total Iteration Time: 3.42459

Cumulative Model Updates: 3,048
Cumulative Timesteps: 25,459,438

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.32117
Policy Entropy: 2.35375
Value Function Loss: 2.81750

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02247
Policy Update Magnitude: 0.08142
Value Function Update Magnitude: 0.09008

Collected Steps per Second: 23,365.31766
Overall Steps per Second: 14,737.06473

Timestep Collection Time: 2.14069
Timestep Consumption Time: 1.25333
PPO Batch Consumption Time: 0.09805
Total Iteration Time: 3.39403

Cumulative Model Updates: 3,054
Cumulative Timesteps: 25,509,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 25509456...
Checkpoint 25509456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.55238
Policy Entropy: 2.37806
Value Function Loss: 2.85276

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.02409
Policy Update Magnitude: 0.07610
Value Function Update Magnitude: 0.06767

Collected Steps per Second: 23,291.90774
Overall Steps per Second: 14,851.60278

Timestep Collection Time: 2.14667
Timestep Consumption Time: 1.21997
PPO Batch Consumption Time: 0.09636
Total Iteration Time: 3.36664

Cumulative Model Updates: 3,060
Cumulative Timesteps: 25,559,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.29511
Policy Entropy: 2.34076
Value Function Loss: 2.85154

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.00519
Policy Update Magnitude: 0.08311
Value Function Update Magnitude: 0.05187

Collected Steps per Second: 22,088.99305
Overall Steps per Second: 13,959.89866

Timestep Collection Time: 2.26439
Timestep Consumption Time: 1.31859
PPO Batch Consumption Time: 0.10848
Total Iteration Time: 3.58298

Cumulative Model Updates: 3,066
Cumulative Timesteps: 25,609,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 25609474...
Checkpoint 25609474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,848.77296
Policy Entropy: 2.33913
Value Function Loss: 3.02699

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.02920
Policy Update Magnitude: 0.08942
Value Function Update Magnitude: 0.03351

Collected Steps per Second: 21,354.50567
Overall Steps per Second: 14,466.02937

Timestep Collection Time: 2.34218
Timestep Consumption Time: 1.11530
PPO Batch Consumption Time: 0.07858
Total Iteration Time: 3.45748

Cumulative Model Updates: 3,072
Cumulative Timesteps: 25,659,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.56267
Policy Entropy: 2.32671
Value Function Loss: 3.07197

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.01072
Policy Update Magnitude: 0.07386
Value Function Update Magnitude: 0.01950

Collected Steps per Second: 22,567.10036
Overall Steps per Second: 14,749.79608

Timestep Collection Time: 2.21694
Timestep Consumption Time: 1.17497
PPO Batch Consumption Time: 0.09950
Total Iteration Time: 3.39191

Cumulative Model Updates: 3,078
Cumulative Timesteps: 25,709,520

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 25709520...
Checkpoint 25709520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764.76090
Policy Entropy: 2.30923
Value Function Loss: 3.15136

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.01660
Policy Update Magnitude: 0.08756
Value Function Update Magnitude: 0.01957

Collected Steps per Second: 22,032.14123
Overall Steps per Second: 14,923.60856

Timestep Collection Time: 2.26996
Timestep Consumption Time: 1.08124
PPO Batch Consumption Time: 0.07557
Total Iteration Time: 3.35120

Cumulative Model Updates: 3,084
Cumulative Timesteps: 25,759,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426.03150
Policy Entropy: 2.33862
Value Function Loss: 2.97864

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02118
Policy Update Magnitude: 0.08345
Value Function Update Magnitude: 0.02103

Collected Steps per Second: 22,063.56879
Overall Steps per Second: 14,263.15710

Timestep Collection Time: 2.26681
Timestep Consumption Time: 1.23970
PPO Batch Consumption Time: 0.09464
Total Iteration Time: 3.50652

Cumulative Model Updates: 3,090
Cumulative Timesteps: 25,809,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 25809546...
Checkpoint 25809546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,556.49701
Policy Entropy: 2.31592
Value Function Loss: 2.92427

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.00678
Policy Update Magnitude: 0.09109
Value Function Update Magnitude: 0.01530

Collected Steps per Second: 22,412.50935
Overall Steps per Second: 15,055.98317

Timestep Collection Time: 2.23188
Timestep Consumption Time: 1.09052
PPO Batch Consumption Time: 0.08334
Total Iteration Time: 3.32240

Cumulative Model Updates: 3,096
Cumulative Timesteps: 25,859,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722.07843
Policy Entropy: 2.33568
Value Function Loss: 2.95385

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.02974
Policy Update Magnitude: 0.07681
Value Function Update Magnitude: 0.04674

Collected Steps per Second: 22,576.99861
Overall Steps per Second: 14,059.23253

Timestep Collection Time: 2.21562
Timestep Consumption Time: 1.34233
PPO Batch Consumption Time: 0.11424
Total Iteration Time: 3.55795

Cumulative Model Updates: 3,102
Cumulative Timesteps: 25,909,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 25909590...
Checkpoint 25909590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,768.97496
Policy Entropy: 2.32913
Value Function Loss: 3.15722

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.02618
Policy Update Magnitude: 0.08152
Value Function Update Magnitude: 0.06770

Collected Steps per Second: 21,360.39291
Overall Steps per Second: 14,068.26902

Timestep Collection Time: 2.34134
Timestep Consumption Time: 1.21361
PPO Batch Consumption Time: 0.09628
Total Iteration Time: 3.55495

Cumulative Model Updates: 3,108
Cumulative Timesteps: 25,959,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,681.53867
Policy Entropy: 2.31682
Value Function Loss: 3.13702

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.00981
Policy Update Magnitude: 0.08784
Value Function Update Magnitude: 0.06739

Collected Steps per Second: 21,977.86941
Overall Steps per Second: 14,281.71488

Timestep Collection Time: 2.27611
Timestep Consumption Time: 1.22655
PPO Batch Consumption Time: 0.09739
Total Iteration Time: 3.50266

Cumulative Model Updates: 3,114
Cumulative Timesteps: 26,009,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 26009626...
Checkpoint 26009626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,808.25061
Policy Entropy: 2.32492
Value Function Loss: 3.11168

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.00971
Policy Update Magnitude: 0.08852
Value Function Update Magnitude: 0.04873

Collected Steps per Second: 20,865.45616
Overall Steps per Second: 13,641.14919

Timestep Collection Time: 2.39861
Timestep Consumption Time: 1.27029
PPO Batch Consumption Time: 0.10101
Total Iteration Time: 3.66890

Cumulative Model Updates: 3,120
Cumulative Timesteps: 26,059,674

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,754.34821
Policy Entropy: 2.30150
Value Function Loss: 3.13797

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.07288
Value Function Update Magnitude: 0.03268

Collected Steps per Second: 22,444.02606
Overall Steps per Second: 14,924.89955

Timestep Collection Time: 2.22776
Timestep Consumption Time: 1.12234
PPO Batch Consumption Time: 0.08672
Total Iteration Time: 3.35011

Cumulative Model Updates: 3,126
Cumulative Timesteps: 26,109,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 26109674...
Checkpoint 26109674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.40697
Policy Entropy: 2.29605
Value Function Loss: 3.16198

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.07228
Value Function Update Magnitude: 0.04227

Collected Steps per Second: 23,322.56439
Overall Steps per Second: 15,528.52699

Timestep Collection Time: 2.14419
Timestep Consumption Time: 1.07621
PPO Batch Consumption Time: 0.07319
Total Iteration Time: 3.22040

Cumulative Model Updates: 3,132
Cumulative Timesteps: 26,159,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,657.49280
Policy Entropy: 2.29041
Value Function Loss: 3.22160

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.01658
Policy Update Magnitude: 0.07166
Value Function Update Magnitude: 0.02878

Collected Steps per Second: 22,618.68034
Overall Steps per Second: 14,795.45450

Timestep Collection Time: 2.21092
Timestep Consumption Time: 1.16904
PPO Batch Consumption Time: 0.08211
Total Iteration Time: 3.37996

Cumulative Model Updates: 3,138
Cumulative Timesteps: 26,209,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 26209690...
Checkpoint 26209690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,647.24793
Policy Entropy: 2.28624
Value Function Loss: 3.14051

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.02886
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.02339

Collected Steps per Second: 23,002.00183
Overall Steps per Second: 14,624.44295

Timestep Collection Time: 2.17381
Timestep Consumption Time: 1.24526
PPO Batch Consumption Time: 0.09771
Total Iteration Time: 3.41907

Cumulative Model Updates: 3,144
Cumulative Timesteps: 26,259,692

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.20840
Policy Entropy: 2.27918
Value Function Loss: 3.06144

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.01197
Policy Update Magnitude: 0.07580
Value Function Update Magnitude: 0.02905

Collected Steps per Second: 22,543.18780
Overall Steps per Second: 14,100.71544

Timestep Collection Time: 2.21876
Timestep Consumption Time: 1.32843
PPO Batch Consumption Time: 0.10562
Total Iteration Time: 3.54720

Cumulative Model Updates: 3,150
Cumulative Timesteps: 26,309,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 26309710...
Checkpoint 26309710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717.01306
Policy Entropy: 2.27225
Value Function Loss: 3.07780

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.01663
Policy Update Magnitude: 0.07191
Value Function Update Magnitude: 0.03077

Collected Steps per Second: 20,783.23310
Overall Steps per Second: 14,068.01786

Timestep Collection Time: 2.40713
Timestep Consumption Time: 1.14902
PPO Batch Consumption Time: 0.08139
Total Iteration Time: 3.55615

Cumulative Model Updates: 3,156
Cumulative Timesteps: 26,359,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.14089
Policy Entropy: 2.25313
Value Function Loss: 3.12085

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.01222
Policy Update Magnitude: 0.07839
Value Function Update Magnitude: 0.02195

Collected Steps per Second: 22,480.05146
Overall Steps per Second: 14,706.14530

Timestep Collection Time: 2.22446
Timestep Consumption Time: 1.17589
PPO Batch Consumption Time: 0.08423
Total Iteration Time: 3.40035

Cumulative Model Updates: 3,162
Cumulative Timesteps: 26,409,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 26409744...
Checkpoint 26409744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.44862
Policy Entropy: 2.26030
Value Function Loss: 3.07612

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.01723
Policy Update Magnitude: 0.07565
Value Function Update Magnitude: 0.01994

Collected Steps per Second: 16,891.49150
Overall Steps per Second: 11,770.34551

Timestep Collection Time: 2.96161
Timestep Consumption Time: 1.28856
PPO Batch Consumption Time: 0.09075
Total Iteration Time: 4.25017

Cumulative Model Updates: 3,168
Cumulative Timesteps: 26,459,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,679.69661
Policy Entropy: 2.25278
Value Function Loss: 3.22943

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.00369
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.01638

Collected Steps per Second: 19,557.59583
Overall Steps per Second: 12,395.76673

Timestep Collection Time: 2.55696
Timestep Consumption Time: 1.47732
PPO Batch Consumption Time: 0.07860
Total Iteration Time: 4.03428

Cumulative Model Updates: 3,174
Cumulative Timesteps: 26,509,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 26509778...
Checkpoint 26509778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659.19221
Policy Entropy: 2.27543
Value Function Loss: 3.16112

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.01635
Policy Update Magnitude: 0.08902
Value Function Update Magnitude: 0.01812

Collected Steps per Second: 15,611.91941
Overall Steps per Second: 10,367.52604

Timestep Collection Time: 3.20358
Timestep Consumption Time: 1.62052
PPO Batch Consumption Time: 0.13071
Total Iteration Time: 4.82410

Cumulative Model Updates: 3,180
Cumulative Timesteps: 26,559,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,814.09267
Policy Entropy: 2.26077
Value Function Loss: 3.28859

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.02676
Policy Update Magnitude: 0.08214
Value Function Update Magnitude: 0.01679

Collected Steps per Second: 18,814.68182
Overall Steps per Second: 12,086.45804

Timestep Collection Time: 2.65856
Timestep Consumption Time: 1.47995
PPO Batch Consumption Time: 0.12961
Total Iteration Time: 4.13852

Cumulative Model Updates: 3,186
Cumulative Timesteps: 26,609,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 26609812...
Checkpoint 26609812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.15942
Policy Entropy: 2.26941
Value Function Loss: 3.29181

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.01806
Policy Update Magnitude: 0.08260
Value Function Update Magnitude: 0.02059

Collected Steps per Second: 17,386.49858
Overall Steps per Second: 12,012.88084

Timestep Collection Time: 2.87625
Timestep Consumption Time: 1.28661
PPO Batch Consumption Time: 0.09920
Total Iteration Time: 4.16286

Cumulative Model Updates: 3,192
Cumulative Timesteps: 26,659,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,766.41250
Policy Entropy: 2.26915
Value Function Loss: 3.31125

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.01198
Policy Update Magnitude: 0.07592
Value Function Update Magnitude: 0.02755

Collected Steps per Second: 19,163.35426
Overall Steps per Second: 12,786.20134

Timestep Collection Time: 2.60936
Timestep Consumption Time: 1.30142
PPO Batch Consumption Time: 0.10733
Total Iteration Time: 3.91078

Cumulative Model Updates: 3,198
Cumulative Timesteps: 26,709,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 26709824...
Checkpoint 26709824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.46144
Policy Entropy: 2.22006
Value Function Loss: 3.23982

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.07978
Value Function Update Magnitude: 0.04933

Collected Steps per Second: 17,849.36049
Overall Steps per Second: 12,366.13746

Timestep Collection Time: 2.80189
Timestep Consumption Time: 1.24238
PPO Batch Consumption Time: 0.09473
Total Iteration Time: 4.04427

Cumulative Model Updates: 3,204
Cumulative Timesteps: 26,759,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691.73203
Policy Entropy: 2.23875
Value Function Loss: 3.21615

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.01408
Policy Update Magnitude: 0.07312
Value Function Update Magnitude: 0.09379

Collected Steps per Second: 19,449.10424
Overall Steps per Second: 12,906.33591

Timestep Collection Time: 2.57307
Timestep Consumption Time: 1.30440
PPO Batch Consumption Time: 0.10234
Total Iteration Time: 3.87748

Cumulative Model Updates: 3,210
Cumulative Timesteps: 26,809,880

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 26809880...
Checkpoint 26809880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,791.15686
Policy Entropy: 2.24136
Value Function Loss: 3.25587

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02065
Policy Update Magnitude: 0.08064
Value Function Update Magnitude: 0.08134

Collected Steps per Second: 18,903.66743
Overall Steps per Second: 12,858.89123

Timestep Collection Time: 2.64520
Timestep Consumption Time: 1.24347
PPO Batch Consumption Time: 0.10182
Total Iteration Time: 3.88867

Cumulative Model Updates: 3,216
Cumulative Timesteps: 26,859,884

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.55281
Policy Entropy: 2.19326
Value Function Loss: 3.47830

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.02315
Policy Update Magnitude: 0.07482
Value Function Update Magnitude: 0.05114

Collected Steps per Second: 17,877.75525
Overall Steps per Second: 12,058.39248

Timestep Collection Time: 2.79755
Timestep Consumption Time: 1.35010
PPO Batch Consumption Time: 0.10295
Total Iteration Time: 4.14765

Cumulative Model Updates: 3,222
Cumulative Timesteps: 26,909,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 26909898...
Checkpoint 26909898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.75906
Policy Entropy: 2.21760
Value Function Loss: 3.58598

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.00814
Policy Update Magnitude: 0.08233
Value Function Update Magnitude: 0.05579

Collected Steps per Second: 17,969.81532
Overall Steps per Second: 12,101.16299

Timestep Collection Time: 2.78400
Timestep Consumption Time: 1.35015
PPO Batch Consumption Time: 0.10729
Total Iteration Time: 4.13415

Cumulative Model Updates: 3,228
Cumulative Timesteps: 26,959,926

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.85477
Policy Entropy: 2.21148
Value Function Loss: 3.63751

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.00604
Policy Update Magnitude: 0.08208
Value Function Update Magnitude: 0.07526

Collected Steps per Second: 19,842.92019
Overall Steps per Second: 13,118.65465

Timestep Collection Time: 2.52231
Timestep Consumption Time: 1.29287
PPO Batch Consumption Time: 0.10195
Total Iteration Time: 3.81518

Cumulative Model Updates: 3,234
Cumulative Timesteps: 27,009,976

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 27009976...
Checkpoint 27009976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446.47406
Policy Entropy: 2.19895
Value Function Loss: 3.23018

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.01666
Policy Update Magnitude: 0.07648
Value Function Update Magnitude: 0.06871

Collected Steps per Second: 19,322.41943
Overall Steps per Second: 12,966.81540

Timestep Collection Time: 2.58819
Timestep Consumption Time: 1.26858
PPO Batch Consumption Time: 0.09789
Total Iteration Time: 3.85677

Cumulative Model Updates: 3,240
Cumulative Timesteps: 27,059,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.27975
Policy Entropy: 2.20815
Value Function Loss: 3.14910

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.01785
Policy Update Magnitude: 0.09141
Value Function Update Magnitude: 0.05274

Collected Steps per Second: 18,531.34532
Overall Steps per Second: 12,703.07579

Timestep Collection Time: 2.69964
Timestep Consumption Time: 1.23862
PPO Batch Consumption Time: 0.10814
Total Iteration Time: 3.93826

Cumulative Model Updates: 3,246
Cumulative Timesteps: 27,110,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 27110014...
Checkpoint 27110014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.57565
Policy Entropy: 2.21398
Value Function Loss: 3.23958

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.04197
Policy Update Magnitude: 0.07956
Value Function Update Magnitude: 0.04171

Collected Steps per Second: 17,804.71970
Overall Steps per Second: 12,193.15022

Timestep Collection Time: 2.80993
Timestep Consumption Time: 1.29319
PPO Batch Consumption Time: 0.10364
Total Iteration Time: 4.10312

Cumulative Model Updates: 3,252
Cumulative Timesteps: 27,160,044

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.37878
Policy Entropy: 2.19401
Value Function Loss: 2.92188

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.01848
Policy Update Magnitude: 0.07675
Value Function Update Magnitude: 0.06786

Collected Steps per Second: 19,072.06950
Overall Steps per Second: 12,556.64758

Timestep Collection Time: 2.62237
Timestep Consumption Time: 1.36070
PPO Batch Consumption Time: 0.11819
Total Iteration Time: 3.98307

Cumulative Model Updates: 3,258
Cumulative Timesteps: 27,210,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 27210058...
Checkpoint 27210058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468.22347
Policy Entropy: 2.23215
Value Function Loss: 2.96943

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.02545
Policy Update Magnitude: 0.08093
Value Function Update Magnitude: 0.04163

Collected Steps per Second: 18,771.85812
Overall Steps per Second: 12,670.22448

Timestep Collection Time: 2.66463
Timestep Consumption Time: 1.28321
PPO Batch Consumption Time: 0.10287
Total Iteration Time: 3.94784

Cumulative Model Updates: 3,264
Cumulative Timesteps: 27,260,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487.46440
Policy Entropy: 2.26635
Value Function Loss: 2.84496

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.08031
Value Function Update Magnitude: 0.08270

Collected Steps per Second: 19,480.26397
Overall Steps per Second: 13,180.42195

Timestep Collection Time: 2.56680
Timestep Consumption Time: 1.22685
PPO Batch Consumption Time: 0.09166
Total Iteration Time: 3.79366

Cumulative Model Updates: 3,270
Cumulative Timesteps: 27,310,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 27310080...
Checkpoint 27310080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,780.23164
Policy Entropy: 2.22924
Value Function Loss: 2.89669

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.04112
Policy Update Magnitude: 0.08898
Value Function Update Magnitude: 0.14037

Collected Steps per Second: 19,493.82260
Overall Steps per Second: 13,642.01617

Timestep Collection Time: 2.56502
Timestep Consumption Time: 1.10028
PPO Batch Consumption Time: 0.08889
Total Iteration Time: 3.66529

Cumulative Model Updates: 3,276
Cumulative Timesteps: 27,360,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,838.99761
Policy Entropy: 2.23279
Value Function Loss: 2.92297

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.02820
Policy Update Magnitude: 0.08316
Value Function Update Magnitude: 0.13056

Collected Steps per Second: 20,210.21175
Overall Steps per Second: 13,316.91477

Timestep Collection Time: 2.47410
Timestep Consumption Time: 1.28068
PPO Batch Consumption Time: 0.10094
Total Iteration Time: 3.75477

Cumulative Model Updates: 3,282
Cumulative Timesteps: 27,410,084

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 27410084...
Checkpoint 27410084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724.74416
Policy Entropy: 2.22082
Value Function Loss: 2.97392

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.01762
Policy Update Magnitude: 0.07251
Value Function Update Magnitude: 0.09513

Collected Steps per Second: 19,629.88555
Overall Steps per Second: 13,296.86927

Timestep Collection Time: 2.54856
Timestep Consumption Time: 1.21383
PPO Batch Consumption Time: 0.09296
Total Iteration Time: 3.76239

Cumulative Model Updates: 3,288
Cumulative Timesteps: 27,460,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,811.14568
Policy Entropy: 2.22517
Value Function Loss: 3.00348

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01607
Policy Update Magnitude: 0.07889
Value Function Update Magnitude: 0.06721

Collected Steps per Second: 20,081.24133
Overall Steps per Second: 13,489.17855

Timestep Collection Time: 2.49028
Timestep Consumption Time: 1.21698
PPO Batch Consumption Time: 0.10403
Total Iteration Time: 3.70727

Cumulative Model Updates: 3,294
Cumulative Timesteps: 27,510,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 27510120...
Checkpoint 27510120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724.06199
Policy Entropy: 2.18900
Value Function Loss: 3.08207

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.05628
Policy Update Magnitude: 0.07332
Value Function Update Magnitude: 0.04273

Collected Steps per Second: 17,154.31955
Overall Steps per Second: 11,858.39822

Timestep Collection Time: 2.91542
Timestep Consumption Time: 1.30202
PPO Batch Consumption Time: 0.09591
Total Iteration Time: 4.21743

Cumulative Model Updates: 3,300
Cumulative Timesteps: 27,560,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 27560132...
Checkpoint 27560132 saved!
